00:00:03 <kmc> constructs data
00:00:15 <mauke> zhulikas: creating values of that type
00:00:22 <kmc> if i just say:  1234 "Foo" ["bar", "baz"]
00:00:24 <zhulikas> can you give me an example of how data can be constructed in different ways using the data structure above?
00:00:25 <kmc> that's just three values
00:00:43 <kmc> the data constructor packages them together and gives it a type
00:00:46 <zhulikas> aaaa
00:00:50 <mauke> zhulikas: it can't, depending on how you define "different"
00:00:54 <zhulikas> I think I get it
00:01:15 <kmc> note that Book is effectively a function of type Int -> String -> [String] -> BookInfo
00:01:16 <zhulikas> the number of different constructors shows how many different structures can a type hold? right?
00:01:23 <mauke> yeah, more or less
00:01:28 <mustelo> zhulikas, if you keep reading real world haskell there's a section in chapter 3 called "algebraic data types" that goes over this
00:01:34 <mauke> zhulikas: data Bool = False | True
00:01:44 <mauke> a type with two value constructors
00:01:55 <shachaf> kmc: I'd be more accepting of the GADT syntax if a pattern match like ((Foo a) b) was allowed. :-)
00:02:05 <kmc> hehe
00:02:25 <shachaf> Of course, a partially-matched pattern is a pretty weird thing.
00:02:27 <zhulikas> data BookInfo = Book Int String [String | Book2 Int [String] [String]
00:02:29 <zhulikas> is it right?
00:02:40 <kmc> yeah
00:02:46 <mustelo> zhulikas, sure, but maybe not useful :)
00:02:53 <kmc> thought the duplication is troubling
00:03:01 <zhulikas> sure it's not useful. I am just trying to get the syntax
00:03:09 <kmc> you might instead say: data BookType = BookA | BookB;  data Book = Book BookType Int String [String]
00:03:11 <mauke> hmm, a book with multiple titles
00:03:17 <mauke> kmc: Book2 takes two lists
00:03:18 <zhulikas> whoa thats really strange :) one type can hold different data structures...
00:04:08 <zhulikas> but then there is a problem of threating each data structure in the type in a same way...
00:04:23 <mauke> that's solved by pattern matching
00:04:25 <mustelo> zhulikas, you would then pattern match to see what type it is
00:04:26 <zhulikas> ok :)
00:04:35 <mauke> s/type/value constructor/
00:04:45 <mustelo> er, right, poor use of the word "type" there
00:04:50 <zhulikas> hehe :)
00:05:19 <zhulikas> kmc, this looks strange to me: data Book = Book BookType Int String [String]
00:05:23 <zhulikas> why did you include BookType inside?
00:05:39 <mauke> zhulikas: why did you include Int inside?
00:05:54 <shachaf> kmc: Maybe you're right about the standard ADT syntax being confusing. :-)
00:06:31 <zhulikas> well this line states that this data structure has a Book value constructor and holds BookType data type which also holds data structures of type Book o.O
00:06:35 <zhulikas> oh, wait.
00:06:39 <zhulikas> there is BookA | BookB
00:06:49 <zhulikas> give me a sec.
00:06:57 <zhulikas> I want to write something and ask if it is right
00:07:42 <mauke> (a*b + a*c) = a * (b + c)
00:08:19 <zhulikas> http://hpaste.org/49901
00:08:21 <zhulikas> is that right?
00:08:28 <zhulikas> dispite the stupid naming
00:08:55 <mauke> well, it's valid code
00:09:00 <shachaf> That depends on what "right" is. It's probably not whatever you meant it to be.
00:09:03 <zhulikas> now I am referencing to a different data type inside BookInfo
00:09:03 <mauke> but it makes no sense as far as I can see
00:09:08 <zhulikas> :D
00:09:10 <mauke> zhulikas: no, you're not
00:09:27 <zhulikas> I want BookInfo to hold either Book1 or Book 2
00:09:43 <mauke> yes
00:09:51 <mauke> but Book1 isn't a type there
00:09:53 <mauke> it's a value constructor
00:10:03 <shachaf> zhulikas: When you say "data A = B C D | F G H", A, C, D, G, and H are types, but B and F are value-level constructors.
00:10:09 <zhulikas> data BookType = Book1 | Book2
00:10:14 <zhulikas> here are value constructors, not data types ?
00:10:23 <shachaf> Book1 and Book2 are.
00:10:28 <mauke> BookType = type;  Book1, Book2 = value constructors
00:10:38 <zhulikas> ok
00:10:47 <shachaf> data BookType where { Book1 :: BookType; Book2 :: BookType } is another syntax for the same declaration.
00:11:00 <zhulikas> don't. I am new :)
00:11:05 <shachaf> ?
00:11:27 <zhulikas> so can I reference to a value constructor from a different type?
00:11:34 <mauke> no
00:12:05 <zhulikas> so how am I supposed to define what's inside Book1 Book2?
00:12:10 <zhulikas> data BookType = Book1 | Book2
00:12:24 <mauke> there's nothing "inside" Book1/Book2
00:12:38 <zhulikas> those are value constructors for SOMETHING :|
00:12:39 <mauke> they're values
00:12:44 <mauke> zhulikas: yes, for BookType
00:12:50 <zhulikas> or you mean those are empty value constructors?
00:13:06 <mauke> yeah, no parameters
00:13:09 <zhulikas> but when how can I create some data using that type
00:13:15 <mauke> you just write Book1
00:13:24 <mauke> that's a value :-)
00:13:27 <zhulikas> so what data does it hold?
00:13:29 <mauke> none
00:13:37 <zhulikas> and what space does it take in the memory?
00:13:48 <mauke> good question
00:13:49 <zhulikas> I can only imagine an empty object in OOP here :)
00:14:01 <mauke> zhulikas: it's not quite empty because it knows whether it's Book1 or Book2
00:14:06 <mauke> that's one bit of information
00:14:28 <zhulikas> a bit more than a bit I guess :D
00:14:37 <mauke> no, literally 1 bit
00:14:40 <zhulikas> oh
00:15:05 <mauke> it's probably stored as a machine word, so 4 bytes here? I'm not sure
00:15:15 <zhulikas> probably
00:16:15 <zhulikas> http://hpaste.org/49902
00:16:18 <zhulikas> so this is right?
00:16:45 <mauke> it still makes no sense to me, but it's valid code
00:16:54 <zhulikas> why it doesn't make sense?
00:17:02 <zhulikas> it stores two possible data structures
00:17:09 <mauke> because your "BookType" doesn't store the type of a book
00:17:19 <mauke> and I don't see why Book11/Book22 are separate types
00:17:23 <mauke> you could just inline them
00:17:29 <zhulikas> for the sake of understanding
00:17:47 <mauke> zhulikas: what was wrong with kmc's original example?
00:18:01 <zhulikas> how Book11 and Book22 which are inside BookType value constructors doesn't show the type of a book?
00:18:27 <mauke> what?
00:19:04 <zhulikas> you mean this one?
00:19:05 <zhulikas> data BookType = BookA | BookB;  data Book = Book BookType Int String [String]
00:19:13 <mauke> yes
00:19:38 <zhulikas> ohh I get it :D I did it in the opposite way before
00:19:39 <mauke> that says a book type is either BookA or BookB; and a Book consists of a book type, an int, a string, and a list of strings
00:19:55 <zhulikas> Book should have a type. BookType should not have a book
00:20:02 <mauke> yeah
00:20:10 <zhulikas> haha that was stupid what I did :D
00:20:18 <zhulikas> that definitely makes sense
00:20:24 <zhulikas> I was just thinking about something else
00:20:37 <zhulikas> ok, thank you very much :)
00:21:06 <zhulikas> data BookType = BookA | BookB looks like an enum to me :)
00:21:15 <mauke> it is
00:21:16 * zhulikas googles enums on haskell
00:21:20 <zhulikas> ok :)
00:21:28 <mauke> data BookType = BookA | BookB  deriving (Enum, Bounded)
00:21:43 <kmc> C's enums, structs, and unions are each an awkward special case of this "algebraic data type" concept
00:21:54 <mauke> now you can do stuff like [BookA .. BookB]
00:21:59 <kmc> it's nice to have a single concept that encompasses all three and much more
00:22:02 <mauke> except that would be completely useless, but whatever
00:22:20 <zhulikas> :D
00:22:40 <zhulikas> what about jumping ? Like [1,3..15] ?
00:22:54 <zhulikas> does it 'index' the constructors in the type ?
00:22:57 * RayNbow wonders why types like Double are an instance of Enum
00:23:00 <mauke> [BookA, BookB .. BookB]
00:23:02 <mauke> zhulikas: yes
00:23:21 <mauke> it's just not very useful here because there are only two possible values
00:23:36 <zhulikas> so If I have enums of BookA..BookZ and I construct a list of [BookA,BookC..BookZ] I can expect it to skip each even constructor?
00:23:39 <mauke> yes
00:23:42 <zhulikas> ok :D
00:23:43 <kmc> zhulikas, that's sugar for (enumFromThenTo 1 3 15)
00:23:53 <kmc> which invokes a method from the Enum type class
00:23:57 <kmc> which in theory can do whatever you want
00:24:03 <zhulikas> I know all this is ridiculous for you guys
00:24:05 <shachaf> kmc: C's unions, being untagged, aren't a lot like ADTs.
00:24:12 <kmc> shachaf, hence "awkward" :)
00:24:17 <shachaf> You can tag them manually, of course, but they're more often used for other things, I think.
00:24:19 <mauke> zhulikas: nah, it's fine
00:24:35 <zhulikas> also I'm starting to like Haskell really much :)
00:24:39 <kmc> shachaf, they're often used for the punning behavior which is disallowed by the spec :)
00:24:40 <kmc> anyway bbl
00:24:45 <mauke> > ['A', 'D .. 'Z']
00:24:46 <lambdabot>   <no location info>:
00:24:46 <lambdabot>      lexical error in string/character literal at chara...
00:24:50 <mauke> > ['A', 'D' .. 'Z']
00:24:51 <lambdabot>   "ADGJMPSVY"
00:25:20 <zhulikas> > ["A", "D" .. "Z"]
00:25:21 <lambdabot>   No instance for (GHC.Enum.Enum [GHC.Types.Char])
00:25:22 <lambdabot>    arising from the arithm...
00:25:28 <shachaf> > [1.0, 3.0 .. 4.0]
00:25:28 <lambdabot>   [1.0,3.0,5.0]
00:25:51 <zhulikas> > [10, 9.25..8]
00:25:52 <lambdabot>   [10.0,9.25,8.5,7.75]
00:25:54 <mauke> zhulikas: what that error message means is that String is not an Enum
00:25:54 <zhulikas> \o/
00:26:10 <zhulikas> But I know it's because it adds aditional 0.5 to a float when doing that (or something similar)
00:26:31 <zhulikas> I see
00:26:50 <mauke> String = [Char]
00:27:42 <zhulikas> data BookType = BookA | BookB  deriving (Enum, Bounded)
00:27:55 <zhulikas> also I didin't think Haskell allows type inheritance
00:28:02 <mauke> it doesn't
00:28:14 <zhulikas> then deriving keyword is misleading for newbies
00:28:21 <mauke> so is 'class'
00:28:31 <zhulikas> I don't get so far yet :)
00:28:32 <shachaf> It's not misleading for people who know nothing about OO and what not.
00:28:35 <mauke> and it's only misleading if you've used something like java before
00:28:55 <mauke> in fact, java's "class" keyword is misleading if you only know haskell
00:29:14 <shachaf> Is deriving even a keyword in Java?
00:29:15 <zhulikas> hehe :)
00:29:18 <mauke> no
00:29:39 <zhulikas> but word means - inheriting
00:29:48 <zhulikas> at least how I understand it
00:29:54 <mauke> not in haskell
00:29:56 <zhulikas> ok :)
00:30:20 <shachaf> "derive" means many other things in e.g. mathematics.
00:30:20 <mauke> it tells the compiler to automatically write ("derive") code for you
00:30:46 <mauke> which it does by looking at the type definition you've written
00:45:38 <ukl> mg
00:45:51 <ukl> (eek, wrong focus, sorry.)
00:52:48 <NihilistDandy> mg must be really filthy in some context
00:53:37 <Cale> mg so bm
01:08:15 <kizzx2> hey guys wassup
01:09:00 <kizzx2> (feeling embarrassed saying this) anyone up for a code critique for a newbie? here's my Game of Life   https://github.com/kizzx2/haskell-gameoflife/blob/master/GameOfLife.hs
01:09:54 <kizzx2> it feels quite messy and i'm really curious how an uberman can turn it into a dozen of lines
01:13:16 <mustelo> kizzx2, what do you feel is messy about it?
01:13:50 <kizzx2> mustelo: on a macro scale, it doesn't feel "clean" haskell (the one-liner style that always stun me)
01:14:14 <kizzx2> on a specific scale (about the program), i need to pass World around to almost every functions
01:15:23 <kizzx2> and it feels rudimentary (doesn't use advanced techniques like inventing my Monad or Arrows), i'm just wondering if it can be improved to use more advanced techniques (yes, just for using those techniques' sake, this is a practice program)
01:15:49 <mustelo> kizzx2, well, passing the same thing around everywhere is classic Reader monad
01:16:08 <shachaf> Or State, if you're modifying it.
01:16:22 <shachaf> State World is a pretty common idiom.
01:16:25 <jocom> kizzx2: http://blog.sigfpe.com/2006/12/evaluating-cellular-automata-is.html
01:16:38 <jocom> kizzx2: That blogpost might give you hints ^^
01:17:00 <jocom> The comments also expand on going to 2-d automata
01:17:04 <kizzx2> thanks!
01:17:17 <kizzx2> i wonder if making it a Reader World is an improvement?
01:17:42 <kizzx2> that makes the function a monadic function, and doesn't that limit its flexibility?
01:17:56 <shachaf> Why would it?
01:18:12 <kizzx2> umm yeah i think it wouldn't :P
01:18:21 <shachaf> Reader World is equivalent to (World ->) -- in fact, (World ->) is also a monad.
01:18:42 <shachaf> Your World seems to consist of both an "immutable" and a "mutable" part, though.
01:19:22 <kizzx2> shachaf: ummhmm?
01:19:31 <kizzx2> a new world is genearted each time in` step`
01:19:44 <mustelo> but the rules don't change
01:20:06 <kizzx2> (and responding to "which part do you feel messy", the Parsec part is a total mess, isn't it)
01:20:20 <mustelo> it could be a bit more idiomatic, sure
01:20:23 * shachaf imagines a game of life where rules are localized somehow and change based on the states of the cells.
01:20:27 <mustelo> using (<*) and friends
01:20:41 <kizzx2> mustelo: thanks, i didnt know that :P
01:20:48 <mustelo> :t (<*)
01:20:49 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f a -> f b -> f a
01:20:50 <mauke> <* is essential for writing parsers
01:20:51 <kizzx2> since this is a beginner program please do point out the "trivials"
01:21:04 <mustelo> comment = string "#D " >> (many $ noneOf "\n") >>= \content -> eol >> return content
01:21:05 <mauke> in fact, I invented it before Applicative
01:21:25 <mustelo> the last part there can use (<*), for example
01:21:30 <mauke> string "#D " *> many (noneOf "\n") <* eol
01:21:37 <mustelo> beautiful
01:21:41 <kizzx2> cool
01:27:39 <mustelo> specifiedRules' :: Parser ([Int], [Int])
01:27:39 <mustelo> specifiedRules' = (liftM2 (,) `on` (fmap $ map digitToInt))
01:27:39 <mustelo>                   (string "#R" *> many1 digit)
01:27:39 <mustelo>                   (char '/' *> many1 digit <* eol)
01:27:57 <mustelo> kizzx2, if you want to go a bit crazy... ^^
01:28:16 <jocom> Can someone help me with clarifying some stuff about the Categorical POV towards Haskell...?
01:28:35 <jocom> Is (a -> b) a type?
01:28:42 <mustelo> jocom, sure
01:28:51 <jocom> I.e., is it an object of Hask?
01:28:52 <kizzx2> mustelo: thanks, i'll go hurt my brain a bit more
01:29:29 <jocom> It it is a type, then that means that all morphisms of Hask are objects as well
01:29:47 <mustelo> kizzx2, not suggesting that's more readable
01:29:48 <jocom> If*
01:30:27 <jocom> And, is there any implementation of multiple categories in Haskell?
01:30:34 <kizzx2> i'm trying to convert the main functions to type Reader World a, one consequence is that all functions start with `do`, is that a common thing?
01:30:37 <jocom> Else every functor is an endofunctor
01:31:16 <mustelo> kizzx2, there are other combinators like the liftMn family which avoid unnecessary do's
01:31:26 <mustelo> but it's not necessarily a bad thing either
01:31:36 <shachaf> jocom: I don't think objects in Hask are polymorphic types.
01:32:01 <jocom> shachaf: Well, maybe I should have given (String -> Int) as example
01:32:17 <jocom> I think that (a -> b) isn't a type
01:32:37 <jocom> But I'm not sure whether (String -> Int) is an object of Hask
01:33:12 <jocom> But, from my mathematical POV, I would expect Monoid to be a category... it seems it isn't
01:33:17 <shachaf> I'd think it would be.
01:33:18 <ion> mustelo: num :: Parser [Int]; natural = map digitToInt <$> many1 digit; specifiedRules = liftA2 (,) (string "#R" *> num) (char '/' *> num) <* eol
01:33:41 <mustelo> ion, much nicer :)
01:33:47 <jocom> shachaf: to which statement did you reply?
01:33:54 <shachaf> (String -> Int)
01:33:58 <jocom> Ok
01:35:20 <jocom> So, we might state: Hom(X, Y) \in ob(Hask) for all X,Y in ob(Hask)
01:35:52 <ion> Whoops, s/natural/num/. I began writing it as natural, but then noticed it results in a list, not an Integer. Forgot to rename it.
01:36:25 <jocom> Am I correct in my assumption that every functor is an endofunctor?
01:36:34 <mustelo> jocom, in haskell, yes
01:37:24 <jocom> mustelo: Obviously I was talking about Haskell, but thanks for the addition (-;
01:37:49 <mustelo> jocom, don't want you crying to ##category theory about functors being endofunctors :)
01:37:58 <jocom> Haha
01:38:33 <mustelo> cell' :: Parser Cell
01:38:34 <mustelo> cell' = Dead <$ char '.' <|> Live <$ char '*'
01:38:43 <mustelo> kizzx2
01:38:44 <jocom> Next thing that isn't clear to me: Why are Haskell monads the categorical equivalent of strong monads
01:38:54 <jocom> Why not just the categorical monad
01:39:21 <jocom> I don't see how the extra structure of a strong monad arises in Haskell
01:40:26 <kizzx2> mustelo: thanks, woot with the Parsec part cleanup this feels cleaner
01:41:13 <kizzx2> i have one more question, in `step` (line 84 - 85), i deconstruct the array to a list, map functions and then put it back to an array
01:41:14 <mustelo> kizzx2, the " >> return x" idiom can be replaced in Parsec using  (<$) from Functor
01:41:15 <jocom> First I've never read about Hask being a monoidal category
01:41:22 <kizzx2> this screams slow performance
01:41:25 <Cale> jocom: There's a function (Monad m) => (a,m b) -> m (a,b) which you can write
01:41:35 <ion> kizzx2: http://heh.fi/haskell/functors/
01:41:38 <kizzx2> is there a better data structure than Data.Array? (i need map and 2d indexing)
01:41:49 <kizzx2> s/than Data.Array/than Data.Array for this situation/
01:41:56 <jocom> Next, I don't see how the needed extra natural transformation arises from bind and return
01:42:01 <benmachine> :t uncurry . fmap . (,)
01:42:02 <lambdabot> forall b a a1. a1 -> (b -> a, b) -> (a1, a)
01:42:10 <benmachine> oh, whoops
01:42:15 <jocom> Cale: Could you explain a bit?
01:42:41 <benmachine> :t uncurry (fmap . (,))
01:42:41 <lambdabot> forall a (f :: * -> *) a1. (Functor f) => (a1, f a) -> f (a1, a)
01:43:15 <jocom> How is Hask a monoidal category?
01:43:25 <Cale> jocom: with (,) and ()
01:43:56 <jocom> Hmmz, never seen (,) before (-;
01:44:08 <benmachine> tuple constructor
01:44:12 <ion> @unpl uncurry (fmap . (,))
01:44:13 <lambdabot> uncurry (\ c -> fmap (((,)) c))
01:44:23 <jocom> Ooh, right, let's see...
01:45:16 <jocom> Yeah, nice! Got that
01:46:11 <mustelo> kizzx2, it doesn't seem that bad to use Data.Array here... it gets bad when you make very localized changes which depend on each other, but I would think that mapping isn't terribly less efficient than you'd expect
01:48:12 <kizzx2> mustelo: so maybe the explanation is conversion from and to array/list is O(n) so it doen't make it that much worse since printing the world is O(n)???
01:48:54 <mustelo> right, since you're potentially changing every cell anyways, it's still O(n)
01:49:07 <kizzx2> right
01:49:15 <mustelo> also, hopefully some of the array -> list -> array stuff will get optimized out
01:49:40 <jocom> Can someone explain to me the uncurry (fmap . (,)) trickery?
01:49:55 <mustelo> jocom, sure, what about it?
01:50:35 <coppro> :t (,)
01:50:36 <lambdabot> forall a b. a -> b -> (a, b)
01:50:36 <mustelo> kizzx2, also checkout Data.Array.IArray for the amap function
01:50:37 <jocom> Well, how does that give a natural transformation M (a, b) => (a, M b)
01:50:39 <coppro> :t fmap . (,)
01:50:40 <lambdabot> forall a (f :: * -> *) a1. (Functor f) => a1 -> f a -> f (a1, a)
01:50:47 <kizzx2> mustelo: thanks for the tip
01:50:54 <benmachine> uncurry (fmap . (,) = \(x,y) -> (fmap . (,)) x y = fmap ((,) x) y = fmap (\z -> (x,z)) y
01:51:07 <coppro> :t uncurry $ fmap . (,)
01:51:08 <lambdabot> forall a a1 (f :: * -> *). (Functor f) => (a, f a1) -> f (a, a1)
01:51:12 <benmachine> er
01:51:20 <benmachine> I forgot my \(x,y) but you get the idea
01:51:47 <mustelo> jocom, are you asking why that function is a natural transformation in the CT sense? or are you asking a syntactic question about why that function can be written that way?
01:52:21 <benmachine> I believe the natural transformation bit comes from being parametrically polymorphic
01:52:27 <benmachine> but I'm not an expert
01:52:31 <mustelo> benmachine, indeed.
01:52:54 <jocom> Ok, that's fine
01:53:03 <jocom> I guess I've got it now (-;
01:57:06 <jocom> Hmm, I still have a question about the fmap part
01:57:32 <jocom> fmap (a,b) would treat (a,b) as a morphism, right?
01:58:31 <mustelo> it would try, but not be happy
01:58:32 <rtharper> jocom: yes, it would assume (a,b) has type (a -> b)
01:59:16 <jocom> but, isn't: fmap . (,) a b equivalent to fmap (a,b) ??
01:59:35 <mustelo> jocom, no!
01:59:45 <mustelo> careful with (,) as it's a binary function
01:59:50 <jocom> Then there is a flaw in my reasoning there
02:00:34 <jocom> I still don't get why :t fmap . (,) is what it is...
02:00:56 <Cale> :t (,)
02:00:57 <mustelo> jocom, okay
02:00:57 <lambdabot> forall a b. a -> b -> (a, b)
02:01:03 <Cale> :t (,) "hello"
02:01:04 <lambdabot> forall b. b -> ([Char], b)
02:01:05 <jocom> Cale: Got that (-;
02:01:29 <jocom> Yes, I understand that part
02:01:36 <benmachine> (f . g) x = f (g x)
02:01:39 <mustelo> jocom, you want to read that as (,) :: a -> (b -> (a,b))
02:01:48 <benmachine> so, fmap . (,) = \x -> fmap ((,) x)
02:01:49 <Cale> fmap . (,) = (\x -> fmap ((,) x))
02:02:19 <mustelo> kizzx2, another one:
02:02:21 <mustelo> readWorld :: FilePath -> IO (Either ParseError World)
02:02:22 <mustelo> readWorld path = parse worldParser path <$> readFile path
02:02:23 <benmachine> or equivalently, \x -> fmap (\z -> (x,z))
02:02:26 <jocom> Aah, I got it
02:03:05 <jocom> So it would be applied something like (fmap . (,) a) b
02:03:19 <kizzx2> :t (<$>)
02:03:20 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
02:03:21 <benmachine> umm
02:03:26 <jocom> In stead of fmap . ((,) a b)
02:03:30 <benmachine> (fmap . (,)) a b
02:03:58 <mustelo> jocom, as an exercise (without using @pl) try to find a combinator of type (c -> d) -> (a -> b -> c) -> a -> b -> d
02:04:26 <mustelo> kizzx2, (<$>) = fmap, just infix version
02:04:38 <kizzx2> mustelo: ic
02:04:39 <jocom> Sorry, what do you exactly mean with a combinator?
02:04:56 <mustelo> well, I mean write that function
02:05:13 <mustelo> then try to do it point free in an economical way, if you're into that sort of thing
02:06:11 <jocom> Well I'd just do f . g, if the inputs where f g a b
02:06:29 <benmachine> I don't think that works
02:06:29 <mustelo> you'd be wrong :)
02:06:36 <jocom> And apply f . g to a and b
02:06:45 <mustelo> jocom, that's exactly the situation we just had with fmap . (,)
02:06:50 <mustelo> doesn't work that way
02:06:53 <benmachine> the thing to understand about . is that it's not magic
02:07:10 <benmachine> the only rule is (f . g) x = f (g x)
02:07:23 <benmachine> and hence (for e.g.) (f . g) x y = f (g x) y
02:07:34 <benmachine> it can't tell how many arguments f or g want
02:07:40 <jocom> Aha...
02:07:44 <mustelo> which in this case was exactly what we wanted
02:07:47 <jocom> Let me try again
02:08:04 <mustelo> but in the exercise, we want the other case: compose a unary function with the result of a binary function
02:08:40 <jocom> But f (g x y) would do the trick, right?
02:08:54 <benmachine> jocom: in mustelo's exercise. yes
02:09:17 <mustelo> jocom, yeah, of course. the fun part is pointfreeing that
02:09:23 <jocom> But, that isn't the solution you were looking for
02:09:26 <jocom> Yeah, idd
02:10:07 <mustelo> jocom, fair warning, I'm not claiming there's deep truth lying in my solution, but it'll help you get your head around (.)
02:10:24 <jocom> I believe you immediately
02:10:44 <jocom> I don't understand why I've never had problems with \circ in all the maths that I've done
02:10:52 <jocom> And still I don't grasp (.)
02:11:24 <benmachine> jocom: well, because in maths multi-argument functions are usually represented with tuples
02:11:27 <NihilistDandy> mustelo: I've got it, maybe
02:11:37 <benmachine> NihilistDandy: so have I, but shh :P
02:11:38 <jocom> benmachine: I guess so
02:11:50 <mustelo> NihilistDandy, free to pm if you want
02:11:52 <benmachine> jocom: in haskell we use functions that return functions, which is considerably rarer (than it should be) in maths
02:13:06 <jocom> Well, what about doing f . g . (,)
02:13:17 <jocom> I guess that might do the trick
02:14:11 <mustelo> jocom, running into the same issue.
02:14:15 <mustelo> just look at g . (,) there
02:14:21 <coppro> f . g . (,) seems very wrong
02:14:35 <jocom> ok
02:14:55 <mustelo> well, I guess I should say, the solution doesn't include (,)
02:15:01 <mustelo> I just meant that g . (,) doesn't make sense
02:15:10 <mustelo> (in this context)
02:16:10 <jocom> Hmmz tricked by the associativity of (.) I guess
02:16:24 <jocom> f . (g . (,))
02:16:54 <mustelo> jocom, no, you've got other problems. stop thinking about (,)
02:17:13 <mustelo> start with \a x -> f (g a b)
02:17:18 <mustelo> er, \a b
02:18:41 <jocom> Ok, my reasoning is: f . (g . (,)) a = f (g . (,) a) = f ( g (a, _) )
02:18:49 <jocom> Which seems to me that it is what I want
02:18:56 <jocom> But, I'll try your way now
02:20:36 <jocom> Hmm, I see
02:20:48 <jocom> Why my former way doesn't work
02:21:07 <jocom> g isn't a function on tuples (:headdesk:) tricked again!
02:22:40 <jocom> so if I curry my previous solution, it should work
02:22:55 <mustelo> currying wasn't the main issue
02:22:59 <jocom> But I guess there is a shorter solution
02:23:08 <mustelo> I promise f . g is not the answer
02:24:16 <jocom> I know that that isn't
02:24:41 <jocom> f.g a b = f (g a) b <= error
02:28:08 <mustelo> jocom, are you familiar with things like (f .) ?
02:32:32 <jocom> mustelo: A bit
02:32:55 <jocom> I takes a function g as input and outputs f . g
02:33:19 <eddayyy> is there a way of generically being able to determine whether some JSON data corresponds to some data type?
02:33:21 <mustelo> right. that's going to be useful here
02:33:21 <jocom> So if f is of type F, and g of type G
02:33:51 <jocom> Then (f.) is of type dom(G) -> range(F)
02:34:13 <sanjoyd> Is literate haskell worth it?
02:34:47 <jocom> mustelo: You want my to make a combinator that has as final type b -> d, right?
02:35:41 <NihilistDandy> sanjoyd: Worth what?
02:35:46 <merijn> sanjoyd: What do you mean?
02:35:50 <mustelo> jocom, the type is: (c -> d) -> (a -> b -> c) -> a -> b -> d
02:36:00 <merijn> sanjoyd: It's just normal haskell with text in between...
02:36:10 <NihilistDandy> ^^
02:36:22 <shachaf> NihilistDandy: Worth it.
02:36:23 <shachaf> > it
02:36:24 <lambdabot>   $16.28
02:36:29 <sanjoyd> NihilistDandy: merijn as in, do people use it for real-world projects? I know this is a very subjective question.
02:36:39 <Algo> what's the language that's only recursion?
02:36:58 <mikeplus64> politics
02:37:04 <NihilistDandy> sanjoyd: It's just a documentation style, sanjoyd
02:37:09 <NihilistDandy> The code is still the same
02:37:34 <NihilistDandy> It depends how you want to distribute your work, I guess
02:37:52 <sanjoyd> I guess it is best to try it out on a toy project, then.
02:38:00 <NihilistDandy> If you want it to be a paper or article that can be compiled, go for lhs. If not, decently commented hs is fine
02:41:41 <jocom> mustelo: What I've come up with now isn't really cool, but it is: f . (g a)
02:42:02 <jocom> Or maybe I should write it as f . (g x)
02:42:07 <mustelo> jocom, in some sense you're halfway there :)
02:42:22 <jocom> Right...
02:42:24 <mustelo> one point down, one point left to free
02:42:30 <jocom> True
02:42:37 <jocom> First going to have lunch
02:42:53 <jocom> Hopefully I can give the answer over an hour or so
02:43:06 <mustelo> jocom, might not be worth it, but suit yourself
03:00:45 <zhulikas> " you can’t have a function that returns different values for the same input, no matter how hard you try."
03:00:49 <zhulikas> what about returning a random value?
03:00:53 <NihilistDandy> Best comment I've seen in months: http://www.reddit.com/r/haskell/comments/j0say/my_humble_rant_about_the_haskell_learning_curve/c28aqgg
03:00:58 <zhulikas> or then it is considered to be I/O ?
03:01:12 <NihilistDandy> zhulikas: Reading LYAH?
03:01:15 <mauke> zhulikas: where would this "random value" come from?
03:01:26 <zhulikas> System.Random
03:01:28 <zhulikas> RandomGen next
03:01:39 <zhulikas> NihilistDandy, http://www.updike.org/articles/Pure_Lazy_Functional
03:01:42 <NihilistDandy> Ah
03:01:43 <zhulikas> that's a nice article
03:02:29 <mauke> zhulikas: next needs an input value
03:02:30 <zhulikas> one thing looks quite extraordinaly for me
03:02:38 <mauke> and given the same input value, it will always return the same result
03:02:47 <NihilistDandy> mauke: 19
03:03:16 <mustelo> no, 42
03:03:28 <zhulikas> http://hpaste.org/49906
03:03:33 <NihilistDandy> 19's much more random than 42
03:03:50 <zhulikas> so when using Haskell I don't need to worry about simple optimisations, right?
03:03:57 <mustelo> mine encodes all the entropy in life the universe and everything
03:04:30 <zhulikas> let randomNumber = 5
03:04:32 <zhulikas> this is quite random
03:04:44 <NihilistDandy> mustelo: Mine looks sort of like a bee
03:04:56 <dncr> i mean the compiler's not actually that good at optimizing things that you'd probably think are "simple"
03:05:17 <NihilistDandy> And a bit like a B
03:05:53 <zhulikas> dncr, what I mean that when you apply a filter to a filter to a filter... you can expect that everything will be combined into one filter instead of at first evaluating first filter, then applying second one to the result, then applying third to the result of second filter and so on...
03:06:16 <zhulikas> I can expect this optimisation, right?
03:06:27 <dncr> ok ya that should be fine i think (warning i know nothing).  laziness is the big one for me.  i think this was interesting http://www.haskell.org/haskellwiki/Performance/Laziness
03:06:28 <zhulikas> I mean I came from OOP, I would need to do such things on my own
03:06:49 <zhulikas> and now I think in what level can I trust the compiler
03:07:09 <dncr> right
03:07:16 <zhulikas> nice :)
03:07:44 <mustelo> zhulikas, in this particular case I would compose the filters by hand. the code will be shorter and you won't be making implicit assumptions about how awesome simon peyton jones is
03:07:46 <NihilistDandy> zhulikas: Premature optimization is an even worse idea in Haskell than in other languages. And it's an awful idea in the first place
03:08:08 <mustelo> (although I agree with everything NihilistDandy just said too)
03:08:30 <zhulikas> what I ask is how functions are combined because of laziness... :) not what is a good programming practice
03:09:01 <mustelo> zhulikas, my suggestion would be to not worry to much about performance until you're quite comfortable with the language itself
03:09:21 <NihilistDandy> Think about thunks
03:10:13 <NihilistDandy> mustelo: I thought assumptions about the awesomeness of SPJ were the basis of Haskell's type theory. WHAT DO I BELIEVE IN NOW?
03:10:31 <mustelo> NihilistDandy, you misread me. I just said you should make those explicit :)
03:10:38 <mustelo> send spj money, etc.
03:10:43 <NihilistDandy> Ah, how silly of me
03:11:36 <NihilistDandy> I'm really jealous of whoever gets that PhD spot.
03:11:51 <NihilistDandy> :D
03:11:57 <mustelo> which is that?
03:12:17 <NihilistDandy> I see an occasional email about it on the cafe and on the GHC list
03:12:26 <NihilistDandy> Let me see if I can dig it up
03:12:37 <mustelo> eh, don't worry about it too much
03:13:06 <NihilistDandy> mustelo: http://www.chalmers.se/cse/EN/news/vacancies/positions/phd-student-position-in8107
03:13:21 <mustelo> NihilistDandy, you linked to that comment on /r/haskell about  thompson's blog post. what do you think of the post itself?
03:14:55 <NihilistDandy> I thought the style entertaining, engaging, and just a touch alarmist, but generally spot on
03:15:21 <mustelo> hmm, so what did you think of the comment then?
03:15:52 <NihilistDandy> Then again, my sample size of non-theory-weirdoes is too small to be sure :D
03:16:26 <NihilistDandy> mustelo: I'm a math major, and comments like that speak to me more than all the tutorials in the world
03:16:51 <mustelo> another math major here. not sure where I stand on that point
03:16:51 <NihilistDandy> Three rules, bam! Monoids.
03:17:04 <jocom> mustelo: Hi, I think I got it!
03:17:14 <mustelo> jocom, nice, let's see.
03:17:15 <jocom> (f.) . g
03:17:19 <mustelo> yup
03:17:27 <jocom> Yuchai!
03:17:27 <mustelo> well done
03:17:47 <jocom> Do you have another one, to test whether I really got the trick?
03:17:55 <mustelo> abstract out f and g now
03:18:08 <mustelo> @type \f g -> (f .) . g
03:18:09 <lambdabot> forall a b (f :: * -> *) (f1 :: * -> *). (Functor f, Functor f1) => (a -> b) -> f1 (f a) -> f1 (f b)
03:18:14 <jocom> hehe, nice question
03:18:18 <mustelo> damn it lambdabot
03:18:22 <mustelo> don't listen to that
03:18:48 <jocom> g is simple
03:18:55 <jocom> (f .) .
03:18:57 <NihilistDandy> To be clear, mustelo, I don't agree with the isolationist mentality. I just like the clarity of expression. Avoiding success doesn't have to come at the price of alienation.
03:19:10 <mustelo> jocom, need one more set of parens, but yes
03:19:32 <jocom> NihilistDandy: The point is that I don't get the point of the point operator
03:19:38 <jocom> I think this is a good exercise
03:19:41 <jocom> For me...
03:19:43 <merijn> @type \f g -> (f Prelude..) Prelude.. g
03:19:44 <lambdabot> forall b c a a1. (b -> c) -> (a1 -> a -> b) -> a1 -> a -> c
03:19:51 <merijn> FTFY :p
03:20:16 <mustelo> merijn, thanks
03:20:20 <merijn> jocom: Oh, I know a simple example where you'd use the dot
03:20:36 <NihilistDandy> jocom: huh? Did I make a comment at you that I've forgotten?
03:20:37 <jocom> merijn: Like?
03:21:06 <merijn> jocom: I assume you can envision a scenario where some computation which returns a list of tuples. Now assume I want to do something with the first tuple entry (say add 5 to an int), dot lets me do the following
03:21:16 <jocom> NihilistDandy: No, I replied to you sentence about isolating
03:21:32 <NihilistDandy> jocom: Oh, that was about a reddit comment
03:21:53 <merijn> > map $ (5+) . fst $ [(1,1),(2,2)..(10,10)]
03:21:54 <lambdabot>   Couldn't match expected type `(a, b)' against inferred type `[a1]'
03:21:56 <merijn> hmm
03:22:02 <merijn> of course
03:22:03 <merijn> I fail
03:22:07 <jocom> NihilistDandy: Aha, well, mustelo just told me to abstract out f and g. Thought you replied to that. Sorry...
03:22:13 <merijn> > map ((5+) . fst) [(1,1),(2,2)..(10,10)]
03:22:14 <lambdabot>   No instance for (GHC.Enum.Enum (a, b))
03:22:14 <lambdabot>    arising from a use of `e_15112210...
03:22:29 <mustelo> NihilistDandy, hmm. I mean the argument that names make things harder is clearly bullshit, but I also like to fantasize about a world where everyone understands and uses haskell
03:22:30 <NihilistDandy> jocom: Haha, no. That's actually kind of awesome. :D
03:22:38 <merijn> > map ((5+) . fst) $ zip [1,2..10] [1,2..10]
03:22:40 <lambdabot>   [6,7,8,9,10,11,12,13,14,15]
03:22:48 <merijn> where
03:22:57 <merijn> > zip [1,2..10] [1,2..10]
03:22:58 <lambdabot>   [(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(10,10)]
03:22:59 <NihilistDandy> mustelo: WHAT THE SHIT IS A LONG LONG?
03:23:07 <NihilistDandy> At least monoids are well-defined :D
03:23:14 <mustelo> yeah... fantasies are not always plausible
03:23:28 <mustelo> jocom, to make further progress, you'll need to start writing the (.) using prefix notation
03:23:31 <jocom> mustelo: Is (.) (flip (.)) correct?
03:23:48 <NihilistDandy> I always found C terminology much more actively obtuse/opaque than I've ever found Haskell terminology
03:23:57 <mustelo> jocom, kind of close, but not quite
03:24:16 <mustelo> NihilistDandy, when people say "names are hard" what they mean is "I've not heard of this before"
03:24:22 <NihilistDandy> indeed
03:24:38 <jocom> (.) (f .) is fine, or not? mustelo <<
03:24:47 <merijn> jocom: The most common use (for me anyway) of composition is in situations like the one I just typed where you need to do some "preprocessing" on a value before using it in computation and where you don't want to map multiple times (because that is not as clear, etc)
03:24:57 <mustelo> jocom, halfway there, yeah
03:25:12 <merijn> mustelo: When I say names are hard I mean "I can never come up with good variable/function names" :p
03:25:16 <NihilistDandy> They should just call monads burritos and give them a mascot. Then we can attract all those hip programmers with their webscale MongoDB skillz~
03:25:35 <jocom> mustelo: Aha, the flip isn't necessart (-;
03:25:43 <jocom> (.) ((.))
03:25:48 <NihilistDandy> So close
03:26:00 <merijn> NihilistDandy: To be fair MongoDB is a pretty solid piece of software from what I can tell about it and Zed. It's just all the Ruby on Rails hipsters giving it a bad name :p
03:26:42 <mustelo> jocom, very close now.
03:26:50 <mustelo> @type (Prelude..) (Prelude..)
03:26:51 <NihilistDandy> merijn: Exactly. Hipster programmers are perfectly good for plug and play flavor of the week stuff, but they just ruin technologies with their...
03:26:51 <lambdabot> forall b c a a1. (a1 -> b -> c) -> a1 -> (a -> b) -> a -> c
03:26:54 <NihilistDandy> hipsterism
03:27:03 <NihilistDandy> Or something
03:27:16 <merijn> NihilistDandy: It was good before it became popular! :>
03:27:35 <mustelo> @type \f g -> ((f Prelude..) Prelude.. g)
03:27:36 <lambdabot> forall b c a a1. (b -> c) -> (a1 -> a -> b) -> a1 -> a -> c
03:27:44 <mustelo> jocom, that's your goal ^^
03:27:54 <NihilistDandy> merijn: I should start telling my programming friends "Oh, I program in… you know what? You've probably never heard of it."
03:28:14 <NihilistDandy> Sadly, I would be both correct, and a douche
03:28:24 <clsmith> i think there is a problem with haskell terminology, tbh, in the sense that some of us aren't mathematicians, and any resource i've found which explains what a monoid or a functor actually is, assumes you already have a 'maths brain'
03:28:55 <mustelo> clsmith, sure, but that doesn't argue against using the same names
03:29:00 <mustelo> just for better explanations
03:29:07 <merijn> clsmith: I kinda agree with you, but if you look at the types of monads/monoids and functors I think most are pretty easy to grok
03:29:40 <shachaf> clsmith: Really? For some things that's true, but I think the definitions of Monoid and Functor are pretty straightforward.
03:29:55 <NihilistDandy> ^^
03:30:11 <rado_> does standard haskell lib come with powermod? ie. a^b % m
03:30:27 <mustelo> shachaf, if you go to wiki for monoid, it's kind of difficult to see how that relates to (List, [], (++))
03:30:39 <NihilistDandy> > 2 ^ 4 `mod` 3
03:30:40 <lambdabot>   1
03:30:42 <idnar> how experimental is the experimental 64-bit OS X GHC?
03:30:52 <merijn> idnar: So far I've had no problems
03:30:56 <rado_> well thats not very efficient
03:31:10 <idnar> merijn: guess I'll give it a whirl, then
03:31:10 <NihilistDandy> rado_: What would you prefer?
03:31:13 <mustelo> rado_, there are some number theory packages that would do that
03:31:13 <shachaf> mustelo: Well, the wiki also links to http://blog.sigfpe.com/2009/01/haskell-monoids-and-their-uses.html
03:31:18 <idnar> oh, I'm on 10.7 / Lion, is that going to be a problem?
03:31:22 <NihilistDandy> idnar: No
03:31:25 <mustelo> shachaf, :) the world is improving
03:31:31 <merijn> idnar: I have yet to hear problems with it. As long as you're not doing something 100% critical I wouldn't worry about it to much :p
03:31:33 <clsmith> i understand monoids now, after reading some things which lessened on the madd mzero stuff, but functors still slightly elude me. as far as i can tell, a functor is ... a functor from one set to another which preserves identity morphisms and composition of morphisms. that is to say, i have no idea what a functor does.
03:31:34 <merijn> @src Monoid
03:31:35 <lambdabot> class Monoid a where
03:31:35 <lambdabot>     mempty  :: a
03:31:35 <lambdabot>     mappend :: a -> a -> a
03:31:35 <lambdabot>     mconcat :: [a] -> a
03:31:49 <idnar> merijn: yeah, just playing around really
03:31:51 <clsmith> *function
03:31:58 <jocom> flip (.) (.), mustelo ?
03:32:15 <mustelo> jocom, oof, getting colder
03:32:21 <jocom> hmm
03:32:27 <rado_> NihilistDandy: the number will grow huge before you reduce them
03:32:29 <idnar> merijn: I initially tried to install darcs / ghc from MacPorts but that doesn't work; so I grabbed a binary of darcs from the website instead
03:32:39 <shachaf> clsmith: Take http://learnyouahaskell.com/functors-applicative-functors-and-monoids as a standard introduction, I guess.
03:33:02 <merijn> idnar: Haskell Platform is the proper way to go
03:33:28 <rado_> NihilistDandy: actually i just checked and seems lazy evaluation prevents inefficiencies
03:33:31 <merijn> idnar: GHC, cabal-install, bunch of basic libraries, etc
03:33:33 <NihilistDandy> idnar: Stop using that dinosaur MacPorts
03:33:34 <mustelo> clsmith, my recommendation would be to look at how to define functor instances for some basic functors: Maybe, List, and even (r ->)
03:33:39 <NihilistDandy> Use Homebrew
03:33:46 <NihilistDandy> rado_: Precisely :D
03:34:16 <shachaf> clsmith: If Foo is a Functor, in Haskell, it means that for every type t you have a type Foo t and a function fmap :: (a -> b) -> Foo a -> Foo b that satisfies a few laws.
03:34:17 <aristid> is there a nice way to model state machines where transitions have (known) probabilities?
03:34:19 <NihilistDandy> Though you could always ask Wolfram to let you have a look at their powermod code
03:34:39 <NihilistDandy> aristid: Whiteboard?
03:34:41 <NihilistDandy> :D
03:34:55 <aristid> NihilistDandy: i mean how to write them in haskell
03:35:03 <shachaf> clsmith: Namely, fmap id v === v, and fmap f (fmap g x) === fmap (\x -> f (g x)) v
03:35:05 <NihilistDandy> I know, just kidding
03:36:02 <mustelo> aristid, do you have a non-probabalistic model that doesn't generalize well, or are you asking for that too?
03:36:15 <aristid> mustelo: no
03:36:31 <aristid> i have a model for a pronouncable password generator :)
03:36:42 <mustelo> aristid, graph structures are notoriously not-fantastic in haskell
03:37:57 <kamaji> Are the haskell docs accessible in HTML format locally somehow?
03:38:10 <kamaji> I mean are they included with say ghci?
03:38:15 <jocom> mustelo: (.)(.)(.)
03:38:29 <mustelo> jocom, yup, that works
03:38:31 <jocom> Or (.).(.)
03:38:35 <mustelo> yeah!
03:38:46 <jocom> Dunno which notation I prefer
03:39:10 <jocom> Dude, this is tricky, even though I'm undergrad algebra/category theory student
03:39:22 <mustelo> jocom, the second generalizes better to higher-arity functions
03:39:24 <jocom> Is there a general approach to this?
03:39:33 <shachaf> jocom: To what?
03:39:38 <jocom> Pointfreeing
03:39:46 <mustelo> jocom, @pf
03:39:52 <mustelo> er
03:39:54 <jocom> ??
03:40:03 <mustelo> @pl \f g -> (f .) . g
03:40:03 <lambdabot> (.) . (.)
03:40:12 <shachaf> jocom: Sure, you can convert any expression to point-free style using S and K by following very simple rules.
03:40:39 <jocom> Sorry, what are S and K, and where can I find the rules? (-;
03:40:47 <shachaf> S = \x y z -> x z (y z)
03:40:51 <shachaf> K = \x y -> x
03:40:54 <shachaf> I = \x -> x
03:41:01 <shachaf> I = S K K, though. :-)
03:41:18 <shachaf> You can try to figure out the rules yourself if you want a nice exercise.
03:41:29 <jocom> Aha, what do S and K stand for?
03:41:30 <shachaf> Any lambda expression can be expressed in terms of combinations of S and K.
03:41:36 <jocom> substitution?
03:41:46 <shachaf> I'm not sure if they stand for anything.
03:42:15 <shachaf> Kesterls and Starlings. :-)
03:42:27 <jocom> Right (-;
03:42:50 <jocom> Well, thanks a lot guys, this was really very helpful
03:43:03 <mustelo> rado_, I can assure you that lazy evaluation does not save you from needing a proper powermod implementation
03:43:10 <shachaf> jocom: Wikipedia has the transformation rules if you want to look there. :-)
03:43:48 <jocom> shachaf: Thx!
03:44:01 <shachaf> http://en.wikipedia.org/wiki/Combinatory_logic#Completeness_of_the_S-K_basis
03:44:11 <jocom> I guess I should take a course on Lambda Calculus
03:44:43 <shachaf> jocom: http://www.angelfire.com/tx4/cus/combinator/birds.html
03:44:54 <shachaf> Starlings and Kestrels, see?
03:45:48 <rado_> mustelo: yeah, i already have one. still isn't that the haskell way, if the stuctures are right, we don't need to worry about the algorithms
03:46:35 <rado_> mustelo: is there an easy way to time it
03:46:42 <mustelo> unix time command :)
03:46:57 <rado_> that work
03:46:58 <rado_> s
03:46:58 <mustelo> if you're on a lesser OS, I'm not sure
03:47:34 <rado_> there is no :time in prelude
03:47:52 <NihilistDandy> kamaji: They are, but they can be difficult to get at
03:48:01 <shachaf> rado_: Time what?
03:48:11 <NihilistDandy> kamaji: You can cabal install docidx, though, which will export an index to a file of your choosing
03:48:12 <mustelo> rado_, I meant: write your program; compile it; run it as "time ./myprog"
03:48:45 <rado_> right i get that
03:49:08 <clsmith> okay, i read lyah and now understand what functors are :p http://learnyouahaskell.com/making-our-own-types-and-typeclasses#the-functor-typeclass
03:49:55 <mustelo> clsmith, as an exercise try to define a functor instance over (r ->) without looking
03:50:11 <jocom> Ok now I've got another question... what is the mathematical interpretation of the 'side effect' of a monad
03:50:18 <shachaf> Here's a fun class for you:
03:50:31 <merijn> jocom: Depends on the monad
03:50:34 <shachaf> class Contravariant f where contramap :: (a -> b) -> f b -> f a
03:50:40 <merijn> jocom: For the IO monad, there is none
03:50:52 <NihilistDandy> My thoughts exactly
03:51:02 <jocom> ??
03:51:14 <jocom> Ok, I think I don't understand side effects
03:51:27 <merijn> jocom: There is (probably) no sane denotational semantics for IO
03:51:45 <merijn> The only semantics there are for IO are operational (which makes them "not mathematical")
03:51:45 * hackagebot cryptocipher 0.2.14 - Symmetrical Block, Stream and PubKey Ciphers  http://hackage.haskell.org/package/cryptocipher-0.2.14 (VincentHanquez)
03:51:53 <jocom> Given some monad M, I don't see any side effects... from the mathematical POV
03:52:08 <mustelo> shachaf, doesn't (r ->) have a sane instance for that?
03:52:12 <jocom> merijn: That makes some sense
03:52:21 <shachaf> mustelo: I think (-> r) does.
03:52:25 <mustelo> er, right
03:52:33 <mustelo> that would make sense :)
03:53:08 <merijn> jocom: The type of monad doesn't tell you which side effects it has, so there are no real semantics to think about them unless the same effects can be formalized in some other way letting you talk about them
03:53:15 <mustelo> in general I imagine most instances would have to do with precomposition like that, no?
03:54:07 <jocom> merijn: But can abstract monads in Haskell have side effects
03:54:10 <jocom> ?
03:54:17 <jocom> Stuff like Maybe, of List
03:54:47 <merijn> Maybe or List don't, but you can use the MonadIO typeclass to make another monad capable of IO behaviour
03:54:54 <mustelo> jocom, depends on what you mean by "side effect"
03:55:32 <jocom> Well, I really don't know what a 'side effect' is...
03:55:40 <merijn> jocom: IO itself is supported by the runtime system which is (at least partly) implemented in C
03:55:50 <jocom> From my mathematical knowledge of monads I can't see what side effects should be
03:55:56 <jocom> or how to think of them
03:56:11 <merijn> jocom: A side effect would be reading a line from stdin
03:56:32 <merijn> Because "readLine" does not return the same line at every invocation
03:56:49 <merijn> And a pure function would always return the same result when given the same arguments
03:56:54 <jocom> Ok...
03:56:59 <jocom> Yes, I understand that
03:57:11 <clsmith> mustelo: working on it :p
03:57:34 <merijn> The IO monad contains this behaviour by (in its implementation) making sure that the compiler cannot reorder code in a way that IO starts behaving odd
03:57:55 <jocom> ok
03:58:10 <jocom> So, for abstract monads, I shouldn't bother about side effects?
03:58:21 <merijn> jocom: As such it only makes sense to think of IO from an operational point of view (because as I said earlier there are no sane semantics)
03:58:43 <merijn> jocom: The documentation should describe any side effects which might be there
03:58:51 <merijn> Since you cannot deduce them from the code
03:58:58 <jocom> I think it is becoming a bit more clear now.
03:59:34 <jocom> Allthough I do not yet see why monads are necessary and sufficient for doing IO
03:59:42 <jocom> But I do think it is cool! (-;
03:59:50 <merijn> They are not necessary, but they are sufficient
03:59:50 <clsmith> mustelo: got it :p it took me a while becauuuse *shrugs* :)
03:59:50 <shachaf> jocom: They're neither.
04:00:01 <mustelo> clsmith, let's see it
04:00:06 <merijn> jocom: Not sufficient? What do you need in addition?
04:00:27 <merijn> jocom: Clean, for example, uses uniqueness types for dealing with IO/side effects in code
04:00:34 <clsmith> mustelo: well, i'm hoping it uh, works: instance Functor ((->) r) where fmap = (.)
04:00:37 <shachaf> jocom: A good exercise is to figure out "how would I do IO in Haskell, given what I know about Haskell right now?". I can think of half a dozen ways at least of doing various types of IO.
04:00:39 <jocom> merijn: yeah, so if I define my own monad, there won't be so called 'side effects'. That is a big relief (-;
04:00:48 <mustelo> clsmith, hehe, yup. now you see why it's a good exercise :)
04:00:55 <merijn> jocom: Your own monads won't do anything unless you code them to do it :p
04:01:10 <merijn> jocom: For example, look at the code for the Maybe monad, it is extremely simple
04:01:13 <merijn> @src Maybe
04:01:13 <lambdabot> data Maybe a = Nothing | Just a
04:01:16 <merijn> eh
04:01:21 <shachaf> jocom: Well, there might well be. But they'll be constrained. You can think of a value of type M a as being a computation that produces an a while having some sort of effect.
04:01:27 <aristid> shachaf: monadic I/O is one of the nicest ways i can imagine. but then, my imagination sucks
04:01:40 <merijn> I forgot how to get the monad instance for Maybe
04:02:09 <shachaf> aristid: It depends on what kind of IO you need.
04:02:11 <merijn> It boils down to the following
04:02:13 <merijn> :t (>>=)
04:02:14 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
04:02:22 <shachaf> aristid: conal would say that it was horrible.
04:02:35 <aristid> return = Just; join Nothing = Nothing; join (Just x) = x
04:02:40 <shachaf> aristid: If all the "IO" you need i printing output to the console, main :: String is much nicer than main :: IO (). :-)
04:02:48 <merijn> "Nothing >>= _ = Nothing" and "Just a >>= f = f a" and "return a = Just a"
04:03:04 <jocom> merijn: I know those
04:03:31 <aristid> shachaf: what I/O would conal prefer? FRP for everything?
04:03:36 <merijn> jocom: Well, no side effects there. The side effects of IO and friends are in the implementation, so if you want to see them you should look at their source
04:03:39 <merijn> aristid: Probably :)
04:03:49 <merijn> I still don't grok FRP, though
04:03:52 <shachaf> aristid: Not sure. Something denotative.
04:04:00 <aristid> merijn: ur stoopid :P
04:04:09 <merijn> Seems like it is everything I've ever wanted, if only I understood it
04:04:20 <aristid> the holy grail of FRP
04:04:38 <jocom> Ok, thx for clearing this up. I'll put my question about why monads are nec/suff for IO back for later. First need to grasp more about denotational semantics, I guess
04:04:47 <shachaf> jocom: They aren't!
04:04:56 <aristid> shachaf: are Iteratees denotative?
04:05:18 <shachaf> aristid: That depends on what you want them to denote, doesn't it? :-)
04:05:20 <jocom> shachaf: Explain...
04:05:25 <merijn> jocom: I recommend reading "Monads for functional programming" by Wadler, fairly readable and a nice explanation of what you want monads for
04:05:31 <jocom> all: what is FRP?
04:05:35 <aristid> shachaf: i'm not sure if i understand what "denotative" means :)
04:05:42 <merijn> jocom: Functional Reactive Programming
04:05:45 <shachaf> Functional Reactive Programming. It's not directly relevant to anything else that's been discussed here.
04:05:52 <jocom> ok
04:06:25 <merijn> jocom: Conal came up with it (http://conal.net/papers/icfp97/), pretty interesting, but not directly related to monads or IO
04:07:00 <shachaf> jocom: Haskell did IO before the idea of "monads" ever came up.
04:07:26 <mustelo> jocom,  there's a nice pre-monads paper which summarizes the world of lazy IO...
04:07:33 <aristid> merijn: oh, conal actually invented it? i thought FRP existed as the Holy Grail since forever :)
04:07:52 <merijn> aristid: No, he came up with the idea. That's why he knows so much about it :p
04:07:58 <jocom> shachaf: But then it might have been a monad, without knowing... [I really don't know anything of Haskell's {history,implementation}
04:08:01 <merijn> shachaf: Which means they are not necessary, but I'm not sure I agree with you that they are not sufficient
04:08:27 <shachaf> Sure, you could probably have described it as such.
04:08:36 <merijn> danka: Ping?
04:09:02 <shachaf> merijn: Is main :: Bool, a program which "imperatively" sets a bit to either 0 or 1, "monadic"?
04:09:21 <jocom> shachaf: I agree that the Typeclass won't be necessary. But the abstract idea...
04:10:03 <shachaf> jocom: Eh. Maybe.
04:10:27 <shachaf> But who cares if your program can be described as involving a lax functor from a terminal bicategory?
04:10:44 <jocom> shachaf: I guess I do [sorry]
04:10:55 <shachaf> jocom: Sure, so do I.
04:11:16 <shachaf> jocom: But you'll probably find it much easier to understand the type class if you first look at some concrete object.
04:11:17 <mustelo> jocom, the paper I mentioned: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.38.5782&rank=1
04:11:19 <merijn> shachaf: Not sure, I don't have any strong opinion on where to draw that line
04:11:22 <clsmith> so if Functors are types that can be mapped over, what's a simple way of defining what a Monadic type does?
04:11:56 <shachaf> clsmith: That's probably not a very effective way to think about it.
04:12:15 <clsmith> i was scared that was going to be the answer ;p
04:13:14 <mustelo> clsmith, there's a great article called "typeclassopedia" in the monad.reader. walks through the standard type classes and tries to explain them
04:13:27 <mustelo> it might be a bit advanced, but you could try to read as far as you can
04:13:56 <clsmith> thanks, i'll have a look
04:14:58 <clsmith> (>>=) and fmap just seem very similar, only (>>=) 'injects' like return? i'm probably just confused.
04:15:00 <mustelo> clsmith, http://www.haskell.org/wikiupload/8/85/TMR-Issue13.pdf
04:15:02 * clsmith goes to read article
04:15:16 <mustelo> fmap takes an a -> b
04:15:24 <mustelo> >>= takes an a -> m b among other things
04:15:56 <mustelo> clsmith, the key is that the function you're "mapping" with in >>= can generate context too, which is not true of the a -> b in functors
04:17:02 <mustelo> clsmith, also, fair warning, that article is long, but worith it, I think
04:17:23 <sp3ctum> when making a data type, can I also restrict the values the type can have?
04:17:45 <sp3ctum> i'd like to make a data type that can have ints of range 1-9
04:18:15 <mustelo> sp3ctum, I think you want #agda :)
04:19:00 <sp3ctum> hmm, probably not
04:19:11 <mustelo> sp3ctum, more seriously, perhaps you can use the Enum or Bounded classes?
04:19:15 <jocom> clsmith: >>= is a join after an fmap
04:19:37 <shachaf> sp3ctum: Sure. data Foo = One | Two | Three | Four | Five | Six | Seven | Eight | Nine
04:21:31 <kizzx2> sp3ctum: you can make it an ADT and provide a constructor function which yields Maybe T
04:21:40 <kizzx2> sp3ctum: therefore no invalid values can be constructed
04:21:47 <sp3ctum> ah, that sounds nice
04:23:13 <sp3ctum> thanks
04:26:35 <clsmith> mustelo: that article just crystalised functors. they're really simple, actually, i'd just found explanations on wikipedia etc extremely opaque
04:27:44 <erus`> haskell.org is down?!?!
04:28:04 <clsmith> erus`: works for me :p
04:28:20 <erus`> you just fixed it didnt you
04:28:24 <erus`> its still slow...
04:28:25 <merijn> erus`: http://www.downforeveryoneorjustme.com/haskell.org :p
04:28:40 <erus`> http://www.haskell.org/haskellwiki/Haskell/Lazy_evaluation has been loading for 10 secs
04:29:43 <mustelo> clsmith, I also recommend its descriptions of the other typeclasses. takes a nice high level view. one good way of keeping yourself honest while reading it is to import qualified Prelude as P and start from scratch, writing instances for each class and walking through proofs of laws
04:32:04 <erus`> can i implement the Fibonacci seq with a list comprehension?
04:32:54 <mustelo> erus`, sure
04:33:15 <mustelo> fibs = 0 : 1 : [a + b | a <- fibs, b <- tail fibs]
04:34:02 <jocom> But why use list comprehension?
04:34:07 <erus`> > let fibs = 0 : 1 : [a + b | a <- fibs, b <- tail fibs] in take 10 fibs
04:34:08 <lambdabot>   [0,1,1,1,1,1,1,1,1,1]
04:34:25 <mustelo> er, right. fuck it's late
04:35:04 <shachaf> > let fibs = 0 : 1 : [a + b | a <- fibs | b <- tail fibs] in take 10 fibs
04:35:05 <lambdabot>   [0,1,1,2,3,5,8,13,21,34]
04:35:18 <mustelo> shachaf, thank you
04:35:45 <merijn> >let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in take 10 fibs
04:35:50 <merijn> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in take 10 fibs
04:35:51 <lambdabot>   [0,1,1,2,3,5,8,13,21,34]
04:36:04 <mustelo> merijn, but ZOMG LIST COMPREHENSIONS!
04:36:24 <shachaf> mustelo: Parallel list comprehensions are a bit evil, aren't they?
04:36:30 <jocom> but Syntactic Heroine!
04:36:39 * shachaf has yet to read the TMR article that maybe talks about how they're not evil.
04:36:44 <merijn> I actually like zipWith more
04:36:58 <rado_> can someone take a quick look at this short program and tell me am I doing it wrong http://pastebin.com/LgtuhMb9
04:37:01 <mauke> The paste LgtuhMb9 has been copied to http://hpaste.org/49908
04:37:05 <rado_> it takes forever
04:37:18 <shachaf> maukebot++
04:37:58 <c_wraith> rado_: your implementation of powermod is going to be *very* slow for large numbers
04:38:01 <clsmith> i take it (zip = zipWith (,)) ?
04:38:09 <rado_> c_wraith: that's just start
04:38:24 <mustelo> clsmith, yup
04:38:35 <rado_> c_wraith: and it's pretty fast in ghci
04:38:35 <kizzx2> :t (liftM2 (,) `on` (map digitToInt))
04:38:36 <lambdabot> [Char] -> [Char] -> [(Int, Int)]
04:38:43 <kizzx2> :t ((,) `on` (map digitToInt))
04:38:44 <lambdabot> [Char] -> [Char] -> ([Int], [Int])
04:39:08 <c_wraith> :t (^)
04:39:08 <lambdabot> forall a b. (Num a, Integral b) => a -> b -> a
04:39:10 <identity_> :t on
04:39:11 <lambdabot> forall b c a. (b -> b -> c) -> (a -> b) -> a -> a -> c
04:39:38 <c_wraith> rado_: I assure you, that implementation of powermod is going to be exceptionally slow for numbers at the end of that range
04:39:41 <mustelo> kizzx2, careful, that's parsing differently than you might expect
04:40:08 <mustelo> it's ((liftM2 (,)) `on` (map digitToInt))
04:40:14 <rado_> c_wraith: let me test
04:40:29 <kizzx2> :t ((liftM2 (,)) `on` (map digitToInt))
04:40:30 <lambdabot> [Char] -> [Char] -> [(Int, Int)]
04:40:50 <mustelo> kizzx2, those parentheses are for you, not lambdabot, it was already getting it right
04:41:00 <c_wraith> : 9 ^ 9 `mod` 4
04:41:00 <kizzx2> mustelo: alrighty :)
04:41:05 <c_wraith> > 9 ^ 9 `mod` 4
04:41:06 <lambdabot>   1
04:41:20 <mustelo> kizzx2, I was worried you thought it was liftM2 ((,) `on` ...)
04:41:27 <clsmith> okay, new question. how is liftM different from fmap?
04:41:32 <rado_> c_wraith: 1 sec
04:41:35 <merijn> :t liftM
04:41:36 <lambdabot> forall a1 r (m :: * -> *). (Monad m) => (a1 -> r) -> m a1 -> m r
04:41:40 <kizzx2> clsmith: good question, i wanted to know too
04:41:41 <merijn> :t fmap
04:41:42 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
04:41:46 <mustelo> clsmith, for sane instances of liftM, they should coincide
04:41:51 <rado_> c_wraith: that's not it
04:42:03 <merijn> clsmith: The should be the same, but not all Monad instances are Functor instances too
04:42:16 <merijn> They probably should be, but haskell doesn't enforce it
04:42:35 <rado_> c_wraith: it takes one second to make and print the whole list
04:42:51 <mustelo> as a historical artifact, a monad is not required by haskell to be a functor, but they can all be made into one by defining fmap f x = x >>= return . f
04:42:57 <rado_> c_wraith: i thought that was the issue too and had custom powermod but its not it
04:43:17 <mustelo> clsmith, tl;dr: they're the same unless someones fucking with you
04:43:27 <clsmith> lol. i see
04:44:02 <clsmith> is it likely that in a later haskell standard all monads will be functors?
04:44:23 <mustelo> perhaps, it would certainly make sense
04:45:09 <jocom> I guess that it is a one-liner in the standard/implementation
04:45:35 <kizzx2> are there some concrete examples where you'd want to invent your own monad, where the situation is not when you want to like a new paper to flex some type muscle or to drown the user in formal proofs? (no need for details just some high level description will do)
04:45:46 <kizzx2> s/like/write/
04:45:53 <kizzx2> s/the user/the reader/
04:45:57 <merijn> kizzx2: Xmonad?
04:46:31 <merijn> There's a lot more situations where a monad might be convenient
04:46:32 <kizzx2> merijn: oh yeah.. i think you told me the same last time i just haven't actually gone into the source yet :P
04:46:44 <merijn> kizzx2: Do you know jQuery? (The javascript framework)
04:46:47 <kizzx2> yeah
04:46:51 <merijn> Also a monad
04:47:07 <kizzx2> that's a moment of enlightenment
04:47:23 <merijn> @google "you could have invented monads"
04:47:24 <lambdabot> http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html
04:47:25 <lambdabot> Title: A Neighborhood of Infinity: You Could Have Invented Monads! (And Maybe You Alrea ...
04:47:29 <mustelo> kizzx2, it's also sometimes useful to write a monad which combines two or more simpler monads. this can be done directly or with monad transformers
04:47:52 <mustelo> that's a great article
04:47:55 <merijn> kizzx2: That article is also nice
04:48:22 <merijn> Monads are not so hard, once you study their types a bit and the more obvious monads (Maybe and List) you'll go "oh! Why does everyone think this is so hard?"
04:48:22 <kizzx2> can jQuery be just a State monad?
04:48:54 <kizzx2> merijn: yeah i think i've past the stage of Monad and Monad Transformer but i can't think of why i'd want to invent one other than stack existing ones
04:48:54 <shachaf> merijn: Don't spread that "jQuery is a monad" nonsense around this channel, please. :-)
04:48:59 <identity_> When you really understand monads, you'll understand that they're just a burrito
04:49:06 <identity_> and how they're not a burrito
04:49:10 <shachaf> "jQuery is a monad" doesn't even make sense. And to the extent that it does make sense, it's wrong.
04:49:12 <merijn> identity_: Burrito's are comonads
04:49:23 <merijn> identity_: It's almost impossible to keep anything inside
04:49:35 <identity_> Don't you insult burritos, boy
04:49:40 <c_wraith> merijn: try wrapping them in foil
04:49:43 <andares> people always talk about monads. =(
04:50:05 <kizzx2> andares: i guess you always have to talk about it when programming Haskell :P
04:50:07 <kizzx2> (main)
04:50:11 <kizzx2> List
04:50:23 <andares> kizzx2: ah. :p I am very new to Haskell.
04:50:25 <merijn> kizzx2: They are not as complicated or as interesting as everyone makes them out to be. If at some point you think "wow, this'd be cleaner with my own monad", great. If you don't think that...fine
04:50:29 <andares> I'm only halfway through the tutorial.
04:50:38 <merijn> andares: Which tutorial?
04:51:03 <andares> merijn: learn you a haskell.
04:51:09 <merijn> Good :p
04:51:21 <MHD> Is there some type hack that'll get the "a" out of the "[a]"
04:51:25 <gienah>  /quit
04:51:27 <andares> huh. flash crashed and managed to make my audio system stutter the same 200ms sound.
04:51:44 <merijn> MHD: Which a did you want to get out?
04:52:08 <kizzx2> MHD: probably `head`
04:52:18 <MHD> merijn: it's the type i need
04:52:19 <erus`> @hoogle a -> b -> b
04:52:19 <lambdabot> Prelude seq :: a -> b -> b
04:52:19 <lambdabot> Control.Parallel par :: a -> b -> b
04:52:19 <lambdabot> Control.Parallel pseq :: a -> b -> b
04:52:22 <identity_> unless you really want the type, then use typeOf
04:52:26 <identity_> @hoogle typeOf
04:52:26 <lambdabot> Data.Typeable typeOf :: Typeable a => a -> TypeRep
04:52:26 <lambdabot> Data.Typeable typeOf1 :: Typeable1 t => t a -> TypeRep
04:52:26 <lambdabot> Data.Typeable typeOf1Default :: (Typeable2 t, Typeable a) => t a b -> TypeRep
04:52:41 <MHD> merjin: So that I can make a "Chan x" out of a "[x]"
04:52:46 <identity_> > typeOf "foo"
04:52:46 <lambdabot>   [Char]
04:53:06 <kizzx2> Chan . head $ xs ?
04:53:36 <identity_> :t newChan
04:53:37 <lambdabot> Not in scope: `newChan'
04:53:41 <identity_> @hoogle newChan
04:53:41 <lambdabot> Control.Concurrent.Chan newChan :: IO (Chan a)
04:53:57 <MHD> yeah I get it now
04:54:30 <MHD> but is there something I can put in a data declaration
04:54:33 <MHD> ?
04:55:25 <MHD> like a genuine hack?
04:56:11 <MHD> man I'd like some pattern matching on types
04:57:13 <shachaf> MHD: Context?
04:57:26 <shachaf> Oh, there is some.
04:57:36 <MHD> shachaf: I am working on a Parser in the IO monad
04:59:10 <MHD> data CParser [i] = CParser (Chan i) ...
04:59:15 <MHD> something like that
05:02:21 <erus`> is there a name for [0..] or [1..]
05:02:26 <shachaf> MHD: You can use data families, maybe?
05:02:47 <MHD> shachaf: Can they do "Only works on lists"
05:04:22 <MHD> and can they do newtypes?
05:04:47 <foo_> quit
05:06:15 <jocom> erus`: What do you mean?
05:06:26 <jocom> You can give it a name yourself
05:06:37 <jocom> in maths they are called the natural numbers, NN
05:07:00 <erus`> is there a name for an infinite list of increasing-by-1 numbers?
05:10:24 <Saizan> > enumFrom 1
05:10:25 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
05:11:58 <jocom> erus`: Not really
05:12:13 <jocom> It's a sequence...
05:13:55 <erus`> god i really miss algebraic types when using C++
05:14:49 <jocom> God didn't create C++, so I guess praying won't help (-;
05:20:42 <pgiarrusso> Hi all!
05:20:54 <mustelo> hello, bruce
05:21:12 <HugoDaniel_> :P
05:21:48 <pgiarrusso> I just learned that type synonyms cannot be used really as phantom types
05:22:02 <pgiarrusso> or rather, that they can but they don't work well
05:23:04 <pgiarrusso> I wanted to add that to the haskell wiki (in the http://www.haskell.org/haskellwiki/Phantom_type page), since it's not mentioned... any comment/suggestion?
05:23:10 <pgiarrusso> If not, I'll just go ahead
05:23:23 <Igloo> gitk
05:23:59 <thoughtpolice> http://www.youtube.com/watch?v=4zgYG-_ha28&feature=player_detailpage#t=4193s < john carmack likes haskell! :D
05:26:04 <c_wraith> disappointing that he allows himself to be held back by everyone else
05:26:49 <thoughtpolice> if you go back a little into the talk he explains more about how he believes performance still matters in his job, and there are some barriers to his adoption. i think his stance is reasonable
05:26:57 <thoughtpolice> that's just zoomed in on the part where he mentions FP :D
05:27:37 <thoughtpolice> but he does explicitly state how he's gone from thinking about performance to thinking about things like code quality, and how in a lot of ways he wants tools that restrict what kinds of errors you can have
05:31:56 <MHD> Any good articles about type inference in imperative languages?
05:33:32 <pgiarrusso> MHD: which languages do you have in mind? ML, the new C++, C#, Scala...
05:33:49 <merijn> Since when is ML imperative?
05:34:08 <pgiarrusso> It's not purely fuctional
05:34:27 <merijn> There's not much difference between type inference in imperative or functional languages, though
05:35:17 <pgiarrusso> Normally that's true - except for the problem of polymorphic references in ML-like languages
05:36:24 <pgiarrusso> But it depends on the focus of your question - I at least don't know an obvious answer, so you'll need to make your question more precise - are interested in the algorithms, the programmer benefits, or what?
05:36:50 <pgiarrusso> MHD: see above
05:37:40 <MHD> I'm working on my language Wypp, which is conceptually similar to C#
05:38:00 <MHD> Looking at having no coerced types at all
05:38:17 <MHD> and function/type overloading
05:41:39 <pgiarrusso> MHD: I'm having a look at TAPL
05:42:26 <pgiarrusso> I'm not sure you can get away well without looking at it
05:45:45 <pgiarrusso> MHD: I'm probably not the best person to answer, but you might be interested in "The Essence of ML Type Inference" (a chapter from ATTAPL, Advanced Topic in Types and Programming Languages, from Benjamin Pierce), and moreover in papers from Odersky about type inference in Scala
05:46:26 <pgiarrusso> Scala has local type inference, and I believe that if you want to support Java-style overloading you need to settle for that.
05:47:09 <MHD> Actually I once stumbled across "Simple decidable type inference with subtyping"
05:49:41 <pgiarrusso> MHD: I only see it's not yet published or cited
05:50:18 <MHD> semi-published a bit on xkcd's CS forum
05:50:49 <pgiarrusso> OK, I mean "published" as in "published in a peer-reviewed venue"
05:51:05 <pgiarrusso> and while I like XKCD, its forum don't qualify
05:51:25 <pgiarrusso> speaking about forum, probably the best venue for your question is lambda-the-ultimate
05:51:30 <pgiarrusso> lambda-the-ultimate.org
05:52:03 <pgiarrusso> The constraints from the title lead either to Ocaml type inference or Scala type inference
05:52:38 <pgiarrusso> But the overloading bit probably means that you want local type inference, like in Scala
05:53:13 <pgiarrusso> (unless you are going to use typeclass-based overloading, but it doesn't sound like)
05:53:49 <pgiarrusso> MHD: Say that you declare two functions with types Int -> Foo and String -> Foo
05:53:54 <pgiarrusso> let's call it bar
05:54:07 <pgiarrusso> now, say that you declare:
05:54:19 <pgiarrusso> foo(var x) {
05:54:19 <pgiarrusso> return
05:54:31 <pgiarrusso> return (bar x);
05:54:32 <pgiarrusso> }
05:54:49 <pgiarrusso> What should be the inferred type of x?
05:54:58 <MHD> if you declare that in Wypp the compiler will tell you you messe up
05:55:00 <pgiarrusso> (sorry for the syntax mixup)
05:55:20 <MHD> this is not intended to be some C-like language where everything is permitted
05:55:38 <pgiarrusso> What do you forbid then there?
05:55:45 <MHD> It will have syntax for -- preferred syntax -- for declaring return variables
05:56:05 <pgiarrusso> How does that help?
05:56:09 <MHD> and if the type sigs of all returns in a function do not match, you get an error
05:56:27 <pgiarrusso> In my example the return type is clearly Foo
05:56:30 <MHD> return variables have a type...
05:56:41 <pgiarrusso> because both overloads of bar return Foo
05:57:02 <pgiarrusso> but they take different params, Int and String
05:57:14 <MHD> wait, what?
05:57:19 <MHD> now I am getting confused
05:57:37 <MHD> wanna move to private chat to discuss this?
05:58:00 <mike-burns> Then what will I watch?!
06:08:29 <pgiarrusso> So MHD, papers about Scala type inference can be found here: http://lampwww.epfl.ch/~odersky/papers/
06:08:39 <pgiarrusso> Scala type system is (an extension of) Java's
06:09:07 <MHD> mike-burns: if you are referrring to you would have watched me being confuzed and sleep deprived and finding out something rudimentary
06:10:06 <pgiarrusso> actually, Scala is more powerful and can be confusing, but I guess it's material is still fine
06:10:21 <MHD> I can crack hard nuts
06:10:30 <MHD> Just not category-extras
06:10:37 <pgiarrusso> OK
06:11:46 <pgiarrusso> I think (but I'm no expert here) that Colored Local Type Inference is the foundation of what they use
06:12:23 <pgiarrusso> But I guess you're best off by asking on Lambda the Ultimate
06:12:33 <MHD> I think with some haskell Logic monad to help me type checking will be fairly all right
06:12:56 <MHD> I do lay awake at night wondering what i'll do when I go self hosting...
06:13:16 <pgiarrusso> you should present your needs and ask for pointers about "local type inference"
06:13:34 <MHD> thanks for yhe help :)
06:13:54 <MHD> man, making a language from scratch requires a lot of research
06:14:07 <pgiarrusso> I guess so... respect man!
06:14:36 <MHD> that's actually nice btw. since I can't get my haskell LLVM module to work, and me getting linux on this machine is a week in the future.
06:15:08 <MHD> pgiarrusso: Thanks, I think I might make a Blogger blog just about Wypp
06:15:19 <MHD> just to keep people updated
06:16:20 <ehamberg> 00
06:16:32 <pgiarrusso> MHD: I guess you should also prepare a write-down of your motivation - like what problem do you address that is not solved by existing languages?
06:16:59 <MHD> pgiarusso: It fixes flaws in most major and upcoming languages.
06:17:31 <MHD> It removes the damn braces, which in an of itself is like banishing 70's hairdos from the workplace
06:17:37 <dmead> guys
06:17:44 <dmead> https://github.com/dmead/Clojure-translate
06:17:47 <dmead> http://www.reddit.com/r/haskell/comments/jarp0/hi_guys_i_made_a_haskell_to_clojure_translator/
06:17:49 <dmead> upvotes plox
06:18:43 <pgiarrusso> dmead: what about a README?
06:18:52 <pgiarrusso> it's currently empty
06:19:01 <dmead> good idea :D
06:19:13 <dmead> i should have said documentation is coming
06:19:15 <pgiarrusso> ditto for LICENSE
06:19:35 <pgiarrusso> Yeah, and probably you want to do that _before_ starting to advertise it
06:20:32 <pgiarrusso> Many people will check out your project only once
06:21:01 <dmead> indeed
06:21:26 <dmead> gotcha
06:22:24 <doc_who> MHD, what texts are you using on language design/PLT?
06:22:45 <MHD> doc_who: What do you mean?
06:24:07 <doc_who> like Essentials of Programming Languages, Types and Programming Languages, Programming Language Pragmatics?
06:25:28 <MHD> doc_who: I am not, which might sound incredible...
06:25:52 <MHD> I know ~twelve languages
06:26:24 <MHD> I have spen so much time hacking and reading aobut haskell that I have gotten rep-strain
06:26:44 <MHD> And I am an eightteen year old geek with too much time on his hands :)
06:27:44 <doc_who> i guess you could figure out how to write an interpreter on your own
06:27:57 <MHD> I am using LLVM for compiler back end
06:28:01 <MHD> that eases things
06:28:18 <mauke> I have figured out how to write an interpreter on my own
06:28:22 <mauke> it's not pretty
06:29:28 <pgiarrusso> MHD: before thinking to the implementation, you could study design criteria for languages
06:29:43 <doc_who> yeah ive discovered that writing an interpreter is alot more involved than i imagined
06:30:07 <pgiarrusso> doc_who: what did you try to implement?
06:30:20 <doc_who> though once you have the AST the interpreter shouldnt be too hard
06:30:35 <doc_who> oh i havent done it yet
06:30:43 <pgiarrusso> Ah right, parsing
06:31:01 <MHD> I'll just Wypp up a list of design criteriae
06:31:22 <doc_who> but im helping these grad students make a new language (using haskell to interpret) and they gave me these books to read
06:32:09 <pgiarrusso> doc_who: I heard good things about all of them, and I studied a lot of Types and programming languages
06:32:28 <pgiarrusso> Anyway, an interpreter needn't be hard, it does depend on the language
06:32:56 <pgiarrusso> For (the core of) Lisp-like languages interpreters tend to be at least pretty small
06:33:24 <pgiarrusso> Programming Languages: Application and Interpretation, for instance, describes a few minimal ones
06:33:49 <pgiarrusso> there no parsing is involved (because they use Scheme's built-in parser)
06:34:04 <pgiarrusso> so everything is a piece of cake
06:34:16 <doc_who> i looked at that one breifly but it was too much gushing about how scheme is amazing
06:34:21 <mauke> parse :: String -> [Piece Cake]
06:34:54 <incluye> the "Piece" monad
06:37:48 <jonkri> if i have a stateful (monadio) monad, is there some way i can access it asynchronously from different threads?
06:38:56 <Entroacceptor> anyone knows how hstringtemplate deals with trees?
06:39:07 <pgiarrusso> mauke: LOL
06:39:21 <c_wraith> jonkri: completely insufficient information.  It really depends on details.
06:41:50 <jonkri> i'm developing an xmpp library, where i'm thinking about wrapping the internal state of the xmpp library in a monad, like "XMPP" or "XMPPT". this would work fine if all the client does it responding to callbacks (which is often the case), but sometimes the client needs to fork new threads and access the xmpp library's (stateful) functions asynchronously
06:43:18 <jonkri> maybe a monad is not a good way of going about it. i previously had a Session object (which contained the xmpp internal event channel, so that it was possible to use it to affect the state loop), but that forced the client to pass around the Session object, and felt a little excessive
06:43:51 <pgiarrusso> jonkri: did you consider using a Reader/State monad for the passing around?
06:44:13 <balor> Is "f : a -> b" the function's type or is it known as the function signature, or something else?
06:44:52 <pgiarrusso> balor: you can say both, but one can be more specific
06:45:15 <pgiarrusso> when you declare a function and specify its type, that's a function signature
06:45:24 <pgiarrusso> and "a -> b" is the type of the function
06:45:41 <balor> pgiarrusso, thanks.
06:45:44 <jonkri> pgiarrusso: i will go with that if i can't find a nice way to do this with a monad :)
06:46:29 <pgiarrusso> jonkri: not sure, but it sounds like in the other approach you'd need locking to protect the state
06:46:42 <pgiarrusso> while in this case, since the Session object is per-thread, you don't
06:47:50 <pgiarrusso> jonkri: As usual, you want to encapsulate which monad you use, in case you later need to add another monad on top of the reader one
06:48:06 <pgiarrusso> *you need to add a monad _transformer_
06:48:25 <jonkri> i see
06:48:50 <jonkri> like a client State monad :)
06:48:55 <Saizan> it seems sensible to me to expose the session object in some way
06:49:11 <jonkri> the client would basically do lift $ ask to get the xmpp session then, right?
06:49:29 <jonkri> Saizan, expose how?
06:49:39 <Saizan> you can still provide a convenient monadic wrapper, but you're not forcing the user to stick to it
06:50:00 <jonkri> well, putting the client state on top of the session would cause the problem of multiple states in different threads...
06:50:32 <pgiarrusso> jonkri: I think the number of lift depends on the number of monad transformers - it's probably better to hide everything within a module and provide functions like getSession
06:50:35 <Saizan> why would you do that?
06:50:45 <mercury^> Why is there a space after the hpaste url in the topic?
06:51:28 <pgiarrusso> jonkri: then getSession = ask or lift ask or lift $ lift ask, depending on your monad transformer stack "du jour"
06:53:16 <pgiarrusso> mercury^: no clue, but it does seems like a harmless typo
06:53:55 <aavogt> pgiarrusso: you'd have multiple ReaderT?
06:54:45 <jonkri> pgiarrusso, are you suggesting that i have something like a SessionT monad based on ReaderT that the client functions run in?
06:54:55 <pgiarrusso> aavogt: unlikely, but you might add e.g. Either/Maybe for errors
06:55:28 <pgiarrusso> jonkri: I guess it could be just a type synonym, but still...
06:55:47 <wjlroe> Can anyone actually read the captchas on http://hackage.haskell.org/trac/ghc/register ? Because I'm convinced I must be a bot
06:55:48 <pgiarrusso> Disclaimer: I've seen it done, never did it myself
06:55:51 <zhulikas> http://hpaste.org/49910 for some reason it cannot match types in line 12
06:55:51 <jonkri> ah, yeah, that's what i meant :)
06:56:15 <pgiarrusso> For instance, in the aavogt case, I'd have 1 reader monad with a compound type
06:56:44 <pgiarrusso> then getSession becomes getSession = session ask
06:57:13 <jonkri> then i could provide some custom fork function which forkIO some kind of SessionT function, right?
06:57:15 <pgiarrusso> sorry, ask >>= return . session
06:57:25 <aavogt> asks session
06:57:31 <jonkri> on top of an arbitrary monadio monad?
06:57:54 <pgiarrusso> aavogt: thanks
06:59:12 <pgiarrusso> jonkri: my point is that you _might want_ to insulate the details of your stack from the client
06:59:25 <MHD> pigarrusso: Design criteria: http://hpaste.org/49911
06:59:39 <pgiarrusso> so that if tomorrow you change it, you don't have to update all clients by adding/removing lifts and stuff
06:59:49 <pgiarrusso> so that'd apply to forkIO
07:00:26 <jonkri> aha, i see :)
07:01:06 <ptd> Is their a version of lines that takes a character (or predicate) to break it up with?
07:01:41 <aavogt> @hackage split
07:01:42 <lambdabot> http://hackage.haskell.org/package/split
07:02:44 <Johannes`> hi, how do i make this work: getn n list = if n == 0 then list else getn (n-1) (head $ tail list)
07:03:13 <jonkri> but how would a client use forkIO when forkIO requires an IO action, when the action the client will want to fork is a SessionT (or whatever) action?
07:03:13 <MHD> MVars are StateVars too
07:03:13 <aavogt> @src (!!)
07:03:13 <lambdabot> xs     !! n | n < 0 = undefined
07:03:13 <lambdabot> []     !! _         = undefined
07:03:13 <lambdabot> (x:_)  !! 0         = x
07:03:13 <lambdabot> (_:xs) !! n         = xs !! (n-1)
07:03:37 * edwardk waves hello.
07:03:42 <edwardk> preflex: xseen dolio
07:03:42 <preflex>  dolio was last seen on freenode/#haskell 10 hours, 42 minutes and 31 seconds ago, saying: And that makes it impossible to write types for certain functions.
07:03:48 <pgiarrusso> jonkri: sounds like you also need IO in your transformer stack
07:04:25 <pgiarrusso> jonkri: or some other kind of thread-support
07:04:28 <jonkri> pgiarrusso, so i will provide the fork function for forking a Session then right?
07:04:54 <pgiarrusso> jonkri: not sure I follow
07:05:14 <pgiarrusso> Johannes`: in your code probably you should just remove the head $ part
07:05:35 <aavogt> Johannes`: are you trying to access an element in [a], or a list in  [[[[[[a]]]]]] -> [[[[a]]]] (where the difference in nesting level depends on n)?
07:06:05 <jonkri> pgiarrusso: i'm thinking that if the user wants to have another thread that works in the SessionT (ReaderT) monad, he can't use forkIO because his function is not an IO function... and i'm guessing i must be the one to provide that specialized forking function which knows the xmpp session
07:06:24 <Johannes`> pgiarrusso: thanks
07:07:01 <pgiarrusso> Johannes`: the result typechecks, but returns a list - is that what you want indeed?
07:07:32 <Johannes`> pgiarrusso: i'll wrap it with head $ getn [..]
07:08:08 <aavogt> Johannes`: then put      then head list else ....
07:08:30 <aavogt> but a prettier definition is that (!!) above
07:08:31 <Johannes`> ah! i get tunnel vision sometimes ^^
07:08:32 <pgiarrusso> jonkri: If you have SessionT IO, then you only need lift . forkIO $ do ...
07:08:37 <MHD> Well, I have been reading a bit and it seems that Wypp has the qualitities of a great language
07:08:42 <aavogt> > "abcdefg" !! 2
07:08:43 <lambdabot>   'c'
07:08:49 <Johannes`> the excercise was to do it without (!!)
07:09:18 <MHD> Anyone have any guides for writing like a report of language features? Because I honestly don't know what to start with...
07:09:23 <pgiarrusso> But then, I'm not sure what you want to do with the session object
07:09:51 <Saizan> pgiarrusso: check the type of lift . forkIO again
07:11:13 <pgiarrusso> @type lift . forkIO
07:11:14 <lambdabot>     Ambiguous occurrence `lift'
07:11:14 <lambdabot>     It could refer to either `Control.Monad.Error.lift', imported from Control.Monad.Error
07:11:14 <lambdabot>                           or `Control.Monad.Logic.lift', imported from Control.Monad.Logic
07:11:42 <pgiarrusso> Saizan: you're right, the type is problematic
07:11:54 <aavogt> @ty mapErrorT
07:11:55 <pgiarrusso> lift . forkIO :: MonadTrans t => IO () -> t IO ThreadId
07:11:55 <lambdabot> forall (m :: * -> *) e a (n :: * -> *) e' b. (m (Either e a) -> n (Either e' b)) -> ErrorT e m a -> ErrorT e' n b
07:12:38 <pgiarrusso> Saizan: the problem is that forkIO wants just an IO thread
07:13:05 <dmead> :t fmap
07:13:06 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
07:13:15 <dmead> @hoogle fmap
07:13:16 <lambdabot> Prelude fmap :: Functor f => (a -> b) -> f a -> f b
07:13:16 <lambdabot> Control.Monad fmap :: Functor f => (a -> b) -> f a -> f b
07:13:16 <lambdabot> Control.Monad.Instances fmap :: Functor f => (a -> b) -> f a -> f b
07:13:25 <jonkri> same problem with catching exceptions, they have to be in the io monad too, right?
07:14:14 <wjlroe> Does anyone know how to add  -optl"-Wl,-read_only_relocs,suppress" to the ghc-options in a .cabal file? It just says "i686-apple-darwin11-llvm-gcc-4.2: "-Wl,-read_only_relocs,suppress": No such file or directory"
07:14:43 <wjlroe> (I'm adding that to remove the warnings that spam the screen on Lion)
07:15:41 <Saizan> pgiarrusso: usually it's solved by using ReaderT (MVar Session) as the transformer (if the monad in question is something state-like)
07:16:25 <Saizan> pgiarrusso: so that myForkIO (ReaderT m) = do mvar <- ask; forkIO (m mvar)
07:16:47 <Saizan> and get and put are implemented with take/putMVar
07:17:40 <pgiarrusso> Saizan: but you still want to use ReaderT to pass the state around in the subthread
07:17:59 <benmachine> it depends what semantics you actually want
07:18:02 <Saizan> pgiarrusso: that's what's happening with myForkIO already
07:18:18 <benmachine> this might be interesting http://hackage.haskell.org/package/monad-peel
07:18:29 <pgiarrusso> ah, so you can probably use runReaderT inside it, or sth like that...
07:18:33 <pgiarrusso> let me understand your code
07:18:35 <Saizan> myForkIO :: MonadIO m => ReaderT (MVar Session) m -> ReaderT (MVar Session) m
07:19:05 <Saizan> assuming i remembered to put the liftIO call there :)
07:20:14 <pgiarrusso> Saizan: I see, I didn't realize ReaderT was a data constructor, now I get it
07:20:36 <zhulikas> I see using pattern matching you can easily evade if/then/else branching \o/
07:20:37 <Saizan> anyhow, all this plumbing doesn't feel like fundamental to solving the problem, just convenience, that's why i'd also give the user a subset of the API to manipulate Session directly, so that he can make his own plumbing if needed
07:21:01 <pgiarrusso> As an alternative interface, one might wrap this inside fork (http://hackage.haskell.org/packages/archive/monadIO/0.10.1.1/doc/html/Control-Concurrent-MonadIO.html)
07:21:16 <pgiarrusso> note that it's not the standard MonadIO class (which comes from transformers)
07:21:17 <zhulikas> does anybody know what happens in pattern matching behind the scenes? Are there any internal if/then/else branches? :)
07:21:55 <dankna> the STG paper explains it
07:22:12 <pgiarrusso> dankna: that's out-of-date
07:22:14 <jonkri> Saizan, what are you referring to with "plumbing"?
07:22:23 <dankna> I imagine it's still fundamentally true though
07:22:35 <pgiarrusso> dankna: you refer to vectored returns, which have been removed in 2007
07:22:38 <dankna> oh!  okay
07:22:42 <dankna> they have eh.  interesting.
07:22:55 <sanxiyn> > let v = 5
07:22:55 <lambdabot>   not an expression: `let v = 5'
07:23:08 <sanxiyn> > if v < 10 then print v
07:23:08 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
07:23:21 <sanxiyn> ... so it's parse error, but what should I write instead?
07:23:53 <jonkri> sanxiyn, if has to have a "else" in haskell, and the then and else expressions has to produce the same tpye
07:24:12 <jonkri> which is also the type produced by the if expression
07:24:13 <sanxiyn> jonkri: Yeah I understand that part
07:24:22 <sanxiyn> How do I produce "IO ()"
07:24:25 <Saizan> jonkri: the monad transformer used to thread Session around
07:24:41 <jonkri> ok
07:24:48 <jonkri> this all just seems so overkill
07:25:08 <pgiarrusso> dankna: that's mentioned in the abstract of this long-awaited paper: http://research.microsoft.com/en-us/um/people/simonpj/papers/ptr-tag/index.htm
07:25:21 <jonkri> i mean, it will take me days just to enable an api working with multiple threads... :S
07:25:48 <dankna> pgiarrusso, ah!  thanks for the reference
07:25:57 <aavogt> @src when
07:25:57 <lambdabot> when p s = if p then s else return ()
07:26:09 <Saizan> e.g. the GHC api uses a class to abstract over this http://www.haskell.org/ghc/docs/latest/html/libraries/ghc-7.0.4/GHC.html#t:GhcMonad
07:26:30 <Saizan> though maybe that'd be really overkill :)
07:27:04 <jonkri> sanxiyn, hmm... you start in the IO monad with main :)
07:27:04 <Saizan> jonkri: you can mostly build this up from over-the-shelf components
07:27:49 <sanxiyn> jonkri: I don't understand.
07:27:58 <sanxiyn> jonkri: I just want to know what should I write in "else" part
07:28:21 <jonkri> sanxiyn, aha. try "return ()"
07:28:41 <sanxiyn> Oh.
07:28:43 <jocom> How do I deduce that: fmap g . pure = (fmap g) . pure  and not  fmap (g . pure)  ? Syntactically, that is...
07:29:01 <jonkri> return takes () and sort of promotes/lift it into the io monad
07:29:36 <Saizan> jocom: prefix function application binds more strongly than any infix
07:29:36 <sanxiyn> So return :: Monad m => a -> m a. Ok. I can sort of see how that works :)
07:29:44 <edwardk> does anyone know why the new Control.Parallel.Strategies doesn't seem to have a way to use Eval to build pseq's?
07:30:20 <edwardk> you can use $|, or the old 'demanding' but thatsabout it
07:30:28 <edwardk> and neither themselves form a Strategy
07:30:34 <jocom> Saizan: Thanks, that was what I needed
07:30:45 <edwardk> nevermind
07:30:48 <edwardk> Seq in there is 'pseq'
07:31:09 <jonkri> sanxiyn, i recommend that you read up on Functors -> Applicative Functors -> Monads... it's going to be a heavy read but it will be worth it :)
07:31:10 <jocom> And can someone explain the use of ($) ? I mean it is defined as  f $ x = f x
07:31:21 <jocom> Why write that $?
07:31:26 <companion_cube> jocom: it's right associativity
07:31:32 <Saizan> the point is that it has the lowest precendence
07:31:38 <companion_cube> f $ g $ h $ x is f (g (h x))
07:31:42 <Saizan> so it can save you parentheses
07:31:52 <jocom> Aha! Thx!
07:31:54 <edwardk> jocom (sometimes (it (is (more (convenent))))) $ than $ writing $ all $ those $ parentheses
07:32:12 <jonkri> thanks Saizan. i will think hard about exactly what functionality the xmpp clients needs :)
07:32:15 <sanxiyn> jonkri: Is that this one: http://www.haskell.org/haskellwiki/Typeclassopedia
07:32:30 <mtrlt> what is  a $ b c $ d  then?
07:32:34 <edwardk> it has very low precedence so you can put anything you want on the right of it
07:32:43 <benmachine> mtrlt: a (b c d)
07:32:44 <edwardk> a (b c (d)
07:32:50 <edwardk> which is a (b c d)
07:32:58 <mtrlt> hmm, thanks :)
07:33:02 <mtrlt> got it.
07:33:04 <edwardk> sadly the associativity is wrong to be maximally useful
07:33:11 <jonkri> sanxiyn, i read the chapters on http://learnyouahaskell.com/chapters (see chapter 11 and 12)
07:33:20 <jocom> edwardk: Why that?
07:33:22 <benmachine> edwardk: I reckon both associativities are useful on occasion
07:33:28 <edwardk> if it associated the other way you could foo $ complex arg 1 $ complex arg 2 … as it is you can only use it to pipeline the right hand side
07:33:44 <edwardk> benmachine: well, since you can always replace all but the last ($) with (.) the current associativity adds no power
07:33:49 <benmachine> or, I tried writing a prelude once using left-associating $ and found myself needing the right-associating one
07:33:56 <edwardk> whereas the other would make for nicer use of $! for multiple arguments, etc.
07:34:09 <benmachine> edwardk: unless of course your components contain other infix applications
07:34:13 <sanxiyn> jonkri: Indeed that seems easier reading. Thanks.
07:34:13 <benmachine> of lower than 9 precedence
07:34:24 <jonkri> sanxiyn, good luck :)
07:34:30 <edwardk> benmachine: true, for that to be maximally useful . also needs 0 precedence
07:34:39 <edwardk> or 9 or whatever
07:34:40 <edwardk> sorry
07:34:41 <benmachine> edwardk: but then you can't do f . g <$> x
07:34:48 <edwardk> and <$> also =)
07:34:55 <edwardk> it becomes a bit infectious
07:35:12 <benmachine> well, or you can just define extra operators
07:35:14 <edwardk> i've often wanted <$> and $ to have the same precedence
07:35:30 <benmachine> but <$> needs to be infixl and the same precedence as <*>
07:35:39 <edwardk> i often wind up writing basically the same code but for one use of <$> over $ and then have to add parens everywhere
07:35:49 <edwardk> true
07:36:02 <roconnor> > let star a = return [] `mplus` [a `mappend` b | b <- star a] in star "ab"
07:36:03 <lambdabot>   ["","ab","abab","ababab","abababab","ababababab","abababababab","ababababab...
07:36:16 <jocom> Am I correct that $ is only useful in infix notation?
07:36:27 <roconnor> > let star a = return mempty `mplus` [a `mappend` b | b <- star a] in star "ab"
07:36:28 <lambdabot>   ["","ab","abab","ababab","abababab","ababababab","abababababab","ababababab...
07:36:30 <benmachine> jocom: well, it's a specific case of id
07:36:40 <jocom> ??
07:36:42 <edwardk> well, if ($) went infixl 0, then you could drag (<$>) and (<*>) etc down as well
07:36:43 <benmachine> jocom: but some people find e.g. flip ($) to be easier to understand than flip id
07:36:58 <benmachine> jocom: or zipWith ($) functions values
07:36:58 <edwardk> ut you'd really need to do so in a fresh language =)
07:37:15 <jocom> ok
07:37:30 <benmachine> it depends what you think of as useful I guess?
07:44:33 <sanxiyn> > do { a <- [1..30]; b <- [a..30]; c <- [b..30]; if (a*a+b*b==c*c) then return (a,b,c) else fail "" }
07:44:33 <lambdabot>   [(3,4,5),(5,12,13),(6,8,10),(7,24,25),(8,15,17),(9,12,15),(10,24,26),(12,16...
07:47:00 <jocom> I'm reading about the laws for Applicative
07:47:24 <jocom> The most important is: fmap g x = pure g <*> x
07:47:39 <jocom> but I don't see how g fits into pure
07:47:54 <jocom> since the type of pure is   a -> f a
07:48:10 <jocom> but g is of type   a -> b
07:48:34 <jocom> What am I doing wrong?
07:48:36 <Lemmih> pure :: (a -> b) -> f (a -> b)
07:48:39 <benmachine> jocom: say g is type b -> c, then a = b -> c
07:49:01 <benmachine> type variables are allowed to be anything, including functions
07:49:08 <benmachine> (function types)
07:50:36 <jocom> benmachine: I understand that
07:51:04 <jocom> But, my point is that the types of the arguments of fmap and pure don't match
07:51:37 <jocom> [[ In my eyes ]] that is
07:51:44 <Lemmih> jocom: Why do you think they don't?
07:52:20 <jocom> pure takes as argument something of type a, whilst fmap takes an argument of type (a -> b)
07:52:21 <dolio> Does a -> a match b -> b?
07:52:29 <jocom> dolio: Yup
07:52:33 <dolio> How?
07:52:48 <jocom> Substitute a for b
07:52:58 <edwardk> jocom: keep in mind you can always instantiate a type variable to a function. ($) is just a special case of id
07:53:02 <edwardk> @type id
07:53:03 <lambdabot> forall a. a -> a
07:53:04 <edwardk> @type ($)
07:53:05 <lambdabot> forall a b. (a -> b) -> a -> b
07:53:10 <edwardk> > (+1) $ 2
07:53:10 <lambdabot>   3
07:53:16 <edwardk> > (+1) `id` 2
07:53:17 <lambdabot>   3
07:53:21 <dolio> So substitute (b -> c) for a.
07:53:54 <edwardk> substituting (b -> c) in for a in (a -> a) yields (b -> c) -> (b -> c)
07:54:12 <mm_freak_> Cale: FRP implementation is online, if you care…  "netwire" package
07:54:13 <edwardk> the same trick is being used in defining fmap in terms of pure and (<*>)
07:54:23 <monochrom> > id id id id id ()
07:54:23 <lambdabot>   ()
07:55:12 <jocom> Hmm, I see how that can be substituted
07:55:24 <monochrom> @type \p q r s -> id p q r s
07:55:25 <lambdabot> forall t t1 t2 t3. (t -> t1 -> t2 -> t3) -> t -> t1 -> t2 -> t3
07:55:27 <edwardk> > ?huh id id id id ()
07:55:28 <lambdabot>   mueval-core: internal error: PAP object entered!
07:55:28 <lambdabot>      (GHC version 6.12.3 f...
07:55:31 <edwardk> interesting
07:55:35 <jocom> And I understand why ($) is a special case of `id`
07:55:37 <mm_freak_> it has quite a few new features compared to yampa, including signal inhibition and instances for ArrowChoice, ArrowZero and ArrowPlus
07:56:07 <jocom> But I thought that the a in fmap and pure had to be the same type...
07:56:12 <dolio> > ?huh
07:56:13 <lambdabot>   mueval-core: internal error: PAP object entered!
07:56:13 <lambdabot>      (GHC version 6.12.3 f...
07:56:30 <mm_freak_> Wire also has an applicative interface, which yampa lacks
07:56:38 <roconnor> edwardk: where do I find a SemiRing class?
07:56:39 <edwardk> @type \f a -> pure f <*> a
07:56:39 <lambdabot> forall a b (f :: * -> *). (Applicative f) => (a -> b) -> f a -> f b
07:56:43 * hackagebot netwire 1.0.0 - Arrowized FRP implementation  http://hackage.haskell.org/package/netwire-1.0.0 (ErtugrulSoeylemez)
07:56:50 <roconnor> edwardk: and do you have a star-semiring class?
07:57:02 <mike-burns> @type fmap
07:57:03 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
07:57:04 <edwardk> roconnor: algebra Numeric.Semiring.Class — it is the two semigroup version. if you want the traditional trapping you want Numeric.Rig.Class
07:57:08 <mike-burns> @type pure
07:57:08 <lambdabot> forall a (f :: * -> *). (Applicative f) => a -> f a
07:57:12 <edwardk> yes, InvolutiveSemiring
07:57:43 <edwardk> though again, if you want the traditional trappings you'll need (Rig r, InvolutiveSemiring r)
07:58:00 <mike-burns> @type (<*>)
07:58:00 <roconnor> what are traditional trappings?
07:58:01 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
07:58:25 <edwardk> wow it is really hard to use the ($|) etc combinators in control.parallel.strategies
07:58:33 <edwardk> not sure i want to propagate that pattern into the code i'm writing
07:59:33 <roconnor> edwardk: an involutive semiring is the wrong star :D  I'm looking for  star x = 1 + x * star x.  I presume I'll need to add my own class.
07:59:46 <edwardk> i started describing commutative applicatives and monads in terms of taking their center, and defining how to compute those using strategies, but this would prompt the need for combinators like (<*|>) which takes a strategy
07:59:52 <edwardk> ah kleene star
08:00:01 <edwardk> i don't have a kleene semiring right now
08:00:20 <roconnor> edwardk: well kleene star also satifies some other laws, but kinda ya.
08:00:24 <edwardk> and if you want the kleene star you may need just a seminearring
08:01:26 <edwardk> http://hackage.haskell.org/packages/archive/monoids/0.1.36/doc/html/Data-Ring-Semi-Kleene.html used to offer one
08:01:31 <edwardk> but that is pretty old =)
08:02:07 <roconnor> edwardk: Kleene algebras usually require an idempotent semiring (aka a dioid), but I don't want idempotency.
08:02:22 <edwardk> *nods*
08:02:53 <roconnor> edwardk: do you alway hide the prelude when working with this stuff?
08:03:15 <edwardk> i hide away the parts that conflict as i go
08:03:43 <edwardk> i have to admit that is my least favorite part of working with the algebra library
08:04:19 <edwardk> don't you hate it when you realize you made a naming mistake at the bottom of a 30+ package tower?
08:04:21 <roconnor> edwardk: is using this algebra library easier than it looks?
08:04:42 <edwardk> dunno. =) i've been playing with it for a while and it seems natural to me ;)
08:05:04 <edwardk> using it is just importing Numeric.Algebra
08:05:10 <mm_freak_> i'm currently trying to find alternative signal function representations, which would allow me to provide both an arrow and a monadic interface and hence also an ArrowApply instance
08:05:14 <edwardk> and then bringing in any concrete types you want to work with
08:05:26 <edwardk> and hiding the parts of the prelude that conflict as you go
08:05:28 <mm_freak_> also i'm trying to find out how to write a working ArrowLoop instance for the current version…  i think, it's not possible
08:05:39 <edwardk> Numeric.Algebra is the kitchen sink include
08:06:02 <edwardk> more or less any class that isn't particular to some niche data type gets included in that
08:06:13 <roconnor> edwardk: Rational isn't an instance of Semiring :(
08:06:17 <edwardk> but no types, just classes (except for the Covector and Natural type that get reexported)
08:06:34 <edwardk> nope, i need to add the field of fractions, but for that i need the gcdring plumbing to work
08:06:48 <edwardk> so i ignore rational
08:06:51 <edwardk> sorry man
08:06:53 <roconnor> edwardk: any Tropical semirings defined?
08:07:09 <copumpkin> mmm
08:07:20 <edwardk> i have the dioid class but i haven't instantiated it to tropical or arctic semirings, etc.
08:07:49 <edwardk> right now it is just an alias for (Semiring r, Idempotent r)
08:08:06 <edwardk> you're in the territory i need to work on =)
08:08:25 <edwardk> i've mostly been focusing on interesting algebras rather than on the now-neglected ring structures
08:09:03 <edwardk> partially because the proofs in the ring space are tricky to show you have the minimal concept set required for something, and i have to go through and prove constructive analogues to all the classical concepts
08:09:12 <roconnor> edwardk: any Matrix Semirings?
08:09:17 <edwardk> not yet
08:09:54 <roconnor> Hmm
08:10:17 <roconnor> maybe I should just make my own star-semiring class for now.
08:10:31 <edwardk> well, I have a group ring, so you can kinda hack one up
08:10:33 <edwardk> yeah
08:12:06 <edwardk> to model the matrix ring you could work with the endomorphism ring of (Vec n r) for some fixed sized vector type Vec n.
08:12:33 <edwardk> er guess it isn't the endomorphism ring
08:12:40 <edwardk> messy
08:14:31 <roconnor> edwardk: well I want matrix multipliation to be matrix multiplication.
08:14:42 <Ke> If I have f :: (a -> b) how do I get storable size of a
08:14:51 <roconnor> edwardk: I guess an endomorphism ring might do this
08:15:17 <roconnor> though it doesn't seem like it would be efficent.
08:15:34 <edwardk> well, that is where you insert the memo combinators =)
08:16:03 <edwardk> of course for that i need a representable-trie instance vectors
08:16:10 <edwardk> er instance for
08:17:31 <edwardk> roconnor: anyways if you want to talk about matrices, give up your matrix and go talk about vector spaces i have tons of stuff in there for working with free modules
08:17:43 <edwardk> pick a basis and use the representable functor machinery
08:18:39 * roconnor wonders what happens when you take the adjenency matrix of a graph in a min-tropical semiring and do a change of basis.
08:19:55 <roconnor> edwardk: oh that reminds me, have you used universal elements of representable functors for anything?
08:20:46 <edwardk> not off the top of my head
08:21:09 <edwardk> going back to that naperian interpretation?
08:21:10 <jonkri> whenever a Chan is used, how do you know when the thread that processes the channel events crashes, and report that back to the threads communicating with the channel? or how is this usually done?
08:22:05 <wli> omfg how the fuck do you find what battery goes to your fucking thinkpad?
08:22:57 <edwardk> wli: in other news, you probaby did the right thing by finding that other company. the place that keegan works at was acquired by oracle shortly after you took the other job ;)
08:23:21 <wli> How the fuck do you find out what fucking model number your thinkpad is when all you have is the thing itself to stare at and no packaging?
08:23:27 <wli> edwardk: I noticed, yeah.
08:25:53 <dolio> I have a sticker with a product id on the bottom.
08:26:16 <jonkri> me too
08:26:25 <luite> usually the only thing that matters is the model (T510, T61p etc), and the display size
08:26:47 <luite> the exact model doesn't really matter, some come with a bigger (9 cell) battery, but they're all compatible
08:26:48 <wli> dolio: Now try looking up any of the goddamn ID numbers on the bottom number.
08:27:15 <wli> luite: I can't tell which of them it is. I'm trying to get one of the 9-cell batteries for it and look up compatibility.
08:28:19 <luite> wli: doesn't it have a type at the bottom right of your screen? something like lenovo T61p (that's what mine says)
08:28:42 <wli> Not at the bottom right. On the underside it says "Product ID: 0301CTO"
08:28:53 <dolio> What about the boot splash?
08:28:58 <wli> There are other things that could plausibly be model numbers.
08:29:08 <luite> looks like a thinkpad edge 15.6"
08:29:23 <wli> dolio/luite: Is that even the right format for a model number? 0301CTO didn't show up on google
08:29:34 <dolio> No.
08:29:37 <luite> CTO is custom built, I think
08:29:43 <luite> the 0301 is the model number
08:29:49 <wli> Ah, it does show up on google.
08:29:55 <wli> Why didn't it last time?
08:30:06 <wli> Okay, now I know what it is.
08:30:14 <edwardk> clearly they are out to torment you
08:31:43 * hackagebot reducers 0.1.2 - Semigroups, specialized containers and a general map/reduce framework  http://hackage.haskell.org/package/reducers-0.1.2 (EdwardKmett)
08:31:43 <wli> omfg the model numbers aren't listed in the same way
08:32:04 <wli> Oh man I've been spraying to the wrong channel for half an hour.
08:32:16 <edwardk> ?
08:32:37 <edwardk> thought it was -blah?
08:32:52 <jonkri> haha
08:33:47 <wli> The right channel would've been -blah
08:34:08 <wli> I can't correlate 0301 with a native IBM model descriptor anywhere now.
08:35:07 <wli> http://www.jr.com/lenovo/pe/LEN_0301DBU/ <-- listed as 0301 vs. Z61t etc. and the letter+2digit + letter descriptors are nowhere correlated with the pure 4-digit numeric models.
08:37:01 <Ke> http://hpaste.org/49913 I tried this, is there a way to get a within scope
08:37:26 <Ke> I guess desugaring into >>= \a doesn't help
08:37:59 <Ke> but sizeOf doesn't actually evaluate anything
08:43:13 <azaq23> Ke: a is a value which you can use from the point where it is defined using <- in the do expression
08:43:24 <azaq23> Ke: where binds to the function, so a is not defined there
08:44:00 <azaq23> Ke: You'll likely be able to write what you want using do-let syntax easily though
08:44:38 <Ke> hmm
08:44:40 <epdtry> azaq23: but 'b' is used in the right-hand side of the 'a <- ...' line
08:45:00 <azaq23> epdtry: Yep, didn't notice this
08:45:32 <azaq23> This makes this a little more difficult and as I don't know the functions you're using I can't tell you how this should be solveds.
08:45:33 <azaq23> -s
08:46:36 <Ke> for any (a -> b) where a is storable
08:47:20 <epdtry> well, sizeOf doesn't evaluate its argument, so 'b' doesn't need the value of 'a', only its type
08:47:25 <roconnor> edwardk: I was just reading about representable functor and the wiki page talks about universal elements.  In our case if P = log(F) of our representable functor than a universal element of F(P) is the instance where the functor's positions are labeled by there respective positions.  Anyhow, this seemed like a useful construct, ... somehow.
08:47:47 <Ke> indeed, but it needs something that is in scope
08:48:19 <edwardk> roconnor: *nods* i'm familiar with the construct, i just haven't defined anything useful with it in code ;)
08:48:54 <roconnor> edwardk: ya ... I don't have any applications either :D
08:49:29 <tech2> Without using fromIntegral as a way of converting Int to Integral, how do I define a function's argument type if it accepts a "length" as an argument? :/
08:50:06 <edwardk> tech2: lengths are typically Ints
08:50:12 <edwardk> @type length
08:50:13 <lambdabot> forall a. [a] -> Int
08:50:34 <edwardk> genericLength exists but you wind up feeling silly using it
08:50:35 <tech2> right, but if I use (Int a) then I get Type constructor `Int' used as a class
08:51:02 <edwardk> Int -> a is a function that takes an Int
08:51:18 <edwardk> Int a is applying the int type constructor to an argument that it doesn't take ;)
08:51:45 <tech2> perhaps my code would explain it better than I could, hell, maybe I'll learn something :)
08:51:47 <epdtry> Ke: i think you could do something like: let { x = undefined ; b = ... sizeOf x ... } , then 'return (a `asTypeOf` x)' to force the types of 'a' and 'x' to match
08:51:58 <edwardk> @hpaste
08:51:59 <lambdabot> Haskell pastebin: http://hpaste.org/
08:52:03 <edwardk> ^- go there and paste it
08:52:37 <hpaste> tech2 pasted “yet more collatz” at http://hpaste.org/49915
08:52:57 <tech2> edwardk: thanks
08:53:18 <edwardk> next_largest :: Integral a => (a, Int) -> (a, Int) — is probably what you want
08:53:42 <edwardk> Integral is a class that says you can pass a lot of things, Word, Int, Integer, for a.
08:53:48 <edwardk> Int is a concrete type.
08:54:04 <tech2> Why is there a separation between class and type?
08:54:10 <edwardk> you probably just want to use Int everywhere unless you are going to be computing these on numbers bigger than ~64 bits
08:54:32 <edwardk> classes in Haskell don't work like they do in OOP. are you familiar with vtables in C++?
08:54:38 <tech2> no, sorry
08:55:00 <edwardk> no worries. in c++ basically a class consists of a pointer to some table used to implement all the virtual methods, and then it has some data it needs.
08:55:15 <edwardk> in haskell the class plays the role of that table, but it is decoupled from the data
08:55:18 <ddarius> C++: always the place to go for clarification
08:55:26 <edwardk> ddarius: =P
08:56:09 <kizzx2> what's the best way to simulate a "break" inside a foldl?
08:56:09 <tech2> :)
08:56:15 <edwardk> @src Num
08:56:15 <lambdabot> class  (Eq a, Show a) => Num a  where
08:56:15 <lambdabot>     (+), (-), (*)           :: a -> a -> a
08:56:15 <lambdabot>     negate, abs, signum     :: a -> a
08:56:16 <lambdabot>     fromInteger             :: Integer -> a
08:56:23 <tech2> edwardk: thanks, I think I get it and it makes a bit more sense now.
08:56:28 <edwardk> Num for instance is a class, that gives you a bunch of operations you can perform on 'a's
08:56:40 <edwardk> we have an instance of Num for Int
08:56:52 <edwardk> > 4 + 5 :: Int
08:56:53 <lambdabot>   9
08:56:54 <tech2> It's a hierarchical type system, kinda?
08:57:12 <kizzx2> i'd say it's a "flat" type system
08:57:25 <mercury^> tech2: it's a lattice
08:57:26 <edwardk> more or less. the way classes work in haskell is nicer in a lot of ways because you can define a data type, and then later on add more classes to give it more methods basically
08:57:44 <tech2> heh, I'll work it out I'm sure.
08:58:00 <edwardk> whereas in more traditional OOP-like languages you better be the maintainer of that source file ;)
08:58:01 <kizzx2> in order to "support" (==), the only way is probably to make type instance of Num
08:58:12 * ddarius doesn't know what "hierarchical" or "flat" would mean as an adjective applied to type systems.
08:58:37 <kizzx2> i guess hierarchical would means something like inheritance in OOP
08:58:52 <kizzx2> which can go N level deep
08:59:02 <mercury^> kizzx2: (==) is given by Eq
08:59:13 <kizzx2> mercur^: oh yeah :P
08:59:37 <kizzx2> what's the best way to simulate a "break" inside a foldl?
08:59:46 <fredmorcos> hi, i would like to "time" a function that i am calling, what should i use? i am new to haskell....
08:59:55 <kizzx2> fredmorcos: criterion
09:00:10 <tech2> edwardk: you can add functions which support a class of types, so it's not necessarily modifying or adding to the type (as one might do in a prototyping based language like Javascript for example), it's neat, but I guess namespaces become a tad amusing.
09:00:16 <kizzx2> fredmorcos: you can also use "./MyProgram +RTS -sstderr"
09:00:18 <Botje> kizzx2: you can't. at least not with foldl.
09:00:33 <kizzx2> Botje: umm i guess that conveys what i want to do, so what's the way to do it?
09:00:37 <mercury^> kizzx2: by cutting the list before you fold
09:00:39 <fredmorcos> kizzx2, nothing in the stdlib?
09:00:46 <tech2> edwardk: there should have been a ? in there somewhere, just not sure where :)
09:00:46 <Botje> kizzx2: can you explain what you're after?
09:00:48 <fredmorcos> kizzx2, what is +RTS and -sstderr?
09:00:58 <edwardk> tech2: well, once you get into multi parameter type classes you start to get some real functionality that is very hard to model in other languages
09:01:00 <rndm> what is an omega algebra? (it shows up as an example in basic category theory for computer scientists)
09:01:10 <edwardk> tech2: because nothing said the class constraint had to have a single 'a' in it =P
09:01:14 <mike-burns> Traditional OOP means Smalltalk? Or does it mean Java?
09:01:15 <kizzx2> fredmorcos: http://book.realworldhaskell.org/read/profiling-and-optimization.html
09:01:46 <edwardk> mike-burns: i was mostly pointing to javaish languages, since nowadays that is what people have exposure to.
09:01:53 <mike-burns> Ah.
09:02:00 <ddarius> edwardk: You don't need multiparameter type classes for that.  Higher kinds already do that, and even the * case has plenty of examples that don't really match up to the way things are done.
09:02:01 <MHD> So I have this crazy idea about static garbage collection based on lexical scopes and two different variable types...
09:02:12 <edwardk> ddarius: true
09:02:25 <tech2> edwardk: I have a long way to go, I'm just using it as a means of breaking out of the stereotypically imperative languages I'm used to.
09:02:27 <edwardk> mhd: congratulations, you just invented regions
09:02:31 <kizzx2> Botje: i have a list of numbers ns, i want to `foldl f 0 ns` on them and break immediately when the accumluated value is high enough
09:02:44 <MHD> edwardk: Cool, do I get a prize?
09:02:58 <edwardk> mhd: sure. you get to go read the regions retrospective paper!
09:03:05 <tech2> MHD: I think the 1960's might have one to offer you? :)
09:03:09 <ddarius> rndm: Whatever it is defined to be in the book.
09:03:13 <kizzx2> Botje: i thought normal dropWhile and laziness would be OK, but memory usage is shooting 1 GB for some reason
09:03:15 <edwardk> http://portal.acm.org/citation.cfm?id=993040
09:03:27 <MHD> edwardk: Actually almost everything about my WIP programming language I have come upon intuitively.
09:03:31 <edwardk> http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.64.160&rep=rep1&type=pdf is more accessible
09:03:44 <rndm> ddarius: yes fine, i suppose i am asking someone to motivate it.
09:04:00 <ddarius> rndm: No one but you knows the definition.
09:04:06 <MHD> tech2: Seriously, though, I will make a blog post about it later.
09:04:06 <edwardk> mhd: anyways that paper links to about 15 years of literature on the topic
09:04:15 <Botje> kizzx2: even if you stop adding elements after the threshold, foldl will still walk the list
09:04:31 <rndm> ddarius: that may be though I am inclined to believe that others here may have read this book
09:04:33 <Botje> kizzx2: you could do it with an unfoldr, maybe. or just tail recursion
09:04:45 <MHD> edwardk: Why would I want to read it now? I just had a true eureka moment, I want to just enjoy the buzz for a few minutes.
09:04:54 <ddarius> rndm: That doesn't mean those people are here right now or that they recall the definition off the top of their head.
09:04:55 <edwardk> mhd: it works decently for some workloads. however it doesn't interact with laziness nicely
09:04:58 <kizzx2> Botje: thanks
09:05:11 <ddarius> rndm: There would be a lot more people that could help if you provided the definition.
09:05:11 <edwardk> mhd: well, because you'll find a lot of neat tricks in it for the things that DO work ;)
09:05:12 <rndm> ddarius: relax a little. =) I'm not demanding anything
09:05:16 <MHD> edwardk: This is for a non-lazy project
09:05:54 <edwardk> in particular i'm rather fond of fluet, horrisett and ahmed's linear regions are all you need: http://www.cs.cornell.edu/people/fluet/research/substruct-regions/ESOP06/esop06.pdf
09:06:03 <edwardk> which lets you ditch the stack discipline
09:06:09 <edwardk> er morrisett
09:06:10 <tech2> MHD: no, really, it sounds cool. I was thinking two-step generational when you were talking earlier so I didn't mean to be too cruel with the semi-jibe.
09:06:44 <MHD> tech2: :)
09:07:38 <tech2> MHD: anyway, before you read the paper of edward's, write down everything you think is neat about it so your thoughts aren't polluted by other's thinking, that way you can refer back to your eureka thoughts and evaluate them later,
09:07:44 <edwardk> fluet, morrisett et al. had a bunch of other papers on the topic of substructural types as well, so regions make a nice entryway into substructural types ;)
09:08:03 <MHD> tech2: thanks for the tip
09:08:06 <Ke> epdtry If you can think of any way, please tell me
09:08:34 <tech2> MHD: I've made that mistake too many times and shot down some quite useful ideas because "other smarter people have obviously thought this through before me"
09:08:58 <tech2> MHD: for now, /ignore edwardk ;)
09:09:05 <edwardk> my usual reading approach is to come in with a thesis. i can do this. then read everyone else's stuff with that in mind
09:09:06 <MHD> heh
09:09:08 <edwardk> =P
09:09:11 <tech2> :D
09:09:31 <edwardk> that argumentative stance makes me pay attention to the details
09:09:45 <MHD> but the thing I am thinking up is basically C++ but with hidden heap allocations.
09:10:00 <edwardk> i find that having more information is generally better than less, so ignore tech2 ;)
09:10:16 <edwardk> mhd: look up cyclone =)
09:10:18 <MHD> I am going to ignore both of you and write my blog posts
09:10:21 <edwardk> =)
09:10:38 <rndm> ddarius: the definition: Let Omega be a set of operator symbols equipped with a mapping ar from the elements of Omega to natural numbers; for each omega in Omega, ar(omega) is the arity of omega. An Omega-algebra A is a set |A| (the carrier of A) and, for each operator omega of arity ar(omega), a function a_omega:|A|^{ar(omega)}, called the interpretation of omega, mapping ar(w)-tuples of elements of the
09:10:39 <edwardk> feel free, then i'll just point to the literature in the comments =P
09:10:40 <rndm> carrier back to into the carrier.
09:11:03 <tech2> every single time... there's a reason I love python, the type system doesn't make me want to kill myself :(
09:11:31 <rndm> ddarius: that's for you =), because you asked. "operator symbols" are not defined prior
09:11:57 <ddarius> rndm: I never asked.
09:12:15 <edwardk> I don't see much point in blogging on a topic that has been well explored without at least trying to look at the literature on something, whenever i do i wind up writing some kind of embarassed followup =P
09:12:20 <rndm> ddarius: sorry, to be more precise: because you suggested that i provide it
09:12:36 <edwardk> anyways back to hacking
09:13:34 <Ke> @type (+(1 :: Int))
09:13:35 <lambdabot> Int -> Int
09:14:07 <Ke> even this fails main = return undefined >>= (\y -> print (sizeOf undefined) >> (return $ y+(1::Int)) )
09:14:59 <Ke> ghc suggests "Probable fix: add a type signature that fixes these type variable(s)"
09:15:13 <ddarius> rndm: Okay, so Ω-algebra isn't the name of the concept being defined there.  It's just a name for the set of operator symbols.  So if you had one unary operator symbol h, you would have an {h}-algebra.
09:15:24 <Ke> but y is clearly inferrable
09:15:30 <clsmith> tech2: python's lack of a type system makes me want to kill myself. (and i'm a paid python programmer.)
09:15:43 <tech2> clsmith: as am I.
09:15:54 <rndm> Omega-Algebra starts after the period
09:16:02 <epdtry> Ke: yes, but 'undefined' can have any type at all, and ghc has no way to decide which one is right
09:16:17 <tech2> clsmith: One day I might actually work out what these errors are trying to tell me, when that happens I'll have a small party with a very selective guest-list.
09:16:25 <ddarius> rndm: Yes, and Omega is just the name of the set of operators.  Again, if that set was {h}, you'd then have an {h}-algebra.
09:16:33 <Ke> epdtry: y+(1::Int) locks the type
09:16:44 <clsmith> tech2: the fact that you can run a program for half an hour and only then get an AttributeError, doesn't annoy you? :/
09:16:56 <epdtry> Ke: the type of 'y', not the type of 'undefined'
09:17:16 <rndm> ddarius: the distinction between lower case omega and Omega is intentional
09:17:25 <rndm> ddarius: lower case omega is a member of Omega
09:17:28 <Ke> hmm, undefined isn't restricted by monomorphism?
09:17:32 <tech2> clsmith: it very rarely happens. I'm working on a 10yr old system with >200k lines of code. It's just got a very good set of unit tests.
09:17:36 <ddarius> rndm: Yes, it would be h in my example.
09:18:01 <rndm> ddarius: and what then are the members of h?
09:18:02 <mreh> where's that Monad instance of Either e again?
09:18:06 <clsmith> tech2: hmm, well i find python's lack of typechecking really gets on my nerves
09:18:08 <rndm> oh {h}
09:18:16 <rndm> has one member, h
09:18:17 <hpc> @hoogle Error
09:18:17 <lambdabot> module Control.Monad.Error
09:18:17 <lambdabot> module Foreign.C.Error
09:18:17 <lambdabot> module Foreign.Marshal.Error
09:18:18 <azaq23> > const "" (undefined :: Integral a => a)
09:18:19 <lambdabot>   ""
09:18:23 <hpc> mreh: ^
09:18:28 <mreh> hpc: ah yes
09:18:31 <epdtry> Ke: oh, I missed the first 'undefined' -- the two occurrences of 'undefined' don't have to be the same type, because 'undefined :: forall a. a'
09:18:51 <ddarius> rndm: You could have a {add, mul, div}-algebra as well.
09:18:52 <hpc> :t fix undefined
09:18:53 <lambdabot> forall a. a
09:18:56 <Ke> gaah
09:19:06 <tech2> clsmith: I guess it depends on a person's background. I've never really had a strong type system to rely on, so I don't find myself missing it. Only one language I've developed with professionally has had static typing and that was Java... so... enough said :)
09:19:27 <Ke> epdtry: that was a typo
09:19:45 <Ke> now it compiles as some absurd quirk
09:19:52 <Ke> or then I am blind
09:20:07 <rndm> ddarius: so what would the {add, mul, div}-algebra be there? what would the carrier be?
09:20:30 <cmccann> Ke, doesn't the monomorphism restriction only apply when a type class constraint is involved?
09:21:22 <rndm> ddarius: what would the arity be, and the mapping a_omega
09:25:03 <Ke> $type (/)
09:25:08 <Ke> @type (/)
09:25:09 <lambdabot> forall a. (Fractional a) => a -> a -> a
09:25:31 <ddarius> rndm: There isn't one {add, mul, div}-algebra, hence me saying "a {add, mul, div}-algebra."  This is defining the notion of an algebra over a set of operator symbols.  Such a notion requires a carrier set and a collection of functions, i.e. you will provide those when you define a particular algebra.  The arity is the arity of the operations which I have kept implicit, in this case the ar(add) would, presumably be 2.
09:25:32 <ddarius> It's not exactly clear as I believe you miscopied the type of a_omega.
09:26:01 <ddarius> I would expect a_omega : |A|^{ar(omega)} -> |A|
09:26:12 <rndm> I will copy again: a_w:|A|^{ar(omega)}->|A|
09:26:23 <copumpkin> :t zomg / zomg
09:26:24 <lambdabot> forall (reserve :: * -> *) banking. (Fractional (reserve banking)) => reserve banking
09:27:11 <pgiarrusso> :t zomg
09:27:11 <ddarius> In this case, Ω is, in more detail, a set Ops of meaningless symbols to stand for an operation, and a function ar : Ops -> N that provides the arity for each Op.
09:27:12 <lambdabot> forall (reserve :: * -> *) banking. reserve banking
09:27:51 <hpaste> fragamus pasted “coin” at http://hpaste.org/49917
09:27:54 <erus`> im coding in C++, i miss deriving (Show) :(
09:28:07 <fragamus> that's a crappy little test function ^^^
09:28:19 <fragamus> I want to fix it so that coin varies
09:28:22 <rndm> ddarius: I suspect as much (I am more looking for an example). what would a_w mean? is it meant to encode type signature?
09:28:24 <erus`> and ghci
09:28:44 <cmccann> erus`, personally if I was coding in C++, the main thing I would miss is not coding in C++
09:28:51 <MHD> does GHC use Parsec?
09:28:57 <erus`> C++ isnt so bad
09:29:03 <ddarius> a_w is just the name of a function.  E.g. a_add.  It can be any function with arity ar(add) = 2, i.e. a_add : |A||A| -> |A|.
09:29:03 <fragamus> the way it works now is that coin gets generated once, and is fixed as one value evermore
09:29:09 <erus`> i duno why it gets so much stick
09:29:13 <cmccann> erus`, it's better than brainfuck, certainly
09:29:17 <MHD> C++ has bad genrics
09:29:17 <cmccann> or INTERCAL
09:29:28 <MHD> not QINTERCAL
09:29:34 <erus`> id rather write something in C++ than C
09:29:41 <tech2> :|
09:29:41 <MHD> QINTERCAL has quantum computing built right in.
09:30:38 <MHD> Ok, guys: http://wypp-lang.blogspot.com/
09:30:43 <ddarius> So, when you define a {add, mul, div}-algebra, you choose a set, let's choose R, the set of real numbers, and a collection of functions, one for each operator symbol, i.e. a_add, a_mul, a_div.  We can choose the normal operations except we have to give a real number answer for divide by zero, so we can define that to be zero.
09:30:48 <MHD> for all of you interested in my little project.
09:30:53 <ddarius> That would be an {add, mul, div}-algebra.
09:30:55 <peteriserins> why is haskell much more popular than lisp for programming language research?
09:31:50 <pgiarrusso> rndm: if you are looking for an example of an omega-algebra, you can have a lot of things, including groups, rings, and so on (excluding their "laws")
09:32:05 <ddarius> Alternatively, we could use the set R+1, i.e. Maybe R, and define each of a_add, etc. to return the extra element if given it for either argument, and a_div to return it also when the second argument, the denominator, is zero, so that we don't have to give a real number for divide by zero.
09:32:14 <edwardk> peterirserins: types
09:32:20 <cmccann> peteriserins, independent of any other differences, some form of Lisp has been around for a very long time; so it's reasonable to expect that most low-hanging fruit there is already taken
09:32:40 <pgiarrusso> peteriserins: if you want a research-oriented Lisp, you should look for e.g. Racket
09:32:42 <ddarius> edwardk: Also purity to some extent, but yes, mostly tyes.
09:32:46 <ddarius> s/tyes/types/
09:33:10 * cmccann isn't sure what else there is to say about Lisps given that the lambda papers already exist
09:33:14 <kizzx2> when haskell reports stackoverflow can i get a "stack trace" of why taht happened?
09:33:29 <ddarius> cmccann: All the metaobject protocol stuff happened long after those.
09:33:30 <edwardk> cmccann++
09:33:32 <pgiarrusso> kizzx2: in ghci you can
09:33:44 <cmccann> kizzx2, probably not, because the stack that's overflowing probably isn't what you expect it to be
09:34:37 <pgiarrusso> the command is IIRC :trace <expr>
09:35:04 <pgiarrusso> kizzx2, cmccann: http://www.haskell.org/ghc/docs/7.0.3/html/users_guide/ghci-debugger.html
09:35:26 <rndm> pgiarrusso: i am. thanks.
09:35:29 <Twey> ddarius: Your encoding is not-UTF-8, FYI.
09:35:40 <kizzx2> pgiarrusso: strange, it's not overflowing in GHCi, but hung there
09:35:44 <cmccann> yes, I've used GHCi's debugger, it's just very counterintuitive at first because of how things are evaluated
09:35:46 <rndm> pgiarrusso: ddarius: i have to step away for a moment, haven't had a chance to fully read. brb
09:35:57 <fragamus> cmccann: you can use a log monad to keep track of what happened
09:35:57 <kizzx2> i've already compiled it -O2
09:36:00 <ddarius> rndm: But you can choose any set you want, and any three binary functions from that set and to it, and you will have an {add, mul, div}-algebra.
09:36:21 <Claudius1aximus> @where RTS-xc
09:36:21 <lambdabot> ghc --make -fforce-recomp -prof -auto-all -rtsopts foo.hs && ./foo +RTS -xc
09:36:26 <kizzx2> whereas just running the thing overflows it quite quickly
09:36:59 <pgiarrusso> kizzx2: you'd first need :set -fbreak-on-exception to catch the exception when it happens
09:37:03 <cmccann> ddarius, hm, you're right, I misremembered some of the dates. Ah, well.
09:37:07 <erus`> if i run something through a lexer it has been lexed. Is my spelling correct there?
09:37:11 <pgiarrusso> and maybe :set -fbreak-on-error
09:37:20 <pgiarrusso> erus`: yes
09:37:28 <tech2> Is there a preferred editing environment for Haskell?
09:37:28 <Twey> peteriserins: Haskell is easier to reason about mathematically, has a syntax that is friendlier for mathematicians, and pure, lazy functional programming has a lot of interesting new frontiers to explore that haven't all been mapped out yet
09:37:44 <pgiarrusso> kizzx2: ghci uses a different runtime, I guess you want to change some settings
09:37:47 <pgiarrusso> maybe reduce the stack size
09:38:03 <kizzx2> that's an idea
09:38:08 <Twey> s/,/ and/
09:38:24 <monochrom> ghci default stack size is 512MB
09:38:41 <Twey> tech2: emacs :þ
09:38:53 <pgiarrusso> monochrom: I do guess that's bigger than the ghc stack size, right?
09:39:02 <tech2> Twey: that's a little unfortunate :)
09:39:04 <edwardk> tech2: i use vim, others use emacs, textmate, leksah, yi, etc.
09:39:22 * cmccann also maintains that purity is best regarded as an implementation detail, mostly significant only because it's required to make types usefully meaningful
09:39:26 <Twey> Most of us seem to use emacs, though there are a few who use vim
09:39:27 <tech2> edwardk: I had wondered about the popularity of yi here, for obvious reasons
09:39:33 <kizzx2> tech2: Vi, that's more fortunate
09:39:34 <fragamus> i like leksah
09:39:46 <monochrom> ghc-generated executables default to 8MB
09:39:47 <Twey> I've not encountered anyone who uses yi or Leksah for Serious Business
09:39:50 <Twey> fragamus: Do you?
09:39:57 <kizzx2> tech2: Vi's haskell mode really has what you want in an IDE, no joking
09:40:02 <fragamus> my business is learning
09:40:04 <edwardk> i've seen leksah being used quite a bit
09:40:12 <ddarius> Twey: The last poll that was done, which was a long time ago admittedly, had about an even split between emacs and vim and plenty of other editors, though together those were the majority.
09:40:13 <fragamus> im a newb
09:40:22 <kizzx2> techn2: "real" code completion (with return type signature) and "go to definition"
09:40:26 <pgiarrusso> monochrom: I expected so. But how do you reduce ghci stack size?
09:40:37 <edwardk> vi's haskell mode is pretty good. i admit i don't tend to use it though, but thats because i'm slow to change my workflow
09:40:38 <monochrom> "ghci +RTS -K8M"
09:40:40 <cmccann> I use a dumb code editor that's not an IDE in any way, for what it's worth
09:40:46 <tech2> kizzx2: vim's haskell mode doesn't seem to indent nicely
09:40:56 <Entroacceptor> kizzx2: does it have auto-compile?
09:40:58 <cmccann> it's surprisingly easy to get by in Haskell without any editor support
09:41:06 <pgiarrusso> tech2: seconded
09:41:14 <kizzx2> Entroacceptor: you can type ":make<CR>" to compile, i map that to Ctrl+F7
09:41:19 <Entroacceptor> with error hilighting
09:41:22 <clsmith> it's surprisingly easy to get by in any language without editor support :/
09:41:34 <edwardk> Entroacceptor: you can set :make to run cabal install
09:41:36 <tech2> pgiarrusso: contemplating writing an indent plugin, but I think that can wait :)
09:41:42 <kizzx2> Entroacceptor: yes it does, with "Quick list", choosing an item on the quick list jumps to the error immediately
09:41:49 <ddarius> cmccann: Purity is an implementation detail when it is, but you can have pure and impure interfaces.  There is a big difference between a mutable list and an immutable list regardless of how they are implemented.
09:42:05 <pgiarrusso> cmccann: have you read Martin Odersky's thought about having a debugger for type inference?
09:42:10 <pgiarrusso> That'd be really cool
09:42:23 <pgiarrusso> even more so for Haskell (Odersky talks about Scala of course)
09:42:46 <ddarius> @google chameleon type debugger
09:42:53 <edwardk> well, given the state of the scala implementation i wind up needing a debugger during type inference a lot. mostly to debug the compiler sadly.
09:42:53 <ddarius> (Not quite the same thing.)
09:42:58 <lambdabot> http://arxiv.org/abs/cs/0311023
09:43:00 <Twey> ddarius: Interesting… there seems to be a lot of discussion about haskell-mode here, but the only talk I've ever seen of vim is from Cale, and apparently edwardk.
09:43:15 <tech2> what's the tool that provides the suggestions/lint functionality in hpaste?
09:43:20 <Twey> tech2: hlint
09:43:22 <Twey> :þ
09:43:24 <tech2> thanks
09:43:27 <pgiarrusso> edwardk: Yeah, I see
09:43:36 * clsmith uses vim too, but is new to haskell :]
09:43:40 <Twey> ddarius: So admittedly it has a rather elite user-base, but I've always thought it to be a small one
09:43:45 <ddarius> Twey: Clearly you are not paying attention.  If nothing else, I use vim and have said as much several times.
09:43:54 <Twey> Perhaps so.
09:44:20 <cmccann> ddarius, yes, that's what I mean about types being meaningful. it's a bit circular, since I'm basically arguing that purity-by-default is important because it allows type-based effect-tracking
09:44:22 <pgiarrusso> edwardk: I also keep hitting bugs in the Scala compiler
09:44:50 <ddarius> At any rate, I don't know what the distribution is now, but I highly suspect the main difference is that there are more "other" editors being used and the relative proportions between emacs and vim have stayed mostly the same.
09:45:13 <pgiarrusso> cmccann: but why do you then "maintain that purity is best regarded as an implementation detail"?
09:45:53 <zmv> ACME :P
09:45:53 <ddarius> Twey: dons is also a vim user.
09:46:05 <cmccann> pgiarrusso, because I'd accept any other means of making the type system similarly useful
09:46:26 <pgiarrusso> You're thinking of monads and effects, I guess, aren't you?
09:46:34 <pgiarrusso> But purity (and only purity) is what enables "theorems for free"
09:46:49 <cmccann> monads are even more an implementation detail
09:47:25 <pgiarrusso> do you have concrete alternatives to purity?
09:47:32 <pgiarrusso> in this context I mean
09:47:51 <edwardk> pgiarrusso: there is a lot of work on effect systems that can serve as a substitute
09:48:15 <pgiarrusso> edwardk: but aren't they replacement for monads basically?
09:48:20 <cmccann> pgiarrusso, not that I'm aware of, but purity feels a bit like a sledgehammer. I can easily imagine a more sophisticated system that tracks effects explicitly in other ways
09:48:30 <ddarius> Yes, but there would be interface differences between a monadic approach and an effect-system approach, so monads still wouldn't be an "implementation detail."
09:48:45 <edwardk> they overlap, but neither subsumes the other per se
09:48:48 <pgiarrusso> purity forces any "forall a. a -> a" function to be id (excluding nontermination)
09:48:54 <ddarius> Something is an implementation detail if you can change it without affecting the interface.
09:49:18 <pgiarrusso> and in more complex examples, that is what ensure the "typechecks -> works" property of Haskell programming
09:49:52 <pgiarrusso> so when you have more monomorphic types, you don't get the same kind of guarantees
09:49:54 <cmccann> ddarius, the only interface I'm concerned with here is the type system as a whole in some abstract sense. clearly the actual language would be very different, yes.
09:50:58 <ddarius> Well, it was not clear that you were talking about some undefined notion before.  Carry on.
09:53:18 <cmccann> ddarius, but yes, I realize that "implementation detail" is not really the best term here, but I couldn't think of a better phrasing off the top of my head
09:53:52 <monochrom> ergonomics details :)
09:54:33 <erus`> what would you guys call haskells partially applied first class function types
09:54:50 <monochrom> function types
09:54:51 <cmccann> what I'm trying to get at is that unrestrained impurity (among other things) undermine the ability to look at a type signature and learn useful things about a function, which is what's most important to me
09:55:06 <erus`> monochrom: when describing them to someone
09:55:18 <erus`> haskell features first class functions with currying
09:55:37 <ddarius> erus`: Every language that has "first class functions" has currying.
09:55:38 <hpc> erus`: i would just say 'partially applied function'
09:56:00 <monochrom> I still maintain my "function types"
09:56:19 <pgiarrusso> ddarius: ML and Scala both have currying, but only in Haskell that's used by default
09:56:29 <monochrom> "what is 'map f'?" "a function" end of story
09:56:36 <cmccann> pgiarrusso, also, I think you were talking about parametricity which is a stronger concept than purity by a fair margin, I believe
09:56:43 * hackagebot hakyll 3.2.0.5 - A static website compiler library  http://hackage.haskell.org/package/hakyll-3.2.0.5 (JasperVanDerJeugt)
09:56:58 <ddarius> pgiarrusso: It's not "used by default" rather the syntax and libraries encourage defining functions in a curried-style.
09:57:25 <ddarius> pgiarrusso: I could just as well define foldr(c,n,xs) = ... as in ML.
09:57:40 <pgiarrusso> ddarius: I know, but it's not in the coding style.
09:57:55 <pgiarrusso> moreover data constructors are curried in Haskell and not in ML
09:58:24 <pgiarrusso> finally, Haskell has been optimized to make currying less expensive
09:58:40 <ddarius> pgiarrusso: I can have uncurried data constructors in Haskell.  ML is more the way it is for historical reasons.
09:58:53 <ddarius> At any rate, none of these things make "currying" a "feature" of Haskell.
09:58:54 <monochrom> cmccann: generally, you are probably going after "an expressive type system", so that each type tells you a whole lot of information. in the limit, it becomes "types as contracts", each type is complete information, you can't ask for more
09:59:27 <ddarius> (The last comment about ML was only with regard to data constructors.)
09:59:49 <ddarius> monochrom: Maybe -you- can't ask for more.
10:00:37 <pgiarrusso> ddarius: let's say that the idiomatic function definition is curried in Haskell and not in ML
10:00:49 <ddarius> pgiarrusso: Is that not what I said at the beginning.
10:01:01 <ddarius> (Only not referencing ML.)
10:01:40 <clsmith> hmm, i'm trying to work out an elegant data structure for this problem. say i've got a whole big file of data, and i want to manipulate it efficiently. i figure fingerstrings with a char- and line-based monoid would do the trick. but i also want a cursor position, which may be a selection, and in fact i want an arbitrary number of cursors, with selections... can anyone think of an elegant way to do that using annotations? (i don't really want to have to m
10:01:52 <clsmith> i .. think that may have got cut off. :/ wall-of-text
10:02:06 <cmccann> monochrom, sort of, but there are different ways to fall short of that limit. reliability is more what I'm after than expressive power, given some civilized minimum for both
10:02:10 <monochrom> wall of text is what irc is for
10:02:24 <ddarius> clsmith: Talk to edwardk.
10:02:42 <pgiarrusso> ddarius: you were underlying the lack of difference between haskell and other languages with first-class function, while in practice there is a difference, due to different idioms
10:03:04 <clsmith> edwardk: ^ any ideas? :)
10:03:34 <clsmith> *fingertrees
10:03:39 <cmccann> clsmith, looks like you got cut off at "don't really want to have to m" btw
10:03:40 <ddarius> pgiarrusso: No, I said, "Every language that has 'first class functions' has currying" which is a factual and in fact tautological statement.
10:04:02 <clsmith> ah, "... map over a list of (cursor,selection) pairs and all that) :p
10:05:28 <pgiarrusso> ddarius: being correct doesn't make it the most useful (or informative) answer
10:06:16 <cmccann> it's not informative because being able to curry is the definition of having first-class functions, pretty much
10:06:43 * hackagebot bytestring-nums 0.3.3 - Parse numeric literals from ByteStrings.  http://hackage.haskell.org/package/bytestring-nums-0.3.3 (JasonDusek)
10:06:53 <erus`> what cant haskell modules have circular refs?
10:07:21 <hpc> erus`: design choice?
10:07:25 <edwardk> clsmith: that sounds a lot like what i'm building with trifecta
10:07:37 <hpc> i personally prefer for dependencies to form a tree, not a graph
10:07:39 <edwardk> clsmith: i'm going to the park with my wife for a couple hours but i'll be back soon
10:07:47 <pgiarrusso> erus`: http://www.haskell.org/ghc/docs/7.0.3/html/users_guide/separate-compilation.html#mutual-recursion
10:08:05 <clsmith> edwardk: haha, ok :) talk soon
10:08:28 <edwardk> clsmith: but you described almost exactly the diagnostics subsystem i'm porting into trifecta right now
10:08:40 <ddarius> cmccann: That is exactly the case.  No need for "pretty much."
10:08:41 <erus`> haskell.org has been playing up for me for 2 days
10:09:27 <pgiarrusso> erus`: if you compare Haskell to Java, I guess a technical difference is that because of type inference, you don't know the types of module B until you get all the types of the modules it depends on
10:09:42 <pgiarrusso> and that is not true in Java
10:10:14 <ddarius> pgiarrusso: The point of my response is that "currying" is not a  "(language) feature" and should not be discussed as if it's some feature Haskell has that other languages lack.
10:10:58 <pgiarrusso> erus`: so to compile two mutually dependent modules A and B, you need the types of A to produce the types of B and viceversa
10:11:09 <erus`> ah
10:11:31 <pgiarrusso> erus`: that link explains that in fact you can compile A and B, but it's a bit messy
10:11:49 <pgiarrusso> so you probably want to avoid the need for that
10:12:11 <pgiarrusso> erus`: what does "play up for" mean? access trouble?
10:12:16 <erus`> yeah
10:12:19 <erus`> timing out
10:12:32 <erus`> it looks like its loading the html ok but not something else
10:12:42 <erus`> its not even rendering the page in firefox
10:12:57 <cmccann> ddarius, I was hedging only because there are some very pathological language designs out there and I wouldn't be surprised to find terms like "first-class functions" being consistently misused in places
10:13:10 <cmccann> when talking about actual languages I prefer not to assume that people will be using terminology in sane ways
10:13:21 <pgiarrusso> erus`: no clue
10:13:40 <pgiarrusso> erus`: works for me
10:13:53 <pgiarrusso> ddarius: I see your point...
10:13:56 <mm_freak_> ddarius: but other languages do lack currying, and it sucks that they do
10:14:14 <mm_freak_> no currying ultimately means no closures
10:14:36 <pgiarrusso> erus`: http://webcache.googleusercontent.com/search?q=cache:73AHCCC52HAJ:www.haskell.org/ghc/docs/7.0.3/html/users_guide/separate-compilation.html+%22How+to+compile+mutually+recursive+modules%22+haskell&cd=1&hl=en&ct=clnk&source=www.google.com
10:14:39 <ddarius> mm_freak_: Yes, but those "other languages" are C++, C, FORTRAN, COBOL, and arguably Java.  Not Python, ML, Ruby, Smalltalk, C#.
10:14:52 <mm_freak_> ddarius: so it is a feature of those languages
10:15:24 <mm_freak_> in fact i think closures are equivalent to currying
10:15:34 <pgiarrusso> erus`: look for How to compile mutually recursive modules
10:15:39 <ddarius> mm_freak_: That's been said except s/closures/first class functions/.
10:16:09 <mm_freak_> ddarius: i think it's stronger, because a partial application is no different from a closure
10:16:15 <ddarius> mm_freak_: The issue is when people talk of "currying" as some feature unique to Haskell.  Also, terms like "first class function with currying" are sort of meaningless/redundant.
10:16:25 <mm_freak_> true
10:16:28 <ddarius> mm_freak_: Closures are an implementation concept.
10:17:14 <ddarius> First class functions could be implemented with closures, they could also be implemented with lambda lifting and partial applications, they could also be implemented with defunctionalization.
10:17:16 <erus`> pgiarrusso: i think i will just try not todo it
10:17:21 <erus`> looks like a serious pain
10:17:22 <ddarius> or via combinators.
10:17:27 <cmccann> currying is uniquely tied to Haskell in one sense, though
10:17:55 <ddarius> Regardless, you will be able to "partially" apply a function no matter how it is implemented.  "Partial application" is just application.
10:18:08 <rndm> ddarius, pgiarrusso: I'm back, read up, and I think I get it. I was trying to interpret |A| as a set of "types" and a_w as arrows mapping cartesian products of |A| back into |A|. This would just be a single Omega-algebra but I was trying to make it look too much like a category.
10:18:23 <ddarius> cmccann: Where, I'm assuming, Clean ∈ Haskell.
10:18:42 <knoc_> If I have an Int, and I know it is even, is there some way to divide it through 2, without complicated conversions such as floor ((fromInteger n :: Double) / 2) ?
10:18:56 <tech2> why would I want to use (head Control.Arrow.&&& length) rather than (\y -> (head y, length y)) ?  hlint seems to be suggesting it but I don't understand why.
10:19:10 <ddarius> rndm: What I'm sure will shortly be defined in that book is the term algebra, probably notation T(Ω) where the carrier will essentially be abstract syntax trees.
10:19:33 <cmccann> ddarius, no, in the sense of shared namesake :]
10:19:45 <ddarius> tech2: It's a style thing.  You don't have to listen to hlint.
10:20:10 <ddarius> Admittedly, you'd want to import Control.Arrow.&&& so you had head &&& length.
10:20:16 <tech2> ddarius: I appreciate that, but I'm trying to understand the motivation behind such style?
10:20:23 <pgiarrusso> tech2: it's a point-free way to write it
10:20:32 <ddarius> tech2: It's shorter and you don't have to make up the name "y".
10:20:34 <rndm> ddarius: and the arrows give rules for grammar classification?
10:20:49 <pgiarrusso> it emphasizes that you are combining together functions
10:21:00 <tech2> ddarius: assuming I import &&&, yes, thanks
10:21:20 <rndm> ddarius: nevermind, i shouldn't drag you far off into the weeds before reading on. thanks
10:21:39 <ddarius> rndm: I don't know which arrows you mean.  If you mean the operations, i.e. the a_w, they will just be what would be called "data constructors" in Haskell.
10:21:49 <pgiarrusso> tech2: http://www.haskell.org/haskellwiki/Pointfree
10:21:53 <rndm> ddarius: i did mean a_w
10:22:03 <pgiarrusso> rndm: don't think of "grammars"
10:22:20 <rndm> pgiarrusso: think of type constructors?
10:22:29 <pgiarrusso> rndm: data constructors instead
10:22:34 <ddarius> tech2: Also, you can technically manipulate head &&& length easier.
10:22:34 <tech2> pgiarrusso: thanks, still working my way through "for great good"
10:22:45 <tech2> ddarius: how so?
10:22:47 <MHD> There, now my toolset is detailed over at wypp-lang.blogspot.com
10:22:55 <rndm> is there a difference in terminology between "type constructor" and "data constructor
10:22:58 <rndm> "?
10:23:18 <cmccann> rndm, yes, type constructors construct types and data constructors construct data
10:23:55 <pgiarrusso> rndm: anyway, the book does not really describe term algebras in detail, which is a pity
10:23:56 <rndm> cmccann: oh i see. the former is polymorphism?
10:24:14 <pgiarrusso> rndm: no
10:24:19 <parcs> rndm: Maybe is a type ctor, Just in a data ctor
10:24:21 <rwbarton> for example take  data Maybe a = Nothing | Just a  ; Maybe is a type constructor, and Nothing and Just are data constructors
10:24:27 <cmccann> rndm, "Maybe Int" is constructing a new type from Int, while "Just 5" is constructing a new value from "5"
10:24:37 <cmccann> haha, everyone uses the same example
10:24:53 <ddarius> rndm: For the Ω = {add, mul, div, one, zero}, the carrier of T(Ω) would be data TOmega = Add TOmega TOmega | Mul TOmega TOmega | Div TOmega TOmega | One | Zero (some nullary constructors added so it would not be trivial)
10:24:54 <parcs> it's the simplest :P
10:25:21 <cmccann> parcs, the simplest that doesn't have type and data constructors with the same name and arity
10:25:35 <rndm> cmccann: ah, okay. that's what i was thinking of, some kind of parameterized type. having a free type parameter isn't called polymorphism?
10:25:37 <pgiarrusso> rndm: a type constructor is a function from types to types (or types constructors - Haskell type constructors are carried)
10:25:38 <parcs> cmccann: yeah
10:25:47 <ddarius> tech2: There are laws that (&&&) should satisfy and, more generically, manipulating terms without binders is simpler than manipulating terms with binders.
10:26:04 <tech2> ddarius: I can see I have a lot to learn.
10:26:05 <pgiarrusso> rndm: with polymorphism, you have a "function" from types to values (usually function values)
10:26:24 <pgiarrusso> rndm: I did have the same confusion too at some point.
10:27:23 <pgiarrusso> rndm: so for instance in System F, you can apply id (with type :: forall a. a -> a) to the type Int and get a "value" of type Int -> Int
10:27:23 <rndm> pgiarrusso: i see. in that case by fixing 'a' i get a function, vs fixing 'a' giving me a data constructor?
10:27:46 <pgiarrusso> rndm: you mean type constructor there; apart from that yes
10:28:23 <pgiarrusso> moreover, "Maybe Int" doesn't want any more type parameters, so it's just a type
10:29:02 <rndm> pgiarrusso: ah i see. i was about to ask isn't Maybe a with fixed 'a' defined by its data constructors
10:29:08 <pgiarrusso> (I don't know if you can say that it's a type constructor of arity 0; for sure you can say that it has kind *, while Maybe has kind * -> *)
10:29:40 <fragamus> can you help me get my coin to flip
10:29:41 <fragamus> http://hpaste.org/49917
10:29:42 <rndm> (oh, but it would give a family of them)
10:30:03 <pgiarrusso> Maybe a with fixed a is a data type, and values inhabiting that type are defined by data constructors
10:30:26 <rndm> blah. it's so weird how one can go so long throwing all of these words around just fine in every day usage and end up here realizing they (I) haven't really understood any of it
10:32:05 <parcs> rndm: just remember that type ctors are used in type annotations and data ctors in expressions
10:32:55 <rndm> parcs: thanks, that makes it really clear
10:33:20 <pgiarrusso> @hoogle RandomGen
10:33:20 <lambdabot> System.Random class RandomGen g
10:34:48 <pgiarrusso> fragamus: can't load that code
10:34:58 <pgiarrusso> where's liftList from?
10:35:05 <tylergillies> does erlang spread threads across cores?
10:35:16 <pgiarrusso> @hoogle liftList
10:35:16 <lambdabot> No results found
10:35:23 <ddarius> pgiarrusso: You can talk of nullary type constructors, such as Int, but it is arguable whether Maybe Int should be called a type constructor.
10:35:34 <fragamus> -- In ListT from Control.Monad this one is the data constructor ListT, so sadly, this code can't be a drop-in replacement.
10:35:37 <fragamus> liftList :: Monad m => [a] -> ListT m a
10:35:40 <fragamus> liftList [] = ListT $ return MNil
10:35:42 <fragamus> liftList (x:xs) = ListT . return $ x `MCons` (runListT $ liftList xs)
10:37:00 <fragamus> hmmmm liftList reminds me of something I had to write before
10:37:20 <pgiarrusso> fragamus: if you want help, what about posting a complete code sample?
10:37:36 <mm_freak_> while an arrow is equivalent to an applicative functor, what is an arrow with ArrowChoice equivalent to?  it seems to be something between an applicative functor and a monad, which has no real typeclass
10:37:59 <fragamus> well my code is full of crap
10:38:05 <pgiarrusso> Is an arrow equivalent to an applicative functor??
10:38:33 <fragamus> I had to make my own ListT and my own RandT
10:38:35 <pgiarrusso> @hoogle getRandomR
10:38:35 <lambdabot> No results found
10:39:07 <pgiarrusso> fragamus: sorry, can't help
10:39:19 <fragamus> dats otay sorry to bother you
10:39:34 <pgiarrusso> mm_freak_: I remember that ArrowApply is equivalent to a Monad
10:40:01 <mm_freak_> pgiarrusso: there is a paper showing a one-to-one mapping between arrows and applicative functors
10:40:08 <mm_freak_> i don't remember where i found it
10:40:15 <mm_freak_> i think it was in the latest HWN
10:41:22 <pgiarrusso> http://cdsmith.wordpress.com/2011/07/30/arrow-category-applicative-part-i/
10:41:35 <pgiarrusso> So Arrow = Category + Applicative
10:42:00 <ddarius> pgiarrusso: Except if you actually read that article, he states that you need a bit more than that to get an Arrow.
10:42:48 <pgiarrusso> ddarius: okay, thanks for the tip. Anyway, the original statement here was incorrect
10:42:55 <ddarius> pgiarrusso: Indeed.
10:45:10 <erus`> whats the difference between f x = j and f =x ? one is a value and one is a function?
10:45:25 <erus`> but then everyone says that "functions are values too"
10:45:38 <ddarius> Functions are values.  Values are not necessarily functions.
10:46:25 <erus`> whats the name for a value that isnt a function
10:46:41 <mwc> erus`: 0-ary function :P
10:46:45 <ddarius> mwc: No.
10:47:02 <tech2> you can't have 0-ary functions ddarius ?
10:47:08 <mm_freak_> while Arrow is equivalent to an Applicative + Category + "a bit more", what is an arrow with ArrowChoice equivalent to?  it seems to be something between an applicative functor and a monad, which has no real typeclass
10:47:16 <jocom> For the type class Traversable of Data.Traversible, I'm trying to reconstruct traverse from sequenceA
10:47:17 <ddarius> erus`: It doesn't really have a name as there is rarely a reason to distinguish that case.
10:47:21 <erus`> meh i'll just go with values and functions. haters gonna hate
10:47:29 <jocom> vice versa I already succeeded
10:47:33 <ddarius> tech2: All functions in Haskell are unary.
10:47:46 <jocom> But this way isn't really succeeding, any hints?
10:47:48 <tech2> ok, thanks
10:47:52 <erus`> ddarius: one has to contain a pattern
10:47:54 <conal> jocom: add an fmap ?
10:48:24 <ddarius> erus`: I don't what "has to contain a pattern" means.
10:48:35 <jocom> conal: Wow, that was simple (-;
10:48:42 <conal> jocom: :)
10:48:43 <erus`> ddarius: an arguement list
10:49:00 <conal> jocom: similarly, check out fold vs foldMap in Data.Foldable
10:49:03 <jocom> But, now, it should also possible to reconstruct fmap from traverse
10:49:23 <erus`> theres no point storing an empty arguement list for every value, so i might aswel distinguish between the two
10:49:25 <ddarius> erus`: Functions have arguments, yes.  I'm saying it's not too common to have to talk about non-function values.
10:49:27 <conal> jocom: oh, and >>= vs join in Monad
10:49:53 <jocom> conal: Yeah, those two are known to me
10:50:20 <jocom> Some overall structure begins to sink in
10:50:42 <jocom> But is that justifiable? That overall structure?
10:51:01 <conal> jocom: somehow sequenceA, fold, and join sit in my brain more comfortably than than traverse, foldMap, and (>>=)
10:51:04 <ddarius> erus`: If you have polymorphism (or even without) it can easily be the case that one of the values that you are not storing arguments for is a function.
10:51:26 <ddarius> erus`: Which works perfectly well with the (usual) function/value terminology.
10:51:38 <erus`> ah ok
10:51:41 <jocom> conal: Though they pairwise differ only a join... I do however agree with you
10:51:50 <jocom> I also prefer fold and join
10:52:08 <jocom> differ an fmap **
10:53:22 <hpaste> tech2 pasted “out of memory, why?” at http://hpaste.org/49919
10:54:54 <jocom> Any hints on how to construct fmap from traverse or sequenceA ??
10:55:40 <tech2> Hi all, made some change to my earlier attempt at learning but now I'm getting out of memory for some reason :/ Ideas?
10:56:11 <pgiarrusso> tech2: which invocation are you using?
10:56:43 * hackagebot css-text 0.0.0 - CSS parser and renderer.  http://hackage.haskell.org/package/css-text-0.0.0 (MichaelSnoyman)
10:56:45 * hackagebot mongrel2-handler 0.3.1 - Mongrel2 Handler Library  http://hackage.haskell.org/package/mongrel2-handler-0.3.1 (BardurArantsson)
10:56:47 <tech2> pgiarrusso: ah, sorry, assume I call "bigger 1", it will give me list of strictly increasing lengthed collatz chains
10:57:15 <tech2> pgiarrusso: I just wanted to be able to call it with a value so I could continue from a known point if the calc was stopped
10:58:02 <tech2> pgiarrusso: I know I'm doing something wrong, just not sure what
10:59:40 <jocom> Am I correct when I say that fmap is constructed from traverse by putting f = id  ??
10:59:53 <ddarius> :t traverse id
10:59:54 <lambdabot> Not in scope: `traverse'
11:00:00 <ddarius> @hoogle traverse
11:00:01 <lambdabot> Data.Traversable traverse :: (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
11:00:01 <lambdabot> Data.Foldable traverse_ :: (Foldable t, Applicative f) => (a -> f b) -> t a -> f ()
11:01:28 <pgiarrusso> traverse id has the same type as sequence
11:01:45 <pgiarrusso> tech2: I'm looking through your code and seeing it makes sense
11:01:47 <ddarius> I think, seeing the type now, jocom meant the type variable f.
11:01:55 <jocom> Indeed
11:02:10 <ddarius> In which case it depends on the laws of traversable.
11:02:21 <jocom> I allready noted that traverse id = sequenceA
11:02:56 <jocom> But, does my sentence about fmap make sense?
11:03:10 <ddarius> The documentation page though just explicitly states that traverse should be fmap for the identity applicative functor.
11:03:30 <jocom> Ok, then I was right (-;
11:03:42 <tech2> pgiarrusso: I'm just wondering where I'm storing a sufficiently large amount of state for it to OOM
11:03:43 * jocom should rtfm
11:04:20 <pgiarrusso> tech2: I'm trying to working out the details even though I'm no expert
11:04:53 <tech2> pgiarrusso: bigger 106239  will lead to it more immediately than bigger 1
11:05:37 <pgiarrusso> do you get it when typing that at ghci's prompt?
11:05:53 <tech2> yes
11:06:45 <pgiarrusso> tech2: basically, I think it might depend on laziness and on building bigger and bigger thunks
11:06:52 <pgiarrusso> not sure where
11:07:05 <tech2> pgiarrusso: thanks for trying though.
11:07:08 <pgiarrusso> but probably you want to learn how to use GHC profiler
11:07:17 <tech2> yeah
11:08:53 <pgiarrusso> starting from http://haskell.org/haskellwiki/Performance
11:09:16 <pgiarrusso> Anyway, my suspect is that you are building somewhere a bigger and bigger thunk
11:09:24 <pgiarrusso> without ever having it evaluated
11:09:32 <pgiarrusso> and that might be the source of all this memory usage
11:10:00 <tech2> I expect it's somewhere around the dropWhile, but I wouldn't have thought that was a problem since I'm calling head on the result.
11:10:11 <tech2> anyone else?
11:11:53 <pgiarrusso> tech2: note that the result is a thunk
11:12:01 <pgiarrusso> which contains a call to length
11:12:09 <pgiarrusso> which contains a pointer to the full list
11:12:21 <pgiarrusso> as long as the result is not forced, you're keeping the whole list in memory
11:13:28 <pgiarrusso> but that doesn't look yet enough of a problem, because that list is long like 500 elements
11:13:33 <tech2> how do I prevent keeping the whole list in memory? I thought I was generating a list of lists, taking each entry and discarding if length <= one of the arguments, and only returning the value when the length was greater.
11:14:53 <Claudius1aximus> tech2: your code seems to run in constant space here (ghc 7.0.3 -O3) (with main = mapM_ print (bigger 1))
11:16:05 <tech2> *Main> bigger 106239
11:16:05 <tech2> [(106239,354),<interactive>: out of memory (requested 2097152 bytes)
11:16:19 <tech2> :(
11:16:28 <pgiarrusso> > bigger 106239
11:16:29 <pgiarrusso> [(106239,354),(142587,375),(156159,383), ....
11:16:29 <lambdabot>   Not in scope: `bigger'
11:16:40 <pgiarrusso> it works here too
11:16:44 <tech2> wtf? :|
11:17:10 <pgiarrusso> these properties are partially compiler-dependent
11:17:46 <DevHC> why aren't the written files flushed when the program exits?
11:17:51 <pgiarrusso> But I mean, how come 2 MB is too much?
11:17:55 <DevHC> (automatically, without calling hFlush)
11:18:07 <pgiarrusso> DevHC: are you calling hClose?
11:18:15 <DevHC> no
11:18:25 <monochrom> use hClose or withFile
11:19:13 <tech2> pgiarrusso: 2MB isn't too much, it's the last chunk to be malloc'd, I have 3GB free memory on the machine, dunno how much heap the ghci has by default (128MB?)
11:19:17 <pgiarrusso> and if you want to know why hClose is not called automatically, that's because supporting these things doesn't work well in a language with GC
11:19:43 <monochrom> heap starts small but grows without limit
11:20:20 <DevHC> kthx
11:20:28 <tech2> monochrom: ok, so this means I'm devouring 3GB with a simple program but can't work out why.
11:20:44 <monochrom> you could impose a limit with a +RTS switch
11:21:29 <tech2> I don't mind not having a limit, I'd just like to find out what I'm doing wrong, because this seems like a failure of understanding for me as to how the code works.
11:22:54 <pgiarrusso> tech2: reasoning about laziness and space is complex for many people
11:23:13 <pgiarrusso> to the point that some people (out of here) argue that laziness by default is a bad idea
11:23:30 <pgiarrusso> which is your GHC version anyway?
11:23:36 <ddarius> Reasoning about space is generally complex.
11:23:49 <tech2> pgiarrusso: 6.12.3
11:24:01 <pgiarrusso> tech2: I have 7.0.3
11:24:08 <ddarius> While laziness has some extra complexity, it is more different than it is more complex.
11:24:12 <tech2> I would have thought I was only dealing with one small list at a time.
11:24:32 <tech2> unless I've just exposed a bug
11:24:52 <pgiarrusso> anyway, I'd try compiling the code with optimizations on (with main = mapM_ print (bigger 1), as given above)
11:25:27 <pgiarrusso> tech2: what is reachable and not reachable might depend on a lot of factors
11:25:30 <monochrom> space is difficult when there is GC. eager or lazy. for example heavy use of OOP design patterns in eager GCed OOP languages
11:26:39 <ddarius> monochrom: Indeed, I was going to add that GC is the actual source of much of the complexity, but I decided against it.
11:27:22 <tech2> how does GHC determine reachability? Or am I travelling down an unfortunate rabbit hole here?
11:27:40 <tech2> I'd prefer to be able to play around with the code rather than having to rebuild it each run
11:29:16 <ddarius> tech2: What happens if you write print (bigger 1) instead of just bigger 1?
11:29:29 <tech2> ddarius: will try, hang on.
11:29:48 <tech2> ddarius: won't I need to map it?
11:29:52 <djahandarie> mm_freak_, ping
11:29:56 <ddarius> No.
11:30:21 <tech2> ddarius: even though bigger x has no stopping condition?
11:31:30 <ddarius> It will output.
11:31:43 * hackagebot language-javascript 0.4.5 - Parser for JavaScript  http://hackage.haskell.org/package/language-javascript-0.4.5 (AlanZimmerman)
11:32:17 <tech2> ddarius: so it does, it's still attempting to devour all my memory
11:32:42 <pgiarrusso> about laziness vs space leaks, see for instance the discussion here: http://lambda-the-ultimate.org/node/2273#comment-40174
11:33:25 <pgiarrusso> The difference between laziness vs eagerness is that a thunk for a single Int value can theoretically consume (if it is still unevaluated) arbitrary amounts of memory
11:33:37 <pgiarrusso> depending on the program, that means
11:36:24 <pgiarrusso> tech2: for instance, look for foldl' here: http://en.wikibooks.org/wiki/Haskell/List_processing#foldl
11:36:43 <ddarius> pgiarrusso: So can any function in an eager language.  Usually, you don't count the cost of forcing parameters (i.e. things not controlled by the algorithm) as part of the cost of the algorithm.
11:39:38 <monochrom> most people are wrong regarding this. including that discussion. including how you look at it.
11:41:21 <Claudius1aximus> tech2: only thing i can suggest is (\y@(h:_) -> (h, length y)) -- though since it worked in constant space here before that chcange i don't know if it'll make any difference
11:41:43 * hackagebot blaze-textual 0.2.0.2 - Fast rendering of common datatypes  http://hackage.haskell.org/package/blaze-textual-0.2.0.2 (BryanOSullivan)
11:41:44 <monochrom> you look at "foldl (+) 0 blah" and see that it mallocs an arbitrary (I think you mean unknown) amount of memory for the thunk. but it is known. I know it mallocs length blah amount of memory for the thunk.
11:41:58 <ddarius> monochrom: I'm not saying that you should treat every thunk as already evaluated.  Doing so would destroy the reasoning in Okasaki's thesis.  But it certainly isn't useful to throw one's hands up and say that x+1 doesn't have any defined space/time behavior because forcing x could force arbitrary amounts of computation.
11:42:39 <ddarius> Claudius1aximus: Good job.  That is where I think the problem is.
11:43:16 <monochrom> at this point the difference between eager and lazy is that lazy has more mallocs, but how many is known, even with only local information. you give me blah, I tell you the foldl mallocs length blah
11:43:37 <pgiarrusso> monochrom: a single thunk has a fixed size, but it can reference a tree of thunks, as it happens with foldl
11:44:12 <ddarius> It is a matter of liveness not allocation.
11:44:15 <monochrom> the foldl mallocs length blah
11:45:27 <pgiarrusso> monochrome: what is blah there?
11:45:35 <monochrom> "foldl (+) 0 blah"
11:45:42 <pgiarrusso> ah I see
11:46:19 <pgiarrusso> So is it obvious to you where the leak is in the original program?
11:47:00 <monochrom> yes ddarius, the next thing to look at is where are all the deallocations, liveness. then there is no difference between lazy and eager. every advanced use of GC'ed languages suffers the same non-local liveness unknown
11:47:15 <ddarius> monochrom: Exactly.
11:47:28 <ddarius> GC is the problem, not (really) laziness.
11:47:45 <tech2> pgiarrusso: sorry, not yet. Still debating various decisions I've made since this worked (albeit in a much uglier set of code) earlier
11:47:58 <monochrom> laziness adds a couple more mallocs, that's all, and those mallocs are known at programmer time
11:48:18 <ddarius> Is programmer time like bullet time?
11:48:28 <monochrom> I don't know bullet time
11:49:11 <pgiarrusso> monochrom: can one establish memory usage of a function without knowing the consumer of the output of that function?
11:49:17 <tech2> so my problem is just working out who still references my thunks, or... whether this is a ghci bug for this earlier version
11:49:33 <ezyang> pgiarrusso: I think so. You just parametrize the behavior over all possible consumers.
11:49:37 <pgiarrusso> The claim I quoted in that discussion says "no, you can't, and that's bad"
11:50:22 <pgiarrusso> ezyang: you mean that you need to write your code so that the consumption is bounded for any consumer?
11:50:31 <monochrom> I need to know how much the consumer consumes
11:50:32 <ezyang> No, not necessarily.
11:50:48 <monochrom> I don't need to know the complete code of the consumer
11:51:09 <ezyang> If I produce an infinite list, and the consumer holds onto every element, I don't need to worry about this infinite memory usage.
11:51:10 <pgiarrusso> moreover, is there any guide on how to reason on space complexity with laziness?
11:51:12 <ezyang> ==monochrom
11:51:31 <pgiarrusso> ezyang: why?
11:51:41 <mm_freak_> djahandarie: pong
11:51:48 <pgiarrusso> because the program is gonna crash anyway?
11:52:06 <ezyang> pgiarrusso: It's the same I don't need to worry about the time usage of a a strict function, if the client is going to call it infinitely many times anyway.
11:52:24 <monochrom> pgiarrusso, is there any guide on how to reason about space in Java? if there is, I know how to modify it for ghc-generated code
11:52:26 <ezyang> pgiarrusso: I wish I could recommend you my blog posts, but they're pretty inadequate at this point in time. I'm still working on a good explanation.
11:53:03 <pgiarrusso> ezyang: but what about a program where the client is sensible, and only hangs on a finite number of elements
11:53:33 <ezyang> Sure. They'll pay for the space of those finite number of elements.
11:53:54 <monochrom> to repeat that for laziness, the "what does the consumer do" part is already solved, it's the "but whose alive" part that's the mystery
11:54:07 <insane> is it possible in HStringTemplate .st file to include template with argument which is going to be substituted? Basically I want to do something like this in st file: $template(arg=$argv$)$
11:54:37 <insane> but when I try to use this syntax I'm getting an error
11:54:55 <insane> I need a way to escape the inner '$'
11:55:45 <pgiarrusso> monochrom: do you mean "but who's alive" or sth else? In both cases, I'm not sure what you mean there indeed
11:56:14 <monochrom> if you're harping on "I build a list, I don't know how much of that list my consumer holds on indefinitely", it's the same as "I use the Observer design pattern in Java, I don't know how many observers hold on to my subject indefinitely"
11:56:40 <monochrom> yeah "who's alive", typo
11:58:05 <ezyang> I wonder if a language for specifying these properties would be useful, much the same way types are useful.
11:58:21 <ezyang> I feel like it should be, and we already have this language, it's just not shown to the user.
11:59:11 <monochrom> and I actually have seen how it is solved. I have only studied it briefly, and will have to study it deeply:
12:00:16 <pgiarrusso> monochrom: in Java I expect the subject to hold through a collection onto the list of observers
12:00:27 <monochrom> http://www.pm.inf.ethz.ch/people/kassiosi/personal  then look for the papers on "dynamic frames"
12:01:04 <ddarius> ezyang: You could specify this behavior as types, though it would probably be limiting and/or painful.
12:01:09 <ezyang> pgiarrusso: So, turns out, in Haskell, we can give you that information too. It's called 'retainers'.
12:01:15 <monochrom> many observers hold a pointer to subjects too
12:02:10 <monochrom> and I can correct mine to "I don't know how many observers hold on to my subject indefinitely, and how many subjects hold on to my observer indefinitely"
12:02:58 <pgiarrusso> Hmm...
12:03:15 <ezyang> You can't printf it, but you can compile with profiling and then have GHC tell you about it.
12:03:30 <pgiarrusso> ah ok
12:03:31 <ezyang> It's quite handy.
12:04:12 <pgiarrusso> well, I guess that at a large scale, in any language you have to use a profiler anyway
12:04:22 <augur> heyos
12:04:33 <augur> any algorithm books for functional/lazy languages?
12:04:34 <pgiarrusso> the interesting question is what happens in a small example
12:04:35 <ezyang> And GHC Haskell's profiling support is top class.
12:04:45 <pgiarrusso> ezyag
12:04:45 <ezyang> augur: Okasaki, but you already knew that.
12:04:53 <ezyang> Try also, maybe, Functional Pearls?
12:04:56 <Peaker_> I think the relation between source code and compiled code, in the face of optimizers, can be chaotic (small, incremental changes at the source can make a radically different result)
12:04:59 <augur> ezyang: ok :)
12:05:10 <Peaker_> therefore specifications about the compiled code are going to be limiting/fragile
12:05:19 <ddarius> At any rate, any complexity that is present in a lazy language is present in an eager language capable of modelling laziness, so the complexity must be somewhere else.
12:05:22 <augur> ezyang: functional data structures, you mean?
12:05:24 <monochrom> Netscape used to be the poster boy for unsolved space leaks. Netscape was written eagerly.
12:05:31 <ezyang> Peaker_: Well, you want the specification to be denotational.
12:05:49 <ddarius> monochrom: Then Mozilla took the banner?
12:05:54 <pgiarrusso> Netscape also had no GC...
12:05:56 <ezyang> aguur: Yeah, but in many ways functional algorithms are all about the data structures, since you avoid mutation.
12:05:59 <monochrom> haha yeah I guess
12:06:25 <Peaker_> ezyang: that means it's source-level, how can it model well the chaotic nature of difference between the source and compiled code, unless it just gives upper/lower bounds, but not the actual characteristics?
12:06:40 <ezyang> That's the point.
12:06:47 <pgiarrusso> anyway, I'm a Haskell learner, so I guess it's more useful to ask the following question:
12:06:48 <ddarius> pgiarrusso: Lacking GC doesn't mean that problem becomes trivial.
12:06:50 <ezyang> That's the point of types too: I don't say exactly what the inputs and outputs are, I approximate it.
12:06:56 <ezyang> This makes it useful.
12:07:01 <pgiarrusso> ddarius: no, it means that the problem becomes harder
12:07:12 <Twey> pgiarrusso: That's not a question!  :þ
12:07:13 <ddarius> pgiarrusso: No, it's more different than harder or easier.
12:07:22 <ezyang> "If I wanted the full story, I'd ask the compiler to dump the compiled STG..."
12:07:24 <ddarius> Of course, correctness becomes much harder.
12:07:35 <ddarius> ezyang: STG?  Pansy.
12:07:35 <monochrom> well, I think Netscape tried to use advanced OOP techniques. if they do that without the help of GC, all the worse, because you really don't know where to put the "free" in your code statically
12:07:36 <pgiarrusso> Twey - yeah, answered in between to ddarius
12:08:28 <monochrom> the space usage question equals the "where would you call 'free'" question.
12:08:33 <Peaker_> ezyang: well, uniqueness types are an interesting experiment in that sphere, IMO, they try to give an operational guarantee by exposing restrictions at the source-level.. I haven't used them, others that did said that they felt they were somewhat restrictive. That interesting compositions were ruled out
12:08:45 <pgiarrusso> anyway, can anyone explain why the proposed fix should solve the problem?
12:08:53 <pgiarrusso> (for the original program)
12:08:53 <ddarius> monochrom: I always just called free immediately after malloc thus avoiding the problem.
12:09:02 <monochrom> hahaha
12:09:06 <ddarius> pgiarrusso: Which proposed fix?
12:09:29 <pgiarrusso> ddarius: somebody proposed a fix to the hpaste before
12:09:44 <pgiarrusso> I am looking for it in the logs
12:09:57 <ezyang> Peaker_: I don't know very much about uniquess/linear types, but I don't think they're very similar.
12:10:06 <ddarius> I recall a change, but not one that was presented as a fix.
12:10:29 <ddarius> The change is in the area that I suspect the problem is, but I don't think the change necessarily fixes it (though it may due to vagaries of compilation.)
12:10:37 <monochrom> I don't know the original code
12:10:40 <pgiarrusso> the proposal was "(\y@(h:_) -> (h, length y))"
12:10:47 <pgiarrusso> monochrom: http://hpaste.org/49919
12:10:48 <ezyang> What I'm thinking of is so simple it probably isn't publishable.
12:11:16 <pgiarrusso> ddarius: by "_proposed_ fix" I did mean that
12:11:31 <Peaker_> ezyang: are you talking about modeling the complexity bounds? Or something more accurate?
12:11:39 <ezyang> Less accurate.
12:11:39 <pgiarrusso> that is, something that might be a fix (or not)
12:12:08 <pgiarrusso> so, I have two questions:
12:12:21 <Peaker> ezyang: I may have joined after you started explaining -- are you talking about memory or computational resources?
12:12:38 <ezyang> Consider a language with only flat data types, that is, they can contain {1,2,3} or bottom. Write a signature that says what arguments you are strict in.
12:12:48 <ezyang> Peaker: Neither. Just denotational semantics :-)
12:13:14 <ezyang> You can't write that in Haskell, and you can't ask the compiler to check if it agrees with you on your assessment.
12:13:27 <ezyang> Actually, probably most of the hair will come with getting the compiler to agree with your annotation.
12:14:04 <pgiarrusso> ezyang: are you excluding strictness annotations because they're extensions to Haskell?
12:14:12 <ezyang> Strictness annotations are different.
12:14:33 <ezyang> They cause an operational change, and are also not flexible enough in the face of compound data types.
12:14:33 <ddarius> Strictness annotations make an argument strict, they don't assert that it is.
12:14:41 <pgiarrusso> I see
12:15:09 <Peaker> ezyang: ah.. Maybe a good step along the way is to have an explicit "Suspend"/"Lazy" or "Identity"/"Eager" data constructors to facilitate laziness/strictness annotations in the types?   Then you could use ListT Eager  or  ListT Lazy  or  even a type-param specifying the laziness.. Then you could even express things such as "My result is as strict as such and such argument"
12:15:11 <pgiarrusso> ddarius: 1) I argued that reasoning about space consumption is harder and you disagreed with me; I maintain that for an equivalent program in Java, it would be clear where and if there is a space leak. Now, why is it hard to understand where is the leak here
12:15:14 <pgiarrusso> ?
12:15:46 <ezyang> pgiarrusso: Because you don't have very much experience diagnosing space leaks in lazy languages?
12:15:59 <ddarius> pgiarrusso: I explicitly did not disagree with you on 1.  Furthermore, in general your statement about Java is patently false.
12:16:19 <ezyang> Peaker: But how would you verify that the annotations are right?
12:16:31 <pgiarrusso> I'm talking about very small Java programs, comparable to the given snippet
12:16:49 <pgiarrusso> of course I don't mean 10 lines of Java
12:17:05 <pgiarrusso> but more than that
12:17:09 <Peaker> ezyang: values that aren't wrapped in Suspend/Lazy maybe can't express suspended computations?
12:17:49 <ezyang> I can pass in suspensions to a strict function. They'll just get forced.
12:18:10 <pgiarrusso> 2) with the proposed change, the first constructor of the list is forced, but still length keeps the list alive. So why should that not be a problem?
12:18:58 <ezyang> I personally find 'nextLargest' hard to understand, from a "what does this do" perspective.
12:19:25 <bgamari> What is the difference between Data.Tensor.Vertex* and Data.Tensor.Vector*
12:19:43 <pgiarrusso> ezyang: surely it's not trivial
12:21:36 <monochrom> pgiarrusso: I think you should be carefully about "equivalent java code": syntactically equivalent? behaviorially equivalent?
12:21:39 <pgiarrusso> nextLargest (x, xlen) =
12:21:40 <pgiarrusso> 	head
12:21:40 <pgiarrusso> 	. (dropWhile ((<=xlen) . snd))
12:21:40 <pgiarrusso> 	. (map ((head &&& length) . collatz))
12:21:40 <pgiarrusso> 	$ [(x + 1)..]
12:21:51 <pgiarrusso> ezyang: that might or might not help
12:21:56 <ezyang> Anyway, I'm pretty sure you want to make 'collatz' value strict.
12:22:12 <ezyang> and that will eliminate the space leak.
12:22:26 <pgiarrusso> ezyang: strict in n?
12:22:42 <ezyang> It's already strict in n.
12:22:51 <ezyang> I'm referring to the strictness of the list you're returning.
12:23:21 <monochrom> pgiarrusso: I also want to know what is the consumer of "bigger 1" or whatever is in place of "1"
12:23:58 <tech2> ezyang: the lists it returns are small though, circa a few hundred entries
12:24:15 <pgiarrusso> ezyang: how do you make it return a forced list?
12:24:34 <pgiarrusso> monochrom: the original poster had trouble running bigger on ghci's prompt
12:24:37 <ezyang> Actually, it's already value strict.
12:24:43 <pgiarrusso> here it works fine
12:24:47 <bgamari> Is there a data type in the standard library for a vector in R^3 with addition, subtraction, dot and cross products, etc?
12:24:53 <pgiarrusso> ezyang: is "value strict" an adjective?
12:24:59 <monochrom> as in "*Main> bigger 1"?
12:25:04 <pgiarrusso> monochrome: yes
12:25:25 <ezyang> yep. It means that when I force the spine, the values inside the container also become evaluated.
12:25:25 <pgiarrusso> or bigger 106239 for faster crashing
12:25:49 <tech2> monochrom: *Main> bigger 106239  \n [(106239,354),<interactive>: out of memory (requested 2097152 bytes)
12:26:27 <pgiarrusso> monochrom: for the other question, about which equivalence, the best description of what I mean would be "implement the same algorithm in Java"
12:27:16 <pgiarrusso> But actually, what I can say is that if you implement that code in a Java-idiomatic way, the space consumption is going to be simple to understand
12:27:23 <pgiarrusso> at least, that's my guess
12:27:41 <monochrom> "same algorithm" is subjective afaik. there have been eternal debates on what "eratosthenes sieve" should "do" and "not do"
12:28:00 <tech2> pgiarrusso: if I implement in a java/python idiomatic way I'd use stored-state to track the largest value seen and this would be a whole lot easier for me to understand.
12:28:07 <ddarius> pgiarrusso: You realize this code produces an infinite persistent list of values, and I don't believe Java has a ready-made way of handling it.
12:28:35 <ddarius> tech2: That would be producing a rather different result, though maybe not for your overall goal.
12:29:10 <monochrom> there are even small debates on whether a well-known piece of haskell code is "quicksort" or "not"
12:29:14 <ddarius> At any rate, it looks like the dropWhile will force all the second elements which will cause length to bring y into memory fully while the first element will hold on to all of y.
12:29:40 <tech2> ugh, I wondered if it was dropwhile... why does it do that?
12:29:53 <pgiarrusso> ddarius: thanks, I see why that matters
12:30:03 <ddarius> The problem isn't that dropWhile is broken.  It does that because that's what you are telling it to do.
12:30:26 <pgiarrusso> ddarius: In Java what you implement is not bigger, but \m -> (!! m) . bigger
12:30:28 <ddarius> The issue is probably that you want head evaluated before length so that you don't hold on to y once length is calculated.
12:30:51 <ezyang> Shouldn't the selector thunk optimization fix this?
12:31:08 <ddarius> ezyang: People are saying that it works when compiled.
12:31:40 <tech2> ddarius: for each value dropwhile retrieves from list xs, if x doesn't meet the condition, do not append it to the result, otherwise yield the remainder of the list, now, since I can't interact with those items dropped, I don't see how or why they'd be held, and since I'm only lazily fetching the head of the result, why is it evaluating anything more than that?
12:31:43 * hackagebot blaze-textual 0.2.0.3 - Fast rendering of common datatypes  http://hackage.haskell.org/package/blaze-textual-0.2.0.3 (BryanOSullivan)
12:32:02 <tech2> ddarius: or have I missed something?
12:32:45 <ezyang> Oh. GHC is CAF'ing the sucker. Ooops.
12:33:24 * tech2 stares blankly
12:33:27 <ddarius> tech2: In the output you provided, you weren't getting a second list element at all, so it's not getting to the (end of) head.
12:33:27 <erus`> i have been coding a hobby project for 8 solid hours...
12:33:36 <erus`> on a Saturday...
12:34:16 <erus`> re doing stuff i have allready written in haskell...
12:34:17 <ddarius> erus`: Weekends are typically when people do hobby activities.
12:34:26 <tech2> I know there are more results though, and even if there aren't since dropwhile is dropping non-matching values, why am I holding on to _any_ state other than the current list element generated tuple?
12:36:20 <tech2> I can imagine this running for a very long time and I have no problem with that, what I can't work out is why this is anything other than sized to the size of the current largest collatz list?
12:36:24 <ezyang> More broadly speaking, the way this code is implemented is stupid.
12:36:28 <roconnor> is there a matrix library I should use, or should I just use Data.Array?
12:36:40 <tech2> ezyang: yes, thank you, I'm new here :)
12:36:45 * hackagebot wedding-announcement 1.0 - a wedding announcement  http://hackage.haskell.org/package/wedding-announcement-1.0 (PetrRockai)
12:36:47 * hackagebot aeson 0.3.2.10 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.3.2.10 (BryanOSullivan)
12:36:49 * hackagebot wedding-announcement 1.1 - a wedding announcement  http://hackage.haskell.org/package/wedding-announcement-1.1 (PetrRockai)
12:36:59 <ezyang> Sorry
12:37:01 <tech2> ezyang: I'd like to learn a better way but it's not easy :)
12:37:12 <erus`> ddarius: 415 lines of code 16 lines of comments
12:37:22 <tech2> ezyang: no problem, I feel the same way about some people's code in Python
12:37:30 <Claudius1aximus> tech2: hey, are you on 32bit?
12:37:34 <erus`> > (show $ 415 / 8) ++ " lines of code an hour"
12:37:36 <lambdabot>   "51.875 lines of code an hour"
12:37:36 <tech2> lol
12:37:40 <tech2> Claudius1aximus: yes
12:37:45 <ezyang> Essentially, you don't actually want to compute [Int] for Collatz.
12:37:50 <tech2> well, perhaps
12:37:53 <Claudius1aximus> tech2: overflowing Int -> negative values?
12:38:26 <tech2> ezyang: what do I want to compute then?
12:38:26 <Claudius1aximus> tech2: try import Data.List (genericLength) and s/Int/Integer/ and s/length/genericLength/
12:38:43 <ezyang> The length of a collatz sequence.
12:38:44 <Claudius1aximus> tech2: just noticed i get memory asplosion with s/Int/Word16/
12:38:59 <ezyang> I think your style can be made to work correctly, but you'll need to make it fuse properly.
12:39:05 <ezyang> *efficiently
12:39:07 <Claudius1aximus> tech2: when Int works fine (but i'm on 64bit)
12:39:25 <ddarius> tech2: Yes, the dropWhile should be forgetting the elements as it goes along.
12:39:40 <ddarius> tech2: But, as it seems is the case, the problem is that some of the lists are (incorrectly) very long.
12:40:39 <ddarius> tech2: However, if the head was evaluated first, then length could discard the elements as it goes along and thus, even with very long lists, it should be able to run in constant memory (modulo the size of the numbers.)
12:40:44 <augur> does anyone know of a parsing technique thats sort of like a mix between a typical backtracking top-down left-to-right parser and an unger parser?
12:41:08 * erus` googles unger parser
12:41:42 <pgiarrusso> ddarius: however the length of the single lists generated by collatz is at most ~500 in the observed instances
12:41:48 <augur> where instead of matching left at every step, you optimize it by looking for terminals that can cut the parsing problem down somewhat?
12:41:52 <tech2> brb, I think the elderflower champagne may have just exploded :/
12:42:00 <augur> eliminating part of the search space?
12:42:05 <pgiarrusso> ddarius: I've observed top 528
12:42:25 <pgiarrusso> and the maximal length is what this code is trying to compute
12:42:39 <ddarius> pgiarrusso: Yes, but I'm pretty sure the second element should return quickly with very little memory even if absolutely nothing was garbage collected, so it's sounding like the problem is a bug.
12:42:45 <Claudius1aximus> tech2: with Int32 i get errors exactly at the same point as you (when adding another guard to collatz:   | n<=0 = error "ouch" )
12:42:47 <ddarius> pgiarrusso: Do you get the bad performance behavior?
12:43:11 <pgiarrusso> ddarius: doesn't happen here with GHC 7.0.3, happens there with GHC 6.12.3
12:43:23 <ddarius> pgiarrusso: The question is 32 v. 64 bit.
12:43:24 <Claudius1aximus> pgiarrusso: that's not important, what is important is 64bit vs 32bit
12:43:44 <pgiarrusso> 64bit CPU here, I'm checking the Haskell platform I have
12:43:44 <ddarius> pgiarrusso: The change Claudius1aximus and I suggested would make it run in (roughly) constant space even in the buggy case very likely.
12:44:32 <ddarius> pgiarrusso: Go into you 6.12.3 GHCi and type maxBound :: Int.
12:45:09 <pgiarrusso> I have 9223372036854775807 (from GHCi 7.0.3, it's tech2 with 6.12.3)
12:45:52 <ddarius> pgiarrusso: Oh, I misread what you said earlier.  I thought you had said "it happens here with GHC 6.12.3" as in you had both installed.
12:45:57 <tech2> ddarius: yeah, 2GB for me
12:46:05 <tech2> erm
12:46:08 <tech2> 2 billion
12:47:38 <ddarius> tech2: I suspect if you make the change suggested by Claudius1aximus, i.e. pattern matching y rather than using head y, it will still take a long time but it won't run out of memory.
12:50:18 <lpsmith> heh,  I just found another advantage to Aeson's choice to have seperate ToJSON and FromJSON classes
12:50:48 <ddarius> You can FromJSON functions even though you can't ToJSON them?
12:50:51 <tech2> ddarius: I'm still new to the terminology here. How do I apply pattern matching on y rather than head y, given where the head is?
12:51:15 * ezyang goes off and implements the stream fusion version of Collatz 
12:51:20 <lpsmith> I was able to declare an instance for (FromJSON  (IO MyType))  to initialize some MVars,  instead of using unsafePerformIO
12:51:22 <ddarius> Quoting Claudius1aximus again: [15:04] <Claudius1aximus> tech2: only thing i can suggest is (\y@(h:_) -> (h, length y)) -- though since it worked in constant space here before that chcange i don't know if it'll make any difference
12:51:39 <tech2> ah, that, thanks
12:52:13 <tech2> ezyang: now _that_ sounds like an impressive title
12:52:51 <pgiarrusso> Claudius1aximus: I implemented the changes you described here, but I got an underflow
12:53:01 <pgiarrusso> [(106239,354),*** Exception: ouch
12:53:06 <lpsmith> one unsafePerformIO eliminated,  one to go.
12:53:33 <ezyang> pgiarrusso: Well, maybe it did underflow?
12:54:34 <pgiarrusso> ezyang: I'm sure so, but either he got sth different, or I misunderstood what he wrote
12:54:50 <pgiarrusso> (namely: "I get an error in the same place as you")
12:55:24 <Claudius1aximus> > (maxBound :: Int) * 3 + 1
12:55:25 <lambdabot>   9223372036854775806
12:56:00 <pgiarrusso> Claudius1aximus: did you get an underflow too, or a space leak?
12:56:02 <ddarius> > maxBound :: Int * 2
12:56:03 <lambdabot>   <no location info>: parse error on input `*'
12:56:09 <ddarius> > (maxBound :: Int) * 2
12:56:10 <lambdabot>   -2
12:56:27 <hpaste> “Paolo G. Giarrusso” pasted “Out of memory - Int32 version” at http://hpaste.org/49926
12:56:43 <Claudius1aximus> pgiarrusso: i got the space leak, caused by underflow
12:56:49 <Claudius1aximus> pgiarrusso: or something
12:56:51 <ddarius> I'm pretty sure he didn't put in that extra guard.
12:56:57 <Claudius1aximus> or made noticable by underflow
12:57:01 <hvr> what is http://hackage.haskell.org/package/wedding-announcement-1.1 supposed to be?
12:57:27 <pgiarrusso> ddarius: I read the guard from here: "Claudius1aximus: tech2: with Int32 i get errors exactly at the same point as you (when adding another guard to collatz:  | n<=0 = error "ouch" )"
12:58:27 <pgiarrusso> anyway, everything seems clear now
12:58:54 <pgiarrusso> if the underflow is not caught, collatz might run for a long, long time
12:58:58 <ddarius> hvr: Looks to be a wedding announcement.
12:59:10 <tech2> pgiarrusso: my guard was OOM :) I only added the guard post-Claudius mention.
12:59:21 <hvr> ddarius: so it's a joke package? ;-)
12:59:49 <tech2> thank you all though, will have to re-tool for Integral I guess
13:00:01 <ddarius> hvr: I wouldn't say a "joke" but it doesn't seem to be a package intended for use.
13:00:15 <ddarius> tech2: Just use Integer instead of Int.
13:00:22 <ezyang> Does anyone know how map (\y -> (y,y)) interacts with stream fusion?
13:00:47 <ddarius> ezyang: I wouldn't expect the function in the map affects the fusibility of map.
13:01:08 <ddarius> ezyang: Of course, later if you unzip or something, that may cause difficulties.
13:02:35 <tech2> ddarius: done, thanks, was just making the change when you mentioned.
13:02:43 <tech2> bbl all, thanks for the assistance and understanding
13:02:48 * ddarius considers not being lazy, but if he's going to not be lazy then he should be responsible.
13:03:31 <pgiarrusso> tech2: did I mention supercompilation in relation to your code?
13:04:34 <hvr> what's the recommended version constraint on `base` these days? ==4.*, >=4 && <5, or >=4.0 && <4.5 ?
13:04:48 <pgiarrusso> tech2: ddarius earlier explained that your code is not the most efficient because you have length . collatz (in disguise) instead of having a function returning the length of the collatz sequence
13:05:02 <ddarius> pgiarrusso: ezyang said that
13:05:11 <pgiarrusso> ddarius: sorry
13:05:14 <pgiarrusso> anwyay
13:05:24 <pgiarrusso> *anyway
13:05:32 <pgiarrusso> tech2: the aim of supercompilation is to allow that code to be optimized and run efficiently
13:05:39 <roconnor> crap I have too many definitions of <*>
13:06:29 <pgiarrusso> the introduction of recent papers on supercompilation in haskell (e.g. Rethinking Supercompilation) is readable and explains the goal
13:06:59 <ddarius> roconnor: How many do you need?
13:07:22 <dylukes> http://upload.wikimedia.org/wikipedia/commons/a/af/Collatz-graph-20-iterations.svg
13:07:25 <dylukes> I love this chart :D
13:07:39 <johnlabea> good evening. i'm a haskell novice, using quick check (because that's what all the tutorials say to use). how do i run my tests in a makefile instead of in ghci? i found a script in the manual, but it uses hugs and i'm using ghci
13:07:53 <roconnor> ddarius: The <*> from applicative, and I have defined my own semiring multiplication.
13:07:54 <johnlabea> i want to do "make check" and run all my tests
13:08:00 <dylukes> byorgey: Is diagrams sufficiently "ready" to allow me to try to make this chart myself?
13:14:03 <hpaste> ezyang pasted “Stream fused collatz” at http://hpaste.org/49927
13:15:00 <roconnor> @src unwords
13:15:00 <ezyang> You know, I always thought 'print' was lazy in it's argument. But this doesn't seem to be the case / my output buffering was wonky
13:15:00 <lambdabot> unwords [] = ""
13:15:01 <lambdabot> unwords ws = foldr1 (\w s -> w ++ ' ':s) ws
13:15:22 <ezyang> Note that this implementation doesn't bother allocating the Collatz list.
13:16:43 <ezyang> (pinging tech2 and pgiarrusso, if you're interested ^^)
13:18:57 <ddarius> ezyang: print will attempt to output a "block" at a time depending on buffering.  If the calculation is slower than the output, I think you will see a "chunky" behavior in some cases.
13:20:10 * ezyang <3 stream fusion 
13:20:18 <pgiarrusso> ezyang: I see that to allow stream fusion you want to use unfoldr rather than direct recursion
13:20:50 <ezyang> Right. Otherwise you don't have a good producer.
13:21:02 <ezyang> It's super straightforward in this case, fortunately :-)
13:21:37 <ezyang> 'nextLargest' also gets fused.
13:21:52 <johnlabea> does anyone know the best way to run quick check on all my modules for use in a makefile?
13:21:52 <pgiarrusso> but why did you change dropWhile?
13:22:20 <ezyang> because if you're only using 'head' afterwards, it's the same as find.
13:22:33 <ezyang> Actually, you could probably use a mapAccum
13:22:45 <ezyang> erm, no, not a mapAccum
13:22:47 <pgiarrusso> johnlabea: ghc -e 'expr' evaluates the expression
13:23:29 <pgiarrusso> I guess you can have imports on ghc command line, import your code and make ghc call a hook function you provide
13:23:30 <johnlabea> thanks
13:23:34 <pgiarrusso> not sure it's the best way
13:23:56 <johnlabea> isn't quick check the standard way to do unit testing? what does everyone else do to test all the code in a quick step?
13:24:26 <ezyang> I can probably also eliminate the allocation in the imperative loop by using a stream fold.
13:25:20 <pgiarrusso> johnlabea: ghc ~/tmp/test.hs -e 'nextLargest (1, 1)'
13:25:35 <pgiarrusso> nextLargest is a function defined there
13:26:04 <pgiarrusso> yeah, QuickCheck is quite standard, there should be a standard test harness
13:26:17 <pgiarrusso> I'd google for it, but you did already surely
13:26:43 * hackagebot mongrel2-handler 0.3.2 - Mongrel2 Handler Library  http://hackage.haskell.org/package/mongrel2-handler-0.3.2 (BardurArantsson)
13:27:33 <ezyang> Hmm, are there algorithms for automatically determine what kind of recursion is being used by directly recursive code?
13:28:06 <pgiarrusso> johnlabea: I found this package: http://batterseapower.github.com/test-framework/
13:28:32 <pgiarrusso> it's by Max Bolingbroke, an energic Haskell hacker
13:28:41 <pgiarrusso> *energetic
13:29:43 <DevHC_> is there any way to create a string which contains teh contents of a file which is only opened when the string is evaluated, other than via unsafePerformIO?
13:31:00 <kmc> unsafeInterleaveIO will do it
13:32:50 <roconnor> @hoogle (a -> [a] -> Bool)
13:32:51 <lambdabot> Prelude elem :: Eq a => a -> [a] -> Bool
13:32:51 <lambdabot> Prelude notElem :: Eq a => a -> [a] -> Bool
13:32:51 <lambdabot> Data.List elem :: Eq a => a -> [a] -> Bool
13:37:38 <DevHC_> gwd
13:45:51 <pgiarrusso> @unmtl StateT s Maybe a
13:45:52 <lambdabot> s -> Maybe (a, s)
13:46:06 <pgiarrusso> @unmtl MaybeT (State s) a
13:46:06 <lambdabot> s -> (Maybe a, s)
13:54:34 <roconnor> How do live without algebraic data types in C?  How would I make a type of regular expressions?
13:55:32 <benmachine> typedef a struct?
13:56:42 <mauke> or a union
13:56:51 <roconnor> with an int field denoting the type of node in the AST of Regular expressions (ie or, seq, or star, etc?)
13:57:33 <mauke> union { struct X x; struct Y y; struct Z z; } typedef Regex_t;
13:58:07 <mauke> struct X { enum NodeType t; ... }; struct Y { enum NodeType t; ... }; struct Z { enum NodeType t; ... };
13:58:08 <roconnor> mauke: don't you need a tag field too to know which union view to access?
13:58:18 <roconnor> oh I see
13:58:18 <dylukes> This is what's called a "variant record".
13:58:21 <dylukes> It's a pretty common C pattern.
13:58:28 <dylukes> Also known as a tagged union.
13:58:39 <dylukes> There are some heinous GCC extension tricks you can do to make them more pleasant too.
13:58:40 <roconnor> dylukes: like how mauke writes it, with the enum NodeType in each struct?
13:58:51 <roconnor> maybe it has to be that way
13:58:56 <tonkman> is it possible to write some kind of type to represent parametric equations
13:58:58 <mauke> you could also use a struct
13:59:03 <tonkman> like 2a+5b
13:59:06 <dylukes> there are a few neat tricks, for instance,
13:59:09 <mauke> struct { tag; union { X, Y, Z } }
13:59:11 <dylukes> say you want to have a closed object system
13:59:17 <dylukes> and you define a bunch of object structure types
13:59:17 <roconnor> tonkman: it is possible, but a bit tricky
13:59:22 <dylukes> and typedef pointer types to them
13:59:31 <dylukes> now, you want a "general" type that can refer to all of them
13:59:35 <roconnor> mauke: okay, that is how I'd be inclined to do it I think.
13:59:36 <dylukes> you can accomplish it by doing
13:59:39 <tonkman> roconnor: can you give few pointers
13:59:44 <mauke> roconnor: I mean struct { tag; union { X, Y, Z } foo; }
14:00:00 <dylukes> union{ mystringp x; mynumberp y; …} __attribute__((transparent_union))
14:00:06 <mauke> roconnor: the "problem" is that now you have to add .foo to every access
14:00:07 <dylukes> er, add on typedef and myobjectp
14:00:14 <azaq23> The first entry in a struct is guaranteered to be at the start of the memory block of some struct, and because you've got a union, you'll be able to access enum NodeType t from the union safely with a cast
14:00:16 <tech2> ezyang: why Maybe? If an error is returned then it's an error, Maybe/Just makes little difference doesn't it?
14:00:20 <dylukes> mauke: I'd suggest looking at C1X generics.
14:00:31 <shachaf> mauke: Why would you do it the other way (putting a tag in each struct separately)? It seems much more prone to error.
14:00:41 <tonkman> I thought that it would be cool to have parametric vectors
14:00:43 <ezyang> tech2: Are you referring to step or find?
14:00:44 <benmachine> tonkman: what kind of equations do you want to support? what kind of operations?
14:00:44 <mauke> shachaf: the "problem" is that now you have to add .foo to every access
14:00:58 <tech2> ezyang: step
14:00:58 <roconnor> mauke: interesting
14:01:00 <shachaf> True, I guess.
14:01:16 <ezyang> It's not an error, it's saying "I'm done, stop constructing this list"
14:01:18 <mauke> shachaf: if you denormalize the definition, you get slightly nicer access code
14:01:19 <dylukes> mauke: Could you paste an example of what isn't working, but you wish was?
14:01:31 <mauke> dylukes: huh?
14:01:36 <dylukes> er,
14:01:38 <tonkman> benmachine: multiplication, addition, etc. Nothing special
14:01:43 <dylukes> paste what isn't working or what you don't like
14:01:46 <dylukes> I'd like to try to play with it.
14:01:59 <tech2> ezyang: ah, sorry, missed the Nothing, was looking more at the "error"
14:02:23 <benmachine> tonkman: so polynomials in however many variables?
14:02:25 <mauke> roconnor: there's a common C extension where you can put an unnamed union in a struct and it'll "inline" the members
14:02:28 <shachaf> dylukes: transparent_union looks like an evil extension.
14:02:40 <dylukes> shachaf: It is an evil extension, but one very often used.
14:02:42 <ezyang> Right, the error is a legit error ase, and I really want the entire program to halt in that case.
14:02:51 <dylukes> It's not an uncommon one, I mean.
14:02:54 <tonkman> benmachine: yes
14:02:59 <tech2> ezyang: I was coming back to my machine to write something similar. I guess my method would just have involved checking against 1 in more than one place
14:03:03 <dylukes> All it does it allow implicit casts in function parameters between a union and the types that make it up.
14:03:04 <mauke> i.e. you write struct { Tag t; union { X x; Y y; } }; and you get a struct with three members (.t, .x, .y), but two of them overlap
14:03:30 <roconnor> would the C++ solution be to make an class type for each type of node of a Regular Expression and have them all implements some sort of RegularExpression interface?
14:03:30 <dylukes> You can use anonymous unions to implement fun vectors with multiple access schemes!
14:03:39 <benmachine> tonkman: you can view polynomials as lists of coefficients
14:03:45 <benmachine> so x^2 + 2x + 1 would be [1,2,1]
14:03:51 <mauke> roconnor: hahaha, "interface"
14:03:51 <tonkman> so i can represent line like r = 2i + 4j
14:03:58 <mauke> (no)
14:04:04 <dylukes> roconnor: C++ doesn't have interfaces, you'd have to use a pure virtual.
14:04:17 <dylukes> (virtual constructor/destructor)
14:04:24 <benmachine> then you can represent polynomials in n variables as polynomials whose coefficients are polynomials in n-1 dimensions
14:04:32 <benmachine> quite an awkward way to do it though :P
14:06:15 <Peaker> mauke: why not "interface"? A class full of pure virtual methods is a representation of an interface, isn't it? (Albeit a somewhat restricted/limited one)
14:06:29 <mauke> roconnor: http://www.boost.org/doc/libs/1_47_0/doc/html/variant.html :-)
14:07:03 <Peaker> roconnor: btw: I find that C does relatively OK with ADT's in their catamorphism representation.. certainly safer than enum tag+union of constructors+structs of fields
14:07:37 <roconnor> Peaker: catamorphism representation, as in a higher order function?
14:07:43 <Peaker> roconnor: yeah
14:08:06 <roconnor> I find that a bit difficult to believe.
14:08:22 <Peaker> roconnor:   void maybe_int(void *arg, void (*handle_nothing)(void *), void (*handle_just)(void *, int));
14:08:43 <Peaker> roconnor: it's much nicer and safer than the alternative of enum tags and unions/etc
14:09:02 <Peaker> roconnor: any function that wants to return a Maybe Int, can just take these 3 params (useful to put in a struct once)
14:09:02 <roconnor> oh I see
14:09:16 <MHD> What is C++'s model for finalization linked to lexical scope called? There was this term...
14:09:25 <mauke> MHD: RAII
14:09:37 <mauke> it works much better in Perl, though
14:09:41 <MHD> No, a more general CS-esque thing
14:09:43 <ben> does it
14:10:12 <pgiarrusso> MHD: for C++ you say destructors rather than finalizers
14:10:16 <MHD> When you have variables and references and don't need GC because memory is being statically collected through finalizers
14:10:19 <mauke> yeah, because in Perl you can do: { my $guard = end { abitrary(); code() }; ... }
14:10:23 <MHD> It's a general concepts
14:10:30 <MHD> Not peculiar to C++
14:10:31 <mauke> without writing a separate class/destructor for each kind of resource
14:10:45 <MHD> Described sometime long ago, 60's or 70's
14:10:52 <pgiarrusso> not sure what you refer to, but finalizers and destructors are really separate beasts
14:10:59 <mauke> MHD: region something?
14:11:04 <MHD> YES!
14:11:09 <Peaker> mauke: part of the niceness of RAII is its ingraining in the libs/culture, and the strong convention..  RAII is also automatically recursive.. If my class has a member of another class, my destructor automatically calls his, etc.
14:11:10 <MHD> region something
14:11:28 <pgiarrusso> MHD: regions were discussed today already, and IIRC with you
14:11:44 <Peaker> (and of course, that it also manages the memory resources involved, whereas in Perl you manage just the "external" resources)
14:11:45 <MHD> Yes, but I am tired and hopped up on caffeine
14:11:53 <MHD> Thus my memory fails
14:11:58 <MHD> Please bear with me
14:12:06 <pgiarrusso> Ah I see, my apologies
14:12:16 <mauke> Peaker: not strictly true; perl doesn't have a real GC so you get to manage cycles yourself
14:12:19 <mauke> sadly
14:12:31 <Peaker> mauke: heh
14:12:32 <johnlabea> when you use guards, dose where apply to all guards, or just the one that you do where after?
14:12:44 <tech2> mauke: perl doesn't clean up cycles? :/
14:12:47 <mauke> well, that's not strictly true either; perl does have a GC, it just doesn't run it until thread shutdown
14:13:01 <pgiarrusso> mauke: in Python they introduced a cycle collector in addition to refcounting, did they not do it in Perl?
14:13:30 <pgiarrusso> mauke: what's the point of that GC then? Invoking finalizers to flush buffers for open files?
14:13:31 <benmachine> johnlabea: 'where' attaches to function clauses
14:13:39 <johnlabea> thanks
14:13:44 <benmachine> johnlabea: so you'll have foo x | thing | otherthing where bar
14:13:57 <benmachine> and bar will work over all the guards and their right-hand sides
14:14:20 <mauke> pgiarrusso: huh?
14:15:05 <roconnor> @type lookup
14:15:06 <lambdabot> forall a b. (Eq a) => a -> [(a, b)] -> Maybe b
14:15:18 <pgiarrusso> Forget what I said - why does the GC run after thread shutdown?
14:15:25 <MHD> There was a problem with my region-based eureka
14:15:27 <pgiarrusso> At that point the program is ending anyway, doesn't it?
14:15:35 <mauke> pgiarrusso: not if you have more than one thread
14:15:38 <sebz> I'm getting "ld: library not found for -lcrt1.10.6.o" on Lion… can someone help?
14:16:03 <danharaj> do you guys like `f . g $ x` or (f . g) x more?
14:16:04 <mauke> pgiarrusso: but it's running so your objects with non-trivial destructors get a chance to do some cleanup
14:16:19 <pgiarrusso> mauke: I see
14:16:19 <Peaker> danharaj: the former, more easily mechanically-refactored
14:16:44 <pgiarrusso> mauke: my example with files was the typical one where you want a non-trivial finalizer to be called
14:16:47 <Peaker> danharaj: though I'd use  f $ g x   there just to save some, sometimes (I don't think I'm always consistent w.r.t that)
14:17:05 <pgiarrusso> i.e., the finalizer of a file object open for writing would call flush
14:17:09 <pgiarrusso> (that's for Python)
14:17:28 <mauke> pgiarrusso: filehandles are both built in and older than objects, so that automatically happens
14:17:31 <mauke> just like C, basically
14:17:38 <tech2> @hoogle genericLength
14:17:38 <lambdabot> Data.List genericLength :: Num i => [b] -> i
14:18:06 <pgiarrusso> In C if you don't call fclose() I don't think you have any guarantee
14:18:38 <mauke> you do, because exiting the program closes all open streams
14:18:38 <pgiarrusso> if you use raw fd's instead, the OS calls close() for you, but that works because you have then no buffering in the application
14:18:56 <mauke> exceptions: killed by signal, calling _exit directly
14:19:56 <mauke> pgiarrusso: int main(void) { printf("Hello, world!\n"); fflush(stdout); return 0; }  // do you think that is really necessary?
14:19:59 <mauke> (it's not)
14:20:12 <pgiarrusso> stdout is line-buffered anyway
14:20:46 <mauke> you don't know that
14:20:52 <mauke> and it often isn't
14:21:21 <pgiarrusso> If you have printf() and then scanf(), you require a certain ordering
14:21:40 <mauke> true but irrelevant
14:21:48 <mauke> also using scanf for user input is a bug in itself
14:22:04 <pgiarrusso> ?
14:22:46 <mauke> as a user I strongly expect line-based interaction (or key interactive)
14:23:01 <mauke> scanf shits all over that
14:23:12 <pgiarrusso> Ah I see
14:23:15 <tech2> ezyang: unfortunately your collatz defn is wrong, collatz 1 == [1] not []\
14:23:48 <pgiarrusso> mauke: you're right, but scanf is the best in the C standard library
14:23:57 <mauke> best what?
14:24:01 <pgiarrusso> everything "right" is out-of-that
14:24:15 <mauke> ?
14:24:18 <tech2> ezyang: any idea how I can fix that since I still need to yield Nothing at some stage?
14:24:23 <Peaker> roconnor: I'm curious whether the catamorphism approach works for others, so tell me if you use it/if it worked for you :)   I've not done any recursive ADT's with the catamorphism approach, not sure if it works well in C
14:25:14 <ezyang> Hmm, you could try a sentinel value which then terminates.
14:25:33 <ezyang> like, step 1 = Just (1, -1); step -1 = Nothing
14:25:48 <pgiarrusso> mauke: line-based interaction is possible in C, but character-based interaction is not
14:26:00 <mauke> well, yes
14:26:08 <tech2> ezyang: feels a bit ugly, but maybe that's just other languages using me as a spokespuppet :)
14:26:26 <ezyang> It is ugly!
14:26:42 <mauke> pgiarrusso: this is all somewhat besides the point. stdout is either line buffered (if it's a terminal) or block buffered (otherwise)
14:27:03 <mauke> and calling exit() closes (+ implicitly flushes) all open streams
14:27:26 <tech2> ezyang: the solution you posted, is this the way you'd solve the problem, or is it just trying to best fit with what I had to start with?
14:27:36 <pgiarrusso> OK, my point was that stdout wasn't a good example
14:28:08 <pgiarrusso> about exit, I stand corrected (but I'll check it up)
14:28:08 <ezyang> It's a reasonably general way. The stream fusion means your code still gets to be nice, in that you can get a list of collatz numbers if you really want to (even though the specific use-case doesn't need it.)
14:28:36 <pgiarrusso> pgiarrusso: ok, man exit agrees with you, apologies
14:29:04 <pgiarrusso> anyway, that doesn't extend to e.g. most scripting languages
14:29:16 <mauke> pgiarrusso: [citation needed]
14:29:34 <mauke> pgiarrusso: it's 7.20.4.3/4 in C99, btw :-)
14:29:39 <tomh-> which one is the tail recursive fold again?
14:29:51 <mauke> tomh-: foldl
14:29:54 <pgiarrusso> mauke: the example I'm actually familiar with is given by most Python implementations (except CPython)
14:30:02 <tomh-> just foldl? not foldl' or so?
14:30:09 <mauke> tomh-: they're both tail recursive
14:30:14 <tomh-> ok
14:30:27 <tech2> ezyang: thanks
14:30:31 <pgiarrusso> tomh-: though usually foldl itself is not recommended for other reasons
14:30:42 <ezyang> arguably unfold should allow you to specify an arbitrary ending sequence.
14:30:54 <ezyang> Note that concat fuses fine, so maybe that's the right way.
14:31:41 <tomh-> pgiarrusso: what reasons might that be?
14:32:07 <danharaj> It's not strict.
14:32:09 <Saizan> ezyang: apo rather than ana
14:32:16 <mauke> tomh-: tail recursion can lead to stack overflows
14:32:18 <pgiarrusso> http://en.wikibooks.org/wiki/Haskell/List_processing#foldl
14:32:42 <pgiarrusso> mauke: doesn't usually tail-recursion prevent stack overflows?
14:32:55 <pgiarrusso> foldl can cause them
14:33:01 <pgiarrusso> but only because it's too lazy
14:33:14 <mauke> pgiarrusso: not with laziness
14:33:39 <danharaj> foldr is lazy but it won't cause a stack overflow in some cases where foldl will.
14:34:00 <tomh-> if it is tail recursive it shouldn't cause a stack overflow right?
14:34:22 <pgiarrusso> mauke: can foldl' cause stack overflows?
14:34:44 <mauke> tomh-: wrong
14:34:52 <tomh-> mauke: how so?
14:35:05 <tomh-> due to laziness?
14:35:16 <danharaj> In Haskell the stack works differently from other languages. It's not the same thing.
14:35:21 <mauke> tomh-: because it can efficiently construct a huge lazy expression
14:35:26 <tomh-> ah ok
14:35:36 <mauke> tomh-: and then when you actually need to evaluate it, it runs out of stack
14:35:56 <mauke> I don't know if the stack is even used for normal function calls
14:36:00 <Saizan> assuming that huge lazy expression is made of calls to functions that are suitably strict
14:36:01 <pgiarrusso> mauke: but isn't foldl' going to prevent that problem? at least, so I heard?
14:36:23 <mauke> pgiarrusso: yes, but I'm not clear on the exact details
14:36:50 <mauke> I always let Cale explain that part :-)
14:36:54 <Saizan> pgiarrusso: you've to use foldl' wisely, since it'll force only the outermost constructor of the accumulator
14:37:26 <MHD> If a typing system is so strong as to being able to identify potentially recursive datastructures and at compilation time generate methods for self inspecting, can I do reference counting with okay performance?
14:37:35 <ddarius> mauke: As I think I finally convinced Cale the other day, tail call optimization is just as necessary in a lazy language like Haskell as it is in an eager language like Scheme.
14:38:20 <mercury^> MHD: ? ^_^
14:38:48 <MHD> mercury^: Looking at GC methods for LLVM which doesn't support GC in multi threaded environments.
14:40:45 <danharaj> ugh, I wish ghci said what happened when it crashes :\
14:43:38 <tech2> danharaj: it's normally relatively descriptive unless it's an OOM issue, cryptic, but descriptive.
14:44:58 <danharaj> tech2: "ghc.exe has stopped working" is not descriptive :p
14:45:36 <danharaj> It doesn't happen when the program is compiled either.
14:46:17 <tech2> danharaj: ouch :(
14:46:48 <danharaj> It's to be expected when I'm using OpenGL and also have this mangled abomination I call a wrapper around a C library that uses finalizer hackery.
14:48:09 <pgiarrusso> I am finally back
14:48:11 <pgiarrusso> Saizan: so you need to pass to foldl' a strict function for it to work, right?
14:48:20 <Peaker> About TCO: When you use sequence on strict monads (e.g: IO), it's non-tail-recursive definition can get you a stack overflow...
14:48:23 <pgiarrusso> (you had just said that foldl' must be used wisely)
14:49:18 <Peaker> whereas a custom tail-recursive sequence works.. I remember hitting this problem in my parallel quicksort reply to the jdh-troll
14:50:13 <Peaker> I am guessing that at least in some special cases (e.g: a single recursive call), it should be possible to mechanically convert the recursion to a co-recursion that is tail-recursive?
14:52:08 <Saizan> pgiarrusso: for example when your accumulator is a pair type you've to do something like foldl' (\(a,b) x -> a `seq` b `seq` (..,..)) .. ..; otherwise thunks can accumulate in the fields of the tuple
14:52:42 <roconnor> @type min
14:52:43 <lambdabot> forall a. (Ord a) => a -> a -> a
14:52:51 <danharaj> 'twould be nice if there were a strict tuple type
14:52:55 <pgiarrusso> Saizan: I see, thanks
14:52:57 <danharaj> maybe (! !) brackets? :p
14:53:04 <danharaj> angry bananas
14:53:11 <pgiarrusso> I think unboxes tuples exist
14:53:17 <Saizan> there are some on hackage
14:53:29 <danharaj> Saizan: TH'd?
14:53:53 <Saizan> danharaj: don't think so
14:55:06 <ddarius> pgiarrusso: Unboxed tuples are different from strict tuples.
14:55:18 * applicative want tuples that are strict, except in the third position.
14:55:23 <pgiarrusso> ddarius: yeah, I realized
14:55:40 <Peaker> maybe foldl' variant that uses deepseq?
14:55:46 <Peaker> That may be too big of a hammer.. I guess
14:55:55 <applicative> unboxed tuples are strict
14:56:07 <pgiarrusso> yeah, but they are more than strict
14:56:13 <applicative> yes
14:56:20 <pgiarrusso> so ddarius is right
14:56:28 <pgiarrusso> you can't e.g. pass them as function arguments
15:00:04 <pgiarrusso> @source foldl'
15:00:04 <lambdabot> foldl' not available
15:00:11 <pgiarrusso> @source Data.List.foldl'
15:00:11 <lambdabot> Data.List.foldl' not available
15:00:36 <Saizan> @source Data.List
15:00:36 <lambdabot> http://darcs.haskell.org/packages/base/Data/List.hs
15:03:07 <pgiarrusso> Peaker: it seems that what you discuss is reasonable
15:03:34 <pgiarrusso> it is mentioned in this thread, though the implementation given is not working: http://haskell.1045720.n5.nabble.com/Proposal-Add-an-analogue-of-to-deepseq-td4541299.html
15:13:25 <Cale> ddarius: Well, only if you were to start off with an unconventionally weird implementation to be able to TCO.
15:14:43 <Cale> If you're doing outermost-first graph reduction already, the extra call stack seems extraneous to begin with.
15:16:13 <Cale> But I guess if you want to call TCO the non-inclusion of that call-stack which would serve no purpose to begin with, well, I guess it's important.
15:16:27 <ddarius> Cale: Yes, and my point is that that's true in eager cases.  This is why it is so hard to characterize TCO in an abstract and compelling way.  Our usual abstract models don't have this "stack" so to have this "optimization" it has to be put in so that we can "optimize" it out.
15:19:16 <ddarius> Most of the compelling arguments for TCO have been done at an assembly level.
15:19:24 * roconnor implements the Gauss-Jordan-Floyd-Warshall-... algorithm that computes transtive closures/shortest path/maximum capacity/most reliable/solultions of linear equations.
15:19:52 <roconnor> oh and also something about regular expressions.
15:20:00 <coppro> lol
15:20:20 <djahandarie> That almost rivals Curry-Howard-Lambek-DeBruijn-Lawvere
15:20:41 <roconnor> coppro: the algorithm is 3 lines long. ... 2 lines if you don't count the single line containing where.
15:21:06 <dylukes> Could someone link me to a copy of From Lists To Streams To Nothing at All?
15:21:15 <dylukes> It seems to have disappeared (for free) from the face of the internet.
15:22:18 <ddarius> @google "From List To Streams To Nothing At All" filetype:pdf
15:22:19 <lambdabot> No Result Found.
15:22:27 <ddarius> @google From List To Streams To Nothing At All filetype:pdf
15:22:29 <lambdabot> http://publib.boulder.ibm.com/infocenter/ieduasst/rtnv1r0/topic/com.ibm.iea.rcc/rcc/7.0/IntroToUCM/RCCv7_UCM_Module3_UCMInternals.pdf
15:22:29 <lambdabot> Title: IBM Rational ClearCase Unified Change Management (UCM)
15:22:32 <ddarius> Hmm
15:22:35 <mauke> did you mean: Lists
15:22:54 <ddarius> @google "From Listn To Streams To Nothing At All" filetype:pdf
15:22:55 <lambdabot> No Result Found.
15:22:59 <ddarius> @google "From Lists To Streams To Nothing At All" filetype:pdf
15:23:00 <lambdabot> http://code.galois.com/talk/2008/08-07-stewart.pdf
15:23:00 <lambdabot> Title: Stream Fusion for Haskell Arrays
15:23:42 <roconnor> djahandarie: I think the proper name might be Gauss-Jordan-Floyd-Warshall-McNaughton-Yamada algorithm.
15:25:12 <Saizan> shouldn't an algorithm take a name more related to what it does at that point?
15:25:30 <ddarius> Saizan: Heresy!
15:25:54 <ddarius> Shock and awe > clarity
15:26:29 <ddarius> Saizan: Of course, part of the problem is that it is doing superficially different things depending on what perspective you're taking.
15:27:21 <roconnor> Ah yes; it also computes the regular expression accepted by a Finite Automata.
15:27:59 <Saizan> too bad the initials don't compose well, GJFWMY
15:28:48 <ddarius> Let's just call it the Alpher-Bethe-Gamow algorithm because that's so awesome.
15:29:31 <roconnor> Saizan: the algorithm computes the asteration of a matrix over a star-semiring.
15:35:01 <Peaker> Cale: Isn't what you call "unconventionally weird" what GHC (and others) do to implement Haskell evaluation?
15:36:09 <Peaker> Cale: Term substitution isn't very efficient if naively implemented, it is better to remember which terms you were substituting when encountering a new thing to substitute, and that ends up as your stack, doesn't it?
15:40:21 <Saizan> that's not your stack
15:41:42 <ddarius> "These are not the stack frames you're looking for."
15:41:50 <Saizan> a stack is made of expression contexts where you are supposed to plug the result of what you're currently evaluating, what you're describing is usually called an environment
15:43:28 <Cale> Peaker: no, GHC's implementation doesn't have a call stack
15:44:17 <Peaker> Cale: Well, GHC does make TCO pretty important in many cases -- does that render it unconventionally weird?
15:45:00 <Cale> Anyway, I guess it's a matter of perspective, but I tend to think of the way we implement Haskell as being sufficiently different that TCO doesn't really make sense conceptually.
15:45:44 <Cale> Peaker: No it doesn't. GHC's implementation is such that you can't really even talk about TCO, because there's no stack to avoid putting call frames on.
15:46:07 <Saizan> Peaker: TCO refers to an optimization the compiler does, not to the programmer transforming code to use tail calls
15:48:23 <Peaker> If GHC doesn't have TCO, why is transforming calls to be tail calls important? What optimization is that invoking/making possible?
15:49:43 <ddarius> Peaker: What Cale is saying, and which I agree with but don't think is unique to lazy languages, is that the typical implementation mechanism doesn't need to do an "optimization" to accomplish this.
15:50:03 <Peaker> So what's happening differently between a tail call and a non-tail call?
15:52:04 <ddarius> Really, as I said the other day, whether in an eager or lazy language, there is no reason you would predict stack overflows in tail recursive scenarios with any(?) of our usual abstract models.  So for TCO to be an "optimization" you have to do some non-sensical pessimization first.  (You would still predict stack overflows in non-tail recursive cases.)
15:53:06 <ddarius> In, for exmaple, 1+f x we can't evaluate the addition until f x is evaluated so (1+[ ]) goes onto a evaluation stack.
15:55:20 <ddarius> In the basic term rewriting semantics, this would be evidenced by reduction occurring not at the top-level.
15:58:07 <Eduard_Munteanu> Well, it depends on how transparent the machine model is. In C, you can pretty much expect each recursive call to create a new stack frame if no optimization is done.
15:58:19 <tech2> 'night all, thanks for all the help today, I've learned a lot
15:58:35 <Eduard_Munteanu> (then again, people don't usually rely on TCO in C)
15:59:00 <Peaker> Eduard_Munteanu: I rely on TCO in C, sometimes..
15:59:03 <ddarius> Eduard_Munteanu: x86 assembly (or whatever) is not one of our "usual abstract models."
15:59:23 <ddarius> Eduard_Munteanu: You can certainly make models where there is a call stack that can be optimized though.
16:01:12 <ddarius> My point is, what we normally think of as the semantics of functions, such as textual substitution of a beta reduction, does not have this call stack and does not predict stack overflows in tail recursive cases.
16:01:39 <ddarius> I.e. to put it another way, TCO isn't an optimization; TCO is a fix to the broken implementation of functions in languages like C.
16:02:54 <Eduard_Munteanu> Isn't Haskell broken as well? It's hard to say how much storage a function call will require.
16:04:17 <Eduard_Munteanu> Normally, models of evaluation of pure expressions merely cares about time, which doesn't say much about stack usage and so on.
16:04:31 <Eduard_Munteanu> s/cares/care/
16:04:32 <Peaker> Eduard_Munteanu: in the face of sharing, saying how much storage anything costs becomes difficult, unless you just put lower/upper bounds
16:05:10 <ddarius> This isn't a matter of difficulty with prediction and is not a constant factors aspect.
16:06:38 <Eduard_Munteanu> Hm, but can we say much about asymptotics of memory usage either?
16:06:48 <ddarius> Eduard_Munteanu: I can evaluated by hand and count.
16:08:00 <ddarius> Eduard_Munteanu: The point is if you evaluate C by hand using, at least, substitute actuals for formals semantics, you will not see stack growth in tail recursive cases.  At that abstract level, there is no reason at all for such growth to occur.
16:08:56 <Peaker> ddarius: when something is in the tail-call position, what is it that you avoid keeping track of? Instead of having 1 + [..]   or [..] + 1        you have [...]     so you don't keep track?  That may be a trivial optimization, but it still is an optimization
16:09:42 <Cale> Peaker: Remember that evaluation is outermost-first anyway, so it's not like you were going to evaluate the parameters first to begin with.
16:09:47 <ddarius> Peaker: If you just do normal textual beta reduction, you will not get stack growth and it has nothing to do with a special case for tail calls.
16:10:06 <Cale> So there's nothing to put on a stack in the first place.
16:10:14 <ddarius> People don't normally consider the identity transform an optimization.
16:10:38 <Cale> Now, with things like (+), which pattern match both of their parameters, the *pattern matches* go on a stack, but that's a whole other thing.
16:11:09 <ddarius> Eduard_Munteanu: Really, to predict stack growth in a C-like language with the straightforward, "naive" semantics, you literally have to add this "call stack" in just so it can grow.
16:11:11 <Cale> (In GHC's implementation they do anyway)
16:11:40 <ddarius> Eager and lazy languages have different contexts, but the logic is essentially the same for the tail call case.
16:12:03 <Eduard_Munteanu> Hm, I see.
16:13:08 <Cale> In a lazy language it's *especially* silly though. The purpose of the call stack is to remember which function you were about to apply while you go ahead and evaluate its parameters. If you apply the function before evaluating the parameters, there's obviously no need to remember that.
16:15:10 <ddarius> Cale: Yes, M[ ] is not a context in a lazy language, instead case [ ] of ... is.  That doesn't really change much as far as tail calls are concerned.
16:15:39 <Saizan> you also have a "[ ]M" context during the evaluation of the function itself
16:15:57 <ddarius> Yes, that one exists in both eager and lazy evaluation.
16:16:29 <johnlabea> i have a data structure that i want to ensure is fully evaluated - if i call seq am i just ensuring that the data structure is evaluated, not any members or members of members? i want the whole tree of values to be strictly evaluated
16:16:43 <johnlabea> this is in order to time performance
16:16:57 <mauke> :t deepSeq
16:16:58 <lambdabot> Not in scope: `deepSeq'
16:17:02 <Cale> :t rdeepseq
16:17:03 <lambdabot> forall a. (Control.DeepSeq.NFData a) => a -> Eval a
16:17:11 <Cale> :t withStrategy
16:17:12 <lambdabot> forall a. Strategy a -> a -> a
16:17:15 <Cale> errr
16:17:50 <johnlabea> thanks
16:17:54 <Cale> oh, weird
16:18:08 <Cale> What's this Eval a business...
16:18:14 <Cale> rdeepseq :: NFData a => Strategy a
16:18:27 <Cale> withStrategy :: Strategy a -> a -> a
16:18:32 <ddarius> Cale: You've not been keeping up with the times.
16:18:40 <Cale> So you write   withStrategy rdeepseq
16:19:22 <Cale> rdeepseq :: NFData a => Strategy a -- this is the type on my machine
16:20:49 <Cale> oh, duh, Strategy is a type synonym
16:21:02 <Cale> okay
16:23:31 <clsmith> so how frowned upon is using an MVar in a data structure in order to avoid O(n), in absence of a better option? :p
16:23:59 <Cale> clsmith: I don't understand "avoid O(n)"
16:24:11 <Cale> MVars are good when they're appropriate
16:24:18 <clsmith> i mean, using an MVar i can get O(logn)
16:24:55 <Cale> vs. what?
16:25:28 <clsmith> O(n) using a pure & immutable approach
16:25:34 <Cale> Usually if you need an MVar, your other choices are things like combinations of IORefs, STM datastructures, or maybe Chan
16:25:55 <Cale> Have you considered Data.Map?
16:27:26 <Cale> Any algorithm using mutable references can be transformed into one which uses a Data.Map or Data.IntMap
16:27:55 <Cale> Using keys of the map in place of pointers
16:28:18 <Cale> (essentially, the Map models what would be your program's heap)
16:30:13 <clsmith> hmm, basically i want to have a tree which has uh, 'threads' between pairs of nodes. each node may have 1 or more of these directed connections. and i need them to remain able to locate the other quickly. does that make sense? i'm tired :p
16:31:51 <Cale> Since lookup in an IntMap is "constant" time (at least as far as pointer dereferencing is constant time), this means that the asymptotic cost of an algorithm using immutable datastructures should be the same as the one using mutable structures.
16:31:57 <clsmith> it's kinda like an interval tree, except the intervals can have points *added* to them
16:32:20 <Cale> (not just lookup, but modifying an IntMap is similarly "constant" time -- bounded by the log of the size of Int)
16:32:41 <clsmith> hmm, that might work
16:32:42 <Cale> Er, log of the number of Int values
16:33:07 <Cale> If you're implementing something like an interval tree, you might also want to look at FingerTree
16:33:47 <Cale> which is a very general datastructure that interval trees, priority search queues, and efficient sequence structures are all special cases of
16:34:24 <clsmith> yeah, i've had a look at them. i don't think they work on their own, in terms of being able to actually enlarge the intervals in response to added points
16:34:34 <Cale> okay
16:36:17 <dolio> Cale: How does that analysis reconcile the problem from More Haste, Less Speed and whatnot?
16:39:04 <Cale> dolio: I think that paper would have counted it as an additional log cost, but since people are already ignoring the log cost of pointer dereferencing, I'm considering it fair to ignore the similar log cost of modelling that here.
16:40:17 <Cale> It's a little bit silly to talk about asymptotic analysis of programs with bounded memory anyway
16:41:18 <Cale> (any program running on a finite machine which terminates does so in constant time, even if the constant is very large ;)
16:42:02 <Veinor> Cale: what about IO?
16:42:06 <ddarius> Cale: Yes but what is done is comparison against an unimplementable RAM machine in the unbounded memory case with unimplementable constant time arithmetic.
16:42:29 <Cale> ddarius: heh
16:42:30 <Cale> yes
16:43:16 <roconnor> > let as = []:map ("a":) as in as
16:43:17 <lambdabot>   [[],["a"],["a","a"],["a","a","a"],["a","a","a","a"],["a","a","a","a","a"],[...
16:43:26 <Cale> and that's cool, but if you're going to choose to ignore a few log and cube root (square root?) factors to do that, I'll choose to ignore a few logs when modelling that sort of thing too.
16:43:46 <roconnor> > let as = []:map ("a"++) as in as
16:43:48 <lambdabot>   ["","a","aa","aaa","aaaa","aaaaa","aaaaaa","aaaaaaa","aaaaaaaa","aaaaaaaaa"...
16:44:01 <benmachine> Cale: what about space complexity in an immutable setting?
16:44:39 <Cale> benmachine: It's the same.
16:44:53 <benmachine> I... suppose so
16:45:07 <benmachine> since you can encode a mutable machine with an immutable intmap with... constant overhead?
16:45:13 <Cale> yep
16:45:19 <Cale> constant factor
16:45:29 <benmachine> fair enough :)
16:45:53 <zzing> Does haskell have anything good for writing safe javascript? I want to make a static webpage system, probably converting markdown to integrate with a template. But there might be some javascript involved, and I would like to ensure that any javascript has a reasonable amount of safety attached with it.
16:46:48 <ddarius> zzing: Do the extant static or dynamic webpage systems not work for you?
16:47:04 <zzing> ddarius: I do not know of any that you speak
16:47:14 <Cale> zzing: Have you looked on Hackage? There seem to be several relevant packages
16:47:21 <mike-burns> It feels like someone is writing a safe JS library every week, but perhaps none are finished.
16:47:24 <Cale> But I have no familiarity with any of them
16:51:56 <zzing> I suspect piki might work for me.
16:52:11 <zzing> I didn't find much that was near mature though.
16:54:48 <ddarius> Whatever you write is going to be even less mature, and there are certainly some systems that are not entirely immature.
16:56:18 <ddarius> Someone packaged up halipeto.
16:56:46 <zzing> certainly
16:58:27 <ddarius> hakyll seems to be a reasonably popular static web site generator.
16:59:46 <zzing> ok, both look plausible and will look at them immediately. THank you.
17:00:20 <ddarius> I wasn't recommending halipeto.  I just remember when Andrew first made it.
17:00:36 <ddarius> I have no idea what state halipeto is in now.
17:01:42 * hackagebot trifecta 0.3 - Parser combinators with slicing and diagnostic support  http://hackage.haskell.org/package/trifecta-0.3 (EdwardKmett)
17:01:52 <ddarius> Why is Jinjing Wang so crazy?
17:04:53 <xplat> @remember kmc Haskell isn't really designed by mathematicians.  it's designed by people who programmers would consider to be mathematicians and mathematicians would consider to be programmers
17:04:53 <lambdabot> Done.
17:05:05 <edwardk> =)
17:05:46 <edwardk> i'm fond of saying that when i'm around a programmer i play a mathematician, and when i'm around a mathematician i play the part of a programmer, so there is a lot of truth to that
17:05:58 <djahandarie> You designed Haskell?!
17:06:07 <edwardk> =P
17:06:16 <mustelo> if hackagebot is any indication, he did.
17:06:23 <mauke> the k in edwardk stands for "continuation"
17:06:26 <edwardk> i was thinking in terms of haskell code, rather than haskell the language
17:06:26 <mike-burns> The libraries play a big part of what most people consider a programming language.
17:08:17 <Veinor> (call/cc edwardk)
17:08:46 <ddarius> No, the Haskell designers consider themselves programmers.
17:09:08 <edwardk> (call/cc call/cc)
17:09:22 <danharaj> And everyone else considers them wizards.
17:09:26 <mm_freak_> mike-burns: according to that only very few languages are programming languages
17:09:40 <mike-burns> Ain't it the truth.
17:09:47 <mm_freak_> for example i found that PHP is not a programming language, because it sucks as a language, and the available libraries suck as well
17:09:49 <djahandarie> There are a lot of libraries in English.
17:09:54 <mm_freak_> and most people using PHP suck, too
17:10:41 <mm_freak_> the interpreter sucks
17:10:43 <mm_freak_> rasmus sucks
17:10:51 <mm_freak_> i think, there isn't anything about PHP, which doesn't suck
17:11:29 <mm_freak_> even the logo sucks
17:13:53 <mm_freak_> ah, yes…  the auto-generated documentation sucks…  and writing proper comments for it sucks, too…  haddock is heaven compared to that
17:14:34 <mm_freak_> sorry, back to a real language
17:14:35 <mm_freak_> =)
17:17:09 <danharaj> I wonder if there's going to be an influx of new people in this channel since Carmack stated that he's tempted by Haskell :p
17:17:24 <hpc> didn't he say that in 2009?
17:17:39 <danharaj> Well he said it again.
17:17:47 <danharaj> good ideas are worth repeating ;)
17:17:52 <hpc> true
17:17:59 <hpc> we'll see
17:18:08 <hpc> i don't think anything will happen until he starts using it
17:19:49 <cmccann> hpc, you might be thinking of a different 3D game programmer who mentioned Haskell favorably some years back
17:21:23 <cmccann> whose primary complaints about Haskell seemed to be that pervasive laziness is troublesome for the kind of code he writes, and that he thought relying entirely on type inference was a bad idea
17:21:26 <jmcarthur> so that's carmack and sweeney both endorsing functional programming one way or another
17:21:32 <edwardk> yep
17:21:45 <cmccann> (where "relying entirely on type inference" meant something like "not even top-level type signatures")
17:22:06 <tomh-> danharaj: where did he say it?
17:22:09 <tomh-> (again)
17:22:20 <ddarius> Perhaps if we get a wave of game programmer wanna-bes flowing in we'll call it the Carmeeney effect.
17:22:21 <cmccann> Tim Sweeney also posts on Lambda the Ultimate occasionally, so he's clearly interested in programming languages
17:22:24 <danharaj> http://www.youtube.com/watch?v=4zgYG-_ha28
17:22:47 <johnlabea> i have a simple function (A -> B), is there a neat way to wrap this to be (A -> IO B)? i know i could do (\a -> return foo(a)), but is there something idiomatic?
17:22:58 <cmccann> johnlabea, (return .)
17:22:59 <danharaj> :t bind
17:23:00 <tomh-> danharaj: got a time where he goes into it?
17:23:00 <lambdabot> Not in scope: `bind'
17:23:02 <cmccann> :t (return .)
17:23:04 <lambdabot> forall a (m :: * -> *) (f :: * -> *). (Monad m, Functor f) => f a -> f (m a)
17:23:06 <danharaj> tomh- maybe
17:23:08 <cmccann> oh pf
17:23:09 <ddarius> Please don't write foo(a).
17:23:10 <cmccann> dammit Cale
17:23:24 <ddarius> Or, for Pete's sake, be consistent and write return(foo(a))
17:23:40 <jmcarthur> return foo(a) isn't even correct
17:23:41 <danharaj> tomh-: try this http://www.youtube.com/watch?v=4zgYG-_ha28&feature=player_detailpage#t=54m00s
17:23:44 <johnlabea> i don't see how i write my syntax has any impact on your ddarius, so calm down
17:23:52 <tomh-> thanks
17:23:58 <danharaj> It's not for ddarius' sake, it's for Pete's sake.
17:24:04 <danharaj> And it has all the impact on Pete.
17:24:13 <cmccann> just parenthesize everything, ((((foo x) y) (bar z)) baz) looks good
17:24:15 <ddarius> Also, just because you don't see it doesn't mean it doesn't.
17:24:31 <jmcarthur> it impacts my ddarius
17:24:43 <jmcarthur> *on my
17:24:54 <shachaf> My ddarius was severely impacted.
17:25:29 <cmccann> johnlabea, pretty much every Haskell programmer would agree that you shouldn't write foo(a)
17:25:46 <jmcarthur> "shouldn't" is a strong way to put it
17:25:56 <shachaf> cmccann: I can imagine a Haskell programmer that would write foo(a) for all function application.
17:25:57 <danharaj> foo(a) implies some sort of meaning that isn't there.
17:26:06 <jmcarthur> danharaj: it does?
17:26:15 <danharaj> jmcarthur: Those parentheses mean nothing :p
17:26:15 <shachaf> > map(succ)([1,2,3])
17:26:16 <lambdabot>   [2,3,4]
17:26:19 <cmccann> yes, there's no limit to the peculiar styles some people have
17:26:34 <kmc> so i've noticed there are a lot of Frequently Asked Questions here
17:26:39 <cmccann> but avoiding superfluous parentheses is pretty well agreed upon from what I've seen
17:26:44 <kmc> it would be nice to compile a document with answers to them
17:26:57 <jmcarthur> @faq Do we have a document for FAQs?
17:26:58 <lambdabot> The answer is: Yes! Haskell can do that.
17:26:59 <kmc> which also covers frequent areas of confusion
17:27:04 <danharaj> kmc: I disagree, mostly because referring people to a faq is less fulfilling of my procrastination.
17:27:10 <cmccann> kmc, I've been meaning to do the same thing for stuff I see a lot on SO
17:27:23 <kmc> well i'm getting tired of writing the same explanations over and over
17:27:42 <danharaj> kmc: so you should make a document and copy and paste from it ;p
17:27:44 <shachaf> Maybe what we need is a bot.
17:27:46 <kmc> so i think i'll write them down on the Haskell wiki
17:27:53 <shachaf> kmc++
17:27:56 <kmc> bots are usually used to link to online documentation
17:28:11 <kmc> ok well i'm going to start a wiki page
17:28:15 <kmc> unless anyone thinks it's actually a bad idea
17:28:20 <kmc> and y'all should add stuff to it
17:28:32 <cmccann> kmc, it's a good idea and the wiki seems a good place for it
17:29:43 <kmc> yeah, i don't want it to be only my project
17:29:51 <kmc> and i do want it to be based on actual frequently asked questions
17:29:54 <kmc> i have a list somewhere already
17:30:07 <shachaf> You should run an analysis on #haskell logs.
17:30:58 <kmc> it's a mediawiki right?
17:31:28 <shachaf> haskellwiki? Yes.
17:33:14 <Eduard_Munteanu> > let __map = uncurry map in __map(succ, [1,2,3,4])
17:33:15 <lambdabot>   [2,3,4,5]
17:33:40 <shachaf> Get your underscores out of this channel.
17:33:44 <Eduard_Munteanu> :)
17:34:40 <Eduard_Munteanu> Hm, I forgot the ';' at the end :P
17:35:26 <shachaf> You also forgot to make its type be IO.
17:36:03 <kmc> sweet, Pandoc can do Markdown → MediaWiki
17:38:16 <Nereid> > length (filt­er ('4' `elem­`) (map show [1..1­000]))
17:38:17 <lambdabot>   <no location info>: lexical error at character '\173'
17:38:26 <Nereid> huh.
17:38:31 <Eduard_Munteanu> kmc: so you want to write that FAQ, but most of the time will be spent figuring out a way to convert from your favourite document language :)
17:38:35 <Nereid> > length (filter ('4' `elem`) (map show [1..1000]))
17:38:35 <lambdabot>   271
17:40:09 <kmc> there's already a little at http://haskell.org/haskellwiki/Introduction#Other_frequently-asked_questions
17:41:21 <shachaf> "7.3 I already have a large application in C or C++."
17:41:40 <shachaf> Is that the same language as C/C++?
17:42:44 <ddarius> danharaj: I didn't really have much of an opinion on John Carmack before, but I like him now because of a few comments he made after 1:07:00.
17:43:24 * shachaf wonders whether to watch the video.
17:43:32 <shachaf> What are the comments?
17:43:35 <ddarius> I started at the 54m mark.
17:43:52 <Eduard_Munteanu> You mean the stuff about using Haskell?
17:44:04 <Eduard_Munteanu> "or Ocaml"
17:44:13 <ddarius> No.
17:47:05 <ddarius> "One of the lessons that we took away from Doom 3 was that script interpreters are ... bad from a performing, debugging, development stand point." [..] "oh it's kind of that argument that you want a free-form dynamically typed language so you can do all of your quick flexible stuff and people who aren't really programmers can do this stuff." ...
17:47:06 <danharaj> ddarius: I take it you weren't a big Doom or Quake person then, if you didn't have an opinion of him ;p
17:48:03 <ddarius> "One of the big lessons of the big projects is that you don't want people who aren't programmers programming, you'll suffer for it."
17:48:32 <ddarius> danharaj: I knew who he was, but I didn't like Quake.  I played the original Doom a decent bit.
17:48:49 <ddarius> By Quake, I mean the original Quake.
17:53:18 * kmc notes apropos of nothing that "singleton" is as much a maths word as "monad"
17:54:31 <ddarius> kmc: There are many, many "maths" word in regular use and in mainstream programming jargon.
17:54:52 <kmc> can you give me a few good examples?
17:54:57 <kmc> "function" of course
17:55:09 <aninhumer> Even if they use it wrong usually :P
17:55:41 <mauke> variable
17:56:06 <aninhumer> expression?
17:56:12 <Peaker> Functor (C++)
17:56:13 <kmc> Haskell uses it wrong too
17:56:14 <mauke> set, term
17:56:25 <mauke> relation
17:56:38 <aninhumer> constant
17:58:29 <Nereid> kmc: not as wrong as C++
17:58:34 <xplat> > join ((==) . nub) $ [1,2,3]
17:58:36 <lambdabot>   True
17:58:38 <xplat> > join ((==) . nub) $ [1,2] ++ [2,3..]
17:58:39 <lambdabot>   False
18:00:18 <shachaf> xplat: Why not just (ap (==) nub)? :-)
18:00:36 <aninhumer> I do wonder if giving things names with a more obvious root would help avoid scaring people off
18:01:07 <kmc> we wonder that a lot
18:01:10 <aninhumer> Functor could be "Mappable" or something, for example?
18:01:15 <shachaf> "warm fuzzy monoid in the category of endofunctors"?
18:01:16 <kmc> i think you basically can't win
18:01:17 <neuman> hi all, would anyone know how would i write a loop that prints a string every n second?
18:01:33 <cmccann> aninhumer, I've never seen any evidence of that being what scares people off
18:01:33 <kmc> forever (putStrLn "Hello" >> threadDelay (n*1000000))
18:01:39 <mauke> neuman: forever, threadDelay, putStr, hFlush
18:01:50 <neuman> kmc: mauke: thanks
18:01:56 <kmc> aninhumer, if you call it "class" then people say "oh, just like Java classes".  if you call something "monad" then they run off
18:01:59 <kmc> you can't win
18:02:02 <shachaf> Well, that will delay n seconds after printing it, not print it every n seconds. :-)
18:02:07 <kmc> i think the unfamiliar terms are better overall
18:02:10 <monochrom> Functor->Mappable is too easy. try Applicative->?
18:02:22 <kmc> i think "can't understand these math words" is more of an excuse not to learn than an actual barrier to learning
18:02:32 <kmc> there are plenty of excuses not to learn something new
18:02:37 <cmccann> monochrom, Applicative is already like that, clearly we need to rename it to StrongLaxMonoidal or whatever
18:02:51 <monochrom> how about MonadPlus?
18:02:56 <kmc> list -> Free Monoid
18:03:06 <mauke> free the monoids!
18:03:13 <shachaf> MonadPlusPlusPlusWouldBuyAgain
18:03:17 <kmc> haha
18:03:18 <hatds> haha
18:03:32 <monochrom> basically if the type class has 5 methods x,y,z,p,q, do you call it XableYableZablePishQly?
18:03:42 <kmc> yes
18:03:51 <aninhumer> The Java way?
18:04:02 <kmc> AddableSubtractableConvertableFromIntegerComparableSingletonFactoryManagerDispatcher
18:04:02 <shachaf> Oh, the name of a typeclass should be constructed from its laws.
18:04:13 <kmc> the first law of Eq is you do not talk about Eq
18:04:14 <monochrom> yeah, the Java way, I thought you liked the Java way. "Mappable"
18:04:56 <cmccann> we should just introduce free-form structural constraints instead of type classes, every type class function is its own constraint. So Num would be (Has(+) a, HasNegate a, HasFromInteger a, ...) etc.
18:05:02 <cmccann> this is obviously a better way
18:05:09 <aninhumer> Well, it accurately (afaik) and concisely describes the functionality of Functors
18:05:15 <alpounet> i don't mind seeing running away people who aren't enough motivated to go behind "complicated words"
18:05:44 <cmccann> anyway, I prefer strange words to familiar words being used in different but specific ways
18:05:54 <cmccann> both are confusing, but the former introduces clarity once you learn the terms
18:05:57 <ski> cmccann : iirc, Clean supports that style
18:05:58 <cmccann> the latter just muddies things forever
18:06:16 <monochrom> Mappable is concise just because it has only one method. it does not bloody scale.
18:06:29 <monochrom> it does not scale to a type class with 10 methods
18:06:39 <geheimdienst> about "can't understand these math words" being an excuse not to learn: i think that's true up to a point, but note that it works both ways. complicated jargon is a good excuse to not improve teaching
18:07:10 <aninhumer> I think it can be discouraging even to those who eventually learn it also
18:07:14 <cmccann> geheimdienst, which is argument for clearly-defined jargon with well-motivated purposes
18:07:19 <monochrom> accurate, concise, guessable --- pick two
18:07:19 <shachaf> We want our type classes to be like this: http://i.imgur.com/j58ip.jpg
18:07:36 <Peaker> Many classes that have 2 methods really should have beben 2 classes, each with 1, in retrospect
18:07:48 <mauke> shachaf: http://mauke.dyndns.org/stuff/img/lol,internet/paradox.jpg
18:07:49 <isBEKaml> I'd not say "can't understand math words" is the reason people run away. I'd just say, "Oh, these guys are trying to answer questions I never even started asking. It's just going way above my level." is the reason.
18:07:57 <isBEKaml> well, just a newbie perspective.
18:08:18 <geheimdienst> isBEKaml: good point
18:08:25 <shachaf> I'm not sure why people care about "math words" more than they care about any other type of word.
18:08:44 <shachaf> If there's a concept that you're not familiar with, it's perfectly reasonably for it to have a word you're not familiar with.
18:08:44 <cmccann> isBEKaml, there are... some problems with how stuff is presented sometimes, I think. Far too much tendency to front-load difficulty and unfamiliar concepts vs. how useful they seem at first
18:09:06 <danharaj> There's a monad tutorial for every haskell user.
18:09:21 <geheimdienst> danharaj: there's a monad tutorial *by* every haskell user
18:09:27 <isBEKaml> cmccann: well, you could just try presenting stuff one at a time, and see how folks handle it.
18:09:30 <danharaj> geheimdienst: that's what I intended :p
18:09:40 <shachaf> Every Haskell user is a monad tutorial.
18:09:45 <edwardk> i too have a problem with math words.. there aren't enough of them to name all the concepts!
18:09:51 <ski> geheimdienst : i haven't done any ..
18:09:57 <danharaj> edwardk: that's why we have affixes!
18:10:02 * aninhumer goes to get some burritos to explain
18:10:10 <danharaj> pseudotensorial fiber bundles!
18:10:38 <ddarius> cmccann: Ah, but you are probably coming from a perspective that it is not a conspiracy.
18:10:54 <cmccann> edwardk, jargon is nowhere near as modular and composable as one might like
18:11:08 <srin> Too much operator overloading as it is D:
18:11:14 <monochrom> well that nails it. self-congratulating programmers do not want to be reminded "this is unfamiliar stuff" by way of "this is unfamiliar name"
18:11:30 <isBEKaml> cmccann: Of course, some concepts are not so obvious when first seen. The good thing, they are all still there. :)
18:11:45 <ddarius> edwardk: Just call everything an algebra.  It works for mathematicians.
18:11:46 <danharaj> Programming is hard! Let's use java!
18:11:53 <edwardk> ddarius: =)
18:12:09 <isBEKaml> danharaj: :)
18:12:11 <edwardk> that explains why every concept i come across seems like a natural fit for the algebra package
18:12:13 <danharaj> ddarius: reminds me of programmers and calling everything an object.
18:12:23 <ddarius> danharaj: But everything is an object.
18:12:27 <aninhumer> Hmm, how many characters are available for naming operators?
18:12:37 <ddarius> aninhumer: How many do you have?
18:12:37 <danharaj> Well, everything is an algebra. :p
18:12:46 <cmccann> monochrom, what annoys me is that half the time it's not even unfamiliar stuff, it's just that presenting amorphously familiar things in a clearly structured way with more precise names makes people think they're not familiar
18:12:56 <danharaj> aninhumer: You can bring to bear the entirety of unicode if you enable unicode syntax in GHC
18:13:24 <ddarius> cmccann: What are talking about?  No programmer understands free monoids.  That's just math gobbledy-gook.
18:13:27 <aninhumer> So is anything not alphanumeric an operator symbol?
18:13:29 <cmccann> danharaj, unicode syntax is just for replacing built-in syntax
18:13:43 <aninhumer> (and not part of syntax)
18:13:54 <cmccann> ddarius, that is a particularly egregious example, yes
18:13:56 <danharaj> cmccann: ah, so you can use unicode without extensions?
18:14:29 <cmccann> danharaj, any unicode character marked as a "symbol" or "punctuation" that isn't reserved syntax can be an operator, I believe
18:14:38 <cmccann> and any unicode character marked as alphanumeric can be used as such
18:14:38 <ddarius> The Report has always said that Haskell source is Unicode.
18:14:51 <ddarius> > isSymbol [minBound..]
18:14:52 <lambdabot>   Couldn't match expected type `GHC.Types.Char'
18:14:52 <lambdabot>         against inferred type...
18:14:55 <ddarius> > filter isSymbol [minBound..]
18:14:56 <lambdabot>   "$+<=>^`|~\162\163\164\165\166\167\168\169\172\174\175\176\177\180\182\184\...
18:15:12 <ddarius> > text $ filter isSymbol [minBound..]
18:15:13 <lambdabot>   $+<=>^`|~
18:15:20 <cmccann> note that some unicode characters are neither symbols nor alphanumeric; you can't use these for anything in Haskell source, I think
18:15:32 <monochrom> don't forget whitespace
18:15:46 <ddarius> > filter isSpace [minBound..]
18:15:47 <lambdabot>   "\t\n\v\f\r \160\5760\6158\8192\8193\8194\8195\8196\8197\8198\8199\8200\820...
18:15:48 <danharaj> how is an implementation supposed to deal with text direction?
18:15:56 <monochrom> anyway read the haskell report (either 98 or 2010) for real
18:16:00 <ddarius> That is probably not specified.
18:16:06 <cmccann> monochrom, ah true, I think unicode whitespace characters should also behave as such
18:16:23 <ddarius> The Report doesn't exactly think through using Unicode, it just asserts that the source is Unicode.
18:16:26 <rwbarton> text direction doesn't seem like the language's problem, that's more of a display issue, isn't it?
18:17:32 <danharaj> fair point
18:17:35 <ddarius> rwbarton: It's questionable how layout should work in the face of rtl languages.
18:17:53 <rwbarton> oh, true
18:18:12 <ddarius> What does Hebrew do when quoting foreign (ltr) words?
18:18:16 <cmccann> > let (∈) = elem in 5 ∈ [1..10]
18:18:17 <lambdabot>   True
18:18:38 <kmc> everything is an object because "object" is defined as that which everything is?
18:18:54 <shachaf> ddarius: Embeds the left-to-right. Or what do you mean?
18:19:02 <ddarius> kmc: Object is Leibniz's monad.
18:19:19 <rwbarton> which way do the quotes go
18:19:38 <rwbarton> or maybe it doesn't matter
18:20:05 <rwbarton> if a ltr open quote looks the same as a rtl close quote
18:20:06 <shachaf> Numbers in Hebrew are also written left-to-right, for what it's worth.
18:20:12 <kmc> "Variant is a data type in certain programming languages, particularly Visual Basic and C++ when using the Component Object Model."
18:20:23 <monochrom> hahaha
18:20:59 <monochrom> is this bitter saturday night? when everyone gripes about mainstream programmer mindset? :)
18:21:16 <mauke> someone meme it
18:21:23 <aninhumer> shachaf: You mean little-endian
18:21:32 <isBEKaml> monochrom: careful about timezones there. :)
18:21:48 <ddarius> monochrom: Don't worry we've started a linguist/Unicode conversation to derail that.
18:22:06 <mauke> coderail
18:22:16 * cmccann complains about the poor support for unicode in other languages
18:22:21 <shachaf> Cobol on Coderails.
18:22:30 <monochrom> oh yeah mainstream programmers also forgot up-to-down text such as classical Chinese!
18:22:42 <monochrom> or rather top-to-bottom
18:22:42 <cmccann> shachaf, http://www.coboloncogs.org/
18:23:21 <aninhumer> monochrom: Just rotate the screen, it's fine
18:23:34 <kmc> monochrom, you mean every day?
18:24:11 <dylukes> cmccann: what.
18:24:13 <dylukes> what is this XD
18:25:03 <cmccann> dylukes, amazing
18:25:04 <shachaf> Just what it looks like.
18:25:05 <rwbarton> I'd think a sane haskell source file would have to be primarily ltr, with rtl spans limited to single identifiers
18:25:08 <roconnor> > 1/1-(1/0))
18:25:09 <lambdabot>   <no location info>: parse error on input `)'
18:25:13 <roconnor> > 1/(1-(1/0))
18:25:14 <lambdabot>   -0.0
18:25:18 <shachaf> http://sqlonrails.org/
18:25:20 <dylukes> Too ba its not real ;~;
18:25:28 <kmc> too bad you're not real
18:25:39 <shachaf> rwbarton: One issue is what you do when RTL text spans multiple lines.
18:25:49 <rwbarton> like a quoted string?
18:25:52 <shachaf> Yes.
18:26:22 <shachaf> However, don't do that.
18:26:24 <rwbarton> I'm pretty uncomfortable using those even in pure ascii haskell source files :)
18:26:27 * shachaf solves all problems.
18:26:31 * cmccann assumes shachaf has plenty of personal experience with RTL text
18:26:51 <roconnor> > 1/(1-(100000000000))
18:26:52 <lambdabot>   -1.00000000001e-11
18:26:55 <shachaf> cmccann: Not all that much, really, but a bit.
18:27:04 <ddarius> rwbarton: You have to specify what should happen in the insane case too though.
18:27:10 <shachaf> (I mean, of mixing RTL with LTR.)
18:27:58 <rwbarton> sure, I can easily believe that there are complications here, given that I don't even know how the layout rules interact with multi-line string literals normally
18:28:16 <roconnor> > 0 * (1/0)
18:28:17 <lambdabot>   NaN
18:28:31 <zong_sharo> is there any up to date tutorials on atom?
18:29:37 <unsignedInt> how can i use "→" instead of "->" in haskell source code?
18:30:09 <shachaf> > (-1/0) ∗ (1/0)
18:30:10 <lambdabot>   NaaN
18:30:15 <shachaf> Mmm, Naan.
18:30:24 <roconnor> O_o
18:30:25 <zong_sharo> unsignedInt: UnicodeSyntax
18:30:27 <roconnor> NaaN?
18:30:40 <aninhumer> To go with all the Curry
18:30:41 <unsignedInt> zong_sharo: hmm.. how do i use that?
18:30:42 <shachaf> "Not an actual Number"
18:30:50 <roconnor> WTF?
18:30:56 <zong_sharo> unsignedInt: do you know how to enable language extensions?
18:31:25 <unsignedInt> zong_sharo: nope.
18:31:48 <zong_sharo> unsignedInt: UnicodeSyntax is one of them
18:31:58 <zong_sharo> unsignedInt: http://www.haskell.org/ghc/docs/7.0.3/html/users_guide/ghc-language-features.html#options-language -- here is a quick intro in extensions
18:32:16 <dylukes> unlike GCC, GHC doesn't turn on extensions by default.
18:32:19 <dylukes> It makes things cleaner.
18:32:55 <unsignedInt> thanks
18:33:19 <zong_sharo> is there _any_ up to date docs on atom (except haddock docs ofc)
18:33:31 <roconnor> shachaf: ah
18:33:39 <roconnor> stupid unicode
18:34:39 * ski . o O ( `NyaaN' )
18:35:06 <aninhumer> Not yet an actual number?
18:35:20 <shachaf> GCC doesn't turn on all extensions by default.
18:35:30 <shachaf> And GHC used to do the annoying -fglasgow-exts thing until recently.
18:35:44 <ski> shachaf : "Numbers in Hebrew are also written left-to-right" -- you mean little-endian ?
18:35:47 <geheimdienst> ski, oh dear, whenever i hear nyan cat, i'm gonna hear "nan nan nan" now
18:35:57 <shachaf> It's a bit harder for GCC to make a change like that since people are actually using it. :-)
18:37:34 <shachaf> ski: Do I?
18:37:45 <shachaf> Arithmetic expressions and such are also written left-to-right.
18:37:58 <ski> i don't know. presumably you know what you meant
18:38:11 <aninhumer> shachaf: Only by convention
18:38:37 <shachaf> aninhumer: Everything is by convention. :-)
18:38:42 <ski> i suppose we could ask Peaker ..
18:38:43 <aninhumer> Well yes
18:39:10 <ski> (istr arabic also does little-endian numbers)
18:39:28 <aninhumer> ski: yep
18:39:48 <shachaf> Doesn't Arabic write its numbers right-to-left?
18:40:16 <ski> arabic writes most everything right-to-left, no ?
18:40:18 <JuanDaugherty> presumably
18:40:37 <shachaf> ski: Right, and so does Hebrew. Except for numbers.
18:41:03 <aninhumer> Arabic is rtl, but it's numbers are the same way around as ours
18:41:29 * ddarius thinks examples would clear things up.
18:41:40 <shachaf> Oh. Are you sure?
18:41:56 <aninhumer> The point being numbers are only directional once you pick an endianness
18:42:03 <rwbarton> at http://www.imo-official.org/problems.aspx you can download IMO problems in many languages
18:42:15 <JuanDaugherty> "ours" are in the order of "thier" text
18:42:29 <rwbarton> Different RTL languages have different conventions for these things
18:43:39 <rwbarton> for example most RTL languages write "(i, j)" as in English, but the Arabic (Kuwait) translation has "(j, i)" except with a backwards comma
18:43:53 <ski> from what i've seen, arabic writes e.g. `1995' (using arabic ciphers/digits) with the `5' digit first (i.e. rightmost), &c.
18:45:19 <ski> i wonder how they pronounce it when spelled out -- like "one thousand nine hundred ninety five" or like "five and ninety and nine hundred and one thousand" ?
18:45:20 <aninhumer> ski: Nope
18:45:37 <aninhumer> Oh wait
18:45:41 <aninhumer> misread
18:46:08 <shachaf> ski: That's independent of the direction it's written. Various LTR languages have both conventions.
18:47:08 <geheimdienst> ski: NINEteen, NINEty-one -- nine comes first in both cases
18:47:17 <ski> shachaf : yeah i know -- hence i wonder what the situation is in e.g. west and east arabic
18:47:49 <rwbarton> I wonder how they type those numbers :)
18:47:58 <rwbarton> do they enter the digits in the order 5991 then?
18:47:58 <ski> geheimdienst : obviously there's exceptions even in the more regular systems :)
18:48:01 <shachaf> ski: In Hebrew you say "one thousand nine hundred ninety and five".
18:48:30 <rwbarton> or perhaps the software they use knows that numbers are written left-to-right
18:48:50 * aninhumer installs scim-tables to play with
18:49:02 <rwbarton> or for that matter, what is the traditional order in which to write the digits by hand
18:49:32 <ddarius> If it's right to left, presumably right to left and thus 5 first.
18:53:41 <aninhumer> I can't imagine people guessing the offset everytime they want to write a number inline
18:54:10 * shachaf was never very good at the whole writing-by-hand thing.
18:55:52 <aninhumer> Well this arabic IME takes numbers big endian
18:56:15 <ivanm> am I correct in understanding that in blaze-builder, Write is a builder for Builder? :p
18:56:21 <aninhumer> So maybe they do just write them ltr
18:57:55 <hatds> can you splice a TH declaration into a where, or is it top level only?
18:58:56 <ivanm> hatds: not sure... I think you might be able to
18:59:44 <hatds> doesn't seem to be working for me
19:00:51 <Liskni_si> hatds: are you surrounding it with $( ) ?
19:00:57 <hatds> yeah
19:01:11 <hatds> "where $(testd)"
19:01:30 <hatds> it worked at top level
19:03:35 <Liskni_si> well, the documentation says that [d| ... |] wants a list of top-level declarations, perhaps it really doesn't work elsewhere
19:09:16 <JuanDaugherty> if I want a newly created user to have their own pkg environment what it the mechanism to cause .cabal to get created for that user?
19:09:44 <JuanDaugherty> (if any)
19:10:31 <ivanm> JuanDaugherty: run "cabal update"
19:10:34 <ivanm> or something like that
19:10:39 <JuanDaugherty> as that user?
19:11:40 <JuanDaugherty> sorry, actually I tried that, responded too quickly.
19:12:58 <ivanm> heh
19:13:01 <JuanDaugherty> I don't think this is something that's worked out yet, but wanted to ask to make sure.
19:14:25 <ivanm> not sure I follow what you mean...
19:15:14 <ivanm> technically speaking, you could just set it up in whatever script gets run when creating a new user to create a .cabal directory and - if using a customised config file - copy that file in
19:15:56 <roconnor> > let star x = recip (1-x) in star 5
19:15:57 <lambdabot>   -0.25
19:16:00 <roconnor> > let star x = recip (1-x) in star (star 5)
19:16:01 <lambdabot>   0.8
19:16:38 <JuanDaugherty> what actually worked for me was to let root's .cabal be the operative one and give ownershop of roots .cabal to the non-root user.
19:17:28 <JuanDaugherty> but won't work to have two actually different pkg environments
19:17:28 <Veinor> > let star x = 1 - recip x in (star 5, star $ star 5)
19:17:29 <lambdabot>   (0.8,-0.25)
19:17:37 <Veinor> cute
19:22:42 <ivanm> JuanDaugherty: ummm.... I'm not following why you're doing anything like that
19:22:56 <ivanm> e.g. how do users change their pkg environment?
19:23:50 <JuanDaugherty> well they can't easily if there's no means to do so
19:23:51 <ddarius> > scanl1 (+) $ iterate (-0.25*) 1
19:23:52 <lambdabot>   The operator `GHC.Num.*' [infixl 7] of a section
19:23:53 <lambdabot>      must have lower prece...
19:23:59 <ddarius> > scanl1 (+) $ iterate ((-0.25)*) 1
19:24:00 <lambdabot>   [1.0,0.75,0.8125,0.796875,0.80078125,0.7998046875,0.800048828125,0.79998779...
19:24:05 <ivanm> JuanDaugherty: "cabal <foo>" will create one for them...
19:24:15 <ivanm> you don't need to specifically go and create one
19:24:17 <ddarius> > drop 100 $ scanl1 (+) $ iterate ((-0.25)*) 1
19:24:18 <lambdabot>   [0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0....
19:25:28 <Claudius1aximus> or put a sensible /etc/skel/.cabal/config if you want
19:26:56 * ddarius needs to make a Mellin transform functional.
19:26:58 <Claudius1aximus> if you want each user to start from an empty slate, don't have installed with cabal --global
19:26:59 <JuanDaugherty> is /etc/skel LSB now, I do see it in debian 6, never saw it anywhere before
19:27:03 <ivanm> Claudius1aximus: I _knew_ there was a way of defining what should be created for new users; forgot it was /etc/skel/
19:27:19 <ivanm> Claudius1aximus: or your package manager
19:27:27 <ddarius> I guess a Laplace transform one wouldn't hurt either.
19:27:32 <ivanm> JuanDaugherty: no idea; gentoo has it, etc.
19:28:02 <Claudius1aximus> and i believe cabal-dev is designed for the empty-slate thing, but i never used it yet
19:28:03 <JuanDaugherty> there's no /etc/skel/.cabal on my deb6 host
19:28:05 <ivanm> I think it's just how useradd works
19:28:12 <ivanm> JuanDaugherty: create one
19:28:19 <ivanm> that's the whole point of /etc/skel
19:28:34 <ivanm> useradd uses it to pre-populate new home directories
19:28:35 <JuanDaugherty> you're saying cabal will look at it?
19:28:41 <JuanDaugherty> ah
19:28:42 <ivanm> Claudius1aximus: well, per-project empty slate
19:31:18 <ddarius> Why does everyone want to numerical -invert- the Mellin transform?
19:31:45 <isBEKaml> as long as we are on Unicode, I'm curious as to how you'd deal with BOM (RTL or LTR, endianness issues) ?
19:33:42 * ddarius guesses he can just do Runge-Kutta since he only needs the single dimensional case.
19:34:15 <ddarius> Though it is an improper integral...
19:43:08 * edwardk waves hello,
19:43:40 * shachaf particles greetings.
19:44:54 <edwardk> preflex: xseen clsmith
19:44:55 <preflex>  clsmith was last seen on freenode/#haskell 3 hours, 10 minutes and 37 seconds ago, saying: yeah, i've had a look at them. i don't think they work on their own, in terms of being able to actually enlarge the intervals in response to added points
19:47:15 <ivanm> anyone here familiar with blaze-builder?
19:49:58 <kizzx2> hey guys, i'm trying to solve the "Word Number" problem... for example wordNumber 3 = "onetwothree" and i need to find the 51 billion-th character of (wordNumber Infinity)
19:50:25 <kizzx2> i have coded in Haskell, it works for small numbers but takes > 10 min on my computer http://ideone.com/7G3Zv
19:50:38 <kizzx2> however, the equivalent C# code takes 1 minute http://ideone.com/JjCb3
19:51:40 <kizzx2> i'm only using the bruteforce approach (i am aware there are better algorithms), i am mainly interested in making the Haskell version perform reasonably  (i have -hy profile and .prof file if anyone is interested)
19:52:10 <kizzx2> * it works for small numbers, but to find the 51-billion-nth character, it takes over 10 min on my cmputer
19:52:50 <ivanm> kizzx2: using !! is expensive
19:52:57 <ddarius> edwardk: You have a handy library for me to do numerical integration of complex-valued complex functions?
19:53:05 <ivanm> use a Map or something rather than lists
19:53:17 <edwardk> ddarius: nope.
19:53:19 <kizzx2> ivanm: ah
19:53:25 <edwardk> that is part of why i'm building the pade machinery
19:53:29 <ivanm> actually, I'd be tempted to make it a direct (albeit partial) function
19:53:50 <edwardk> so i can do rational function approximation and integrate over that
19:54:13 <ddarius> If you can retire an increment in one cycle, it would already take over 10 seconds to simply count to 51 billion on a multi-GHz processor.
19:54:37 <ddarius> So that's about 60 cycles on average.
19:54:51 <ddarius> Of course a memory stall will be very painful.
19:54:54 <kizzx2> what do you mean "retire an increment"?
19:55:55 <ddarius> Completing the execution of an opcode is called "retiring."
19:56:02 <edwardk> ddarius: as a side note i removed one of the layers of interning from trifecta. much nicer now
19:56:11 <ddarius> Gut
19:56:18 <kizzx2> ddarius: oic
19:56:20 <edwardk> so it interns paths and bytestring leaves but not the ropes themselves
19:57:15 <edwardk> now i just need to write the rendering code to layer all the fixits and ranges on top of one another.
19:57:40 <ddarius> kizzx2: So to elaborate on ivanm's statement, xs !! 51000000000 means chasing 51 billion pointers.
19:57:54 <kizzx2> display n | n == 1 = "one" | n == 2 = "two" | n == 3 "three"
19:57:54 <kizzx2> ^ is this fast in Haskell? is it O(n) or can GHC optimize into jump table or something?
19:58:06 <ivanm> kizzx2: just use direct pattern-matching!
19:58:15 <kizzx2> o
19:58:15 <ivanm> display 1 = "one"; display 2 = "two"; etc.
19:58:23 <danharaj> gross pattern matching on numbers
19:58:32 <ddarius> Not that O(n) for n = 10 or whatever is really a problem.
19:58:35 <ivanm> danharaj: you don't like that? why?
19:58:53 <ivanm> ddarius: no, but if it's repeated a large number of times...
19:58:57 <danharaj> something visceral inside me
19:59:11 <kizzx2> so if i make (display 0 = "zero"; display 1 = "one"; ...) isn't is the same as using (!!)?
19:59:28 <isBEKaml> danharaj: ah, regexes. they can do that. :P
20:07:28 <ivanm> kizzx2: that's O(1), !! is O(n)
20:07:53 <kizzx2> ivanm: so pattern matching is O(1)?
20:08:04 <ivanm> yup
20:08:37 <kizzx2> i wonder how it would be implemented, i thought it would be translated to C like:
20:08:37 <kizzx2> if(n == 0) do0branch(); else if(n==1) do1branch(); ...?
20:10:32 <monochrom> I wouldn't use "O(whatever)" to obscure facts. if you have 10 guards in haskell or 10 if-then-else's in C, they take up to 10 steps.
20:11:02 <shachaf> O(whatever) algorithms are my favorite, though.
20:11:18 <parcs> pattern matching isn't linear?
20:11:33 <pedro3005> kizzx2, or use switch
20:11:43 <monochrom> not sure what's "linear", but probably yes
20:12:15 <ivanm> parcs: well, I've been told that it's O(1) when I asked about my functions on data types with about 150 constructors... ;-)
20:14:09 <parcs> i once read to place more common patterns before less common ones to improve performance
20:14:29 <monochrom> sometimes I do that too
20:14:54 <monochrom> some other times I read core and find that they are re-ordered behind my back, so I don't know
20:15:22 <kizzx2> afaik the only technique (in C) to turn 100 if-then-else into O(1) is to use a jump table and that requires a pretty aggressive compiler
20:15:39 <monochrom> well, re-ordered when they are mutually exclusive, like Nothing vs Just.
20:26:57 <kizzx2> parcs: where did you read that? from a C mindset (:P) that may not improve performance, it depends on where the `jmp` is placed and taking cache locality into account
20:27:31 <ddarius> The way GHC implements pattern matching for large sums is it just enters the thunk passing all the branches of the case and the thunk will choose the appropriate one.
20:27:36 <ddarius> I.e. it is essentially a jump table.
20:28:06 <kizzx2> ddarius: doesn't the conclusion depends on how the thunk is implemented?
20:28:14 <ddarius> I'm not sure what GHC does for Ints.  In general, guards can't be optimized in this manner and superficially pattern matching on numbers just translates to a use of guards, but GHC may be smarter.
20:28:18 <kizzx2> if the thunk is implemented as a series of if-then-else.....
20:29:11 <ddarius> kizzx2: That would be completely retarded.  The thunk is a function \branch1 branch2 branch3 -> ...  all it has to do is select the branch that corresponds to that constructor, it knows which constructor it is.
20:29:51 <ddarius> If you know the concept of Church-encoding (actually Scott-encoding), that's essentially what GHC is doing.
20:31:31 <ddarius> For small sums (3 or less on 32-bit, 7 or less on 64-bit) GHC does an if-tree.
20:32:07 <kizzx2> ddarius: i'm not very theoretically adept, but did you mean that pattern matching for N patterns does not need to do N comparison, in general?
20:32:20 <kizzx2> s/comparison/comparisons/
20:32:41 <kizzx2> s/does not need to do/does not need to do, at most/
20:33:00 <ddarius> Pattern matching one level of one item against n branches does no explicit comparisons at all in the large sum case.
20:33:20 <ddarius> And presumably 2 or 3 for the small sum case.
20:34:18 <parcs> ddarius: how does pattern-match failure work?
20:34:51 <ClaudiusMaximus> @djinn (Bool, Bool) -> a -> b -> c -> d -> Either (Either a b) (Either c d)
20:34:51 <lambdabot> f (a, b) c d e _ =
20:34:51 <lambdabot>     case a of
20:34:51 <lambdabot>     False -> Left (Left c)
20:34:51 <lambdabot>     True -> case b of
20:34:51 <lambdabot>             False -> Left (Right d)
20:34:53 <lambdabot>             True -> Right (Left e)
20:34:58 <ddarius> parcs: That's just alternative of the case.
20:35:10 <ddarius> +another
20:36:29 <andares> hrm. food or haskell.
20:37:55 <jmcarthur> both
20:38:35 <ClaudiusMaximus> i used haskell to generate if-trees for dvd virtual machine once - had to split some of the trees between different menus because they were too big, and in the end the disc seek times ruined the whole effect anyway...
20:38:38 <ddarius> kizzx2: If we Scott-encode the Either type, data Either a b = Left a | Right b, the two constructors become functions left a l r = l a; right b l r = r b; then what would be case x of Left a -> f a; Right b -> g b; becomes x f g.
20:39:00 <ddarius> DVD Virtual Machine?
20:39:27 <ClaudiusMaximus> ddarius: yeah, the thing that makes buttons on menus do stuff
20:40:08 <ClaudiusMaximus> ddarius: i was abusing it to have a pseudorandom walk across a hyperbolic tiling...
20:41:44 <ClaudiusMaximus> ddarius: http://dvdauthor.sourceforge.net/doc/dvdauthor.html#AEN2085
20:46:57 <ddarius> ClaudiusMaximus: How did it help you do the pseudorandom walk?
20:48:04 * applicative is amazed to realize he is only four of the 926,312 github users
20:48:38 <ddarius> applicative: How many cell phone users are you, because it looks like we'll have more cell phones than people pretty soon.
20:49:41 <applicative> zero or one, depends whether I just laundered it again
20:50:11 <applicative> in the future many cellphones will have to share people....
20:50:51 <ClaudiusMaximus> ddarius: i had 24 cells, each with a possibility of 14 orientations; from each of those states there were some transitions (rotations and translations) to a new state
20:51:32 * ski . o O ( <http://en.wikipedia.org/wiki/24-cell> )
20:52:08 <ClaudiusMaximus> ski: hehe, not that one (it was a symmetric 24-colouring of {7,3})
20:52:42 <ski> `{7,3}' ? is that Klein's quartic ?
20:52:48 <Rotaerk> bet you can't say icositetrachoron ten times fast
20:53:12 <ClaudiusMaximus> no, it's a hyperbolic tiling with three regular heptagons about each vertex
20:53:37 <ClaudiusMaximus> (i don't know what klein's quartic is, actually - maybe it is)
20:53:48 <ddarius> Rotaerk: Once you split it properly, it's actually quite pronouncable.
20:53:55 <ddarius> Ten times is a bit excessive though.
20:53:58 <ClaudiusMaximus> but if you do want 24-cell, you can have http://claudiusmaximus.goto10.org/v/reflex/breathing-exercise.ogv
20:54:19 <ClaudiusMaximus> i can't remember if i made that one with haskell or otherwise, i can go check...
20:54:21 <ddarius> ClaudiusMaximus: My question was more, why were you doing this for the DVD Virtual Machine?
20:54:42 <ski> ClaudiusMaximus : <http://math.ucr.edu/home/baez/klein.html>,<http://en.wikipedia.org/wiki/Klein_quartic>
20:54:53 <Rotaerk> ClaudiusMaximus, that really does remind me of breathing
20:55:16 <ClaudiusMaximus> ddarius: because i wasn't aware of any other widely available platform for video supporting scripted control
20:55:43 <ClaudiusMaximus> ddarius: now there's html5 which will probably work, maybe mkv supports scripting in some variant
20:57:00 <ClaudiusMaximus> ski: interesting!  i shall have to read..
20:57:45 <kizzx2> i tried to redo the WordNumber thing using function and pattern matching, a la        (lenOnes :: Int64 -> Int64; lenOnes 0 = 0; lenOnes 1 = 3; lenOnes 2 = 3; ....} it seems that it's not doing better than (!!), for anyone interested, here' sthe new version http://ideone.com/1I05n and the .prof http://hpaste.org/49932
20:58:06 <kizzx2> i found that the "len" functions are taking quite a high amount of time
20:58:34 * ski can't recall how Schläfli symbols work ..
20:59:45 * applicative notes that the new 'wedding' package on Hackage presupposes that marriage is a relation of 'one man and one woman'
21:00:02 <ski> stable marriages ?
21:00:17 <ddarius> kizzx2: Writing !0 is redundant.
21:00:39 <kizzx2> oic
21:00:47 <kizzx2> i suspected, but put in there for assurance
21:00:50 <hatds> anyone else find themselves switching over to wikipedia instead of reading a webpage's actual "what blah.com is about" info?
21:01:00 <NihilistDandy> hatds: Yes
21:01:10 <kizzx2> http://imagebin.org/166762 because this is the -hy profile, i am tring to eliminate allocates of Int64 (which is actually _not_ that many (under 2M))
21:01:10 <applicative> ski, he suggests that you can freely upload a new version to mention your wedding.  But then he uploaded a new version a couple hours later.
21:01:13 <edwardk> applicative: clearly you need to generalize
21:01:14 * ski . o O ( <http://en.wikipedia.org/wiki/Derangement> )
21:01:46 <applicative> edwardk, yes, I think I can manage this abstraction
21:03:13 * ddarius recommends changing: solve x (0,0,1) zipped to solve x (0,0,1) (map (\n -> (n, wordLength n)) [1..])
21:03:52 <kizzx2> ddarius: lemme give it a try
21:03:55 <ski> @hackage wedding
21:03:55 <lambdabot> http://hackage.haskell.org/package/wedding
21:03:58 * applicative wonders whether he should upload a package `congratulations`, then we can each reupload it to add our own congratulations to Petr R. & Lucia
21:04:18 <ski> applicative : 404
21:04:34 <NihilistDandy> ^^
21:04:36 <ddarius> @hackage wedding-announcement
21:04:36 <lambdabot> http://hackage.haskell.org/package/wedding-announcement
21:04:37 <hpaste> applicative pasted “wedding” at http://hpaste.org/49933
21:04:45 <applicative> it prints this ^^^
21:05:16 <kizzx2> ddarius: but it seems like (from the .prof) that the bottleneck is wordLength, which i have tried for a day to squeeze and optimize but it can't seem to :(
21:05:18 * ski is disappointed this isn't a package for computing stable marriages
21:05:47 <ddarius> kizzx2: Interpreting profiling output is not trivial.
21:05:49 <edwardk> i actually thought it was when applicative described the probem =)
21:05:49 <kizzx2> ddarius: since an imperative C# naive implementation can do the thing in 1 minute (whereas Haskell takes >5 min) i must be missing something obvious
21:06:13 <applicative> haha, I'm not sure what I thought it was, before I unpacked it...
21:06:15 <ski> edwardk : i did, as well :/
21:06:34 <applicative> its under the recent Hackage heading "Facts" or Factual
21:07:30 <applicative> which has one other package realizing the states of the united states *in the typesystem*
21:07:33 <edwardk> it doesn't use nearly enough external packages to be impressive
21:07:44 <ddarius> @hackage monoid-owns  For you edwardk.  First note the sole category, then look at the source.  Admittedly, the author gives everything away.
21:07:44 <lambdabot> http://hackage.haskell.org/package/monoid-owns  For you edwardk.  First note the sole category, then look at the source.  Admittedly, the author gives everything away.
21:08:24 <edwardk> lolwut
21:08:58 <ddarius> The description is also good.
21:09:26 <edwardk> maybe he really wanted that (+)
21:09:33 <applicative> I think it's very 'practical' to import Prelude hiding (+)
21:09:50 <edwardk> applicative: to be fair, i do just that with my algebra package ;)
21:10:15 <ddarius> applicative: Hey, we can write "foo"+"bar" now.  Which is actually probably the whole reason for this package's existence.
21:10:27 * ski likes the duplicate `Monoid ByteString', there
21:10:58 <ddarius> If you are aware of Jinjing Wang's other opuses, you will understand.
21:12:29 * applicative confesses he admires his boldness
21:13:05 <ddarius> applicative: As demonstrated in this package, or in his packages overall?
21:13:15 <applicative> ski, haddock got rid of the Lazy/Strict distinction
21:13:15 <ddarius> Because this package is pretty tame for him.
21:13:29 <applicative> ddarius, overall, I've looked at some before
21:14:05 * ski is reminded of gems like <http://srfi.schemers.org/srfi-100/srfi-100.txt> and <http://srfi.schemers.org/srfi-86/srfi-86.html>
21:14:15 <applicative> he uses (.) for (backward0 function application. Kind of alarming, but legitimate.
21:14:37 <ski> applicative : yeah i know. it's still bad
21:16:43 * hackagebot mwc-random 0.10.0.0 - Fast, high quality pseudo random number generation  http://hackage.haskell.org/package/mwc-random-0.10.0.0 (BryanOSullivan)
21:19:20 <ski> (applicative : in case it wasn't clear, i meant it was bad of haddock)
21:21:42 <ddarius> ski completely appreciates (.) = flip ($)
21:21:43 * hackagebot base64-bytestring 0.1.0.3 - Fast base64 encoding and deconding for ByteStrings  http://hackage.haskell.org/package/base64-bytestring-0.1.0.3 (BryanOSullivan)
21:22:28 * cmccann is suddenly tempted to make a package that renames everything from Prelude for no obvious reason
21:22:54 <ski> ddarius : hm ?
21:23:26 <ddarius> From MPS, join = List.intercalate; join' = concat, though join isn't in the Prelude.
21:24:37 * applicative forever curses the absence of join from the Prelude.
21:24:42 * cmccann can never remember what's actually in the Prelude
21:24:56 * applicative is usually informed by the GHC
21:25:20 <cmccann> most of my projects have a module that does nothing but re-export a whole bunch of stuff not in Prelude so that I don't have to worry about it :T
21:25:25 <cmccann> ugly, but oh well
21:25:28 <ddarius> I'm somewhat amazed that a ' was too much to have the standard function not be redefined.
21:25:58 <ddarius> Though, for all I know, he completely redefines Monad somewhere.
21:26:05 <cmccann> ddarius, his new name for the standard join is interesting too
21:26:10 <hatds> is the quasi quoter for TH directly available somewhere?  i.e. the actual functions String -> Q Exp and so forth
21:26:44 <applicative> oh, cmcann, well at least he has it.  is it mu?
21:27:12 <cmccann> "squeeze"
21:27:58 * ski str <http://pleac.sourceforge.net/pleac_haskell/index.html> did `(.) = flip ($)', but it might have changed since
21:28:02 <kmc> hatds, not directly, but see haskell-src-meta
21:28:05 <cmccann> there's also a function "end = return ()" which is, er, interesting
21:29:10 <applicative> > let squeeze = join in squeeze (chr <$> [1..10])
21:29:10 * ski has a few times used `done = return ()', just because it looks cute
21:29:10 <lambdabot>   Couldn't match expected type `m a'
21:29:10 <lambdabot>         against inferred type `GHC.Types...
21:29:11 <ddarius> ski: The original one was like that.  I suspect it was written by Jinjing, but then a new, more idiomatic one was made.
21:29:29 <cmccann> ahahaha "don't :: (Monad m) => m a -> m ()"
21:29:33 <sshc> How does setting "default-language" to @Haskell2010@ affect Cabal's behaviour when invoking GHC?
21:29:35 <ddarius> ski: http://pleac.sourceforge.net/pleac_haskell-on-steroids/index.html
21:29:55 <ski> cmccann : don't = const done  -- ? :)
21:30:09 <cmccann> ski, not written as such but yes, that's what it does
21:31:02 <ski> ddarius : great ! that's more like it :)
21:31:25 <ddarius> Basically, Jinjing and the PLEAC person for some crazy reason want Haskell to look like Ruby.
21:31:47 <cmccann> ahahahaha "isn't = is_not"
21:32:01 <cmccann> where "is_not a b = not (is a b)" of course
21:32:09 <applicative> there are plenty of objections, of course, but it does bring out that most of the operators are just defined functions, which is worth emphasizing again and again
21:32:31 <cmccann> and "is = eq" and "eq = flip (==)"
21:32:41 <cmccann> ...why the flip is there I have no idea
21:32:58 <applicative> if there was a bit more scope for this, it might be that some of the objections people have could be overcome, as with 'you dont have to use camel case' etc
21:33:03 <cmccann> I don't know, it's oddly charming in a way. I actually like that this sort of thing is possible in Haskell.
21:33:13 <ski> cmccann : wait, are you quoting actual code !?
21:33:23 <cmccann> https://github.com/nfjinjing/air/blob/master/src/Air/Light.hs
21:33:32 <ski> i mean, like someone has actually written ?
21:33:40 <cmccann> ski, yes, I just linked to it
21:33:41 <ddarius> You've not heard of Jinjing?
21:33:55 <ski> not before now
21:34:27 <ddarius> Here's a good one: f - x = f x
21:34:29 <ski> though it reminded me of a certain ChurlSoo in the Scheme world
21:34:48 <cmccann> ddarius, I didn't realize at first that this was trying to look like Ruby, which I guess makes some of this make more sense... sort of.
21:34:56 <ski> cmccann : i thought you were just fooling around ..
21:35:06 <Nisstyre> What is scheduleWaitThread () ?
21:35:07 <cmccann> yeah, he's using - in place of standard ($)
21:35:09 <applicative> he has an eccentric style. Its actually kind of interesting.
21:35:27 <applicative> he calls one of his libraries ''OO in haskell"
21:35:36 <ski> (cf. the two SRFI links i mentioned above)
21:35:50 <ddarius> And (<->) in place of (-).
21:36:19 <ddarius> I hope this is a typo: ninth = at 8; tenth = at 10
21:36:24 <cmccann> I like how apparently he felt function composition deserved > and < rather than comparison functions
21:36:27 <applicative> euler_1 = ( [3,6..999] ++ [5,10..999] ).unique.sum
21:36:35 <kmc> buh
21:36:35 <ddarius> (Note eigth = at 7)
21:36:41 <ddarius> +h
21:36:43 * hackagebot llvm 0.10.0.0 - Bindings to the LLVM compiler toolkit.  http://hackage.haskell.org/package/llvm-0.10.0.0 (BryanOSullivan)
21:36:59 <ski> ddarius : naturally
21:37:02 <applicative> cmcann, yes a lot of the decisions are not at all bad if you think of everything being done from scratch
21:37:03 <ddarius> Maybe ruby does it that way.  I wouldn't put it past the Ruby people.
21:39:07 <applicative> it is a bit much that the Prelude takes both > and < and =< and >=
21:39:45 <sshc> In ghci, how do I print the information that the default prompt ("%s> ") displays?
21:39:57 <ski> applicative : well, actually it takes `<=', not `=<' (which it *ought* to take, mumble Prolog grumble)
21:40:09 <edwardk> applicative: how dare they ;)
21:40:09 <ddarius> applicative: While they are not completely insane from an ab initio perspective (and not just "no Haskell"), I still would not say that "a lot of the decisions are not at all bad."
21:40:51 <ddarius> Yeah really, why would you want to follow a mnemonic, convention merely a few hundred years old?
21:41:11 * applicative might have been going too far there.
21:41:14 <cmccann> forget the past, this is the future
21:41:39 * ski wonders what sshc means
21:41:43 * hackagebot riak 0.6.0.1 - A Haskell client for the Riak decentralized data store  http://hackage.haskell.org/package/riak-0.6.0.1 (BryanOSullivan)
21:41:57 <applicative> ski, sorry, automatic typing -- shows how often I use <=
21:42:40 <ski> applicative : also says something about the choice between `<=' and `=<', imo :)
21:43:29 <applicative> ski, actually that's right, I agree.
21:43:32 <ski> cmccann : *nod*, let's ignore all the centuries of starting to count from one, counting from zero is more natural
21:43:41 * applicative doesn't want to study Prolog though
21:43:43 * ddarius notes that he uses (P.<) several times in that package but never uses (<).
21:44:08 <cmccann> ski, perhaps a compromise, namely counting from 0.5
21:44:17 <ski> applicative : the only relevant thing here is that Prolog uses `>=' and `=<', instead of `>=' and `<='
21:44:21 <ddarius> He also doesn't seem to alias the comparison operators, so I guess you just have to import Prelude qualified.
21:44:27 <sshc> ski: "%s" in prompt seems to expand to a list of all the modules that are loaded (and files that were loaded with :l?).  How do I print this information?
21:44:31 <ddarius> Admittedly, he doesn't ever use P.> and he does use >.
21:45:12 <ski> (applicative : thus leaving `<=' and `=>' to be defined by the user, should she so wish)
21:45:22 <applicative> ski, yes, i grasp that. but isnt the choice of signs for the operators basically what language designers do?
21:45:34 <ddarius> ski: Zero is more natural.
21:45:47 <ski> ddarius : of course it is
21:45:55 <NihilistDandy> tee hee
21:45:56 * ski says with a straight face
21:46:30 <NihilistDandy> Naturals SSSS0 life, yo
21:46:43 * hackagebot trifecta 0.4 - Parser combinators with slicing and diagnostic support  http://hackage.haskell.org/package/trifecta-0.4 (EdwardKmett)
21:46:53 * ddarius isn't sure what was wrong with ($) that (-) improves upon.
21:47:08 * applicative proves the infinity of the numbers to children by starting counting with zero and asking how many numbers he's said so far
21:47:09 <ski> applicative : yes -- as long as they choose the correct alternative ;)
21:47:44 * ski has tried to convince brother about starting to count from zero, hasn't succeeded :/
21:47:49 <ddarius> I don't think he uses ($) for something else, so he's just ignoring a valuable single character operator to stomp on a very valuable single character operator.
21:48:01 <applicative> no, someone says zero, then at each stage we ask "How many numbers have we mentioned?"
21:48:06 <ski> (and this one is a hobby mathematician, so some extent)
21:48:16 <NihilistDandy> applicative: I prove the infinity of numbers to children by a rigorous treatment of real analysis. Needless to say, I'm not allowed to babysit, anymore
21:48:31 <edwardk> finally fixed the bug in the handling of injected line directives. now to get back to diagnostics
21:48:32 <mustelo> ha
21:49:01 <ddarius> NihilistDandy: Of course not filling their heads with lies about "real" numbers.
21:49:20 <NihilistDandy> Perish the thought
21:49:49 <NihilistDandy> I need to come up with more Peano puns
21:50:16 <NihilistDandy> There just aren't many words in English that sound like numbers.
21:50:25 <NihilistDandy> Well, I guess there are infinite such words
21:50:27 <NihilistDandy> But still
21:50:36 <ddarius> I'll tell my non-existent child, "You know that Santa Claus the other kids talk about?  He's not real; those kids are dumb.  Also, those 'real' numbers.  More bologna."
21:51:01 <edwardk> ddarius++
21:51:11 <NihilistDandy> ddarius: I hope you'll pronounce it "bo-lo-nya", too
21:51:18 <NihilistDandy> Get that out there in the beginning
21:51:26 * ski . o O ( Bologna process ? )
21:51:38 <edwardk> coz that won't get your kid beat up at lunch ;)
21:51:51 <ddarius> My kids will never be beat up at lunch.
21:52:01 <djahandarie> Because he will be trained in various martial arts.
21:52:01 <ski> you won't have any ?
21:52:27 <NihilistDandy> edwardk: My kids will be busy introducing their detractors to unsafePerformIO, if you follow me :D
21:52:40 <ddarius> djahandarie: Probably.  ski: Probably.  But you are both wrong as to the intended reason.
21:52:47 <NihilistDandy> Perhaps a bit of unsafeCoerce for good measure
21:52:58 <djahandarie> Because he won't have any lunch?
21:53:00 <pikhq_> Because he won't be public schooled?
21:53:07 <NihilistDandy> ddarius: Your kids will be AIs
21:53:09 * ski idly wonders what his intended reason was
21:53:14 <ddarius> NihilistDandy: Oh god no.
21:53:17 <ddarius> I hate computers.
21:53:28 <djahandarie> Join copumpkin in your hate
21:53:29 <NihilistDandy> Beep blorp, I less than three you, father
21:53:34 <pikhq_> Strange place to be for a computer-hater.
21:53:40 <copumpkin> yeah, I hate them too
21:53:43 <copumpkin> I put up with them though
21:53:46 <NihilistDandy> pikhq_: All programmers hate computers
21:53:52 <NihilistDandy> That's why we bend them to our will
21:54:30 <ddarius> ski: There's just something about people in my family that gives off a vibe such that such things do not happen.
21:54:52 <ddarius> NihilistDandy: You would think the non-programmer users would get the hint from programmers...
21:55:06 <NihilistDandy> ddarius: They never learn~
21:55:08 <djahandarie> ddarius, is there also a "mug me" vibe?
21:55:29 <ddarius> djahandarie: Perhaps.
21:55:43 <ddarius> djahandarie: I didn't say they wouldn't get mugged at lunch.
21:55:56 <NihilistDandy> Maybe regular users are just functioning rage-o-holics
21:55:58 <ski> ddarius : well ok. you certainly radiate a "no nonsense" aura, and i assume it could be inherited
21:56:02 <pikhq_> NihilistDandy: I love computers. I'm just a dominatrix to them. :P
21:56:08 <NihilistDandy> I CAN'T LIVE WITHOUT RAGEOHOL
21:57:03 * ddarius idly wonders what hydrocarbon complex that hydroxyl group is bound to.
21:58:38 <NihilistDandy> ddarius: FFFFFFFFFUUUUUUUUUUUCCCCCCC
21:58:48 <NihilistDandy> (nonstandard notation)
21:58:55 <NihilistDandy> *KKKKKK
21:59:00 <NihilistDandy> Wait, never mind
21:59:06 <NihilistDandy> Krypton is noble
21:59:08 <ski> (is that uranium ?
21:59:12 <ski> )
21:59:25 <NihilistDandy> Fluorine, Uranium, Carbon
21:59:30 <edwardk> f7u12
21:59:57 <NihilistDandy> I suppose I should have found a way to add the necessary hydrogen in, too
22:00:10 <NihilistDandy> Oh, well~
22:00:14 <edwardk> putting the -oh on there kinda mucks it up though
22:00:32 <ski> it might be a free radical in space ?
22:00:55 <sshc> -XNoImplicitPrelude seems to have no effect with ghci 7.0.2.  I *don't* want Prelude to be imported!  (I need . to unambiguously refer to Control.Category..).
22:01:17 <ddarius> sshc: NoImplicitPrelude doesn't make the Prelude not be imported.  You can do that without an extension.
22:01:21 <ski> sshc : `import Prelude ()' ?
22:01:28 <edwardk> maybe you read it backwards oh-fffffffuuuuuuuuuuuuu
22:01:50 <sshc> ski: Everything in Prelude is still imported.
22:01:57 * applicative joins the chorus of computer haters.
22:02:01 <sshc> ddarius: Really?  How?
22:02:05 <ski> sshc : "How do I print this information?" -- i'm not sure, doesn't your prompt print it for you automatically ?
22:02:12 <ddarius> sshc: By doing what ski said.
22:02:12 <NihilistDandy> edwardk: That'd do it
22:02:35 <edwardk> it doesn't sound very stable
22:02:40 <sshc> ddarius: Placing that in ghci seemed to have no effect
22:02:54 <ddarius> sshc: That's because the report doesn't talk about GHCi.
22:03:02 <ddarius> Though I guess you did say GHCi.
22:03:07 <ddarius> Check the docs.
22:03:18 <applicative> wait, maybe we should just add a  Congratulations.hs module to Petr R.'s wedding package.
22:03:25 <ddarius> Maybe :m -Prelude ?
22:03:45 <ddarius> Yep.  That seems to work.
22:03:47 <sshc> ddarius: Yes!  Thatk did it.  Thanks!
22:04:04 * applicative preens himself on his limitless ascii art talents
22:04:19 <ddarius> applicative: Unbounded below or above?
22:04:22 <cmccann> sshc, I think GHCi's Prelude import is independent of the modules being loaded
22:04:58 <ddarius> So -XNoImplicitPrelude and :m -Prelude should produce an interesting result.
22:05:11 <m0ltresse> hi
22:05:19 <xenocryst> hello!
22:05:38 <NihilistDandy> Hi
22:05:48 <ski> > 2
22:05:48 <ski> <interactive>:1:0: Not in scope: `fromInteger'
22:05:48 <ski> <interactive>:1:0: Not in scope: `>>'
22:05:49 <lambdabot>   2
22:05:52 <cmccann> or at least, GHCi's implicit Prelude is independent, you have to do :set -XNoImplicitPrelude for that, or when starting GHCi
22:06:03 <ski> ddarius : indeed
22:06:19 <ddarius> The Not in scope >> is golden.
22:06:51 <cmccann> ddarius, yes, that's always fun
22:07:20 <cmccann> makes it pretty hard to forget what you're doing at any rate
22:07:52 * applicative is refactoring 'wedding-announcement-0.1' to fit with the future use intended and with the Hierarchical Module System.
22:07:53 <djahandarie> Where does that come from?
22:08:03 <ddarius> djahandarie: GHCi is a do-block (roughly)
22:08:36 * applicative makes Wedding.Petr.Lucia in anticipation of other modules in Wedding.Petr
22:08:50 <ddarius> Not Wedding.Lucia.Petr?
22:09:19 <djahandarie> ddarius, so it would only happen if it was not the first thing you entered?
22:09:36 <ddarius> djahandarie: ?
22:09:57 <applicative> ddarius, I was thinking of that as an objection to the Heirarchical Module System. It's out and out patriarchy'.
22:10:00 <djahandarie> I'm just wondering what strange desugaring would need to be used for "2" to involve >>
22:10:21 <ski>   do <ghci-command>; <ghci-command>; ...
22:10:30 <applicative> ddarius, in ML this wouldn't problem, what with first class modules and all
22:10:48 <djahandarie> Right -- so it would only give that error if it was the second thing involved, right? Because you wouldn't need >> if you have only entered one command. Or something.
22:10:53 <ski> applicative : how would that help ?
22:10:54 <djahandarie> I can't replicate that to test it for whatever reason
22:11:13 <ddarius> applicative: Go back to your +.ing ilk.
22:11:33 <ski> djahandarie : you need to call `(>>)' on the first command and the action representing all the future commands
22:11:43 <djahandarie> Ah, alright.
22:11:43 <ddarius> djahandarie: It does bind the value to it.
22:11:53 <ddarius> 'it'
22:12:13 <applicative> ski, not sure I was thinking I'd have a signature LuciaWedding and Petrwedding and then somehow make something that fit both?
22:12:20 <djahandarie> Hmm, I'd expect an error involving >>= in that case
22:12:37 <djahandarie> But ski's explanation makes sense
22:13:19 <ddarius> djahandarie: It would presumably use let in the value case.
22:13:35 * ski recalls being able to say (roughly) `?- my_module --o rppl.' in lolli
22:13:37 <ddarius> If ski types just... uh...
22:13:56 * ddarius wishes LolliMon was a real implementation.
22:14:04 <ddarius> Or Celf.
22:14:15 * ddarius should check in on Celf again.
22:14:24 <ski> (`rppl' being another instance of a read-prove-print-loop, and `my_module --o' would temporarily assume the clauses in that module for the duration of the `rppl' call)
22:14:43 <ski> ddarius : .. if i type just what ?
22:15:09 <ddarius> Something that would be interpreted as an IO action, but none should be in scope.  In fact, IO shouldn't be in scope.
22:17:01 <ddarius> Hmm...
22:17:46 <ski> ddarius : the implementation i've tried is <http://www.cs.cmu.edu/~fp/courses/98-linear/lolli.html> ..
22:17:56 <hydo> any idea of an ETA on the impending large snap release?  The reason I ask is that I want to write in support for mongrel2, but it dawned on me that it might not be a good idea to start that if the snap guts are being reworked.
22:18:26 <hydo> damnit.
22:18:40 <hydo> thought I was in snap.  hurf.
22:19:18 <ddarius> Lolli /= LolliMon, though I'm pretty sure Lolli's implementation isn't practical either.
22:19:44 <ski> well, it's a tree interpreter in SML, iirc
22:20:01 <ski> (i remember i hacked it up a little)
22:23:07 <ski> (oh, actually i didn't, i only thought of doing it. i did hack Terzo (lambdaProlog) a little, though)
22:23:36 <ddarius> "Terzo"?
22:27:25 <ski> ddarius : <http://www.lix.polytechnique.fr/Labo/Dale.Miller/lProlog/terzo/index.html>
22:27:41 <ddarius> ski: Which GHC do you have?
22:29:03 <ski> did the above in 6.12.3, why ?
22:30:54 <ski> Celf is some ELF variant or implementation ?
22:32:23 <ddarius> Celf is an implement of CLF.
22:32:34 <ddarius> ski: How did you call GHCi?
22:33:07 <ddarius> I guess they changed it in 7.0.1.
22:33:13 <ddarius> Don't know about 7.2.
22:33:16 <ski>   $ ghci -XNoImplicitPrelude
22:34:30 <ddarius> Yeah, that doesn't produce entertaining behavior in 7.0.1, but "works" in 6.12.1.
22:34:56 <ski> "Celf - A concurrent logical framework" <http://twelf.org/~celf/>
22:35:05 <ski> haven't seen that before
22:35:17 <ddarius> It's fairly new.
22:36:43 <ski> recently i got MetaML to build
22:36:58 <ski> i'm pondering hacking in some modifications
22:37:09 <ddarius> MetaOCaml seemed more interesting, though they probably included those changes in MetaML.
22:37:43 <ddarius> I want to find a particular paper talking about a MetaML-like system using a more detailed modal logic.
22:37:44 <ski> i dunno what the differences between MetaML and MetaOCaml are (apart from being for ML resp. OCaml, of course)
22:38:38 <ski> afaik, MetaML stopped being updated a long time ago -- i couldn't find sources anywhere on the web, but found i had them sitting on my disk
22:39:19 <ski> a particular paper you've seen before -- or one you're wishing exists ?
22:39:46 <ddarius> The former.
22:40:03 <ddarius> It was relatively new.  Like four or so years ago.
22:40:52 * ski rewrote a (very simple) pattern-compiler in MetaML to use delimited continuations, instead of nqCPS -- worked fine
22:42:05 <ski> i was however pondering how to be able to compute not just expressions, but also patterns and declarations, so you could splice computed such into larger terms
22:43:53 <ski> ddarius : hm, what kind of modal logic ?
22:44:08 <ski> one talking also about open expressions ?
22:45:19 * ski vaguely recalls reading some papers about using modal logic for typing computations with open and closed expressions
22:48:29 <ddarius> ski: A more or less straightforward extension of the typical one.
22:52:42 * ski wonders where he found "\"One-Day Compilers\"  or  How I learned to stop worrying and love static metaprogramming" <http://www.venge.net/graydon/talks/mkc/html/index.html>
22:58:53 <sohum> @pl \m -> return . (foo m)
22:58:53 <lambdabot> (return .) . foo
22:59:12 <ski>   return .: foo
22:59:41 <kizzx2> what's a 10-thousand feet overview of "ST vs State"?
23:00:11 <coppro> :t (.:)
23:00:12 <lambdabot> forall a b (f :: * -> *) (g :: * -> *). (Functor f, Functor g) => (a -> b) -> f (g a) -> f (g b)
23:00:15 <edwardk> State is just a function that takes an s and gives you an answer and a new s
23:00:29 <edwardk> ST is magic that lets you locally program with side-effects
23:00:37 <edwardk> @unmtl State s a
23:00:38 <lambdabot> s -> (a, s)
23:01:27 <edwardk> ST is like a 'local version of IO' where you can program with references, arrays, etc. as long as nobody can do anything with them after you're done
23:01:28 <sohum> @hoogle .:
23:01:28 <lambdabot> No results found
23:01:41 <coppro> @hoogle (.:)
23:01:41 <lambdabot> No results found
23:01:50 <edwardk> @type (.).(.)
23:01:51 <lambdabot> forall (f :: * -> *) a b (f1 :: * -> *). (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
23:01:58 <kizzx2> edwardk: "real" side effects as in in place update of a value?
23:02:03 <ski> kizzx2 : yes
23:02:15 <edwardk> kizzx2: yes. you have STRefs you can mutate, STArrays you can mutate, etc.
23:02:27 <kizzx2> that seems handy
23:02:35 <ski> kizzx2 : more precisely, updates of the mutable cells which `STRef s a's and `STArray s i a's refer to
23:03:00 <ddarius> State gives you exactly one "mutable" cell.
23:03:05 <kizzx2> yes, now i think i understand the difference is that the "put" in State is actually not mutating anything but putting in a new value
23:03:19 <kizzx2> so seems like ST can be used for performance squeezing scenarios
23:03:29 <ski> @type Control.Monad.ST.runST
23:03:30 <lambdabot> forall a. (forall s. ST s a) -> a
23:03:31 <ski> @type Data.Array.ST.runSTArray
23:03:31 <lambdabot> forall i e. (Ix i) => (forall s. ST s (GHC.Arr.STArray s i e)) -> Array i e
23:03:33 <ski> @type Data.Array.ST.runSTUArray
23:03:34 <lambdabot> forall i e. (Ix i) => (forall s. ST s (Data.Array.Base.STUArray s i e)) -> Data.Array.Base.UArray i e
23:04:00 <edwardk> put s = \ _ -> ((), s)  is basically what State does in response to put
23:04:12 <edwardk> and get = \s -> (s, s)
23:04:24 <coppro> yeah, State is just a newtype around (a, s)
23:04:25 <edwardk> (though there are newtype wrappers involved)
23:04:37 <edwardk> coppro: around s -> (a, s)
23:04:43 <coppro> edwardk: err, sorry :)
23:04:47 <ski>   runState (put s1) _s0 = ((),s1)
23:04:57 <ski>   runState get s = (s,s)
23:05:02 <coppro> Understanding the State monad is really easy if you understand the ((->) r) monad
23:05:15 <kizzx2> so would it be correct as an executive summary?    State is for general structuring where functions want to get and put state; ST is usually used when you want to locally implement "imperative algorithms" for whatever reason
23:05:17 * ski wishes (something like) that would be valid syntax
23:06:02 <kizzx2> s/where.../where functions want to get and put a shared state/
23:06:15 <coppro> I don't really like the notion of 'get' and 'put', but sure
23:06:24 <ski> kizzx2 : `State s' can also be used for "locally implement imperative algorithms", i suppse
23:06:42 * hackagebot wl-pprint-extras 1.2.1 - A free monad based on the Wadler/Leijen pretty printer  http://hackage.haskell.org/package/wl-pprint-extras-1.2.1 (EdwardKmett)
23:06:46 <kizzx2> ski: umm i think for that purpose ST is strictly more appropriate because it does in place updates?
23:06:55 <edwardk> kizzx2: yes
23:07:12 <edwardk> kizzx2: yes (regarding the executive summary)
23:07:18 <kizzx2> thanks :)
23:07:27 <ski> kizzx2 : the difference with `ST s' is (a) it allows dynamically allocating new cells (of any type you want); and (b) it's expected that it uses in-place mutation
23:07:48 <ddarius> newtype State s a = State (forall st. ReaderT (STRef st) (ST st) a); runState (State m) s = runST (newSTRef s >>= runReader m); put x = State (do ref <- ask; writeSTRef ref x); get = State (do ref <- ask; readSTRef ref x)
23:08:09 <edwardk> ddarius: =P
23:08:27 <kizzx2> ddarius: o :P
23:08:47 <ddarius> s/runReader/runReaderT/
23:09:41 <ski> kizzx2 : fyi, Mercury also has (basically) `ST' <http://www.mercury.csse.unimelb.edu.au/information/doc-latest/mercury_library/store.html>
23:09:43 <ddarius> Unfortunately, you can't make StateT that way.
23:10:08 <ddarius> s/STRef st/STRef st s/
23:11:41 <copumpkin> ಠ_ಠ
23:11:44 * ski . o O ( `StateTM :: * -> ((* -> *) -> (* -> *)) -> (* -> *)' )
23:12:07 <kizzx2> ski: o this is the first time i heard about Mercury
23:12:26 <ddarius> ski: Something that will transform ST providing the base for StateTM to work over?
23:12:45 <ddarius> kizzx2: Don't worry.  You can forget about it.
23:12:58 <kizzx2> lol
23:13:24 <ski> ddarius : yeah i was thinking `newtype StateTM s t a = MkStateTM (forall st. ReaderT (STRef st s) (t (ST st)) a)'
23:14:29 <ski> so it's a transformer transforming monad transformers into monads
23:15:01 <kizzx2> omg why do haskell ppl like to make it so twisted lol :P
23:15:21 <ski> huh .. what's twisted, here ?
23:15:43 <kizzx2> just a newbie rambling, forget about it :P
23:16:26 <roconnor> is there a unicode symbol for supercript * ?
23:17:17 <roconnor> or is * already superscript *?
23:17:18 <ski> roconnor : in Agda input-method ?
23:21:37 <ski> oops
23:21:58 <sohum> @pl \p -> foo (bar m (f p)
23:21:58 <lambdabot> (line 1, column 23):
23:21:58 <lambdabot> unexpected end of input
23:21:58 <lambdabot> expecting variable, "(", operator or ")"
23:22:03 <sohum> @pl \p -> foo (bar m (f p))
23:22:03 <lambdabot> foo . bar m . f
23:22:57 <sohum> @pl \f -> ask >>= (return . foo m . f)
23:22:57 <lambdabot> (`fmap` ask) . (foo m .)
23:23:04 <sohum> @pl \m f -> ask >>= (return . foo m . f)
23:23:04 <lambdabot> (((ask >>=) . (return .)) .) . (.) . foo
23:23:10 <sohum> ew and ew
23:23:24 * ski guesses he shouldn't `diff' two files containing logs of all changes made to a terminal running a curses-based application
23:24:16 <ski> sohum :   barf >>= return . frob  =  return . frob =<< barf  =  liftM frob barf
23:24:48 <sohum> oh, right
23:25:50 <sohum> I knew the >>= return pattern looked weird
23:27:14 <ddarius> It should look like liftM/fmap.
23:27:38 <sohum> mmhm!
23:58:44 <copumpkin> http://www.reddit.com/r/haskell/comments/jarp0/hi_guys_i_made_a_haskell_to_clojure_translator/c2ajzqx
23:58:47 <copumpkin> ಠ_ಠ
23:59:32 <shachaf> copumpkin: Wow, I've never heard *that* one before.
23:59:45 <copumpkin> I don't even know what to say to that
