00:00:32 <EvanR> or pipes / conduits / iteratees o my
00:00:40 <opqdonut> or just spell it out:
00:01:41 <opqdonut> consume :: Handle -> IO (); consume h = do eof <- hIsEof h; if h then (return ()) else (do hGetChar h; consume h)
00:02:15 <opqdonut> once you can handle writing that, you can star boiling it down via guard or untilM or any of the other monad utilities
00:02:29 <opqdonut> err should be "if eof" not "if h"
00:04:14 <shanemikel> or I can use sequence with a regular map
00:05:03 <shanemikel> oh.. hGetLine throws at EOF
00:05:46 <opqdonut> yeah hard to use map/sequence/mapM since you don't know when to stop
00:06:08 <opqdonut> you can of course write your own getLine :: Handle -> IO (Maybe String), but that doesn't help you in stopping
00:07:38 * hackagebot ghcid 0.6.4 - GHCi based bare bones IDE  https://hackage.haskell.org/package/ghcid-0.6.4 (NeilMitchell)
00:07:38 * hackagebot hmatrix-quadprogpp 0.3.0.0 - Bindings to the QuadProg++ quadratic programming library  https://hackage.haskell.org/package/hmatrix-quadprogpp-0.3.0.0 (AkioTakano)
00:07:53 <shanemikel> opqdonut: I've read much about haskell being the best imperative language, but for every person saying that, there are 10 that say it's trash
00:08:30 <EvanR> shanemikel: map and sequence dont make much sense
00:08:33 <shanemikel> I've experienced much of it's greatness, but I haven't done a whole lot of more complicated IO
00:08:49 <EvanR> those assume you have a list already
00:09:12 <EvanR> shanemikel: the deal is that you can write a combinator to do whatever the IO strategy you want is
00:09:33 <shanemikel> Sure.  Not that this is complicated by any means..
00:09:33 <EvanR> the fact that theres not much "built in" is kind of unfortunate, but i dont have a better idea of what it woudl be
00:11:01 <shanemikel> Okay.  I appreciate y'all helping me through my latest existential crisis
00:11:19 <EvanR> if i had to choose between language with abstract powers and crap language with a million builtins for things...
00:11:29 <EvanR> abstraction powers*
00:12:30 <shanemikel> I wonder why so many people claim false things about haskell
00:12:55 <simpson> shanemikel: Haskell is polarizing for some reason.
00:14:17 <shanemikel> so, was everything in the vein of readFile (lazy mapping) before IO monad/
00:14:49 <EvanR> IO was based on lazy lists at one point
00:15:01 <EvanR> i dont know the hysterical raisens behind readFile
00:16:54 <shanemikel> I can live with it.  I can see there may be idiomatic uses of it.. It certainly makes sense for certain "files" like stdin (in simple cases).. but It really gives ammo to naysayers and scared the hell out of me
00:18:29 <EvanR> shanemikel: there is a technique to use lazy IO to do "quick and dirty" things without much memory
00:18:58 <EvanR> but i wish it was a thing in a standard module somewhere and a strict readFile was the default
00:19:00 <shanemikel> sure
00:19:11 <shanemikel> I agree
00:19:44 <vlatkoB> Is there a func like this?
00:19:44 <vlatkoB> xx :: (Monad m,Functor f) => (a -> b) -> m (f a) -> m (f b)
00:19:44 <vlatkoB> xx f ma = fmap f <$> ma
00:19:46 <EvanR> the number of "stupid tricks" like lazy IO that crop in other languages is outnumbering in my experience
00:20:18 <shanemikel> like?
00:20:19 <EvanR> and in those contexts its considered cool and normal
00:20:54 <shanemikel> well, you don't need to answer that
00:21:03 <EvanR> javascript callback hell, javascript promise chains, javascript generators
00:21:13 <shanemikel> I know plenty of stupid tricks.. In fact, I didn't gnow anything but until I discovered haskell
00:21:20 <EvanR> call with current continuation
00:21:45 <shanemikel> multiple inheritance
00:21:48 <EvanR> ruby runtime replacement
00:21:48 <shanemikel> lol
00:21:57 <EvanR> oh basiclly everything
00:22:14 <EvanR> all of C++
00:24:50 <opqdonut> vlatkoB: that's called (fmap.fmap)
00:25:23 <opqdonut> > (fmap.fmap) (+1) [Just 1]
00:25:26 <lambdabot>  [Just 2]
00:26:20 <EvanR> :t fmap `fmap` fmap
00:26:22 <lambdabot> (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
00:26:39 <opqdonut> or that
00:26:42 <opqdonut> aka:
00:26:44 <opqdonut> :t fmap fmap fmap
00:26:45 <lambdabot> (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
00:27:03 <EvanR> :t let \f -> f f f in f fmap
00:27:04 <lambdabot> parse error on input ‘in’
00:27:20 <shanemikel> EvanR: I think you mentioned shen the other day. have you heard of pixie?
00:27:25 <EvanR> :t let tri f = f f f in f fmap
00:27:26 <lambdabot>     Occurs check: cannot construct the infinite type:
00:27:26 <lambdabot>       t2 ~ t2 -> t3 -> t1
00:27:26 <lambdabot>     Relevant bindings include
00:27:33 <EvanR> nope
00:27:34 <opqdonut> sorry :)
00:27:39 <EvanR> :t let tri f = f f f in tri fmap
00:27:40 <lambdabot>     Occurs check: cannot construct the infinite type:
00:27:40 <phadej> fmap.fmap is "lensy" approach, works with Traversable too
00:27:40 <lambdabot>       t1 ~ t1 -> t2 -> t
00:27:40 <lambdabot>     Relevant bindings include
00:28:08 <phadej> EvanR: you need explitit type annotation for that
00:28:20 <EvanR> i think it cant be done
00:28:31 <EvanR> f has 1 type, fmap has 3
00:28:54 <opqdonut> you can do it with a general enough type annotation
00:30:19 <vlatkoB> so, no. Thanks.
00:30:38 <opqdonut> :t (\(f :: forall a b f. Functor f => (a -> b) -> f a -> f b) -> f f f) fmap -- EvanR, phadej
00:30:39 <lambdabot> (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
00:30:45 <opqdonut> that's pretty boring of course
00:31:06 <opqdonut> generalizing the signature of f is left as an exercise to the reader
00:31:09 <EvanR> jeebus
00:31:30 <opqdonut> (I'm just basically saying f has the type of fmap, i.e. f is fmap)
00:31:30 <phadej> EvanR: GHC cannot infer higher-rank types
00:32:10 <EvanR> ah right, its high ranked because its still polymorphic after you apply it
00:32:35 <phadej> yep
00:35:10 <Diatta> I'm trying to declare a function in ghci with a type def and tried doing multi line with :set +m but it isn't accepting my code, is there any way to do this.  http://pastebin.com/KSrm2Mxy
00:36:43 <phadej> Diatta: I'rather
00:36:44 <phadej> let { factorial :: Integer -> Integer; factorial n = product [1..n] }
00:37:23 <Diatta> phadej: got it thanks, makes sense.
00:38:20 <Axman6> the curley brackets aren't necessary btw, only the semicolon
00:39:36 <Diatta> Axeman6: I just tried both, thanks for the info.
00:45:03 <phadej> Axman6: it's merely a hint to the reader, "there are more then one thing on this line"
00:50:45 <Diatta> that makes sense too
00:54:24 <koz_> Is there a way I can get backtraces out of a Haskell execution? I'm trying to figure out where a (!!) is being used, since my code doesn't use it anywhere directly.
00:55:44 <opqdonut> there's the ghci debugger which is pretty nice
00:56:02 <opqdonut> but at first it'll feel weird if you're used to imperative debuggers
00:56:45 <koz_> opqdonut: There's a nontrivial amount of state I would have to set up to replicate this.
00:56:59 <koz_> Hence why I want a backtrace from the (!!) causing an explosion.
00:57:24 <opqdonut> koz_: open your app in ghci, set breakpoint, call main?
00:57:32 <koz_> That easy, huh?
00:57:34 <koz_> OK
00:57:39 <opqdonut> other than that there are no actual backtraces
00:57:50 <opqdonut> you'd have to resort to manual Debug.Trace invocations
00:57:59 <koz_> How would I set a breakpoint in GHCi?
00:58:36 <opqdonut> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci-debugger.html
00:58:56 <opqdonut> :break Module 123
00:59:22 <koz_> Where 123 is the line?
01:00:15 <opqdonut> yeah
01:00:19 <opqdonut> or :break functionName
01:00:27 <koz_> opqdonut: Thanks very much - I'll give it a go.
01:00:32 <opqdonut> good luck
01:01:07 <koz_> opqdonut: I may well need it...
01:30:36 <merijn> @remember shapr IoT - Internet of TERROR
01:30:37 <lambdabot> I will never forget.
01:51:34 <jakub> My code https://goo.gl/enXAFX compiles fine with ghc-8 but fails to compile with ghc-7.10 with http://pastebin.com/DdY1rUBB. The used packages have the same versions (except base obviously): mtl 2.2.1, transformers 0.5.2, lens 4.14, zippers 0.2
01:52:04 <jakub> any idea what might be causing it?
01:56:53 <jacereda> I need to apply a function (gshow) to a deeply nested field in a record specified by its 'path', understanding that 'path' as a [String] with all the field names leading to that field... Any hint?
01:58:52 <jacereda> I think I need Data.Data instance for my record and syb, but I'm having a hard time understanding syb...
02:01:27 <jacereda> Also, if uniplate is a better answer let me know, I might try with that instead
02:20:15 <jacereda> I came up with this, don't know if there's a better/faster way... http://lpaste.net/2996673191511851008 
02:41:40 <bernalex> anyone using evil-mode with ghc-mod? how do you jump to the next error?
02:45:29 <bernalex> also, is haskell-mode's type stuff supposed to not be very good? saying that f x y = x + y is a -> a -> a is more than slightly inadequate.
02:46:43 <Wolf> Hello there
02:46:49 <Wolf> Can somebody help me with homework
02:47:00 <Wolf> For some reason my code gives stack overflow
02:47:33 <Guest40988> bintonum :: Integer -> Integer bintonum x = btonCalc x 1 btonCalc :: Integer -> Integer -> Integer btonCalc x y      | x `mod` 10 == 1 = (btonCalc (x `div` 10) (y+1) + power 2 (y-1))                   | otherwise = btonCalc (x `div` 10) (y-1) power :: Integer -> Integer -> Integer power a 0 = 1 power a b = a * power a (b-1) Why does this not work
02:47:34 <Kasccc> Anyone use PatternGuards? Do you know why case aMaybe of { Just thing | Just a <- maybeGetThing thing -> show a; Nothing -> "" } is causing an incomplete pattern match?
02:47:39 <MasseR> Guest40988: what kind?
02:48:16 <merijn> Kasccc: What if aMaybe is Just, but "maybeGetThing thing" is Nothing?
02:48:26 <Guest40988> Basicly it should turn a binary into decimal
02:48:28 <Kasccc> I know this particular example would be better served just leveraging the Maybe monad, but this example is simplified.
02:48:51 <Kasccc> merijn: Shouldn't it just fail over to Nothing -> ... ?
02:49:02 <merijn> Kasccc: But aMaybe being Just means it doesn't match Nothing
02:49:14 <Guest40988> Ello?
02:49:22 <Kasccc> I thought the guard causes it fail over
02:49:22 <liste> @paste -- Wolf please paste your code here
02:49:22 <lambdabot> Haskell pastebin: http://lpaste.net/
02:49:22 <merijn> Kasccc: If you replace Nothing with "_" it will fall through to that, yes
02:49:29 <Kasccc> Ahhhhhhhhh
02:49:29 <Kasccc> Ok
02:49:31 <Kasccc> Thank you
02:49:41 <merijn> Kasccc: The guard causes it to fail over, but it doesn't magically use that value of the failing guard for the main case
02:49:50 <liste> (Wolf: "here" meaning that pastebin, not this channel)
02:49:58 <Guest40988> @liste http://lpaste.net/163110
02:49:58 <lambdabot> No module "http://lpaste.net/163110" loaded
02:50:04 <merijn> Kasccc: If the guard fails it will fallthrough and try "aMaybe" against the next clause (i.e., Nothing) which fails
02:50:42 <merijn> Kasccc: So you'd either add an "otherwise" case to the Just clause (so the guard falls through to that) or wildcard the Nothing branch so it accepts both Nothing *and* Just with failing guard
02:52:47 <Kasccc> merijn: Thanks
02:53:08 <Kasccc> I had done something similiar in the past and now that you explained it, it is indeed obvious. Just a brain fart moment :)
02:53:25 <Guest40988> Liste, it's me, Wolf. My code is on http://lpaste.net/163110
02:55:24 <Guest40988> http://lpaste.net/163110 Anyone know why this doesnt work?
02:56:34 <lyxia> Guest40988: can you describe how it doesn't work
02:57:11 <Guest40988> It doesnt load an answer, gives stack overflow
02:58:01 <Guest40988> Try it out yourself if you want
02:58:10 <lyxia> Guest40988: btonCalc doesn't stop calling itself
02:58:18 <lyxia> add a base case
03:00:10 <Guest40988> Thank you
03:00:51 <lyxia> You're welcome!
03:41:14 <guest2675> GHC 8.0 is coming up with a strict pragma, which I believe will put strict annotations everywhere unless annotated as lazy. But will those strict annotations have a performance penalty? At runtime, will it keep needlessly checking if the value is evaluated? 
03:47:08 <lyxia> GHC avoids such unnecessary checks.
03:59:19 <guest2675> lyxia: so when an argument has been marked strict, GHC will evaluate it when it is triggered by the function, but whenever it is used in the internals of the function, GHC will not keep checking if it is evaluated? I am confused because in Real World Haskell, in the chapter dealing with strictness annotations, there was a warning that using seq or strictness annotations may cause an overhead of this needless checkin
03:59:20 <guest2675> g. 
04:03:32 <lyxia> I'm not familiar with the details myself, but that's the way I picture it. GHC does something called "strictness analysis" and removes checks it determines to be redundant.
04:07:28 <guest2675> lyxia: Thanks!
04:10:48 <merijn> strictness analysis is actually not about checks whether things are evaluated (in fact, I don't think such checks exist in any meaningful way)
04:11:12 <merijn> strictness analysis is related to unboxing code to avoid unnecessary allocation and boxing/unboxing
04:12:25 <merijn> guest2675: Can you point me to this warning in RWH?
04:23:20 <guest2675> merijin: I seem to be unable to find it now. Perhaps I read it somewhere else. The warning was on the lines of that one should investigate the underlying cause of the space leak and only apply a bang pattern there because applying it everywhere or always using strict datatypes will have an performance overhead
04:25:58 <merijn> guest2675: Sure
04:26:04 <merijn> guest2675: But that's something else
04:26:24 <merijn> guest2675: It's just saying "if you make everything strict you might end up evaluating more than you have to"
04:26:29 <jonkri> In order to create an UTCTime value, I can of course use the UTCTime type constructor. What would be an appropriate way to create a UTCTime value based on day and seconds in another time zone? (Like, the UTCTime of day d and second s in the CEST timezone.)
04:26:51 <hpc> jonkri: the easiest way is to parse a string of the time
04:26:54 <merijn> Imagine strictly evaluating [1..1000000000] when you only inspect the first 100 elements, clearly making that list strict is just waisting CPU time
04:27:38 <bollu> someone here had this cool notion of continuous maps being that as "preservers of information", which is why "every function whose image is the indescrete topology is a continuous function". Could you please expand on that?
04:27:48 <bollu> I think it was kmc if I'm not wrong
04:30:14 <guest2675> merijn: I see, thanks. Right, so it is merely saying that a mixture of laziness and strictness is ideal? So making everything strict, say the datatype and function arguments, all of them, will make Haskell no worse than if it was a strict language to begin with? The additional minor overhead of checking if the expression has been evaluated or not, will no longer exist?
04:31:20 <jonkri> hpc: Ah, using parseTime, thanks!
04:31:35 <guest2675> Also, in Haskell, switching off laziness is as simple as using an annotation, and now with GHC 8.0
04:31:54 <merijn> guest2675: If we're just considering computation then laziness will ALWAYS do less than or equal work as a strict implementation, for hopefully obvious reasons
04:32:40 <merijn> guest2675: There's no way laziness does MORE computation. Now, practically speaking laziness can sometimes cause more space to be allocated than strictness (e.g., accumulator in a fold), which might make the overall runtime lazier
04:32:48 <praetor> how do I turn a String path into a FilePath that I can pass to listDirectory?
04:33:37 <merijn> guest2675: So you add strictness annotations to solve these space leaks. Ideally, these strictness annotations ONLY do work the lazy implementation was already gonna do anyway (so you don't do more computation), you just reduce the space consumption by changing the order in which you compute things
04:33:42 <bernalex> alanz: is there a haskell-ide chan?
04:33:59 <bernalex> also, if there's anyone using emacs & evil-mode, tell me how to haskell.
04:34:40 <bernalex> M-p and M-n doesn't jump between errors with ghc-mod. and, can you make ghc-mod just autoapply stuff? like "case a of _ -> x, why not just x?"
04:35:07 <merijn> guest2675: Making EVERYTHING strict will almost certainly result in computing MORE than just laziness would, so almost certainly do more computation. It can even result in more space usage, so this new strictness stuff won't magically remove your need to understand what you're doing
04:35:09 <guest2675> Right i understand that, I just want to confirm that the additional, although minor, overhead caused by checking if the value is already computed, is not done when using seq or bang patterns. What I mean is that suppose I have a function f x y = ..., then every time x is used in the body of f, there will be a check to see if x is evaluated or not. Will that check be performed even if I call x `seq f x y or if I defi
04:35:09 <guest2675> ne f to be strict in x with f !x y = ... ?
04:36:30 <merijn> guest2675: I'm not sure there even is such a check, and I don't know the details of seq either
04:36:48 <Ferdirand> what if all f does is pass x to other functions ?
04:39:08 <guest2675> Also, why is it that there are no convenient "lazy annotations" in strict by default languages? I know that GHC 8 will have them on a module by module basis, but is it something that is quite hard to achieve? Does it always need to be accompanied by a "delay" and a "force" unlike in a lazy by default language where it just needs a single annotation?
04:40:11 <bernalex> guest2675: there is in idris.
04:40:21 <guest2675> GHC 8 will also achieve this by adding annotations behind the scenes to an already strict by default language. But in almost all lazy by default languages, achieving laziness is awkward
04:40:34 <guest2675> bernales: is that strict by default?
04:40:43 <bernalex> yes.
04:41:04 <guest2675> bernales: I believe that Idris is based on Haskell, so how does it compare? What does it lack compared to Haskell?
04:43:07 <alanz> bernalex, #haskell-ide-engine
04:43:29 <bernalex> guest2675: idris is at this point quite different to haskell. idris is eagerly and total by default, has dependent types, has its own runtime, supports proof construction, etc.
04:43:37 <bernalex> alanz: ta! there's #haskell-ide but it's almost empty.
04:44:10 <guest2675> bernales: but is not very useful for general purpose programming?
04:44:25 <bernalex> guest2675: it is a general-purpose programming language.
04:51:16 <hpc> idris is total by default now? :(
04:51:53 <bernalex> hpc: oh, wait, I guess it isn't, unfortunately.
04:52:06 <hpc> for me at least, the whole attraction of it over agda was that it has IO operations in the prelude and that it's turing-complete
04:52:34 <hpc> imo it's good that idris is non-total, because it's not primarily a proof language
04:53:52 <hpc> huh, i have a really broken idris install
04:53:56 <hpc> it can't import Prelude
04:54:13 <bernalex> hpc: total by default would imply that you could have partial functions.
04:54:30 <bernalex> hpc: I would prefer opt-out totality to opt-in totality in idris.
04:54:47 <hpc> you mean non-total by default
04:54:56 <maerwald> huh?
04:55:10 <hpc> "non-total by default would imply that you could have partial functions"
04:55:15 <bernalex> hpc: wat
04:55:17 <maerwald> unsafe "head" is fine if your totality checker says it's fine
04:55:24 <maerwald> so you can have partial functions just fine
04:55:34 <bernalex> hpc: total-by-default means that functions are total, but there is a way to achieve partiality.
04:55:55 <bernalex> hpc: if there is no way to have partial functions, then you have an actually total language, like coq.
04:58:21 <jimir> hello
04:59:00 <jimir> hello
05:06:13 <robstewartUK> Should I expect a runtime performance overhead when usin the IO monad? I have a benchmark of pure code, which recursively calls itself many times. I also have a monadic version, lifting all base case results trivially with `return`. The monadic version takes 3x/4x longer to run (15 seconds vs 48 seconds). Why might that be?
05:06:30 <jonkri> hpc: Hmm... How would I know the current date in the given timezone?
05:06:46 <merijn> robstewartUK: The compiler can inline/rewrite/whatever the pure code much more easily
05:07:00 <merijn> robstewartUK: GHC makes a lot of use of the guarantees provided by purity during optimisation
05:07:22 <merijn> robstewartUK: To the point that your code might not look remotely like what you wrote when it start generating code
05:07:24 <hpc> jonkri: UTCTime is the time in the UTC timezone, so any sort of now will suffice ;)
05:07:53 <hpc> :t getCurrentTime
05:07:54 <lambdabot> Not in scope: ‘getCurrentTime’
05:07:59 <hpc> bah
05:08:32 <robstewartUK> I have checked Core for the program, and both version do look similar, though not totally identical (the main distinction being lots of >>= rather than lets).
05:08:55 <opqdonut> robstewartUK: are you compiling with -O2?
05:09:17 <merijn> oh, yes, good point
05:09:17 <robstewartUK> yes
05:09:17 <jonkri> hpc: Hmm... So getCurrentTime gives me the Day in UTC, but what about the Day for like CEST?
05:09:27 <merijn> jonkri: There should be conversion functions
05:09:55 <hpc> generally you do all your logic in UTC, then print the date in the time zone you want at the end
05:09:58 <hpc> with formatTime
05:10:00 <opqdonut> robstewartUK: interesting. you could try the Identity monad too
05:10:29 <merijn> jonkri: utcToLocalTime
05:10:39 <hpc> i expect with Identity it will notice from the non-opaque definition of (>>=), if you're using -O2
05:10:48 <opqdonut> indeed
05:11:05 <jonkri> hpc: Thanks for that, but in this particular instance it doesn't make sense to have the logic in UTC (I'm working with reference values of midnight in CEST).
05:11:12 <merijn> jonkri: Which has "utcToLocalTime :: TimeZone -> UTCTime -> LocalTime"
05:11:15 <jonkri> merijn: Cheers!
05:11:19 <hpc> ah, then that
05:11:24 <scshunt> jonkri: ehhh. I'd still prefer to convert.
05:11:25 <merijn> jonkri: And a bunch of related stuff
05:11:33 * hpc usually doesn't have much occasion to write stuff with LocalTime
05:11:47 <scshunt> jonkri: For instance, what about when daylight savings ends?
05:12:14 <tiny_test> robstewartUK: that happens all the time. don't forget that (>>=) is a function and so you pay the price of a function call on every monadic operation
05:12:29 <merijn> tiny_test: Function calls are super cheap though
05:12:35 <merijn> tiny_test: That seems unlikely to be the problem
05:12:50 <merijn> I would expect bigger problems from repeated wrapping/unwrapping with IO
05:12:59 <tiny_test> merijn: it's still extra work
05:13:09 <jonkri> schjetne: Thanks, I will consider that!
05:13:27 <merijn> tiny_test: Depends on how much gets inlined
05:13:43 <tiny_test> we acutally had some benchmarks about this, we compared same function that runs in IO, Identity and some other monads. I can't find it atm unfortunately
05:15:10 <robstewartUK> Oh.. wow. In fact I've just discovered what the problem was. My type signature for the monadic version was (Monad m) => ... . This code took 48s to run. I just removed this constraint and replaced all `m` with `IO`, and my code now runs at 16s.
05:15:18 <merijn> :)
05:15:25 <robstewartUK> Passing dictionaries around costs 3x speed!
05:15:28 <tiny_test> so it was function calls
05:15:32 <merijn> robstewartUK: Not just that
05:15:36 <tiny_test> :-)
05:15:42 <merijn> robstewartUK: If the dictionary gets inlined and can trigger further inlining
05:16:04 <merijn> robstewartUK: i.e. inline the dictionary, inline return/>>= for IO and notice you can simplify/inline that further
05:16:26 <robstewartUK> merijn: I see, thanks.
05:16:26 <tiny_test> you were doing dynamic dispatch e.g. looking up (>>=) in the dictionary in runtime and calling it, instead of inlining IO's >>= in compile time
05:16:52 <merijn> robstewartUK: It's actually amazing how crazy fast specialisation can make things :)
05:17:48 <merijn> robstewartUK: Assuming you're doing something numeric (e.g., Int or so) I would guess that inlining also enables strictness analysis to unbox everything
05:18:30 <opqdonut> is automatic specialization possible?
05:18:44 <opqdonut> the compiler _could_ notice that the things are used heavily/only as IO
05:19:13 <robstewartUK> merijn: yes a lot of number crunching, so you may well be right.
05:26:06 <snickerdoodle> hi! what's the difference between transformers and mtl?
05:26:11 <robstewartUK> opqdonut tiny_test merijn : thanks folks, that was very helpful. 3.3x speedup by specialising for the IO monad (and a few minutes on freenode) is remarkable.
05:27:39 <cow_2001> how do i add a local source directory of a dependancy inside my executable's source tree using stack?
05:34:16 * hackagebot hdevtools 0.1.3.1 - Persistent GHC powered background server for FAST haskell development tools  https://hackage.haskell.org/package/hdevtools-0.1.3.1 (ch1bo)
05:59:17 * hackagebot hbayes 0.5.2 - Bayesian Networks  https://hackage.haskell.org/package/hbayes-0.5.2 (alpheccar)
06:16:26 <ddflare6172002> Hello :D I [heart] haskell
06:17:30 <praetor> Hi! what's wrong with this? :(
06:17:32 <praetor> move :: String -> IO ()
06:17:34 <praetor> move dir = do
06:17:35 <praetor>  mapM $ \x -> renameFile x dir++x $ listDirectory "."
06:17:59 <ddflare6172002> prator: please place it in collabedit:
06:18:21 <praetor> sure
06:18:32 <merijn> praetor: Looks like completely wrong parentheses
06:18:34 <ddflare6172002> thx
06:18:42 <praetor> http://collabedit.com/6ue2n
06:18:47 <cow_2001> יוררשי! https://github.com/commercialhaskell/stack/blob/master/doc/yaml_configuration.md
06:18:49 <cow_2001> קרר
06:18:51 <cow_2001> err
06:19:00 <cow_2001> goddamn mlterm
06:19:05 <merijn> praetor: That brackets like "mapM ((\x -> (renameFile x dir)++x) (listDirectory "."))"
06:19:07 <ddflare6172002> can you join the url
06:23:45 <praetor> then what's wrong with this:
06:23:47 <praetor> mapM  (\x -> renameFile x ext++x)  (listDirectory "." ) 
06:25:00 <merijn> praetor: Pretty sure "(renameFile x ext) ++ x" is a type error
06:25:33 <praetor> ah sorry didn't see that part
06:27:29 <nmdanny> :pf
06:27:51 <nmdanny> @pl \s -> first f `fmap` p s
06:27:52 <lambdabot> (first f `fmap`) . p
06:29:24 <praetor> merijn: I still get Couldn't match type 'IO ()' with '()'
06:29:52 <praetor> Actual type: IO(IO())
06:31:03 <nmdanny> can lamdabot desugar do expressions?
06:31:19 <merijn> @undo do { x <- foo; return (x + y) }
06:31:19 <lambdabot> foo >>= \ x -> return (x + y)
06:31:51 <nmdanny> @undo \s1 ->     do       (f,s2) <- p1 s1       (b,rest) <- p2 s2       return (f b,rest)
06:31:51 <lambdabot> <unknown>.hs: 1: 52:Parse error: Last statement in a do-block must be an expression
06:32:09 <nmdanny> @undo \s1 ->     do      { (f,s2) <- p1 s1  ;     (b,rest) <- p2 s2    ;   return (f b,rest) }
06:32:09 <lambdabot> \ s1 -> p1 s1 >>= \ (f, s2) -> p2 s2 >>= \ (b, rest) -> return (f b, rest)
06:32:30 <nmdanny> @pl \s1 ->     do      { (f,s2) <- p1 s1  ;     (b,rest) <- p2 s2    ;   return (f b,rest) }
06:32:30 <lambdabot> (line 1, column 20):
06:32:30 <lambdabot> unexpected '{'
06:32:30 <lambdabot> expecting variable, "(", operator or end of input
06:32:49 <nmdanny> @pl \s1 -> p1 s1 >>= \(f, s2) -> p2 s2 >>= \(b, rest) -> return (f b, rest)
06:32:49 <lambdabot> (uncurry (flip ((>>=) . p2) . (`ap` snd) . (. fst) . (((return .) . (,)) .)) =<<) . p1
06:33:15 <nmdanny> welp.
06:34:13 <quchen> Is anyone else having trouble using tasty-html? I'm running the testsuite with "--html foo.html" but nothing is generated, without any errors
06:45:32 * hackagebot language-dot 0.1.0 - A library for the analysis and creation of Graphviz DOT files  https://hackage.haskell.org/package/language-dot-0.1.0 (BenGamari)
06:55:56 <hvr> bgamari: neat...
07:10:33 * hackagebot intero 0.1.3 - Complete interactive development program for Haskell  https://hackage.haskell.org/package/intero-0.1.3 (ChrisDone)
07:10:42 <sm> ooh
07:11:18 <sm> bah chrisdone, you tease us
07:25:34 * hackagebot tidal-serial 0.8 - Serial support for tidal  https://hackage.haskell.org/package/tidal-serial-0.8 (AlexMcLean)
07:30:34 * hackagebot directory-listing-webpage-parser 0.1.1.0 - directory listing webpage parser  https://hackage.haskell.org/package/directory-listing-webpage-parser-0.1.1.0 (sifmelcara)
07:39:37 <HaskellNoob> Hi
07:39:42 <byorgey> hi HaskellNoob 
07:40:30 <HaskellNoob> I am trying to write a solution for Project Euler 85 in Haskell, but I am having a weird bug.
07:40:44 <HaskellNoob> Here is my code:
07:40:45 <HaskellNoob> triangleNumbers = [x * (x - 1) `quot` 2 | x <- takeWhile (validTriangeNum) [1..]]
07:40:51 <HaskellNoob> findSmallestDifference :: Integer -> [Integer] -> [Integer]
07:40:56 <HaskellNoob> findSmallestDifference a (ls) = [a * (ls !! index), a * (ls !! index - 2)]
07:41:03 <HaskellNoob>     where index = length (takeWhile (\x -> a * x <= 2000000) ls)
07:41:11 <hexagoxel> @where paste
07:41:13 <lambdabot> Haskell pastebin: http://lpaste.net/
07:42:02 <HaskellNoob> http://lpaste.net/163120
07:42:50 <nmdanny> Question regarding applicative parsers:
07:43:14 <bollu> what's the category theory explanation of application? Functor is Functor, Monad is monoid of endofunctors, applicative is..?
07:43:20 <bgamari> hvr, heh, it's been around for a while
07:43:51 <bgamari> hvr, I just needed a dot library and it looked pretty sensible so I picked up maintainership on it
07:44:03 <HaskellNoob> I want the program to take two consecutive elements from a list of triangle numbers such that when multiplied by a number (a), one element is less than two million, and the other is greater than two million.
07:44:13 <nmdanny> if I want to lift a function over several applicative functor arguments, but ignore several arguments, how would I do that, using applicative syntax?
07:44:26 <cocreature> bollu: monoid in the category of endofunctors :P
07:44:38 <HaskellNoob> However, It outputs values above 2000000
07:45:02 <HaskellNoob> These two: [2002770,2002764]
07:45:03 <bollu> cocreature: you're nitpicking my Monad definition right? :) But seriously, does anyone know?
07:45:08 <bollu> Like, how do I express applicative?
07:45:11 <bollu> in cat. theory?
07:45:21 <cocreature> bollu: no I was answering your question, applicatives are monoids in the category of endofunctors :)
07:45:31 <cocreature> bollu: https://www.reddit.com/r/haskell/comments/2lompe/where_do_the_applicative_laws_come_from/clws90h is a pretty good explanation
07:45:45 <cocreature> I’m no expert so I can’t tell you much more than ed has written there
07:45:51 <bollu> cocreature: wait, so the difference between monad and applicative is
07:45:56 <HaskellNoob> Is there a better place to ask novice questions (with quick feedback)?
07:46:12 <cocreature> bollu: the choice of tensor product
07:46:26 <bollu> what the fuuuuck, how the hell do you bring in tensors / multi-linearity into category theory where the notion of "linear" doesn't exist?
07:46:27 <cocreature> bollu: for monad it’s composition of functors, for applicative it’s day convolution
07:47:07 <cocreature> bollu: sry kinda busy right now, the keyword you should search for is “monoidal category”
07:47:31 <bollu> cocreature: will do, thanks
07:47:47 <nmdanny> using applicative notation for a parser, is there a way to simplify the following? :
07:47:51 <nmdanny> intPair :: Parser [Integer]
07:47:54 <nmdanny> intPair = combine <$> posInt <*> char ' ' <*> posInt
07:47:57 <nmdanny>   where combine i1 _ i2 = [i1,i2]
07:48:06 <hexagoxel> @tell HaskellNoob is it intended when you write "(ls !! index - 2)", which is ((ls !! index) - 2) ?
07:48:06 <lambdabot> Consider it noted.
07:48:29 <jle`> nmdanny: already looks pretty simple to me, to be honest
07:48:39 <jle`> you can use (*>) to ignore an input directly i guess
07:48:46 <jle`> but also, why are you returning a list
07:48:48 <nmdanny> basically, I have a positive integer, followed by ignored space, followed by another positive integer
07:48:54 <jle`> if you always know that it's *two* items?
07:49:04 <jle`> use a tuple instaed :)
07:49:05 <nmdanny> ehh I don't know, i'm doing some exercise and thats what it said
07:49:10 <nmdanny> but anyway,
07:49:19 <jle`> intPair = (,) <$> posInt <*> char ' ' *> posInt
07:50:05 <jle`> er wait, it's infixl, so maybe it should be written (,) <$> posInt <*> (char ' ' *> posInt)
07:50:16 <jle`> or (,) <$> posInt <* char 'a' <*> posInt
07:50:33 <nmdanny> Oh I see,
07:50:48 <nmdanny> I tried doing (,) <$> posInt <* char ' ' *> posInt
07:51:05 <nmdanny> which doesn't make sense I guess
07:51:08 <jle`> mhm
07:51:29 <bollu> what are "penagonal coherence conditions"?
07:51:39 <bollu> (what's penagonal)?
07:52:03 <nmdanny> ok so            posInt <* char ' ' <*> posInt          means:  a positive int, followed by an ignored parser for ' ', followed by a positive int
07:53:02 <jle`> it's parenthesized as (posInt <* char ' '), so yeah
07:53:26 <praetor> how do you cast a FilePath into a String?
07:53:37 <nmdanny> :t FilePath
07:53:39 <lambdabot> Not in scope: data constructor ‘FilePath’
07:53:54 <nmdanny> isn't a FilePath an alias for a string?
07:55:16 <praetor> I'm getting couldn't match expected type '[[char]]' with 'IO [FilePath]'
07:55:42 <praetor> oh wait
07:55:50 <jle`> [[Char]] is [FilePath]
07:55:52 <nmdanny> That's because your [FilePath] is in an IO monad
07:55:52 <praetor> maybe I have to use '<-' right?
07:55:57 <geekosaur> yes
07:56:04 <geekosaur> in a do block running in IO
07:56:12 <praetor> Okay, haven't gotten to monads yet
07:56:16 <praetor> thanks
07:56:32 <jle`> don't worry bout it, it doesn't really have anything to do with monads :)
07:56:51 <jle`> the word 'monad' serves no purpose there, "it's in IO" would make more sense
08:05:43 <singpolyma> Hey all!  I'm tring to use http-streams with a particularly picky server, and can't figure out what options to set on the HsOpenSSL context.  Connection with normal cURL works, but conecting from my code gives me ConnectionAbruptlyTerminated every time
08:06:21 <sm> singpolyma: maybe comparing with wreq would give some clues
08:15:36 * hackagebot bitcoin-payment-channel 0.1.0.0 - Library for working with Bitcoin payment channels  https://hackage.haskell.org/package/bitcoin-payment-channel-0.1.0.0 (runeks)
08:19:02 <runeks> woot!
08:19:14 <jle`> ocharles_: do you think you'd recommend http://amzn.com/1970001240 ?
08:19:32 <jle`> (question open to other agda people too)
08:30:14 <ddflare6172002> hello
08:30:28 <phadej> jle`: I quickly skimmed thru, seems nice
08:32:36 <Rydgel> Is agda garbage collected too?
08:34:47 <jle`> hm thanks
08:35:36 * hackagebot intero 0.1.5 - Complete interactive development program for Haskell  https://hackage.haskell.org/package/intero-0.1.5 (ChrisDone)
08:36:37 <phadej> Rydgel: would say "there are no explicit memory management"
08:37:24 <phadej> Rydgel: it compiles to Haskell: http://agda.readthedocs.io/en/latest/tools/compilers.html
08:37:56 <bollu> Does IHaskell allow someone to use only the "Kernel" part of the code and let someone write a kernel for some custom DSL?
08:40:16 <bollu> what's intero? Looks interesting
08:48:15 <ddflare6172002> I am not spamming
08:48:19 <ddflare6172002> Please dont kick me
08:48:33 <ddflare6172002> BTW how do you do that?
08:57:31 <bmuk> Hello everyone, I'm trying to use both wreq and Spock in the same module, it won't let me because `get` is ambiguous. I tried importing Network.Wreq as Wreq
09:00:07 <notdan> bmuk: try `import Network.Wreq hiding (get)` and `import qualified Network.Wreq as Wreq`
09:00:26 <notdan> bmuk: `import Network.Wreq as Wreq` still brings stuff into the current scope
09:00:57 <bmuk> import qualified Network.Wreq as Wreq works, what is the import Network.Wreq hiding (get) for? To bring everything but get into the current scope?
09:01:13 <bmuk> get is all this project actually needs from Wreq :p
09:02:34 <notdan> bmuk: yeah, that's what hiding does
09:02:42 <notdan> and in your case i guess that line doesn't make much sense then :)
09:02:47 <bmuk> ok, thanks notdan :)
09:05:11 <bmuk> so I'm trying to make a spock server that simply passes the uri to my function. `do get var $ \uri -> myFun uri` seems to work for everything except root (which gives me a 404)
09:06:16 <notdan> hm
09:07:10 <notdan> bmuk: i think root might be special?
09:08:02 <bmuk> It appears to be :/
09:09:57 <notdan> you can try `get ("test" <//> var) myFun` if you can afford an additional subpath
09:10:05 <notdan> that should capture even an empty path
09:12:30 <bmuk> I can't for my use case. I'm rewriting a redirector service from clojure to haskell (to test performance, etc.). It sits on our old domain and fans out requests to two subdomains depending on the uri
09:16:37 <bmuk> speaking of redirecting, how would I go about doing that with Spock? I see `redirect "/user-list" here: https://hackage.haskell.org/package/Spock-0.10.0.1/docs/Web-Spock-Safe.html 
09:17:16 <bmuk> but that's local uri, would it work the same with, say `redirect ("foo.com" <> uri)?
09:19:37 <bmuk> actually it looks like Spock can't handle arbitrary uris (probably because this wouldn't be type-safe?) - i.e. with `get var -> \uri...` localhost:8080/uri works, but localhost:8080/different/uri gives a 404
09:27:10 <sm> what is the best channel for discussing Atom haskell plugins like haskell-ide ?
09:31:09 <cocreature> if haskell-atom is not already a thing you should create it :)
09:31:47 <sm> hrm.. that might be an idea
09:32:12 <sm> even though I love my emacs..
09:32:32 <sm> if we get a third vote, let's do it
09:32:36 <cocreature> I hate my emacs, I just can’t get myself to learn something else
09:32:41 <sm> right :)
09:33:49 <sm> I love my emacs on mondays, wednesdays, fridays, and sundays
09:35:25 <mpickering> sm: They have a gitter channel
09:36:13 <sm> I might as well spam it here too.. I'm recording what I figure out about atom at http://joyful.com/haskell-ide-setup , and am looking for fellow testers
09:36:19 <sm> mpickering: thanks
09:37:19 <sm> https://gitter.im/atom-haskell/ide-haskell I guess.. ide-haskell-specific
09:37:25 <cocreature> sm: sorry for being so grumpy but please don’t make yet another unofficial page explaining how to setup haskell tooling. it will get out of date, people will still find it and the maintainers of the software will have to deal with confused users. just contribute the docs to the projects directly
09:39:12 <sm> I appreciate that. I think I can reduce that by strongly dating it
09:39:58 <cocreature> fair enough, but if you contribute the docs to the project 1. more people can find it and 2. it’s easier to keep it up2date
09:40:06 <sm> dealing with all projects will dissipate the effort and wouldn't have helped the newcomer I was talking to
09:40:25 <sm> but, I am finding and reporting issues upstream as a result of trying to document a process that works
09:40:39 * hackagebot json-pointer-aeson 0.1 - Integration layer for "json-pointer" and "aeson"  https://hackage.haskell.org/package/json-pointer-aeson-0.1 (NikitaVolkov)
09:41:28 <sm> when the doc is wrong, I will gladly update it or take it down
10:08:26 <gridaphobe> alanz: hi, i'm trying to use ghc-exactprint to implement a source-to-source translation, but it appears to discard any new top-level declarations i add. is this expected? (they all have an UnhelpfulSrcSpan since the code was generated, which might be relevant)
10:09:40 <mpickering> gridaphobe: Yes
10:09:56 <mpickering> you have to provide proper relative locations otherwise, how can it know where to print it?
10:10:26 <mpickering> The API isn't very good, we spent a lot of effort getting it to work but then ran out of steam a bit before adding a nice API
10:10:47 <gridaphobe> i guess i would assume that it would shift the rest of the locations accordingly (it must do something similar when i modify existing code)
10:10:58 <gridaphobe> but admittedly that seems very tedious..
10:11:01 <mpickering> It would be possible to implement a "pretty printer" but we haven't yet
10:11:29 <gridaphobe> i would be happy if it just dumped any new declarations at the end of the file, with ghc's standard pretty-printer
10:12:08 <mpickering> There is a hacky way to do it currently
10:12:18 <gridaphobe> i'm fine with hacky :)
10:12:22 <mpickering> Use GHC's pretty printer, then reparse it and insert the fragment
10:13:01 <gridaphobe> hrm, wouldn't that discard the comments and pragmas? i originally tried using ghc's parser/printer and that was my problem
10:13:06 <mpickering> you need to make sure to add the new annotations from the reparsing to the old annotations
10:13:14 <mpickering> If you just pretty print the new fragment
10:13:35 <mpickering> If you're generating new syntax then you can't be adding comments as well?
10:13:49 <gridaphobe> no, but i need to preserve existing comments
10:14:20 <gridaphobe> i guess i can (1) exactPrint the existing source and (2) ghc-print the new decls at the end
10:14:38 <mpickering> yes that would work 
10:14:55 <gridaphobe> ok, that'll do for now, thanks!
10:15:52 <mpickering> If someone wants to implement a pretty-printer for us then they are welcome to :) 
10:16:51 <mpickering> In that case there's no real point in using ghc-exactprint though
10:16:59 <mpickering> you might as well just use GHC's parser
10:24:30 <alanz> mpickering, bar layout, comments etc
10:24:49 <alanz> We just need some kind of default options if the annotations are missing
10:28:27 <bmuk> ghc can't find "Servant", but I have servant >= 0.4 in my cabal file?
10:29:01 <dcoutts> bmuk: see cabal info servant  vs  cabal info servant-server
10:30:27 <bmuk> ah ok, servant is for Servant.API, and servant-server is for Servant
10:31:02 <bmuk> is this a good project to emulate? https://github.com/k-bx/owlcloud
10:44:35 <bmuk> I know this is a fairly simple question, but how can I make a JSON object like this: {"AuthInfo": { "Username": "foo@bar.com", "Password": {"Password": "P@55w0rd"}}} with toJSON? I don't remember how to make hashmap literals
10:45:28 <bmuk> I'm trying to POST it to our API
10:47:06 <EvilMachine> Hey, what’s the operator precedence of (-<)?
10:47:36 <EvilMachine> (as in: what’s its fixity declaration?)
10:47:52 <EvilMachine> (Since it is “special”, I kinda can’t find it.)
10:50:41 <{AS}> > :info (-<)
10:50:42 * hackagebot opaleye-trans 0.3.2 - A monad transformer for Opaleye  https://hackage.haskell.org/package/opaleye-trans-0.3.2 (wraithm)
10:50:43 <lambdabot>  <hint>:1:1: parse error on input ‘:’
10:52:13 <geekosaur> no :info in lambdabot, it's not ghci
10:52:31 <sqrt2> bmuk: do you mean something like this? toJSON (AuthInfo user pass) = object ["AuthInfo" .= object ["Username" .= user, "Password" .= object ["Password" .= pass]]]
10:52:36 <EvilMachine> :info doesn’t help for (-<) anyway. 
10:52:39 <EvilMachine> it’s a built-in
10:52:59 <nitrix> Yeah -< is syntax for arrow abstractions.
10:53:01 <EvilMachine> (If {-# LANGUAGE Arrow #-} is enabled)
10:53:14 <EvilMachine> Yes, nitrix. But it must have a precedence.
10:53:39 <nitrix> EvilMachine: Does `\.. -> ...` have a precedence?
10:53:51 <nitrix> (The arrow in it) ?
10:54:02 <EvilMachine> nitrix: yes, because everything has to be evaluated in a certain order.
10:54:12 <nitrix> The -> isn't evaluated though.
10:54:14 <nitrix> It's syntax.
10:54:48 <EvilMachine> So you are saying that syntax doesn’t have to be evaluated in any order or that it isn’t evaluated at all?
10:55:59 <EvilMachine> Of course it is evaluated. As in: The parser MUST decide where to put they symbols surrounding it, in the hierarchy. Otherwise it could never compile it.
10:56:01 <nitrix> Usually the syntax does something. It binds a variable, it builds an expression, it does _something_, and that something is subject to precedence, but the syntax is merely syntax :/
10:56:18 <nitrix> EvilMachine: You're confusing parsing / lexing with evaluation.
10:56:37 <nitrix> Afaik.
10:56:41 <EvilMachine> That’s what I meant.
10:57:47 <nitrix> EvilMachine: It's like asking the precedence of = or `do`.
10:58:10 <EvilMachine> It’s part of evaluation. I could have used an even more generic term too. Because I kinda assume that humans understand what I obviously meant. (Just like I don’t think I need to specify which species of chicken crossed the road and which type of road. :P)
10:58:20 <EvilMachine> nitrix: They have precendence too. Duh
10:58:33 <nitrix> What more generic term would you have used?
10:58:40 <nitrix> Evaluation is obviously incorrect.
11:00:09 <EvilMachine> nitrix: Please stop “helping” people. You’re just obsessing over pointless technicalities where every normal human would have a normal conversation. Too bad, as this channel is usually great. But hey, what do I expect when it’s this sunny outside. The socially competent people left long ago. (And I just came back.) So goodbye.
11:02:27 * monochrom frowns. Clearly Haskell is where you have to dissociate parsing from evaluation.
11:02:37 <nitrix> "This channel" is what everyone contributes to individually. I'm not sure his ego fits in.
11:02:57 <ddflare6172002> HOw to tern on yoyr computor
11:03:09 <nitrix> monochrom: Did I do anything wrong?
11:03:21 <monochrom> no, in fact I think EvilMachine was wrong.
11:03:29 <ddflare6172002> HOw to tern on yoyr computor
11:03:31 <ddflare6172002> ?
11:04:07 <monochrom> evaluation vs parsing may be a pointless distinction in eager languages. but in Haskell it is pointedly important.
11:04:47 <nitrix> I was thinking to mention it, but I thought it was too much of a sidestep from the original topic of "precedence" of "syntax".
11:04:56 <simpson> This channel *does* have an attitude problem, but there's nothing that can be done about it. CLV.
11:05:11 <monochrom> it explains why "True || (undefined || undefined)" is parsed as "True || (undefined || undefined)" and yet evaluated as True as though the undefined's didn't happen.
11:05:47 <hpc> simpson: how do you figure?
11:06:38 <Zekka|Sigfig> nitrix: Before giving him an explanation he was satisfied with for his original question, you accused him of not knowing terminology — I think he provoked you by claiming he intentionally used incorrect terminology though
11:06:54 <simpson> hpc: About which part?
11:06:58 <Zekka|Sigfig> it’s imho pretty clear why he reacted that way after you said that but I have trouble really blaming you
11:07:11 <adamCS> nitrix,monochrom:  Also, just in general, being precise (which is good!) can be very close to being pedantic (which is tiresome!).  This channel works well, I think, because most people make room for the precision to flourish despite it sometimes being/feeling-like pedantry.
11:07:35 <nitrix> │13:52:32     EvilMachine | Yes, nitrix. But it must have a precedence.
11:07:37 <hpc> simpson: that entire line; my experience has been that this is one of the friendliest channels on the network
11:07:37 <nitrix> 13:55:17     EvilMachine | Of course it is evaluated.
11:07:41 <nitrix> 13:55:59     EvilMachine | That’s what I meant. 
11:07:58 <nitrix> I don't know. He seemed really eager to argue; otherwise I'd have let it slip.
11:08:15 <Zekka|Sigfig> Yeah, that’s why I have a hard time blaming you
11:08:28 <Zekka|Sigfig> but I think there’s a hypothetical world where you could have given him an answer he would have been satisfied with
11:08:28 * hpc agrees with adamCS
11:08:30 <nitrix> I don't normally nitpick.
11:08:45 <adamCS> hpc: :)
11:08:47 <nitrix> adamCS: I absolutly agree. It's a fine line.
11:08:49 <simpson> hpc: I'm sorry to hear that! We should agree to disagree.
11:09:43 <adamCS> nitrix: Yes.  But making room to wander around over and back makes for much more useful conversations.
11:09:55 <alanz> mpickering, gridaphobe https://github.com/alanz/ghc-exactprint/issues/37
11:10:12 <Zekka|Sigfig> Usually when I see a guy who makes an error like his I try to get back to that theoretical misunderstanding, so I’d be talking a little bit about how parsing works
11:10:20 <Zekka|Sigfig> That has some danger of coming off really condescending though
11:10:24 <hpc> simpson: perhaps it has a presentation problem, but i find the attitude here to be polite and always looking for the best way to solve a person's issues or misunderstandings
11:10:42 <hpc> as opposed to many other channels where the attitude is "how do you not know this, you idiot"
11:11:09 <monochrom> I simply don't answer people whose questions are full of "I already know I am right"
11:11:11 <Zekka|Sigfig> I think most people won’t feel helped when you say “that’s totally incorrect” and leave it at that
11:11:14 <hpc> it can be very direct and corrective at times though
11:11:42 <simpson> hpc: Don't worry about it.
11:11:58 <bmuk> sqrt2: would AuthInfo be a datatype there?
11:13:37 <monochrom> and I think it's time for us to make a distinction between "tern" and "turn", "computor" and "computer", so that we can better help that poor chap who needs help turning on a computer :)
11:17:01 <tippenein> trying to write a mpa reduce with Pipes - http://lpaste.net/163134
11:17:13 <tippenein> map*
11:17:56 <tippenein> I'm unclear what the right tool for pulling out this info from a Text stream is
11:18:22 <Iceland_jack> bmuk: You can use "generics" to derive them automatically:
11:18:22 <Iceland_jack>     newtype Password = Password { password :: String }                       deriving (Generic, ToJSON)
11:18:22 <Iceland_jack>     data    AuthInfo = AuthInfo { username :: String, password :: Password } deriving (Generic, ToJSON)
11:18:39 <Iceland_jack> Then you can write
11:18:40 <Iceland_jack>     ghci> encode (AuthInfo "foo@bar.com" (Password "hello"))
11:18:40 <Iceland_jack>     "{\"username\":\"foo@bar.com\",\"password\":{\"password\":\"hello\"}}"
11:19:20 <Iceland_jack> You need to enable extensions for that (‘DeriveGeneric’, ‘DeriveAnyClass’, ...)
11:19:29 <hpc> ooh nifty
11:19:34 <bmuk> Iceland_jack: say I want "AuthInfo" before all of that?
11:19:41 <hpc> programmable deriving
11:19:52 <Iceland_jack> bmuk: Just add a newtype as needed
11:20:11 <Iceland_jack> Try making it model your existing Haskell data type 
11:20:17 <Iceland_jack> if one exists
11:20:17 <hpc> Iceland_jack: how does one do that instead of something like acid-state's $(deriveFoo ...)?
11:20:23 <bmuk> and that's {-# LANGUAGE DeriveGeneric #-}?
11:20:24 <hpc> internally
11:20:42 <Iceland_jack> bmuk: yes
11:20:44 <bmuk> I'll make a gist of what I have currently
11:21:06 <Iceland_jack> hpc: A ‘Generic’ instance gives you information about record fields and the shape of the data
11:21:33 <hpc> Iceland_jack: i mean, what is ToJSON doing that lets it go into a deriving()?
11:21:44 <Iceland_jack> That's DeriveAnyClass
11:21:59 <Iceland_jack> Without it, you'd have to write
11:21:59 <Iceland_jack>     instance ToJSON Password
11:21:59 <Iceland_jack>     instance ToJSON AuthInfo
11:22:28 <Iceland_jack> The ToJSON class has a "default" method, when you elide the method definition it gets used
11:22:29 <bmuk> https://gist.github.com/bmuk/a50d9250bf07848512c945d48c46138f
11:22:36 <hpc> "The compiler will simply generate an empty instance"
11:22:37 <hpc> ah
11:22:55 <bmuk> ^ that is my hacky attempt at creating the first part of this API (doesn't talk to the backend yet)
11:23:05 <hpc> and the default instance depends on Generic
11:23:06 <Iceland_jack> This is from "ToJSON"
11:23:07 <Iceland_jack> class ToJSON a where
11:23:07 <Iceland_jack>   toJSON :: a -> Value
11:23:07 <Iceland_jack>   default toJSON :: (Generic a, GToJSON (GHC.Generics.Rep a)) =>
11:23:10 <Iceland_jack>                     a -> Value
11:23:18 <Iceland_jack> That's right, if "a" doesn't have a Generic instance it doesn't work
11:23:39 <hpc> i may have to try that out one of these days
11:24:29 <ski> presumably the precedence of `-<' is lower than `0' ?
11:24:59 <Iceland_jack> The basic idea is simple, if you can define methods like...
11:24:59 <Iceland_jack>     instance GFoo () where
11:24:59 <Iceland_jack>     instance (GFoo a, GFoo b) => GFoo (a, b) where
11:24:59 <Iceland_jack>     instance (GFoo a, GFoo b) => GFoo (Either a b) where
11:25:02 <Iceland_jack> you can derive "GFoo" automatically for lotsa types
11:25:09 <Iceland_jack> simplified syntax
11:25:24 <hpc> data type algebra!
11:26:07 <Iceland_jack> That' right, types like "Bool" get turned into "Either () ()" basically
11:26:14 * ski . o O ( "algebra data type" )
11:27:18 <Iceland_jack> Reality is not quite so nice
11:27:18 <Iceland_jack>     ghci> from True
11:27:18 <Iceland_jack>     from True :: D1 ('MetaData "Bool" "GHC.Types" "ghc-prim" 'False) (C1 ('MetaCons "False" 'PrefixI 'False) U1 :+: C1 ('MetaCons "True" 'PrefixI 'False) U1) x
11:27:39 <Iceland_jack> But if you ignore the metadata
11:33:05 <hpc> well, that :+: there is a big hint :D
11:36:22 <Iceland_jack> hmm
11:36:30 <Iceland_jack> I wonder if "Rep" could be marked injective
11:37:25 <bmuk> Iceland_jack: I'm getting "multiple declarations of 'password'"
11:38:28 <Iceland_jack> If you make 'Password' not be a record it should work fine, of course then you won't get two "password" keys 
11:39:02 <bmuk> so going with the object ["AuthInfo" ... approach might be better?
11:39:03 <Iceland_jack> if you want more complicated fields, you're going to have to read the docs yourself
11:39:13 <Iceland_jack> Yes it may be
11:39:15 <bmuk> of course
11:39:23 <Iceland_jack> but there is a lot of value in having something the compiler can generate
11:39:27 <bmuk> I appreciate your help
11:39:28 <Iceland_jack> and you can use duplicate fields in GHC 8
11:39:36 <Iceland_jack>     ghci> :set -XDuplicateRecordFields
11:40:20 <Iceland_jack> I sometimes create dummy data types just to get the compiler to do more work
11:40:38 <ipweb25> http://espedito.homepc.it/ Hi to all...)
11:41:48 <Iceland_jack> For example if I want "HEART" to display as "♥" in 
11:41:48 <Iceland_jack>     data Foo = A ... | B ... | HEART | C ... | D ...
11:41:48 <Iceland_jack> but I want A/B/C/D/... to be generated I sometimes define a separate data type with 'derive Show'
11:42:41 <Iceland_jack>     data Foo = HEART | Foo' Foo'
11:42:41 <Iceland_jack>     instance Show Foo where
11:42:41 <Iceland_jack>       show HEART     = "♥"
11:42:41 <Iceland_jack>       show Foo' foo' = show @Foo' foo'
11:42:44 <Iceland_jack> anyway
11:42:59 <Iceland_jack> *   show (Foo' foo') = ...
12:08:44 <nitrix> Funny
12:08:47 <nitrix> http://blog.rust-lang.org/2016/05/13/rustup.html
12:09:01 <prohobo> i dont wanna take rust everywhere :(
12:09:02 <nitrix> Rust just got a toolchain manager; reminds me of Stack.
12:09:37 <nitrix> For a few seconds, I thought "hey this is cool", then realised Haskell is leading the way again :P
12:10:06 <Iceland_jack>     Rust on a plane
12:50:58 <bmuk> I have OverloadedStrings turned on, but I'm getting can't match [Char] with Text errors when using aeson
12:52:34 <hpc> OverloadedStrings only applies fromString to literals in the source code
12:52:57 <ski> no implicit coercion between `[Char]' and `Text', i.e.
12:53:10 <hpc> so you have something along the lines of can't match Integer with Double
12:54:07 <bmuk> here is what I have: https://gist.github.com/bmuk/db0945f39f411810ed3eb394af31e737
12:54:39 <bmuk> authInfo takes Texts, so I'm not sure why the problem would be inside authInfo and not where I'm calling it from if they were indeed [Char]
12:54:52 <bmuk> plus AuthInfo takes Texts as well
12:57:23 <hpc> what's the type of post?
12:57:36 <hpc> also can you include the type error itself? it has both line and character information
12:58:20 <bmuk> https://gist.github.com/bmuk/e9ba25f348da164f637dce26dd3e5138
12:59:39 <athan> Does anyone know if in modern FP languages like Haskell can eliminate calls to `const`, and just treat the data as-is, statically?
12:59:54 <athan> and likewise calls to `\_ -> ...`
13:00:13 <Jinxit> let's say the output of my haskell lib is an AST, where the end goal is to let users generate code in their own language based on that AST. is there anything I can do to make that process easier, or should I just provide the AST itself?
13:00:33 <hpc> bmuk: you misspelled LANGUAGE
13:00:37 <athan> Not sure if the underscore adds this extra meaning here to the compiler - in that the result of this function does not change for its input, s.t. any applications to it can be eta-eliminated
13:00:48 <bmuk> hpc: wow. sorry
13:00:52 <hpc> what a diabolically subtle error, since those pragmas are comments
13:02:03 <bmuk> Indeed lol. Now I'm getting this: https://gist.github.com/bmuk/e9ba25f348da164f637dce26dd3e5138
13:02:33 <ski> athan : not sure what you mean by "just treat the data as-is, statically"
13:02:50 <ski> athan : perhaps you mean automatically applying an appropriate isomorphism ..
13:04:21 <athan> ski: I think I do
13:04:24 <sm> Jinxit: like pandoc's "native" output format ?
13:04:44 <athan> where `x = \a -> const x a` and `\a -> const x a = x` 
13:04:57 <athan> the latter is what I was refering to for the eta-elimination
13:05:13 <hpc> bmuk: not sure, but i would start from what the type of (:<|>) is
13:05:46 <bmuk> hpc: I may switch back to Spock, since it seems easier than Servant
13:06:03 <Jinxit> sm: not familiar with pandoc
13:06:05 <bmuk> does the community have an opinion Spock vs. Servant?
13:06:43 <hpc> not sure
13:07:19 <sm> bmuk: Spock is more general purpose, and the types will certainly be simpler
13:07:40 <sm> Servant is the new hotness, and can save a lot of work if you're building a web api
13:07:48 <bmuk> which I am
13:08:05 <bmuk> Well, more like a REST wrapper around an existing API
13:08:57 <sm> servant can be hard, but there's a lot of users and support. Not sure about spock
13:09:30 <bmuk> I think I'll be ok if I push through it, it's just been a while since I've messed with haskell
13:13:39 <lifter> servant is a thing of beauty
13:14:34 <bmuk> Reading the tutorial would probably help :p
13:15:04 <sm> yes :)
13:15:04 <bmuk> Sometimes I get the idea that I know what I'm doing and I can just put it all together with stuff I glean from Hackage
13:17:53 <sm> I found https://samurails.com/web-api/calling-your-web-api-restful-youre-doing-it-wrong a good read btw
13:18:47 <bmuk> I'll take a look, thanks! I mainly say REST to differentiate from our existing SOAP/RPC api
13:19:06 <sm> I've been calling mine "RESTish", but I'm going to stop
13:20:41 <amcsi_> any good webserver/frameworks for haskell web backend development?
13:21:12 <geekosaur> no REST for the wicked
13:21:19 <bmuk> ha
13:21:43 <hpc> syntax don't grow on trees
13:21:46 <hpc> wait, it does
13:21:57 <jle`> ha
13:22:16 <geekosaur> syntax grows trees, as opposed to growing on them
13:25:13 <bmuk> "If creating a real Stateless authentication system is too much of a pain for you, then don’t. You know what I’m going to say now: just don’t call your API RESTful "
13:25:23 <bmuk> what would a stateless authentication system look like?
13:25:33 <Nycatelos> Does the Haskell Book have a thing for people who can't afford to buy it
13:25:38 <sm> amcsi_: yesod snap spock scotty servant wai
13:25:39 <Nycatelos> like a discount or something?
13:26:23 <sm> Nycatelos: yes, email the authors
13:26:36 <ggVGc> imagine if haskell did this, https://jsfiddle.net/eo0zn9pL/1/
13:26:58 <Nycatelos> sm: thanks, should I send an email to support or contact one of the authors
13:27:01 <Nycatelos> as I don't want to annoy them
13:27:32 <sm> bitemyapp or someone in #haskell-beginners will now
13:27:34 <sm> know
13:28:28 <sm> amcsi_: and happstack! my bad
13:29:17 <begriffs_> bmuk: JWT is an example of stateless auth.
13:29:37 <Akii> bmuk: that's easy, isAuthenticated :: () -> Bool
13:30:00 <Akii> and then you're either a positive or a negative person
13:30:00 <bmuk> Akii: lol
13:30:23 <athan> bmuk: No session initialization system
13:30:33 <athan> so you'd be expected to give your clients secret keys or something similar
13:30:46 <athan> so they can just ping `foo.json&securityId=asdf`
13:31:02 <athan> instead of needing to ping a login link, then do some horrible OAuth crap, just to fetch data
13:31:04 <Akii> can't remember, is OAuth2 stateless?
13:31:14 <bmuk> begriffs_: I use a token (probably not jwt), and pass that as a parameter in the body of the HTTP request. But you have to login once with username/password to get a token, so isn't that still state?
13:31:34 <athan> bmuk: I would consider that state
13:32:01 <Akii> "stateless" is like the state monad actually
13:33:18 <bmuk> what is the point of a RESTful service, if it can't have state? i.e. you can't have a CRUD app be RESTful because that implies state
13:33:33 <begriffs_> It's stateless in this sense: the JWT contains claims, such as this is user jdoe. When the server receives another request with this token the server doesn't have to look up any cookies or stored information to verify that it's true. The server checks the cryptographic signature. So even if there were multiple servers all load balanced any of them could handle the request, they don't need to know the history of
13:33:34 <begriffs_>  how the token was made, just check its signature with a pure function.
13:33:41 <athan> bmuk: I'm thinking the statelessness only refers to the operation of requesting data
13:33:46 <athan> the data itself could change over time
13:34:12 <bmuk> ah okay, that makes more sense
13:34:34 <Akii> the point is to have all the info needed by the server inside the request
13:35:11 <Akii> funny, that sounds functional
13:35:48 * hackagebot telegram-api 0.3.1.0 - Telegram Bot API bindings  https://hackage.haskell.org/package/telegram-api-0.3.1.0 (klappvisor)
13:43:16 <hpc> when was the last time hoogle's index was updated?
13:44:54 <lpaste> tippenein revised “map reduce with Pipes”: “map reduce with Pipes” at http://lpaste.net/163134
13:44:57 <jle`> a few years ago i think
13:45:05 <jle`> hpc: updates were put on hold for the impending release of hoogle 5
13:45:12 <Gurkenglas> I mathematically imagine a type as a set that contains \bot, with a relation that relates \bot to everything, and that has a least upper bound for each chain in the set. Does some paper talk about such a formulation of type theory?
13:45:28 <jle`> but there have been some delays in hoogle 5, so the state of the official hoogle database is in a bit of a limbo
13:45:55 <Gurkenglas> *for each ascending chain
13:46:31 <jle`> hpc: but, for now, there's http://hoogle.haskell.org (running a beta of hoogle 5) and the stackage hoogle
13:46:48 <jle`> s/alpha/beta
13:46:59 <jle`> er, s/beta/alpha, i mean
13:48:28 <jle`> but yeah, the official hoogle is about 2 years out of date at this point.  i wonder if it's worth just running an update every year or so
13:48:48 <jle`> or at least maybe consider suspending its claim as the "official" hoogle
13:55:49 * hackagebot haxr 3000.11.1.5 - XML-RPC client and server library.  https://hackage.haskell.org/package/haxr-3000.11.1.5 (BrentYorgey)
13:56:30 <shanemikel> hoogle w/o type search. that's useful
13:56:38 <lpaste> michaelt annotated “map reduce with Pipes” with “map reduce with Pipes (annotation)” at http://lpaste.net/163134#a163139
13:57:27 <shanemikel> jle` thanks for the stackage hoogle though, didn't know about that. gonna be helpful
13:57:31 <lpaste> michaelt revised “map reduce with Pipes (annotation)”: “map reduce with Pipes (annotation)” at http://lpaste.net/163139
13:58:50 <cheater> amcsi_: snap is well suited for backend, it was made specifically with that in mind
13:59:19 <cheater> bmuk: you authenticate using something and then you get a token, that token authenticates you in the future, you send it with the rest of your requests as a cookie
14:01:07 <bmuk> cheater: we put it in the request's JSON as opposed to a cookie because subdomains can snoop on cookies
14:05:22 <czapla> hi all, Im new to haskell and going through some of http://learnyouahaskell.com/ which was recommended to me as a good starting point.
14:05:49 * hackagebot cryptohash-sha1 0.11.7.1 - Fast, pure and practical SHA-1 implementation  https://hackage.haskell.org/package/cryptohash-sha1-0.11.7.1 (HerbertValerioRiedel)
14:06:31 <czapla> I am getting an error while executing the following (it's from chapter 8 - recursive data structures): 
14:06:39 <czapla> https://gist.github.com/michalczaplinski/3fd36b7d942a76c8d877b34e3de50c59
14:07:22 <dolio> What's the error?
14:07:25 <czapla> The error message is: Non type-variable argument in the constraint: Num (List a) (Use FlexibleContexts to permit this) When checking that ‘it’ has the inferred type
14:07:48 <dolio> Oh yeah. 5 isn't a List.
14:07:51 <czapla> im executing it inside jupyter notebook if that makes any difference
14:08:21 <geekosaur> dolio, it is if that instance exists :p
14:08:28 <dolio> It doesn't.
14:08:36 <aweinstock> czapla: 3 :-: 4 :-: 5 :-: Empty
14:08:59 <aweinstock> czapla: or possibly: fix (\x -> 3 :-: 4 :-: 5 :-: x)
14:09:21 * geekosaur strongly suspects the former...
14:09:46 <czapla> aweinstock: 3 :-: 4 :-: 5 :-: Empty results in the same error
14:10:07 <czapla> so I was wondering if that's an error in the book
14:11:13 <aweinstock> @let data List' a = Empty | a :-: (List' a) deriving (Show, Read, Eq, Ord); infixr 5 :-:
14:11:15 <lambdabot>  Defined.
14:11:20 <aweinstock> :t Empty
14:11:21 <lambdabot> List' a
14:11:27 <aweinstock> :t 5 :-: Empty
14:11:28 <lambdabot> Num a => List' a
14:11:37 <aweinstock> > 3 :-: 4 :-: 5 :-: Empty
14:11:40 <lambdabot>  3 :-: (4 :-: (5 :-: Empty))
14:11:51 <aweinstock> czapla: looks good to me?
14:12:08 <ski> Gurkenglas : see "domain theory" ?
14:12:41 <Gurkenglas> Ooh, thanks.
14:13:07 <ski> athan : oh, you're talking about eta ..
14:13:11 <aweinstock> czapla: are you using exactly the code from the gist, but in ghci?
14:13:18 <ski> Gurkenglas : and "denotational semantics"
14:16:07 <ski> Gurkenglas : stuff like "Complete Partial Orders", CPOs
14:16:34 <czapla> aweinstock: im using it inside the jupyter notebook. when i type it inside ghci, i get a parse error on 'infixr'.
14:22:24 <pyon> Why was (<>) made right-associative?
14:22:45 <Cale> pyon: Well, that's usually what you'd want for e.g. lists
14:23:24 <Cale> It's *supposed* to be associative and so the difference shouldn't matter except for performance.
14:24:34 <aweinstock> czapla: try (3 :-: (4 :-: (5 :-: Empty))) without the infixr in ghci
14:24:45 <athan> ski: Is there a general guideline for lambda expression evaluation s.t. space doesn't explode?
14:25:10 <athan> so I could have discrepency for applying `eta` or `beta` to an expression to evaluate it further or something?
14:25:28 <athan> (assuming the whole expression has unique namespaces through `alpha` or something)(
14:26:05 <Moon_> Hi
14:26:41 <athan> Moon_: whudup b
14:26:56 <Cale> athan: hmm, I've never heard of an evaluator which even considered applying eta expansion or contraction. It's all beta really (and sort of alpha, but you don't typically actually rename things)
14:26:57 <ski> athan : not sure what you're asking about :/
14:27:28 <athan> Cale: Shoot really? I though eta would be crucial to make sure the expression doesn't explode in size or something
14:27:33 <Cale> athan: It's just *which* beta reduction to do, when more than one applies.
14:27:38 <athan> I live off of rumors so idk :\
14:27:44 <athan> ahh okay
14:27:46 <athan> hmm
14:28:09 <athan> and that's where non-strict semantics come in to play with beta application rules?
14:28:35 <Cale> Well, lazy evaluation always picks the outermost beta
14:29:07 <Cale> (and in addition, does something to share evaluation of bound variables between their occurrences)
14:29:09 <monochrom> delete all rumours from your mind.
14:29:20 <Cale> Strict evaluation always picks an innermost beta
14:29:28 <Cale> (but not inside of a lambda)
14:29:31 <ski> athan : eta is useful in CPS, to get (repeated) tail calls not require unbounded space
14:30:13 <ski> s/Strict evaluation/Call-by-value reduction/
14:30:31 <Cale> hm?
14:30:50 * hackagebot GLUtil 0.9.0.1 - Miscellaneous OpenGL utilities.  https://hackage.haskell.org/package/GLUtil-0.9.0.1 (AnthonyCowley)
14:30:59 <monochrom> :)
14:30:59 <nkaretnikov_> wrengr_away: great post on quantifiers!
14:31:01 <ski> afaik, "strict" is about den. sem., while "by-value" is about op. sem.
14:31:06 <Cale> "Call" isn't really a word in my vocabulary
14:31:22 <Cale> So I don't like the "Call-by-X" terminology, I just find it confusing.
14:31:34 <ski> often the "call-" part is omitted
14:31:46 <ski> i agree that part is a bit confusing
14:31:57 <bernalex> "strict evaluation" is a bit confusing too.
14:31:59 <xa0> heh, just did an exam on those...
14:32:04 <athan> Cale: Oh wow okay
14:32:13 <xa0> nah i think strict evaluation is far clearer
14:32:19 <bernalex> eager evaluation of operators in Church encodings map to strict evaluation of functions.
14:32:45 <bernalex> really we're talking about eager/greedy evaluation, which is sometimes, under really weird circumstances, called strict evaluation.
14:33:00 <athan> Cale, ski You guys are awesome, thank you so much
14:33:05 <Cale> I dunno, I've always heard and used "strict evaluation"
14:33:10 <monochrom> the problem is that "strictness" is a denotational thing, not an operational, evaluation thing.
14:33:11 <Cale> everywhere
14:33:25 <HallaSurvivor> does anybody know if there's a way to make vim handle multi-line comments correctly?
14:33:37 <Cale> There's also a denotational semantics side to the same word
14:33:44 <bernalex> Cale: in evaluation strategy informatics (which is in compiler books etc), you'll usually see eager evaluation.
14:33:48 <HallaSurvivor> -- comments grey out fine, but anything inside of {- -} doesn't
14:33:50 <Cale> You can talk about whether a function is strict, which is different
14:33:52 <bernalex> but more commonly there's call-by-X.
14:34:03 <hpc> HallaSurvivor: sometimes ^L will fix it by refreshing the terminal
14:34:17 <HallaSurvivor> hpc, thanks! brb, let me try it
14:34:26 <bernalex> denotationally, you'll say "non-strict semantics", which is then in the compiler books implemented e.g. as call-by-need/lazy evaluation, or speculative evaluation, or whatever.
14:34:34 <Cale> HallaSurvivor: It does for me, though if you have a really long block comment, sometimes it will fail to notice the start of it when you're scrolling upward into it
14:34:38 <athan> monochrom: In this circumstance, how would you view the term "strictness"?
14:34:42 <hpc> vim just sometimes doesn't get multi-line highlights
14:34:48 <hpc> i see it in every language
14:34:54 <monochrom> it's a denotational thing, like I said.
14:35:13 <monochrom> denotational semantics does not commit to evaluation steps.
14:35:27 <bernalex> I see "strict semantics" and "non-strict semantics" a lot, but compiler books tends to talk about evaluation strategies, and there it's cal-by-value/eager evaluation and call-by-need/lazy evaluation. etc.
14:36:02 <athan> so how do strict and non-strict semantics affect meaning?
14:36:14 <athan> compared to how the evaluation strategy computes reduction?
14:36:19 <pyon> Cale: So, basically, it's a convention that monoid instances should be efficient when used right-associatively?
14:36:22 <monochrom> in fact, strict denotational semantics can be implemented by outermost-first evaluation too. just make sure you also do the inner ones after.
14:36:24 <pyon> s/mon/Mon/
14:36:34 <athan> monochrom: ahh wow okay
14:36:43 <hpc> basically, denotational semantics looks like equational reasoning
14:36:45 <HallaSurvivor> hpc, unfortunately it didn't work :( It's not super annoying, but it's messing with my ocd a bit :P
14:36:51 <hpc> f is non-strict if f _|_ /= _|_
14:36:53 <hpc> that sort of stuff
14:37:03 <bernalex> haskell should be (and in the '98 report *is*) a *non-strict* language, not a lazy language.
14:37:03 <athan> :O
14:37:06 <athan> oh wow okay derp
14:37:09 <athan> that makes a lot of sense
14:37:13 <Cale> pyon: Well, most of the monoid instances we care about are that way, so right-associating is a reasonable default.
14:37:21 <bernalex> because as monochrom is talking about, strictness is a denotational thing, not an implementational thing.
14:37:27 <athan> so in some light, non-strict semantics would entail a specific class of evaluation strategies though
14:37:38 <pyon> Ah.
14:37:43 <monochrom> denotational semantics tells you "what is the answer, if any". it doesn't not tell you the computer steps for getting that answer.
14:37:45 <bernalex> athan: non-strict semantics is on the denotational level, and is abstracted away from evaluation strategies.
14:38:11 <bernalex> athan: lazy evaluation is a way to implement non-strict semantics. another evaluation strategy could be non-speculative evaluation.
14:38:12 <hpc> the operational semantics would be f is lazy because in f _|_ the thunk for bottom doesn't get forced
14:38:16 <monochrom> (furthermore, denotational semantics requires you to define answers, or lack thereof, by structure induction on the language syntax.)
14:38:17 <athan> s.t. if my language L is non-strict, then `f _|_ /= _|_`, therefore I /cannot/ use by-value evaluation
14:38:25 <bernalex> I think even strict evaluation with a Lazy type could achieve non-strict semantics.
14:38:47 <monochrom> (and yes, now you know what is denotational semantics. you just don't know how to do it if the language has recursion or loops.)
14:39:00 <hpc> there are theoretically other operational strategies that map to a denotational semantics
14:39:07 <Cale> You could also pick an evaluation strategy which did one innermost-first reduction followed by an outermost-first reduction, and alternated back and forth like that, and that would have non-strict semantics.
14:39:07 <hpc> but i am not a bad enough dude to know of any of them offhand
14:39:17 <athan> bernalex: okay that makes perfect sense, thank you
14:39:20 <hpc> at least not for non-strictness
14:39:37 <bernalex> athan: uh I mean 'speculative evaluation' not 'non-speculative'.
14:39:40 <bernalex> sorry about that.
14:39:40 <monochrom> if you take a course on denotational semantics, it's 1% what I said and 99% how to deal with loops, recursion, and recursive data.
14:39:55 <athan> monochrom: that sounds freaking awesome
14:40:01 <bernalex> athan: speculative evaluation would be like "maybe we'll need this sometime, let's evaluate it just in case".
14:40:01 <monochrom> it's the only reason why denotational semantics requires a lot of math.
14:40:08 <bernalex> which is more amenable to parellisation than lazy evaluation.
14:40:30 <bernalex> there was a haskell compiler that did optimistic evaluation iirc
14:40:49 <bernalex> some spj paper.
14:40:49 <monochrom> do not underestimate the requirement "you have to define it by structural induction on syntax". it is a huge block when you try to give semantics to recursion.
14:41:01 <bernalex> IIRC it started with something like "lazy programs are beautiful but slow" :D
14:41:38 <bernalex> tl;dr is that optimistic evaluation is speculative evaluation with abort strategies.
14:41:57 <monochrom> for example suppose you write down the code "x = 0 : x".
14:42:13 <bernalex> I think it actually learned when an evaluation was too costly, and avoided doing it again. they sped up a bunch of programs compared to ghc.
14:42:21 <Cale> To put what monochrom said another way, denotational semantics is about associating mathematical objects to each of the valid terms in your language which somehow correspond to what the programs "mean", i.e. assigning mathematical values to your language's expressions. That may include values which indicate various sorts of nontermination. It could, but usually does not indicate anything about time or space performance.
14:42:21 <bernalex> so non-strict semantics is a really huge and interesting design space!
14:42:54 <bernalex> Cale: if you don't know what your program means, you can't even know if it's wrong, as conal would point out were he here. :)
14:43:21 <monochrom> you can't just say "the answer for x = 0 : the answer for x" for denotational semantics. because you violate "by structural induction on syntax". the requirment is that "the answer of expr = ... the answer of a subexpression of expr, not expr itself again ..."
14:43:36 <bernalex> it's kind of related to how unit tests can only prove that you weren't able to prove that the program is broken.
14:43:49 <monochrom> so eventually they found that they needed a lot of math on partial orders to get it done
14:43:58 <Cale> Well, that might be going too far -- there are ways to talk about whether a program is right or wrong which are more operational than denotational, but it's certainly a nice approach to start with a denotational simplification of what's going on.
14:44:17 <Cale> Note also that in practical terms, a program can be *very* wrong and still have the correct denotation.
14:44:18 <maerwald> unit tests can only prove that the program does not fail where you expect it to fail (if done right)... 
14:44:50 <Cale> It's possible for a program to take far too long to compute its result, for instance, and most denotational semantics won't capture things like that.
14:46:40 <monochrom> it is possible to rationalize the word "strict evaluation" by claiming: "I mean all operational evaluation strategies that comply with the denotational strictness"
14:46:48 <monochrom> but it is also pointless.
14:47:13 <bernalex> Cale: most (all?) denotational semantics proponents won't advocate that a denotational semantics solves everything and is the only thing you need.
14:47:31 <Cale> bernalex: sure
14:47:31 <monochrom> the space of operational evaluation strategies is still big enough to give you a wild range of asymptotic time/space behaviours that you still know nothing.
14:48:11 <Cale> I honestly don't think it would be too bad to adopt "lazy semantics" as a term -- it's the denotational semantics that corresponds to lazy evaluation. That doesn't mean that there aren't other evaluation strategies which would use the same semantics.
14:48:24 <bernalex> Cale: "lazy semantics" doesn't really mean anything usually.
14:48:34 <bernalex> Cale: languages are usually just non-strict.
14:48:35 <Cale> Yeah, I'm aware that everyone avoids that
14:48:42 <monochrom> for example, "lazy evaluation of foldl1 (+) [1..n] takes linear space" is right on. but "strict evaluation of foldl (+) [1..n] takes constant space" is wrong.
14:48:56 <Cale> But "non-strict semantics" also doesn't mean "not (strict semantics)"
14:49:08 <bernalex> Cale: no, and why should they. :)
14:49:20 <monochrom> there is a huge space of strict evaluations such that you get anywhere between constant space and linear space.
14:50:15 <monochrom> the word "strict evaluation" began from some experts 10-20 years ago, even including Richard Bird. but they were wrong. they didn't think it through.
14:50:32 <monochrom> by today's standard it is not enough to cite "the experts did it"
14:50:58 <monochrom> if the experts were wrong, kill the experts. if Buddha is wrong, kill Buddha.
14:51:55 <Cale> monochrom: It's wrong because it requires log space? ;)
14:53:14 <Cale> monochrom: Which strict evaluator would take linear space on that?
14:53:23 <monochrom> here is how to evaluate foldl (+) [1..n], even foldr, and have strictness, and still take linear space, even n lg n space if you factor in the lg n factor we usually forget
14:53:37 <monochrom> build the 1+...+n thunk first.
14:53:43 <bitemyapp> Nycatelos: yep, email us please.
14:53:46 <monochrom> now evaluate all subexpressions of it.
14:54:28 <Nycatelos> bitemyapp, to suppport@$domain?
14:54:41 <Cale> monochrom: Oh, you're talking about an evaluator with strict semantics but which doesn't do strict evaluation. Okay.
14:55:30 <Cale> monochrom: To me at least, "strict evaluation" refers to a particular reduction mechanism.
14:55:47 <Cale> Not just any reduction mechanism with strict semantics.
14:55:53 <monochrom> but you don't have a reason to call it "strict evaluation"
14:56:10 <monochrom> or at most, as much reason as calling something "call by whatever"
14:56:12 <Cale> Well, it's a particular reduction mechanism that happens to have strict semantics.
14:56:25 <Cale> which is in some sense the most obvious thing :)
14:56:48 <Cale> In particular, it's just innermost-leftmost reduction.
14:56:50 <monochrom> ok, which particular one?
14:57:22 <monochrom> is there anything in "strict" or "evaluation" that implies the innermost-leftmost one?
14:57:37 <monochrom> as opposed to the left-right-and-centre one?
14:58:20 <monochrom> is there anything that you can say "call" in "call by value"?
14:58:27 <Cale> Well, we could ask the same question about the semantics :)
14:58:32 <Cale> It's just a name
14:58:50 <Cale> Is there anything about strict semantics which makes the word "strict" appropriate?
14:59:33 <Cale> If anything, it feels a bit backward to me :)
14:59:48 <Cale> Strict semantics identifies too many terms with _|_
15:00:53 <bitemyapp> Nycatelos: email address here: http://haskellbook.com/support.html
15:01:08 <Nycatelos> bitemyapp, thanks
15:01:08 <Cale> So it's sort of "more handwavy" about the meaning of any given term than non-strict semantics, which has to make more distinctions
15:01:53 <bitemyapp> sm: thank you
15:01:57 <bitemyapp> @karma+ sm 
15:01:57 <lambdabot> sm's karma raised to 8.
15:01:59 <Cale> Perhaps they should be "coarse semantics" and "fine semantics"
15:02:20 <dolio> Smashed.
15:02:21 <Moon_> My lord, haskell is my new favorite language
15:02:27 * ski . o O ( "That's a fine semantics you have here, ..." )
15:02:40 <Rembane> ...shame if anything would happen to it...
15:02:47 * ski nods solemnly
15:03:04 <dolio> f is smashed if f(_|_) = _|_.
15:03:15 <dolio> And the constructor for the smash product is smashed in both arguments.
15:03:27 <Cale> hahaha
15:03:30 * ski . o O ( smashing bottoms )
15:03:36 <monochrom> neato
15:03:46 <bitemyapp> ski: ever thought about changing your name to sk?
15:04:09 <Cale> bckw
15:04:48 <Moon_> is there a god way to represent binary and preform nand on it in haskell?
15:04:51 <Moon_> *good
15:05:12 <monochrom> yes, look into the module Data.Bits (comes with GHC)
15:07:05 <ski> @let infixl 7 .↑.; x .↑. y = complement (x .&. y)
15:07:07 <lambdabot>  Defined.
15:07:22 <ski> @type (.↑.)
15:07:24 <lambdabot> Bits a => a -> a -> a
15:07:57 <ski> > 3 .↑. 6
15:07:59 <lambdabot>  -3
15:08:09 <ski> > 3 .↑. 6  :: Word8
15:08:11 <lambdabot>  253
15:15:37 <Cale> I actually think I really like the terms coarse and fine semantics.
15:15:43 <Cale> There's a nice comparison to topology there
15:15:55 <Cale> Where you have coarser and finer topologies
15:17:26 <Cale> and the natural definition of a homomorphism of semantics makes the analogy appropriate
15:21:32 <Cale> Also, it's just nice to be able to say that Haskell has fine semantics ;)
15:36:26 <koz_> I was reading Stephen Diehl's stuff, and he mentioned uniplate and biplate. Is there any good writeups on how to use them, and in general, should I? I have some AST-type transformations I need to do, and he claims that it's good for that.
15:42:38 <tippenein> michaelt: yeah, that's what all_files does
15:43:47 <Cale> koz_: They're certainly something to look at
15:45:00 <koz_> Cale: Do they just go by 'uniplate' and 'biplate' on Hackage, or is the actual package called some other thing?
15:45:22 <Cale> https://hackage.haskell.org/package/uniplate
15:45:53 * hackagebot yaml-light-lens 0.3.3.2 - Lens interface to yaml-light.  https://hackage.haskell.org/package/yaml-light-lens-0.3.3.2 (AnthonyCowley)
15:46:06 <TheSomebody> hey, I'm pretty new to lenses. I have a Maybe Fold' and would like to turn this into a Fold' (so basically I'm looking for a Fold' that always fails, but not _Void as that doesn't match the correct type)
15:46:28 <Cale> koz_: There is also https://hackage.haskell.org/package/multiplate which is a similar take on things
15:46:53 <TheSomebody> i.e. I need a maybe _FoldThatAlwaysFails
15:46:56 <TheSomebody> am I approaching this wrong?
15:47:24 <koz_> Cale: Which one should I use? uniplate seems to have had no updates for a while.
15:47:25 <TheSomebody> (I actually have a Maybe Int and would like to ^? to get the list element)
15:47:46 <koz_> TheSomebody: Look at Prisms.
15:47:51 <koz_> (I think that's what you're after)
15:48:02 <jle`> what list?
15:48:02 <Cale> koz_: I can't really imagine why these libraries would need to be updated, so I wouldn't take that as a bad sign
15:48:30 <koz_> Cale: OK, I'll have a look at both of them.
15:49:28 <koz_> Cale: I guess I'm also gonna have to be familiar with how Data and Typeable do their thing to understand uniplate?
15:49:29 <TheSomebody> I thought prisms are stronger? (all prisms are traversals, and all traversals are folds?)
15:49:42 <jle`> what are you trying to do at the higher level?
15:49:48 <Cale> TheSomebody: What do you mean by "fails"?
15:49:55 <TheSomebody> I have a list [a], and a Maybe Int.
15:50:18 <TheSomebody> say ix :: Maybe Int, l :: [a]
15:50:34 <johnw> TheSomebody: see the chart on https://hackage.haskell.org/package/lens
15:50:42 <johnw> Fold is more general than Traversal
15:50:56 <TheSomebody> I'd like to get a fold that essentialls does: fmap (l!!) ix
15:51:28 <jle`> what are you planning to do with that fold?
15:52:01 <TheSomebody> yes, agreed, and I only need the fold, which is why I didn't understand why I should look at prisms?
15:52:27 <TheSomebody> just use it to access the list element
15:52:45 <Cale> I... don't really even understand why you'd need stuff from Lens for this :)
15:52:58 <TheSomebody> because lens is cool and I'm trying to learn it
15:53:19 <Cale> Fair enough
15:53:28 <jle`> you might not have much success learning it if you apply it to weird things it might not be suited for :)
15:54:05 <TheSomebody> why is it not suited to this?
15:54:15 <Cale> Folds don't fail though
15:54:21 <TheSomebody> (other than being overkill)
15:54:24 <Cale> Prisms have a notion of failing to match
15:55:20 <TheSomebody> "When using a Traversal as a partial Lens, or a Fold as a partial Getter" - doesn't that mean a Fold can "fail" (in the sense of not being defined everywhere)?
15:55:35 <TheSomebody> or am I misreading this completely?
15:56:31 <TheSomebody> (it's from here: https://hackage.haskell.org/package/lens-4.14/docs/Control-Lens-Fold.html#v:-94--63-)
15:57:52 <glguy> Regarding the fold that always fails above:
15:57:56 <glguy> preview (maybe ignored ix (Just 043)) 04"my string"
16:00:50 <TheSomebody> cool, and [over ignored f == id] if I'm reading this right
16:01:40 <Cale> yeah
16:03:46 <glguy> maybe ignored ix 07:: Ixed s 07=> Maybe (Index s) 07-> Traversal' s (IxValue s)
16:03:47 <Cale> I'm not really sure in what sense a Traversal is a partial Lens... but sure, you can have a Traversal which successfully traverses no elements of something :)
16:07:18 <bizarrefish> hi all
16:07:23 <hjljo> hi
16:07:40 <TheSomebody> (thanks for the help, I'll try to understand that diagram better, so many types, so confusing...)
16:07:44 <EvanR> Cale: a prism maybe, which is a special kind of traversal
16:07:57 <bizarrefish> would it be fair to say fmap lifts morphisms from Hask to some other category?
16:08:13 * bizarrefish is trying to get some theory down, still
16:09:43 <jle`> bizarrefish: mostly true, Functor represents endo-functors, so the morphisms go from Hask to Hask
16:09:49 <michaelt> the Functors in question are 'endofunctors :: Hask -> Hask'
16:10:57 <EvanR> it would be interesting to model other kinds of functors within haskell
16:11:05 <EvanR> from one category to another inside haskell
16:11:12 <johnw> EvanR: this is possible, and there is a blog post about it
16:11:27 <johnw> https://dorchard.wordpress.com/2011/10/18/subcategories-in-haskell-exofunctors/
16:11:29 <bizarrefish> Isn't it common to model non-Hask categories with types?
16:11:45 <bizarrefish> Maybe category, List category, etc..
16:11:53 <EvanR> Maybe and List have the wrong kind
16:12:12 <bizarrefish> Category needs to be a -> b -> * ?
16:12:23 <michaelt> a -> a -> *
16:12:45 <bizarrefish> Oh, right. Kinds.
16:12:48 <EvanR> k -> k -> * ?
16:12:52 * bizarrefish scratches head
16:13:06 * EvanR would have first thought * -> * -> *
16:13:07 <michaelt> :k Category
16:13:09 <lambdabot> (k -> k -> *) -> Constraint
16:13:12 <jle`> bizarrefish: if your category has types as objects, and (->) to represent morphisms, then it *is* Hask
16:13:30 <jle`> in the case of Functor functors, the target category has haskell types as its objects, and (->) for its morphisms
16:13:35 <jle`> so it's Hask :)
16:13:44 <Welkin> did anyone else get fucked by the ubuntu 14.04 update today?
16:14:06 <bizarrefish> I'm trying to think of what a non-endo functor would look like, if all the functors are endofunctors.
16:14:09 <michaelt> The objects in a Category (in recent base) can be of any 'kind', the arrows will be in *
16:14:15 <jle`> not all functors are endofunctors
16:14:24 <jle`> but the typeclass Functor represents endofunctors
16:14:31 <jle`> *its instances are endofunctors
16:14:58 <bizarrefish> That's what I meant...i think
16:15:03 <jle`> you could parameterize your Functor by the source and target "category"
16:15:22 <bizarrefish> So, even in List, the morphism is still ->
16:15:34 <bizarrefish> Or Maybe, or Free, or Id
16:15:44 <jle`> (those aren't categories, but i think i know what you mean)
16:16:06 <jle`> List and Maybe are functors, not categories
16:16:07 <bizarrefish> Indeed, they're all...endofunctors in Hask.
16:16:27 <jle`> they take you from a Category defined by (->) to a Category defined by (->)
16:16:36 <jle`> well, their Functor instances do
16:17:29 <jle`> but there are some common non-(->) categories in Haskell.  there's `Kleisli m` (for any Monad m), whose objects are Haskell types, but whose morphisms have the form Kleisli m a b
16:17:42 <jle`> (a newtype for a -> m b)
16:17:43 <Cale> EvanR: https://github.com/ekmett/hask/blob/master/src/Hask/Category.hs
16:18:06 <Cale> EvanR: in particular, see the definition of Functor there :)
16:18:15 <jle`> and there's the mealy machine / auto category that people often bring up
16:19:17 <jle`> (and these are just categories whose objects are Haskell types)
16:19:46 <Cale> instance Functor Dict where
16:19:46 <Cale>   type Dom Dict = (:-)
16:19:46 <Cale>   type Cod Dict = (->)
16:19:46 <Cale>   fmap f Dict = case f of Sub g -> g
16:20:09 <jle`> super cute
16:20:58 <Cale> instance Functor (,) where
16:20:58 <Cale>   type Dom (,) = (->)
16:20:58 <Cale>   type Cod (,) = Nat (->) (->)
16:20:58 <Cale>   fmap f = Nat $ \(a,b) -> (f a, b)
16:21:10 <Cale> ^^ how to fmap over the first component of a pair ;)
16:24:32 <maerwald> Cale: that's a nice link to scare people away from haskell :P
16:26:02 <bizarrefish> So....fmap puts a morphism in a functor. return puts an object in a functor?
16:26:18 <suzu> all this abstraction astronautism is good for scaring people away from hs
16:26:19 <suzu> lol
16:26:33 <Cale> If f is a functor, then fmap says how to turn a function (a -> b) into a function (f a -> f b)
16:26:38 <bizarrefish> I'm trying to scare myself into understanding :P
16:26:56 <bizarrefish> (it helps to at least glimpse a lot more than you need to *know*)
16:27:07 <suzu> fmap lets functions work with functors
16:27:11 <suzu> return puts stuff inside a functor
16:27:22 <suzu> work with stuff inside a functor *
16:27:30 <Cale> I don't like "puts stuff inside"
16:27:36 <bizarrefish> Thing is, I can use functors and monads and stuff, but I want to know how they relate to the category theory stuff.
16:27:38 <suzu> i think its a good intuition for beginning
16:27:46 <suzu> then once you find out a function is a functor things go cray
16:27:48 <bizarrefish> Cale: I didn't like 'puts in' either
16:27:55 <bizarrefish> Suggests a container.
16:28:42 <Cale> A better analogy for how we're usually using monads, is the computational one: return v is an m-action which does nothing except always produces v as its result when executed.
16:28:56 <Cale> i.e. it "returns v"
16:29:01 <bizarrefish> That's how I always think of Monads.
16:29:32 <bizarrefish> I often say 'yields', but that gets annoying when working with coroutines, where the yielding is something different altogether.
16:29:41 <suzu> that'll screw you up with pipes/conduit too
16:29:41 <suzu> :P
16:29:45 <bizarrefish> 'Ultimately results in'
16:29:49 <bizarrefish> :)
16:30:04 <Carl_Miller> Hi
16:30:10 <bizarrefish> elo
16:30:12 <Cale> I think the term "returns" is perfectly okay here
16:30:12 <suzu> hi
16:30:25 <bizarrefish> I remember when I discovered 'sequence'. Mind=Blown.
16:30:57 <Cale> Well, functions like sequence are the whole point of bothering talking about monads
16:31:00 <bizarrefish> Of course, I implemented it. Then I came on here feeling like I'd touched the face of god, and someone here told me I was talking about sequence.
16:31:24 <Cale> If we didn't have things like sequence and liftM2 and so on which worked with an arbitrary choice of monad, there would be no point in talking about monads.
16:31:41 <bizarrefish> I then went on a kind of monad rampage, where I implemented some monads in Java.
16:31:50 <suzu> implement a monad in Java?
16:31:55 <suzu> cool
16:32:06 <jle`> huh, would you call a length-encoded vector type a dependent type?
16:32:10 <jle`> like Vec 10
16:32:11 <Cale> bizarrefish: Were you able to define a sequence function which could work with any monad? :)
16:32:36 <Cale> That, I think, is the real litmus test for whether you've captured the abstraction correctly.
16:32:48 <bizarrefish> Cale: Nope
16:32:53 <bizarrefish> not in java, anyway
16:33:17 <Cale> Yeah, it's tricky and/or awkward
16:33:21 <bizarrefish> I actually cooked it up in Scala, but scala didn't like it either (at least, not the way I was writing it, because scala has too many type systems :P)
16:33:25 <Cale> to do it in just about anything other than Haskell
16:33:41 <suzu> i would think that >>= looks like a cluster in pretty much anything that isnt hs
16:33:55 <Cale> You sort of need type classes to make Monad useful as an abstraction, because that third function parameter to (>>=) just makes everything suck.
16:33:59 <bizarrefish> An implementation of a Free monad in Java = https://gist.github.com/bizarrefish/c8258bb8e1b1263be440965d89521472
16:34:25 <maerwald> bizarrefish: indenting level over 9000
16:34:37 <bizarrefish> I use anonymous nested classes to make the binding thing slightly prettier, and some additional operators I call 'then' and 'thenreturn' :P
16:34:44 <bizarrefish> or thenimmediate, or something
16:34:45 <Cale> maerwald: it's just tabs
16:34:51 <bizarrefish> maerwald: Ja :D
16:35:08 <maerwald> Cale: oh right, I forgot people use that in inferior languages
16:35:15 <Cale> hahaha
16:35:43 <bizarrefish> The Java 7 version is actually the best part. At the top is the Java 8 version which uses lambdas
16:36:04 <bizarrefish> SEQUENCE, BITCH: https://gist.github.com/bizarrefish/c8258bb8e1b1263be440965d89521472#file-chattermonad-java-L183
16:36:23 <bizarrefish> It's horrible
16:36:36 <Cale> bizarrefish: Except defining it separately for each monad defeats the whole purpose of talking about monads in the first place :P
16:36:48 <bizarrefish> Cale: Not the whole purpose, but at least 50%
16:36:56 <bizarrefish> You can do a lot with just that monad
16:37:02 <ski> bizarrefish : fwiw, s/monad/monadic action/, in several places
16:37:07 <bizarrefish> Though I guess the observation that it's a monad....is irrelevant
16:37:17 <Cale> right
16:37:43 <Cale> If you can't write code which works with an arbitrary monad, then the observation that something is a monad is pointless
16:37:55 <Cale> (mostly)
16:38:41 <bizarrefish> Cale: Still good for documentation purposes. Anyone reading that clusterfuck might have an easier time if you tell them that it's a monad,
16:38:46 <Cale> right
16:39:29 <Cale> and maybe for inspiration in terms of how to structure a library
16:40:07 <simpson> bizarrefish: It could be worse.
16:40:14 <bizarrefish> I'll say I use a much neater variant of this in the implementation of a binary request/response protocol, and damn it produces code which works first time!
16:40:50 <Cale> bizarrefish: I bet you *could* do an encoding in Java which would let you have polymorphic sequence, but it would be a good deal more annoying to use, because you'd have to pass which monad you were using as an argument to everything.
16:40:54 <bizarrefish> (That's what I always liked about haskell, the code tends to work first time)
16:41:14 <simpson> bizarrefish: Look, it's scanl. Kind of. https://github.com/MostAwesomeDude/mt-stream/blob/master/stream.mt#L91-L108
16:41:16 <bizarrefish> Cale: Indeed, i'm an engineer, so I gotta tradeoff :/
16:41:45 <Cale> There would be a generic bind operation which would take a record of the monad operations as an argument, and would basically extract the relevant bind operation from that
16:42:05 <exio4> you'd basically compile Haskell code? :P
16:42:17 <Cale> You'd compile the type class machinery away
16:42:21 <Cale> and then translate
16:42:50 <bizarrefish> simpson: What's .mt?
16:42:55 <Cale> (>>=) :: Monad m -> m a -> (a -> m b) -> m b -- but can Java even do this much?
16:43:11 <simpson> bizarrefish: Monte. http://monte.rtfd.org/
16:43:13 <jle`> there's a javascript library that implements generic monadic functions i believe
16:43:22 <bizarrefish> Cale: Sounds like perhaps some kind of...visitor implementation.
16:43:23 <jle`> with decent syntax
16:43:37 <Cale> You can definitely do this trick in Javascript or most dynamically typed things
16:43:42 <bizarrefish> In fact, you might be doing triple-dispatch there
16:43:46 <bizarrefish> Lemme think
16:44:05 <simpson> bizarrefish: Basically I implemented `data Stream a = Stream a (Stream a)` in Monte, and added explicit backpressure, and then started adding the various utility functions.
16:44:12 <bizarrefish> Heh, sounds like the turning point for the protagonist of some crappy programming-based anime
16:44:15 <bizarrefish> :P
16:44:26 * bizarrefish makes gasping sounds
16:44:37 <simpson> I did map, fold, filter, scan, and then my brain started leaking.
16:44:44 <bizarrefish> simpson: Currently looking up what scanl does :)
16:44:57 <jle`> > scanl (*) [1,2,3,4,5]
16:44:59 <lambdabot>      No instance for (Typeable t0)
16:44:59 <lambdabot>        arising from a use of ‘show_M591983918849238959818583’
16:44:59 <lambdabot>      In the expression:
16:45:01 <jle`> aw
16:45:03 * Carl_Miller scoops up simpson's brains, pours them back in their ears, then puts them back in the freezer
16:45:04 <jle`> > scanl (*) 1 [1,2,3,4,5]
16:45:05 <lambdabot>  [1,1,2,6,24,120]
16:45:17 <jle`> it's a little weird that scanl includes the initial accumulator
16:45:29 <Cale> At one point I wrote a bunch of higher order functions in dc
16:45:41 <Cale> I don't know if I even have the file any more
16:45:49 <Cale> dc is basically line noise
16:46:02 <simpson> > scanl (+) 0 [1..5] -- triangulars
16:46:04 <lambdabot>  [0,1,3,6,10,15]
16:46:39 <jle`> > scanl f a [x,y,z]
16:46:41 <lambdabot>  [a,f a x,f (f a x) y,f (f (f a x) y) z]
16:46:41 <simpson> jle`: Yeah, I wracked my brains for a while trying to understand how to model that. I finally got it when I understood that the recursive call to scanl is delayed for longer than I had thought.
16:46:47 <Cale> I mean, what languages do you know which admit newline as an identifier symbol?
16:47:13 <jle`> > scanl (+) 0 [1..5] :: [Expr]
16:47:14 <lambdabot>  [0,0 + 1,0 + 1 + 2,0 + 1 + 2 + 3,0 + 1 + 2 + 3 + 4,0 + 1 + 2 + 3 + 4 + 5]
16:47:14 <Cale> "dc provides at least 256 memory registers, each named by a single character. You can store a number or a string in a register and retrieve it later."
16:47:39 <Cale> We need unicode dc
16:48:12 <Cale> So that we can have zero-width joiner as the name of a memory register
16:52:36 <bizarrefish> Cale: Can you use BELL?
16:53:26 <Cale> bizarrefish: any byte
16:53:50 <bizarrefish> Hector Salamanca: ^G ^G ^G ^G ^G
16:54:02 <bizarrefish> Hmm
16:54:11 <bizarrefish> Damn, we need this in Java
16:54:14 <bizarrefish> (my day-job is java)
16:54:51 <Zekka|Sigfig> bizarrefish: It might be fair to say fmap lifts morphisms to another category, but it will confuse people who don’t know the same theory
16:55:45 <Zekka|Sigfig> I would say “a functor is like a container; if so, fmap maps over the contents”
16:56:09 <Zekka|Sigfig> imho, be sure to use language that (a) you completely understand (b) people around you will mostly understand
16:56:29 <Cale> Well, in Haskell, all our instances of Functor are endofunctors, and so it's always to the same category
16:56:44 <Cale> (unless you're using Ed's Hask package)
16:57:06 <Zekka|Sigfig> Cale: I guess what I’m hinting at is that you probably shouldn’t speak category theory at all unless your audience is specifically category theorists
16:57:22 <Zekka|Sigfig> I’m not sure most programmers have a good reason to know or care about category theory
16:57:55 <bizarrefish> More perspective is sometimes good, even if the 'why' isn't clear.
16:58:13 <bizarrefish> It expands their minds, expanded mind = better programmer with more perspective?
16:58:16 <jle`> bizarrefish specifically asked about category theory, though, so i think bringing up concepts is fair :)
16:58:28 <Zekka|Sigfig> Well, there’s a whole lot of things you can learn to expand your mind, and no one has time for all of them
16:58:49 <bizarrefish> Indeed, Category theory is the one i've picked. I'm about 3 days into thinking seriously about it
16:58:56 <Zekka|Sigfig> usually you want to try to teach people on thing at a time
16:58:56 <bizarrefish> Damn, I wish I had a mentor
16:59:16 <bizarrefish> Indeed, I learned this the first time I needed to train someone at work :P
16:59:25 <Zekka|Sigfig> I’m really trying to give communication advice more than learning/self-teaching advice — if you think “category theory seems cool, I want to know more about it” then there’s nothing wrong with that
16:59:30 <bizarrefish> The guy had 0 commercial experience, it was hard.
17:00:01 <bizarrefish> Indeed, I agree. It would be improper to go sticking category-theory-esque comments all over my source code.
17:00:04 <bizarrefish> :P
17:00:12 <Zekka|Sigfig> Most of the reason I bring this up is because I run into a lot of people in this channel who seem to use more theoretical descriptions than they probably need to
17:00:44 <bizarrefish> I'll quite happily listen to all of them until I eventually get what they're talking about :D
17:00:59 <Zekka|Sigfig> you’ll run into people who specifically say you need a free monadic design, when what they mean is “you should define a data type that represents programs”
17:01:11 <bizarrefish> But indeed, not everybody learns that way, and i'm not even sure it's optimal for me, but I don't know any better one
17:01:31 <suzu> how can i get a strict array?
17:01:31 <bizarrefish> I'd tend to say both, in that case.
17:01:39 <Zekka|Sigfig> Yeah, I think that’d be fine
17:01:45 <shanemikel> if cats were tossed around more often, i bet it would help with the communication gap, and i might learn it on accident, who knows :)
17:01:47 <suzu> Data.Array seems to be non-strict
17:01:48 <monochrom> no, what you need is Randall's new book Thing Explainer.
17:02:00 <Zekka|Sigfig> you’re probably trying to teach two things: one, it’s useful to solve some problems by using a data type to represent programs
17:02:05 <bizarrefish> I built such a monad recently, in fact, and used program-words like 'executeProgram(ProgramMonad<T>)'
17:02:07 <Zekka|Sigfig> two: Free is a really good tool to do that
17:02:14 <bizarrefish> Free is best monad evar
17:02:16 <Zekka|Sigfig> (imho both are true)
17:02:22 <johnw> shanemikel: I wager to think that if cats were tossed around, learning is definitely something that would happen
17:02:26 <jle`> (Free is not monad, but)
17:03:21 <bizarrefish> For clarity, it wasn't a fully generalized free monad (Java isn't good at doing that stuff), it had some types and structure fixed, a little assumption here or there.
17:03:33 <shanemikel> I don't really think the "context" thing is a gem
17:03:41 <bizarrefish> Context monad?
17:04:01 <Zekka|Sigfig> I think “context” is a nice word but only once you and your learner already know what it means
17:04:11 <shanemikel> no, it's a common metaphor for monads, functors, applicatives, etc
17:04:13 <Zekka|Sigfig> it’s way better than “container” but your learner probably already understands “container” and not “context”
17:04:19 <shanemikel> "Computation within a context"
17:04:20 <bizarrefish> Oh right, I see what you mean.
17:04:39 <Cale> "context" is a word that I hate even more than "container" when it comes to monad explanations
17:04:43 <bizarrefish> Yeah, it's hard to argue with it, but it's also still prone to leaving the listener going 'whut?'
17:04:50 <Cale> Because *I* don't even know what it means
17:04:58 <Zekka|Sigfig> If you say “Functor” and your explanation is “context” you’ve just introduced another level of indirection
17:05:06 <Cale> and it just seems totally inappropriate to the situation
17:05:14 <shanemikel> maybe if the context was better, it'd make sense
17:05:16 <bizarrefish> Then the category theorists define context as a functor!
17:05:16 <bizarrefish> :D
17:05:27 <suzu> actually better question
17:05:32 <suzu> does takeWhile work in O(n)?
17:05:33 <ggVGc> Cale: context to me means "Carries an environment with it"
17:05:44 <ggVGc> i.e something that exists in a context has a reference to an environment
17:06:04 <Cale> yeah, that's not an appropriate description of even Reader actions
17:06:04 <ggVGc> if I exist in the context of the world, I have a reference to the world
17:06:05 <bizarrefish> Reader monad would be an example of that
17:06:30 <bizarrefish> (at least, if someone had said to me 'carries an environment with it', i would probably have said: 'what, like a class?')
17:06:48 <Zekka|Sigfig> FWIW one thing I think is pretty important: when you teach someone something, you want them to feel the pain point and you want to target your solution to that pain point
17:06:49 <davean> suzu: "takeWhile" on what? on a list? On a Sequence?
17:06:49 <Cale> Reader actions explain what to do with an arbitrary environment of the appropriate type, but they don't have a reference to any particular environment
17:06:50 <bizarrefish> At which point the explaining person would likely have wanted to stab me
17:06:56 <suzu> a list
17:06:56 <davean> suzu: It varies by datastructure
17:06:58 <shanemikel> that's what I take it for, but somehow the word context at first seems meaningless
17:07:11 <Cale> and the analogy gets even worse for other monads
17:07:15 <Zekka|Sigfig> Explanations like “use Free” almost never accomplish this, because the part of the explanation that would have addressed the pain point is hidden behind a word the learner doesn’t know
17:07:49 <davean> suzu: then yes, or more specificly O(min(t, n)) where t is the requested amount, and n is the length of the list.
17:07:55 <suzu> i see
17:08:00 <suzu> is there an O(1) accumulation takeWhile?
17:08:03 <suzu> and by that i mean
17:08:08 <monochrom> "context" and "computation" are great words that you can use so people think they know, maximizing the Dunning-Kruger effect.
17:08:17 <davean> accumulation?
17:08:19 <suzu> i want to accumulate a prefix from a list
17:08:21 <jle`> suzu: i'm not sure how takeWhile would work without checking every element until you find soemthing that doesn't satisfy the predicate
17:08:35 <jle`> suzu: how else would it know that the first ten items satisfy the predicate without testing all ten of them?
17:08:44 <suzu> but i dont want the accumulation on each item to be O(n) in the size of the accumulator
17:08:46 <Zekka|Sigfig> I’ll be back in a little bit, possibly on another computer
17:08:46 <Cale> "Computation" can be confusing at the outset, but at least it's technically correct.
17:08:49 <suzu> or else it'd grow at O(n^2)
17:08:51 <suzu> :/
17:08:52 <davean> jle`: A finger tree where the takeWhile is on the metric
17:08:52 <jle`> how would takeWhile (<= 6) [1..] work without checking the first 6 lists?
17:08:54 <jle`> *items
17:08:59 <Cale> (I recall being confused by it myself, even)
17:09:00 <suzu> jle`: you are correct
17:09:05 <suzu> i mean in the accumulation
17:09:13 <monochrom> like I always say, there are two opposite kinds of "understanding". first kind is "can write an essay that gets an A+ from an essay teacher". second kind is "passes scientific tests".
17:09:16 <jle`> davean: sure, that requires a specific data structure that's aware of your predicate, heh.  doesn't work for all predicates in general
17:09:28 <davean> jle`: no, which is why I asked him what it was on
17:09:57 <jle`> suzu: what do you mean 'on the accumulation' ... can you show an exmaple?
17:10:32 <shanemikel> yeah, that's worth something, I guess.  plus, it has a verb form and can imply imperative instruction
17:10:35 <suzu> yes, so for instance
17:10:39 <suzu> say i had a list [1..]
17:10:43 <Cale> The word "action" is reasonably good somehow. It seems to work better than "computation", even though you might not expect there to be much difference
17:10:53 <suzu> and i wanted to get the first 10 even numbers
17:11:07 <suzu> i'd have an accumulator of []
17:11:14 <suzu> walk until i find a 2
17:11:34 <suzu> add that to my accumulator, which is O(n) if i do [] ++ [2]
17:11:44 <suzu> and then when i find the 4 i'd do [2] ++ [4]
17:11:49 <suzu> and so this is going to run terribly
17:11:57 <cheater> :t liftM
17:11:58 <monochrom> I am less harsh on "container". people's idea of "container" has a significant overlap with the Functor type class, even Traversable and Applicative.
17:11:58 <lambdabot> Monad m => (a1 -> r) -> m a1 -> m r
17:11:59 <johnw> Cale: I bet there is no good word
17:12:02 <cheater> :t (<$>)
17:12:03 <lambdabot> Functor f => (a -> b) -> f a -> f b
17:12:05 <jle`> @src takeWhile
17:12:05 <lambdabot> takeWhile _ []                 = []
17:12:05 <lambdabot> takeWhile p (x:xs) | p x       = x : takeWhile p xs
17:12:05 <lambdabot>                    | otherwise = []
17:12:15 <Cale> johnw: Well, you need to give examples.
17:12:19 <cheater> <$> for a Monad is just liftM right?
17:12:29 <monochrom> yes there is liftM
17:12:46 <monochrom> but I still recommend <$> or fmap, simply because Prelude has it already :)
17:12:46 <suzu> does that make sense?
17:12:47 <Cale> monochrom: Same here.
17:13:05 <cheater> are there any times liftM will do something different than <$>?
17:13:11 <suzu> every time i want to append to the accumulator, i walk the entire thing in this case, because my accumulator data structure is a list
17:13:12 <jle`> suzu: doesn't sound like an issue about takeWhile, though
17:13:31 <Cale> monochrom: (being less harsh about "container" -- though I do get picky about container-y explanations)
17:13:39 <cheater> does AMP mean that they have to be exactly the same in result? (but not necessarily the way the result is computed)
17:13:40 <jle`> you can use diff lists to get linear accumulations, too
17:13:51 <jle`> cheater: they should behave the same, from the Monad laws
17:14:01 <cheater> how do you get that from the laws?
17:14:01 <jle`> this was true even before AMP :)
17:14:10 <suzu> are there other data structures that have an O(1) snoc?
17:14:12 <monochrom> I think sometimes liftM may be a little bit less efficient because it's hardcoded to "m >>= return . f". but I am not sure.
17:14:17 <suzu> other than a difflist
17:14:28 <monochrom> oh yes, AMP does imply they should give the same answers.
17:15:02 <Cale> suzu: sure, various sorts of trees can do that
17:15:16 <Cale> suzu: Or indeed, snoc-lists
17:15:20 <jle`> suzu: alternatively you can do a right fold instead fo a left fold, like takeWhile does
17:15:48 <jle`> so you're always consin'
17:15:58 <cheater> jle`: ok... but how do you get that from the laws?
17:16:26 <shanemikel> Dunning-Kruger effect. I can't help but suspect the behavioral phsychologists for contributing to this
17:16:39 <shanemikel> finally, they're studying themselves!
17:17:04 <monochrom> haha
17:17:19 <shanemikel> err.. developmental psychologists
17:17:24 <jle`> cheater: i can't think of the actual proof right now, but the documentation for Monad seems to imply that fmap = liftM comes from the laws
17:17:27 <jle`> cheater: http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Monad.html#t:Monad
17:17:38 <suzu> oh hmm
17:18:08 <jle`> suzu: note that takeWhile accumulates a list, but it's O(n) on the accumulated list
17:18:25 <suzu> yeah how does that magic work
17:18:42 <jle`> it's not magic, just look at the source :)
17:18:44 <jle`> @src takeWhile
17:18:45 <lambdabot> takeWhile _ []                 = []
17:18:45 <lambdabot> takeWhile p (x:xs) | p x       = x : takeWhile p xs
17:18:45 <lambdabot>                    | otherwise = []
17:18:57 <suzu> i was just googling for the source just now
17:18:59 <jle`> it just conses x to the rest of the list's takeWhile
17:19:00 <suzu> didnt know lambdabot could print it
17:19:00 <bizarrefish> It's been a stimulating discussion, but alas, I must go and sleep for some period of time. Toodloo, peeps.
17:19:01 <suzu> neat
17:19:21 <jle`> suzu: it's the same way 'map' is O(n)
17:19:29 <bizarrefish> May you all find your functor to happiness.
17:19:30 <suzu> i'll just write my code in a similar fashion then
17:19:42 <jle`> map id [1,2,3] isn't (([] ++ [1]) ++ [2]) ++ [3]
17:19:43 <suzu> no need for me to pull out the datastruct death ray here
17:19:46 <suzu> :)
17:19:51 <jle`> it's 1 : 2 : 3 : [] :)
17:20:29 <jle`> if map id [1,2,3] was (([] ++ [1]) ++ [2]) ++ [3] we'd probably all be in trouble
17:25:01 <monochrom> cleary, it should be (([1] ++ [2]) ++ [3]) ++ []  :)
17:25:33 <monochrom> it's how java and python do it :)
17:27:00 <cheater> it says "In many situations, the liftM operations can be replaced by uses of ap, which promotes function application.
17:27:03 <cheater> "
17:27:07 <cheater> but not in all situations
17:27:14 <cheater> which is the confusing part for me
17:28:27 <monochrom> clearly, liftM f m = return f `ap` m :)
17:36:26 <roboguy`> cheater: ap is <*>, which is more flexible than liftM (aka fmap)
17:36:37 <koz_> How is Ord defined for lists? Is it by maximum element?
17:36:58 <mauke> koz_: lexicographically
17:37:15 <cheater> :t liftM
17:37:16 <lambdabot> Monad m => (a1 -> r) -> m a1 -> m r
17:37:17 <cheater> :t ap
17:37:18 <lambdabot> Monad m => m (a -> b) -> m a -> m b
17:37:25 <cheater> :t fmap
17:37:26 <lambdabot> Functor f => (a -> b) -> f a -> f b
17:37:29 <nitrix> koz_: e.g. "aaa" is before "aab"
17:37:32 <koz_> mauke: Ah, I see. That explains it.
17:37:52 <nitrix> s/before/LT/
17:38:14 <koz_> nitrix: I guess that's why String behaves the way it should.
17:38:22 <koz_> Since String is just [Char].
17:38:27 <nitrix> koz_: Yep.
17:38:35 <koz_> Alrighty, thanks.
17:38:52 <nitrix> koz_: Then each individual elements are ordered based on the element's Ord instance.
17:40:02 <roboguy`> > pure (+) <*> Just 1 <*> Just 2
17:40:04 <lambdabot>  Just 3
17:40:57 <roboguy`> > return (+) `ap` Just 1 `ap` Just 2  -- Alternatively
17:40:59 <lambdabot>  Just 3
17:41:10 <nitrix> > (+) <$> Just 1 <*> Just 2
17:41:11 <lambdabot>  Just 3
17:41:25 <nitrix> > Just (1+) <*> Just 2
17:41:27 <lambdabot>  Just 3
17:50:05 <hackrilege> \query lambdabot
17:51:57 <hackrilege> oh, why cant i do this;
17:52:01 <hackrilege> @let http://lpaste.net/163144
17:52:01 <lambdabot>  Parse failed: TemplateHaskell is not enabled
17:52:03 <hackrilege> ?
17:53:54 <nitrix> Those ">"'s are weird.
17:55:36 <hackrilege> do you think thats it? its just literal haskell...
17:55:49 <hackrilege> i like it easy to comment things out for debuging
17:56:31 <pavonia> What file extension does your module have?
17:58:41 <nitrix> I see many `Nothing -> Nothing`.
17:59:05 <nitrix> Normally that's a sign you should look into functors. Or maybe that's ill-advised :/
18:00:20 <exio4> Functors, Applicatives, Monads =P 
18:00:30 <hackrilege> sorry bad connection
18:00:34 <nitrix> hackrilege: I see many `Nothing -> Nothing`.
18:00:46 <nitrix> hackrilege: Normally that's a sign you should look into functors/applicatives/monads.
18:01:35 <Cale> Well, not functors in general
18:01:37 <Cale> Just Maybe
18:01:39 <Cale> :)
18:01:44 <hackrilege> (=<<)
18:01:47 <hackrilege> :t (=<<)
18:01:49 <lambdabot> Monad m => (a -> m b) -> m a -> m b
18:02:01 <hackrilege> see left',right' i was just being lazy sorry
18:02:03 <nitrix> Cale: Kind error! :P
18:03:25 <Cale> :k Just Maybe
18:03:26 <lambdabot> Maybe (* -> *)
18:03:40 <Cale> It kind checks :)
18:03:55 <monochrom> you are evil :)
18:04:15 <obadz> :k 
18:04:16 <lambdabot>     parse error (possibly incorrect indentation or mismatched brackets)
18:04:19 <obadz> :k Just
18:04:21 <lambdabot> k -> Maybe k
18:04:25 <obadz> huh?
18:04:26 <nitrix> I see what you did there.
18:04:26 <hackrilege> anyway, it looks like as there are many ways Free can opperate as a stack (depending at which level to add things), i was hoping that by making Free a a Zipper that i could use left and right to navigate to the level i wanted to lush and pull at...
18:04:34 <obadz> is this because of GHC 8 unification?
18:04:46 <Cale> Nah, this is a GHC 7.x thing
18:04:49 <Cale> It's DataKinds
18:04:55 <hackrilege> can anyone here me?
18:05:12 <hackrilege> :D
18:05:37 <forker> This strikes me as quite a bit of boilerplate: https://github.com/prowdsponsor/esqueleto/blob/master/src/Database/Esqueleto/Internal/Language.hs#L340 (identical function types). Is there anything existing/coming that would allow to declare type synonyms within typeclasses?
18:06:07 <Cale> forker: You can list multiple things on the left of the ::
18:06:33 <Cale> They could have written  (==.), (>=.), (>.), ..., (!=.) :: PersistField typ => ...
18:06:36 <nitrix> Cale: Very nice. You actually just taught me about DataKinds in the simplest way possible.
18:06:46 <hackrilege> cant you use associated types for this?
18:07:13 <hackrilege> forker?
18:07:16 <Cale> hackrilege: That's if you want the instances to be able to define them differently
18:07:30 <Cale> forker is just complaining about repetitiveness
18:07:40 <Cale> which is reasonable
18:08:01 <Cale> But yeah, there's not a way to make a locally scoped type synonym
18:08:14 <forker> hackrilege: doing my reading on associated types :)
18:08:27 <hackrilege> oh ok thanks
18:08:38 <forker> Cale: thanks, that is quite a tip!
18:09:12 <hackrilege> um, so i guess my probles is i dont quite know how to take a derivative of a datatype to derive the zipper
18:10:31 <hackrilege> basically to me it feels like the datastructure has to be turned inside out. imagine navigating upward from a node in a binary tree, this is just an upside down binarytree, and thats how the zipper works. but for Free s, the shape of the container s is conceptually difficult for me to turn inside out..... does that make sense?
18:11:46 <hackrilege> i was guessing that by just making instance Stack (Free s), that i could use push and pull as normal in Zipper (Free s)
18:12:28 <hackrilege> i wont go on until someone can say they follow... i dont want to spam up the channel
18:12:41 <hackrilege> http://lpaste.net/163144
18:14:00 <nitrix> :t sequenceA
18:14:02 <lambdabot> (Applicative f, Traversable t) => t (f a) -> f (t a)
18:14:36 <nitrix> How do you call the property of those two types `t` and `f` being compatible for each others. I have a blank.
18:14:57 <Welkin> isomorphic?
18:15:06 <Welkin> oh, no
18:15:08 <nitrix> commutive?
18:15:27 <hackrilege> you are commuting them there i guess...
18:15:44 <nitrix> Commutative? Is that the right term?
18:15:56 <Welkin> I suppose it is a product?
18:16:38 <hackrilege> im not sure i like its use here... you are commuting them, but they are not commutative since t (f a) /= f (t a)
18:17:22 <hackrilege> its just a mapping between types, equivalent to a commutation
18:18:35 <hackrilege> f and t would be commutative if sequenceA = id
18:18:42 <hackrilege> perhaps...
18:18:47 <nitrix> What about ehm... mapM? Which is just an effectful fmap.
18:19:04 <hackrilege> what about it?
18:20:19 <lambdafan> say I have data Test = Foo | Bar | Baz. I want to make an Enum instance suck that if I have let test = Baz, succ Baz is Foo. Is that an abuse of the Enum typae. If so, is there a better way to get what I want?
18:20:33 <lambdafan> erm such that, not suck that
18:21:13 <hackrilege> again, commuting operators does nothing if the operators commute, so these castings eg traverse are only = id if the types commute.
18:21:40 <nitrix> lambdafan: It think it breaks Enum, but I don't know enough. Have you considered safeSucc instead?
18:22:42 <nitrix> @let safeSucc = headMay . drop 1 . enumFrom
18:22:43 <lambdabot>  .L.hs:161:12: Not in scope: ‘headMay’
18:22:45 <geekosaur> it breaks things like enumFrom unless they're also Boundedm, iirc
18:22:50 <geekosaur> er Bounded
18:22:55 * geekosaur kan tipe gud
18:23:11 <hackrilege> an Enum instance requires a bijection to the integers? you have a surjection
18:23:19 <nitrix> @let headMay [] = Nothing; headMay (x:xs) = Just x
18:23:21 <lambdabot>  Defined.
18:23:23 <nitrix> @let safeSucc = headMay . drop 1 . enumFrom
18:23:25 <lambdabot>  Defined.
18:23:35 <nitrix> @let data Test = Foo | Bar | Baz
18:23:36 <lambdabot>  Defined.
18:23:44 <nitrix> > safeSucc Baz
18:23:46 <lambdabot>      No instance for (Enum Test) arising from a use of ‘safeSucc’
18:23:46 <lambdabot>      In the expression: safeSucc Baz
18:23:54 <geekosaur> deriving...
18:23:56 <nitrix> Whoops. You get the point.
18:24:14 <lambdafan> yeah I was hoping to yield a value everytime I used succ
18:24:34 <lambdafan> I'm looking to "flip a switch" with minimal code
18:24:37 <hackrilege> so just define toEnum using mod
18:24:45 <Moon_> @let data Test = Foo | Bar deriving(Show) --Fixed
18:24:46 <lambdabot>  .L.hs:167:1:
18:24:47 <lambdabot>      Multiple declarations of ‘Test’
18:24:47 <lambdabot>      Declared at: .L.hs:163:1
18:25:03 <Moon_> oh, how can i override it? :P
18:25:09 <hackrilege> @undefine
18:25:09 <lambdabot> Undefined.
18:25:10 <hpc> @let deriving instance Show Test
18:25:11 <lambdabot>  .L.hs:146:24: Not in scope: type constructor or class ‘Test’
18:25:13 <nitrix> Nuuuu.
18:25:14 <hpc> oh
18:25:16 <geekosaur> you could of course derive Enum and Bounded and then use: succCycle x | x == maxBound = minBound | otherwise = succ x
18:25:26 <Moon_> @let data Test = Foo | Bar deriving(Show) --Fixed
18:25:27 <lambdabot>  Defined.
18:25:29 <hackrilege> too many cooks!
18:25:32 <nitrix> People are too trigger happy with undef :(
18:25:45 <Clint> or are they
18:25:47 <lambdafan> geekosaur, that's what I want!
18:25:48 <hackrilege> lol, its not like we were working for hours!
18:25:52 <Moon_> > Test
18:25:53 <lambdabot>      Not in scope: data constructor ‘Test’
18:25:53 <lambdabot>      Perhaps you meant variable ‘nest’ (imported from Text.PrettyPrint.HughesPJ)
18:25:59 <hpc> i say they aren't too trigger happy enough
18:26:15 <Moon_> >show Test
18:26:23 <Clint> so close
18:26:28 <hackrilege> need whitespace
18:26:43 <Moon_> > show Test
18:26:44 <geekosaur> Moon_, Test is the type, Foo and Bar are the values
18:26:45 <lambdabot>      Not in scope: data constructor ‘Test’
18:26:45 <lambdabot>      Perhaps you meant variable ‘nest’ (imported from Text.PrettyPrint.HughesPJ)
18:26:49 <hpc> @src Bool
18:26:49 <lambdabot> data Bool = False | True deriving (Eq, Ord)
18:26:51 <Moon_> Ah
18:26:55 <hpc> there's a hint
18:27:01 <Moon_> i understnd only a few things so far
18:27:29 <Moon_> > x = 1
18:27:30 <lambdabot>  <hint>:1:3: parse error on input ‘=’
18:27:34 <Welkin> Sun and Moon
18:27:38 <hpc> i am gradually coming around to the opinion that the default data syntax is not that great, and it should be GADT by default
18:27:45 <Moon_> Im still stinky with haskell but i love it
18:27:47 <Welkin> Moon_: looks like you need some guidance
18:27:50 <Welkin> start here
18:27:54 <hpc> just the syntax if not the semantics
18:27:55 <Welkin> @where learnhaskell -- Moon_ 
18:27:55 <lambdabot> https://github.com/bitemyapp/learnhaskell
18:28:08 <hackrilege> > let (x,y) = (y:x,0) in x
18:28:10 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
18:30:25 <hackrilege> still cant figure this out http://lpaste.net/163144
18:32:07 <hackrilege> am i getting kicked?
18:32:15 <Welkin> hahaha
18:32:16 <Welkin> no
18:32:30 <Welkin> you would get a message that says "you were kicked by <name>"
18:32:43 <hackrilege> ah thats reassuring thanks
18:32:44 <hackrilege> ghost in the machine
18:33:40 <suzu> @src takeWhileC
18:33:40 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
18:33:47 <hackrilege> I thought Cale might be getting bored of Free Zippers... or anyone else for that matter! ill be finished soon i think
18:34:11 <geekosaur> hackrilege, it's saying you quit. check for unexpected keyboard shortcuts
18:34:34 <hpc> this channel actually all takes place in Cale's imagination
18:34:42 <hpc> when his attention drifts people start netsplitting
18:34:42 <Welkin> hackrilege: you have been h4ck3d!
18:34:55 <hpc> it's all very nolanesque
18:34:57 <geekosaur> (as a longtime Mac user, control-q keeps catching me by surprise on linux)=...)
18:35:29 <Welkin> geekosaur: I HATE when I try to close some tabs in firefox using Command-W and I accidentally hit Q
18:36:16 <Clint> i don't do either of these things
18:36:19 <hpc> 90% of all tab navigation is ^tab and ^w
18:36:22 <geekosaur> hm, actually that looks like you're having network issues
18:36:23 <hpc> and between them, a landmine
18:36:38 <Welkin> Clint: of course you don't, you just shoot up mexicans and italians
18:36:42 <Clint> :-O
18:36:55 <hackrilege_> where is the hWebBrowser?
18:37:02 <Clint> hbro?
18:37:12 <hpc> Clint: is your last name Eastwood? ;)
18:37:29 <Clint> hpc: only as a disambiguation at my last job
18:37:48 <hackrilege_> yes hbro! awesome times
18:37:51 <geekosaur> (here, I've been finding that during heavy use periods the NAT table overfills and overwrites my connections. I now route IRC to a hotspot instead of the main connection)
18:38:03 <geekosaur> (it's not my network...)
18:38:35 <Welkin> not in my backyard!
18:38:37 <hpc> uni?
18:38:46 <geekosaur> motel :/
18:38:54 <hpc> yeesh
18:38:54 <Welkin> psycho?
18:39:20 <geekosaur> only when the druggies are about >.>
18:39:22 <hackrilege_> escaping gang war
18:39:33 <Welkin> the Bates?
18:39:49 <Welkin> you can go stay there I believe
18:39:51 <geekosaur> (yes, I got the reference)
18:39:55 <Clint> and i thought this channel was weird when a welkin was talking to a moon
18:40:08 * geekosaur actually had a souvenir ashtray from the Bates Motel at one point
18:41:37 <hackrilege_> most of the haskell community is on the run from the military... we wont munch their data!
18:41:54 <Welkin> after recently watching the original Jurassic Park again, I became interested in chaos theory
18:42:01 <Welkin> funny movie to talk about that
18:42:51 <hackrilege_> !!?
18:43:04 <Welkin> the mathematician in the film talks about it a lot
18:43:16 <Clint> no stranger then the fractals in arcadia
18:43:26 <Welkin> Ian Malcolm played by Jeff Goldblum
18:43:28 <hackrilege_> stop now before you cause a bifurcation!
18:44:46 <hackrilege_> and consider this wholesome mental challenge http://lpaste.net/163144
18:44:57 <Welkin> and in the second JP film, he mentions the Heisenberg uncertainty principle
18:45:02 <Welkin> in the strangest contexts, haha
18:45:28 <hackrilege_> :(
18:46:21 <hackrilege_> i got a pretty high score on the google dinosaur game...
18:46:35 <Welkin> and of course no one can forget the famous line at the end of Jurassic Park 1: "It's a Unix system!"
18:47:47 <hackrilege_> probably dinosaurs could solve my bug... http://lpaste.net/163144
18:48:33 <Welkin> it's not a bug, it's a programming error!
18:48:45 <Welkin> dijkstra says
18:49:27 <hackrilege_> ill keep that in min
18:49:29 <hackrilege_> mind*
18:49:37 <Welkin> haha ubuntu
18:49:45 <Welkin> 21:48 < monoubuntu> i have a problem with fucking ubuntu and USB WIFI Adapter
18:49:52 <hackrilege_> are you on crack?
18:50:00 <Welkin> and someone triggered a command that has a bot tell them to watch their language
18:50:21 <Welkin> hackrilege_: no
18:51:02 <hackrilege_> sure your not
18:51:31 <hackrilege_> why are you talking about jurasic park and swearing?
18:51:54 <Welkin> I acknowledge my thoughts and let them pass through me
18:51:57 <hackrilege_> i assumed most users were more mature than me...
18:52:13 <Welkin> as water flows through a stream
18:52:32 <Welkin> I am unsure what you mean by "mature"
18:53:00 <hackrilege_> to strictly adhere to accepted codes of conduct
18:53:09 <Welkin> that is not mature... it is naive
18:53:23 <hackrilege_> perhaps so
18:53:24 <Welkin> and there are no codes of conduct
18:53:50 <hackrilege_> yeh but i get told to talk on blah when i speak about ghc on android
18:54:06 <shanemikel> it's called conduit, the codes are here https://github.com/snoyberg/conduit
18:54:14 <hackrilege_> booo
18:54:28 <Welkin> hackrilege_: yeah, I do too
18:54:34 <hackrilege_> down with snoyberg and the other enemies of documentation
18:54:40 <Welkin> but blah is not a nice place
18:55:08 <hackrilege_> once able minds, ravaged by offtopic discussion
18:55:51 <Welkin> I should find more channels around here
18:56:15 <Welkin> talking about haskell gets old really fast
18:56:45 <hackrilege_> im sure the other 1500 users agree
18:56:57 <Welkin> most of them never talk :P
18:57:04 <shanemikel> are there that many?  
18:57:34 <hackrilege_> 1429 online says my thing, but i bet half of them are just advertising and illuminati watch nodes
18:57:40 <shanemikel> I suspect many people filter the channel for keywords related to their projects/areas of interest .. and wait for notifications
18:57:43 <Clint> we're all just bots
18:58:02 <hackrilege_> yeah, where is zipper
18:58:12 <Welkin> he is in kenya
18:58:18 <Welkin> doing kenya things
18:58:24 <shanemikel> If you randomly start saying a bunch of project names and subjects, I bet it will get lively fast
18:58:27 <hackrilege_> you can see lions in kenya
18:59:01 <hackrilege_> im not going to randomly start saying anything!
18:59:10 <Clint> too late
18:59:16 <hackrilege_> yeh i was trolled
18:59:32 <hackrilege_> Welkin the bantersaurus
19:07:16 <hackrilege_> certainly that was the strangest way i have failed to engage the channel in discussion...
19:07:58 <hackrilege_> still up for grabs! http://lpaste.net/163144
19:08:05 <bollu> there seem to be two ways to define a natural transformation
19:08:59 <bollu> 1. a mapping between functors that makes the diagram (F A -> F B) (G A -> G B) commute (that is, a pair of morphisms eta_a :: F A -> G A, eta_b :: F B -> G B that commute
19:09:37 <bollu> 2. a mapping between the functors (A -> F B) (A -> G B) such that there is an eta_b :: F B -> G B that commutes
19:09:51 <bollu> wait, I messed up #2.
19:10:12 <bollu> What I wanted was to say "a set of morphisms between the images of the functor'd objects indexed by the domain"
19:10:17 <bollu> I don't see how 1 and 2 are equivalent
19:10:23 <bollu> as in, 1 seems to contain strictly more information than 2
19:10:29 <bollu> am I right or wrong?
19:10:55 <bollu> ski, Cale:	can I have some help with this please? :)
19:11:22 <Cale> whaaa
19:11:44 <bollu> is that completely messed up? :)
19:11:52 <bollu> Cale: okay, I know that #1 is correct
19:11:54 <hackrilege_> the diagram commutes!?
19:12:01 <bollu> Cale: I'm just trying to express what wikipedia expresses
19:12:06 <bollu> https://en.wikipedia.org/wiki/File:Natural_transformation.svg
19:12:07 <bollu> that one
19:12:09 <bollu> as for #2
19:12:10 <Cale> right
19:12:16 <bollu> I mean, like
19:12:18 <Cale> I don't get #2
19:12:30 <bollu> Cale: hang on a sec
19:12:35 <Cale> Given functors F,G: C -> D
19:12:49 <Cale> A natural transformation eta: F -> G consists of
19:13:10 <Cale>   for each X in C, an arrow eta_X: FX -> GX in D
19:13:14 <bollu> Cale: okay, look at this: https://bartoszmilewski.files.wordpress.com/2014/05/cone.png
19:13:23 <bollu> Cale: so, the red arrows are the natural transform
19:13:46 <bollu> since, for each object in A \in J, they have a map between \Delta A -> F A
19:13:54 <Cale> yeah, the natural transformation Delta -> F
19:13:58 <Cale> yep
19:14:01 <ski> bollu : yes, completely messed up :)
19:14:14 <bollu> yeah, so doesn't number 1 have more information than number 2?
19:14:15 <ski> (both `1' and `2')
19:14:23 <bollu> I can re-create number 2 from number 1
19:14:32 <bollu> since I know exactly what gets mapped to what in the image
19:14:32 <Cale> wait, what?
19:14:47 <bollu> okay, I'm trying to show that the way of thinking about a nat. transform
19:14:48 <Cale> Okay, there's really just one definition of natural transformation
19:14:56 <bollu> okay, go on
19:15:24 <Cale> It's what I said above, only with the condition that you already know
19:15:50 <Cale> That for each a: X -> Y in C, we have that eta_Y . Fa = Ga . eta_X
19:15:50 <bollu> Cale: so in that case, how does the first diagram make sense (from wikipedia?)
19:16:01 <bollu> that diagram has an eta_y as well
19:16:05 <bollu> where do you get that from?
19:16:14 <Cale> A natural transformation eta: F -> G consists of
19:16:15 <bollu> isn't that part of the natural transform as well?
19:16:17 <Cale>   for each X in C, an arrow eta_X: FX -> GX in D
19:16:31 <bollu> https://upload.wikimedia.org/wikipedia/commons/f/f2/Natural_transformation.svg
19:16:37 <Cale> It's a collection of arrows in D, one for each object of C.
19:16:52 <Cale> This square is a diagram in D
19:17:10 <bollu> ^ right, so that only gives you the "left side arrow" eta_x in the commuting diagram. Where do you get eta_y from?
19:17:21 <Cale> It's *for each X in C*
19:17:31 <Cale> Y is also an object in C
19:17:44 <Cale> So there's also an eta_Y: FY -> GY
19:17:47 <bollu> ahh right!
19:17:50 <Cale> and so on for every object of C
19:17:56 <bollu> okay, right, so eta is indexed by the objects of C
19:18:00 <bollu> oh my god it all makes sense now
19:18:08 <bollu> thanks :)
19:18:10 <bollu> a ton
19:18:39 <hackrilege_> argh
19:18:47 <bollu> I'm used to most places where lowercase indicates objects and uppercse indicates, like, collections
19:18:56 <bollu> I keep tripping over whether A is an object or a category
19:19:00 <bollu> and I get it mised up :(
19:19:02 <bollu> mixed*
19:19:59 <bollu> ski: one more quick question
19:20:10 <Cale> bollu: Yeah, there are a few too many kinds of things we're dealing with for any one convention about variables to work out well
19:20:16 <bollu> ski: I think it was you who had an explanation for why every map into the indescrete topology was continuous
19:20:27 <Cale> I also can explain that
19:20:32 <bollu> Cale: go ahead :)
19:20:43 <Cale> Well, what are the open sets of the indiscrete topology?
19:20:43 <bollu> Cale: no, you gave a topological explanation
19:20:52 <bollu> Cale: ski gave an explanation in terms of "preserving inforation"
19:20:53 <bollu> information*
19:20:53 <ski> bollu : hm. perhaps it was shachaf
19:21:00 <bollu> ski: hm, right, maybe
19:21:03 <Cale> Oh, that's kind of handwavy
19:21:15 <bollu> Cale: I see, how come?
19:21:31 <Cale> Well, there's a way to make it somewhat precise, but only to a point
19:21:33 <hackrilege_> F (f) is fmap f?
19:22:15 <Cale> http://www.cs.bham.ac.uk/~mhe/papers/entcs87.pdf
19:23:14 <hackrilege_> urgh that reference...do i have to read that before i can get a job as prof haskell?
19:23:57 <Cale> That's a reference for bollu to understand the connection between topology and data types
19:24:21 <Cale> There's a certain analogy to be made there which mostly works, with some little tweaks
19:24:26 <ski> @where topology
19:24:26 <lambdabot> "topology in Haskell" <http://www.haskell.org/pipermail/haskell/2004-June/014134.html> and "Synthetic topology of data types and classical spaces" <http://www.cs.bham.ac.uk/~mhe/papers/entcs87.(pdf|dvi|ps)> by Martn Escard
19:24:27 <ski> (:
19:24:40 <hackrilege_> or rather "to what extent is an understanding of Synthetic topology a prerequisite for professional academic Haskell"
19:25:25 <ski> hackrilege_ : it's more like knowledge of Haskell may help get an understanding of Synthetic topology
19:25:26 <Cale> hackrilege_: I'm sure there are lots of academics who haven't read that
19:25:48 <Cale> hackrilege_: and yeah, fmap f in Haskell is written Ff or F(f) in category theory literature
19:26:05 <Cale> (where F is the functor in question)
19:26:10 <ski> (where `F' is the functor in question)
19:26:11 <hackrilege_> awesome
19:26:13 * ski smiles
19:26:14 <hackrilege_> so what is eta?
19:26:23 <ski> a natural transformation
19:26:23 <hackrilege_> neta, whatever that letter is
19:26:26 <ski> e.g.
19:26:30 <ski> @type listToMaybe
19:26:32 <lambdabot> [a] -> Maybe a
19:26:47 <Cale> η
19:26:53 <zRecursive> Does -XStrict automatically make all codes strict ?
19:27:07 <hackrilege_> sure, generally a function of type :: (Functor f,Functor g) => f a -> g a
19:27:46 <geekosaur> zRecursive, it inserts strictness annotations everywhere iirc
19:28:00 <geekosaur> as opposed to a strict code gen
19:28:14 <Cale> I find that extension troubling
19:28:28 <Cale> People might actually use it
19:28:36 <geekosaur> me too, actually
19:28:36 <zRecursive> geekosaur: is it really needed ?
19:28:45 <hackrilege_> so a natural transformation is any operation η :: (Functor f,Functor g) => f a -> g a , where η.(fmap f) = (fmap f).η?
19:28:55 <ski> hackrilege_ : rather, generally a function of type `forall a. F a -> G a' (with some caveats), for given `F' and `G'
19:29:00 <geekosaur> zRecursive, I would say no, especially since using it without knowing what you are doing will cause a lot of code to diverge
19:29:13 <Cale> hackrilege_: yeah, though the definition lets you specify which function it is for each a
19:29:22 <ski> hackrilege_ : note that the type of `listToMaybe' doesn't fit the pattern `(Functor f,Functor g) => f a -> g a'
19:29:30 <geekosaur> there's quite a lot of stuff in Prelude and common libraries that rely on laziness
19:29:32 <hackrilege_> :t listToMaybe
19:29:33 <lambdabot> [a] -> Maybe a
19:29:35 <ski> @type listToMaybe :: (Functor f,Functor g) => f a -> g a
19:29:36 <lambdabot>     Couldn't match type ‘f1’ with ‘[]’
19:29:36 <lambdabot>       ‘f1’ is a rigid type variable bound by
19:29:36 <lambdabot>            an expression type signature:
19:29:37 <Cale> hackrilege_: polymorphic functions in Haskell automatically enjoy the property that eta . fmap f = fmap f . eta
19:29:40 <ski> type error ^
19:29:46 <zRecursive> geekosaur: i think so, thx
19:29:48 <geekosaur> and, potentially, inlined code would behave differently from non-inlined code
19:30:21 * ski thinks hackrilege_ unsufficiently distinguishes between object and meta levels
19:30:39 <ski> Cale : .. as long as both are in fact functors :)
19:30:40 <hackrilege_> how dare you
19:30:43 <geekosaur> (I don't know if it's smart enough to avoid that, or maybe just inserts its annotations before inlining happens so inlined code would be lazy as expected by the library it was inlined from)
19:30:47 <Cale> ski: right
19:31:14 <hackrilege_> so how do you invert a Free Functor?
19:31:19 <hackrilege_> http://lpaste.net/163144
19:31:30 <ski> @type Data.IORef.readIORef  -- here one is not a functor
19:31:31 <lambdabot> GHC.IORef.IORef a -> IO a
19:31:32 <Cale> hackrilege_: pls no
19:31:46 <hackrilege_> !?
19:31:51 <hackrilege_> ok but tell me why
19:32:25 <Cale> I don't want to have to try to understand your crazy zipper and stack shenanigans well enough to answer this :)
19:33:01 <hackrilege_> the paste used to be 300 lines long, now its under 100
19:33:23 <geekosaur> ...
19:33:25 <Cale> true, but now you're actually asking questions about what the code does rather than how to get it to typecheck
19:33:36 <hackrilege_> its about deriving zippers
19:34:09 <hackrilege_> push and pull makes sense for a list. what about a Free List?
19:34:35 <hackrilege_> the result is that you can navigate and edit a Free Functor using a zipper
19:34:37 <hackrilege_> its boss
19:35:54 <hackrilege_> decomposing a list via pattern matching on (:) and rebuilding the list in reverse is ok, even its ok to do that with Trees, and other simple Free things
19:36:41 <hackrilege_> but these Free Free things, Free lists, Free trees and so on, i dont know how to "invert" the various containers....
19:37:18 <hackrilege_> look its damn near impossible to explain using human syntax, thats why iv been working on this paste, for what, a month! http://lpaste.net/163144
19:37:28 <hackrilege_> just to try and describe to you this very problem
19:38:01 <hackrilege_> the type errors were all leading to this poit, arnt you interested to see what has been achieved?
19:39:08 <hackrilege_> i know its not quite lens, as Free datatypes are homogenious, but it allows all the navigational stuff and its a single instance...
19:42:06 <hackrilege_> well i guess i got you to explain your stance, ill come back when this is finished or not at all
19:42:29 <hackrilege_> i hope i succedde!
20:10:32 <koz_> What's a Lens-y way to write this? foo x y = sort (x ^. bar) == sort (y ^. bar)
20:10:47 <koz_> (also generally a less repetitive way would be nice)
20:12:31 <pavonia> koz_: Are x and y of the same type?
20:12:50 <koz_> pavonia: Yes.
20:13:35 <pavonia> :t on (==) (sort . (^. bar))
20:13:36 <lambdabot>     Not in scope: ‘bar’
20:13:36 <lambdabot>     Perhaps you meant one of these:
20:13:36 <lambdabot>       data constructor ‘Bar’ (line 147),
20:13:41 <pavonia> :t \bar -> on (==) (sort . (^. bar))
20:13:42 <lambdabot> Ord a1 => Getting [a1] a [a1] -> a -> a -> Bool
20:14:32 <koz_> Hmm, interesting.
20:14:36 <koz_> Thanks!
20:14:53 <pavonia> No problem
20:15:16 <koz_> I never quite got the 'on' thing.
20:16:23 <pavonia> It's like "apply a unary function on both sides before applying the binary function"
20:21:39 <jle`> @src on
20:21:39 <lambdabot> (*) `on` f = \x y -> f x * f y
20:21:47 <hackrilege> ok i think i have got it, i will add an associated type to stack for the output of pull, so that rather than just returning a contained element, it returns this element in a context retaining information about its nesting within the datatype it was extracted from. Boom
20:21:58 <hackrilege> Cale^
20:23:47 <hackrilege> i feel like i might be stretching the concept of Zipper a little here, but i definitely cant make a Free Zipper just from Stack
20:24:32 <hackrilege> i shall return with bountiful examplification
20:37:28 <koz_> Also, if I have something like '(compare `on` sort) x y', how would I write this using $ to avoid brackets?
20:37:33 <koz_> (assuming I can)
20:39:39 <c_wraith> You could just write it as on compare sort x y
20:39:55 <koz_> c_wraith: That'll work? Woah.
20:40:15 <c_wraith> I'd go with your original version, though
20:40:41 <koz_> c_wraith: Yeah - it is a bit more readable. But that is really cool - I tend to over-bracket as a safety mechanism.
20:42:28 <koz_> Also, do I understand correctly that '(compare `on` length) ++ (compare `on` sort)' would compare first by length, then by sorted lex order?
20:44:41 <c_wraith> Um.  If you mean <> by ++ then yes
20:45:11 <koz_> c_wraith: Yeah - I use BasicPrelude which overloads (++) to mean (<>)
20:46:53 <nitrix> Where does the ~ notation comes from for type specialization?
20:47:42 <koz_> nitrix: For type family stuffs?
20:48:17 <nitrix> Just in regular. Literature, here, I see it a bit everywhere. If it has a stronger foundation in type families, I might look at those as well.
20:48:33 <nitrix> I just get curious about the most peculiar things sometimes.
20:48:33 <tomberek> .
20:48:54 <tomberek> is compdata still in general use?
20:50:23 <koz_> nitrix: AFAIK, ~ means 'is isomorphic to' or 'is equivalent to' in many cases.
20:50:47 <nitrix> Is type specialization an isomorphism?
20:51:45 <nitrix> To me, isomorphism means they have the same capabilities; if you loose generality, it seems like they wouldn't be quite isomorphic.
20:52:32 <nitrix> That's just intuition though; I'm often wrong :P
20:59:08 <arthropododo> Could you guys recommend me one or two ~hour-long videos about introduction to haskell? (for someone without any functional programming background, except for a bit of C++ template metaprogramming)
21:01:26 <koz_> I *really* need more practice in the use of Lens-y things...
21:06:05 * hackagebot persistent-template 2.5.1.2 - Type-safe, non-relational, multi-backend persistence.  https://hackage.haskell.org/package/persistent-template-2.5.1.2 (GregWeber)
21:16:06 * hackagebot persistent-template 2.1.8.1 - Type-safe, non-relational, multi-backend persistence.  https://hackage.haskell.org/package/persistent-template-2.1.8.1 (GregWeber)
21:20:23 <Rotaerk> arthropododo, why does it need to be videos?
21:24:43 <arthropododo> Rotaerk, no special reason other than that's usually what I do before starting on books
21:25:00 <Rotaerk> arthropododo, https://github.com/bitemyapp/learnhaskell
21:25:11 <Rotaerk> that's a non-book option
21:27:12 <arthropododo> Rotaerk, thanks
21:55:50 <gfixler> what's the status of this? https://wiki.haskell.org/MonadPlus_reform_proposal
22:16:08 * hackagebot casr-logbook 0.0.5 - CASR 61.345 Pilot Personal Logbook  https://hackage.haskell.org/package/casr-logbook-0.0.5 (TonyMorris)
22:18:58 <squall> when using TypeFamilies, i get the error "multiple declerations of Q", which is the associated type of my class, when i write an instance for this class for a datatype parametrised with a type constrained to also be an instance of this class....
22:19:20 <squall> is this a bug?
22:21:32 <squall> or am i using the wrong syntax?
22:24:32 <squall> aha, it was my syntax, each instance should have a different constructor, eg data Q = Qa Int, data Q=Qb Char in each seperate instance of a class with abstract datatype Q :: *
22:28:47 <athan> @tell squall yeah, associated data types basically mean you're creating a new data constructor for each instance, not like a type morphism / macro
22:28:47 <lambdabot> Consider it noted.
22:40:57 <fred-fri_> im confused by the different options for getting started with haskell. i want to be able to have completely isolated environments for individual projects. what should i do?
22:42:24 <nisstyre> fred-fri_: cabal sandboxes
22:43:08 <jle`> fred-fri_: stack :)
22:43:27 <jle`> stack is a bit nicer becuase with sandboxes, projects can't share compiled libraries
22:43:38 <jle`> so you end up building separate copies of half the entire ecosystem for every project
22:43:46 <jle`> *with cabal sandboxes
22:44:25 <fred-fri_> sounds like cabal sandboxes is more isolated then? and 100% guarantee no conflicts?
22:44:46 <jle`> both have the same interface
22:44:49 <jle`> and ensure no conflics
22:45:12 <jle`> they have the same amount of isolation from a user interface perspective
22:45:52 <jle`> the only difference is that when i switch my stack snapshots/environments, things build in seconds instead of minutes :)
22:46:00 <jle`> *dozens of minutes
22:46:28 <jle`> and, upgrading a single package is easy
22:46:29 <fred-fri_> jle`, it sounds like haskell platform is a bad choice
22:46:44 <jle`> if you decide that you need a newer version of a single package, the cabal sandbox workflow is:
22:46:48 <jle`> 1) delete your entire sandbox for that project
22:46:55 <jle`> 2) rebuild everything from scratch over the course of an hour
22:46:57 <nisstyre> you could also look into using something like nix
22:46:58 <jle`> the stack workflow is:
22:47:01 <jle`> 1) change the version
22:47:03 <nisstyre> it might not solve your problems
22:47:07 <jle`> 2) everyhting works :D
22:47:11 <nisstyre> but it's good for running multiple versions of things
22:47:25 <fred-fri_> ok im gonna go with stack
22:47:32 <jle`> i've never had any problem having multiple versions of packages running side-by-side within the same project
22:47:32 <croben> good evening fine people
22:47:48 <jle`> i am not sure what role the haskell platform serves in the ecosystem
22:47:51 <jle`> good evening croben :)
22:48:12 <jle`> i think there is a decent percentage of the community that actively discourages the platform in its current state and mission
22:48:13 <croben> i was wondering if haskell is a good language to use for writing something like a sudoku solver
22:48:23 <jle`> yeah, it would definitely be :)
22:48:40 <croben> cool, i'm going to try that then
22:49:16 <croben> i'm pretty new to the language, so i wasn't really sure how to start this task in haskell
22:49:37 <croben> but if you say it'll be ok, it'll be ok, jle` 
22:49:37 <fred-fri_> now the next question is how to install stack, eg manually or through my os package
22:50:00 <jle`> fred-fri_: either way is fine, once you get it you can run 'stack upgrade' to be up to date
22:50:15 <jle`> i think the recommended way is to use your OS's package manager if you can
22:50:28 <jle`> croben: you can look into constraint satisfaction stuff :)
22:51:18 <nisstyre> if it's available with cabal then just add .cabal/bin to your $PATH variable and install it
22:51:34 <croben> looking at some solvers now and i think maybe it's a bit above my level
22:51:46 <croben> in haskell, that is
22:53:15 <jle`> croben: i wrote an old blog series a few years back that might help?  i haven't tried applying it to sudoku yet :) https://blog.jle.im/entries/series/+monadplus-success-failure-monads.html
22:53:43 <croben> it's not really sudoku i'm solving, but it's a very similar game
22:53:52 <croben> thanks!
22:54:27 <croben> i'm more on the level "what are monads", if you catch my drift
22:57:31 <guest6745> When is GHC 8.0 expected to be released?
23:41:17 <guest347> Approximately when is GHC 8.0 expected to be released?
