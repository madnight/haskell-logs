00:35:08 <turiya> hi
00:35:24 <turiya> how to i give type signature in IO
00:37:03 <Cale> turiya: can you be more specific about what you want to do?
00:38:02 <Welkin> Cale: how do i shot web?
00:40:09 <Cale> Welkin: ¯\(°_o)/¯
00:41:55 * hackagebot product-profunctors 0.7.1.0 - product-profunctors  https://hackage.haskell.org/package/product-profunctors-0.7.1.0 (tomjaguarpaw)
00:46:59 <Athas> Is there a good hack to have code work in both GHC 7.8 and 8.0, without tons of redundant-context warnings about contexts that require both 'Applicative m' and 'Monad m'?
00:50:32 <Welkin> Athas: there is a compiler flag
00:54:02 <Welkin> Athas: -Wno-redundant-constraints
00:55:48 <Athas> Welkin: I'll need to add that conditionally in my .cabal, right?
00:55:59 <Athas> (Since it does not exist prior to GHC 8.0.)
00:57:56 <Welkin> yes, I believe so
01:01:55 * hackagebot aivika 4.3.5 - A multi-method simulation library  https://hackage.haskell.org/package/aivika-4.3.5 (DavidSorokin)
01:01:57 * hackagebot aivika-transformers 4.3.5 - Transformers for the Aivika simulation library  https://hackage.haskell.org/package/aivika-transformers-4.3.5 (DavidSorokin)
01:51:58 * hackagebot hylogen 0.1.2.0 - an EDSL for live-coding fragment shaders  https://hackage.haskell.org/package/hylogen-0.1.2.0 (sleexyz)
01:55:54 <mikail_> Hi, please can some one help me understand how foldr foo 10 [1,2,3] = -8 ?
01:55:58 <mikail_> let foo x y = x - y
01:57:26 <mikail_> For foldl on the same, I get 4 which I think expands out like  (foo (foo (foo 10 - 3) 2) 1) —> 4
01:57:31 <lyxia> [1,2,3] = 1 : (2 : (3 : []))
01:57:41 <lyxia> replace : with foo, [] with 10
01:57:52 <lyxia> 1 `foo` (2 `foo` (3 `foo` 10))
01:58:12 <lyxia> 1 - (2 - (3 - 10))
01:58:43 <mikail_> thanks lyxia!
01:58:49 <lyxia> You're welcome!
01:59:54 <mikail_> the way I have expanded out foldl on the same, is that how the compiler is doing it?
02:00:08 <mikail_> (foo (foo (foo 10 - 3) 2) 1) —> 4
02:00:19 <geekosaur> > foldr (-) z [a,b,c]
02:00:20 <lambdabot>  a - (b - (c - z))
02:00:48 <geekosaur> ^ uses simple-reflect to show how foldr evaluates
02:01:03 <lyxia> uh no, foldl first combines 10 with 1
02:01:24 <geekosaur> > foldl (-) z [a,b,c]
02:01:26 <lambdabot>  z - a - b - c
02:02:07 <mikail_> ok guys thanks
02:05:04 <quxbam> Is it recommendable to ship binaries with test-suites?  Git-annex does this and Joey Hess seems to love it
02:08:41 <quxbam> Any opinions?
02:22:49 <quxbam> Is it possible to default some class methods to generalizednewtypederiving?
02:23:23 <quxbam> Probably not...
02:50:15 <dogui> hi, does anyone have material to read about 'container monads', if that's the correct term?
02:50:40 <dogui> or a summary of different classifications of monads would be great too
02:54:59 <EvanR> dogui: https://wiki.haskell.org/Monads_as_containers
02:55:17 <EvanR> https://wiki.haskell.org/Monads_as_computation
02:58:34 <ayush1> hi guys I am new here
02:58:45 <quxbam> hi ayush1
02:58:53 <quxbam> how can we help?
02:59:05 <ayush1> quxbam: hi
02:59:15 <ayush1> quxbam: I am learning haskell
02:59:32 <ayush1> quxbam: and don't get how is recursion so fast
02:59:49 <ayush1> quxbam: in haskell vs java cpp ...
03:00:29 <quxbam> ayush1: there are various reasons
03:00:40 <ayush1> quxbam: ok
03:00:41 <quxbam> the compiler has a lot more stuff to reason about
03:00:49 <ayush1> hmm
03:01:00 <quxbam> and thanks to lazyness your recursion can abort quite early
03:01:09 <ayush1> quxbam: ye
03:01:20 <quxbam> think about the =
03:01:29 <quxbam> in java, this sign is a lie
03:01:29 <ayush1> ok
03:01:35 <ayush1> lie?
03:01:37 <ayush1> how?
03:01:43 <quxbam> x=4 
03:01:45 <quxbam> x=5
03:01:50 <ayush1> yes
03:02:03 <quxbam> so, this isn't possible in mathematics and not in haskell
03:02:08 <ayush1> yes
03:02:11 <ayush1> that is FP
03:02:21 <quxbam> yes, it's maths
03:02:29 <quxbam> but java hasn't got this property
03:02:30 <tmobile> ayush1: Recursion in general is not faster in Haskell. However, the compiler is guaranteed to perform an optimization called tail call elimination whenever possible.
03:02:42 <ayush1> tmobile: oh
03:02:48 <tmobile> Other compilers provide this optimization, but it is not guaranteed.
03:02:56 <ayush1> oh
03:03:06 <ayush1> also when should we prefer FP
03:03:12 <quxbam> always :)
03:03:17 <ayush1> quxbam: why?
03:03:24 <quxbam> because you can reason about it
03:03:31 <tmobile> If you write a recursive Haskell function that is not tail recursive, then it'll be just as "slow" as its counterparts in other languages.
03:03:41 <ayush1> tmobile: oh
03:03:42 <quxbam> more easily and with tools which are very elaborate (maths)
03:04:00 <tmobile> However, as quxbam mentioned, non-strictness means that results from recursive functions can be consumed incrementally.
03:04:13 <quxbam> or not consumed at all
03:04:18 <ayush1> oh
03:04:31 <tmobile> So it's often Ok to use even tree recursive definitions in general.
03:04:56 <quxbam> you can think, that every data structure is an iterator
03:04:59 <quxbam> more or less
03:05:04 <ayush1> oh
03:05:20 <quxbam> > take 5 [1..]
03:05:22 <lambdabot>  [1,2,3,4,5]
03:05:28 <quxbam> > sum [1..]
03:05:32 <lambdabot>  mueval-core: Time limit exceeded
03:05:33 <dogui> EvanR: that's not what I mean, I think, I don't want an explanation of monads, which I think I understand sufficiently
03:05:58 <dogui> EvanR: from my understanding there are certain classes of monads, containers (which have some formal definition, presumably) are one
03:06:05 <ayush1> doesn't FP *sometimes* increase the time complexity?
03:06:13 <ayush1> of an algorithm
03:06:14 <quxbam> ayush1: lazyness allows quite elegant data structures, because they are allowed to be infinite
03:06:25 <EvanR> dogui: not familiar with formal notion of containers
03:06:28 <ayush1> oh
03:06:30 <ayush1> ok
03:06:33 <quxbam> ayush1: i don't think so
03:06:38 <dogui> EvanR: ok thanks!
03:06:53 <EvanR> i dont usually think of monads as containers
03:06:55 <ayush1> quxbam: say we need to find 3 in a row
03:06:59 <quxbam> ayush1: you can, if you're hard pressed, write imperative code in haskell
03:07:05 <quxbam> ok
03:07:11 <ayush1> quxbam: then in java or cpp
03:07:21 <ayush1> quxbam: this will be done by one loop
03:07:26 <ayush1> quxbam: in O(n)
03:07:28 <quxbam> in haskell as well
03:07:37 <ayush1> quxbam: but in haskell how would you do it
03:07:48 <quxbam> find (==3)
03:07:51 <ayush1> quxbam: recursive sliding window?
03:07:54 <EvanR> find (==3) [1,2,3,4,5]
03:07:59 <EvanR> > find (==3) [1,2,3,4,5]
03:08:01 <lambdabot>  Just 3
03:08:04 <Jinxit> three in a row
03:08:07 <Jinxit> not find the three
03:08:16 <EvanR> ah
03:08:17 <quxbam> the question wasn't clear
03:08:24 <quxbam> a row can be anything
03:08:34 <ayush1> quxbam: find 3 in an array
03:08:46 <EvanR> group [1,2,3,3,3,4,5,6]
03:08:47 <EvanR> > group [1,2,3,3,3,4,5,6]
03:08:49 <lambdabot>  [[1],[2],[3,3,3],[4],[5],[6]]
03:08:50 <quxbam> the number?
03:09:05 <ayush1> like ans [1,2,2,2,1,2] 2 = true
03:09:39 <ayush1> quxbam: a boolean
03:09:53 <ayush1> quxbam: given an array and an int
03:10:09 <ayush1> quxbam: find weather that number is 3 in a row.
03:10:17 <quxbam> ah ok
03:10:19 <EvanR> > (find ((>= 3) . length) . group) [1,2,2,2,3,2]
03:10:21 <lambdabot>  Just [2,2,2]
03:10:35 <ayush1> who is lambdabot 
03:10:41 <quxbam> ghci
03:10:43 <EvanR> in this case lazy evaluation makes it more efficient
03:10:44 <quxbam> more or less
03:11:02 <EvanR> the group wont continue once it finds the first triple
03:11:09 <quxbam> yeah, in this case, this is *more* efficient than c or java
03:11:26 <ayush1> in cpp you could achieve that with break statement
03:11:27 <Jinxit> why would C or java continue?
03:11:37 <EvanR> yes
03:11:43 <EvanR> lazy evaluation lets you do any control flow
03:11:46 <quxbam> but your array is already in memory
03:11:51 <quxbam> or calculated
03:11:53 <Jinxit> I'm not convinced this is more efficient than a loop with a break
03:11:55 <quxbam> in haskell not
03:12:08 <EvanR> its more efficient than equivalent code in js, ruby
03:12:35 <ayush1> EvanR: is it more efficient than equivalent code in cpp and java
03:12:58 <EvanR> for a long list, i dunno
03:13:06 <EvanR> ghc does optimizations (tm)
03:13:09 <Jinxit> EvanR: by "equivalent", do you mean grouping and checking for length? or just using an accumulator?
03:13:14 <quxbam> ayush1: it depends on what you operate, if you use lazyness in java, it's the same
03:13:30 <EvanR> Jinxit: find the first grouping with length 3
03:13:39 <EvanR> by doing find, length, group
03:13:53 <Jinxit> yes, but maybe doing find, length, group is not the optimal way
03:14:04 <EvanR> definitely not
03:14:25 <EvanR> but its nice in haskell that more natural ways of saying stuff gets a speed boost
03:14:37 <EvanR> even if it may not be as optimal as theoretically possible
03:14:50 <EvanR> i always mess up loops in C
03:14:54 <quxbam> the compiler is quite good, I would be surprised if this doesn't result in a single assembly loop
03:15:50 <EvanR> i use grouping and filtering a lot in ruby anyway
03:15:51 <quxbam> besides, this can be quite easily benchmarked
03:16:41 <EvanR> more importantly, your application profiled to see if thats even the slowest thing involved
03:17:50 <brownie2342> 
03:18:10 <ayush1> ok I got it
03:18:16 <ayush1> thanks for your help
03:18:44 <Jinxit> well the question was if doing the same thing in FP had the same time complexity
03:19:02 <EvanR> which brings up whether time complexity even applies
03:19:13 <EvanR> to mutable memory vs immutable structures
03:19:32 <quxbam> ayush1: read http://code.haskell.org/~dons/papers/icfp088-coutts.pdf
03:19:43 <quxbam> it explains quite well what magic is possible
03:19:49 <EvanR> O(1) is not necessarily telling the whole story about memory, so the question is probably about something else
03:19:52 <Jinxit> so we should just drop all notions of time complexity?
03:20:43 <ayush1> thanks quxbam 
03:20:56 <EvanR> it would be nice if there was a better gauge of performance than that
03:21:20 <quxbam> ayush1: :) it's perhaps a 'hard' read for the beginning, but it's quite normal to read papers in haskelllandia
03:21:34 <ayush1> quxbam: o
03:21:57 <Jinxit> it's a useful abstraction IMO
03:22:22 <Jinxit> everybody knows the optimizer does things and that cache is significant for performance
03:22:42 <Jinxit> but at a first glance you can see that something O(n^3) is probably problematic
03:23:04 <EvanR> but log n vs 1 is just theoretically misleading
03:23:04 <Jinxit> just like we avoid building lists with ++
03:23:23 <EvanR> even if its coincidental that 1 happens to be faster for some other reason
03:24:06 <quxbam> yeah, the converging complexity levels are all the same
03:24:16 <quxbam> the diverging one are problematic
03:24:55 <quxbam> (log n converges more or less ;) )
03:25:51 <EvanR> as soon as i upgrade to infinite memory, ghc blows mutation out of the water ;)
03:26:05 <tmobile> log(n) converges less, not more.
03:26:36 <tmobile> lim n->∞ log(n) =  ∞
03:26:42 <Jinxit> inf
03:26:46 <quxbam> obviously
03:27:05 <quxbam> i was comparing to n or n^3
03:27:20 <quxbam> log n grows really slow
03:27:34 <EvanR> its basically constant! ;)
03:27:40 <quxbam> my point :)
03:28:02 <EvanR> for any feasible amount of memory, which is why its O(1)
03:28:19 <quxbam> > log (fromIntegral (maxBound :: Int))
03:28:21 <lambdabot>  43.66827237527655
03:28:32 <quxbam> quite acceptable
03:28:49 <EvanR> > log (fromInteger (2^128))
03:28:50 <lambdabot>  88.722839111673
03:34:32 <quxbam> does anybody what happend to the genetic twiddling of llvm arguments by donsbot?
03:34:37 <quxbam> sounded quite interesting
03:34:41 <quxbam> know
04:42:05 * hackagebot generics-eot 0.2.1.1 - A library for generic programming that aims to be easy to understand  https://hackage.haskell.org/package/generics-eot-0.2.1.1 (SoenkeHahn)
04:45:24 <EvanR> i am looking at docs for generics-eot which is trying to be easy to understand, but i dont see an expansion of what "eot" means
04:45:58 <maerwald> I only see docs for 0.1, because hackage is broken again
04:47:05 * hackagebot hmatrix 0.17.0.2 - Numeric Linear Algebra  https://hackage.haskell.org/package/hmatrix-0.17.0.2 (AlbertoRuiz)
04:47:21 <maerwald> it says it follows the generics-sop library where sop means "sum of products", so what can eot mean?
04:48:15 <EvanR> dunno
04:48:22 <maerwald> "end of products"? :o
04:48:29 <EvanR> end of times
04:49:37 <maerwald> electric overhead traveling
04:50:47 <maerwald> "Eot is a type level function that maps arbitrary ADTs to isomorphic generic representations."
04:51:08 <tmobile> Extreme overpowered theorem
04:53:02 <Boomerang> ethernet of things
04:54:57 <maerwald> there's the problem, when do you know your library is easy to understand :P
04:56:52 <cocreature> either of types?
04:57:37 <ggVGc> can someone mention some non-parsing situation where Applicative is used a lot?
04:58:16 <EvanR> when you want to apply a simple container of types to a container of arguments
04:58:26 <EvanR> er a container of functions
04:58:31 <EvanR> "cof"
04:58:52 <ggVGc> yeah, but I have problems coming up with practical use cases for it
04:58:59 <EvanR> Applicative is also handy for munging arguments with the function Applicative
04:59:50 <EvanR> liftA2 comes up a lot, and it would come up more if your data types were Applicative
05:00:21 <ggVGc> I've only used liftA2 when writing lenses
05:00:52 <EvanR> another case is doing form validation
05:01:05 <EvanR> or command line argument validation
05:01:33 <EvanR> also its handy for DSLs where liftA2 will apply a haskell function inside your DSL
05:02:44 <EvanR> and its handy for doing Monad without taking up multiple lines
05:02:47 <ggVGc> EvanR: reason I am asking is because I feel like maybe I can use Applicative in a good way for composing the different modes of my application
05:02:59 <EvanR> you might be able to
05:03:45 <ggVGc> I don't have a clear picture yet, but I've started getting the feeling that it's "kind of monadic maybe", and hence maybe Applicative
05:04:07 <ggVGc> but I've never written a monad or applicative instance myself before
05:04:11 <ggVGc> anyway, thanks
05:04:55 <ggVGc> I'm essentially approaching some kind of DSL for specifying the modes and input handling for them
05:05:04 <EvanR> the interesting cases for applicative are when its not just monad-lite
05:05:54 <ggVGc> right
05:06:09 <ggVGc> EvanR: this is the foundation of my composing of modes right now, https://gist.github.com/b61fdd0c71abde10a5fc342fc9c23649
05:06:15 <ggVGc> does it seem applicative-ish to you?
05:06:28 <ggVGc> or it might also be unreadable
05:06:41 <EvanR> [AppMode] -> AppMode is monoid not applicative
05:06:56 <ggVGc> ah, right
05:06:59 <ggVGc> yeah, that makes sense
05:07:11 <ggVGc> now I see that
05:07:14 <ggVGc> thanks
05:07:39 <EvanR> well it might be, if combining AppModes is associative
05:11:07 <ggVGc> hm, it isn't I guess
05:11:28 <ggVGc> EvanR: it's not, because the update function short circuits upon the first mode that andled input
05:12:51 <EvanR> starting from the left?
05:13:28 <ggVGc> yeah
05:13:38 <EvanR> it might still be assoc, but the fact that you combined all three things in one type means it might be hard to get any nice properties to come out
05:13:51 <EvanR> input handling, updating, and rendering
05:14:00 <ggVGc> ah, yeah
05:14:13 <ggVGc> there's a reason for that, but I see what you mean
05:14:50 <ertesx> ggVGc: i use digestive-functors, which is an "proper" applicative library for web forms
05:15:13 <ertesx> proper in the sense that it is non-monadic (every monad is also an applicative functor)
05:15:25 <EvanR> && short circuits on the first False and is associative
05:15:27 <ertesx> s/an/a/
05:15:51 <ggVGc> EvanR: yeah, but my modes have a conceptual idea of chaining
05:16:06 <ggVGc> the point is for them to eat input and otherwise propagate to the next one
05:16:09 <ggVGc> so order matters
05:16:19 <ggVGc> but actually..
05:16:26 <ggVGc> hm, yeah, no, that's how it is
05:16:28 <EvanR> sounds like composition done inside out somehow
05:17:20 <ggVGc> why inside out?
05:17:23 <EvanR> in f . g . h . whatever each function decides whether to return something now or use the next function
05:17:23 <ggVGc> isn't it composition?
05:17:42 <ggVGc> ah, yeah
05:17:47 <ggVGc> so in that sense I guess it's backwards
05:18:04 <ggVGc> but I also usuaslly use >>> instead of . so I guess I'm just backwards thinking
05:18:23 <EvanR> either way its not composed if its [a] -> a
05:19:01 <tmobile> \quit
05:19:01 <EvanR> you dont get any benefit of different types
05:19:46 <ertesx> ggVGc: i have used (>>>) when composing vertically (in source code layout)
05:21:19 <ggVGc> man ,this is annoying
05:21:36 <ggVGc> I feel there's a generalisation to what I' doing and that I'm reimplementing language features
05:21:40 <ggVGc> but I can't see it
05:22:26 <Jinxit> ggVGc: code?
05:22:54 <ggVGc> Jinxit: I have this for building "modes" out of smaller modes, https://gist.github.com/anonymous/b61fdd0c71abde10a5fc342fc9c23649
05:23:12 <EvanR> at the very least you should be able to abstract the control flow you want, if its not a standard pattern
05:23:15 <ggVGc> it;'s working nicely, but I feel it can be rethought in a better way
05:23:22 <ggVGc> EvanR: yeah, exactly
05:25:06 <ertesx> ggVGc: at the very least AppMode looks like a monoid to me
05:25:18 <ertesx> but not a particularly interesting one
05:25:24 <ggVGc> ertesx: yeah that's what EvanR said, but it's not associative
05:25:38 <EvanR> are you sure its not
05:25:41 <ertesx> i wouldn't call it a monoid, if it weren't associative =)
05:25:43 <ggVGc> well, okay, maybe it is
05:25:56 <ggVGc> but yeah, it might not be a useful one really
05:26:07 <Jinxit> that sounds to me like there's design trouble if you can composite them but it's not associative
05:26:32 <ggVGc> I might be thinking incorrectly about the term associative
05:26:33 <ertesx> if you add a type argument, it could also be an Applicative, but since you have multiple actions, you would have to declare one or more (perhaps even all) primary
05:26:34 <Jinxit> as in easy to do the wrong thing
05:26:42 <Jinxit> (a*b)*c = a*(b*c)
05:26:44 <quxbam> I think it is a monoid
05:26:54 <quxbam> it behaves just like Either
05:26:58 <EvanR> (mode0 <> mode1) <> mode2 = mode0 <> (mode1 <> mode2)
05:27:22 <ggVGc> EvanR: yeah, alright, it's associative then
05:27:29 <ggVGc> I was being a dumb
05:27:30 <ertesx> ggVGc: mode1 <> mode2  -- this could be the mode that runs mode1's action and then mode2's action in order
05:27:40 <ertesx> it's a trivial monoid, and the underlying operator is (>>)
05:27:46 <ertesx> (or (*>))
05:27:56 <quxbam> or <>
05:28:20 <ggVGc> ertesx: yeah, but in a1 <> a2, a2 does not get executed if a1 handled the input
05:28:27 <ggVGc> but it does get rendered
05:28:30 <ertesx> ggVGc: if you add a type argument, the underlying operator becomes (<*>), and it becomes a slightly more interesting Applicative
05:28:44 <ertesx> ggVGc: that sounds fine to me
05:28:52 <EvanR> if thats what <> means then fine, all that matters is what happens if you change the grouping
05:29:01 <ggVGc> cool
05:29:24 <ertesx> ggVGc: it's a product monoid with (as far as i see from your code) three components (the individual fields)
05:29:46 <ertesx> if you have such a product type and compose each field individually in a monoidal way, then you have a product monoid
05:29:48 <EvanR> enjoy ;)
05:30:18 <ertesx> *which* composition you use for each field does not matter, as long as each one is monoidal
05:30:27 <ggVGc> ah yeah, that makes sense
05:30:44 <EvanR> > ([1,2], Sum 3) <> ([5,6], Sum 9)
05:30:46 <lambdabot>  ([1,2,5,6],Sum {getSum = 12})
05:30:48 <ggVGc> I geuss I should split this stuff up into a monoid each for render/update/renderPlayPOs
05:30:54 <ggVGc> to make it more versatile
05:31:10 <ggVGc> but I am not sure that's useful for my application
05:31:21 <ertesx> if it's not useful, don't do it
05:31:24 <ggVGc> yeeah
05:31:28 <ggVGc> but it might turn out to be
05:31:30 <ggVGc> I@ll think about it
05:31:53 <ertesx> personally i would make it Applicative rather than Monoid
05:31:59 * EvanR waits for the moment when you throw the whole design in the trash and redesign it
05:32:12 <ggVGc> the rendering is very tightly coupled with the input handling, because it runs on midi controllers where literally each button is a LED
05:32:16 <ertesx> i don't think that's necessary =)
05:32:21 <ggVGc> so the screen and the input surface have the exact same interface
05:32:50 <EvanR> youd think it was tightly coupled
05:33:02 <ggVGc> EvanR: nah, it's great. I've had all my modes just written one by one until now, waiting for when I can see how to compose them well
05:33:05 <ggVGc> and now it's much better
05:33:13 <EvanR> but midi/audio stuff and UI is usually super uncoupled due to performance mismatch
05:33:27 <EvanR> for real time stuff
05:33:32 <ggVGc> but this is a fairly specific thing
05:33:40 <ggVGc> they only render whenever any of them handle input
05:34:11 <EvanR> wouldnt they only really need to render if their model changed?
05:34:20 <EvanR> and if a vsync happens 
05:34:28 <minib00m> hey there guys, does anyone know how i can check when ghc8 will be available on arch linux?
05:34:29 <ggVGc> yeah, but that's just an optimization
05:34:31 <ggVGc> which isn't necessary
05:34:54 <EvanR> its as much of an optimization as not just polling the renderer
05:35:11 <ggVGc> theres no pollig
05:35:14 <quchen_> How do I hyperlink to foldl' in Haddock? 'foldl'' does not work, 'foldl\'' does not work, 'foldl' ' does not work. :-\
05:35:16 <ertesx> ggVGc: i would call it "reactive"
05:35:21 <ggVGc> ertesx: yeah, exactly
05:35:24 <ertesx> not really an optimisation, just sensible application design =)
05:35:44 <EvanR> thats what i was getting at
05:35:52 <minib00m> @kind Just
05:35:53 <lambdabot> k -> Maybe k
05:36:01 <ggVGc> ertesx: the key thing here though, and why the modes are coupled like this, is that the target for input and rendering is literally the same data structure. Since each pixel is a button essentially
05:36:41 <ertesx> ggVGc: show AppMode
05:36:50 <EvanR> in order to get clicking on regions of the picture correct, it doesnt need to be coupled, i thought about this last week
05:36:50 <ggVGc> EvanR: there's no render loop. A render tick is just pushed out to all control surfaces whenever an of them handle input
05:37:16 <Jinxit> ertesx: were you the one doing ML in haskell?
05:37:55 <ertesx> Jinxit: ML = machine learning?  then yes, and *am* doing
05:38:08 <Jinxit> did you make it public yet?
05:38:12 <ggVGc> ertesx: don't hurt me, https://gist.github.com/c405f0062d4a4695f332ea38eb893934
05:39:09 <ggVGc> EvanR: my point is I can't come up with a situation where I'd want to combine rendering from one mode with input handling from another
05:39:14 <ggVGc> it doesn't make sense in this application
05:39:45 <EvanR> tightly coupled because i have no reason not to? ;)
05:39:55 <ggVGc> basically
05:40:01 <ggVGc> because in haskell it's easy to break that out later
05:40:06 <EvanR> my reason not to was it was making my code horrible
05:40:10 <ggVGc> and until then the work is easier and quicker if it's more coupled
05:40:23 <EvanR> complex records are complex
05:41:07 <Jinxit> you never get the design right the first time anyways, so you might as well roll with ugly code until you can see all your needs clearly
05:41:14 <ertesx> Jinxit: sorry, i had other things to get done, but please poke again next week…  i should be able to implement the overall abstraction
05:41:22 <ggVGc> Jinxit: exactly what I've been doing
05:41:39 <Jinxit> sure, I'm mostly interested from a design perspective rather than using it tbh
05:41:45 <EvanR> on the subject of mouse clicking on the rendering... instead of a R2 -> Color being the result of rendering, it could be R2 -> (Color, a), and then you show the color and clicking the mouse produces a value of type a
05:41:59 <EvanR> that really makes things nice
05:42:07 <ertesx> Jinxit: the idea is very simple and inspired by how you compose applicative functors
05:42:19 <ertesx> Jinxit: using composition, products, coproducts, etc.
05:42:45 <Jinxit> was the idea to be able to compose "any" ML algorithm?
05:44:19 <ertesx> Jinxit: any layered one:  logistic = linear -> softmax;  deep learning = rbm -> rbm -> ...;  traditional neural net = linear -> logistic -> linear -> logistic -> ...
05:45:12 <ertesx> with the ability to compose horizontally as well:  annLayer -> (annLayer ||| annLayer) -> annLayer
05:46:43 <Jinxit> what about things like SVM, random forests, boosting?
05:47:02 <kqr> how would I go about converting a type that is a member of Fractional, Num, Real and RealFrac to a Double?
05:47:17 <EvanR> realToFrac
05:47:33 <kqr> thanks
05:47:33 <ertesx> kqr: you can't…  you need Real
05:47:36 <kqr> oh
05:47:48 <kqr> I do have Real
05:48:00 <EvanR> :t fromRational
05:48:01 <lambdabot> Fractional a => Rational -> a
05:48:05 <EvanR> :t toRational
05:48:07 <lambdabot> Real a => a -> Rational
05:48:57 <ertesx> Jinxit: SVM is just a linear model with a different learning algorithm, so should work; random forests should work, too…  they are more like an algorithm rather than a model…  boosting i'm not familiar with…  but let me design it first before i make any bold claims
05:50:59 <Jinxit> sure
05:52:00 <ertesx> one bold claim i can make right now: i'm not going to implement SVM myself =)
05:53:10 <ertesx> (unless you give me a good SMO implementation)
05:54:18 <Mateon1> Hello, is there a zipList, or a transpose function? I want to change [[1,2,3,...], [4,5,6,...], ...] into [[1,4...], [2,5...], [3, 6, ...], ...]
05:54:32 <ertesx> Mateon1: transpose?
05:54:43 <ertesx> > transpose ["abc", "def", "ghi"]
05:54:45 <lambdabot>  ["adg","beh","cfi"]
05:54:53 <Mateon1> Uhh, which module is that in?
05:54:59 <ertesx> i think it's even in the Prelude
05:55:04 <ertesx> if not, it's in Data.List
05:55:09 <Mateon1> <interactive>:28:1: error: Variable not in scope: transpose
05:55:27 <bennofs> :t Data.List.transpose
05:55:28 <Mateon1> Hm, alright, seems to be in Data.List
05:55:28 <lambdabot> [[a]] -> [[a]]
05:57:17 <minib00m> >[[x,y,z] | x <- [1,2,3], y <- [4,5,6], z <- [7,8,9]]
05:57:37 * ertesx .o( remember from your childhood when you used to import Data.List into every other module? )
05:58:08 <EvanR> yeah its weird
05:58:25 <EvanR> i guess we dont need as much list processing these days
05:58:37 <ertesx> we do, but it's in Data.Foldable now =)
05:58:54 <Mateon1> minib00m: That only works when there's a fixed amount of lists, at which point you might as well zipWith3
05:59:02 <Mateon1> Or, zip3, sorrt
05:59:04 <Mateon1> sorry*
05:59:18 <ertesx> minib00m's variant is not a zip anyway
05:59:44 <Mateon1> Or, right
05:59:50 <Mateon1> Gah, the typos
06:00:19 <ggVGc> I'm trying to make Monoids out of my parts of a mode, what's wrong here? https://gist.github.com/be3ca1903e688bd302fbbee0df5b0318
06:00:22 <ertesx> there is a ZipList applicative, but it's not useful for transposing…  doesn't work all the time (think different lengths), and if it does, it's slow
06:00:30 <ggVGc> I've never written a monoid implementation for my own types before :(
06:01:05 <EvanR> ggVGc: eh... is this a type synonym for a Maybe
06:01:19 <ggVGc> EvanR: I'm just trying to get it to compile
06:01:22 <ertesx> ggVGc: write a Monoid instance for AppMode, not the individual field types
06:01:24 <ggVGc> before I start implementing mappend
06:01:32 <Mateon1> Monoids aren't scary, unfortunately the syntax for defining one is
06:01:45 <ggVGc> ertesx: yeah, but I want to separate them like EvanR suggested
06:01:54 <ertesx> ggVGc: then use a newtype
06:02:01 <EvanR> i think what i suggested would require a larger redesign
06:02:03 <ggVGc> oh, rght
06:02:05 <ggVGc> that's why
06:03:07 <ertesx> ggVGc: newtype FieldA = FieldA { runFieldA :: X -> Y -> Z }
06:03:23 <ertesx> you can make that a monoid (and even an Applicative, which is monoids on steroids)
06:03:30 <EvanR> this is a lot of work just to use mconcat
06:03:42 <ggVGc> ertesx: yep, thanks
06:03:49 <ertesx> ggVGc: but honestly i would just write a Monoid/Applicative instance for AppMode =)
06:03:49 <Hafydd> Haha.
06:04:03 <EvanR> ertesx: it doesnt look like a type variables would make sense
06:04:14 <ggVGc> ertesx: yeah at some point this will become applicative. That's what I've been suspecting, hence why I started talking in here about this today
06:04:25 <Hafydd> class Steroid s where
06:04:28 <ertesx> EvanR: i don't know…  the type doesn't rule it out
06:04:39 <EvanR> you can add a phantom variable to anything
06:04:41 <ggVGc> ertesx: well, I had a think, and actually there are a few instances where composing rendering functions might be useful, so I'm gonna do this
06:05:00 <EvanR> ggVGc: thats because rendering functions are just functions ;)
06:05:20 <EvanR> unless they are hidden in a record
06:05:35 <ggVGc> I also have a function for creatign a "simple" mode, and I can get rid of that if the parts are monoids
06:05:44 <ertesx> ggVGc: don't do it just to have done it…  you're running the risk of overengineering here
06:05:59 <ertesx> a simple Monoid AppMode will likely give you a very nice interface already
06:06:19 <ggVGc> ertesx: yeah, I wasn't going to, but I looked through some of the code that I'm abbout to refactor using this, and there are some places where composition of rendering is useful
06:06:25 <ggVGc> so the splitup is good
06:06:48 <ertesx> ggVGc: haskell is exceptionally good at refactoring…  if you find that it's indeed useful, refactor later =)
06:07:09 <ertesx> don't worry too much about doing this right now…  do one thing after another
06:07:13 <EvanR> i wish my wrists were as good as haskell is at needing to be refactored
06:07:17 <ggVGc> I'm already at the point where I can see that. All the modes are already there and working correctly, but I'm starting to have troubles adding new ones
06:07:21 <ggVGc> hence why I'm doing tis
06:07:40 <ertesx> have fun =)
06:07:53 <ggVGc> I find myself wanting to use parts of previous modes, but haven't had a good way of doing it
06:08:10 <minib00m> ertesx: how is Applicative a monoid on steroids? 
06:08:16 <ertesx> ggVGc: as in AppMode templating?
06:08:23 <quxbam> Why is HSpec using a preprocessor for discovery and not just a function in IO ?
06:09:06 <ertesx> minib00m: add a type argument to any Monoid, and you get an Applicative…  remove the type argument of any Applicative, and you don't necessarily get a Monoid
06:09:35 <EvanR> minib00m: theres an equivalent form of Applicative where unit :: f a, fuse :: f a -> f b -> f (a,b)
06:09:44 <EvanR> so heterotyped monoid
06:09:44 <ggVGc> ertesx: more like, there are some kinds of rendering that are fairly generic, like when I want to "select a value from a list" and use the whole grid for the selection, but the action on the selection is different
06:09:48 <ggVGc> I have multiple places like that
06:09:57 <ertesx> minib00m: in general i tend to write Applicative first and then implement Monoid in terms of it
06:10:02 <ggVGc> and implementing those with monoid composition will bemuch ncier
06:10:04 <ertesx> (if sensible, of course)
06:11:05 <EvanR> minib00m: and the laws for this correspond to the monoid laws
06:11:09 <minib00m> ertesx: got you! 
06:13:58 <EvanR> er :: f ()
06:14:01 <EvanR> not f a
06:16:03 <ggVGc> ertesx: just went with this for now.. https://gist.github.com/5dcc1a89b9b8824b97ec355f3b29494c
06:16:35 <quchen_> Is there a place I can read about how the STG handles IO?
06:16:56 <quchen_> There's a lot of buzz around RealWorld in the typed domain, but what about the next lower level?
06:17:09 <ggVGc> actually this is better eh, https://gist.github.com/e56eff02b989ad1388e2bfdd05d0520f
06:19:05 <quchen_> Is there a print# primop of sorts?
06:21:35 <minib00m> EvanR: i had to process what you wrote for a moment. So your version of applicative with fuse :: f a -> f b -> f (a,b) is equivalent to monoid concat operation? To me seems like it, but i'm not sure
06:23:50 <EvanR> its equivalent to <*>
06:23:55 <EvanR> if you squint
06:24:21 <EvanR> its a 2-type version of <>
06:36:52 <minib00m> EvanR: 
06:37:18 <minib00m> thanks, it makes more sense now, still need to dive to some more theory behind this
06:38:35 <bartolo> hi, I'm trying to install ghc-mod from cabal but the building process fails http://pastebin.com/8FqXJMDc ghc-pkg check report this http://pastebin.com/Efacgrgb
06:38:49 <bartolo> I've already tried to remove ~/.cabal 
06:39:16 <bartolo> *with cabal not from cabal
06:39:53 <bennofs> bartolo: try also removing ~/.ghc
06:40:56 <bartolo> bennofs: ok thanks. It would take some time to re-download all the pacakges :p
06:59:41 <ggVGc> this feels like i'm reimplementing something Either-related? https://gist.github.com/8ba02113818f35b5c4ea06589fa1a3c5
07:05:19 <bennofs> Is there some ghc flag that shows me what packages GHC loads when compiling a module=
07:07:28 <chipf0rk> is there a way to print something to stdout in a haskell terminal program, and keep it editable? i want to prompt the user with getLine, but print out an (editable) default string
07:15:56 <ggVGc> if I have a type Monoid type, and I'm writing a function that is specific to that type, is it better style to refer to mempty or directly to the function that is equivalent to mempty for that type?
07:16:13 <ggVGc> i.e, is this okay? https://gist.github.com/9575af0aec23722a92cd9a4730d7f4d1
07:16:17 <ggVGc> what reads best to people
07:26:28 <bartolo> bennofs: thanks it worked
07:28:05 <bennofs> bartolo: cool :) the reason why you need to delete ~/.ghc is because that is the location where the list of "installed packages" is stored. So if you only delete ~/.cabal, then cabal will still think that all the packages you had installed before are indeed installed (in fact, I think ~/.cabal only contains data files for packages by default, so you wouldn't even have had to delete that one.)
07:33:45 <nitrix> How would I build a list from a large tree in such a way that each node gets simply `cons` to the final output?
07:34:10 <nitrix> Recursively doing ++ is performing terrible as it ends up being quadratic (I think?)
07:35:02 <nitrix> It isn't a Foldable; as its a spatial partitioning tree.
07:35:16 <nitrix> It wouldn't be too useful to traverse everything :P
07:35:25 <ggVGc> is it possible to give a name to a group of arguments, without turning them into a tuple?
07:35:33 <ggVGc> in te type declaration
07:36:29 <ggVGc> i.e this, https://gist.github.com/11448e172a0c600014ad4d17e8a6d33f
07:36:35 <ggVGc> is there any way to do something similar?
07:37:10 <ggVGc> sorry, meant this, https://gist.github.com/2f5521c46120b3ce2049bfa692f4db9b
07:38:05 <ertesx> nitrix: if it's a Foldable, you should make it a Foldable, regardless of whether you think it's useful or not
07:38:12 <ertesx> nitrix: same for Functor and Traversable
07:38:27 <nitrix> ertesx: I will; it's just not helping this precise problem.
07:38:41 <ertesx> nitrix: sounds like it would: toList
07:38:51 <ertesx> :t toList
07:38:52 <lambdabot>     Ambiguous occurrence ‘toList’
07:38:52 <lambdabot>     It could refer to either ‘Data.Foldable.toList’,
07:38:52 <lambdabot>                              imported from ‘Data.Foldable’ at /home/lambda/.lambdabot/State/L.hs:87:1-20
07:38:58 <ertesx> :t Data.Foldable.toList
07:39:00 <lambdabot> Foldable t => t a -> [a]
07:39:13 <nitrix> ertesx: That'd be all the elements, so not really.
07:39:29 <nitrix> It's a QuadTree.
07:40:00 <ertesx> don't you want to get a list of *all* nodes?  if not, specify
07:41:05 <nitrix> ertesx: I recursively go through all nodes, but some branches gets pruned when the region of the space their cover doesn't match the criteria of the range lookup.
07:41:36 <ertesx> nitrix: you can make a non-flat fold for your tree
07:42:12 <nitrix> ertesx: How does that work?
07:42:23 <ertesx> are you familiar with type fixed points?  or: can you think of a QuadTreeF, such that Fix QuadTreeF = QuadTree?
07:42:49 <nitrix> Haven't seen that yet, unfortunately.
07:43:14 <ertesx> newtype Fix f = Fix { unwrap :: f (Fix f) }
07:43:27 <ertesx> Fix f ≃ f (f (f (f …
07:43:45 <nitrix> ertesx: What's the goal? To have a type that lets me specify the region of interest and declare the fold instance on that type instead?
07:43:47 <monochrom> the mother of recursive types.
07:43:48 <ertesx> data ListF a x = Cons a x | Nil  -- it's just List, but with the recursion replaced by a placeholder
07:44:01 <ertesx> then Fix ListF ≃ List
07:44:11 <ertesx> the point is that it gives you a template for folds
07:44:28 * nitrix scratches head.
07:44:34 <ertesx> foldQuadTree :: (QuadTreeF r -> r) -> QuadTree -> r
07:44:35 <nitrix> Trying to digest that.
07:45:05 <ertesx> look at the familiar foldr:  foldr :: (a -> r -> r) -> r -> [a] -> r
07:45:34 <ertesx> with some type algebra you will find that it's isomorphic to:  (ListF a r -> r) -> [a] -> r
07:45:53 <ertesx> ListF is the fold (and unfold) template for lists
07:48:50 <ertesx> nitrix: first learn to represent recursive types as fixed points of flat types…  really all you need to do is to take the recursion points out and replace them by a placeholder
07:49:09 <ertesx> data Nat = Z | S Nat  -- a fixed point of:
07:49:15 <ertesx> data NatF x = Z | S x
07:49:38 <ertesx> Nat ()  -- you can have Z and S ()
07:49:52 <nitrix> Oh I see.
07:49:53 <ertesx> Nat (Nat ())  -- you can have Z and S Z and S (S ())
07:50:11 <ertesx> Nat (Nat (Nat ()))  -- you can have Z and S Z and S (S Z) and S (S (S ()))
07:50:19 <ertesx> Fix Nat  -- you can have any natural number
07:51:20 <ertesx> now NatF gives you a fold template for Nat:  foldNat :: (NatF r -> r) -> Nat -> r
07:51:43 <nitrix> I see what's happening.
07:51:53 <nitrix> I wonder if I can figure this out for four quadrant.
07:53:17 <ertesx> it also gives you an unfold template:  unfoldNat :: (r -> NatF r) -> r -> Nat
07:54:26 <ertesx> if you're interested in the categorical details: the technical term for this is F-algebras and catamorphisms, F-coalgebras and anamorphisms
07:54:38 <ertesx> but it's not too important to understand the idea and use it in your code
08:02:57 <Zemyla> ertesx: How does that work when the data type's recursion isn't natural, like Seq a = Empty | Single a | Deep (Digit a) (Seq (Node a)) (Digit a)?
08:07:13 * hackagebot identicon 0.1.0 - Flexible generation of identicons  https://hackage.haskell.org/package/identicon-0.1.0 (mrkkrp)
08:27:14 * hackagebot LambdaDB 0.0.0.6 - On-memory Database using Lambda Function environment.  https://hackage.haskell.org/package/LambdaDB-0.0.0.6 (Ailrun)
08:30:21 <inkjetunito> good evening. is there a way for binding two or more variables on one shot? i would like to bind to elements of a tuple or a list.
08:31:45 <Hafydd> inkjetunito: yes: simply bind to a pattern containing these variables in the relevant places. For example:
08:31:51 <Hafydd> > let (x, y) = (1, 2) in x + y
08:31:53 <lambdabot>  3
08:32:10 <texasmynsted> ahg.  How do I get rid of Prelude in ghci?
08:32:26 <texasmynsted> I am starting it from stack ghci
08:32:48 <texasmynsted> I have tried adding -XNoImlicitPrelude
08:32:53 <texasmynsted> That did not work
08:33:08 <texasmynsted> I tried starting it and saying :m -Prelude
08:33:12 <texasmynsted> that did not work
08:33:22 <texasmynsted> I am running out of ideas
08:36:04 <inkjetunito> Hafydd: thanks
08:37:14 * hackagebot pipes 4.2.0 - Compositional pipelines  https://hackage.haskell.org/package/pipes-4.2.0 (GabrielGonzalez)
08:38:27 <ggVGc> what do I need to do to generalise this into not becoming a huge nesting? https://gist.github.com/2846d114c3320cad222c225d86eb1d66
08:38:28 <Ohso_> Trying to understand {-# LANGUAGE Safe #-}    I've read about it, but what is an example of an "unsafe" piece of code? What exactly does using this buy me?
08:38:33 <ggVGc> I think I should use MonadPlus?
08:38:45 <ggVGc> each nesting is the fallback if the event wasn't handled
08:39:01 <ggVGc> but I'd like to make it compose
08:39:07 <texasmynsted> oh :m -Prelude finally worked
08:39:11 <ggVGc> but I can't figure it out
08:52:15 * hackagebot envparse 0.4 - Parse environment variables  https://hackage.haskell.org/package/envparse-0.4 (MatveyAksenov)
09:12:16 * hackagebot sorted-list 0.1.6.1 - Type-enforced sorted lists and related functions.  https://hackage.haskell.org/package/sorted-list-0.1.6.1 (DanielDiaz)
09:14:14 <ryantrinkle> is there any way to make Data.Dependent.DMap and Data.Map be the same thing? it's a bit of a shame that they have to duplicate the code between them
09:14:35 <ryantrinkle> https://hackage.haskell.org/package/dependent-map-0.2.1.0/docs/Data-Dependent-Map.html#t:DMap
09:21:12 <cinimod> I have just installed the Haskell Platform for Mac OS X
09:21:21 <cinimod> And then tried to run cabal
09:21:58 <cinimod> It has been running something called cabal.real for the last 4 minutes
09:22:03 <cinimod> Is that expected?
09:22:17 * hackagebot cgrep 6.6.8 - Command line tool  https://hackage.haskell.org/package/cgrep-6.6.8 (NicolaBonelli)
09:25:06 <ertesx> Zemyla: good question
09:25:08 <ggVGc> is there a better way to write this in terms of Foldable, without relying on toList? https://gist.github.com/1056d71ad015d366a4f8202747a55f3e
09:26:45 <ertesx> ryantrinkle: i don't think so
09:27:00 <ertesx> Data.Map is a special case
09:27:24 <ryantrinkle> ertesx: interesting; how so?
09:30:36 <Zemyla> ggVGc: I think so. mapMaybe f . toList = foldr (\a r -> maybe r (:r) $ f a) []
09:30:38 <ertesx> ryantrinkle: data Key :: * -> * -> * where Key :: k -> Key k a
09:31:12 <ertesx> ryantrinkle: then DMap (Key k a) Identity ~ Map k a  -- if i haven't got something wrong
09:31:42 <ryantrinkle> yes, that's right
09:31:52 <ryantrinkle> Key ~ Data.Functor.Constant.Constant, iirc
09:31:58 <Zemyla> And actually, maybe [] g . listToMaybe . mapMaybe f . toList = foldr (\a r -> maybe r g $ f a) []
09:32:22 <Zemyla> :t \f g -> maybe [] g . listToMaybe . mapMaybe f . toList
09:32:24 <lambdabot>     Ambiguous occurrence ‘toList’
09:32:24 <lambdabot>     It could refer to either ‘Data.Foldable.toList’,
09:32:24 <lambdabot>                              imported from ‘Data.Foldable’ at /home/lambda/.lambdabot/State/L.hs:87:1-20
09:32:24 <ryantrinkle> however, i don't know of any way to actually express that
09:32:32 <ryantrinkle> perhaps it could be made coercible?
09:32:36 <Zemyla> :t \f g -> maybe [] g . listToMaybe . mapMaybe f . Data.Foldable.toList
09:32:38 <lambdabot> Foldable t1 => (a1 -> Maybe a) -> (a -> [t]) -> t1 a1 -> [t]
09:32:45 <Athas> How come Accelerate is used so rarely compared to Repa (judging by http://packdeps.haskellers.com/reverse)?
09:33:08 <Zemyla> :t \f g -> foldr (\a r -> maybe r g $ f a) []
09:33:09 <lambdabot> Foldable t => (a -> Maybe a1) -> (a1 -> [t1]) -> t a -> [t1]
09:33:25 <ertesx> ryantrinkle: "express"?
09:33:42 <Zemyla> There you go, ggVGc. That should express it in terms of foldr.
09:33:51 <ryantrinkle> ertesx: as in, how could we actually make haskell aware of that equivalence
09:33:57 <ryantrinkle> so that the code could be written only once
09:34:25 <ertesx> ryantrinkle: well, you could make dependent-map a dependency of containers and define Map in terms of DMap
09:35:04 <ryantrinkle> i suppose so, although i wonder if the performance would suffer
09:35:16 <ryantrinkle> i think it'd have to, at least until the GADT/newtype optimization gets in
09:35:24 <ryantrinkle> since the Constant/Key wrapper would introduce a new indirection
09:35:42 <Zemyla> Is there a Map over Strings or Texts that is actually a nested map over characters?
09:35:45 <ertesx> it can be a newtype
09:36:15 <Zemyla> I know, but has anyone written it already?
09:36:25 <ertesx> ryantrinkle: Constant is a newtype anyway, but more generally GADTs can be newtypes
09:36:31 <ryantrinkle> ertesx: hmm, ah right
09:36:36 <bergmark> Zemyla: a prefix tree?
09:36:45 <Zemyla> Basically.
09:36:45 <ryantrinkle> ertesx: yes, but iirc, they can't have existential contexts, even if they include only equivalences
09:36:52 <ryantrinkle> i do see that that doesn't come up here
09:36:52 <ertesx> Zemyla: there is the bytestring-trie library, if that's what you're looking for
09:36:55 <ryantrinkle> i was thinking of Some
09:36:57 <ertesx> Zemyla: it's a radix tree
09:37:39 <Ohso_> Using leksah on Debian stable, while editing files it will start trying to build over and over again, looping for some time before stopping and finally saving the changes to my file. It was very seldom at first, but now happens almost everytime I touch a file. What the heck is it doing?
09:39:09 <{AS}> "Warning: The package list for 'hackage.haskell.org' is 23.3 days old." I like the precision
09:39:29 <{AS}> Those .3 days really matter
09:40:44 <{AS}> :)
09:40:48 <ertesx> if you have the precision, might as well display it ;)
09:42:02 <ertesx> you know what annoys me?  my mobile phone displaying crap like "just now", "a few minutes ago" or "yesterday"
09:42:59 <{AS}> :)
09:51:50 <jle`> {AS}: kind of crazy that you checked it when it was exactly 23.30000000 days old
09:52:29 <{AS}> jle`: It usually displays more precision? :O
09:53:03 <jle`> no, heh, it was a joke v.v
09:53:40 <{AS}> Ah, heh
09:53:42 <{AS}> I mean I laughed
09:53:51 <{AS}> but then I wondered (because I couldn't tell :))
10:07:51 <nomeata> I guess it is about time for me to look more closely into using stack. It is quite clear to me how to use a stack.yaml to pin down precise versions to be used in a leaf project. But what are the recommended practices when maintaining a library that I want to be compatible with, say, LTS-4, LTS-5 and LTS-6? Have multiple stack.yaml files?
10:08:54 <nomeata> hmm, maybe http://docs.haskellstack.org/en/stable/travis_ci/ answers that question
10:32:36 <petercommand> Is it possible that a constructor closure has a pointer tag of 0 after evaluating to head normal form?
10:42:20 * hackagebot sorted-list 0.2.0.0 - Type-enforced sorted lists and related functions.  https://hackage.haskell.org/package/sorted-list-0.2.0.0 (DanielDiaz)
10:42:30 <lambda-11235> What if module export lists could be specified using hiding, so that only private members need to be listed?
10:42:43 <jmcarthur> petercommand: How do you evaluate a closure to head normal form? Do you mean WHNF?
10:42:57 <ondraa> hello. I have a function, I would like it to be of type EventM t, however once I use it with EKey it gets specified to EventM EKey and then it refuses to compile with EventM EButton. Is there any way how to make this polymorphic if EKey and EButton are not instances of some class?
10:43:01 <lambda-11235> e.g. module Foo hiding (boo) where
10:48:39 <lyxia> ondraa: that sounds like monomorphism restriction
10:49:35 <lyxia> ondraa: did you define your value as "f = ..." with no arguments? try adding an annotation "f :: EventM t ; f = ..."
10:49:52 <hsk3> https://www.haskell.org/ghc/
10:49:53 <hsk3> I just noticed that GHC 8 is out zomg zomg
10:50:04 <hsk3> a week ago lol
10:50:39 <petercommand> jmcarthur: I evaluated the data type using deepseq
10:50:40 <jmcarthur> petercommand: Anyway, I think the answer is yes, because I think other pointers to the same heap object aren't updated until the next time the gc moves it.
10:51:20 <jmcarthur> petercommand: Well, maybe I'm being pedantic, but deepseq is not able to give you anything better than WHNF in general, even though it claims otherwise.
10:51:35 <jmcarthur> petercommand: If there are no functions involved, it will actually give you NF.
10:51:43 <petercommand> it's a tree-like data structure
10:51:55 <petercommand> so it will be NF
10:52:30 <lyxia> ondraa: there should be some typeclass involved actually, "f :: TheTypeclass t => EventM t"
10:52:31 <jmcarthur> petercommand: Okay. In any case, if there are other pointers to that tree, they won't be updated immediately upon evaluating it, but only the next time the GC moves it.
10:52:45 <jmcarthur> Or at least that is my understanding.
10:53:10 <ondraa> lyxia: I did define it as "f = ..." in a where section. It's not the monomorphism restriction.
10:53:48 <ondraa> lyxia: yes, I think so, I was just curious if it can be done without a typeclass as in my example I cannot do it (it's the gtk3 library)
10:54:27 <petercommand> jmcarthur: ok..so I should be able to use the pointer with the tag of 0 to access the info table of the constructor closure, is this correct?
10:54:47 <jmcarthur> petercommand: From the paper: "[...] we cannot guarantee to tag *every* pointer to a constructor [...]. In contrast, though, a non-zero tag must never lie [...]"
10:55:21 <jmcarthur> petercommand: Yes. You should even be able to do so with a tagged pointer by masking the tag bits out.
10:55:44 <ondraa> lyxia: but I guess I can call it an error in the gtk3 library and let it go (as I need to call liftIO later anyway so I just call it on more places)... so thank you
10:56:33 <Welkin> I haven't even used haskell is months
10:57:20 <petercommand> jmcarthur: ghc trac stated otherwise: "Pointer tagging is not optional, contrary to what the paper says"
10:57:44 <petercommand> https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/HaskellExecution/PointerTagging
11:00:01 <jmcarthur> petercommand: It looks like they are only talking about entering continuations or non top level functions, and it looks like they way they ensure the property is true is by dynamically adding the tag if it's not there already.
11:00:06 <jmcarthur> petercommand: So I think what I said is still true.
11:00:43 <petercommand> jmcarthur: I am trying to get the info table of a constructor closure...and I am getting strange data in it
11:00:50 <petercommand> jmcarthur: i see..
11:01:49 <jmcarthur> Interesting. It didn't occur to me that when we know what the tag bits must be we can just offset the pointer instead of masking it. They seem to claim that works for the vast majority of pointer dereferences.
11:02:35 <petercommand> I have a foreign exported function that returns IO (StablePtr Block) where Block is a tree-like data type (a record)
11:03:20 <petercommand> and I tried to use GET_CON_DESC(CON_INFO_PTR_TO_STRUCT(GET_INFO(UNTAG_CLOSURE((StgClosure *)deRefStablePtr(stablePtr))))) to access the info table and constructor description of the constructor closure
11:03:54 <jmcarthur> petercommand: Hmm... It seems to me that a StablePtr could never include tag bits, or else C code might get confused.
11:04:04 <jmcarthur> But I'm only making wild guesses.
11:04:21 <petercommand> jmcarthur: StablePtr is just a handle
11:04:52 <ondraa> lyxia: FYI I ended up using the 'any' type
11:04:54 <Welkin> C will get confused? lol what?
11:04:55 <petercommand> deRefStablePtr does a table lookup to give the original value
11:05:11 <petercommand> which is a closure ptr
11:05:12 <jmcarthur> Oh, I see. I didn't see that function call in your code at first.
11:05:17 <jmcarthur> I understand.
11:05:33 <jmcarthur> I think we've reached the limits of my knowledge though.
11:09:38 <mikail_> Hi, is there a built in function in Haskell to calculate the average of a list of doubles?
11:10:11 <Welkin> who knows?
11:10:18 <Welkin> just sum the list and divide by the length
11:10:32 <mikail_> i'm having trouble with that
11:10:53 <mikail_> i have a list of type: PrimMonad m => m [Double]
11:11:07 <Welkin> > (\a -> sum a / length a) [1..10]
11:11:08 <lambdabot>      No instance for (Fractional Int) arising from a use of ‘/’
11:11:08 <lambdabot>      In the expression: sum a / length a
11:11:08 <lambdabot>      In the expression: \ a -> sum a / length a
11:11:24 <mikail_> when i do this: (sum <$> k) / (length <$> 100)
11:11:24 <monochrom> mikail_: you will need fromIntegral
11:11:29 <Welkin> > (\a -> sum a / fromIntegral $ length a) [1..10]
11:11:31 <lambdabot>      No instance for (Show a0)
11:11:31 <lambdabot>        arising from a use of ‘show_M34665813447374725235177’
11:11:31 <lambdabot>      The type variable ‘a0’ is ambiguous
11:11:34 <monochrom> @quote monochrom fromIntegral
11:11:34 <lambdabot> monochrom says: You've got an Int / But you want Double / Who do you call? / "fromIntegral!"
11:11:42 <mikail_> i get <interactive>:40:16:                                                                                                                                                                                             Couldn't match type ‘Int’ with ‘Double’                                                                                                                                                                    
11:11:44 <Welkin> damn it
11:11:58 <mikail_> oh ok
11:11:59 <Welkin> > (\a -> sum a / fromIntegral $ length a) [1.0 .. 10.0] :: [Double]
11:12:00 <mikail_> thanks
11:12:01 <lambdabot>      No instance for (Fractional [Double]) arising from a use of ‘/’
11:12:01 <lambdabot>      In the expression: sum a / fromIntegral
11:12:01 <lambdabot>      In the expression: sum a / fromIntegral $ length a
11:12:09 <Welkin> haha
11:12:14 <Welkin> oh fuck you `/`
11:12:29 <Welkin> > (\a -> sum a / fromIntegral $ length a) ([1.0 .. 10.0] :: [Double])
11:12:31 <lambdabot>      Couldn't match type ‘Double’ with ‘Int -> b’
11:12:31 <lambdabot>      Expected type: [Int -> b]
11:12:31 <lambdabot>        Actual type: [Double]
11:12:42 <lyxia> m [Double] is not quite a list though
11:12:53 <Welkin> > (\a -> sum a / (fromIntegral $ length a)) ([1.0 .. 10.0] :: [Double])
11:12:55 <lambdabot>  5.5
11:12:58 <Welkin> jesus
11:13:08 <monochrom> this is why you shouldn't trust $
11:13:29 <monochrom> it is not DWYM
11:13:36 <monochrom> (nothing is)
11:19:38 <hsk3> Within the do-block of a ActionT Text (ReaderT String IO), how can I actually get at that String?
11:19:45 <hsk3> It seems it's hidden.
11:19:53 <Welkin> run the reader
11:19:55 <Welkin> runReaderT
11:19:58 <monochrom> lift ask
11:20:01 <Welkin> oh yeah
11:20:02 <Welkin> haha
11:20:04 <Welkin> ask
11:20:18 <monochrom> "lift" for skipping the ActionT level
11:20:35 <Welkin> wow, I forgot a lot of this in just a few months
11:20:36 <monochrom> actually, I wonder if "lift" is necessary.
11:20:48 <Welkin> probably not
11:20:57 <Welkin> if there are the right type classes for ActionT
11:20:59 <Welkin> whatever that is
11:21:05 <monochrom> yeah. (MonadReader)
11:21:21 <Welkin> where is ActionT from anyway?
11:21:36 <hsk3> scotty
11:21:36 <monochrom> one of the web programming libraries
11:25:18 <hsk3> monochrom: ask only gives me the reader, which is a wrapped function. it doesn't actually give me the value that is passed into this function...
11:25:21 <hsk3> does it?
11:25:33 <hsk3> and that's the String there
11:25:58 <hsk3> oh shit, wait
11:26:07 <hsk3> ask :: Monad m => ReaderT r m r
11:26:10 <hsk3> that's why r is twice!
11:26:23 <hsk3> clever
11:28:16 <Welkin> cobreadmonster: hola
11:28:30 <cobreadmonster> Ah, look it's Welkin!
11:40:06 <hsk3> main :: IO ()
11:40:07 <hsk3> main = do
11:40:07 <hsk3>     ([prefixArg] :: [String]) <- getArgs
11:40:16 <hsk3> Why is that
11:40:17 <hsk3> Illegal type signature: ‘[String]’
11:40:18 <hsk3> ?
11:41:02 <lyxia> hsk3: types in patterns is part of an extension
11:41:11 <hexagoxel> ScopedTypeVariables
11:41:47 <hsk3> ok thanks
11:43:29 <monochrom> you don't need a type for this example
11:43:51 <hsk3> yeah i know, just wanted to make it explicit
11:44:36 <monochrom> then ScopedTypeVariables is your friend
11:45:45 <hsk3> yep, it works :)
11:46:59 <monochrom> you don't need that pair of parentheses
12:01:40 <newcomer> I'm trying to define a trivial instance of Monad for educational reasons. Here's my code. The problem is actually with making it an instance of Show. It complains about pattern binding. http://lpaste.net/164739
12:02:40 <monochrom> I doubt that you attribute the problem cause correctly.
12:03:07 <newcomer> monochrom, besides being an instance of Monad but not Applicative.
12:03:11 <monochrom> but you have written "Show (D dx ds)" instead of "show (D dx ds)"
12:03:11 <shachaf> monochrom: Why not? The S in Show needs to be lowercase.
12:03:26 <newcomer> oh, that's it!
12:03:54 <monochrom> true, the compiler attributes the problem cause correctly
12:04:56 <newcomer> my ghci is of version < 7.10 so it gives a warning but runs it anyway.
12:06:28 <newcomer> so if I make my little type constructor an instance of Monad, can I some how make it "derive" Applicative?
12:07:06 <Welkin> yes
12:07:10 <Welkin> pure = return
12:07:24 <Cale> This "monad" fails the unit laws, btw.
12:07:33 <Cale> *Main> return 5 >>= f'
12:07:34 <Cale> D 10 ", then we doubled"
12:07:34 <Cale> *Main> f' 5
12:07:34 <Cale> D 10 "we doubled"
12:07:49 <shachaf> This "monad" fails those laws on purpose, though.
12:08:04 <Cale> *Main> f' 5 >>= return
12:08:04 <Cale> D 10 "we doubled, then "
12:09:35 <Cale> Yeah, pretty much. The issue is that this operation on strings which is being performed is only a semigroup operation and not a monoid operation.
12:12:09 <newcomer> Cale, yes, I figured it will fail the Monad laws but went with it being "pretty" anyway.
12:15:18 <Cale> newcomer: One thing you could do to get a monad for real is instead concatenate together lists of strings, and insert the "then, " between the steps for display at the end.
12:17:12 <shachaf> Sure, but then you lose track of when the returns happened.
12:23:56 <jmcarthur> I thought I might learn something by making this, but unfortunately I didn't. Sharing anyway. http://i.imgur.com/HOSgUwJ.png
12:24:12 <jmcarthur> It shows what GHC extension imply others.
12:25:03 <Cale> jmcarthur: Still kind of a nice thing to have. See if it can be added to the GHC User's Guide somewhere
12:25:35 <Welkin> perhaps we need a GHC clippy?
12:25:38 <jmcarthur> I think there should be a warning flag to help you find redundant extensions.
12:25:53 <Welkin> to help the user
12:27:07 <newcomer> This is what I wanted to make. http://lpaste.net/164747 ... Now how can I make it "derive" Applicative from Monad?
12:28:16 <jmcarthur> Just realized I made a mistake. Fixed: http://imgur.com/drL9wnc
12:29:18 <lyxia> newcomer: instance Applicative D where (<*>) = ap ; pure = return
12:34:37 <newcomer> lyxia, it complained that it's not an instance of Functor so I added "instance Functor d where fmap = liftM".
12:34:57 <newcomer> lyxia, I also had to import Control.Applicative and Control.Monad
12:35:07 <Welkin> of course
12:35:16 <Welkin> an Applicative must be a Functor
12:37:03 <newcomer> Welkin, I understand. But there must be an easier way to define a type constructor as an instance of Monad and tell the compile to "derive" the rest. right?
12:38:46 <lpaste> glguy annotated “No title” with “monad instances” at http://lpaste.net/164747#a164750
12:38:54 <glguy> newcomer: The modern set of instances looks a bit like that
12:41:07 <newcomer> glguy, Thanks.
12:41:18 <newcomer> But this was a nice little learning experience. I only had to define >>= and return and I got liftM and >=> for free.
12:42:04 <Welkin> newcomer: well yes :P
12:42:36 <Welkin> liftM is just (>>= . return)
12:43:03 <Welkin> er
12:44:09 <newcomer> This is the final version that works nicely. http://lpaste.net/164752
12:44:41 <Welkin> I need to start writing haskell again
12:44:44 <Welkin> I'm rusty as fuck :D
12:49:19 <minib00m> newcomer: what's the difference between your monad of D and applicative of D? 
12:51:13 <newcomer> minib00m, keep in mind that I'm just a beginner. I had to make D an instance of Applicative because the compiler complains about it being a Monad but not an Applicative.
12:52:03 <newcomer> 55555555555555555555555555555555555555555
12:52:13 <glguy> newcomer: When you violate the Monad laws with your instance you can't rely on things using those instances
12:52:14 <glguy> *Demo> fmap id (g' 10)
12:52:14 <glguy> (30; we tripled, then )
12:52:19 <glguy> now fmap id isn't id
12:52:19 <minib00m> newcomer: don't get me wrong, i'm probably bigger newcomer than you, just trying to figure out things "D
13:00:05 <newcomer> What about now, does it comply with the laws now? http://lpaste.net/164753
13:01:08 <minib00m> why don't you test it yourself, for example with quickCheck? :) 
13:03:03 <newcomer> minib00m, that's part of being a beginner. I only know what quickcheck is. :)
13:04:06 <glguy> Yeah, now it's OK
13:05:32 <newcomer> glguy, :)
13:06:15 <dfeuer> kosmikus, I found an only mildly ugly way to nix the Sized junk, and bring the AdjustFun GADT down to two constructors, without duplication. Unfortunately, I can't measure a speed difference compared to the current implementation. It should be possible to improve it a bit using a nasty unsafeCoerce, I think, but that's evil.
13:07:59 <dfeuer> kosmikus, however, I wonder if this technique might be more useful for something like mapWithIndex, where the built function is used multiple times.
13:08:02 <lpaste> glguy annotated “Little Monad” with “little monad via writer” at http://lpaste.net/164752#a164755
13:08:48 <glguy> newcomer: In this case you're reimplemented an instance of a more general thing. Instead of reimplementing it you can reuse the existing instances :)
13:10:18 <dfeuer> Hrmmmm...
13:10:28 <dfeuer> Maybe that's silly.
13:10:31 * dfeuer ponders.
13:15:29 <Gurkenglas> minimaOnByM and its siblings in Control.Monad.Loops should only require Applicative instead of Monad, since it always has to run all monadic actions to determine minima
13:16:41 <Gurkenglas> Oh wait, it compares different elements depending on what's the running minima. Only the OnM variants then, I guess.
13:17:26 * hackagebot here 1.2.8 - Here docs & interpolated strings via quasiquotation  https://hackage.haskell.org/package/here-1.2.8 (TaylorHedberg)
13:18:29 <newcomer> lol @ Nothing :: Maybe Page. https://www.fpcomplete.com/ide?title=No%20title&paste=http://lpaste.net/raw/164753
13:18:34 <Gurkenglas> Like, it should be "minimaOnByM f cmp = traverse f >=> minimaByM cmp", and that one should have that big recursive block
13:19:14 <Gurkenglas> (that one = minimaByM)
13:19:30 <lifter> GHC (am actually using GHC 8) sometimes infers type signatures w/ "forall" in them, such as `forall a b. Either a b -> (Blah, Maybe b)`. Why? Are these needed?
13:19:37 <Gurkenglas> Link for the lazy to the code I'm talking about: https://hackage.haskell.org/package/monad-loops-0.4.3/docs/src/Control-Monad-Loops.html#minimumOnByM
13:21:11 <Gurkenglas> (I guess the semantics would be different because the monadic actions from f would all happen first, but why is the current order more correct?)
13:21:52 <minib00m> newcomer: hillarious page i must say :D
13:22:26 * hackagebot pipes-safe 2.2.4 - Safety for the pipes ecosystem  https://hackage.haskell.org/package/pipes-safe-2.2.4 (GabrielGonzalez)
13:22:28 * hackagebot pipes-parse 3.0.7 - Parsing infrastructure for the pipes ecosystem  https://hackage.haskell.org/package/pipes-parse-3.0.7 (GabrielGonzalez)
13:27:27 * hackagebot pipes-concurrency 2.0.6 - Concurrency for the pipes ecosystem  https://hackage.haskell.org/package/pipes-concurrency-2.0.6 (GabrielGonzalez)
13:27:36 <hexagoxel> lifter: i'd guess that the ghc output just is overly explicitly and that you can omit the "forall […] ." part.
13:27:39 <hexagoxel> lifter: see http://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#ghc-flag--XExplicitForAll
13:28:18 <lifter> hexagoxel: Yeah, seems like I might not need it.
13:28:20 <lifter> Thanks.
13:29:41 <hexagoxel> lifter: out of curiosity, did you see this behaviour change from ghc7->8 ?
13:30:29 <lifter> hexagoxel: Not entirely sure. I've seen it in the past... So perhaps not. BUT, GHC is now asking me to supply type signatures for my pattern synonyms, and it is suggesting sigs w/ forall in them.
13:30:47 <lifter> That is new.
13:31:41 <hexagoxel> ah, ok.
13:34:06 <geekosaur> ghc8 changed how patsyn type signatures were handled, and is probably using the default forall behavior
13:37:43 <lifter> Right on.
13:42:27 * hackagebot hdaemonize 0.5.0.2 - Library to handle the details of writing daemons for UNIX  https://hackage.haskell.org/package/hdaemonize-0.5.0.2 (sickmind)
13:50:01 <mikipomp> ciao
13:50:21 <mikipomp> !list
13:53:28 <thomasd> anyone here familiar with semi-advanced PL Theory topics? 
13:53:40 <thomasd> I'm looking for advice on how to implement pattern matching
13:53:57 <thomasd> in addition to spj-implfuncproglangs-1987
13:54:14 <nitrix> thomasd: Afaik, a tag system. Tagged struct or tagged union.
13:56:04 <tenniscp25> is persistent-odbc ready for production?
14:00:43 <maerwald> tenniscp25: last commit was 10 months ago
14:00:57 <maerwald> I wouldn't be so worried about "ready for production" but rather "how well is it maintained?"
14:01:09 <maerwald> a lot of haskell libraries get created quickly and then die out slowly
14:05:29 <gajus> Well, thats a coincidence. Was talking the other week how'd like to start learning Haskell but I cannot find top-tier contracts. The next day got headhunted for a position in a company thats using predominantly Haskell.
14:05:45 <Habib> nice
14:06:16 <Rotaerk> gajus, hmm, if you're not used to functional programming, learning haskell can be like learning to program all over again
14:06:35 <Rotaerk> so trying to get a haskell job and then learning for that job seems risky
14:06:53 <Rotaerk> should give yourself more time with the language before getting hired for it
14:06:54 <gajus> Rotaerk My role has nothing to do with Haskell.
14:07:10 <gajus> Well, everyone else in the team will be using Haskell. Just not me.
14:07:15 <Rotaerk> oh
14:07:30 <gajus> So, it is a great learning environment should I choose to learn it.
14:07:44 <Habib> nicer, totally misread your first commnet
14:08:52 <Habib> lol, before i found out about haskell and functional programming in general, i remember looking at the programming paradigms wikipedia page, and being fascinated by all the different paradigms. i completely ignored functional, as i just assumed i knew exactly what it was (functions, which C has, right?).
14:08:54 <Welkin> Habiba
14:08:55 <Welkin> lol
14:09:24 <Habib> at my first comment or my second?, because that was a very quick reaction.
14:09:35 <Habib> almost immediate
14:09:38 <Welkin> your name
14:09:52 <Habib> haha, i've never had anyone find my name funny before.
14:09:57 <Habib> this is my real name
14:10:46 <gajus> well, it has positive connotations https://en.wikipedia.org/wiki/Habibi
14:11:12 <Clint> ...
14:11:40 <gajus> td;dr; means "beloved"
14:11:52 <Welkin> habibi is "friend" right?
14:12:00 <gajus> or that
14:12:11 <gajus> Depends on the context.
14:12:12 <Habib> i was raised by religious parents, and in the religion, it's customary to give children names with very positive connotations. neutrality isn't really a thing in muslim (or evangelical christian, i think?) names.
14:12:23 <Habib> i always took it as “beloved”.
14:12:52 <Habib> i am the first-born.
14:13:08 <Welkin> in indonesia, they name their children by number
14:13:11 <tdammers> who would want to give their kid a name that is the equivalent of "meh"?
14:13:14 <Welkin> "child one, child two, child three"
14:13:21 <Habib> it means “beloved”, but it can be used in a romantic context or platonic or familial
14:13:30 <Welkin> in other south asians countries they do this too
14:14:02 <tdammers> george foreman named all his 5 sons "george", so there's another pragmatic approach
14:14:14 <Habib> is it really pragmatic?
14:14:22 <Welkin> tdammers: and one of them popped out mexican, so he named him jorge
14:14:26 <Habib> seems like a hassle to distinguish them, the very purpose of names, is it not?
14:14:34 <Welkin> haha
14:14:50 <Welkin> billy bob, bobby bill, bill bobby, and billy bobby john
14:14:58 <tdammers> it's pragmatic in the sense that you don't have to come up with a name
14:15:08 <Welkin> that's how the appalachians do it
14:15:10 <Habib> well, yeah, but then you might as well not come up with a name
14:15:28 <Habib> instead of slapping the same name on all of them.
14:16:11 <Welkin> https://en.wikipedia.org/wiki/Balinese_name
14:16:37 <Welkin> everyone is named Wayan
14:16:37 <Welkin> lol
14:17:50 <Welkin> names are a curious thing
14:17:55 <Habib> yes, very.
14:17:56 <Welkin> in many cultures, anmes don't mean anything
14:18:01 <Welkin> and some don't use names
14:18:12 <glguy> Curious, but also off-topic in #haskell
14:18:34 <Welkin> glguy: always here to kill our joy
14:19:32 <Habib> here's something on-topic, maybe my brain is just off tonight, but i've been postponing the last few chapters of LYAH and i'm just finishing them off right now (i know i spoke on here with someone who suggested moving on if i'm comfortable, but i'm a little bit of a completionist if i'm almost complete, anyway).
14:19:47 <Habib> anyone want to explan what this type signature means?
14:19:49 <Habib> runState :: State s a -> s -> (a, s)
14:20:13 <Clint> which parts don't you understand?
14:20:19 <Habib> so State is a constructor that takes an initial state s, but then what's a?
14:21:11 <Habib> i think i understand how this makes the threeCoins example function easier to write, but i want to rewrite it without do notation just to make sure i fully understand it
14:21:25 <Clint> in this line s and a are type variables
14:21:48 <maerwald> as is the result
14:21:53 <maerwald> *a is the result
14:21:59 <Habib> the tuple containing a and s.
14:22:01 <geekosaur> "State s a" is a computation (that is, a function) with a state of type s, producing a result of type a
14:23:07 <geekosaur> runState takes a State s a (again, a function) and an initial state value, and gives you back a tuple containing the result and the final state
14:23:43 <Habib> ah, okay, so State constructor itself takes a function, and then holds it until you pass it to runState along with s.
14:23:45 <tenniscp25> maerwald: i'm afraid so. btw, could you please recommend what i can use to make my sql-intensive app as type-safe as possible? my target database is ms sql server.
14:23:57 <lin> msSQL
14:24:00 <lin> Whyyyy
14:24:14 <tenniscp25> because i didn't choose...
14:24:18 <geekosaur> yes, pretty much
14:24:39 <maerwald> I don't know. All of my experiences with haskell database bindings/libraries were disappointing.
14:25:36 <Welkin> persistent is amazing
14:25:47 <maerwald> so in the end I would probably go with low-level db bindings still, since those are almost always well maintained
14:25:51 <Welkin> I am not sure if there is anything specificly for mssql though
14:26:10 <Welkin> most only support sql, postgres, and sqlite
14:26:31 <tenniscp25> i couldn't find mssql backend for persistent
14:26:56 <tenniscp25> persistent-odbc is the closest i could find
14:27:30 * hackagebot oscpacking 0.2.1.1 - Implements an osculatory packing (kissing circles) algorithm and display.  https://hackage.haskell.org/package/oscpacking-0.2.1.1 (infrared)
14:31:04 <Habib> how can you say `State random`, though? random takes a generator and returns a tuple containing the random number, along with a new generator. State takes a function that takes an initial seed (the generator in random's case) and that returns a tuple containing a result along with new seed of the same type as the original. but where does the m come in?
14:31:20 <Habib> StateT :: (s -> m (a, s)) -> StateT s m a
14:31:28 <Habib> random :: (RandomGen g, Random a) => g -> (a, g)
14:32:30 <Habib> shouldn't random be something like :: (RandomGen g, Random a) => g -> m (a, g)
14:32:41 <geekosaur> here's a trick:
14:33:03 <geekosaur> State s a    is short for    StateT s Identity a
14:33:13 <Habib> ooooh.
14:33:38 <Habib> see when i try to :t State, it i get an error that it's not in scope and i may have meant StateT
14:33:43 <geekosaur> right
14:33:51 <Habib> :i State doesn't give anything useful either
14:33:59 <Habib> or at least, nothing i could make sense of
14:34:15 <geekosaur> State is a type alias (type State s a = StateT s Identity a)
14:34:18 <Habib> so i don't need to understand StateT yet then, since the book doesn't explicitly mention it yet.
14:34:27 <glguy> state random :: (RandomGen g, Random a) => State g a
14:34:34 <Habib> got it
14:34:46 <geekosaur> ":t" is looking for a constructor named State but there isn't one because State is a type-level alias. the constructor is StateT
14:34:49 <glguy> 'state' is the automatically lifting constructor that you use instead of 'State' when it's not a transformer
14:35:10 <geekosaur> and there is a function `state` (note lowercase) that acts like the old State constructor from when State was its own type instead of an alias
14:35:18 <Habib> lifting?
14:36:54 <roboguy`> :t state
14:36:56 <lambdabot> MonadState s m => (s -> (a, s)) -> m a
14:37:19 <jmcarthur> A pattern synonym might make sense for this kind of thing.
14:37:49 <Habib> and i know nothing about transformers.
14:37:57 <Habib> RWH gets into that stuff, though, right?
14:38:01 <roboguy`> you can pretend that 'm' is just State
14:38:05 <Welkin> RWH is really old
14:38:08 <Welkin> and not very good
14:38:22 <Habib> what would you recommned?
14:38:26 <jmcarthur> I think RWH was good, but became outdated very quickly.
14:38:38 <Welkin> just read the typeclassopedia
14:38:40 <jmcarthur> @where haskellbook
14:38:40 <lambdabot> http://haskellbook.com
14:38:43 <Welkin> and various papers
14:38:46 <Welkin> and ask in here
14:38:52 <jmcarthur> haskellbook!
14:38:56 <Welkin> oh, and use the upenn course
14:39:09 <Habib> i remember this conversation, i should have taken more notes. last time i got recommended “Parallel and Concurrent Programming in Haskell - Techniques for Multicore and Multithreaded Programming” and “CIS 194: Introduction to Haskell”.
14:39:18 <Welkin> you can get started on a real project after just covering the basics
14:40:01 <Habib> i've already got one “real” project down so far.
14:40:13 <Habib> a simple crappy snake game for the console.
14:40:17 <Welkin> lol
14:40:24 <Welkin> that is a toy project
14:40:26 <Welkin> but a good start
14:40:42 <jmcarthur> I think a crappy snake game is a pretty reasonable project.
14:40:42 <Habib> haha, what would you consider “real” in this context?
14:40:46 <Habib> https://github.com/habibalamin/snake
14:41:11 <Welkin> well, anything that someone would actually build and use in a real world situation
14:41:12 <monochrom> I wouldn't insist on "real".
14:41:36 <Welkin> a hobby project works too though
14:41:36 <jmcarthur> "real world" is not necessary for learning at all
14:41:38 <Habib> i would build this, since i did, and people would use it, since i shared it with my ruby-using colleagues
14:41:41 <Habib> ;P
14:41:52 <jmcarthur> "real world" is not even a well defined idea
14:41:55 <monochrom> my criteria would be: reachable, satisfaction after reaching
14:42:01 <Welkin> jmcarthur: "real world" haskell?
14:42:02 <Welkin> lol
14:42:16 <Habib> well, snake was reachable (since i did) and i felt satisfied after reaching it.
14:42:22 <Habib> so i think that counts.
14:42:34 <Welkin> that's good
14:43:09 <Habib> the code is not very good, as i was telling the people giving me feedback here last time. i focused a lot more on understanding haskell than clean code, so i avoided do notation in favour of directly using the functions.
14:43:17 <monochrom> yes, I despise the title and idea of "real world haskell" too. it's the result of kissing up to people who say "real world" blindly.
14:44:11 <Welkin> it is the distinction between programming as an exercise vs programming as a tool
14:44:14 <Welkin> programming is a tool for me
14:44:15 <monochrom> but it's not my title, so I don't have to defend it.
14:45:31 <monochrom> that is a false dichotomy
14:46:09 <monochrom> if one's programming career is any challenging at all, it is (by definition of "challenging") both exercise and tool.
14:46:21 <Welkin> I mean an academic exercise
14:46:30 <monochrom> both learning and shipping happen, and it's all mixed up
14:47:11 <monochrom> but I understand that some people's programming career is simply repetitive and no post-school learning is necessary.
14:47:31 <monochrom> the downside is that those are the people who are most vocal about "real world"
14:47:38 <Welkin> post-school learning?
14:47:44 <Welkin> I never learned any haskell in school
14:47:45 <Welkin> wtf
14:47:58 <monochrom> so I take it to mean unchallenging, nothing new, the same scripting over and over again.
14:48:09 <Welkin> and yes, I learned everything about C and how it works
14:48:16 <Welkin> could I actually build *anything*? hell no
14:57:31 * hackagebot pinchot 0.18.0.2 - Write grammars, not parsers  https://hackage.haskell.org/package/pinchot-0.18.0.2 (OmariNorman)
14:57:42 <darthron> hi!
14:58:50 <darthron> could someone explain why `fact = scanl (*) [1..]` works? How does it get to 2! ?
14:59:43 <simpson> darthron: Are you familiar with scanl yet?
14:59:45 <monochrom> wait, is it missing a parameter?
15:00:01 <simpson> :t scanl
15:00:05 <lambdabot> (b -> a -> b) -> b -> [a] -> [b]
15:00:07 <darthron> Yes, sorry, it's scanl (*) 1 [1,..]
15:00:08 <simpson> You need the starting accumulator.
15:01:00 <darthron> Yes, I am familiar with it, it's like a foldl, but it also keeps the results
15:01:17 <glguy> > scanl (+) z [a,b,c,d]
15:01:19 <lambdabot>  [z,z + a,z + a + b,z + a + b + c,z + a + b + c + d]
15:01:24 <monochrom> scanl (*) 1 [x, y, z, a] = [1, 1*x, (1*x)*y, ((1*x)*y)*z, ((1*x)*y)*a]
15:01:29 <simpson> Right. It builds up the fold incrementally, and each step in the result list is a partial fold of the pieces that have come before it.
15:01:58 <darthron> Yes, but I can't figure it out why it doesn't give [1,1..]
15:02:06 <darthron> When it multiplies by 2
15:02:16 <monochrom> I don't understand the question.
15:02:21 <monochrom> but I know the answer is:
15:02:27 <monochrom> > scanl (*) 1 [1..]
15:02:28 <simpson> > [1,..] -- just double-checking that you know how this syntax works
15:02:31 <lambdabot>  [1,1,2,6,24,120,720,5040,40320,362880,3628800,39916800,479001600,6227020800,...
15:02:32 <lambdabot>  <hint>:1:4: parse error on input ‘..’
15:02:54 <monochrom> > [1..]
15:02:57 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
15:03:10 <Welkin> lol, bad timing simpson 
15:03:12 <Welkin> you confused me
15:04:13 <darthron> why isn't scanl (*) 1 [1,..] = [1, 1 * 1, 1 * 1 * 1, ..] ?
15:04:49 <geppettodivacin> darthron: Because [1,..] isn't [1,1..]
15:04:52 <Welkin> > [1,1..] -- this would be
15:04:53 <geppettodivacin> > [1,..]
15:04:54 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
15:04:55 <lambdabot>  <hint>:1:4: parse error on input ‘..’
15:05:02 <Welkin> but yours is an error
15:05:12 <geppettodivacin> Oops, right.
15:05:14 <darthron> oh, right, sorry
15:05:22 <geppettodivacin> > [1..]
15:05:24 <darthron> thank you!
15:05:25 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
15:05:47 <geppettodivacin> darthron: You're welcome!
15:06:12 <monochrom> syntax errors are contagious
15:06:23 <Welkin> > [1,5..] -- you can do this too
15:06:25 <lambdabot>  [1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77,81,85,89,93,97,101...
15:06:25 <monochrom> after one person writes [1,..], everyone writes it too
15:08:13 <darthron> you can write fibs = 1 : scanl (+) 1 fibs. Could you write fact using the same style?
15:09:44 <darthron> as in fact = 1 : scanl (*) 1 fact
15:09:57 <monochrom> I don't know. but read my http://www.vex.net/~trebla/haskell/scanl.xhtml for why that works for fib. and then you can see whether the same reason extends to factorials.
15:10:01 <darthron> but modyfing it such that it multiplies with an incremented counter
15:10:18 <jmcarthur> darthron: You mean to generate all factorials?
15:10:25 <Habib> okay, i give up. is there a way to write `runState randomSt (mkStdGen 1)` in a way that doesn't use lets with temporary variables holding each new generator, nor uses do notation that returns 3 random *things* that each use the generator returned by the last returned random *thing*?
15:10:38 <Habib> randomSt being `state random`.
15:10:41 <darthron> jmcarthur: yes
15:10:49 <jmcarthur> > scanl (+) [1..]    -- no need for the recursive definition
15:10:50 <lambdabot>      No instance for (Typeable t0)
15:10:51 <lambdabot>        arising from a use of ‘show_M85491402465967981459651’
15:10:51 <lambdabot>      In the expression:
15:10:51 <Welkin> Habib: yes... use bind to connect them all together
15:10:56 <jmcarthur> wat
15:11:01 <jmcarthur> > scanl (+) 1 [2..]    -- no need for the recursive definition
15:11:03 <lambdabot>  [1,3,6,10,15,21,28,36,45,55,66,78,91,105,120,136,153,171,190,210,231,253,276...
15:11:13 <jmcarthur> what have i done wrong
15:11:27 <monochrom> you used addition :)
15:11:32 <jmcarthur> lol
15:11:38 <jmcarthur> > scanl (*) 0 [1..]    -- no need for the recursive definition
15:11:40 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
15:11:42 <jmcarthur> oh god
15:11:43 <monochrom> I think you got the triangle numbers
15:11:46 <jmcarthur> ill stop now
15:11:54 <jmcarthur> That was totally an accident
15:11:59 <jmcarthur> The idea is clear
15:12:34 <Habib> you mean `>>=`? i tried that, but i think i'm just plopping things together rather than truly understanding here. i did suspect >>= to lead to the answer, but i can't think how to get there.
15:12:47 <jmcarthur> > scanl (*) 1 [2..]   -- I lied. Here it is. I'm just being more careful this time.
15:12:49 <lambdabot>  [1,2,6,24,120,720,5040,40320,362880,3628800,39916800,479001600,6227020800,87...
15:13:00 <Welkin> Habib: look at the definition of the Monad instance for Random
15:13:10 <koz_> OK, I have a slightly complex question. I have a Set (Set Foo), and I wanna return another Set (Set Foo) such that none of the 'inner' sets are subsets of each other. I.e. if I had { {Foo_1, Foo_2} , {Foo_1} }, I want to get { { Foo_1 } } back. Is there a (simple) way to do this?
15:13:11 <monochrom> @type random
15:13:13 <lambdabot> (RandomGen g, Random a) => g -> (a, g)
15:13:18 <Welkin> Habib: you will need to dig into the source code and inspect it to get an intuition for how it works
15:13:38 <jmcarthur> koz_: Are you willing to sacrifice efficiency for simplicity?
15:14:10 <monochrom> Habib: does "runState (do {x <- randomSt; y <- randomSt; return (x,y)}) (mkStdGen 1)" satisfy your requirement, except I only did 2 not 3?
15:14:44 <koz_> jmcarthur: Currently, yes.
15:14:47 <monochrom> in fact, s/runState/evalState/, pretty sure no one cares about the final generator state
15:14:56 <jmcarthur> koz_: Also, what criteria do you use to decide which ones to drop? Why did you drop the one you did in your example instead of the other one?
15:15:07 <Habib> :i Monad doesn't mention anything about random.
15:15:16 <koz_> jmcarthur: Drop the larger sets if possible.
15:15:25 <Habib> monochrom: that uses do notation which is a no go.
15:15:47 <monochrom> may I use >>= then?
15:15:49 <Habib> not that i want to avoid it in real life, i just think seeing it without the do notation will help me understand the types better
15:15:55 <Habib> yes, that's exactly what i'm looking for.
15:15:59 <monochrom> if not, may I use <*> then? that's a bottom line
15:16:07 <Habib> >>= is fine
15:16:26 <monochrom> evalState (randomSt >>= \x -> randomSt >>= \y -> return (x,y)) (mkStdGen 1)
15:17:52 <monochrom> I only have two names x,y for the random numbers obtained, not any name for the intermediate generator states, and not stuck with the initial generator states. these are the doings of >>=, it propagates internal state
15:18:16 <monochrom> but of course, the implementation of >>= is going to be full of "let"s :)
15:18:30 <monochrom> but at least I don't get my own hands dirty
15:18:41 <monochrom> programming is an art of subcontracting
15:18:53 <Habib> thank you, that works. it helps me understand the types as well, but now i'm just confused as to how it deals with the state.
15:18:58 <monochrom> the holy grail being recursion --- the ultimate subcontracting
15:19:11 <Habib> ha, subcontracting to yourself.
15:19:13 <monochrom> >>= does the dirty state work for you
15:20:07 <koz_> jmcarthur: My current thought is 'pair up all the inner sets, check for subset relations, drop the bigger one, reassemble'.
15:20:09 <monochrom> "xxx >>= fff" passes xxx's poststate to fff
15:20:36 <monochrom> so fff won't be seeing the initial state at all. it sees the poststate caused by xxx.
15:20:47 <Habib> yes, i think i was just being an idiot by specifying to IO, so i was imagining an unwrapping.
15:20:58 <Habib> but >>= can be defined differently with different instances.
15:21:08 <Habib> because it's a function belonging to a typeclass, that being Monad.
15:21:15 <koz_> Habib: Many people have unconscious associations between monadic ops and IO.
15:21:20 <Habib> and state defines it as so.
15:21:24 <Habib> i think i have it now.
15:21:34 <Habib> now just to avoid falling asleep and forgetting it all :).
15:21:43 <Habib> must… stay… awake.
15:21:46 <sbrg> Habib: exactly. in State's case, it's defined to implicitly thread state. 
15:21:51 <Welkin> Habib: if you want to understand IO, read the paper "Lazy Functional State Threads" by Simon PJ
15:22:01 <monochrom> Sleeping Beauty may know a trick or two for you :)
15:22:23 <monochrom> that's only ST, not IO.
15:22:24 <Habib> thanks, guys.
15:22:27 <Welkin> to be found here: 
15:22:28 <Welkin> http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html#monads
15:22:37 <Welkin> monochrom: but IO is just ST
15:22:54 <monochrom> no, at best you can only explain the IORef part of IO
15:23:41 <monochrom> but why am I arguing with someone who's just going to call my point "only an academic difference and has no RealWorld# consequence"?
15:23:50 <Habib> State seems to be more confusing than IO, to be honest.
15:24:11 <Habib> i actually understand IO now, and how to work with it with pure functions.
15:24:12 <maerwald> it's mostly just hiding an explicit parameter
15:24:25 <Habib> It's just the innards are a black box.
15:25:08 <maerwald> maybe implement it yourself then
15:25:17 <Habib> That is one thing that bugs me a little, though. IO is just a value, but all IO looks the same from the outside. All I know is that it can return something, but the description of what it does can only be found at the source.
15:25:49 <maerwald> you mean IO is not really descriptive?
15:25:52 <monochrom> a few other things are like that, at any rate.
15:25:53 <Habib> I guess that's like functions as well, though, since they are not Show instances.
15:26:44 <monochrom> if I give you an "x :: Int", how much can you do with it?
15:27:15 <monochrom> you can print it. you can add it with something. but can you know how I got my x?
15:27:34 <jmcarthur> :t Set.fromList . mapMaybe (\case [] -> Nothing; (xs:xss) -> xs <$ (guard . all (Set.null . Set.intersection xs)) xss) . tails . sortOn (Down . Set.size) . Set.toList  -- koz_: Something like this maybe?
15:27:36 <lambdabot> parse error: naked lambda expression ''
15:27:49 <jmcarthur> Maybe lambdabot doesn't know LambdaCase?
15:27:55 <koz_> jmcarthur: That is... I think I need some time to understand what this is doing.
15:28:04 <Habib> But x is just a number, IO is a description of an action that will be performed at a later time.
15:28:05 <Welkin> lambdabot is special
15:28:18 <monochrom> if you print it and see it's 4, you may think you know everything. but how did I write the code to give you a 4? is it directly "4"? or is it a complicated formula that takes a day to run and then comes out as "4"?
15:28:49 <jmcarthur> koz_: Convert to list, sort in order of decreasing size, iterate over each tail of the list, eliminate any sets whose intersections with any set in the tail of the list is non-empty, convert back to set.
15:28:55 <maerwald> Habib: it doesn't even say what kind of action though ;)
15:28:56 <Habib> It doesn't matter, though. It's a 4 now, and I know it's a 4 and I can do what I want depending on what it is. If I'm holding an IO action on the other hand, I can't make decisions based on what it's going to do.
15:29:11 <Habib> I can only do it and weep.
15:29:28 <koz_> jmcarthur: Interesting - thanks! It just uses a few things I'm not familiar with, like 'guard'.
15:29:29 <Habib> I guess that's not that important, but I just have an aversion to black boxes.
15:29:41 <koz_> Habib: It's a natural aversion to have, but side-effects are horrid.
15:29:45 <monochrom> ok, next example, if I give you "y :: Int -> Bool", how much can you find out about it?
15:29:49 <koz_> They're unpredictable, can fail without warning, etc.
15:30:02 <maerwald> koz_: you can make the effects more specific though
15:30:21 <koz_> maerwald: Could you elaborate a bit on that?
15:30:22 <Habib> It would be nice to know if the IO i'm holding will just print something to the screen or delete a file, at least.
15:30:39 <maerwald> koz_: I feel like I've done that here a hundred times and monochrom is probably going to yawn now ;)
15:30:41 <jmcarthur> Habib: If you want to inspect something, you could make your own type to do it.
15:30:46 <Habib> And yes, I mentioned functions as one of those inscrutable values, but yeah…
15:31:09 <maerwald> koz_: you might want to look at idris and purescripts effect system though
15:32:03 <jmcarthur> Habib: data InspectableIO a = forall e. Show e => PrintSomething e (InspectableIO a) | DeleteAFile FilePath (InspectableIO a) | Return a
15:32:07 <monochrom> I agree that "printing vs deleting" is a good point. this is worse than my Int->Bool.
15:32:41 <monochrom> some people actually write newtype wrappers over IO and expose only a few intended operations.
15:32:51 <Habib> interesting.
15:33:07 <maerwald> or you can just have a proper effect system instead of adding newtype hackery 
15:33:39 <jmcarthur> maerwald: Please define "proper effect system". I haven't seen any that don't require me to write a bunch of boilerplate to get this.
15:34:05 <jmcarthur> maerwald: They just exchange newtype boilerplate for some other data type and handlers boilerplate.
15:34:16 <jmcarthur> (That was extensible effects. Maybe you have something else in mind.)
15:34:17 <maerwald> jmcarthur: did you look into idris effect system?
15:34:48 <monochrom> to explain IO you have to step outside Haskell
15:34:54 <jmcarthur> maerwald: Idris effects looks like extensible effects to me. Is that true?
15:35:03 <maerwald> sort of yes
15:35:08 <Habib> To be fair, other languages are the same, we just don't think of them that way.
15:35:11 <maerwald> but not as ugly as in haskell
15:35:13 <jmcarthur> maerwald: I see data type definitions and handlers.
15:35:23 <Habib> Like, how does Ruby's `puts` put a string to the screen?
15:35:35 <Habib> That's a black box too, just not as obviously one, so we don't complain about it.
15:35:42 <jmcarthur> maerwald: How is a data type and handler better than a newtype and functions?
15:35:44 <monochrom> one more reason Haskell makes you sad. it highlights a problem and not suggest a solution :)
15:36:11 <monochrom> (in addition to: it highlights how your day-job language makes you sad :) )
15:36:12 <Habib> Haha, sounds like the kind of person I hang out with.
15:36:18 <maerwald> jmcarthur: uhm, it's already written and part of the core?
15:36:27 <Habib> I mean, highlighting problems and not suggesting solutions.
15:36:35 <maerwald> we have extensible effects in haskell too, the problem just is: no one uses them
15:36:36 <jmcarthur> maerwald: But it's not already written if we're talking about controlling which effects can be used in some scope.
15:37:02 <maerwald> people are used to IO and IO is all over Prelude, so there is little chance these things change
15:37:02 <jmcarthur> maerwald: e.g. if I want to have some "safe" IO, I still need to write boilerplate either way (and I'd argue it's not boilerplate in either case but important code)
15:37:10 <texasmynsted> I am really loving Haskell.  What other language should I look at after Haskell.  I was thinking Idris, or Agda, but maybe there are others to consider.  (A pragmatic language for doing things not creating proofs.)
15:37:19 <maerwald> where in e.g. purescript you have: main :: forall e. Eff (fs :: FS, trace :: Trace, process :: Process | e) Unit
15:37:28 <maerwald> instead of main :: IO ()
15:37:48 <jmcarthur> maerwald: Ah, so the advantage isn't really the effect system but the fact that some effects have already been decomposed for you.
15:37:51 <Aruro> i dont see how putStrLn is IO, what possible can go wrong?
15:38:00 <Habib> Lisp if you're thinking of the opposite end of functional in terms of strictness. Very loose and Ruby-like. I've heard amazing/horrifying things about its macro system.
15:38:16 <maerwald> jmcarthur: yeah, as I said, oleg wrote a paper on extensible effects in haskell and there is a library, but no one is using it
15:38:20 <Habib> opposite end of type strictness in the functional realm.
15:38:20 <koz_> Does Data.Set.toList *necessarily* give an ordered list?
15:38:29 <texasmynsted> no, what very strict, perhaps dependent typing
15:38:33 <jmcarthur> Aruro: It's not about whether something can go wrong, but whether its purpose is to evaluate to some value or to perform some effect.
15:38:37 <texasmynsted> want, not what
15:39:28 <monochrom> texasmynsted, then I think Idris is currently the closest thing to your preference
15:39:30 <jmcarthur> maerwald: What I'm trying to say is that this isn't even an extensible effects property. We can do the same thing with monad transformers and such. It's just a matter of arguing for one or the other model of composing effects.
15:39:32 <Aruro> jmcarthur: it evaluates to the stuff it prints
15:39:42 <texasmynsted> ok, thank you.  :-)
15:39:54 <maerwald> jmcarthur: no, you can't do the same thing with monad transformers in all cases
15:39:55 <jmcarthur> Aruro: No it doesn't. It ultimately just evaluates to IO (). No String in that type expression.
15:40:09 <maerwald> jmcarthur: monad transformers impose static ordering of effects, where extensible effects don't
15:40:11 <monochrom> I don't know whether Elm is close. because I don't know Elm. but you may like to take a look.
15:40:12 <jmcarthur> maerwald: Sure you can. Actually extensible effects are the more limited implemented.
15:40:25 <Welkin> elm has recently changed a lot
15:40:26 <Aruro> jmcarthur: it stores bytes in the special block of memory, thus just repeating them. can be other interpretation too
15:40:26 <Habib> I don't think Elm has dependent typing, though I could be wrong.
15:40:33 <Welkin> it used to be "frp-like" using "signals"
15:40:33 <int-e> koz_: You should use toAscList if you need a sorted list... but Data.List.toList is actually implemented as toAscList.
15:40:37 <Welkin> now it is totally different
15:40:41 <jmcarthur> maerwald: Monad transformers in the style of mtl do not impose any ordering until you start applying "run functions", which would be analogous to handlers in extensible effects terminology.
15:40:56 <int-e> koz_: And of course there are some dirty tricks you can play so that toAscList doesn't live up to its promise
15:40:59 <jmcarthur> Aruro: But that's not haskell. That implementation detail.
15:41:10 <roboguy`> texasmynsted: if you're looking for learning about dependent types, Coq is an option. It doesn't fully satisfy the "pragmatic language" criteria, but you can generate Haskell, Lisp or ML code from Coq after you have proven it. Software Foundations is also a good book on the subject and it uses Coq
15:41:17 <texasmynsted> I think Purescript looks better than Elm
15:41:42 <jmcarthur> maerwald: e.g. there is no ordering implied by   (MonadState m s, MonadReader m r) => m ()
15:41:44 <maerwald> jmcarthur: I don't like monad transformers at all, but I haven't dug much into mtl
15:41:45 <texasmynsted> Software Foundations?  I will check it out
15:41:51 <koz_> int-e: There's always ways to subvert non-type-system-enforced properties. No-one is *forcing* you to write law-compliant Functors, for example...
15:41:57 <int-e> > toAscList . fromList $ [1,0/0,-1 :: Double] -- broken Ord instances...
15:41:58 <lambdabot>      Not in scope: ‘toAscList’
15:41:59 <lambdabot>      Perhaps you meant one of these:
15:41:59 <lambdabot>        ‘IM.toAscList’ (imported from Data.IntMap),
15:42:12 <Aruro> jmcarthur: im just saying there is no IO, there is just bad implementation in file system/ operational system. Everything in PC is deterministic.
15:42:20 <int-e> > S.toAscList . S.fromList $ [1,0/0,-1 :: Double] -- broken Ord instances...
15:42:22 <lambdabot>  [1.0,NaN,-1.0]
15:42:27 <ijp> Which theorem provers have good support for bird style program calculation?
15:42:28 <roboguy`> texasmynsted: definitely would recommend it. It's free: https://www.cis.upenn.edu/~bcpierce/sf/current/
15:42:45 <jmcarthur> maerwald: I also think the ability to compose transformers without regard for ordering is kind of foolish in general. Extensible effects just picks some particular ordering for you instead of giving you the choice. That's a reason transformers are actually more powerful.
15:42:47 <ijp> maerwald: you may never get over it. It's been years since I decided I didn't like monad transformers :)
15:43:07 <jmcarthur> I don't actually care for transformers as an overall design strategy for a program either.
15:43:12 <maerwald> ijp: which is why I think extensible effects is the more elegant solution and the Eff type of Idris
15:43:15 <monochrom> best of both worlds: write like (MonadState m s, MonadReader m r) => m (), then instantiate to Oleg-style instances :)
15:43:16 <int-e> koz_: Anyway I just didn't know how dirty you were willing to play.
15:43:16 <jmcarthur> I think they are fine when creating opaque abstractions.
15:43:34 <jmcarthur> And when creating abstraction like that, extensible effects are basically never what I am looking for.
15:43:45 <koz_> int-e: My types are pretty well-behaved, so it should be fine.
15:43:55 <roboguy`> ijp: hmm, what do you have in mind by "bird style"? I'm familiar with his style, but I'm not sure what you're looking for as far as it being translated into a proof assistant language
15:44:33 <Aruro> if u build whole OS ground up in Haskell and there is no internet, do you have IO?
15:44:34 <maerwald> jmcarthur: anyway, I think the initial point was that the IO type is sort of brute-force for "all there is in the outside world"
15:44:36 <ijp> roboguy`: essentially I mean "pointfree"
15:44:38 <jmcarthur> Aruro: The Haskelly way to describe that operation would be to construct a value that describes the side effect, not to actually perform it.
15:44:39 <maerwald> and is kind of ugly
15:45:00 <jmcarthur> maerwald: I agree with your criticism of IO. It's a "sin bin."
15:45:08 <maerwald> and should be more fine-grained, but not just in a random library, but in the _core_ of the language (including Prelude)
15:45:18 <ijp> I tried something like this with coq about a year or so ago, and I remember having to use functional extensionality got really clunky
15:45:24 <monochrom> no, almost no theorem prover have good support for Bird style program calculations. Since they require human-guided equational reasoning. And all theorem provers out there try their best to violate either human-guided or equational.
15:45:42 <ijp> Ideally it would also generate folds/unfolds for types
15:45:44 <jmcarthur> maerwald: I disagree that the standard library should arbitrarily partition its operations into separate types. The dividing lines one person chooses are likely to be very different from the ones I would choose.
15:45:56 <ijp> monochrom: I expected as much
15:46:10 <maerwald> jmcarthur: well, look at this one
15:46:10 <maerwald> :t readFile
15:46:12 <lambdabot> FilePath -> IO String
15:46:18 <maerwald> why do we need full IO there?
15:46:29 <ijp> I could hack something together myself, but no point if someone already did
15:46:32 <jmcarthur> maerwald: We don't. That's not the point I'm trying to make.
15:46:57 <maerwald> I think there are a lot of functions where a definite decision can be made
15:47:26 <maerwald> it's harder for a library where you don't really know what the user is going to do within your e.g. monadstack
15:47:44 <jmcarthur> maerwald: To be honest, it's not crazy for me to imagine that reading a file might have real observable side effects on the OS.
15:47:50 <Aruro> actually why main is forced to be IO ? what i want just to write  head [1..2] ?
15:47:52 <jmcarthur> maerwald: /proc, etc.
15:48:10 <maerwald> jmcarthur: if you read /proc, there are no side effects
15:48:16 <Aruro> jmcarthur: its horrible os design
15:48:26 <jmcarthur> maerwald: If I read any file, /proc is "modified"
15:48:35 <jmcarthur> maerwald: That's a real side effect.
15:48:41 <roboguy`> ijp: Coq automatically generates the inductive and recursion functions for all inductive data types (ADTs, essentially)
15:48:43 <glguy> Aruro: Because 'head [1..2]' isn't something you execute, it doesn't "do" anything
15:48:57 <Aruro> in fact real side effect (due to cosmis rays) can be in any so called pure computation
15:49:12 <jmcarthur> maerwald: Some files might even launch missile when I read them.
15:49:17 <maerwald> jmcarthur: but your function still does only need "read power"
15:49:20 <maerwald> that's the point
15:49:31 <jmcarthur> maerwald: My point is that is not even true.
15:49:38 <simpson> maerwald: By chance, have you heard of capability-based security?
15:50:09 <jmcarthur> maerwald: I could read some fd out of proc tied to a network connection which when closed launches missiles. All from an "innocent" readFile call.
15:50:18 <maerwald> jmcarthur: it is, you open the file in read-mode and by that interact with the kernel, ofc you have no control over the kernel process but it makes sense to denote this still
15:50:50 <jmcarthur> It may make sense to you in your problem domains, but it doesn't necessarily make any sense whatsoever to others.
15:50:57 <maerwald> I find it hard to agree that this is a justification for stuffing IO everywhere instead of more fine-grained types
15:50:59 <ijp> roboguy`: yes, I remembered, but I don't really think coq is a good fit
15:51:07 <jmcarthur> No, I'm not arguing for that.
15:51:27 <ijp> that said, I should just give it another try anyway
15:51:28 <jmcarthur> I just think if we are going to do better it needs to be a real improvement instead of just a mask to make it "look" better.
15:51:32 <maerwald> when your program is executed within the RTS, everything is a side-effect
15:51:58 <jmcarthur> My point is that a separate type for FS operations is a more of a lie than the distinction between IO and non-IO types.
15:52:03 <roboguy`> ijp: aw that's a shame. It's probably the most well supported (and my personal favorite so far). Something like Idris might be worth a look too
15:52:32 <ijp> yeah, it's a really good system overall
15:52:34 * hackagebot sr-extra 1.46.3.2 - A grab bag of modules.  https://hackage.haskell.org/package/sr-extra-1.46.3.2 (DavidFox)
15:52:43 <ijp> I'll give idris a fair peek too
15:52:47 <maerwald> jmcarthur: so, what do you suggest then?
15:52:48 <jmcarthur> In the absence of IO, syscalls are mostly a runtime implementation detail, and presumably the runtime should know how to interact with the OS safely.
15:53:26 <jmcarthur> maerwald: I have no suggestion. I just don't want to end up in a situation where we declare the problem "fixed." We have already made that mistake to some extent with IO.
15:53:49 <maerwald> what I'd already find nice if I have special syntax for the haskell RTS to say which syscalls are allowed and GHC should then be able to reject the program if I get blacklisted syscalls in my callstack
15:53:50 <jmcarthur> maerwald: Partitioning IO is a kludge to make us feel better, not to actually improve anything.
15:54:04 <Aruro> jmcarthur: u percieve there is some safe side of computation?
15:54:06 <jmcarthur> Sorry, I'm making obnoxiously strong points now.
15:54:13 <simpson> jmcarthur: How would you feel about a Capsicum-style setup, then?
15:54:24 <simpson> Aruro: There's safe computation. It's just not something that people often use.
15:54:25 <ijp> feeling better is also a good thing
15:54:42 <maerwald> jmcarthur: you are perverting the point :P it's really just about knowing what "kind" of syscalls are done, not what actually happens to the outside world by internal kernel processes
15:55:08 <jmcarthur> maerwald: Why don't we just list all the syscalls in the type then?
15:55:22 <maerwald> that would not be particularly high-level
15:55:26 <jmcarthur> Sorry for the slippery slope argument.
15:55:47 <jmcarthur> I don't think listing the "kind" of syscalls is much better with respect to abstraction, though.
15:55:53 <maerwald> it would be fine to allow that, but people will still want "fuzzy" groups of syscalls
15:55:58 <maerwald> without thinking about it too much
15:56:02 <maerwald> which is *fine*
15:56:17 <jmcarthur> simpson: I don't have strong feelings. Capability security is cool and intuitive, but I haven't seen it work very well in practice. I think people are too lazy.
15:56:54 <jmcarthur> maerwald: I also think that is fine. I just think that is a very domain specific idea and doesn't make much sense in a standard library.
15:56:56 <simpson> jmcarthur: What if the *language* enforced the capability invariants?
15:57:10 <simpson> jmcarthur: Y'know about E, right? I'm building Monte, an E revival.
15:57:27 <maerwald> jmcarthur: dealing with the filesystem is domain specific and part of the standard library, so it should be in there
15:57:27 <ijp> jmcarthur: I think that's fair
15:57:39 <Aruro> simpson: there is no possible safe computations, because of the hardware/physics
15:57:45 <jmcarthur> simpson: People are not going to think very carefully about what capabilities they are providing to various bits of code, and I can't think of a good way to make capabilities appear at the type level where I would really want it. They are a largely value-oriented form of security.
15:57:52 <roboguy`> ijp: HERMIT is another option as well, for equational reasoning. It works on existing Haskell programs
15:58:33 <ijp> neat. shame about the acronym engineering there
15:58:45 <simpson> jmcarthur: Interesting; I have not thought at all about the role of types. Monte forces people to care about available capabilities, by making all I/O unsafe, but we have a very humble type system.
15:58:50 <Aruro> simpson: cosmic rays/radiation  can alter any computation
15:59:25 <maerwald> we need a type for cosmic radiation! haha
15:59:32 <Aruro> yeah :D
15:59:41 <simpson> Aruro: Oh. Well, whatever, yeah. I thought that you were talking about the problem of implementing "safe" versions of eval(), where "safe" is on a spectrum of operational power vs. high-level correctness.
15:59:44 <roboguy`> Aruro: That wouldn't be a very pragmatic definition of "pure computation," since it then couldn't exist...
15:59:46 <Aruro> put whole solar system in IO :D
15:59:51 <monochrom> that is very nihilist. I don't think there is anything worth arguing, anything worth implementing, if you're so nihilist.
16:00:18 <simpson> Aruro: This is an interesting problem because it turns out that there's an entire world between assembly and Agda, in terms of "safe".
16:00:30 <Aruro> roboguy`: u will have errors, and pure functions will not be pure, so u have practical influence
16:01:26 <simpson> Aruro: Look at it this way. If you have the C standard, and a pencil and paper, and some C program, you can reproduce segfaults on paper.
16:01:28 <roboguy`> Aruro: not sure what you mean... It seems like "pure" would just become another word for "impossible"
16:01:29 <Aruro> simpson: i just saying that arguments about IO can be extended to other physical effects, practicly making non of the possible computations truly pure.
16:01:31 <simpson> That's the kind of "safe" that I'm talking about.
16:01:52 <Aruro> roboguy`: pure where 1+1 always returns 2
16:01:54 <roboguy`> Aruro: but does that actually matter in practical terms? I would argue that it does not
16:01:55 <jmcarthur> maerwald: Thought of a way to rephrase my point. In some domains the set of safe filesystem-related syscalls is smaller than in others. That is why I am skeptical of a standardized type for all filesystem related IO.
16:02:28 <maerwald> jmcarthur: if you don't you pollute thousands of libraries with general IO and it's going to get hard to make use of more fine-grained types
16:02:36 <monochrom> how do you even know that "pure" should mean "1+1 returns 2"? FWIW cosmic rays mess up your brain so you're being insane.
16:02:36 <Aruro> roboguy`: depents on application, perhaps somewhere it does matter greatly, very big very long computations, supercomputers
16:02:53 <maerwald> monochrom: lol
16:03:03 <monochrom> hell, even a bit of lead in water can do that
16:03:34 <Aruro> monochrom: so? u think u contradicted me? :) vice versa
16:03:42 <maerwald> jmcarthur: whereas jumping from more fine-grained types to general IO is a simple lifting
16:03:51 <maerwald> so it should be that way around
16:03:55 <roboguy`> Aruro: well, if you ever find that let me know! In the meantime, I'm probably going to call things "pure" even though there is a minuscule chance that the computer could be affected by cosmic rays...
16:04:18 <jmcarthur> maerwald: newtypes are pretty darn simple, IMO
16:04:23 <samg_> I'm writing a monad that 
16:04:27 <roboguy`> I mean, not only would a bit need to be flipped by a cosmic ray, it would need to be: a bit that affects the program in question *and* it would have to not be corrected by error correction systems
16:04:31 <Aruro> roboguy`: same with large magnetic fields and other stuff, computer is not isolated peace of god.
16:04:40 <maerwald> jmcarthur: there boilerplate goes again and incompatible newtypes in hundreds of libraries *sigh*
16:04:43 <maerwald> that's not going to help
16:04:55 <samg_> (err), I'm writing a monad that's almost a state monad except the state is a monoid and map/bind use mappend to accumulate the state value -- is this a well-known monad?
16:05:14 <simpson> samg_: Isn't that Writer?
16:05:23 <maerwald> if you want to fix IO, you have to fix it in base. Period.
16:05:27 <dolio> Why haven't you just fixed this, if it's such a big deal for you? You could have done it in the time you've spent talking about it in here.
16:05:33 <samg_> simpson: aha -- I'll look :)
16:06:07 <Aruro> roboguy`: all im saying idea of what is IO or effectful computation can be greatly extended if desired.
16:06:35 <dolio> You don't need to change base. You just need to write a library for the abstraction you want to program to, and use it.
16:07:42 <roboguy`> Aruro: I guess so. There is also something that makes every "pure computation" impure by that definition: all computations raise the temperature slightly, which is an effect on the outside world
16:08:10 <Aruro> roboguy`: yeah, and can lead to processor overheating and braking of whole computation.
16:08:26 <ijp> dolio: the only problem there is if you want to pull in other libraries that might also deal with IO (for whatever reason)
16:08:32 <roboguy`> Not even just that, the raising of the temperature itself is an "effect"
16:09:00 <Welkin> running the computer has an effect
16:09:08 <roboguy`> It is something that probably will not be the same each time, making it "impure" (by that definition)
16:09:08 <Welkin> even just looking at your computer has an effect
16:09:12 <dolio> Abstract that, too, then.
16:09:26 <Welkin> even empty space is not empty
16:09:34 <Welkin> there are random effects
16:09:34 <Aruro> :)
16:09:37 <roboguy`> That's what makes me question that the usefulness of that definition of purity, ha
16:11:07 <samg_> simpson: I'm new to haskell. Where can I find the Monad instance for Writer?
16:11:52 <Aruro> samg_: Control.Monad.Writer
16:11:55 <samg_> is it implemented in terms of a monad transformer?
16:12:13 <Aruro> samg_: yes
16:12:24 <samg_> ah, ok thanks :)
16:12:25 <Aruro> WriterT
16:12:58 <roboguy`> samg_: https://hackage.haskell.org/package/transformers-0.5.2.0/docs/src/Control.Monad.Trans.Writer.Lazy.html#line-189
16:13:16 <samg_> oh perfect, thank you!
16:13:35 <Cale> It's a little bit unfortunate that we don't have a convenient version which isn't implemented in terms of a monad transformer to show to beginners.
16:14:00 <samg_> yeah, I haven't totally grokked monad transformers, but at first blush this looks like what I'm implementing
16:14:03 <Cale> Though I guess you could step back in time and look at an old version of mtl
16:14:05 <roboguy`> samg_: you can find the locations of instances by using the :info command (or :i) in ghci. For example, :i Writer tells you it's implemented in terms of WriterT and :i WriterT tells you where the Monad instance is
16:14:09 <jmcarthur> Cale: If we would just add the Monad ((,) a) instance, we'd have it.
16:14:41 <dolio> GHC 8 has it, I think.
16:14:42 <samg_> kind of cool that I got here from a series of abstractions from a clearly over-specific monad
16:15:09 <jmcarthur> dolio: It does!
16:15:27 <dolio> Did 7.10 have it? That already had Monoid in Prelude, I think.
16:15:31 <jmcarthur> Cale: Okay, so as of GHC 8, we have a plain Writer monad, just without that name.
16:15:43 <dolio> Hmm, apparently not.
16:16:34 <roboguy`> ah, right
16:16:49 <Welkin> we do?
16:16:51 <Welkin> what is it?
16:17:03 <jmcarthur> Welkin: Is that addressed to me?
16:17:06 <roboguy`> samg_: here's the instance in GHC 8 that is just implemented with (,). It might be easier to read than the transformers version: https://hackage.haskell.org/package/base-4.9.0.0/docs/src/GHC.Base.html#line-324
16:17:08 <jmcarthur> Welkin: It's ((,) a)
16:17:36 <jmcarthur> Welkin: What roboguy` just linked
16:18:35 <samg_> oh that's slick
16:18:48 <samg_> where does return come from?
16:19:06 <roboguy`> it's defaulted to pure in GHC 8
16:19:07 <jmcarthur> samg_: Guessing it has a default definition based on Applicative now.
16:19:16 <Welkin> samg_: it was named that to mirrior "imperative" programming using do-notation
16:19:24 <roboguy`> (maybe since 7.10, I can't remember)
16:19:31 <Welkin> I think of it as "return to the monad"
16:19:38 <jmcarthur> Welkin: I think samg_ was asking why it wasn't included in that Monad instance, not why it's named "return".
16:19:46 <samg_> yeah, but thanks :)
16:20:01 <EvanR> return to innocence
16:20:03 <samg_> cool that my 50-line abstraction is a single-line monad instance now
16:20:07 <Welkin> like calling your pokemon back to its pokeball
16:20:12 <jmcarthur> return to bad habits
16:20:37 <EvanR> monads are like pokeballs?
16:20:41 <Welkin> yes
16:20:50 <jmcarthur> Do pokeballs join?
16:21:04 <EvanR> i think if you try to put a pokeball in a pokeball it causes a rift in spacetime and free chalupas at taco bell
16:21:05 <Welkin> they can fit arbitrary elements of arbitrary size
16:21:15 <jmcarthur> Not what I asked. :)
16:22:34 <EvanR> basically a kind error
16:24:31 <EvanR> the monad tutorial fallacy usually includes several ideas at once, i now realize that the wrapping/burrito part derives from the fact that in haskell generally many things you do are syntactic manipulation, AST-like
16:24:44 <EvanR> which necessarily involves nesting data 
16:25:07 <EvanR> which is a subject of itself
16:26:00 <EvanR> and why jquery is mistaken for a monad
16:26:44 <simpson> EvanR: Well, *that* happened because some JS folk were jealous of some Python folk; in the Python Twisted library, the Deferred type is a proper monad.
16:26:47 <Aruro> monad was a brilliant marketing move, why haskell is still alife.
16:26:51 <simpson> Corresponding to some kind of Cont+Either.
16:27:18 <EvanR> interesting
16:27:41 <Welkin> Aruro: you mean State Threads :P
16:27:56 <Welkin> so it can do IO
16:28:19 <simpson> Aruro: It wasn't a marketing move. It was a response to perceived problems with lazy I/O.
16:28:49 <Aruro> simpson: calling it a Monad was, marketing can also be unplanned
16:29:21 <dolio> It didn't have anything to do with lazy I/O, either, really.
16:29:23 <ijp> does MonadTutorial form a monad?
16:29:56 <Aruro> and now folks from all over the kingdom come and seek wisdom in the house of monad.
16:30:08 <simpson> Too bad they can never leave~
16:30:09 <Rotaerk> monads are like burritos, and hamburgers, and now I'm hungry
16:30:11 <EvanR> or actively deride monads without knowing wtf they are
16:30:24 <simpson> But seriously, Haskell's still got the "Avoid success at all costs" motto, right?
16:30:31 <EvanR> i hope so
16:30:37 <ijp> too late for that
16:31:46 <geekosaur> it does but it's parsed as: avoid "success at all costs"
16:32:15 <dolio> I don't parse it that way.
16:32:35 * hackagebot postgresql-binary 0.9.0.1 - Encoders and decoders for the PostgreSQL's binary format  https://hackage.haskell.org/package/postgresql-binary-0.9.0.1 (NikitaVolkov)
16:32:36 <simpson> A void success; at all, costs.
16:32:49 <Welkin> help your uncle jack off the horse
16:36:27 <ijp> Welkin: my favourite example is "Missing Girl Remains Found"
16:36:59 <Cale> It's not really parsed like that
16:37:09 <Cale> Well, you can
16:37:16 <Cale> But the original intent was the other way
16:38:04 <Cale> Success, especially early success, is a great way to end up with a language with lots of problems you find out about but it's too late to fix without having everyone complain.
16:38:31 <Welkin> Cale: js?
16:38:42 <Cale> Yeah, pretty much :)
16:38:44 <zq> you mean like lazy io
16:38:49 <ijp> or the web
16:38:54 <ijp> really there is no shortage of examples
16:40:52 <geekosaur> Cale: problem is Haskell failed even there: see AMP, MonadFail
16:41:09 <Cale> Well, sure, but it could have failed a bunch more than that :)
16:41:56 <geekosaur> (and, come to think of it, one could argue that a lot of the things that went into H'98 were exactly the kind of failure people were supposed to avoid...)
16:42:59 <Aruro> geekosaur: like?
16:43:20 <benzrf> geekosaur: ah, but if haskell had been more successful, we mightve had a py3 situation :)
16:43:29 <geekosaur> I just named a couple of them, Aruro. that was the point
16:44:05 <geekosaur> another example was monad comprehensions being dumbed down to list comprehensions... and again, ghc has reverted that (via a LANGUAGE pragma)
16:44:49 <Welkin> oh really?
16:44:56 <Welkin> what are all the goodies in ghc8?
16:45:00 <Welkin> I haven't kept up
16:45:11 <Aruro> Welkin: its already in 7.8.4
16:45:32 <Cale> Of course, GHC is really the language at this point.
16:45:37 <Aruro> monad comprehensions, maybe earlier
16:45:46 <geekosaur> well, no, I guess AMP doesn't count as an H98 flaw. hard to blame them for Applicative not even existing at the time, just being vaguely reached toward (Arrows, and some early work on "idioms" that wouldn't really bear fruit until the next decade)
16:46:01 <Cale> There hasn't been a really meaningful Haskell Report since H98, and things moved on past that quite a bit.
16:46:16 <dolio> Functor was wrong, though. But that's been true since introduced.
16:47:48 <roboguy`> Functor was wrong?
16:47:55 <dolio> With respect to Monad.
16:47:58 <Aruro> im still thinkging about it :D
16:47:58 <geekosaur> Functor not being a "superclass" of Monad
16:48:03 <roboguy`> ahh, right
16:48:32 <Profpatsch> Is there a usable TCP and UDP socket library.
16:48:42 <roboguy`> Wasn't that also because Monad existed first (although, both existed by H98)?
16:48:44 <Profpatsch> Network.Socket gives me herpes.
16:48:58 <geekosaur> how usable do you consider conduit or pipes?
16:49:13 <Profpatsch> geekosaur: Never tried them.
16:49:20 <Profpatsch> Do I get acceptable errors?
16:49:32 <Profpatsch> *** Exception: user error (bind: can't peform bind on socket in status Bound)
16:49:43 <Profpatsch> Is not what I consider acceptable „user errors“
16:49:45 <geekosaur> (I won't argue the point re the network library; Network.Socket is pretty much raw FFI bindings, and Network doesn't do UDP and is generally underwhelming for real use)
16:50:06 <Profpatsch> I want to learn pipes tho. j)
16:50:07 <Profpatsch> ;)
16:50:28 <roboguy`> Profpatsch: that particular error doesn't look too bad to me... You can't bind a socket twice
16:50:45 <Profpatsch> Just give me something that at least doesn’t blow up in multiple hundred ways simultaneously. :(
16:51:12 <geekosaur> roboguy`, Id argue that should not be "user error" but a reasonable subclass of IOException
16:51:48 <roboguy`> hmm, probably yeah
16:51:55 <Profpatsch> Also, I have no idea how to sensibly define HostAddress = Word32
16:52:18 <Profpatsch> I’m not even sure what that is (then again I have to re-learn Berkley Sockets every time I use them).
16:52:41 <Profpatsch> Probably an IP Address in Network order.
16:52:41 <EvanR> you dont want to manually put in an IPv4 address
16:52:48 <EvanR> use name resolution
16:52:56 <Profpatsch> Yeah, but why does bind need an IPv4 address?
16:53:02 <EvanR> "192.111.111.111" or whatever will resolve to that address
16:53:03 <Profpatsch> Or what happens if I specify 0?
16:53:17 <Profpatsch> Normally I tell programs to bind to host 0.0.0.0
16:53:25 <Profpatsch> or to 127.0.0.1
16:53:29 <geekosaur> 0 is what you would specify. bind to IP address lets you listen on a single network interface
16:53:30 <EvanR> that accepts connections from anywhere, or localhost
16:53:48 <Profpatsch> And how do I get 127.0.0.1
16:54:04 <Profpatsch> There’s no constant for that (at least not in Network.Socket)
16:54:06 <EvanR> resolve "127.0.0.1" ;)
16:54:24 <EvanR> or "localhost"
16:54:35 <geekosaur> isn't there an iNADDR_ANY and such?
16:54:51 <Profpatsch> you mean getAddrInfo?
16:55:37 <s4ke> hi. i need some help. i am getting a weird type error 
16:55:38 <s4ke> https://gist.github.com/s4ke/eb04bcda073f3b09fb718c8930c28b27
16:56:22 <Profpatsch> geekosaur: What’s good alternatives?
16:56:38 <glguy> You're looking for an address to bind to?
16:56:56 <zq> if i have a type variable with the same typeclass constraint appearing in every ctor of a gadt, is it possible to abbreviate this?
16:56:56 <geekosaur> Profpatsch, as I said, Network.Socket is raw. HostAddress is an IPV4 address; HostAddress6 is the IPv6 version
16:57:12 <EvanR> you can use Data.Bits to build the Word32
16:57:18 <geekosaur> iNADDR_ANY is indeed exported. there's no predefined binding for localhost though
16:57:19 <glguy> If you're trying to figure out an address to bind to you should be asking getAddrInfo
16:57:47 <EvanR> or use Network which simply takes the string and does it all for you
16:57:49 <geekosaur> and as to alternatives, all the real work has gone into network access on top of conduits or pipes, which is why I pointed you to those earlier
16:57:50 <roboguy`> s4ke: hmm, what's the type of spawn?
16:58:08 <Profpatsch> geekosaur: Hm, okay.
16:58:09 <s4ke> Parrow arr a b -> arr [a] [b]
16:59:00 <Eduard_Munteanu> zq, with a constraint synonym
16:59:07 <s4ke> roboguy` i updated the gist
16:59:24 <Eduard_Munteanu> zq, otherwise, not really
17:01:00 <roboguy`> s4ke: ahh, it's because you are using app like a function, so arr is getting specialized to (->)
17:01:04 <roboguy`> :t app
17:01:05 <lambdabot> ArrowApply a => a (a b c, b) c
17:01:14 <roboguy`> those a's have to be the same
17:01:36 <s4ke> i am using app like a fn?
17:01:42 <s4ke> how can i not do that :D?
17:02:20 <zq> Eduard_Munteanu: is there something like kind classes, then
17:02:31 <s4ke> roboguy` thx for the help btw
17:03:07 <Eduard_Munteanu> zq, why?
17:04:02 <zq> Eduard_Munteanu: because it would be an alternate route around the problem i just posed?
17:04:12 <roboguy`> s4kashya: no problem! I'm not sure I'll be able to help much more than that. I don't have much experience with ArrowApply (or Arrows in general)
17:04:17 <roboguy`> ^ s4ke
17:04:36 <Eduard_Munteanu> zq, well, no, not really. I'm not sure what that would look like.
17:05:00 <roboguy`> s4ke: might help to replace app with _ and see what type GHC would want
17:08:34 <s4ke> (arr [a] [b], [a]) -> [b]
17:17:37 * hackagebot managed 1.0.5 - A monad for managed values  https://hackage.haskell.org/package/managed-1.0.5 (GabrielGonzalez)
17:25:16 <roboguy`> s4ke: I don't think you can convert an Arrow to a function, while retaining generality, like that
17:25:21 <roboguy`> I did find a way to implement that though
17:25:40 <s4ke> if i have a ArrowRun class that works
17:25:47 <s4ke> but i dont want to unwrap monads from kleisli
17:25:50 <s4ke> if thats possible
17:26:51 <roboguy`> You were close. You probably have to just use Arrow combinators (spoilers, if you want to work out the last part for yourself): parMap = (arr $ \(fn, as) -> let fns = replicate (length as) fn in (spawn fns, as)) >>> app
17:27:13 <roboguy`> actually, you don't really need that let
17:30:18 <roboguy`> s4ke: an ArrowRun might end up restricting things, I feel
17:30:27 <s4ke> yeah. thanks
17:30:41 <roboguy`> sure!
17:31:02 <jmcarthur> simpson: Sorry for digging this up, as I realize it was a while ago. The motto is to be parsed as "Avoid (success at all costs)." not "(Avoid success) (at all costs)."
17:31:29 <simpson> jmcarthur: Sure.
17:31:36 <roboguy`> I imagine the wording is intentionally ambiguous, ha
17:32:27 <s4ke> roboguy. thanks. that helped me a lot
17:32:49 <shachaf> jmcarthur: 
17:32:52 <shachaf> Are you sure about that?
17:32:57 <shachaf> Oops.
17:33:48 <shachaf> The explanation I heard was that when a language is successful enough, you can't change it, and therefore it's not useful as a research language anymore.
17:33:51 <jmcarthur> shachaf: I don't mean to imply that the original source of the quote intended it that way, but that this is a reasonable reinterpretation of the quote nowadays.
17:34:13 <jmcarthur> shachaf: A voluntary reinterpretation, I mean.
17:34:18 <roboguy`> s4ke: No problem!
17:34:38 * geekosaur recalls that discussion, which is why he mentioned it earlier
17:34:46 <geekosaur> maybe I should dig it out of logs
17:35:03 <shachaf> Well, imagine what a high price the motto "avoid success at all" costs.
17:35:34 <geekosaur> extremely high considering that one's long since lost :p
17:38:54 <jmcarthur> Sorry, I should be more clear when I say this that I am not necessarily representing the original statement accurately.
17:39:49 <jmcarthur> shachaf: I agree with your understanding of the origin of that quote.
17:40:22 <jmcarthur> I just prefer (avoid) (success at all costs)
17:41:50 <dolio> shachaf: But is it more costly than the alternative?
17:54:19 <s4ke> roboguy` : i made it even shorter (and changed some bits, as i made my spawn definition to an arrow as well): parMap = (arr $ \(fn, as) -> (replicate (length as) fn, as)) >>> (first parEval) >>> app
18:03:40 <EvanR> @djinn (a -> b) -> (a,a) -> (b,b)
18:03:41 <lambdabot> f a (b, _) = (a b, a b)
18:03:55 <EvanR> @hoogle (a -> b) -> (a,a) -> (b,b)
18:03:58 <lambdabot> Data.Graph.Inductive.Query.Monad (><) :: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
18:03:59 <lambdabot> Data.Graph.Inductive.Query.Monad mapSnd :: (a -> b) -> (c, a) -> (c, b)
18:03:59 <lambdabot> Data.Graph.Inductive.Query.Monad mapFst :: (a -> b) -> (a, c) -> (b, c)
18:04:57 <hpc> @. djinn type \f (b, c) -> (f b, f c)
18:04:58 <lambdabot> f a (b, _) = (a b, a b)
18:05:02 <hpc> oh right
18:05:35 <geekosaur> :exf (a -> b) -> (a,a) -> (b,b)
18:05:36 <exferenceBot> \ f1 b -> let ((,) d e) = b in (f1 e, f1 d)
18:05:36 <exferenceBot> \ f1 b -> let ((,) d e) = b in (f1 d, f1 e)
18:06:05 <hpc> bwah?
18:06:05 <EvanR> cool
18:06:16 <shanemikel> any recommendations on how to setup a stack project where I'm using tools like ghc-vis and hood/hat ?
18:06:24 <geekosaur> interesting way to write it...
18:06:42 <EvanR> so there isnt some slick operator for this?
18:07:06 <EvanR> bimap (f,f)...
18:07:18 <hpc> :t (&&&)
18:07:20 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
18:07:28 * EvanR looks closely at this type
18:07:29 <hpc> :t (***)
18:07:31 <lambdabot> Arrow a => a b c -> a b' c' -> a (b, b') (c, c')
18:07:37 <hpc> :t join (***)
18:07:38 <lambdabot> Arrow a => a b c -> a (b, b) (c, c)
18:07:44 <hpc> aha!
18:07:48 <hpc> let a = (->)
18:07:57 <EvanR> zoinks
18:08:05 <hpc> jinkeys
18:08:48 <shanemikel> :t join
18:08:50 <lambdabot> Monad m => m (m a) -> m a
18:09:23 <hpc> i expect normally it would look better to just expand it and write (f a, f b)
18:09:30 <hpc> :t let join f x = f x x
18:09:31 <lambdabot> <no location info>: not an expression: ‘let join f x = f x x’
18:09:35 <hpc> :t let join f x = f x x in join
18:09:36 <lambdabot> (t1 -> t1 -> t) -> t1 -> t
18:09:53 <hpc> shanemikel: using m = ((->) t1)
18:10:00 <EvanR> the thing is that f is not one letter
18:10:23 <EvanR> and me wrists only have so much mileage left
18:10:30 <hpc> heh fair enough
18:13:04 <EvanR> is there a way to specify stuff like m = ((->) t1) directly yet, to deal with ambiguous type errors
18:13:30 <hpc> in ghc8, using @
18:13:36 <hpc> i wonder if lambdabot is updated yet
18:13:36 <EvanR> "i cant tell what a0 is", "a0 is ((->) Bool) you idiot"
18:13:39 <hpc> :t map@Int@String
18:13:41 <lambdabot> parse error on input ‘@’
18:14:00 <EvanR> oh nice
18:14:03 <shanemikel> why doesn't GHC just compile and run this? https://highlyscalable.files.wordpress.com/2013/08/storm-kafka-cassandra-system.png?w=805
18:14:09 <hpc> it goes in forall order, so map@Int@String :: (Int -> String) -> [Int] -> [String]
18:14:23 <EvanR> that is awesome
18:14:44 <EvanR> which extension is that?
18:14:50 <hpc> not sure
18:15:07 <EvanR> and can you put type variables
18:15:10 <hpc> i still need to get around to actually trying it
18:15:18 <hpc> you literally know as much as i do :P
18:15:27 <EvanR> i dont have ghc 8 ...
18:16:20 <hpc> it might be on by default, since it doesn't really conflict with anything
18:16:41 <hpc> but yeah, not having ghc8 makes it kinda useless ;)
18:17:35 <shanemikel> so, ghc-vis uses a flag --disable-library-profiling.. what's that flag to? cabal or ghc?
18:17:47 <shanemikel> and where do I put that in  my projects config?
18:18:40 <geekosaur> that's a cabal flag
18:19:13 <shanemikel> does it make sense to put that in a .cabal file in my project?
18:20:09 <geekosaur> not like that, at least. for a cabal sandbox it goes in the sandbox config. dunno offhand where you'd put it in stack
18:21:29 <shanemikel> just to be clear, is that a cabal flag that effects the way cabal works, or a flag to the ghc-vis build specifically?
18:24:20 <geekosaur> the former
18:25:06 <geekosaur> tells cabal not to build both normal and profiling versions of any libraries
18:31:26 <shanemikel> ok, thanks.. it looks like stack has the same flag for the build command, but no mention about how that relates to stack.yaml config
18:32:12 <geekosaur> I would normally not expect it to be in the config
18:32:40 * hackagebot turtle 1.2.8 - Shell programming, Haskell-style  https://hackage.haskell.org/package/turtle-1.2.8 (GabrielGonzalez)
18:32:41 <geekosaur> at least, not per-project config
18:42:58 <Profpatsch> Ugh, so when you create a socket from getAddrInfo, it is not possible to read its port & address and talk to it without being partial.
18:43:27 <Profpatsch> s <- getAddrInfo Nothing (Just "localhost") Nothing
18:43:33 <Profpatsch> p <- getPort s
18:43:38 <Profpatsch> *socketPort
18:44:02 <Profpatsch> sendAllTo $ SocketAddrInet ?!? p
18:46:05 <Profpatsch> Hm, a little bit different, but the gist is that one has to do a partail match on the SockAddr to get the HostAddress back out.
18:46:08 <Profpatsch> grml
18:46:31 <glguy> Profpatsch: What're you trying to do?
18:46:40 <glguy> You shouldn't be touching SocketAddrInets
18:47:17 <glguy> at least in common usage of the API
18:48:57 <Profpatsch> glguy: I’m creating a test server for my client.
18:49:19 <Profpatsch> And of course I want to use a random free port.
18:49:35 <Profpatsch> And resolve localhost to the right Word32.
18:49:48 <Profpatsch> But the API seems to block any sane use.
18:49:58 <EvanR> you can easily do this with Network
18:50:06 <EvanR> including a random free port
18:50:15 <Profpatsch> EvanR: Which is deprecated. And only does TCP.
18:50:18 <EvanR> what?
18:50:35 <Profpatsch> New users are encouraged to use Network.Socket instead.
18:50:40 <Profpatsch> https://hackage.haskell.org/package/network-2.6.2.1/docs/Network.html
18:50:55 <EvanR> network works fine
18:53:10 <glguy> https://paste.fedoraproject.org/372008/
18:53:13 <glguy> something like that?
18:55:13 <glguy> But EvanR's right, using Network is fine
18:57:52 <Profpatsch> glguy: For UDP?
18:58:33 <glguy> that's TCP
18:58:40 <glguy> udp is a little different and uses datagram not stream
18:59:05 <Profpatsch> Yeah, but Network doesn’t do UDP.
18:59:06 <roboguy`> Profpatsch: what are you using UDP for?
18:59:35 <Profpatsch> roboguy`: A server that uses UDP. :)
18:59:41 <roboguy`> ahh, ha
19:00:12 <Profpatsch> I want to implement a UDP client for the UDP Pixelflut running above my head.
19:00:26 <Profpatsch> Normally it’s TCP, but this one is configured for UDP.
19:01:59 <Profpatsch> I probably need forkIO anyway, or the whole thing will deadlock.
19:02:15 <Profpatsch> That is the test.
19:03:57 <glguy_> You won't use listen but you also won't touch the sock addr. recvFrom will give you them
19:09:48 <category_> Does anyone know what datatype I can use in the accelerate library to hold an arbitrary collection of arrays and / or tuples?  I'm using the CUDA backend and need to keep the datastructures on the gpu but since I can't nest arrays I'm not sure how to do this
19:14:12 <Profpatsch> Phew, I thought recv and send would block but apparently they don’t.
19:19:58 <roboguy`> category_: it looks like accelerate uses a shape system for multidimensional arrays. You could probably use that instead of trying to nest arrays
19:21:49 <roboguy`> (which makes sense, because I don't think you generally do nested arrays on GPUs. You transform the indices into a single index)
19:34:50 <mgsloan> shanemikel: I haven't tried those tools recently (with stack), but you should get good mileage out of running the tools within "stack exec" (perhaps "stack exec bash")
19:35:31 <mgsloan> If they're on hackage, you can also install good versions of the tools by doing "stack install pkg" (or specify a version, if it's not in the stackage snapshot)
19:42:10 <roboguy`> stack exec cabal exec stack exec cabal exec
19:42:12 <roboguy`> (putting the... stack in stack)
19:52:17 <mgsloan> cabal would probably fail complaining about GHC_PACKAGE_PATH
19:52:30 <mgsloan> It really should parse it and use it as --package-db arguments, but it doesn't
20:02:27 <haskell760> In https://wiki.haskell.org/Arrow_tutorial part 6 (Teaser), why does ((arr id) <+> f) >>> ((arr id) <+> g) expand to    ((id . id) x) ++ ((id . f) x) ++ ((id . g) x) ++ ((g . f) x) =    x ++ (f x) ++ (g x) ++ ((g . f) x) ?
20:07:19 <roboguy`> haskell760: have you tried substituting the definitions of arr, id, (<+>), (>>>) in?
20:07:44 * hackagebot optparse-helper 0.2.1.1 - Helper functions for optparse-applicative.  https://hackage.haskell.org/package/optparse-helper-0.2.1.1 (pharpend)
20:08:43 <roboguy`> haskell760: Oh, I guess it doesn't give those definitions... I would suggest either looking them up or trying to derive them yourself
20:09:58 <roboguy`> (they should be in the source for Control.Arrow from the standard library)
20:25:41 <haskell760> roboguy`: withId $ prepend "<" :: ArrowPlus a => a [Char] [Char] but runKleisli takes Kleisli m a b; I don't see how the withId part is a Kleisli
20:26:04 <haskell760> i.e. how can you run runKleisli on xform?
20:32:45 * hackagebot MissingH 1.4.0.0 - Large utility library  https://hackage.haskell.org/package/MissingH-1.4.0.0 (JohnGoerzen)
21:04:27 <simpson> @pl \xs x -> xs ++ [x] -- tell me a joke, @pl
21:04:27 <lambdabot> (. return) . (++)
21:04:42 <koz_> simpson: Are you trying to amuse yourself using @pl?
21:04:58 <koz_> @pl \a b c d e f g -> (g a c b e f d c)
21:05:00 <lambdabot> flip flip id . (liftM2 (flip . ((flip . ((flip . (flip .)) .)) .) . flip . ((flip . (flip .) . flip) .) . flip) .) . flip . (flip .) . flip . flip id
21:05:33 <simpson> koz_: I'm implementing a stream library in a strict language and I only have foldl. So yes, jokes.
21:05:47 <koz_> simpson: :(
21:22:32 <EvanR> in the Data.QuadTree api / code i do not understand why there is an Eq constraint
21:22:41 <EvanR> getLocation :: Eq a => Location -> QuadTree a -> a
21:22:59 <EvanR> its defined in terms of a Lens', atLocation :: forall a. Eq a => Location -> Lens' (QuadTree a) a
21:23:16 <EvanR> im not seeing where the Eq on a is used
21:24:47 <EvanR> Location = (Int,Int), it seems like its just recursively traversing into the tree by bisecting the coordinates or stopping because it hits the bottom
21:27:47 * hackagebot phoityne-vscode 0.0.4.0 - ghci debug viewer on Visual Studio Code  https://hackage.haskell.org/package/phoityne-vscode-0.0.4.0 (phoityne_hs)
21:34:19 <shanemikel> the university system in europe is starting to look a lot better than the U.S. to me.. depressing
21:34:34 <shanemikel> u.k.
21:38:29 <thimoteus> saw some uncured bacon something at the store, thought it said uncurried
21:39:46 <EvanR> gross
21:41:03 <shanemikel> it's not really possible to uncurry things in the real world
21:41:08 <shanemikel> that shit just don't come out
21:42:31 <dfeuer> HMPH
21:42:48 * hackagebot hw-prim 0.0.3.0 - Primitive functions and data types  https://hackage.haskell.org/package/hw-prim-0.0.3.0 (haskellworks)
21:42:51 <dfeuer> Lots of work just now to get absolutely nowhere. I wonder if it's good for anything else....
21:45:14 <dfeuer> I mean... not absolutely nowhere, but 630ns vs 640ns is absolutely not worth using unsafeCoerce and several extra GHC extensions.
22:22:43 <jle`> can we change the current typeclass instance notation in haddock to be a little less confusing with how it shows kind parameters?  maybe instead of (Tagged k s a) or (Tagged * s a), with k/* as the kind parameter, how about `Tagged @k s a` or `Tagged @* s a` ?
22:24:06 <jle`> i'm not sure where the haddock convention comes from, actually
22:24:33 <Eduard_Munteanu> Something like 'Tagged ?k s a' alludes to implicits.
22:25:22 <jle`> i was confused for a while as to why there was a magic new parameter, but even now that i know what it means, it's still a bit confusing to read
22:25:36 <jle`> a little weird to scan/skim
22:25:57 <Cale> Yeah, it should probably just hide those most of the time, it just... doesn't.
22:28:32 <jle`> even if it doesn't want to hide them, maybe it would be nice to visually distinguish them from the actual arguments maybe
22:56:35 <shanemikel> anybody here have a good experience at an american university studying CS?
23:15:45 <shanemikel> lol, that's encouraging
23:19:33 <minib00m> what's encouraging?
23:20:29 <shanemikel> the huge response to my question: if anybody has had a good experience studying CS in the US
23:23:21 <systemfault> Well... It's past midnight for nearly everyone in the US... not sure what you're expecting.
23:23:37 <shanemikel> oh, I guess it is
23:23:57 <shanemikel> where did y'all go to school?
23:24:27 <shanemikel> or do graduate study
23:26:06 <minib00m> Warsaw University in Poland :)
23:29:18 <shanemikel> did they teach functional programming to undergrads?
23:30:52 <nakal1> not anymore in Germany. 10 years ago they taught haskell here for first semester students. then changed to java.
23:33:56 <shanemikel> looks like I'm gonna have to study "Object technology" and basically teach myself everything that I actaully want to learn. that is, there looks like there might be a few interesting grad courses here
23:36:48 <minib00m> shanemikel: yeah, they did, it's part of "programming paradigms" lecture, but it's not really in depth
23:37:12 <Hijiri> They did OCaml and Scala in my PL class
23:37:19 <minib00m> we have bonus lecture that we can take "advanced functional programming" where haskell is molested much more :) 
23:37:20 <Hijiri> which is require for the CS major
23:37:35 <Hijiri> the graduate PL class has haskell and also introduces liquid haskell
23:40:54 <shanemikel> The only schools that are really impressing me so far are cabridge and oxford..
23:42:15 <shanemikel> there is somebody here: http://www.pl-enthusiast.net/2014/09/02/who-teaches-functional-programming/ at CMU that seems to take it seriously
23:42:35 <shanemikel> and, of course I know of the stanford computer music guy
23:45:51 <shanemikel> Do you guys feel like you got a lot out of your studies, and learned some invaluable engineering discipline that can help you in every technology, or do you feel like you were trained to build apps?
23:47:57 <shanemikel> Basically, I'm looking so much at schools because I'm trying to decide if I'm interested in grad school (And lately it's starting to look like the right programs are few and far-between)
23:48:51 <minib00m> i took more from my friednly colleagues than teachers :P
23:57:40 <shanemikel> well what were they getting payed for, then?
