00:07:36 * hackagebot case-insensitive 1.2.0.7 - Case insensitive string comparison  https://hackage.haskell.org/package/case-insensitive-1.2.0.7 (BasVanDijk)
00:07:36 * hackagebot wai-http2-extra 0.0.2 - WAI utilities for HTTP/2  https://hackage.haskell.org/package/wai-http2-extra-0.0.2 (KazuYamamoto)
00:15:47 <srhb> ongy: Using it as an identifier?
00:17:31 <ongy> srhb: no, it's a '<char>' expression. Some work, others don't
00:17:59 <ongy> I have OverloadedStrings active, but it's of type Char, so it shouldn't make a difference
00:18:40 <ReinH> ongy: GHC has interpreted source files as utf8 since 6.6
00:18:51 <ReinH> Can you show your code?
00:19:05 <srhb> I can't seem to reproduce that on 7.8.4
00:19:58 <srhb> Oh, yes I can. I
00:20:00 <ongy> https://travis-ci.org/monky-hs/monky/jobs/146293689 travis with error, https://github.com/monky-hs/monky/blob/monky2.0/Monky/Examples/CPU.hs#L65 (I have "fixed" it for now)
00:21:02 <ongy> for reference: https://github.com/monky-hs/monky/blob/monky2.0/Monky/Examples/Time.hs#L39 works without problems
00:21:17 <ReinH> ongy: Oh. https://ghc.haskell.org/trac/ghc/ticket/5518
00:22:03 <srhb> Well, this is an issue that was fixed between 7.8 and 7.10
00:22:34 <ReinH> srhb: I thought it was fixed earlier than that.
00:22:50 <srhb> I can certainly reproduce it on 7.8.4, but not 7.10.3
00:23:31 <ongy> srhb: 7.10 build works on travis aswell
00:23:37 <ReinH> Right then.
00:23:41 <ongy> it's 7.8 and 7.6 that fail
00:23:59 <ongy> so ghc doesn't just enforce correct representation but also that the chars are defined?
00:24:02 <ReinH> So it's not that ticket, but a virtually identical one that I haven't found yet. ;)
00:24:07 <srhb> Yeah :P
00:24:36 <srhb> Or maybe it was fixed by accident, and there is no ticket!
00:24:55 <ReinH> srhb: :)
00:24:59 <ReinH> maybe it regressed?
00:25:03 <srhb> Probably.
00:26:37 <srhb> It's also present on 7.4.2. I don't think I have any older compilers lying around.
00:26:54 <srhb> Oh, I do...
00:27:19 <srhb> Yeah, 7.2.2 as well. Old one!
00:27:38 <srhb> Moreover ghci crashes on that one :-)
00:28:37 <ReinH> heh
00:28:57 <srhb> But yeah, guess it might be hard to dig out the issue, since it's clearly very old. Ah well. At least it appears to be fixed.
00:29:16 <ReinH> Try it on 7.2.1, that's the one it's supposed to be fixed on :p
00:29:57 <srhb> ReinH: Hah, yes, that works
00:30:01 <ReinH> Did the Unicode standard regress too? That char used to not be a letter, but it has been a letter since 7.2.1...
00:30:15 <srhb> Huh, it's a symbol isn't it?
00:30:26 <ReinH> According to the ticket,
00:30:28 <ReinH> $ ghc-7.2.1 -e "Data.Char.generalCategory '\8342'"
00:30:30 <ReinH> ModifierLetter
00:30:37 <srhb> Oh, that one. I thought you meant ongy's
00:30:49 <ReinH> wait, that's a different one
00:30:51 <ReinH> anyway
00:30:55 <srhb> Which is Symbol: pocket calculator
00:30:59 <ReinH> Ah right.
00:31:09 <ReinH> And I guess symbols are now ... er... ok then.
00:31:21 <ongy> :)
00:31:23 <srhb> But yeah, looks like the fix went right out in 7.2.2 again and didn't return before 7.10
00:31:43 <ReinH> Why does GHC care what category a codepoint is in? It's still a character...
00:33:07 <ReinH> I mean, '=' is a symbol too.
00:33:43 <ReinH> Ok, I guess not *all* codepoints are characters, fine.
00:33:49 <ongy> would the compiled application crash, if I read that in form somewhere and tried to print it to stdout? I ghc also does some encoding stuff on handles
00:33:56 <ReinH> but it shouldn't be disallowed just because it's a symbol...
00:36:21 <ReinH> ongy: I don't think haskell processes were crashing a few years ago because of utf8
00:37:15 <ReinH> This is a parse error, not a runtime error.
00:37:33 <ongy> I have noticed, the my application crashes when I try to print the degree (Â°C) glyph and don't have an utf8 locale
00:38:04 <ongy> so it does *some* unicode stuff on outputs aswell. And it's not all of utf8 that's failing
00:38:38 <kadoban> It crashes? That's rather curious. With an error, or?
00:40:07 <srhb> I can crash ghci with it, but not ghc.
00:40:21 <srhb> (well, I say crash, really it's spending 100% cpu doing *something* useless)
00:41:19 <kadoban> That's ... even weirder?
00:41:27 <srhb> Yeah, but.. It's also old. :P
00:42:44 <ReinH> attempting to confuse the halting oracle is not useless.
00:43:24 <ReinH> Or perhaps you are cold. Then it's useful too.
00:43:30 <srhb> :P
00:47:44 <ongy> kadoban: "<stdout>: commitBuffer: invalid argument (invalid character)", on a 7.10.3 ghc
00:48:04 <ongy> that took way to long to test -.- I should have just done it local
00:48:14 <kadoban> Huh, that's ... weird.
00:50:04 <ongy> it's the degree glyph, works with utf8 locale, LANG=C ./<application> crashes with that error
00:50:30 <ReinH> Yeah you're gonna want to not do that. :)
00:51:03 <ongy> I know, I only ran into it when I wanted to pipe the output through ssh
00:54:23 <dysfun> are you sure the infinite delay isn't on the ssh side?
00:54:43 <dysfun> oh no, yours is an error
01:02:32 * hackagebot aeson-diff 1.1.0.0 - Extract and apply patches to JSON documents.  https://hackage.haskell.org/package/aeson-diff-1.1.0.0 (ThomasSutton)
01:12:32 * hackagebot dtw 1.0.3.0 - (Fast) Dynamic Time Warping  https://hackage.haskell.org/package/dtw-1.0.3.0 (fho)
01:26:35 <cheater> do you think a system could work where each function in haskell is assigned a class of time complexity and the complexity of new functions is auto-derived?
01:26:58 <cheater> acowley: ^
01:27:33 * hackagebot ghc-typelits-natnormalise 0.4.6 - GHC typechecker plugin for types of kind GHC.TypeLits.Nat  https://hackage.haskell.org/package/ghc-typelits-natnormalise-0.4.6 (ChristiaanBaaij)
01:28:54 <ongy> cheater: what if I have an input list of size N, pass that to something that makes a list of size N^2 out of it (permutate I think).
01:29:24 <ongy> so at least for list modifying functions you would need more information to do this
01:29:51 <tdammers> the problem there, I believe, is that it may not be obvious what your n is
01:30:25 <cheater> ongy: the new complexity could be calculated automatically by analyzing the new function, given the right heuristics, and if it's not possible you could include your own proof (e.g. just say "this function is O(N) because i say so" or have a more elaborate proof)
01:30:47 <cheater> tdammers: it would be obvious once you start keeping track of your N's and other variables
01:31:04 <cheater> often time complexity is described in terms of multiple variables
01:31:20 <cheater> or you'll even see something like max(O(N), O(K))
01:31:30 <tdammers> hmhm
01:31:40 <cheater> it's not unusual
01:31:45 <tdammers> it'd sure be a complex beast though
01:31:53 <cheater> the system? or using it?
01:31:56 <tdammers> the system
01:32:00 <cheater> i envision that it would be super simple to use
01:32:09 <tdammers> yes, I'm more worried about the implementation
01:32:17 <cheater> yeah, it sure would need some tinkering to get right, but i don't think it would be so terrible
01:32:36 <cheater> i mean at the outset you could start with no heuristics and just have manual proofs of everything
01:32:50 <tdammers> you have to have *some* axioms
01:32:56 <cheater> no you don't really, no
01:33:01 <cheater> i mean what axioms?
01:33:14 <tdammers> you have to teach your system the trivial cases
01:33:26 <kadoban> cheater: Even figuring out if stuff will *ever* finish at the language level requires moving to something like agda or coq or idris ... can't imagine worrying about complexity is going to be easier, even ignoring that O(n) doesn't mean anything on its own.
01:33:45 <tdammers> but even then, ...
01:33:48 <cheater> i'm talking about heuristics like "this function takes inputs of size N, M, P and is of this certain shape, so it'll be O(N^2)"
01:34:03 <cheater> kadoban: eh, that's just give-up talk
01:34:36 <cheater> tdammers: you don't have to teach it anything, you could start by having the programmers describe the complexity by hand
01:34:45 <tdammers> cheater: same thing
01:34:51 <cheater> like they would describe the types of a function if there was no type inference
01:34:55 <tdammers> you have to bootstrap its inference somehow
01:35:04 <kadoban> cheater: K, well good luck then, I'll be holding my breath waiting for your implementation to come out.
01:35:06 <cheater> you don't have to start with inference
01:35:08 <tdammers> (complexity inference, that is)
01:35:29 <cheater> kadoban: ever tried being, you know, at the least not destructive, if not *gasp* constructive?
01:35:42 <cheater> tdammers: yeah
01:35:47 <tdammers> attempting the impossible is not constructive
01:35:52 <cheater> tdammers: a good first step would be to have no inference at all
01:36:09 <tdammers> you have to have *some* degree of inference for the system to be useful at all
01:36:16 <cheater> why do i?
01:36:26 <kadoban> cheater: You read my problems with it for like 5 seconds and then dismissed them with some lame handwave, why would I bother?
01:37:16 <tdammers> because if you don't, you're just making a minilanguage for declaring the complexity of your functions, but you have to derive them all by hand
01:37:18 <cheater> kadoban: "can't work because of halting problem" is an argument that i hear monthly and yet things work, sorry if i didn't spend too much time thinking about it, but it's not the 20th time i've seen it
01:37:24 <ongy> oh, lazyness will also be real fun with that, won't it? repeat....
01:37:36 <merijn> tbh, halting problem only applies in Turing complete languages
01:38:08 <merijn> ongy: Laziness itself is not a problem, but it does rule out local reasoning. You could only reason globally
01:38:29 <cheater> as merijn suggests, given that there is only a limited amount of elementary particles in the universe, no language is turing complete, so your argument is completely unreasonable kadoban
01:38:43 <kadoban> cheater: lol
01:38:54 <merijn> That is not what I suggested
01:39:03 <cheater> i know :-) it was a joke
01:39:22 <merijn> It's also not true, because Turing completeness of languages is independent of the existence of correct implementations of said languages
01:39:29 <merijn> Languages are not constrained by the universe
01:40:01 <cheater> that assumes the holographic principle in philosophy, which is a controversial axiom
01:40:12 <merijn> wut
01:40:26 <tdammers> implementations are, but the finite universe constraint leads to a derived turing completeness notion that is only theoretically weaker than full on TC
01:40:45 <cheater> in other words, you assume things exist beyond what can be possibly experienced by a mind
01:41:00 <merijn> tdammers: If we care about denotational semantics we don't care about the implementation
01:41:30 <cheater> but even your denotational semantics define a finite space
01:41:31 <merijn> tdammers: Whether we can build an implementation that matches a given denotational semantics is an entirely different problem area
01:41:43 <merijn> cheater: Eh, why is that?
01:41:53 <tdammers> namely, as long as your theoretical language is turing complete, and the practical implementation respects the theory until the point where the finiteness of its granulate becomes a problem, then the halting problem is reduced to "cannot be decided during the existence of the universe", which is theoretically finite, but in practice it's just as bad
01:42:09 <cheater> if you took all the work of every person throughout all time that works on or with your language, it would still be finite, and could be reasoned about finitely
01:42:29 <tdammers> cheater: no they don't. the work itself is of finite extent, but the concepts it defines and describes need not be
01:42:41 <merijn> cheater: That's not a formal argument and has so many holes in it I'm not even going to bother
01:43:04 <tdammers> cheater: I can define a set of axioms and rules that is capable of generating and describing infinitely many objects, and I can reason about it in finite time
01:43:16 <ReinH> So, do people still talk about Haskell here?
01:43:22 <tdammers> ReinH: tangentially
01:43:33 <ReinH> Or is it kindergarten philosophy time?
01:43:33 <cheater> so about defining complexity of functions
01:44:16 <cheater> how could you label functions such that you could look up a function's complexity, and request that it is in certain bounds?
01:44:24 <tdammers> ReinH: the scope is still "explaining why automatically deriving algorithmic complexity of a given function" may or may not be a feasible idea
01:44:53 <merijn> tdammers: Oh, it's certainly feasible. The real question is "up to which amount of complexity is it feasible" ;)
01:44:56 <ReinH> tdammers: And we're at "because the universe isn't infinitely big?" now or whatever?
01:45:02 <cheater> it certainly is feasible, if you limit yourself to what's doable, and i bet a lot is doable
01:45:11 <merijn> cheater: So start implementing?
01:45:19 <cheater> well, i'm just wondering how it could work
01:45:24 <tdammers> if you reduce the scope to just that, i.e., declare complexities explicitly and then at call time demand that they are in a certain class, you might even be able to do it through Haskell's existing type system
01:45:32 <merijn> tdammers: hah
01:45:36 <cheater> you'd need some way to be able to label functions with something like a type class
01:45:45 <tdammers> ReinH: somehow, we arrived there via the halting problem
01:45:54 <cheater> and there would need to be some sort of type checking involved
01:46:01 <merijn> tdammers: I've worked on an EU project (one of several hundred similar projects I've seen) that wanted to try that. It, inevitably, went nowhere :)
01:46:18 <ReinH> I'm impressed that you are simultaneously saying that something is easy, asking other people how to do it, telling them that they are wrong, and not in fact doing that easy thing yourself.
01:46:22 <tdammers> merijn: granted, the biggest problem there may have been the "EU" parat
01:46:25 <tdammers> s/parat/part/
01:46:46 <ReinH> tdammers: Of course we did.
01:47:00 <ReinH> tdammers: The halting problem is the gateway drug for bad philosphgy.
01:47:09 <tdammers> ReinH: hah.
01:47:46 <cheater> ReinH: that's a surprising impression
01:48:08 <merijn> tdammers: The biggest problem was: international project partners disagree on which part time should be spent :)
01:48:20 <tdammers> merijn: exactly
01:48:32 <ReinH> tdammers: In other crowds it's Cantor's diagonalization. ;)
01:48:36 <cheater> ReinH: now you've understood my strategy. once the halting problem is used as an argument, i try to devolve the conversation so quickly that everyone abandons that branch of reasoning and gets back on topic
01:48:57 <tdammers> ReinH: GÃ¶del's theorem is also popular
01:49:03 <cheater> tdammers: how would you stuff this concept into the existing type system?
01:49:16 <kadoban> Which would be ... how you're going to infer how quickly functions will complete in a language that can't infer if functions will complete.
01:49:20 <tdammers> cheater: you could wrap your functions in types that carry complexity information
01:49:37 <merijn> ReinH: I would say GÃ¶del's theorem, Cantor diagonalisation and Turing completeness are very similar in many ways
01:49:42 <cheater> so i think regarding usability, you would like this to be opt-in, in that you wouldn't like your functions to e.g. be stuck inside a monad
01:49:59 <ReinH> merijn: I would have said Godel's theorem but its equivalent to the halting problem, so I already said it.
01:50:11 <cheater> but being inside a type would possibly be a good stepping stone
01:50:18 <tdammers> what do monads have to do with it?
01:50:23 <merijn> ReinH: So would I, but last time I did that some mathematicians yelled at me, so I'm hedging :)
01:50:34 <cheater> create some wrapper types, have everything inside those types, try to implement some basic complexity inference
01:50:36 <ReinH> merijn: :)
01:50:42 <merijn> cheater: I would say that your first step should be to pick up and read a copy of TaPL
01:50:52 <cheater> why this book specifically?
01:51:04 <cheater> are we back on the halting problem train?
01:51:05 <tdammers> because it's a very good book, and relevant to the topic
01:51:18 <ReinH> cheater: The topic being 'How do I systematically do a thing that I deny having a system for"?
01:51:43 <cheater> that's a fetching concept ReinH
01:52:25 <ReinH> I don't think that a heuristic-based approach is reasonable.
01:52:43 <merijn> cheater: Because it's the book on type systems and programming languages and you are proposing something about type systems while clearly not knowing enough base knowledge this book would provide
01:52:52 <tdammers> if you don't like to dive into the theory directly, I suggest taking a bunch of sample programs and doing the work by hand
01:53:03 <tdammers> and then think about how you would have a computer do it for you
01:53:36 <tdammers> you'll get stuck, at which point you might still want to read up on what other bright minds have come up with so far
01:53:47 <tdammers> but that's up to you
01:54:03 <merijn> ReinH: How hard could analysing complexity possibly be? I've only been working for 3 years to figure out 10 lines of fairly trivial code :)
01:54:08 <cheater> i am kind of disappointed that people assume all kinds of insulting things about me because i'm talking about an idea that i'd like to come up with solid concepts for
01:55:24 <ReinH> What insulting things have people assumed about you?
01:55:27 <merijn> cheater: You're trying to do something hard in a field I've been working in for over 5 years and when I recommend you read up on the basics you dismiss what I say as being insulting
01:56:45 <cheater> i haven't dismissed it, but i've been upset by the way people go about talking about this, i'm literally being beat up for having an idea, well done community
01:57:04 <gfixler> where is zipWithFB useful?
01:57:13 <cheater> :t zipWithFB
01:57:14 <lambdabot>     Not in scope: âzipWithFBâ
01:57:14 <lambdabot>     Perhaps you meant one of these:
01:57:14 <lambdabot>       âzipWithâ (imported from Data.List),
01:57:38 <gfixler> zipWithFB :: (a -> b -> c) -> (d -> e -> a) -> d -> e -> b -> c
01:57:42 <gfixler> zipWithFB c f = \x y r -> (x `f` y) `c` r
01:57:46 <cheater> zipWithFB :: (a -> b -> c) -> (d -> e -> a) -> d -> e -> b -> c
01:57:48 <gfixler> http://hackage.haskell.org/package/base-4.9.0.0/docs/src/GHC.List.html#zipWith
01:57:49 <EvanR> cheater: i assumed you were a cheater
01:57:51 <ReinH> cheater: I guess you are unaware of how combative your expression of your idea has been, but "having an idea" is not the cause of any of your discomfort.
01:57:51 <cheater> right yeah gfixler 
01:57:58 <tdammers> cheater: people aren't insulting you. We're telling you that your ideas are almost certainly naive, and we've tried explaining why. That's not an insult. And then when you don't understand the explanations, people try different angles, and eventually suggest reading up on the standard literature. That's not beating up, that's making an honest-to-god effort.
01:58:34 <tdammers> believe it or not, people have been trying to help here.
01:58:35 <cheater> tdammers: you're telling me you're not insulting me, and in that sentence you're telling me i don't understand something, and you think that's not belittling?
01:58:43 <tdammers> yes
01:58:48 <ReinH> Correct.
01:58:54 <ReinH> Do you think you understand everything?
01:59:03 <merijn> cheater: What's belittling about telling someone they don't understand something when they, in fact, don't understand it?
01:59:09 <cheater> i don't think it's your place to assume what i do and don't understand
01:59:21 <ReinH> ...
01:59:28 <ReinH> You keep using that word.
01:59:45 <gfixler> cheater: this is standard intellectual discourse stuff
01:59:55 <gfixler> cheater: I've been hearing how wrong I am for 2 years in here :)
02:00:00 <gfixler> cheater: it's really good for learning!
02:00:39 <gfixler> can certainly be frustrating at times, though
02:00:52 <cheater> gfixler: let's rewrite the definition of zipWithFB so the names of the variables fit the names of the type variables
02:01:14 <EvanR> experts and acolytes both should check themselves before they wreck themselves, not saying who is which
02:01:17 <gfixler> cheater: I don't know what their names are, though
02:01:23 <sbrg> cheater: the thing is, if someone tells you "it can't work because of the halting problem" and they are wrong and you do manage to do something because they misunderstood the problem's complexity.. well, that's cool for you. but if someone tells you "it can't work because of the halting problem" and they're right, there's very little you can do. in this case, I'm pretty sure those who are claiming that it
02:01:25 <gfixler> cheater: no info online about why this function exists; not in the docs
02:01:26 <sbrg> will at least be very, very difficult to even get remotely useful results(because halting problem) are right
02:01:48 <cheater> zipWithFB c a = \d e b -> (d `a` e) `c` b
02:02:21 <ReinH> It might be interesting to imagine a class of languages for which such a type system could be written.
02:02:24 <merijn> sbrg: Hell, I'm claiming that even if you abandon Turing completeness and thus the halting problem it will STILL be very difficult to get useful results :)
02:02:29 <gfixler> I can see what the function does, but it seems very specific
02:02:34 * hackagebot language-javascript 0.6.0.8 - Parser for JavaScript  https://hackage.haskell.org/package/language-javascript-0.6.0.8 (ErikDeCastroLopo)
02:02:42 <cheater> now i can see a bit better what's happening. you have three lists, and two functions that zip them together into one list. that's sometimes easier than writing a single function of three arguments and using it to zip three lists together at once.
02:02:50 <gfixler> wondering about the use case(s) that prompted its addition to the Prelude
02:03:13 <cheater> sbrg: your message got cut.
02:03:15 <sbrg> merijn: I agree. otherwise this would most likely have been implemented somewhere by someone long ago
02:03:31 <cheater> sbrg: at "those who are claiming that it".
02:03:39 <sbrg> cheater: oh. > .. will at least be very, very difficult to get even remotely useful results (because halting problem) are right
02:04:10 <EvanR> sbrg: the finding 100 dollars and ignoring it because someone would have picked it up already if it werent fake trick ;)
02:04:18 <EvanR> 3rd time this week
02:04:24 <sbrg> cheater: I think it's a cool idea and I think you could definitely get somewhere, at least with "simpler" functions, but it's definitely not trivial
02:04:29 <darthron> Hi, guys! I have a question for you. I would like to understand how (fmap . fmap) typecheck
02:04:35 <darthron> :t (.)
02:04:36 <lambdabot> (b -> c) -> (a -> b) -> a -> c
02:04:38 <cheater> of course it's not trivial
02:04:42 <sbrg> EvanR: haha
02:04:44 <darthron> :t fmap
02:04:45 <lambdabot> Functor f => (a -> b) -> f a -> f b
02:04:50 <cheater> darthron: a -> b -> c is the same as a -> (b -> c)
02:04:54 <merijn> sbrg: Well, also, because of course big O notation is wrong to the point of uselessness and we don't even have anything better at the moment :)
02:05:23 <cheater> so here in (.)'s first argument the c is actually (f a -> f b) from the type of fmap.
02:05:26 <sbrg> merijn: hm? wrong? what do you mean?
02:05:38 <merijn> sbrg: It assumes constant time memory access, which is bollocks
02:06:02 <merijn> sbrg: The most enlightening explanation of this I've read so far is here: https://queue.acm.org/detail.cfm?id=1814327
02:06:12 <kadoban> merijn: Wat? It assumes whatever your model does. Nobody said your model has to ignore memory access.
02:06:34 <ReinH> :t (.) `asAppliedTo` fmap
02:06:35 <lambdabot> Functor f => ((a1 -> b) -> f a1 -> f b) -> (a -> a1 -> b) -> a -> f a1 -> f b
02:06:38 <EvanR> darthron: make sure you use new variable names, there are more than three types involved, and so a b c isnt enough
02:06:46 <merijn> kadoban: I'm saying that there is no current popular model that does account for memory access, so we don't even have a de facto standard model for expressing performance of code
02:06:50 <sbrg> merijn: well, i'm not sure I would agree. when you are characterizing the complexity of any function, you work within a certain context where some operations are assumed to take constant time. this is obv. why some algorithms perform significantly worse in practice than they should in theory because of .. well, what have you. cache, memory accesses, etc etc. 
02:06:55 <ReinH> darthron: ^
02:07:27 <merijn> sbrg: It's rather common for algorithms that are objectively an order of magnitude worse are in reality an order of magnitude better
02:07:28 <sbrg> but you could also decide to work within a context where memory accesses are taken into account(we have an interesting course at my uni called IO efficient algorithms which does this)
02:07:32 <merijn> sbrg: This stuff matters
02:07:55 <kadoban> merijn: Yeah that sounds basically true, yeah.
02:08:23 <sbrg> merijn: I agree that it matters. I just don't think it's wrong because you are working within a context that gives you "ideal" results. if you want the correct performance characteristics, you need to take the platform into account. 
02:08:25 <merijn> kadoban: Of course I'm not saying such a model isn't possible :)
02:08:33 <EvanR> you just cant compare different big O judgments, its simply a different O ;)
02:08:58 <merijn> sbrg: Well, presumably when you want to annotate performance of functions in your language you care about ACTUAL performance, not theoretical :)
02:09:34 <darthron> cheater: since c is (f a -> f b), does it mean that b is (a -> b) from fmap? If so, it means that the b form (a -> b) of (.) is a function as well, but (a -> b) should be the other fmap, right?
02:09:47 <sbrg> merijn: aye. but then again, why stop there? why not take into account the complexity of adding numbers on your processor? etc etc. at some point, you need to stop because the practical complexity of everything is going on is overwhelming.
02:09:52 <cheater> interesting quote from that article: "the results coming out of the CS department would be so much more interesting and useful if they applied to real computers and not just toys like ZX81, C64, and TRS-80"
02:10:09 <ReinH> darthron: (a' -> b') -> (f a' -> f b') is a type of the form (a -> b)
02:10:15 <tdammers> merijn: the problem, I believe, is that big-O describes complexity, not performance
02:10:18 <sbrg> but the complexity is only as correct(or realistic) as the depths you go to analyze all characteristics
02:10:24 <ReinH> darthron: a = (a' -> b), b = (f a' -> f b')
02:10:25 <sbrg> tdammers: that's a good way to put it
02:10:57 <ReinH> tdammers: moreso, it describes complexity for a class of computing devices which don't exist.
02:10:59 <merijn> tdammers: Complexity is about performance. The reason it doesn't work is that the algorithm assumes constant time memory access. If you accounted for actual memory accesses it would Just Work for performance
02:11:17 <darthron> ReinH: fmap = (a -> b) -> (f a -> f b)
02:11:31 <darthron> ReinH: fmap = (x -> y) -> (f x -> f y)
02:11:33 <ReinH> darthron: yes, I just renamed the variables, which I am allowed to do.
02:11:38 <merijn> tdammers: Of course, it's bloody impossible to predict actual memory access time since that means you have to know what's in L1, L2, L3, or global memory and nowadays NUMA nonsense :)
02:11:39 <ReinH> (As are you.)
02:12:04 <tdammers> merijn: yes, complexity is about performance, but theoretical algorithmic complexity doesn't cover all the aspect. So we're basically saying the same thing.
02:12:09 <ReinH> darthron: (.) takes (a -> b), (x -> y) -> (f x -> f y) is an (a -> b) for some a and b.
02:12:18 <koz_> I was gonna watch a TV show. Instead, #haskell proved more entertaining today.
02:12:25 <koz_> So thanks, all of you. :)
02:12:32 <merijn> Actually, I guess I'm referring to theta notation instead of big O
02:12:40 <sbrg> merijn: well, if you're going to take memory accesses into account, you can't stop there. caching, memory layout blah blah blah can all have a significant impact, and by then, you're trying to create a mathematical model for a modern processor with say, 4 cores and 3 caches, some of which might be local to some cores, and then there's the registers and blah blah
02:12:59 <darthron> ReinH: Replacing the first fmap in (.) we get: ( (a -> b) -> (f a -> f b) ) -> (a' -> b') -> a' -> c', right?
02:13:04 <ReinH> merijn: Another practical problem with these notations is that no one actually knows what they mean (to a first approximation)
02:13:10 <merijn> ReinH: :)
02:13:11 <ReinH> :t (.)
02:13:12 <lambdabot> (b -> c) -> (a -> b) -> a -> c
02:13:41 <sbrg> in a class about parallel computing we went through single core performance first, looked at a lot of figures and numbers and whatnot. we used old processors as example, because modern processors are simply impossible to understand these days
02:13:43 <ReinH> merijn: big O especially just means "graph shaped like this" now.
02:13:48 <tdammers> and of course there's always the practical concern that even though algorithm A may have better complexity than algorithm B, but we don't know where the break-even point is; it may be impractically large
02:13:48 <darthron> ReinH: I replaced the first b with (a -> b) and c with (f a -> f b)
02:14:06 <merijn> ReinH: Try telling people that quicksort is O(n^2) :)
02:14:07 <ongy> I can't believe how hard it was for me to get that (.) is (b -> c) -> (a -> b) -> (a -> c)
02:14:36 <koz_> tdammers: My Master's thesis hit exactly that problem.
02:15:02 <ReinH> darthron: So if (.) :: (b -> c) -> (a -> b) -> a -> c, fmap :: Functor f => (x -> y) -> (f x -> f y), then b ~ (x -> y) and c ~ (f x -> f y)
02:15:10 <ReinH> so (.) fmap :: ?
02:15:36 <ReinH> We don't know a, but we know b and c.
02:15:37 <sbrg> I think that we can all summarize: Computer science is impossible. We're all like bumblebees when we try to computer science. We don't know we can't fly so we do it anyway.
02:15:40 <sbrg> (I know that's a myth)
02:16:15 <darthron> ReinH: fmap :: b -> c, but how does the second fmap work with our b being the second argument?
02:16:24 <tdammers> koz_: theoretically speaking, you can reduce any algorithm to O(1) by precalculating it for all possible inputs and storing the output in a sufficiently large hashmap
02:16:42 <ReinH> What is the type of ``(.) fmap''?
02:16:43 <tsahyt> Can I use a pragma to inline a function in another but not in general?
02:16:47 <merijn> tdammers: Not really, that'd depend on the complexity of computing the key :)
02:16:55 <ongy> tdammers: where sufficiently large is \infty
02:17:08 <tdammers> merijn: I'll hand-waive that part :D
02:17:33 <tdammers> ongy: only if your input sets are unbounded
02:17:33 <darthron> :t (.) fmap
02:17:34 <lambdabot> Functor f => (a -> a1 -> b) -> a -> f a1 -> f b
02:17:36 <ReinH> tsahyt: Not afaik, but generally GHC is better at selective inlining optimizations than humans
02:17:38 <sbrg> tdammers: sure, you trade O(whatever) copmutation time for O(whatever) memory usage
02:17:39 <merijn> koz_: incidentally, hanging around in #haskell was almost more useful than my actual CS degree ;)
02:17:44 <darthron> :t (.) (fmap)
02:17:45 <lambdabot> Functor f => (a -> a1 -> b) -> a -> f a1 -> f b
02:17:53 <tdammers> sbrg: I know, that's the joke
02:18:08 <koz_> merijn: I think they've been about equally useful to me, but honestly, my Master's supervisor and multi-year mentor was kinda hardcore.
02:18:13 <merijn> sbrg: Memory is cheap ;)
02:18:19 <ReinH> darthron: So how does the type of fmap unify with the type of (.) fmap?
02:18:22 <sbrg> true
02:18:24 <ReinH> :t (.) fmap
02:18:25 <lambdabot> Functor f => (a -> a1 -> b) -> a -> f a1 -> f b
02:18:26 <ReinH> :t fmap
02:18:26 <tsahyt> ReinH: I've actually seen some reasonable speedups with inlining manually in this codebase
02:18:27 <lambdabot> Functor f => (a -> b) -> f a -> f b
02:18:30 <ReinH> solve for ^
02:18:30 <sbrg> and in reality it's often not a bad solution tbh
02:18:39 <tsahyt> ReinH: nothing amazing, but about 2% or so off total execution time in some cases
02:18:44 <sbrg> game devs use it all the time. just hardcoding lookup maps in their code
02:19:22 <ReinH> tsahyt: And INLINABLE doesn't give GHC a big enough nudge?
02:19:23 <darthron> ReinH: so (a -> a1 -> b) -> a is fmap's (a -> b)?
02:19:30 <tsahyt> Oh I haven't tried that
02:19:40 <ReinH> There is no (a -> a1 -> b) -> a
02:20:10 <ReinH> The argument to (.) fmap must be of type (a -> b -> c)
02:20:12 <ReinH> :t fmap
02:20:13 <lambdabot> Functor f => (a -> b) -> f a -> f b
02:20:42 <ReinH> If we say (.) fmap :: (x -> y -> z) then x ~ (a -> b), y ~ f a, z ~ f b
02:20:45 <ReinH> er
02:20:54 <ReinH> if we say the first argument to (.) fmap :: (x -> y -> z)
02:20:56 <darthron> ReinH: so a is (a -> b), f a is b and f b is c?
02:21:01 <ReinH> right
02:21:16 <ongy> ReinH: what's '~' in that notation?
02:21:17 <ReinH> but those are not the same variables
02:21:21 <ReinH> ~ is type equality
02:21:46 <ReinH> i.e., the a in the type of (.) fmap and the a in the type of fmap are not the same variable
02:22:17 <ReinH> :t ((.) fmap) `asAppliedTo` fmap
02:22:18 <lambdabot> (Functor f, Functor f1) => ((a -> b) -> f1 a -> f1 b) -> (a -> b) -> f (f1 a) -> f (f1 b)
02:22:38 <ongy> :t asAppliedTo
02:22:39 <lambdabot> (a -> b) -> a -> a -> b
02:22:57 <koz_> That's a neat function!
02:23:11 <ReinH> Let Haskell do your type unification for you, it's pretty good at it.
02:23:50 <ReinH> So we have:
02:23:55 <ReinH> :t (.) `asAppliedTo` fmap
02:23:56 <lambdabot> Functor f => ((a1 -> b) -> f a1 -> f b) -> (a -> a1 -> b) -> a -> f a1 -> f b
02:24:02 <ReinH> :t ((.) fmap) `asAppliedTo` fmap
02:24:03 <ongy> he, I tried to understand Text.Printf (printf) type yesterday... that one's fun
02:24:03 <lambdabot> (Functor f, Functor f1) => ((a -> b) -> f1 a -> f1 b) -> (a -> b) -> f (f1 a) -> f (f1 b)
02:25:29 <ReinH> ongy: Basically, printf returns either a String or a function that returns either a string or a function that returns either a string or a function that returns...
02:25:39 <tdammers> recursive types, whee
02:25:55 <ongy> ReinH: it also has an IO () version. But I understood it at the end, I build something similar
02:26:08 <ongy> noticed that it's quite uncooperative and made a better version of what I wanted to do...
02:32:48 <darthron> ReinH: I don't get why :t (.) (fmap) yields that result. Why does the second argument get that a1?
02:33:17 <merijn> darthron: The a's and b's in different type signatures are not the same
02:33:41 <merijn> darthron: GHC tries to keep the names of variables similar by adding, e.g. a number to them if two names clash
02:34:08 <merijn> darthron: 'a1' is the same as 'z' or 'foobar' would be
02:34:17 <darthron> meijn: I understand that. Could you please tell me which is the common 'b' from the (.) type?
02:34:41 <adarqui> i remember being confused by seeing things like 'site' in a type signature instead of an a or b or m.. etc.. i still remember the moment that i realized it wasn't anything special, because it was so funny.
02:35:05 <merijn> darthron: The 'b' from (.) corresponds to 'f a -> f b' from fmap
02:35:40 <koz_> My favourite type symbol names are the lens ones.
02:35:43 <koz_> s t a b
02:35:56 <adarqui> ya that's a violent type signature
02:36:00 <koz_> (the function whose signature is something like 'Lens s t a b -> Lens b a t s' was genius)
02:36:18 <koz_> (that might have been Prism, not Lens, in retrospect)
02:36:18 <adarqui> i still want to s t a b myself when trying to figure out all of the various stuff in the lens package
02:36:23 <darthron> merijn: then how can we replace the (b -> c) from (.) if b is 'f a -> f b'? fmap has the (f a -> fb) as the second argument
02:36:37 <merijn> darthron: Eh, I was confused, apparently
02:36:38 <koz_> adarqui: The simple-lens tutorial (well, and lens-tutorial) make it *far* easier.
02:36:47 <ReinH> (.) :: (y -> z) -> (x -> y) -> x -> z
02:36:49 <koz_> There's also a few tutorials online for it which are awesome (they're linked from a wiki page)
02:36:51 <merijn> That's what I get for not looking at the type of (.) again :)
02:36:52 <adarqui> koz_: ya
02:36:52 <ReinH> :t ((.) fmap) `asAppliedTo` fmap
02:36:53 <lambdabot> (Functor f, Functor f1) => ((a -> b) -> f1 a -> f1 b) -> (a -> b) -> f (f1 a) -> f (f1 b)
02:37:01 <merijn> :t (.)
02:37:01 <lambdabot> (b -> c) -> (a -> b) -> a -> c
02:37:09 <merijn> Oh, no, I was right
02:37:10 <koz_> But yes, some of that magic is really magical - I even had to email Edward and ask him about some of the magic Prisms could do.
02:37:47 <ReinH> woops, wrong one
02:37:49 <merijn> darthron: Simple "b -> c" simply becomes "(f a -> f b) -> c"
02:37:59 <ReinH> :t (.) `asAppliedTo` fmap
02:38:00 <lambdabot> Functor f => ((a1 -> b) -> f a1 -> f b) -> (a -> a1 -> b) -> a -> f a1 -> f b
02:38:21 <merijn> darthron: And since we're composing fmap with fmap it becomes
02:38:29 <adarqui> i'm on the super slow road to haskell mastery.. but i'm ok with it now.. just taking my time enjoying myself ;f
02:38:36 <merijn> "(f a -> f b) -> (f1 (f a) -> f1 (f b))"
02:39:30 * ongy still can't get his head around lifting more than once
02:40:25 <ongy> mh, or I just fail at operator precedence
02:41:37 <adarqui> to prevent lots of lift . lift'ing u need to make things instances of MonadTrans, no?
02:41:40 <adarqui> just wondering
02:43:04 <ReinH> or a specific monad typeclass, e.g., MonadState s
02:43:16 <ReinH> (from mtl)
02:43:21 <adarqui> ya, kewl
02:44:12 <adarqui> one thing i find funny about haskell is.. i struggle with it far more than any other language i've ever "learned" (if that's what you can even call it) .. but, i'm far more productive in haskell than any of those other languages
02:44:16 <adarqui> it's an interesting dynamic
02:44:30 <koz_> adarqui: Haskell makes impossible things easy and easy things hard.
02:44:31 <koz_> :P
02:44:33 <adarqui> which only inspires me more because, the better at haskell I get, i just seem to get exponentially more productive
02:44:37 <adarqui> ya
02:44:50 <koz_> My Little Language : Haskell Is Magic.
02:45:53 <koz_> Also, I think I set a personal record for 'largest numerical literal used in actual code'.
02:45:55 <koz_> 12297829382473034410
02:46:27 <adarqui> nice. what's that for?
02:46:53 <koz_> adarqui: It's 32 '10's in sequence. I'm using it as an encoding for a particular kind of data I'm working on.
02:47:04 <adarqui> cool
02:47:14 <tdammers> koz_: I came up with a very similar observation yesterday - there are three classes of programming languages: 1) those that make difficult things easy and easy things easy enough (Haskell); 2) those that make difficult things difficult and easy things easy enough (all languages not in categories 1 and 3), and 3) languages that make difficult things impossible, easy things impossible, and incorrect things
02:47:17 <tdammers> easy (PHP)
02:47:36 <koz_> tdammers: That's a nice characterization.
02:47:41 <Ralith_> koz_: why not encode that in hex for better readability?
02:47:50 <merijn> I liked this characterisation:
02:47:55 <koz_> Ralith_: I didn't realize I could, honestly.
02:48:05 <koz_> What would that look like in hex, actually?
02:48:14 <tdammers> koz_: also explains why I don't get enthusiastic about, say, clojure - it *is* better than JavaScript, but it's still in the same fundamental category
02:48:15 <merijn> "Writing correct programs is hard in any language. Writing incorrect programs is hard in Haskell. Therefore everything is hard in haskell." :)
02:48:35 <koz_> merijn: Nice!
02:48:36 <merijn> koz_: 0x...
02:48:48 <merijn> Actually, I think recent GHC have an extension for bit notation
02:48:56 <merijn> So you can write 0b1010101010101
02:48:58 <koz_> merijn: Oh, OK. DId not know that.
02:49:05 <koz_> I haven't really tried bit-twiddling in Haskell yet.
02:49:08 <koz_> For obvious reasons.
02:49:17 <koz_> 0b10101... would be stupid-long.
02:49:23 <koz_> Writing it in hex is probably a smarter move.
02:49:34 <merijn> {-# LANGUAGE BinaryLiterals #-}
02:49:46 <Cale> Usually, though I can see cases where it would be far easier to see what's going on with binary literals
02:50:17 <merijn> For defining, like, Word8 sized masks it's nice
02:50:32 <Ralith_> koz_: 0xA...
02:50:38 <Ralith_> much more obvious
02:51:18 <int-e> Ralith_: but the example was 0x1555
02:51:33 <Cale> Haskell makes lots of things easy. The other day I did this thing in 2 or 3 hours: http://cale.yi.org/Armory/  source: http://cale.yi.org/Armory/Armory.hs
02:51:45 <Cale> It's a nice little showcase I think
02:52:03 <Ralith_> int-e: he wasn't asking about the example
02:52:26 <merijn> Cale: I have no clue what that does xD
02:52:36 <balor> how do i kindly ask ghci to pass options to my main?  I want to call something like `> main -o foo.txt` 
02:53:09 <tdammers> balor: not sure if that's possible at all
02:53:15 <Cale> merijn: There's a game of chance that's adjunct to a strategy game I like called Prismata, where you play to win skins for your units and emotes and stuff
02:53:18 <balor> tdammers, thanks
02:53:34 <tdammers> balor: what I'd do is split main in two parts - the part that processes arguments, and the part that gets them
02:53:43 <tdammers> main = getArgs >>= theActualMain
02:53:50 <Cale> merijn: In that game, you flip over some cards, and various poker-like combinations of them give you points, and you can decide to buy more flips, or use the points you have to get some prizes
02:53:55 <tdammers> and then you call theActualMain from within ghci, with the desired arguments
02:54:07 <adarqui> i remember there being something like :set args though?
02:54:08 <adarqui> in ghci
02:54:16 <Cale> this calculates the probability of being in various point ranges if you choose to flip again
02:54:18 <balor> tdammers, thanks a lot.
02:54:33 <lyxia> balor: there's System.Environment.withArgs
02:55:19 <tdammers> ^ that would work too
02:55:38 <ongy> koz_: you want bit twiddling in haskell? It's still better than most languages
02:55:58 <koz_> ongy: I don't doubt it.
02:56:03 <Cale> merijn: apart from the fact that it's annoying to explain what it does to people who have never seen the flip game before, it's a pretty nice demo for Haskell... I get in a quick and dirty monad of random variables and exploit it to easily do the calculation.
02:56:06 <koz_> It's not my first, second, or *third* optimization pass of this code.
02:56:28 <Cale> merijn: and then the GUI bit is quite easy with reflex-dom
02:59:33 <koz_> 0xAAAAAAAAAAAAAAAA <- best literal
02:59:54 <Cale> actually, there are a few lines of dead code there -- I provide an expectation operation but don't use it
03:00:14 <Cale> (because I grabbed some of this code from another program that I'd written earlier)
03:00:45 <adarqui> koz_: i prefer the plays on dead and beef, and feef
03:00:46 <Cale> I should probably show the expected value.
03:01:24 <tdammers> adarqui: 0xdeadbeef is no longer an option in 2016
03:01:28 <koz_> adarqui: It's more the 'wtf'ness of it all.
03:01:34 <tdammers> adarqui: too offensive
03:02:07 <adarqui> :f
03:02:26 <koz_> 0xdeadbee works
03:02:26 <ertes> balor: use :main
03:02:29 <ongy> pff, I use dead:beef::/32 for all ipv6 examples
03:02:35 <ertes> balor: :main -myopts myarg1 myarg2
03:02:44 <balor> ertes, oh, awesome.
03:03:42 <ertes> balor: it's not entirely like running your program (most notably it doesn't kill your threads for you), but it does set the program name and command line args
03:04:19 <cheater> koz: you're probably better off doing something like 3+3*4+3*4^2+... in a formula, so that you understand what's going on there
03:04:39 <koz_> cheater: I've commented what it means, and I can make more sense of that hex than an expansion like that.
03:04:50 <koz_> Since it's for a Word64 being used as a bitstring.
03:04:50 <cheater> OK
03:05:00 <cheater> it is my experience that comments end up being detrimental
03:05:14 <koz_> cheater: It is mine that, properly applied, they can be very helpful to future me.
03:05:16 <cheater> however, you're probably better off with what's more natural to you
03:05:43 <koz_> cheater: On that, we are in total agreement. :P
03:06:04 <ongy> koz_: pack $ replicate 8 0xAA
03:06:14 <ongy> might be nicer to read, but the type should tell you either way
03:06:15 <adarqui> i was going to printf this as hex but it isn't working: (Data.Bits.complement 0xdeadbeef)
03:06:39 <koz_> ongy: Interesting - I think I'll leave the literal for now, it's too hilarious.
03:06:57 <ertes> > showHex (complement 0xdeadbeef :: Word64) ""
03:06:59 <lambdabot>  "ffffffff21524110"
03:07:14 <cheater> :t showHex
03:07:15 <lambdabot> (Integral a, Show a) => a -> ShowS
03:07:16 <koz_> Your number is mad.
03:07:27 <cheater> huh why does it need "" ?
03:07:33 <adarqui> thnx ertes 
03:07:37 <ertes> it's in Numeric, along with many other lesser known functions =)
03:07:53 <ertes> cheater: it uses composition for concatenation to make sure it's right-associated
03:08:06 <ertes> > (showHex 1 . showHex 2 . showHex 15) ""
03:08:07 <lambdabot>  "12f"
03:08:20 <adarqui> ya that's why i couldn't get it to work in ghci
03:08:23 <adarqui> i left out the ""
03:08:30 <ongy> :t show
03:08:31 <lambdabot> Show a => a -> String
03:08:39 <ertes> :t shows
03:08:41 <lambdabot> Show a => a -> ShowS
03:09:25 <osa1> do we have something in base for `not . any` ?
03:09:41 <ReinH> tdammers: these days 0xdeadbeef isn't enough bits anyway :p
03:09:47 <ertes> osa1: we have all . not =)
03:09:51 <ReinH> 0xBADC0FFEE0DDF00D ftw
03:10:09 <ongy> :t all .not
03:10:10 <lambdabot>     Couldn't match type âBoolâ with âa -> Boolâ
03:10:11 <lambdabot>     Expected type: Bool -> a -> Bool
03:10:11 <lambdabot>       Actual type: Bool -> Bool
03:10:21 <tdammers> ReinH: too painful. TRIGGERED!
03:10:45 <ertes> huh?
03:10:48 <ertes> :t all . not
03:10:49 <lambdabot>     Couldn't match type âBoolâ with âa -> Boolâ
03:10:49 <lambdabot>     Expected type: Bool -> a -> Bool
03:10:49 <lambdabot>       Actual type: Bool -> Bool
03:10:53 <ongy> :t all . map not
03:10:54 <lambdabot>     Couldn't match type â[Bool]â with âa -> Boolâ
03:10:55 <lambdabot>     Expected type: [Bool] -> a -> Bool
03:10:55 <lambdabot>       Actual type: [Bool] -> [Bool]
03:11:00 <ertes> :t all
03:11:01 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
03:11:06 <ertes> oh
03:11:10 <ertes> :t all . (not .)
03:11:11 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
03:11:22 <ertes> osa1: we have all . (not .) =)
03:11:26 <ongy> :t all not
03:11:27 <lambdabot> Foldable t => t Bool -> Bool
03:11:57 <int-e> :t not . any
03:11:58 <lambdabot>     Couldn't match type ât0 a -> Boolâ with âBoolâ
03:11:58 <lambdabot>     Expected type: (a -> Bool) -> Bool
03:11:58 <lambdabot>       Actual type: (a -> Bool) -> t0 a -> Bool
03:12:06 <int-e> :t not . or
03:12:07 <lambdabot> Foldable t => t Bool -> Bool
03:13:25 <ertes> i suggested an ill-typed alternative to an ill-typed functionâ¦  i love coirony
03:15:05 <ReinH> ertes: My favorite form of medy.
03:15:45 <int-e> @check \xs -> (not . or $ [] ++ xs) === all not xs
03:15:46 <lambdabot>  +++ OK, passed 100 tests.
03:17:32 <maerwald> that's where quickcheck is easy...
03:18:51 <koz_> ertes: Coirony?
03:19:35 <wedens> question to intero users (emacs): should it highlight unused imports and language extensions?
03:19:36 <ongy> why [] ++ xs and not just xs?
03:19:37 <Cale> [] ++ xs is an amusing way to ask for a list
03:20:07 <ongy> oh because they are over foldable
03:20:09 <Cale> :t or
03:20:10 <lambdabot> Foldable t => t Bool -> Bool
03:20:11 <Cale> yeah
03:20:39 <ReinH> No one appreciated my joke :(
03:20:49 <ReinH> Maybe you are colaughing.
03:21:20 <Cale> ReinH: That's what happens with medy.
03:21:25 <ertes> ReinH: i found it very mical!
03:21:26 <ReinH> Cale: thank you
03:21:45 <ReinH> What's the difference between a nut and a coconut?
03:22:00 <maerwald> what's a conut then?
03:22:25 <ReinH> Answer: A coconut is a drupe, not a nut.
03:22:38 <maerwald> haha
03:22:42 <shachaf> Nuts are 2-categorical, I suspect.
03:22:52 <shachaf> So you can have a conut and an opnut and a coopnut.
03:23:23 <ongy> http://static.portlandbolt.com/uploads/2014/07/heavy_hex_nut1-374x250.jpg nuts?
03:23:35 <ertes> koz_: sorry, i can't explain that jokeâ¦
03:24:02 <liste> riddle: what transforms de to ffee?
03:24:45 <ReinH> liste: coprogrammers?
03:24:48 <liste> ders (:
03:24:54 <ReinH> oh, that's better
03:33:05 <merijn> Is there a function for displaying a number in binary? Like 0b01010 notation?
03:34:30 <liste> merijn: is showIntAtBase 2 enough?
03:34:34 <liste> from Numeric
03:34:54 <liste> :t showIntAtBase 2
03:34:55 <lambdabot> (Integral a, Show a) => (Int -> Char) -> a -> ShowS
03:35:36 <merijn> I guess I can repurpose that
03:42:35 <maerwald> do we have a type for binary numbers?
03:42:51 <tdammers> we have a typeclass
03:43:10 <tdammers> or do you mean [Bool]?
03:43:11 <ReinH> > binary # 100
03:43:13 <lambdabot>  "1100100"
03:43:18 <maerwald> tdammers: no
03:43:22 <ReinH> merijn: it can be yours for the low low price of all of the lens machinery
03:43:24 <liste> :t binary
03:43:25 <lambdabot> (Integral a, Applicative f, Choice p) => p a (f a) -> p String (f String)
03:44:01 <tdammers> "binary number" is a representation, and an implementation detail; I don't consider it a type
03:44:05 <ReinH> it is a prism :)
03:44:08 <maerwald> tdammers: I do
03:44:34 <ReinH> > "1100100" ^? binary
03:44:35 <lambdabot>  Just 100
03:45:02 <ertes> if i don't use the value of a weak pointer, can i just use Weak ()?
03:45:16 <ertes> i only need it for finalisation
03:45:18 <tdammers> fwiw, Integer is a binary number type
03:45:26 <koz_> Is there a function similar to 'all', but for 'none' instead?
03:45:29 <tdammers> but it really depends what you want out of it
03:45:31 <koz_> Do I just negate the predicate?
03:45:37 <merijn> koz_: "not . all" ? :p
03:45:46 <koz_> merijn: Derpage.
03:46:20 <maerwald> tdammers: that's like saying String, Text, ByteString etc are implementation details, not a type
03:46:38 <maerwald> you can pull off that argument for pretty much any type
03:46:40 <merijn> maerwald: Except those things have different behaviour and different interfaces
03:46:45 <tdammers> that's why I ask what you want out of the type
03:46:53 <merijn> maerwald: How does a "binary number" behave differently from "Integer"?
03:46:54 <ReinH> merijn: is that eqyuva
03:46:57 <ReinH> errr
03:46:57 <ertes> merijn: i'm glad i'm not the only one who fell for that trap =)
03:47:00 <ertes> :t not . all
03:47:01 <lambdabot>     Couldn't match type ât0 a -> Boolâ with âBoolâ
03:47:01 <lambdabot>     Expected type: (a -> Bool) -> Bool
03:47:01 <lambdabot>       Actual type: (a -> Bool) -> t0 a -> Bool
03:47:01 <ReinH> equivalently productive?
03:47:08 <maerwald> merijn: you can have different interfaces indeed
03:47:21 <merijn> maerwald: I'm asking what the difference would be according to you
03:47:30 <tdammers> String is a list of Chars; Text is a unicode string with a list-like API but different performance characteristic; ByteString is a sequence of bytes
03:48:25 <ReinH> merijn: I think you want any . map not
03:48:29 <ReinH> er, koz_
03:48:29 <tdammers> the crucial part being that as far as the types are concerned, the fact that Text uses UTF-16 behind the scenes is completely irrelevant
03:48:38 <ReinH> so it can short circuit
03:48:50 <tdammers> just like the fact that Int uses binary representations behind the scenes is irrelevant
03:48:59 <maerwald> tdammers: you can use them all 3 interchangably if you do it right
03:49:03 <ertes> i love how everybody gets the types wrong on this
03:49:07 <ertes> :t any . map not
03:49:08 <lambdabot>     Couldn't match type â[Bool]â with âa -> Boolâ
03:49:08 <lambdabot>     Expected type: [Bool] -> a -> Bool
03:49:08 <lambdabot>       Actual type: [Bool] -> [Bool]
03:49:12 <maerwald> so they can be seen as different implementations of the same thing
03:49:18 <liste> :t (not .) . all
03:49:19 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
03:49:20 <tdammers> maerwald: not really - only for a subset of use cases
03:49:29 <maerwald> tdammers: that's what I just said
03:49:32 <hpc> :t not
03:49:33 <lambdabot> Bool -> Bool
03:49:39 <merijn> maerwald: So how would you implement "binary number" differently from Integer? You haven't answered that question
03:49:39 <hpc> :t any
03:49:40 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
03:50:16 <maerwald> merijn: the way you can construct it could be restricted for instance
03:50:24 <maerwald> you could have a different Monoid instance
03:50:25 <maerwald> and whatnot
03:50:34 <ReinH> ertes: close enough
03:50:46 <ReinH> ertes: any/all and/or are annoyingly named
03:50:52 <merijn> maerwald: You could also just have a newtype for that
03:50:59 <maerwald> merijn: aha
03:51:54 <merijn> But "could" "could", is not what I was asking. I was asking you specifically what they SHOULD be according to you
03:52:20 <maerwald> merijn: I already gave you examples. I don't really know what you want.
03:53:02 <maerwald> I just think the argument "it's just different representations and therfore doesn't justify a real type" is not very strong.
03:53:27 <merijn> It's not even different representations. It's different visualisation of the same representation
03:53:30 <tdammers> the argument is closer to "between the existing numeric types, what exactly is it you're missing?"
03:53:33 <ongy> Data.Bits does most of what you want
03:53:43 <maerwald> this is getting silly, really
03:53:59 <ertes> ReinH: glad to share the coirony =)
03:54:09 <tdammers> Integers already *are* binary numbers, so the question "how do you want your binary-number type to differ from integers" is perfectly valid
03:54:16 <maerwald> ongy: yeah, for example
03:54:25 <maerwald> ongy: but according to tdammers you would never need it!
03:54:40 <merijn> maerwald: Way to strawman
03:54:50 <ReinH> tdammers: b-b-but binary is an implementation detail of integers.
03:55:03 <tdammers> maerwald: no, I didn't say you would never need it; I said it already exists, and doesn't require dedicated types, just a typeclass
03:55:37 <tdammers> ReinH: yes, but the semantics of integers allow us to use them as binary numbers, regardless of representation
03:55:57 <tdammers> ReinH: you could even achieve that on a hypothetical ternary-number based platform
03:56:21 <ertes> integer's aren't binary numbersâ¦  integers are a mathematical object, and "binary number" is a representation that happens to be the one used by integer-gmp, the default implementation
03:56:23 <tdammers> just like you can make integers behave like decimal numbers on a binary-number platform
03:56:41 <ReinH> that's... a property of all bases.
03:56:46 <tdammers> exactly
03:56:49 <koz_> :t comparing
03:56:50 <lambdabot> Ord a => (b -> a) -> b -> b -> Ordering
03:56:54 <koz_> :t equating
03:56:55 <ertes> i'd go as far as to say: there is no such thing as a "binary number"
03:56:55 <lambdabot> Not in scope: âequatingâ
03:57:00 <koz_> :(
03:57:03 <merijn> ertes++
03:57:10 <ReinH> ertes: well, that isn't very far to go at all
03:57:11 <ReinH> since there isn't
03:57:21 <hpc> yeah, it sounds like maerwald is looking for a type that's "Integer, but a totally separate type that has the interface of the Bits class"
03:57:29 <hpc> which... Integer is that type
03:57:38 * hackagebot fitspec 0.3.1 - refining property sets for testing Haskell programs  https://hackage.haskell.org/package/fitspec-0.3.1 (rudymatela)
03:57:52 <ertes> merijn: don't bother, you can't save my karma =)
03:58:24 <tdammers> "binary number" is a concept, but it refers to a representation of a number, not the number itself
03:58:38 <ongy> Integer is Bits?
03:58:42 <tdammers> yes
03:58:44 <merijn> ongy: Of course
03:59:00 <hpc> instance Bits Integer where ...
03:59:00 <ongy> >complement (1 :: Integer)
03:59:13 <ongy> ok, what did I do wrong?
03:59:18 <hpc> > complement (1 :: Integer)
03:59:18 <merijn> ongy: No space after >
03:59:19 <lambdabot>  -2
03:59:30 <ongy> >complement (1 :: Int)
03:59:33 <ongy> > complement (1 :: Int)
03:59:35 <lambdabot>  -2
03:59:59 <ertes> data Natural = Z | S !Natural;  data Integer = Neg !Natural | NonNeg !Natural
03:59:59 <LKoen> :t complement
04:00:00 <lambdabot> Bits a => a -> a
04:00:19 <Cale> > complement 0 :: Integer
04:00:20 <lambdabot>  -1
04:00:31 <hpc> ertes: that has two zeroes
04:00:42 <ertes> hpc: you don't know that
04:00:44 <tdammers> complement doesn't necessarily imply "invert all the bits"
04:00:50 <merijn> hpc: So do floats :)
04:01:05 <hpc> yeah, and floats are terrible too ;)
04:01:07 <Cale> tdammers: Well, that is inverting all the bits... in the 2-adic expansion.
04:01:09 <merijn> tdammers: Eh, yes it does :)
04:01:24 <merijn> tdammers: In fact, inverting all the bits is literally the description in the docs
04:01:24 <ertes> hpc: Neg Z being 0 would be a bit counterintuitiveâ¦  i'd say that Neg Z denotes -1 =)
04:01:40 <ReinH> or -0
04:01:43 <hpc> ertes: i would perhaps call it TwosComplement then, or something
04:01:59 <tdammers> merijn: but not necessarily all the bits that the type can hold
04:02:22 <merijn> tdammers: hmmm, I'm trying to think if that matters
04:02:41 <tdammers> merijn: it does if you think of Integer as a binary number with unlimited bits
04:02:58 <tdammers> if that's your model, then complement would have to flip infinitely many bits
04:03:20 <merijn> tdammers: Does it? It only has to arrive at the same end result as, theoretically flipping all those bits
04:03:50 <hpc> indeed, if you literally flip all the bits in a gmp integer you end up with more often than not an invalid integer
04:04:08 <tdammers> "same" in the sense that you can ignore all the bits beyond the point where they are all equal
04:04:39 <tdammers> 111111111111111111111111111111111111101 == 1101
04:05:15 <ongy> tdammers: asuming twos complement
04:06:15 * LKoen remembers when he was in primary school and learned two calculate a difference between two base10 numbers
04:06:26 <LKoen> and I tried subtracting a big number from a small number
04:06:51 <ertes> LKoen: so you're still goingâ¦
04:08:08 <Cale> We might define the distance between two integers n and m to be 1/2^k where k is the largest power of 2 which divides the difference (n - m).
04:08:10 <LKoen> ertes: yes the task took a while longer than expected :(
04:08:23 <Cale> and this will give meaning to expansions of the form  sum over n = k to infinity of a_n 2^n
04:08:25 <ertes> "grandpa, why are you writing all those digits on the wall?" â "homework"
04:08:28 <Cale> where a_n is 0 or 1
04:08:56 <ongy> > rotate (1 :: Integer) 20
04:08:58 <lambdabot>  1048576
04:09:02 <ongy> > rotate (1 :: Integer) 200
04:09:03 <lambdabot>  1606938044258990275541962092341162602522202993782792835301376
04:09:20 <ongy> so rotate works on the infinite size, good to know
04:09:33 <ertes> for some value of "works"
04:11:38 <Cale> and indeed, we can show that in this metric (sum over n = 0 to infinity of 2^n) = limit as M -> infinity of (sum over n = 0 to M of 2^n) = limit as M -> infinity of (2^(M+1) - 1) = -1
04:12:19 <Cale> i.e. these numbers are approaching -1, because they differ from -1 by exactly a large power of 2 :)
04:13:12 <Cale> So that lends some credence to the idea of an infinite expansion for -1 which looks like ...111111
04:13:28 <Cale> (in binary)
04:13:47 <ongy> Cale: do you have the proof somewhere? that sounds one of those that show that 1=0
04:14:04 <Cale> I basically just gave you the proof
04:14:11 <Cale> What detail would you like unfolded?
04:14:38 <ertes> the argument is surprisingly similar to how summing over 2^(-n) for n â â \ {0} approaches 1
04:14:50 <ertes> 2^n â -1; 2^(-n) â 1
04:14:52 <Cale> the distance between 2^(M+1) - 1 and -1 in the metric I gave is 1/2^(M+1)
04:15:08 <Cale> which obviously tends to 0 as M grows
04:15:36 <Cale> (I guess, for some version of obviously, it's a detail we could check, I guess.)
04:17:37 <maerwald> hpc: no, that's not what I said. There are already some libraries/frameworks that have a Bit type (because that's subtyping Integer doesn't give you, nor does a Bit class). Adding a "Bits" type on top of that that's not awfully slow like [Bit] isn't really that far from imagination.
04:17:45 <ertes> by that argument one could probably show that â¦111111.111111â¦ = 0
04:18:09 <LKoen> ertes: what's 11111... ?
04:18:14 <ongy> Cale: oh, I missed the lines over me testing rotate
04:18:22 <ongy> with those it makes way more sense
04:18:57 <Cale> ertes: If you were careful about what that doubly infinite thing meant, yes.
04:19:09 <ertes> LKoen: by "â¦111111.111111â¦" i mean a number with a binary expansion of all ones in both directions
04:19:16 <LKoen> oh
04:19:34 <LKoen> yes okay that sounds like zero then
04:19:48 <Cale> You'll want to do something like say it's the limit as M -> infinity of sum over n = -M to M of 2^n
04:20:07 <ertes> does it?  start with all zeroes and flip more and more bits to 1, the number gets larger and larger
04:20:19 <LKoen> assuming usual operations hold, ...111.111... = ...111 + 0.111... = ...111 + 1 = (+1 carry to infinity) 000
04:20:19 <ertes> but as soon as you have flipped *all* the bits, it collapses back to 0
04:20:58 <ertes> that's quite interesting
04:21:09 <LKoen> you're left with that carry at infinity though
04:21:25 <Cale> The right way to check what happens is to use the metric explicitly
04:22:03 <LKoen> ertes: not unrelated, https://www.youtube.com/watch?v=MqUWS4o_nkY
04:22:09 <Cale> and see if the sequence {1.1, 11.11, 111.111, ...} converges
04:22:12 <ertes> am i?  by "â¦111111.111111â¦" i mean the sum of the number Cale gave (sum 2^n for n â â) and the number i gave (sum 2^(-n - 1) for n â â)
04:22:35 <Cale> You have to be careful about the limit in cases like this
04:23:09 <Cale> The result may (in principle at least) depend on the way in which you let the bounds grow
04:23:45 <Cale> If you let the lower bound of summation grow faster toward -infinity than the upper bound grows to infinity, then perhaps you obtain a different result
04:24:16 <Cale> (at least, a priori)
04:24:49 <Cale> So I picked the balanced one, where the lower bound of summation is -M and the upper bound is M
04:25:05 <Cale> and so our partial sums will be 2^(M+1) - 2^(-M)
04:26:20 <Cale> and now in order to make sense of this, we'll actually need the 2-adic norm on the rationals
04:31:41 <Cale> Nope, I don't think it converges, actually.
04:34:30 <Cale> We can rearrange that to (2^(2M + 1) - 1) / (2^M), so its valuation is v((2^(2M + 1) - 1) / (2^M)) = v((2^(2M + 1) - 1) - v(2^M) = 0 - M
04:35:31 <Cale> So if x = (2^(2M + 1) - 1) / (2^M), then |x| = 2^-v(x) = 2^M, which is growing, rather than shrinking as we'd like.
04:37:29 <Cale> and even more unfortunately, it's hard to imagine that it depends on my choice of bounds, having seen the calculation
04:37:39 * hackagebot decimal-arithmetic 0.2.0.0 - An implementation of Mike Cowlishaw's  General Decimal Arithmetic Specification  https://hackage.haskell.org/package/decimal-arithmetic-0.2.0.0 (RobLeslie)
04:38:07 <Cale> ^^ hah, kind of relevant :)
04:38:19 <Cale> (hackagebot)
04:39:18 <LKoen> ohhhh do tell me someone lost a lot of money because of an unfortunate decimal->binary conversion
04:39:55 <Cale> Well, we were talking about series expansions of numbers :)
04:40:12 <Cale> (in this case, a bit more exotic perhaps than the usual decimal expansion)
04:40:19 <LKoen> it's a bit weird though because fixed-point should fix any problem in finances
04:40:39 <merijn> Or just use integer with a sufficiently small denomination
04:41:21 <LKoen> merijn: isn't that how fixed-point works?
04:41:35 <LKoen> if it isn't then my understanding of fixed-point has been wrong for years
04:41:56 <Cale> Well, once you pick a denomination which is 10^-k
04:42:02 <merijn> LKoen: I've seen fixed point implementations using separate before and after dot numbers
04:42:10 <LKoen> oh
04:42:22 <Cale> you're basically doing decimal arithmetic then
04:42:23 <LKoen> that sounds unhelpfully complicated
05:00:30 <meinteil> Stupid question perhaps, but is the United Kingdom a country or not? England, Wales Scotland and Northern Island are the countries right?
05:01:04 <alercah> they're countries in one state
05:01:05 <meinteil> Has the killer app been written in Haskell yet? I leanred Haskell around 2009 and it seems not much have happened in terms of adoption...am I wrong?
05:02:23 <tdammers> unpopular opinion: if you need a killer app in order to be convinced, use Ruby instead
05:03:30 <tdammers> anyway, I don't have any numbers, but my impression is that Haskell adoption in the industry has seen quite a boost recently, but much of it is happening behind closed doors
05:03:53 <maerwald> tdammers: where does that impression come from?
05:04:24 <tdammers> maerwald: general quality of the ecosystem, conversations I'm overhearing, job openings being posted, the occasional tech blog
05:04:36 <maerwald> tdammers: weird, I don't see any job posting in haskell
05:05:22 <tdammers> maerwald: it's still tiny, mind you - the boost may be big, but relative
05:05:26 <boj> maerwald: reddit, or functionjobs tends to have a random post or two show up
05:05:38 <Myrl-saki> I'm making a comment system in Haskell, this is what I did. http://ix.io/160j
05:05:51 <merijn> Because, like many other desirable jobs, they often get filled through networks than jobhunting sites
05:05:59 <tdammers> indeed
05:06:03 <merijn> reddit, haskell-cafe and similar see a fair amount of jobs
05:06:06 <Myrl-saki> Is there a better way to do that?
05:06:12 <Myrl-saki> I of course want it to be rose trees.
05:06:12 <merijn> I hear about even more jobs through the grapevine
05:06:16 <tdammers> more than half the haskell jobs I've seen in the past year were never posted publicly
05:06:20 <tdammers> I got approached directly
05:06:33 <merijn> If you have a skilled haskell team you're not gonna scrape the bottom of the linkedin barrel for applicants
05:06:36 <Myrl-saki> Also, if I do it like that, then the JSON and the database data wouldn't be seamless.
05:06:43 <liste> Myrl-saki: wouldn't parent be CommentId Maybe?
05:06:53 <merijn> You're gonna reach out to people and go through their network of people
05:06:53 <Myrl-saki> liste: True.
05:07:08 <maerwald> tdammers: my impression is that haskell is settling on a very tiny niche and will not really go far beyond that in industry
05:07:29 <merijn> maerwald: And this matters, because?
05:07:34 <Myrl-saki> liste: Is there a better way to do it anyway? I want the types between JSON and the DB to be seamless?
05:07:38 <maerwald> merijn: ?
05:07:42 <tdammers> if the niche is "quality programming", I'm perfectly fine with that
05:07:51 <merijn> maerwald: How does the size of the niche in industry matter?
05:08:08 <tdammers> merijn: because the topic was "Haskell adoption in the real world"
05:08:29 <Myrl-saki> Apparently, there is a persistlist.
05:08:34 <liste> Myrl-saki: I'd make a type out of comment poster
05:08:43 <liste> that way, it's easier to add fields later
05:08:48 <tdammers> I do, however, see a recent trend away from dynamic languages and back towards more rigid compile-time constraints
05:08:58 <merijn> tdammers: The only parts of adoption I care about are "demand vs supply" and availabiity of interesting jobs
05:09:34 <tdammers> merijn: unfortunately, the situation is such that I'm currently back to Python, JS, and C++
05:09:44 <maerwald> tdammers: hmm, javascript, php and C are still in the top5 according to the tiobe index
05:09:58 <maerwald> C# is also very popular in job descriptions
05:10:02 <tdammers> maerwald: it's a trend, not absolute numbers
05:10:36 <tdammers> a few years ago, it looked like typed programming was dead entirely - everyone jumped on the JS / Python / Ruby bandwagon and left stuff like C++ and Java behind
05:10:38 <maerwald> tdammers: well, I don't see that trend in job descriptions, but ymmv
05:11:15 <tdammers> publicly visible job descriptions might not be the best metric
05:11:25 <maerwald> that's the metric I care about though
05:11:30 <tdammers> why?
05:11:35 <maerwald> because I want jobs?
05:11:58 <tdammers> yes, but why do you insist on restricting yourself to publicly visible job postings?
05:12:25 <maerwald> I don't understand what you mean by that
05:12:50 <tdammers> there are other ways of finding a job, and they all have better success rates than applying on a puublic job posting
05:12:52 <merijn> maerwald: That many times job openings get distributed along twitter, over IRC, in person, email
05:13:23 <maerwald> tdammers: but that's not a good metric, is it?
05:13:27 <tdammers> the result of that is that public job postings are biased towards the low end of the quality spectrum
05:13:50 <Myrl-saki> Err...
05:13:52 <Myrl-saki> wtf
05:13:56 <Myrl-saki> gg.
05:14:03 <Myrl-saki> "        Comment: a self reference must be a Maybe
05:14:18 <Myrl-saki> I used a list.
05:14:18 <tdammers> excellent programmers are in such high demand that they rarely appear on the job market; and awesome jobs tend to be filled without having to resort to recruiters or public posting
05:14:19 <Myrl-saki> >.<
05:14:51 <Myrl-saki> To be fair, it's fine like this since I can omit it from the fields.
05:14:56 <Myrl-saki> because Json
05:14:57 <tdammers> so public job postings are biased towards crap programmers and crap jobs
05:15:01 <Myrl-saki> I'll put it as an issue anyway.
05:15:18 <tdammers> and, by extension, crap technologies, crap methodologies, crap company cultures, etc.
05:15:20 <maerwald> tdammers: mh, I see quite a lot of awesome job postings: https://galois.com/careers/#careers-list
05:15:25 <maerwald> as an example
05:15:38 <liste> Myrl-saki: you want an one-to-many relationship, I guess?
05:15:52 <tdammers> I said "biased". Which implies exceptions.
05:15:55 <liste> a list self-reference would be many-to-many
05:16:26 <Myrl-saki> liste: Hmmm
05:16:36 <Myrl-saki> liste: How is it many-to-many?
05:17:28 <maerwald> tdammers: I don't really believe that the number of "hidden" awesome haskell jobs is that much bigger than in another field, so for the metrics it doesn't really matter much
05:18:00 <Myrl-saki> liste: http://ix.io/160v
05:18:06 <liste> Myrl-saki: C1.children = [C3, C4], C2.children = [C3, C4]
05:18:22 <tdammers> I'm perfectly convinced that the percentage of "awesome" jobs is higher among hidden jobs than among public ones
05:18:54 <tdammers> and I'm also convinced that the probability of Haskell being involved is roughly proportional with the awesomeness of a job
05:19:04 <Myrl-saki> liste: Oh, right.
05:19:09 <tdammers> statistical noise notwithstanding
05:19:10 <Myrl-saki> liste: Well, that kinda sucks.
05:19:12 <liste> Myrl-saki: just keep the parent reference and let persistent invert the references for JSON output
05:19:39 <maerwald> tdammers: well, I nwas talking about the amount of awesome hidden jobs compared to other languages. If it's the same, then the hidden jobs can be ignored for the metrics.
05:19:40 <Myrl-saki> liste: Kinda too much work for my part. =_=
05:20:16 <liste> Myrl-saki: not really, it's really no work
05:20:31 <Myrl-saki> liste: Can you explain?
05:20:33 <tdammers> maerwald: no, it can't. If awesomeness correlates with hiddenness, and also with haskellness, then it logically follows that haskellness and hiddenness also correlate
05:21:05 <zomg> I suspect that popularity of a language and the number of hidden jobs are reverse proportional
05:21:06 <maerwald> tdammers: I cannot follow that logic
05:21:09 <zomg> :P
05:21:20 <zomg> smaller community -> more likely to hire by reference
05:21:29 <meinteil> in a list of west european countries, should England, Wales, Scotland and Northern Ireland be separate countries or should only United Kingdom be listed?
05:21:32 <Myrl-saki> man.
05:21:45 <Myrl-saki> how do you guys get hired? ._.
05:21:47 <zomg> erm, inversely proportional even
05:21:47 <ongy> meinteil: wait for a few years, then it's seperate
05:22:05 <merijn> meinteil: Depends on the purpose of the list
05:22:09 <boj> tdammers: how do these hidden jobs select? seems they lean heavily on publicly available code and/or how visible the person is in the community
05:22:10 <tdammers> maerwald: I'll dumb it down. 1. The more awesome a job, the more likely it is to be filled before it gets posted publicly
05:22:22 <merijn> meinteil: Also, most available list of countries are out of date anyway
05:22:26 <maerwald> tdammers: that's still irrelevant for the metrics point I made
05:22:32 <merijn> boj: Networking
05:22:38 <boj> hmm, indeed
05:22:48 <zomg> the networking case is kinda shit
05:22:52 <Myrl-saki> liste: Oh right.
05:22:56 <zomg> live in some empty corner of the world? you're shit out of luck
05:22:56 <zomg> :P
05:22:56 <tdammers> boj: the way I've seen it work most of the time is that someone recommends someone, and often the interview is mostly just a technicality after that
05:22:58 <Myrl-saki> liste: I remember my biggest gripe with this.
05:23:04 <tdammers> maerwald: hear me out
05:23:07 <Myrl-saki> liste: Also, I think you're wrong.
05:23:08 <boj> i have a project i am building in a vacuum though, quite huge, quite far along. not sure networking helps me
05:23:10 <merijn> boj: Someone currently working the job is presumably involved in the community and knows people/follows people on twitter :)
05:23:22 <Myrl-saki> liste: And at the same time, my shit is bad.
05:23:23 <tdammers> maerwald: 2. the more awesome a job, the more likely it is that Haskell is involved
05:23:26 <merijn> boj: Talking to people here, on haskell-cafe and twitter qualifies as networking :)
05:23:27 <boj> yeah, that makes sense
05:23:39 <maerwald> tdammers: now that's just your personal opinion and matters even less for metrics
05:23:58 <ongy> twitter -.-
05:24:04 <tdammers> maerwald: it's a suspicion I'm having, and my observations seem to support them
05:24:09 <Myrl-saki> liste: Since a single comment is instead one database object.
05:24:16 <tdammers> maerwald: of course if those suspicions are incorrect, none of that holds
05:24:20 <merijn> ongy: I see plenty of openings in various field come bu on twitter :)
05:24:23 <tdammers> maerwald: but I believe they probably hold
05:24:23 <maerwald> tdammers: that's too much "suspicion" and "feeling" to me
05:24:31 <Myrl-saki> liste: I'll just go with what you said but I'm not formatting the JSON either. I think it's best to keep it that way.
05:24:43 <tdammers> maerwald: that's because "awesome" is hard to quantify
05:25:16 <tdammers> it is, however, crystal clear that public job openings are about the least efficient way of finding a job or filling a position well
05:25:41 <maerwald> tdammers: you are basically saying "I like haskell a lot, so awesome jobs will probably invole haskell, which means that the number of awesome hidden jobs for haskell is higher than for e.g. javascript and thus public job descriptions don't hold as a useful metrics"
05:25:43 <Myrl-saki> liste: Formatting it would mean overriding `instance ToJSON x => ToJSON [x] ...`
05:25:46 <maerwald> which I find completely false
05:25:55 <tdammers> so it's reasonable to assume that "better" jobs, by whichever metric, are more likely to appear under the radar than publicly
05:26:15 <tdammers> awesome <-> haskell is a more debatable correlation
05:26:26 <tdammers> but awesome <-> hidden is pretty logical
05:26:34 <maerwald> there's no useful indication that haskell has more awesome hidden jobs than e.g. C
05:26:49 <tdammers> of course not
05:27:05 <maerwald> which means public job descriptions ARE a useful metric
05:27:12 <ongy> maerwald: I thing the community sice argument holds
05:27:43 <tdammers> the second part of the argument rests on the observation that bad programmers seldomly stick with Haskell (or other off-mainstream languages)
05:27:58 <ongy> tdammers: and then there's me
05:28:32 <merijn> ongy: The logical conclusion is that you must be awesome too ;)
05:28:37 <tdammers> we cannot easily quantify that observation, but that doesn't make it entirely useless
05:28:47 <maerwald> tdammers: how does any of that correlate with "bad programmers"?
05:29:04 <tdammers> bad jobs hire bad programmers
05:29:16 <tdammers> because they have to
05:29:20 <maerwald> and how is that relevent for the metrics?
05:29:23 <tdammers> because the good programmers won't bite
05:29:26 <merijn> I'd rather say: Good programmers don't get themselves hired by bad jobs :p
05:30:03 <tdammers> so, statistically: bad programmers <-> not haskellers; bad programmers <-> bad jobs; bad jobs <-> public job postings
05:30:47 <tdammers> the missing link is that because bad jobs have to hire whatever they can get their hands on, they can't afford to use haskell
05:31:01 <maerwald> tdammers: so, C is for bad programmers?
05:31:07 <tdammers> no, it's not
05:31:25 <tdammers> but bad C programmers are easier to hire than bad haskellers
05:31:44 <tdammers> good C programmers are just as hard to hire as good Haskell programmers
05:31:48 <merijn> Is it because everyone is a bad C programmer? :)
05:32:00 <tdammers> merijn: I think you're thinking of PHP
05:32:18 <merijn> tdammers: I'm doing C right now, pretty sure I'm thinking of C :p
05:32:32 <maerwald> tdammers: so there is no significant difference in the relative number of awesome hidden job postings between haskell and C?
05:32:53 <mfukar> maerwald, how do you count "hidden" job postings? :)
05:33:02 <maerwald> mfukar: no idea, tdammers started it
05:33:16 <maerwald> and he seems to have a feeling for it, I don't know
05:33:28 <mfukar> ah. Just as well. I'd be interested in case it can be applied to "hidden" bugs.
05:34:00 <merijn> mfukar: Extrapolation from experience: i.e. how many job postings do I encounter that are not public divided by total number of haskell postings (the ones you encountered + public)
05:34:13 <maerwald> I think hidden job postings are completely useless as metrics when we talk about trends in the industry.
05:34:27 <tdammers> maerwald: ideally, you want to count *all the jobs*
05:34:35 <tdammers> open or not, publicly posted or not
05:34:51 <mfukar> tdammers, if a posting is private, does it exist?
05:34:52 <boj> mfukar: ask the bugs if they network ;)
05:34:53 <tdammers> but you can't see them all, you can only see the ones that are 1) currently open, and 2) publicly posted
05:34:54 <maerwald> tdammers: you are just presenting a lot of guessing about what awesomeness is, what bad/good programmers are etc
05:35:00 <maerwald> I think that's far beyond any useful metrics
05:35:21 <mfukar> boj: "like LinkedIn...but for bugs!" ;)
05:35:34 <merijn> mfukar: LinkedIn doesn't count for networking >.>
05:35:35 <maerwald> if you look at public job postings, you don't see any significant increase of haskell job postings
05:35:45 <mfukar> :(
05:35:48 <tdammers> all I'm saying is that the percentage of Haskell jobs in public postings does not necessarily match the percentage of Haskell usage in the industry overall (in man-hours, value created, number of workers, or whatever you want)
05:36:05 <maerwald> tdammers: yes, it's not exact science...
05:36:09 <maerwald> but better than "gut feeling"
05:36:25 <Rotaerk> isn't it more accurate to compare the IRC channel counts? *cough*
05:36:51 <Rotaerk> 1421 vs ##csharp's 472
05:36:54 <tdammers> it's not just inexact, I suspect that there's an actual bias, and that's not just based on a gut feeling, but on actual working experience in the industry (both Haskell and non-Haskell), as well as observations
05:37:13 <maerwald> that's all personal stuff
05:37:41 * hackagebot extra 1.5 - Extra functions I use.  https://hackage.haskell.org/package/extra-1.5 (NeilMitchell)
05:38:39 <tdammers> I see zero Haskell jobs on monsterboard and linkedin; but they exist, I've seen them, I get approached for Haskell jobs
05:39:03 <tdammers> so from what I get to see, Haskell is objectively underrepresented in public postings
05:39:53 <maerwald> how is that "objectively"?
05:40:07 <maerwald> for that, you need actual numbers
05:40:45 <boj> tdammers: my interest is only tangential to what you two are discussing, but what qualifications do you have which made people consider approaching you?
05:40:51 <merijn> ok, this discussion has gone long enough that I think it's really no longer on topic for #haskell and should be moved elsewhere
05:41:05 <merijn> boj: In my case: talking in here a lot >.>
05:41:18 <boj> merijn: interesting, that alone?
05:41:41 <merijn> boj: Well, that, and not seeming incompetent ;)
05:44:04 <tdammers> merijn: agree; also, it starts getting on my nerves
05:57:44 <quchen> jaspervdj: Hey, is there some get-together in ZÃ¼rich this evening like last year? Haven't heard anything.
05:58:47 <quchen> My net is pretty sketchy on the train though, I might not see the a response. In that case, mail me (http://hackage.haskell.org/package/stgi -> email) if you can! :-)
05:59:00 <ertes> are Weak pointers a good way to attach finalisers to pure values?  or should i use ForeignPtr?
05:59:30 <ertes> use case:  a pure number computed via FFI that has to be released when it goes out of scope
05:59:49 <merijn> ertes: You can use MVar/TVar too
06:00:06 <merijn> But yes, if you have a ForeignPtr that is probablybetter
06:00:38 <ertes> merijn: performance is critical, and all i need is a finaliserâ¦  is there a technical reason why ForeignPtr is better?  it seems to make everything a lot more complicated
06:00:45 <lpaste> mnoonan pasted âInference with type familiesâ at http://lpaste.net/170944
06:01:26 <mnoonan> ^ is there a way to convince ghc of the fact that INT (Maybe t) ~ Maybe (INT t) to make that program typecheck?
06:01:53 <merijn> ertes: Foreign pointers are fairly immediate in running finalisers, afaik. Weak pointers have...dubious reliability in case the things they're attached to gets unboxed/inlined/whatever
06:02:11 <ertes> i see
06:02:15 <ertes> yeah, makes sense
06:02:24 <thewormkill> mnoonan: how I see it, you have a cycle there, no?
06:02:36 <thewormkill> is that what you want?
06:02:47 <thewormkill> ah, nvm
06:02:49 <thewormkill> I misread
06:04:06 <thewormkill> I think your problem is that you define a value constructor called Maybe
06:04:29 <Cale> I agree, that's the main problem :)
06:05:00 <Cale> Class associated data declarations introduce data constructors just like ordinary data declarations do.
06:05:11 <thewormkill> I learned that the hard way ^^
06:05:35 <thewormkill> made me feel stupid for a week or so afterwards
06:05:43 <mnoonan> oh! I wanted a type-level function in the class, not a data declaration.
06:05:49 <merijn> thewormkill: Learning things the hardway is a good way not to forget them ;)
06:06:09 <nitrix> ertes: It's guaranteed the finaliser for weak pointers will run, but it's not precise `when` nor in what order. There is a benefit though, mutually recursive weak pointers & finalizers don't prevent each others from being collected.
06:06:13 <thewormkill> yes, indeed. One can, however, make it too hard ;)
06:06:15 <nitrix> ertes: IIRC. http://community.haskell.org/~simonmar/papers/weak.pdf
06:07:15 <ertes> nitrix: actually ForeignPtr is a more sensible choice for other reasons, too, so i'm going with that one =)
06:07:28 <ertes> but thanks
06:07:32 <nitrix> ertes: Probably a wise choice.
06:09:14 <lpaste> mnoonan revised âInference with type familiesâ: âInference with type familiesâ at http://lpaste.net/170944
06:10:14 <mnoonan> data -> type family, which I think is what I wanted, but now a different error. Is there a type annotation I can stick in to make it happy?
06:16:58 <Cale> mnoonan: You probably need a proxy argument
06:18:08 <Cale> mnoonan: Consider what happens when you have, for example
06:18:26 <Cale> data A = A Int; data B = B Int
06:19:10 <Cale> instance Rep A where type INT A = Int; fromInt = id
06:19:24 <Cale> instance Rep B where type INT B = Int; fromInt = (*2)
06:19:47 <Cale> Now, suppose I try to use fromInt at type Int -> Int
06:19:56 <Cale> How is it supposed to know which instance to choose?
06:20:23 <mnoonan> I guess I was assuming the "Rep a =>" instance constraint was considered
06:20:34 <Cale> It most certainly is not
06:20:50 <Cale> Constraints on instances are only considered after the instance is committed to.
06:21:00 <mnoonan> ah
06:21:34 <Cale> But also, it wouldn't even necessarily help here if they were
06:22:28 <Cale> I could go on and define another instance of Rep for some type X and for which  type INT X = Maybe X
06:22:35 <meinteil> in a list of west european countries, should England, Wales, Scotland and Northern Ireland be separate countries or should only United Kingdom be listed?
06:22:44 <Cale> meinteil: wrong channel
06:26:01 <Cale> mnoonan: Then supposing we tried fromInt :: Int -> Maybe X, and supposing it just searched through all the instances for us, looking for ones which apply (rather than immediately complaining that it has no basis on which to really look) we'd know we were searching for an instance where the type INT a would unify with Maybe X
06:26:21 <Cale> and of course, that instance I gave above would do the trick, but also this instance for Maybe would
06:27:27 <Cale> Oh, I suppose we'd also need to have an instance for which INT a was X
06:27:29 <mnoonan> Cale: I see, that makes sense.
06:27:35 <Cale> but yeah, this kind of search is not something that it does
06:27:50 <Cale> It does only type-directed searching, basically pattern matching on the type constructors
06:28:33 <Cale> This also is important to making it possible to understand which instance will be selected when you start putting instances in various separately-compiled modules
06:29:04 <Cale> Various aspects of how it's designed are meant to ensure that the selection of which instance to use are coherent throughout a program composed of many modules
06:29:43 <mnoonan> I've been too corrupted by type-level hackery in C++ that is all about the surrounding context :|
06:29:49 <Myrl-saki> entityIdToJSON :: (PersistEntity record, ToJSON record, ToJSON (Key record)) => 
06:29:51 <Myrl-saki> Woops
06:29:56 <Myrl-saki> entityIdToJSON :: (PersistEntity record, ToJSON record, ToJSON (Key record)) => 
06:29:56 <Cale> Which is part of why it can't consider the class constraints on instances when deciding which instance to use
06:30:00 <Myrl-saki> errr, wtf. emacs
06:30:10 <Myrl-saki> $(deriveJSON defaultOptions{omitNothingFields = True} ''(Entity Comment))
06:30:21 <Cale> because if it did, maybe new instances become available in future modules, changing the decisions it would have made, after it already compiled code for previous modules
06:30:22 <Myrl-saki> I get a "parse error on input"
06:30:57 <Cale> Myrl-saki: Perhaps try putting more of your code and the complete error up on lpaste.net
06:31:08 <Cale> oh
06:31:28 <tsahyt> is there a library providing graph search algorithms in full generality, i.e. they take functions for successors, etc.?
06:31:31 <Cale> hm, is that ''(...) allowed?
06:31:35 <Cale> I don't think that's a thing, is it?
06:31:38 <tsahyt> quite like the astar library but for different algorithms
06:31:46 <Myrl-saki> Cale: Yeah. It's more of a "how should I do it?"
06:31:53 <Myrl-saki> Cale: newtype?
06:32:03 <Myrl-saki> err
06:32:05 <Myrl-saki> type synonym*
06:32:26 <Cale> I don't know if that'll work
06:32:51 <Myrl-saki> unsupported type.
06:32:56 <Cale> I suppose you could try it with FlexibleInstances and TypeSynonymInstances turned on
06:33:33 <Cale> But I'm not even sure you're allowed to apply '' to a type synonym
06:34:06 <Myrl-saki> nope.
06:34:31 <Myrl-saki> I wonder how I'd do this then.
06:34:55 <Cale> tsahyt: Interesting idea
06:35:24 <Myrl-saki> I'd want to do the json postfix on the persistent datatype instead, but it doesn't seem to omit Nothing.
06:36:00 <Myrl-saki> I guess I can do it manually.
06:36:19 <Myrl-saki> that'stiringthough. :(
06:36:34 <Cale> It's a little bit annoying that deriveJSON takes a Name
06:37:05 <tsahyt> Cale: fgl has functions that are sufficiently general to make dfs etc do pretty much whatever you want, but it requires usage of the provided graph representations. But I can define the graph implicitly in my case and I'm losing quite a bit of performance by building the graph explictly, especially because it's part of an iterative algorithm that does rebuilding and search in each iteration.
06:37:21 <tsahyt> but I can't find anything on hackage that fits the bill
06:38:07 <Cale> tsahyt: I wish I could say I wrote astar as a result of a similar such need, but really I just wrote it as an exercise.
06:38:39 <tsahyt> Cale: astar is nice to use though. Unfortunately it doesn't work for graphs that contain loops.
06:38:48 <Cale> Wait, what?
06:38:51 <Cale> It really ought to
06:38:59 <tsahyt> loop as in a node being its own successor
06:39:05 <Cale> oh
06:39:13 <tsahyt> https://github.com/weissi/astar/issues/1
06:39:20 <Cale> er, yeah, I never tried it on such a graph I suppose
06:40:18 <Cale> It would be easy to fix that bug at the expense of a little bit of time, just by adjusting the neighbours function that's passed in.
06:40:32 <tsahyt> well it's not like such loops would ever be taken into an optimal path anyhow
06:40:37 <Cale> right
06:40:38 <tsahyt> assuming costs > 0
06:40:51 <Cale> so you can just delete them from the neighbour set without thinking about it
06:41:01 <Cale> Perhaps it should do this
06:41:17 <Cale> I see Johannes put the code on github
06:41:36 <tsahyt> it's the repo linked from the hackage package iirc
06:41:39 <Cale> I basically handed the maintainership over to him since he seemed interested.
06:41:56 <Cale> I'm terrible at using github etc.
06:42:59 <tsahyt> I only ever use it to report issues. I've got a personal git server for all my own projects
06:43:19 <tsahyt> none of which ever made it to release
06:43:30 <tsahyt> some of them just require a little bit of cleanup
06:44:16 <tdammers> my projects are a mess, scattered across github, bitbucket, and my own git server
06:47:43 * hackagebot type-functions 0.2.0.4 - Emulation of type-level functions  https://hackage.haskell.org/package/type-functions-0.2.0.4 (WolfgangJeltsch)
06:48:34 <Cale> hmm, it's sort of unfortunate that Data.Set doesn't seem to have an O(log n) operation for doing a filter/partition by a predicate that is guaranteed to be monotone
06:49:11 <tsahyt> monotone in what way?
06:49:32 <hpc> monotone in the comparison that Set uses to efficiently store elements
06:49:50 <Cale> In the sense that whenever x <= y then p x <= p y
06:50:17 <hpc> Cale: you should write it and submit it as a patch
06:50:34 <Cale> Maybe...
06:50:37 <hpc> there's some other functions in that module already that assume monotonicity and are marked unsafe-ish
06:50:43 <Cale> Yeah, mapMonotonic
06:50:47 <hpc> so it's likely to be accepted
06:51:02 <hpc> and then you get to take ownership of that module for the rest of time
06:51:06 <Cale> lol
06:51:56 <Cale> See, this is why I'm more likely to just nudge dfeuer
06:54:02 <Zemyla> Why does lambdabot still use the old transformers version of Data.Functor.Classes?
06:54:28 <cocreature> probably because nobody has updated lambdabot to use the new transformers version
06:54:47 <cloudhead> is there something like Map.adjust where the adjustment function is (a -> m a)? or a version of mapM that works on a single entry in a traversable?
06:55:04 <cloudhead> I keep on having this pattern come up
06:56:28 <hpc> Traversable doesn't expose a generic way to index into a structure
06:56:35 <hpc> you'll likely just have to write it yourself
06:57:15 <hpc> not everything has a *M and *M_ version included
06:57:29 <cocreature> writing it yourself if the constructors are not exposed is not that easy
06:57:51 <cloudhead> ok, thanks
06:58:02 <hpc> Map has indexing and overwriting though, so it's easy in this case
06:58:21 <hpc> usually the only times i will find it hard is when it's impossible anyway
06:58:34 <cloudhead> yeah seems like have to do a Map.lookup and then Map.insert
07:00:30 <lyxia> cloudhead: It's an open issue https://github.com/haskell/containers/issues/278
07:00:57 <cloudhead> ohh
07:00:59 <cloudhead> good to know
07:07:44 * hackagebot stm-containers 0.2.14 - Containers for STM  https://hackage.haskell.org/package/stm-containers-0.2.14 (NikitaVolkov)
07:11:58 <jackhill> Hi, I would like to do some calendar arithmatic, like calculating what the date was 180 days ago. What package should I use?
07:12:21 <tsahyt> @hackage thyme
07:12:21 <lambdabot> http://hackage.haskell.org/package/thyme
07:12:21 <Cale> time
07:12:24 <tsahyt> or time
07:13:37 <tsahyt> "UTCTime is not Y294K-compliant" might be my new favorite quote from API documentations
07:13:47 <Cale> http://hackage.haskell.org/package/time-1.6.0.1/docs/Data-Time-Calendar.html
07:13:51 <tsahyt> well I suppose it's good that somebody worries about future compatibility issues
07:14:35 <ongy> 294k? Is that when 64bit epoch wraps?
07:15:37 <Cale> getCurrentTime in Data.Time.Clock will give you a UTCTime, to which you can apply utcToLocalTime along with a TimeZone from Data.Time.LocalTime to get a LocalTime, and apply localDay to that to get a Day
07:16:35 <tsahyt> ongy: 64 bit should provide dates much much further in the future than a mere 300k years
07:16:49 <tsahyt> according to wikipedia it's 293 billion years in both directions from epoch
07:17:12 <ongy> that sounds reasonable, then why does UTCTime fail?
07:17:20 <tsahyt> no idea to be honest
07:17:23 <tsahyt> http://hackage.haskell.org/package/thyme-0.3.5.5/docs/Data-Thyme-Calendar.html
07:17:27 <tsahyt> this is where I've found it
07:17:34 <Cale> Oh, that's a Data.Thyme problem
07:17:42 <hpc> it's utctDay :: Day that does it
07:17:46 <tsahyt> ongy: because it counts microseconds from epoch
07:17:49 <Cale> Because they use Int instead of Integer for Day there
07:17:57 <Cale> er
07:18:08 <hpc> oh, no it isn't
07:18:48 <tsahyt> ongy: standard unix time counts seconds. so UTCTime has 1/1000th of the span
07:19:00 <tsahyt> no wait
07:19:09 <tsahyt> a millionth
07:19:25 <ongy> which makes billions thousands
07:19:49 <Cale> Anyway, Data.Thyme replaces lots of stuff with Int-based things which induces bounds
07:20:01 <Cale> (but makes it a bit faster)
07:21:09 <infandum> What *should* be faster:  (Map.fromListWith (Vector.++) . fmap (\(x, y) -> (x, Seq.singleton y) (xs :: [(String, a)])) or (Map.map Foldable.toList . Map.fromListWith (Sequence.><) . fmap (\(x, y) -> (x, Seq.singleton y)) (xs :: [(String, a)]))?
07:21:49 <infandum> That is, is it faster to convert to Sequence and back JUST for a bunch of concatenations or is it faster to just append them in Vector?
07:23:23 <shapr> kosmikus: are you organizing MuniHac?
07:24:18 <tdf>  /njs
07:24:54 <kosmikus> shapr: not alone, but yes
07:25:08 <shapr> awesome! Good time to be in Munich :-)
07:25:26 <kosmikus> shapr: are you?
07:27:26 <shapr> kosmikus: probably not, when is MuniHac?
07:30:56 <no_hate> how much RAM is hackage using with its acid-state?
07:37:44 <ongy> shapr: 2nd of september to 4th
07:41:12 <ongy> hm, is there something *better* than termina-ansi for terminal colours? more spcifically, 256 colour support
07:44:20 <shapr> ongy: ah, I won't be in Munich for that
08:12:46 <jackhill> tsahyt, Cale: thanks (and sorry for the delay, I got distracted
08:26:46 <jeltsch> I am trying to install a package, but cabal-install hangs during installing a dependency.
08:27:17 <jeltsch> It shows:
08:27:20 <jeltsch>     Ready to install syb-0.6
08:27:22 <jeltsch>     Downloading syb-0.6...
08:27:24 <jeltsch>     Waiting for install task to finish...
08:27:28 <jeltsch> Any ideas what I can do?
08:27:33 <jeltsch> hackage.haskell.org seems to be alive.
08:30:16 <jeltsch> Hmm, when retrying, it worked.
08:30:23 <jeltsch> Maybe some temporary server failure.
08:30:38 * jeltsch thinks that for #haskell, it is very silent here.
08:32:12 <ongy> jeltsch: you should have a look into the backlog
08:32:23 <jeltsch> ongy: What backlog?
08:32:28 <jeltsch> Server? Client?
08:32:59 <ongy> wherever you have one (just for the silent thing, I don't know if anything is interesting to you)
08:33:44 <jeltsch> Hmm.
08:37:47 * hackagebot type-equality-check 0.0.0.4 - Type equality check  https://hackage.haskell.org/package/type-equality-check-0.0.0.4 (WolfgangJeltsch)
08:38:44 <joeyh> anyone know if hackage allows two packages with names that only vary in capitalization to both be uploaded?
08:39:38 <jeltsch> joeyh: I do not know, but suppose it does, because package names are case sensitive.
08:40:26 <ClaudiusMaximus> there are both 'safe' and 'Safe' on hackage
08:41:21 <glguy> and as it happens Safe is deprecated in favor of safe
08:41:27 <ClaudiusMaximus> indeed
08:41:32 <joeyh> and, cabal install safe installs Safe because it has a higher version number
08:41:47 <joeyh> so, if I upload quickcheck-999999 , cabal install quickcheck behavior will change..
08:41:47 <Zemyla> If you have a bifunctor, then can you use ana- and catamorphisms to implement fmap on Mu (f a) = f a (Mu f a)?
08:42:17 <glguy> joeyh: When I type "cabal install safe" it doesn't attempt to install Safe
08:42:35 <glguy> nor the other way around
08:42:37 <Zemyla> Like, mufmap :: Bifunctor f => (a -> b) -> Mu (f a) -> Mu (f b)?
08:43:53 <joeyh> glguy: ah, ok, so it only falls back to case insensativity when there's not a tie, I think
09:07:27 <clarkenciel> is HaXml the right choice for html parsing?
09:08:32 <hpc> probably html-conduit or something like that
09:09:46 <SAL9000> Would Haskell be a good choice of language for writing a FUSE filesystem?
09:10:34 <hpc> possibly
09:10:55 <clarkenciel> ah thanks hpc 
09:11:29 <hpc> it depends on how comfortable you would be dealing with FFI, and how uncomfortable the api is
09:11:48 <dmj`> question :: String -> Bool; question x = "Would haskell be a good " `isPrefixOf` x
09:12:22 <SAL9000> :-)
09:12:33 <ongy> dmj`: "Would haskell be a good thing to never touch?"
09:12:53 <mauke> Would haskell be a good name for my dog
09:13:24 <hpc> SAL9000: at a very cursory glance through libfuse, it seems like you would be fine
09:13:27 <hpc> https://github.com/libfuse/libfuse/blob/master/include/fuse.h
09:13:45 <SAL9000> hpc: I was thinking of using existing bindings; http://hackage.haskell.org/package/HFuse-0.2.1/docs/System-Fuse.html
09:13:46 <hpc> (relative to whatever nightmares are just inherent to writing your own filesystem, of course)
09:14:28 <hpc> oh neat
09:15:02 <SAL9000> I'm planning to implement a checksumming layered filesystem
09:15:24 <hpc> give it a try, let us know how it goes
09:16:19 <mniip> type family Ask (q :: Symbol) where Ask _ = Maybe
09:18:22 <mniip> hmm
09:18:32 <mniip> dependent kinding lets us write kindclasses :o
09:19:51 <slack-haskell> <erikr> SAL9000: check out HFuse: https://hackage.haskell.org/package/HFuse
09:20:22 <SAL9000> erikr: I have, looking at their examples now. Thanks anyway, though!
09:26:30 <LKoen> is there a standard library function   (a -> c) -> (b -> d) -> (a, b) -> (c, d) ?
09:26:44 <mniip> :t bimap
09:26:45 <lambdabot> Bifunctor p => (a -> b) -> (c -> d) -> p a c -> p b d
09:26:48 <mniip> :t (***)
09:26:50 <lambdabot> Arrow a => a b c -> a b' c' -> a (b, b') (c, c')
09:26:57 <johnw> ***
09:27:17 <johnw> ah, right
09:27:19 <mniip> they coincide for the (->) arrow and the (,) bifunctor
09:27:56 <LKoen> > (***) (*2) (+2) (5, 7)
09:27:58 <lambdabot>  (10,9)
09:28:04 <LKoen> cool
09:28:19 <LKoen> > bimap (*2) (+2) (5, 7)
09:28:20 <lambdabot>  (10,9)
09:28:25 <LKoen> thank you
09:28:26 <ongy> :t (&&&)
09:28:27 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
09:28:53 <LKoen> hmmmm does this just collapse the two first elements?
09:29:08 <mniip> two first elements?
09:29:11 <LKoen> (1, 2) &&& (3, 4)
09:29:16 <LKoen> > (1, 2) &&& (3, 4)
09:29:17 <mniip> (,) is not an arrow
09:29:18 <lambdabot>      Could not deduce (Arrow (,)) arising from a use of â&&&â
09:29:18 <lambdabot>      from the context (Num b, Num c, Num c')
09:29:18 <lambdabot>        bound by the inferred type of
09:29:36 <ongy> I was looking at it for myself, since I was reminded of arrows
09:29:38 <ongy> sorry
09:29:44 <mniip> Arrow is a profunctorial typeclass
09:30:03 <mniip> contravariance in the first parameter is implied
09:30:16 <LKoen> that's a lot of complicated words mister
09:31:01 <LKoen> ohhhh it collapses two functions then
09:31:31 <LKoen> ((*2) &&& (+2)) 3
09:31:36 <LKoen> > ((*2) &&& (+2)) 3
09:31:37 <lambdabot>  (6,5)
09:32:01 <LKoen> do you have another example of arrows?
09:32:12 <nub> hey i'm completely new to haskell...any advice on a good resource to get started? preferably one that doesn't cost money...
09:32:27 <ARM9> are you also completely new to programming?
09:32:37 <nub> no, not at all
09:32:57 <mniip> LKoen, sadly arrows aren't an often used concept in haskell
09:33:09 <dmj`> nub: CIS194, typeclassopedia, anything byorgey (Brent Yorgey)
09:33:10 <mniip> there's like 3 instances worth noting
09:33:22 <dmj`> nub: http://www.seas.upenn.edu/~cis194/
09:33:23 <LKoen> nub: book.realworldhaskell.org/read/ http://learnyouahaskell.com/
09:33:27 <mniip> (->), Monad m => Kleisli m, Comonad w => Cokleisli w
09:34:31 <nub> thanks everyone! i'll check those out
09:42:34 <DzyubSpirit> Is there thing like First for Maybe, only for Either?
09:45:42 <locallycompact> ?
09:45:49 <jle`> DzyubSpirit: it's not obvious what the identity would be, i think
09:46:55 <Zyxoas> o gawd i need help!
09:47:11 <Zyxoas> These types are driving me nuts!
09:47:24 <dmj`> Zyxoas: we're here for you, just breathe
09:47:35 <Zyxoas> I'm trying to create an application which uses Persistent and Hedis.
09:47:50 <dmj`> Zyxoas: yes
09:48:05 <Zyxoas> I'm creating the Redis connection outside of the main loop function.
09:48:49 <Zyxoas> And then using this to connect to the Persistent backend:
09:49:48 <Zyxoas> runStderrLoggingT $ withPostgresqlPool postgreSQLConnectionInfo 10 $ \pool -> liftIO $ flip runSqlPersistMPool pool $ loop
09:49:59 <Zyxoas> This works if "loop" does only Persistent stuff and IO,
09:50:14 <Zyxoas> but I have no idea how to introduce Hedis.
09:50:36 <Zyxoas> For HEdis I'm using:
09:50:38 <Zyxoas> runRedis :: Connection -> Redis a -> IO a
09:51:10 <Zyxoas> But I fear this is unsufficient due to it not being a transformer?
09:52:13 <Zyxoas> The point being, I do not want to create the Redis connection or the Persistent connection in a loop, so I need a single function that can accommodate both Persistent commands and Hedis commands.
09:52:19 <Zyxoas> I have no idea how. :-(
09:52:58 <Zemyla> http://comonad.com/reader/2012/wadlers-law-revisited/ How long did it take to get OverloadedRecords in Haskell?
09:54:01 <dmj`> Zyxoas: so, generally you'll want to establish connection pools early on in your main function before your app starts, store them in some kind of configuration data type, then you could pass that into a ReaderT with a base monad of IO. You can lift hedis functions into any monad capabale of producing IO (MonadIO). 
09:54:31 <Zyxoas> Sounds good... theoretically.
09:54:33 <mauke> Zemyla: no idea, but my guess would be a few months
09:55:06 <Zyxoas> In practice, I'm stumped. I barely even understanding what the magic incantation to connect to Persistent even does. :-(
09:55:24 <EvanR> transformer hell
09:56:30 <dmj`> Zyxoas: start simple, just make a simple app that connects to redis w/ hedis, run things in a reader, will be less overwhelming
09:56:40 <dmj`> baby steps
09:57:41 <Zyxoas> So, dmj` I need to somehow: create a pool of connections, have a loop is purely Redis based, use the connection pool in the loop whenever I want to do some Persistent actions?
09:58:02 <Zyxoas> Sounds reasonable, I guess... :-\
09:58:30 <dmj`> Zyxoas: it depends on what you're trying to do, what are you trying to do
09:59:16 <Zyxoas> The application reads messages from a Redis queue, and then uses the database to make decisions and write it's answers.
09:59:36 <Zyxoas> So it is message-driven, database-based application...
09:59:48 <EvanR> there are simpler ways to access databases
10:00:02 <EvanR> persistent sounds like something thats going to run facebook
10:00:23 <EvanR> and youre going to create it over a weekend and get paid $100 for it on elance
10:00:31 <Zyxoas> I'd rather use Persistent. Hehe. Tytpe safety, and it write a shit tonne of code for me...
10:00:39 <Zyxoas> Hehe.
10:02:17 <EvanR> just saying an application that reads messages from a redis queue and then uses a data to make decisions and write back answers doesnt sound like it requires transformering
10:03:00 <dmj`> Zyxoas: depending on how you're storing the data, you could just serialize to json
10:05:57 <EvanR> storing database data as json, in my experience is hellish even in a web-friendly language
10:06:34 <marinintim> why is it hellish?
10:07:40 <shapr> EvanR: I'm just looking at using firebase, so I'd like to hear your thoughts on json dbs
10:08:31 <EvanR> its hellish because your "schema" is in your head, and the usually tooling to investigate the data and modify / fix it in an emergency doesnt work anymore
10:09:33 <EvanR> database technology to keep constraints dont work anymore
10:11:20 <EvanR> shapr: firebase.google.com ? having a hard time seeing what this is
10:12:06 <shapr> EvanR: it's a json db with a REST API
10:12:16 <EvanR> in the sense of mongo?
10:12:44 <EvanR> that sort of thing is a step of up from literally putting json text into a blob
10:13:05 <EvanR> or a file
10:13:26 <EvanR> is-a-step-up *goes to get coffee*
10:17:36 <maerwald> mongodb is less of a pain if you strictly use mongoose... however, there's no mongoose equivalent in haskell
10:19:18 <ironChicken> i'm about to start work on a module which takes a flat list of things and turns them into a hierarchical list (i guess some sort of m-way tree) based on certain properties of the things in the original list
10:19:30 <ironChicken> are there any libraries that might help with this sort of thing?
10:19:40 <ironChicken> or is it a bit too vague and generic?
10:22:19 <lyxia> it is a bit too vague and generic
10:22:57 <Zemyla> ironChicken: By hierarchical list you mean like a rose tree?
10:24:28 <mauke> :t Node
10:24:29 <lambdabot> a -> Forest a -> Tree a
10:24:58 <mauke> > Node 42 []
10:25:00 <lambdabot>  Node {rootLabel = 42, subForest = []}
10:25:41 <Zemyla> But yeah, that sounds like an anamorphism.
10:26:31 <EvanR> ironChicken: so you want a parser
10:27:51 * hackagebot QuickCheckVariant 0.1.0.3 - Generator of "valid" and "invalid" data in a type class  https://hackage.haskell.org/package/QuickCheckVariant-0.1.0.3 (sanjorgek)
10:27:53 * hackagebot interlude-l 0.1.0.2 - Prelude replacement based on protolude  https://hackage.haskell.org/package/interlude-l-0.1.0.2 (darwin226)
10:27:55 * hackagebot interlude-l 0.1.0.3 - Prelude replacement based on protolude  https://hackage.haskell.org/package/interlude-l-0.1.0.3 (darwin226)
10:29:23 <ironChicken> Zemyla: i'd not come across rose tree before, but yes, something like that
10:30:04 <ironChicken> EvanR: i already have a list of haskell types, so i'm not parsing from some input format
10:30:45 <ironChicken> but i guess it will have to behave a bit like a parser in that there will probably be some sort of arbitrary read-ahead required
10:32:06 <EvanR> a parser
10:32:56 <EvanR> in that it converts a list into something else based on implicit structure
10:33:04 <ironChicken> yes
10:33:08 <ironChicken> so a parser
10:33:26 <EvanR> maybe look into parsec
10:33:50 <EvanR> it can work on arbitrary tokens streams
10:34:10 <ironChicken> i've actually already used parsec for the first part of this project so it could be quite convenient
10:34:25 <ironChicken> but i have to admit i hadn't thought of it for converting haskell types into other haskell types
10:38:01 <EvanR> its not converting haskell types but the list
10:39:58 <mniip> hmm
10:40:21 <mniip> so it looks like ((->) k) is not a functor in the kind world
10:42:54 <Myrl-saki> mniip: ayyy
10:44:52 <Zemyla> ironChicken: Do you have any examples?
10:47:51 * hackagebot clckwrks 0.23.18 - A secure, reliable content management system (CMS) and blogging platform  https://hackage.haskell.org/package/clckwrks-0.23.18 (JeremyShaw)
10:54:11 <mniip> hmm
10:54:23 * mniip adds more kitchen sinks
10:57:05 <EvanR> firebase seems like its doing the best it can given the circumstances, the guide recommends not nesting data and using manual indexes as part of your tree to make stuff reasonably performant
10:57:16 <EvanR> basically mongo
10:59:06 <mniip> :o
10:59:24 <mniip> class (k ~~ l) => (a :: k) ~~ (b :: l)
10:59:33 <mniip> instance (a ~ b) => a ~~ b
10:59:54 <mniip> oops, forgot the fundeps | a -> b, b -> a
11:00:39 <mauke> I,I (=>) :: Constraint -> * -> *
11:01:40 <mniip> wow
11:02:50 <mniip> > :t value
11:02:50 <mniip> <interactive>:1:1: error: No instance for (IsStar *) arising from a use of âitâ
11:02:51 <lambdabot>  <hint>:1:1: parse error on input â:â
11:03:06 <mniip> how does that work
11:03:20 <mauke> :t value
11:03:21 <lambdabot> Not in scope: âvalueâ
11:03:53 <lpaste> mniip pasted âIsStarâ at http://lpaste.net/170982
11:04:27 <mniip> how do you get a type error when querying a type
11:05:18 <hpc> wait what, you can do empty fundeps like that?
11:07:02 <mniip> interesting
11:07:06 <mniip> that fundep is not even needed
11:07:22 <mniip>  > :t undefined :: IsStar a => p a
11:07:22 <mniip> p a :: p *
11:07:32 <mniip> w/o the fundep
11:07:37 <mniip> with an instance though
11:10:59 <mniip> ah
11:11:01 <mniip> I get it
11:11:41 <mniip> there's an implicit kind quantification and it quantifies the kind over the * sort
11:11:48 <mniip> fun
11:12:52 * hackagebot dejafu 0.3.2.1 - Overloadable primitives for testable, potentially non-deterministic, concurrency.  https://hackage.haskell.org/package/dejafu-0.3.2.1 (barrucadu)
11:19:49 <mniip> is it possible to truly quantify something...
11:26:04 <shirt> what is the "try" variant of "catches"?
11:30:51 <lyxia> shirt: in what context?
11:31:07 <shirt> lyxia: Control.Exception
11:32:12 <shirt> the docs say "we recommend using try rather than catch for ordinary exception recovery", but there is no version of try for the "catches" function
11:33:27 <EvanR> well, use catches
11:34:06 <lyxia> I think a try variant of catches would be quite unwieldly
11:39:29 <c_wraith> I can't even figure out what type signature it would have. 
11:41:15 <c_wraith> unless it returned IO (Either (anonymous sum of all exception types) a) 
11:41:34 <c_wraith> note that haskell lacks anonymous sums. 
11:41:50 <c_wraith> and that interface would be a complete pain to use, regardless. 
11:42:47 <platz> c_wraith: "lacks anonymous sums" not for along, apparrently
11:43:57 <c_wraith> funny thing about that extension proposal is that it's only unpacked sums. 
11:48:15 * hackagebot interlude-l 0.1.0.4 - Prelude replacement based on protolude  https://hackage.haskell.org/package/interlude-l-0.1.0.4 (darwin226)
11:48:31 <dmwit> shirt: I guess `try . try . try . try` (for however many exceptions you want it to deal with) is not completely terrible.
11:48:34 <dmwit> :t try . try . try
11:48:35 <lambdabot> (Exception e, Exception e1, Exception e2) => IO a -> IO (Either e (Either e1 (Either e2 a)))
11:52:16 <shirt> dmwit: thanks! is that better than just using "catches"?
11:54:31 <shirt> if the lambda bodies in all of my "Handler"s are all "pure False" then catches should be safe, right?
12:02:20 <dmwit> I doubt it's significantly better, though it will have the advantage mentioned in the documentation (no changes to masking).
12:02:36 <dmwit> I'm not sure what "safe" means to you, so I can't answer your second question.
12:03:16 * hackagebot gitson 0.5.2 - A document store library for Git + JSON.  https://hackage.haskell.org/package/gitson-0.5.2 (myfreeweb)
12:12:27 <Iceland_jack>     try @AsyncException . try @ErrorCall . try @TypeError :: IO a -> IO (Either AsyncException (Either ErrorCall (Either TypeError a)))
12:18:16 * hackagebot hdaemonize 0.5.1 - Library to handle the details of writing daemons for UNIX  https://hackage.haskell.org/package/hdaemonize-0.5.1 (sickmind)
12:25:34 <amf> is there an easy way (syntax or func) to merge to values (of the same type) where both values implement non-overlapping fields? e.g. let a = Val { f1 = Just 1 }, b = Val { f2 = Just "2"}; merge a b yields Val { f1 = 1, f2 = "2" }
12:26:06 <amf> i should add, without naming all the fields
12:33:17 * hackagebot hdaemonize 0.5.2 - Library to handle the details of writing daemons for UNIX  https://hackage.haskell.org/package/hdaemonize-0.5.2 (sickmind)
12:41:11 <joe9> need some advice, please? I have a haskell program that reads a position value every .5 seconds and writes to a file. I have another haskell program that reads each such file and adds to a Data.Map Microsecond <position data structure>. It then proceeds to write out a .json file which is used by a charting app. My problem is that the process of "writing to a .json file" is taking longer and a lag is building up slowly between the latest
12:41:11 <joe9> position file and the .json file.
12:41:52 <joe9> Instead af writing the Data.Map Microsecond <position data> structure fully each time. Is there any way I can write out the .json file incrementally?
12:42:18 <joe9> that is, have the .json string built for the old data and keep adding the new data to it.
12:42:44 <joe9> I am using Data.Aeson for the json stuff.
12:49:17 <slack-haskell> <erikr> joe9: What about just copying the contents of the current .json file and appending the new entries?
12:49:49 <jakeehrlich2> So I'm new to vim and trying to setup haskell-vim: https://github.com/neovimhaskell/haskell-vim
12:50:12 <jakeehrlich2> it recomends installing with pathogen: https://github.com/tpope/vim-pathogen
12:50:59 <slack-haskell> <erikr> joe9: ultimately I think you want to find a better way of communicating with your charting app so you don't have to duplicate the already written data.
12:51:06 <jakeehrlich2> I went thought the pathogen install instructions and the haskell-vim instructions and got nothing. There is no difference when I open a .hs file
12:51:07 <sm> hey is that a bridge from slack ?
12:51:12 <jakeehrlich2> What might I be doing wrong?
12:51:36 <slack-haskell> <erikr> sm: yes - there is a bridge from slack
12:51:55 <EvanR> uhm. whats slack?
12:52:03 <EvanR> this is creepy
12:52:16 <jakeehrlich2> chat application that has lots of plugins
12:52:16 <EvanR> i meant to ask, which slack ?
12:52:22 <sm> where's the slack channel ? I read https://www.reddit.com/r/haskell/comments/4tw45j/you_may_need_a_slack_team_for_haskell/ but didn't see an announcement
12:52:32 <slack-haskell> <erikr> https://haskell-lang.slack.com/messages/irc-haskell/
12:53:17 * hackagebot interlude-l 0.1.0.5 - Prelude replacement based on protolude  https://hackage.haskell.org/package/interlude-l-0.1.0.5 (darwin226)
12:53:50 <sm> thanks, and how does one get access to it ?
12:55:35 <slack-haskell> <erikr> I followed the reddit link
12:56:17 <sm> which reddit link ? 
12:59:00 <slack-haskell> <erikr> the one posted to /r/haskell as a link post:  http://invite.haskell-china.org/
12:59:47 <joe9> slack-haskell: copying would not work. as the json type is an array. I would have to figure out a way to add the new contents to the end of that array (maybe, sed magic, etc.)
13:00:07 <sm> ah - the title at https://www.reddit.com/r/haskell/comments/4tw45j/you_may_need_a_slack_team_for_haskell/ is a link there, I see. That wasn't clear at all
13:00:18 <hodapp> I didn't realize there's a haskell-lang.slack.com... I've only been on functionalprogramming.slack.com for haskell
13:00:28 <Sonolin> yea same
13:02:51 <slack-haskell> <erikr> joe9: just copy the original file, back up one character position, write a comma and the new entries
13:04:10 * ertes has ForeignPtr trouble
13:04:45 <ertes> it seems more pain than gainâ¦  all i need is to add a finalizer to a pure value
13:05:03 <ertes> is there any drawback to using an IORef instead?
13:05:33 <EvanR> does this have anything to do with FFI? you can just use a weak pointer
13:05:49 <EvanR> weak ref
13:06:52 <slack-haskell> <erikr> sm: do you need an invite for functionalprogramming.slack.com ? I'm a slack neophyte.
13:08:02 <ertes> EvanR: it's GL objects, so i do get them through FFI (e.g. glGenBuffers), but ideally i'd unwrap them immediately and just make sure they are glDeleteBuffers-ed
13:08:33 <ertes> there is no inherent need to keep the pointer or the allocated memory aroundâ¦  in fact there are reasons *not* to
13:09:20 <EvanR> actually weak would be just as much of a pain in the ass
13:10:08 <EvanR> also this doesnt sound like a pure value, the number that goes to a buffer?
13:10:54 <EvanR> you should be able to copy this value at will, but the thing should only deallocate if you lose all references to it
13:11:17 <EvanR> so you need something like a smart pointer
13:12:41 <EvanR> nevermind foreign ptr makes more sense after all
13:13:14 <EvanR> you just dont need to dereference it, just keep the number with it
13:13:18 * hackagebot servant-swagger-ui 0.1.1.2.1.4 - Servant swagger ui  https://hackage.haskell.org/package/servant-swagger-ui-0.1.1.2.1.4 (phadej)
13:14:16 <slack-haskell> <erikr> fond the invite for functionalprogramming.slack.com: http://fpchat.com/
13:15:24 <EvanR> erikr would you like to log in to #haskell IRC instead
13:17:04 <Welkin> wtf is this slack-haskell? some kind of bot?
13:17:22 <EvanR> i think slack has deployed it as part of its irc support
13:17:50 <Welkin> this is just spam to me
13:18:18 <refried_> sorry erikr
13:19:18 <ertes> EvanR: i think i'll go with IORef instead of ForeignPtr
13:19:38 <EvanR> well, you cant access an IORef outside IO
13:19:51 <EvanR> not that youd need to for opengl...
13:20:04 <ertes> that's fineâ¦  i can't access a ForeignPtr outside of IO either =)
13:20:28 <EvanR> you dont need to
13:20:36 <EvanR> the buffer handle is just an Int
13:21:01 <EvanR> if you pass around the (Int, ForeignPtr ()) then when all these are gone itll be finalized
13:22:05 --- mode: ChanServ set +q slack-haskell!*@*
13:22:50 <EvanR> thank you
13:24:04 <ongy> is there a way to write into an MVar, overwriting the current value if it's full?
13:24:17 <ongy> for my usecase I can just use tryTakeMVar before it, but it feels dirty
13:24:48 <EvanR> you can use swap
13:25:08 <EvanR> which wont really work...
13:25:17 <EvanR> maybe you want to use a TVar isntead?
13:26:07 <EvanR> TVar (Maybe Foo)
13:26:27 <ongy> Maybe my idea how to use it is just bad
13:26:46 <ongy> My current Idea has 2 possible consumers, one that wants to read multiple times, and one that ones to block
13:27:15 <EvanR> maybe you want two TVars
13:27:40 <EvanR> a TVar Foo and a TMVar Foo, and you write to both at once in a transaction
13:27:48 <pavolzetor>  /msg NickServ identify damnFB202
13:28:10 <EvanR>  /ns id hunter2
13:28:28 <twk> ^^
13:28:57 <twk> ********* see? ;)
13:29:11 <pavolzetor> hi, I run haskell on windows and the forkIO behavior is funky, for example I bind zeromq socket in separate thread but it freezes whole program
13:29:31 <EvanR> maybe you need to link with -threaded
13:29:51 <EvanR> also the zeromq bindings might be borky
13:31:40 <ongy> I could just pass an (a -> IO ()) to the producer instead of MVar/IORef, and choose the correct variable with that
13:31:56 <pavolzetor> EvanR, helped
13:32:01 <pavolzetor> I thought it is default in stack
13:32:30 <pavolzetor> what happens when you do not have threading? does that forked thread get parked onto HEC and main is blocked?
13:33:12 <fragamus> well im using a mutable array and i feel dirty
13:34:42 <dmwit> ongy: How about a Chan for the multi-reader and an MVar for the one-time reader?
13:34:58 --- mode: ChanServ set +o glguy
13:36:27 <dmwit> pavolzetor: You definitely need to change your password now, in case you didn't notice what just happened.
13:36:43 <ongy> dmwit: using a function works for me. I can choose what to use under the hood later on. For now the one time reader is just the action and multi-reader is IORef and atomicWriteIORef
13:38:04 <pavolzetor> dmwit, thank you, I will
13:41:17 <ongy> but thanks for the suggestion. I (hopefully) will remember them the next time
13:42:44 <pavolzetor> why did the forkIO work on linux without the -threaded flag?
13:43:31 <dmwit> The runtime system uses epoll in the background to wake up the appropriate Haskell thread.
13:43:43 <ongy> pavolzetor: forkIO generally works, but if one haskell thread blocks it will block the entire runtime without -threaded
13:43:56 <dmwit> pavolzetor: You may like the non-gtk parts of http://dmwit.com/gtk2hs
13:44:02 <ongy> blocks outside the haskell runtime that is (some ffi call)
13:44:21 <dmwit> or blocks inside the Haskell runtime without allocating, though this is harder to make happen
13:45:01 <dmwit> s/blocks/loops/
13:45:33 <ongy> I thought the interupt prevents that
13:45:54 <dmwit> What is "the interrupt"?
13:46:30 <ongy> SIGVTALRM timer thingy
13:46:37 <ongy> and yes, I'm good at naming things
13:46:50 <pavolzetor> thanks, but I just took the code from linux and build it on windows without any modifications. on linux it run on windows it did not
13:47:08 <pavolzetor> is it a real thread or the greenthread?
13:47:10 <dmwit> ongy: Hm. I'm not sure about alarm signals. It's possible you're right about that.
13:47:27 <dmwit> forkIO starts a green thread.
13:48:32 <pavolzetor> I see, so that one is scheduled onto the HEC? (I have seen on windows that it worked sometimes, but it was random without -threaded)
13:48:45 <pavolzetor> can you explain why it worked on linux?
13:49:10 <dmwit> I can explain why it worked on Linux. I cannot explain why it did not work on Windows.
13:49:46 <dmwit> Without -threaded, there is only one HEC. Which Haskell thread is scheduled on that context after a forkIO is I think unspecified.
13:50:52 <pavolzetor> okay, why did it work on linux?
13:52:20 <dmwit> At each (Haskell) allocation, the runtime system chooses which Haskell thread to schedule on the HEC.
13:52:42 <dmwit> Any Haskell thread that isn't blocked is a candidate, and the RTS tries vaguely to schedule things that haven't run in a while.
13:53:25 <dmwit> There is an IO manager that's involved in all socket operations and which keeps track of which threads are blocked.
13:53:27 <pharaun> tho re locing won't the thread scheduling end up being more fair (ie mvar) vs (tvars) 
13:55:31 <dmwit> Since allocations happen often, the upshot of this is that all Haskell threads generally have a chance to run "soonish" if they are not blocked.
13:56:27 <pavolzetor> what happens if i block within zeromq on linux?
13:56:38 <pavolzetor> (I think it is FFI)
13:56:40 <pharaun> in the C-side of the code?
13:56:53 <pharaun> well depends on if you called it with unsafe or safe iirc
13:57:13 <dmwit> With -threaded, unsafe vs. safe does not matter for blocking.
13:57:27 <pavolzetor> I am not sure, I just use the bindings
13:57:30 <dmwit> But I kind of doubt the blocking operation happens in C if things are working without -threaded.
13:57:34 <pharaun> dmwit: oh? good to know
13:57:45 <dmwit> I mean without -threaded, unsafe vs. safe does not matter for blocking.
13:57:48 <dmwit> *without*
13:58:02 <pharaun> i know, i was just saying that i ddnt know, thought it always mattered
13:58:33 <pavolzetor> I still do not understand why linux worked (reliably) without -threaded
13:59:20 <ongy> because windows and sockets is weird, there might be a slight difference in the library
13:59:33 <dmwit> pavolzetor: Because the Haskell runtime system is managing the socket.
13:59:43 <ongy> is it not on windows?
14:00:02 <dmwit> ongy: I don't know. As I said: I cannot explain why it does not work on Windows. =)
14:00:20 <pavolzetor> dmwit, on windows?
14:00:38 <dmwit> Again: I know nothing about Windows.
14:01:17 <pavolzetor> ok, so on linux the runtime is managing socket
14:01:43 <ongy> pavolzetor: do you know which function blocks?
14:01:57 <pavolzetor> it depends, either main or the forked one
14:02:02 <pavolzetor> it is non-detemrinistic
14:02:39 <hexagoxel> my testsuite contains a larger amount of similar testcases on different multiline string literals. the amount of overhead when writing tests is annoying. does a nicer solution exist for such, where e.g. i can have a test file with multiple sections that is parsed into [Spec]?
14:03:52 <hexagoxel> (using hspec atm, but any suggestions welcome)
14:04:02 <pavolzetor> thanks gfor help, have to go
14:05:16 <glguy> Assuming that we're talking about the zeromq4-haskell package http://hackage.haskell.org/package/zeromq4-haskell-0.6.5/docs/src/System.ZMQ4.html#receive
14:05:35 <glguy> There's different code for mingw32 and otherwise
14:05:41 <vozz> Can I have some help with HXT / Arrows? I've got a file with a load of item tags that contain a title tag and a link tag (and some other tags). How would I extract say the text from the title and the link and keep them together? I've got something like `doc //> hasName "item" ((/> hasName "title" >>> getText) && (/> hasName "link" >>> getText))` but it isn't working
14:06:14 <ongy> glguy: pavolzetor left
14:06:16 <vozz> Oops, I mean &&&
14:06:35 <sm> hexagoxel: you want to run the same tests against multiple inputs ?
14:07:15 <hexagoxel> sm: yes. atm even just one test :)
14:07:31 <glguy> ongy: In any case it seems like on Windows the code calls an unsafe, blocking read function
14:07:59 <hexagoxel> sm: it currently is a list of "it NAME (func LIT)"
14:08:39 <sm> can't you construct those using higher-order functions, map something to something ?
14:09:34 <hexagoxel> sm: but the main overhead is in the multiline string literals.
14:09:57 <sm> would those be easier with doctest ?
14:11:59 <sm> I test a lot of multiline input/output with shelltestrunner, but that works only for things accessible at the command line
14:12:44 <hexagoxel> i think doctest would have roughly the same overhead.
14:13:26 <sm> what's the overhead exactly.. having to write the same literals repeatedly ?
14:13:59 <sm> or just writing them once, since multiline literals are a bit of a pain in haskell ? 
14:17:05 <adelbertc> hey folks
14:17:22 <adelbertc> currently reading http://www.parsonsmatt.org/2016/07/14/rank_n_classy_limited_effects.html and am looking through the code block at the bottom, specifically the Category Interpret instance
14:17:47 <hexagoxel> sm: it currently looks like http://lpaste.net/8475195975206436864
14:18:05 <adelbertc> as I understand the kind of Category is (* => * => *) => *, and the kind of Interpret is .. something crazier thats not that. im wondering how the types align in that case
14:18:13 <adelbertc> is it PolyKinds at play?
14:19:30 <ReinH> adelbertc: Category has been upgraded, yes
14:19:33 <ReinH> @kind Category
14:19:34 <lambdabot> (k -> k -> *) -> Constraint
14:19:52 <ReinH> The kind you give is from a previous version of the library
14:19:55 <sm> hexagoxel: ok, and what's the problem ?
14:20:37 <ReinH> (And is not correct notation-wise, but I take your meaning)
14:20:46 <hexagoxel> sm: i'd much rather be able to write it like in the annotation of that paste
14:21:01 <hexagoxel> or anything in that direction
14:21:50 <sm> hexagoxel: ok, I see what you mean. Me too
14:22:06 <sm> in Racket, this could probably be done very easily
14:22:25 <hexagoxel> maybe i am the first to run into needing such, but i doubt it.
14:22:52 <sm> in haskell I guess it means building a custom quasiquoter, as used in eg yesod
14:22:57 <adelbertc> ReinH: got it, thanks!
14:22:58 <hexagoxel> i can of course write me some parsec.
14:23:06 <adelbertc> out of curiosity, what is the correct notation for it?
14:23:16 <hexagoxel> hm yeah or quasiquoter
14:23:21 <sm> or just a parser, true
14:23:25 <hexagoxel> :)
14:25:58 <hexagoxel> does any markup language have low-overhead representation for [(String, multiline-string)] ?
14:26:10 <jakeehrllich> So I ran into a case where I expected functional dependencies to introduce type equalities on type varibles. This does not seem to be implemented. Is there an extension for this?
14:26:19 <sm> in that example, you're really not far off though, the boilerplate isn't huge
14:26:42 <sm> you could make a custom [text||] that does more stuff
14:27:22 <twk> jakeehrllich: type families allow for solutions for problems that fundeps could be used for. They have what you need, but work differently, so you'd need to rewrite your code. It might be worth looking into though
14:27:55 <hexagoxel> sm: i'll see; thanks for the input!
14:28:16 <jakeehrllich> twk: Can you give an example?
14:28:57 <sm> or, you could define a list of (name, multilineinput) and sequence [it n (roundTripEqual inp) | (n,inp) <- inputs]
14:29:18 <twk> you essentially define types that are asssociated with a particular typeclass instance. Then you can use those in different contexts.
14:29:30 <twk> jakeehrllich: https://wiki.haskell.org/GHC/Type_families
14:29:33 <jle`> jakeehrllich: maybe you can compare mtl and mtl-tf; mtl uses fundeps and mtl-tf uses type families to implement essentially the same thing
14:30:21 <jle`> for an example, that is
14:32:51 <twk> that said, there is probably a fundep way to solve your problem, but to find it, we'd need more specific info :)
14:33:18 <dolio> If it's required that fundeps introduce a type equality, then it will never happen.
14:33:38 <dolio> They don't work that way, and won't until someone reimplements them on top of type families.
14:33:38 <twk> yes, but it's possible that it isn't required if you tweak the design
14:34:25 <twk> which I believe isn't taht unlikely (at least when I do things like that, I often realize that the initial approach was just suboptimal and caused any issues I had)
14:35:42 <rrradical> is there a way to prevent cabal-install from running configure? (ie., to use the result of a previous configuration run)
14:36:49 <jakeehrllich> http://lpaste.net/170997
14:37:28 <jle`> rrradical: are you talking about cabal-install the utility, or the 'cabal install' command?
14:37:31 <jakeehrllich> there's a simplification of my specific case. I basically just pulled realvent code and and stripped it of things so it won't compile or anything. 
14:37:55 <rrradical> jle`: the command, sorry
14:38:54 <rrradical> jle`: oh hm, I guess I can just call install from the generated setup exe. Ok that works for me, never mind
14:39:18 <jle`> congrats!
14:48:21 * hackagebot canteven-http 0.1.1.0 - Utilities for HTTP programming.  https://hackage.haskell.org/package/canteven-http-0.1.1.0 (taphu)
15:03:22 * hackagebot QuickCheckVariant 0.1.0.4 - Generator of "valid" and "invalid" data in a type class  https://hackage.haskell.org/package/QuickCheckVariant-0.1.0.4 (sanjorgek)
15:20:56 <newhoggy> Does anyone know of a Haskell library that has a function String -> IO (), that will print to the screen with search and scrolling just like in the unix command less or more?
15:21:13 <newhoggy> And do it lazily if possible.
15:22:40 <Welkin> newhoggy: just echo your string into `less` in your shell
15:22:48 <Welkin> there are plenty of haskell shell libraries
15:23:04 <newhoggy> What if I wanted this functionally from ghci?
15:23:32 <newhoggy> s/functionally/functionality
15:24:04 <newhoggy> I'm writing a simple query language DSL which when run could megabytes of text.
15:26:29 <hpc> your program would be the one running less, with createProcess or something like that
15:26:44 <newhoggy> Ah, that sounds good.
15:26:46 <hpc> or ideally, perhaps create a temporary file somewhere and pass that to $EDITOR
15:26:47 <newhoggy> Thanks!
15:26:57 <newhoggy> Right!
15:34:44 <monochrom> System.IO has something for temp files
15:38:23 * hackagebot hsqml 0.3.4.1 - Haskell binding for Qt Quick  https://hackage.haskell.org/package/hsqml-0.3.4.1 (RobinKay)
15:42:50 <schell> is there a lens to check for whether or not something is a member of a group? like `elem`?
15:44:46 <schell> looks like there an `elemOf` of sorts :)
15:45:14 <crough> contains?
15:45:49 <schell> crough: ah! yeah, that too
15:46:17 <mniip> :t \x -> getAny . fold (Any . (==x))
15:46:18 <lambdabot>     Couldn't match type âAnyâ with âa -> Anyâ
15:46:18 <lambdabot>     Expected type: a1 -> a -> Any
15:46:18 <lambdabot>       Actual type: a1 -> Any
15:46:35 <mniip> hmm it's not Any
15:46:55 <crough> First? 
15:47:06 <mniip> ah yes, it is Any
15:47:10 <mniip> :t \x -> getAny . foldMap (Any . (==x))
15:47:11 <lambdabot> (Eq a, Foldable t) => a -> t a -> Bool
15:48:02 <crough> is lens imported by lambdabot?
15:48:23 <crough> > [1,2,3] & contains 2 %~ False
15:48:24 <lambdabot>      Couldn't match expected type âBool -> Boolâ with actual type âBoolâ
15:48:24 <lambdabot>      In the second argument of â(%~)â, namely âFalseâ
15:48:24 <lambdabot>      In the second argument of â(&)â, namely âcontains 2 %~ Falseâ
15:48:58 <crough> > [1,2,3] ^. contains 2
15:48:59 <lambdabot>      No instance for (Num t0) arising from the literal â1â
15:48:59 <lambdabot>      The type variable ât0â is ambiguous
15:48:59 <lambdabot>      Note: there are several potential instances:
15:49:03 <crough> phhht 
15:49:04 <glguy> crough: [] isn't an instance of contains
15:49:10 <glguy> crough: and %~ takes a function 
15:49:12 <crough> ahh, because I can't add to it
15:49:14 <crough> and right
15:49:23 <crough> contains is like At
15:49:26 <crough> :P
15:49:47 <crough> > IntSet.fromList [1,2,3] ^. contains 2
15:49:49 <lambdabot>      Not in scope: âIntSet.fromListâ
15:49:49 <lambdabot>      Perhaps you meant one of these:
15:49:49 <lambdabot>        âIS.fromListâ (imported from Data.IntSet),
15:49:50 <frskl> ahh it's a wonderful day
15:49:54 <crough> > Data.IntSet.fromList [1,2,3] ^. contains 2
15:49:55 <lambdabot>  True
15:49:58 <crough> there we goooo
15:50:01 <glguy> crough: You can experiment in /msg
15:51:01 <crough> ... why have I never thought of doing that with lambdabot
15:51:19 <mniip> ok so how does this work
15:51:25 <crough> I have been using Haskell for god knows how long and never learned how to use this damn bot properly-- that would have helped immensely 
15:51:34 <mniip> class a ~# b => (~~) (a :: j) (b :: k) 	-- Defined in âGHC.Typesâ
15:51:45 <mniip> yet, data (~#) (t3 :: a) (t4 :: b)
15:51:49 <crough> glguy: you deserve some kind of medal
15:51:54 <mniip> therefore (~#) :: a -> b -> TYPE 'VoidRep
15:52:09 <mniip> TYPE VoidRep ~/~ Constraint
15:56:51 <vozz> Can someone help me with XML lenses? I'm using xml-lens and I've got this: http://lpaste.net/1874171505743495168 I think I have to turn the Elements into a lens somehow?
16:06:07 <glguy> vozz: I'm guessing you didn't mean to use ./ in the last two lines
16:06:43 <johnw> I would have used el, not ell, is that the problem?
16:07:16 <glguy> vozz: as it is you're trying to treat item as a Traversal instead of an Element
16:07:18 <vozz> glguy: I did because I don't really know what I'm doing :D I just figured it out though, I have to use ^.. right?
16:10:13 <vozz> Hm, how do I turn an Element into a Traversal? Changing it to ^.. runs properly, but gives back a huge list of ([], [])
16:10:36 <glguy> You don't turn elements into traversals
16:14:34 <glguy> A bunch of empty lists means that your items didn't have the element children you asked for, so either they're nested further down or named differently or something
16:16:49 <glguy> try: item ^.. plate . ell "title" . text
16:21:33 <johnw> isn't that the same as: ^.. id ./ el "title" . text
16:22:02 <glguy> Looks like it
16:22:43 <glguy> Maybe the id version is more consistent
16:26:59 <rockbmb> hello; does anyone know how to write generic Arbitrary instances for non-recursive datatypes? I'm taking a look at Data.Data and GHC.Generics but I'm not quite sure how to use them for this task.
16:30:51 <johnw> there are libraries that already do that, btw
16:33:24 * hackagebot riak 1.1.0.0 - A Haskell client for the Riak decentralized data store  https://hackage.haskell.org/package/riak-1.1.0.0 (lambda_foo)
16:34:18 <rockbmb> @johnw which ones? I only know of generic-random, but it has a really non-negligible bias towards constructors with Strings
16:34:18 <lambdabot> Not enough privileges
16:34:52 <glguy> rockbmb: @ is for bot commands
16:35:12 <rockbmb> oh, my bad - I'm too used to slack
16:36:12 <rockbmb> johnw: can you give me a couple of examples, if you don't mind?
16:36:25 <johnw> sorry, I don't remember their names, just that they're there
16:38:44 <rockbmb> johnw: alright, I'll keep looking. thanks!
16:44:23 --- mode: ChanServ set -o glguy
16:53:25 * hackagebot swagger2 2.1.1 - Swagger 2.0 data model  https://hackage.haskell.org/package/swagger2-2.1.1 (NickolayKudasov)
17:31:02 <Squarism> ive only used monads for IO (networking/threads/channels/console-io). What is peoples view on using them where its sort of optional, ie for arbitrary monad types like either/maybe/list? Does it make code more readable/concise/better?
17:31:35 <twk> in some cases, sure
17:31:38 <EvanR> you can think of Monad for those basic types (and more) as "flattenable"
17:31:44 <EvanR> its very convenience
17:32:03 <avalokite> Can I think of a monad as a human?
17:32:07 <EvanR> but watch out for transformers
17:32:27 <EvanR> they can eventually make some code, if youre lucky, more concise and readable
17:32:39 <EvanR> after a large amount of extra code
17:32:54 * avalokite needs a good analogy to be able to share with children for what monads are and how to use them
17:33:24 <EvanR> tell them its a certain algebraic structure on an endofunctor
17:33:52 <Rotaerk> don't try to teach monads by analogy :P
17:34:06 <Rotaerk> none of them will suffice
17:34:26 <twk> I must admit that I believe it depends on the person trying to understand them
17:34:49 <twk> some people prefer analogies and are able to generalize afterwards
17:35:24 <twk> but interestingly, that perfect audience for monad tutorials insn't as large as the sheer amount of those tutorials suggests
17:35:32 <EvanR> well thats fine except monad analogies are usually totally wrong
17:35:46 <twk> that's true
17:36:00 <EvanR> im sure you could do better but im not about to try given the circumstances
17:36:12 <Rotaerk> I've said it before, I'll say it again:  teach difficult abstractions by presenting a series of concrete examples, and allowing them to intuit the abstraction
17:36:16 <EvanR> monad tutorial fallacy has silenced all debate
17:36:41 <twk> Rotaerk: yes, I believe that's a reasonable way, but for me at least, it *is* analogy
17:36:49 <twk> if you know what I mean
17:36:58 <Squarism> i understand there are some power in the Monad api's but, beeing a newcomer, quite hard to digest / make things more complicated. 
17:37:01 <EvanR> concrete examples arent analogies
17:37:05 <Rotaerk> I don't think it's up to your personal style of learning though, twk
17:37:19 <Rotaerk> even if you learn better by analogy... if there isn't a good analogy, then that's not an option
17:37:21 <crough> I want to see one where someone very earnestly tries to explain it as "it's just an F where mapping commutes and a pair of arrows called Î¼ and Î¼"!
17:37:31 <EvanR> Squarism: try combining a chain of Maybe results manually, then try with monads (or applicatives)
17:37:41 <crough> *and Î¼
17:37:44 <crough> damn it
17:37:45 <crough> nevermind
17:37:49 <crough> Î·
17:38:07 <Rotaerk> Î·evermind
17:38:10 <twk> EvanR: technically not, but they work in a similar fashion when it comes to the ways people grasp the explanation
17:38:13 <EvanR> crough: someone just saw that and is running to memegenerator
17:38:17 <crough> Î·evermiÎ·d
17:38:23 <shachaf> crough: What do you mean?
17:38:25 <twk> but ofc, analogies are in general an inferiour approach
17:38:31 <chronon-io> crough: There's this: http://www.stephendiehl.com/posts/monads.html
17:38:46 <crough> shachaf: mu is 'return' and nu is 'join' and F is a functor (could have mu and nu backwards)
17:38:50 <chronon-io> Probably not quite as clear as you were hoping though
17:38:53 <crough> shachaf: it's not very helpful
17:38:56 <shachaf> crough: Yes, I know.
17:39:03 <shachaf> crough: (Except they're backwards like you said.)
17:39:13 <shachaf> But what's "mapping commutes"?
17:39:24 <crough> functor law 
17:39:46 <crough> just an attempt at being obtuse, not accurate ;) 
17:39:50 <shachaf> Oh.
17:40:07 <shachaf> I guess a monad is just a particular equivalence class of adjunctions.
17:40:10 <EvanR> hmm. its a mapping between categories that commutes ;)
17:40:22 <Rotaerk> monads are like burritos that can contain burritos, and every time you unwrap one layer, you get squirt in the face with sour cream
17:41:03 <EvanR> burritos must have something to do with transformers which... should definitely not come up when "teaching" monads
17:41:09 <Squarism> EvanR, ive learned that and sure - i see the power. I want to learn these tricks. Just that there seems to be many packages/modules dealing with monad work and beeing new to the language i just dont know how far into monad land you should plan to go
17:41:16 <shachaf> I think the word "burrito" ought to be banned in here.
17:41:21 <Rotaerk> lol
17:41:32 <Rotaerk> what if someone's just really hungry and in the mood for mexican
17:41:33 <twk> what if the channel decides to collectively get mexican food?
17:41:34 <shachaf> I'm serious, really.
17:41:48 <crough> monads are little gnomes that build their houses inside of even smaller gnomes, and when you use >>= they leave their homes and go to their workplaces which are also in the bigger gnomes
17:41:48 <shachaf> False positives are a price that has to be paid.
17:41:52 <Rotaerk> true
17:41:54 <twk> then "they" will switch to wraps
17:42:04 <EvanR> Squarism: hmm. theres just the Control.Monad base lib and monad-loops which honestly you probably dont want for just one control loop
17:42:13 <EvanR> ignore all transformers for now
17:42:20 <Squarism> ok
17:42:50 <shachaf> These sorts of definitions are old and not funny.
17:42:50 <EvanR> look at Either, Reader, State, Random, Cont monads
17:43:03 <Rotaerk> (and Maybe)
17:43:05 <shachaf> If you came up with an interesting new characterization of monads, that would be interesting.
17:43:12 <Squarism> ok.. will do
17:43:16 <EvanR> Squarism already knows Maybe, so try that sequence next
17:43:21 <crough> EvanR, Squarism: state was the one that really made it click for me back in the day
17:43:41 <EvanR> State is one that seems to always be on peoples minds, so i put it third
17:43:53 <Rotaerk> ah k
17:44:26 <Rotaerk> maybe the function monad too
17:44:47 <EvanR> do the function monad after Random and before Cont
17:45:05 <chronon-io> I found the discussion here to be really helpful for understanding monads in an abstract way: https://en.wikibooks.org/wiki/Haskell/Applicative_functors#A_sliding_scale_of_power
17:45:08 <Squarism> Theres no nice write up showing of what monads can do for day to day data handling? Possibly with ; with and wo use of them
17:45:32 <EvanR> well, you can look into the pipes library
17:45:35 <EvanR> its a monad
17:45:51 <Squarism> + applicative and other useful abstractions
17:46:12 <EvanR> for day to day, use IO and dont try to understand "monads"
17:46:46 <EvanR> you wont come up with genuinely new kinds of monads day to day
17:47:08 <Rotaerk> Squarism, "monads" as in instances of Monad, such as Maybe, Either, etc, are clearly useful *regardless* of whether they're monads, so the question is not whether monads are useful so much as the monad *abstraction*
17:47:38 <Rotaerk> and the monad abstraction is useful because you can often write functions in terms of it, without tying them down to any one type
17:47:43 <Rotaerk> as with any abstraction
17:48:01 <erisco> interesting, so SO has a new documentation feature
17:48:04 <EvanR> otoh you can easily figure out new ways to abuse do notation once you figure out what it desugars to, and this happens in other languages with monads
17:48:10 <erisco> "When it discusses the type signature, it says that `main` is not a pure function. This is confusing. All functions in Haskell are pure. The `IO` monad makes it appear that it is not pure. We need to use correct wording here. - akonsu"
17:48:23 <erisco> how is this to be approached, because there is no consensus on what purity means
17:48:43 <Rotaerk> main isn't even a function
17:49:11 <EvanR> the docs might do well to say that 
17:49:21 <EvanR> main isnt even a function, at the beginning of each page
17:49:51 <erisco> The type IO () is the type of an IO action (i.e. this is not a pure function, but it can possibly interact with the environment, output text, launch missiles, etc.) which has no return value (or, more precisely, a boring return value that doesn't actually contain any information).
17:50:01 <crough> so, speaking of monads-- why does Data.Functor.Compose not have an instance? http://lpaste.net/171007
17:50:23 <EvanR> its not a pure function because its not even a function i think is a good way to start?
17:50:33 <erisco> I think purity should just be dropped from the description entirely
17:50:40 <erisco> lets just be direct and say "side effect"
17:50:47 <EvanR> how about drop the word function
17:50:50 <erisco> or "IO", or something else less mystifying
17:50:53 <erisco> yes of course
17:51:10 <shachaf> monads++
17:51:13 <EvanR> then pure would make so little sense whoever would have to remove it
17:51:19 <shachaf> The Traversable requirement is pretty arbitrary.
17:51:23 <Xnuk> ++monads
17:51:52 <EvanR> mo++nads
17:51:59 <Squarism> Rotaerk, im totally familiar with the usefullnes of these classes. Its just that i understand they would be even more useful if utilize their monad aspect - which i seldom do right now.
17:52:14 <EvanR> well you have to learn each one individually
17:52:27 <erisco> http://stackoverflow.com/documentation/haskell/251/hello-world if you wish to weigh in
17:52:33 <Rotaerk> particularly learn how >>= works for each individual type
17:52:43 <Gurkenglas> "cabal install lens gloss" <- this tried to install lens 14.4 and gloss 1.0.0.0 (the latter of which failed with a bang pattern error). what do?
17:52:49 <Squarism> okey
17:53:14 <EvanR> the only commonality is that they "flatten" using join :: Foo (Foo a) -> Foo a
17:53:17 <crough> shachaf: it and distributive give you pretty easy inversion of functor layers-- I think this just leaves out state in terms of the common ones 
17:53:24 <shachaf> layers++
17:53:49 <crough> noone likes my mdashes :(
17:53:58 <jle`> crough: i don't think your instance is lawful
17:54:01 <shachaf> Most interesting monads aren't Traversable of Distributive.
17:54:18 <shachaf> (Only one specific sort of monad is Distributive.)
17:54:33 <crough> shachaf: either, maybe, list, and reader satisfy all of those
17:54:45 <shachaf> All of what?
17:54:54 <crough> sorry, either traversable or distributive
17:55:04 <crough> as well as identity satisfying both (boo coherence)
17:55:11 <shachaf> Only monads isomorphic to (e ->) for some e are Distributive.
17:55:20 <crough> jle`: that's possible, haven't tested them
17:55:39 <shachaf> Only monads that "contain" a sequence of values are Traversable.
17:55:53 <jle`> crough: i think it's safer to say that the laws aren't satisfied until you prove them :p
17:56:05 <jle`> crough: it's easy to write a function that typechecks.  most of them don't satisfy the laws :o
17:56:20 <EvanR> Squarism: ex. join :: [[a]] -> [a] is the obvious concatMap (aka flat_map seen elsewhere), you can think of this as taking a multi-answer result of multi-answer result type, and giving you all the results unnested 
17:56:27 <jle`> i don't know how you'd even begin to start trying to prove the laws with the instance you have
17:56:31 <EvanR> er, concat
17:56:42 <EvanR> > concat [[1,2,3],[4,5]]
17:56:44 <lambdabot>  [1,2,3,4,5]
17:57:12 <Rotaerk> Squarism, it's also perhaps important to recognize that >>= is *not* normally used like: ma >>= (\a -> mb) >>= (\b -> mc)
17:57:23 <EvanR> so list monad is useful for multi-answer results
17:57:33 <crough> jle`: fair
17:57:43 <Rotaerk> the do-notation desugars to a nested structure like:  ma >>= (\a -> mb >>= (\b -> mc))
17:57:48 <Squarism> EvanR, i use that often
17:57:57 <Rotaerk> so see how Maybe, et al, work with that kind of usage
17:58:11 <jle`> instance Monad Maybe where return _ = Nothing; _ >>= _ = Nothing :)
17:58:42 <EvanR> you can think of >>= as fmap (to create this nesting in the first place) followed by a join
17:59:02 <Squarism> Rotaerk, i somehow feel more comfortable using that instead of do / <- notation. The latter just feels like an alternative language =D
17:59:06 <EvanR> and do notation is fancy junk for >>=
17:59:17 <Rotaerk> use >>= for now, until you're comfortable with it
17:59:31 <Rotaerk> then move on to the sugar
18:00:37 <erisco> the tail end of this Hello World tutorial goes way off the mark I think
18:00:47 <erisco> why go to do { putStrLn "hello World!"; return () }
18:01:16 <cloudhead> ericso: I don't see why combinators need to be mentioned in the hello world example, given that there is nothing to "combine"
18:01:26 <divVerent> jle`: nice instance Monad Maybe... wonder if this can be actually made useful, essentially a "do-nothing-at-all" monad ;)
18:01:40 <cloudhead> same as do notation, not really relevant to a hello world example
18:01:46 <jle`> heh, the point was that it typechecked, but is not a lawful monad
18:01:59 <divVerent> sure
18:02:09 <divVerent> just wondering if it can be made lawful "somehow"
18:02:36 <erisco> cloudhead, that's right, I don't think delving into monads or do-notation is in scope of "Hello World!"
18:02:51 <bernalex> the hello world of fp is fib.
18:03:03 <bernalex> main = print "hello world" isn't very interesting.
18:03:04 <erisco> talking about law-abiding Monadsâ¦ IO? ;)
18:03:13 <divVerent> hm... no, can't
18:03:35 <erisco> I can only proposed one change at a time
18:03:49 <cloudhead> erisco: yeah, it seems like somehow the doc manages to touch upon half a dozen of complex topics which are completely out of scope for a hello world
18:03:51 <erisco> but if you wish to wrap up the conclusion differently cloudhead I am sure everyone would be greatful
18:03:59 <divVerent> erisco: IO is certainly law abiding
18:04:00 <bernalex> erisco: IO is law-abiding.
18:04:12 <erisco> bernalex, divVerent how was this determined?
18:04:19 <bernalex> I don't understand the question.
18:04:22 <divVerent> insert it into the three laws
18:04:24 <divVerent> it fulfills them all
18:04:37 <bernalex> yeah.
18:04:59 <divVerent> first two laws are trivial, associativity is a bit harder to prove formally
18:05:15 <EvanR> does it require a semantics of IO?
18:05:27 <divVerent> somewhat
18:05:28 <EvanR> or assuming its a free monad
18:05:52 <bernalex> how IO actually works is not defined in the standard
18:06:07 <bernalex> howere you can easily demonstrate that GHC's IO is law-abiding.
18:06:28 <EvanR> erm
18:06:33 <divVerent> well, you don't need to know its internals for that
18:06:35 <EvanR> ok
18:06:45 <Welkin> is it lawful good?
18:06:48 <divVerent> the laws only require things you can formally check/prove within Haskell
18:06:52 <Rotaerk> ..
18:06:52 <divVerent> no, it's lawful chaotic
18:06:53 <bernalex> newtype IO a = IO (State# RealWorld -> (# State# RealWorld, a #)); instance Monad IO where ...
18:07:02 <Welkin> I love chaotic
18:07:02 <Welkin> :D
18:07:13 <divVerent> bernalex: but yes, that's the standard way to start proving something about IO
18:07:15 <Rotaerk> that's like saying "good evil"
18:07:18 * EvanR censors bernalex's mentioning the unmentionable
18:07:20 <divVerent> treat it as "opaque state + value" kind of object
18:07:28 <divVerent> Rotaerk: yes, I know
18:07:29 <bernalex> I started to write it out, but couldn't be bothered. so I searched, and someone already did this of course: https://stackoverflow.com/questions/12617664/a-simple-example-showing-that-io-doesnt-satisfy-the-monad-laws -- see the top answer.
18:07:32 <Rotaerk> heh
18:08:00 <bernalex> @src IO
18:08:00 <lambdabot> Source not found. And you call yourself a Rocket Surgeon!
18:08:07 <bernalex> unfortunately I can't get lambdabot to mention the unmentionable.
18:08:17 <bernalex> @src IO a
18:08:17 <lambdabot> Source not found. The more you drive -- the dumber you get.
18:08:21 <bernalex> that's true, lambdabot.
18:08:36 <bernalex> anyway, it certainly is a law-abiding monad.
18:08:54 <bernalex> now. why did I go to my IRC channel in the first place? hmmm
18:10:05 <divVerent> bernalex: indeed, the one thing is that termination vs nontermination is kind of a problem with the monad laws
18:10:15 <divVerent> what's easy to prove is "if you get a return value, it is right"
18:10:31 <bernalex> divVerent: yeah, well, throw seq at it, and you break all of haskell, so.
18:10:46 <EvanR> all bets are off for any laws if _|_ ?
18:10:55 <EvanR> except definitions of strictness which rely on it
18:11:19 <EvanR> is Hask even a category with _|_
18:11:44 <bernalex> EvanR: no
18:11:46 <dolio> Yes, but not with seq.
18:12:39 <divVerent> bernalex: basically because seq has kinda no semantics :P
18:12:41 <bernalex> > let bottom = bottom in bottom
18:12:45 <lambdabot>  mueval-core: Time limit exceeded
18:12:55 <divVerent> other than "wait a little while calculating a value for nothing"
18:12:59 <dolio> No, seq has semantics.
18:13:08 <divVerent> I mean, it doesn't change any values
18:13:26 <EvanR> seq causes not _|_ to become _|_ sometimes
18:13:33 <divVerent> if you get a return value, it's the same both with real seq and a "fake" that just returns its second arg
18:13:40 <divVerent> right, so essentially it adds time
18:13:45 <EvanR> and crashes
18:13:47 <divVerent> as bottom is basically "does not terminate"
18:13:54 <divVerent> crashes are just an optimization for not terminating
18:13:57 <divVerent> :P
18:14:01 <EvanR> erhm..
18:14:11 <bernalex> the last category law is broken with â¥ and seq
18:14:15 <divVerent> I mean, let x = x in x is a bottom too
18:14:17 <EvanR> it actually changes the "value"
18:14:20 <dolio> The problem with seq is that it can tell the difference between â¥ and \_ -> â¥.
18:14:23 <EvanR> it doesnt just add time
18:14:37 <bernalex> id . f = \_ -> â¥
18:15:00 <bernalex> throw seq at that and the third law ragequits
18:15:13 <bernalex> hask is a category if you do
18:15:16 <bernalex> f .! g = ((.) $! f) $! g
18:15:20 <bernalex> and use .! in place of .
18:15:39 <divVerent> EvanR: it adds an infinite amount of time, as a bottom is basically defined as that
18:15:44 <bernalex> but that would be unpleasant, so instead we lie ourselves to sleep at night by ignoring seq.
18:16:11 <dolio> Arguably, there might be category structure that still works, but it requires being fancier than the usual, 'objects are types, hom spaces are function types.'
18:16:43 <EvanR> divVerent: i guess if you take _|_ to be "any value you want, just the least defined version of it"
18:16:47 <hodapp> what are you guys trying to do, scare all the kids to death?
18:16:50 <EvanR> rather than a new value added to the types
18:17:02 <divVerent> yes, I do think I have to take it as that
18:17:07 <divVerent> as let x = x in x is a bottom too
18:17:27 <divVerent> yet it exhibits quite different behavior
18:17:49 <EvanR> which is different from "_|_ is a value of any type, tacked on because non totality"
18:18:09 <divVerent> well, let x = x in x is also a value of any type...
18:18:19 <EvanR> yes thats a term for _|_
18:18:25 <EvanR> in any case
18:18:34 <bernalex> â¥ is the type that has no values.
18:18:45 <EvanR> gross
18:18:49 <divVerent> so my point is, seq basically executes in sequence, and by virtue of that propagates nontermination
18:19:05 <dolio> No, you don't know that seq does that.
18:19:13 <divVerent> it doesn't have to
18:19:14 <dolio> seq is just strict in both arguments.
18:19:16 <divVerent> indeed
18:19:18 <divVerent> it just usually will
18:19:36 <divVerent> if it can for some reason magically prove that the first arg isn't a bottom
18:19:40 <divVerent> it doesn't have to evaluate it
18:19:54 <EvanR> i like magical reasons
18:19:54 <divVerent> this "some reason" might be ghc analyzing the expression inside
18:20:26 <dolio> It could also evaluate its second argument first, then evaluate its first argument, and yield the second thing after that.
18:20:27 <divVerent> so e.g. seq longComputation doSomethingThatUsesLongComputationMultipleTimes might not actually "precache" the long computation
18:20:56 <divVerent> it just usually will, as seq is basically meant for that - as an optimization hint to the code generator
18:22:04 <divVerent> that it's a relatively bad way to hint to a compiler to compute a subexpression first is obvious... it probably should never have existed in this way
18:24:37 <divVerent> the part about seq that I don't get is why it ever got so popular
18:24:45 <divVerent> I mean, it's not even guaranteed to gain anything
18:25:11 <divVerent> yes, it's strict in the first arg... but that doesn't actually FORCE anything about e.g. reusing it later
18:25:18 <divVerent> it still may get computed again and become a huge thunk
18:26:55 <Rotaerk> it really just adds an artificial dependency from the right argument to the left, so that *if* the right is evaluated, then the left is
18:28:04 <jle`> divVerent: actually, if you're looking for a "do-nothing" Monad, try looking at 'Proxy' :)
18:28:05 <divVerent> right, whatever "evaluation of the left" means other than termination
18:28:13 <jle`> (to continue a discussion from an hour ago)
18:28:19 <divVerent> most uses of seq assume more than just the dependency
18:28:48 <divVerent> I mean, nothing stops the compiler from evaluating the same expression more than once, with or without dependency on the already computed value
18:29:09 <jle`> Proxy is basically Maybe w/o Just
18:29:12 <divVerent> sometimes there's even good reasons, e.g. computing again may be cheaper than transferring the value between threads/processors/machines/clusters
18:29:17 <dolio> Rotaerk: That's not really a good explanation, either, because someone could take that to mean that 'let x = e1 ; y = e2 in (x `seq` y, y)' would set things up such that evaluating the second element of the pair would evaluate x.
18:29:21 <divVerent> right
18:31:11 <Rotaerk> ah yea, would have to say "x `seq` y" is the same as y but with x artificially treated as a dependency
18:31:28 <dolio> Yeah.
18:31:44 <Koterpillar> > let x = x `seq` x in x
18:31:48 <lambdabot>  mueval-core: Time limit exceeded
18:33:11 <jle`> > fix seq ()
18:33:13 <lambdabot>  ()
18:34:39 <jle`> fix seq 1 is (seq (seq (seq (seq ...))) `seq` 1, isn't it?
18:41:41 <erisco> it will be interesting to see how well this documentation thing works
18:41:47 <dolio> jle`: It's a little tricky.
18:42:00 <erisco> Wikipedia has mustered a reasonable level of quality on technical topics
18:42:50 <dolio> `seq â¥ a = â¥`, but the question is what `seq â¥` is. And it's probably `\_ -> â¥`, which seq sees as not â¥.
18:44:13 <xsperry> this bitch is super hot http://www.cam4.com/alison10
18:44:21 <dolio> So, fix f = â¥ if f â¥ = â¥, but `seq â¥` is actually not â¥ (I think), so fix seq may not be â¥.
18:44:22 <xsperry> lol wrong channel 
18:44:38 --- mode: ChanServ set +o glguy
18:44:38 --- mode: glguy set +b *!*@unaffiliated/xsperry
18:44:39 --- kick: xsperry was kicked by glguy (xsperry)
18:44:48 <erisco> though, like if you're already used to accessing encyclopedias, papers, and original articles, Wikipedia seems redundant
18:45:12 <erisco> and so this documentation site has a similar feel
18:45:22 <erisco> why not just pick up one of the excellent Haskell books, for example
18:46:57 <dolio> fix seq () = (let x = \y -> seq x y in x ()) = 
18:47:24 <dolio> seq (\y -> ...) () = ()
18:47:58 <jle`> ah
18:49:48 --- mode: glguy set -o glguy
18:54:20 --- mode: ChanServ set +o glguy
18:54:22 --- mode: glguy set +b-b *!*@webbox222.server-home.org *!~bc816c65@webbox222.server-home.org
18:55:32 <Welkin> hahaha
18:55:40 <Welkin> posting porn sites
18:55:55 <Welkin> and I disagree with that guy's opinion about that woman...
18:56:17 <glguy> don't push it
19:03:34 --- mode: glguy set -o glguy
19:16:33 <Squarism> ok... rabbit hole programing here - is there a better way to find out if s is part of z in http://lpaste.net/171015
19:17:39 <Squarism> really i want to add s to z if not contained in z
19:18:16 <Squarism> determined by agreeing idx
19:46:20 <tom___> Hi guys, I've got a question about Haskell and lists.
19:46:31 <peddie> Squarism: can you just use a set?
19:47:22 <tom___> Let say i have myFunction :: [a]->[a] . Why myFunction (xs++ys) doenst work ? (parse error).
19:47:24 <Squarism> peddie, you mean for equality determination?
19:48:01 <Cale> tom___: Some reason unrelated to that expression
19:48:02 <glguy> tom___: Put the code on a pastebin for us to see http://lpaste.net
19:48:10 <geekosaur> tom__, under what circumstances? Were you using that as a pattern?
19:48:40 <peddie> Squarism: if you have to do a lot of these, yes, for equality determination and fast membership checking
19:48:58 <tom___> I'm learning haskell, and they talk about foldr1, but don't give the code. I made one. But i want to get it in an other way.
19:49:16 <Squarism> peddie, its very rare and the lists are max 3 elements long
19:49:27 <peddie> oh
19:49:57 <lpaste> tom pasted âmonFoldr1â at http://lpaste.net/1455630602060431360
19:50:02 <Squarism> i have some idea i could do double-liftA ? =D
19:50:11 <tom___> http://lpaste.net/1455630602060431360 hope it ll work ?
19:50:16 <Squarism> (i mainly do this as an exercise
19:51:26 <geekosaur> so yes, it's a pattern. how were you imagining it would know where xs ends?
19:51:30 <Koterpillar> tom___: when you use 'a ++ b' in patterns, do you expect [1,2,3] to match as a = [], b = [1, 2, 3], or a = [1, 2], b = [3], or anything else?
19:51:49 <geekosaur> in any case, a pattern is made form constructors. (++) is an operator (function), not a constructor; the list constructors are [] and (:)
19:51:51 <glguy> whatever you happen to expect, you can't pattern match on function applications
19:52:56 <Squarism> peddie, wow.. it worked : liftA2 (liftA2 elem) (s) (fmap Just z)
19:53:02 <tom___> Koterpillar, in any case, it not properly defined. But in my monFoldr1 function, beacause of the "x:" I think it should be ok.
19:53:32 <peddie> Squarism: good grief, I'd just pattern match myself . . . what you've written would probably take me a minute to understand
19:53:41 <tom___> (a++b:[] = [1,2,3] implies that b = 3.)
19:53:42 <Squarism> haha
19:54:02 <peddie> Squarism: but it's good to be able to rewrite stuff like that to check your understanding :)
19:54:07 <Squarism> im thinking ; now i program like a haskell programmer
19:54:23 <Koterpillar> tom___: see what geekosaur said
19:54:27 <Squarism> decipher this!
19:54:34 <Koterpillar> tom___: you can only match a list starting from the head
19:56:11 <tom___> Oh, i didnt see geekosaur. Ty for your answer.
19:56:37 <tom___> Can't remember if it was said in the tutorial...
19:57:20 <tom___> Do you have a solution for foldr1 (better than the other one i posted in thelink) ?
19:57:43 <tom___> And using the foldr
20:03:08 <tom___> It seems they dont talk about the difference (they called ":" an operator too).
20:04:04 <glguy> : is an infix "data constructor"
20:04:11 <tom___> No one have a foldr1 with a foldr ?
20:05:16 <tom___> Ok glguy. I'll look abot operator and constructor soon (they didnt talk about it yet, if i'm correct).
20:06:29 <dfeuer> An operator can be either a function or a data constructor, depending on whether it starts with a :.
20:06:44 <dfeuer> The notion of operator in Haskell is purely syntactic.
20:09:06 <Cale> dfeuer: Something for you to add to Data.Set: filterMonotonic, partitionMonotonic
20:09:23 <tom___> Can't find definitions of "operator" and "constructor". I'ld like to understand about it. Someone have a link to share ?
20:09:29 <Cale> dfeuer: When you have a predicate which is guaranteed to be monotonic, these operations are possible in O(log n)
20:09:43 <glguy> :t \f -> foldr (\x -> Just . maybe x (f x)) Nothing
20:09:44 <lambdabot> Foldable t => (a -> a -> a) -> t a -> Maybe a
20:10:26 <tom___> (oh, just see the dfeuer answer...)
20:11:16 <dfeuer> Cale, oh, that's pretty interesting. I guess there are actually two `filterMonotonic` variants?
20:11:37 <Cale> dfeuer: yeah, or I suppose there's a way to do it which just looks for where the thing changes
20:12:02 <Cale> and then it works with both monotone increasing and decreasing functions
20:12:16 <lpaste> tom revised âmonFoldr1â: âmonFoldr1â at http://lpaste.net/1455630602060431360
20:13:17 <tom___> Bye guys.
20:13:39 <Cale> dfeuer: It's basically like split, but less annoying to use :P
20:14:17 <dfeuer> Cale, that's an option, I suppose, although there's an efficiency cost. Speaking of extremely related things, split is unbearably useless and splitMember has a nasty API. Can you come up with a splitMember variant people might like?
20:15:21 <dfeuer> One option might be to just use your partitionMonotonic and then check the relevant minimum; is that best, or is it best to get (Set a, Maybe a, Set a), or something else altogether?
20:15:26 <Cale> dfeuer: Making the middle part have type Maybe a might be better
20:15:59 <dfeuer> Cale, it could hardly be worse than the extant interface, but is it better enough?
20:16:19 <Cale> Well, for the remaining use cases once we have a partitionMonotonic
20:16:56 <Cale> An operation I often find myself wanting to do is to obtain all the elements of a Set which are constructed with a given data constructor
20:17:25 <Cale> which becomes doable efficiently if I have partitionMonotonic
20:17:47 <Cale> (assuming the usual ordering on a data type)
20:18:03 <dfeuer> Cale, would you mind sending an email to libraries? Or would you rather I did it?
20:18:07 <Cale> similarly for Map
20:18:14 <dfeuer> OTOH,
20:18:20 <dfeuer> well,
20:18:25 <Zemyla> I have a question. Why is it that updateLookup has different semantics for Maps and IntMaps?
20:18:37 <dfeuer> why did you put them all in a Set to begin with, instead of maintaining a collection of sets?
20:19:02 <Cale> Zemyla: do you mean updateLookupWithKey?
20:19:25 <Zemyla> Yeah.
20:19:30 <dfeuer> data FooSet a b c d = FooSet (Set a) (Set b) (Set c) (Set d), for which you can implement a Set-like interface for data Foo a b c d = A a | B b | C c | D d
20:19:40 <Cale> dfeuer: Well, that's somewhat fair, but sometimes you have a Set or Map for another reason
20:19:49 <Cale> and you want to perform other Set/Map operations at other times
20:20:29 <Cale> and yeah, implementing a replica of all of Data.Map's functionality for your one type is a bit heavy :)
20:20:43 <dfeuer> Cale, what about generics?
20:21:29 <Cale> I don't know
20:22:21 <Cale> Also, we actually already have a our own replica of Data.Map which is called Data.AppendMap and whose sole major distinction is that it has the correct Monoid instance
20:22:26 <dfeuer> Cale, the more I think about it, the less confident I am that your proposed functions are generally applicable. They only *really* improve performance over the current API if you have a monotonic predicate with an expensive inverse.
20:22:30 <Cale> -a
20:22:52 <Cale> dfeuer: I'm thinking mostly of predicates of the form (< x) and such
20:22:58 <shachaf> Cale: You should make a variant of that for Array.
20:23:09 <shachaf> Cale: You can index them with AppendIx.
20:23:15 <Cale> lol
20:23:28 <dfeuer> Cale, the problem is that you're imposing a proof obligation. Those kind of suck.
20:23:46 <Cale> dfeuer: Well, sure, but mapMonotonic already exists...
20:24:03 <Cale> So it's not like you can't screw up the structure of your Set/Map with the operations there :)
20:24:57 <Zemyla> You know, there are monotonic predicates which can't be expressed in the form (> a).
20:25:02 <Cale> and this is comparatively more benign, in that while you can get weird results if you put in some non-monotone predicate, you're not going to get a dysfunctional Set or Map
20:25:20 <Cale> yes
20:25:29 <dfeuer> Hmm.... I guess there are cases where the inverse is slow/complicated. If you want to check for x^5 + a*x^4 + b*x^3 + c*x^2 + d*x + e > f, that will be very hard without the function you seek.
20:25:30 <Cale> Heh, things like isJust
20:25:41 <Zemyla> For example, f :: Rational -> Bool, f x = x > 0 && x * x > 2.
20:25:44 <Cale> Well, that's a poor example, because Nothing
20:25:49 <dfeuer> (Even with positive coefficients)
20:25:49 <Cale> isRight :P
20:26:06 <Cale> and yeah, stuff like that
20:26:16 <Zemyla> dfeuer: If f x = x > a, then what is a?
20:27:35 <dfeuer> Zemyla, I don't undertand your question.
20:27:50 <dfeuer> I guess it can be hard to find the cutoff.
20:27:53 <Cale> If I have a Map (Either a b) c, there ought to be *some* efficient way to pull it apart into (Map a c, Map b c)
20:28:11 <dfeuer> Ah....
20:28:32 <dfeuer> If you have a   Map (Either Integer Integer) c, there is no cutoff point.
20:28:33 <Cale> Maybe we ought to just have *that* operation
20:28:36 <Cale> right
20:29:01 <dfeuer> That gets too specific to Either.
20:29:13 <Cale> Either is special, it can get some special support
20:29:19 <dfeuer> So I'm warming to your partitionMonotonic.
20:29:37 <Zemyla> dfeuer: The answer is there is no value a which can be used for partition instead, because sqrt 2 is not in the rationals.
20:29:43 <dfeuer> Not *that* special.
20:29:59 <Cale> It's the coproduct, more or less
20:30:03 <dfeuer> Zemyla, yes.
20:30:16 <Cale> It's very special
20:30:30 <Cale> Either and (,) are not arbitrary
20:30:55 <dfeuer> Cale, once you start talking in those terms, I'd be much happier with a module implementing sets for Generic coproducts.
20:31:21 <dfeuer> Oh, that's another story, I guess. But likely more efficient.
20:31:49 <Cale> But anyway, partitionEither :: Map (Either a b) c -> (Map a c, Map b c) would be welcomed
20:31:53 <dfeuer> At some point, you actually want generic-trie.
20:32:54 <dfeuer> Cale, I'm happier with the partitionMonotonic suggestion than with that one. Especially because we'll want both monotonic filters too.
20:33:07 <Cale> Sure
20:33:12 <dfeuer> Can you name the oppositeFilter?
20:33:16 <dfeuer> opposite filter?
20:33:40 <Cale> Well, if I can only have one, I'd have partitionMonotonic
20:33:48 <dfeuer> Sure.
20:34:00 <Cale> Perhaps the filter version should just look for the change boundary
20:34:33 <dfeuer> Send the email to the list. Name that, and both filters if you can. Naming the boundary tends to suck, because finding it again is not as cheap as you might expect.
20:34:40 <Cale> and work regardless of whether the predicate is increasing or decreasing
20:35:01 <Cale> hm?
20:35:11 <dfeuer> Oh, change boundary...
20:35:14 <Cale> yes
20:35:23 <dfeuer> You still need two filters.
20:35:29 <Cale> Internally.
20:35:35 <Cale> But you can provide one which will always work
20:35:36 <dfeuer> No, you always need two filters.
20:35:40 <Cale> what?
20:35:49 <dfeuer> One which gets all the small stuff, and one which gets all the large stuff.
20:35:54 <Cale> I mean, you can provide a single efficient function which will work in both of those cases.
20:36:03 <Cale> It's going to give you all the True stuff.
20:36:18 <dfeuer> Oh, I see.
20:36:22 <Cale> and it will figure out whether that's the large or the small stuff for itself
20:36:30 <dfeuer> Hrmmm...
20:36:40 <Cale> (at a constant additional cost)
20:36:50 <dfeuer> Not constant. Logarithmic.
20:36:55 <Cale> No, constant.
20:36:59 <Cale> It only has to figure it out once.
20:37:00 <dfeuer> ?
20:37:02 <Zemyla> If you give partitionMonotonic a non-monotonic function, it'll just partition at an arbitrary point where the predicate changes, yes?
20:37:20 <Cale> Zemyla: yeah
20:37:27 <Cale> Well, ideally.
20:38:01 <dfeuer> Cale, I'm pretty sure it may have to inspect the maximum element and the minimum element, each of which costs logarithmic time.
20:38:43 <Cale> dfeuer: hmm
20:38:56 <dfeuer> Check the root. Then descend the left spine looking for a change. Didn't find one? Now you need to descend the right spine, and that left descent was (I think) a waste of time.
20:38:58 <Cale> dfeuer: Oh, right, we only have some value in the middle
20:39:20 <dfeuer> Yeah, you don't have a finger tree.
20:39:46 <Cale> dfeuer: It's not like Set implemented via FingerTree
20:39:46 <Cale> (and not even for the fingery reason)
20:40:17 <Cale> You'd normally annotate the subtrees with the minimum element
20:40:23 <Cale> I suppose I should say monoidally indexed tree
20:40:31 <Cale> But yeah, we don't have that
20:40:58 <Cale> Okay, fair enough, it's a log extra cost
20:41:23 <dfeuer> Speaking of semi-related things, there's a special case in Data.Map.fromList for the situation where the keys are ascending. It looks like it does some fancy efficient thing until the keys aren't ascending, then reverts to repeated insertions. I'm a-wondering if it would make sense to be more like Data.List.sort and take chunks of ascending and of descending, convert them, and take the union.
20:42:12 <Cale> That sounds plausible
20:43:15 <dfeuer> It'll definitely be worse in the case of up-down-up-down-up-down....
20:44:13 <Cale> I guess you can also have a special case for when you only got one element
20:44:19 <Cale> ugly
20:44:24 <Zemyla> dfeuer: Actually, if you expose both ends like a feque, you are guaranteed to always get at least three at a time.
20:44:37 <Zemyla> *deque
20:44:57 <dfeuer> Zemyla, explain?
20:45:37 <Zemyla> The sort code keeps track of ascending runs and descending runs separately, right?
20:45:39 <Cale> Heh, Map.fromSequence
20:45:57 <dfeuer> Zemyla, currently, the code is not nearly that smart.
20:46:09 <dfeuer> As far as I can tell.
20:46:10 <Cale> Well, the proposed idea
20:46:25 <Zemyla> I mean Data.List.sort (which should honestly be moved to Data.Traversable).
20:47:27 <Squarism> is it "Ugly"/"OK"/"Nice" to bind an Either type result just to propagate an error through an evaluation? Like : eitherRes >>= (\_ -> someNewRight)  ?
20:47:39 <dfeuer> Zemyla, sorting a Traversable doesn't always make sense, even if it's possible. E.g., sorting a Map. Anyway, Zemyla, explain this dequish thing?
20:47:54 <Cale> Squarism: You can use (>>) for that
20:48:00 <Cale> Squarism: and it's fine
20:48:13 <Squarism> okej, good to know
20:48:33 <Zemyla> dfeuer: Well, it's definitely possible, I wrote the code for it weeks ago.
20:49:46 <Zemyla> Anyways, let's say that values tk be sorted are added to a sort accumulator.
20:50:18 <dfeuer> Go on....
20:51:00 <dfeuer> Oh, you mean your Traversable sort. Yeah, there are various ways to do it. foldr to a list, sort, then put back with State. Or your can shove things into a heap or tree and do the same State trick.
20:51:00 <Zemyla> data Accumulator a = Empty | One a | Two a a {- low, then high -} | More (NonEmpty a) (NonEmpty a)
20:51:14 <dfeuer> Oh, accumulator.
20:51:47 <Zemyla> dfeuer: Yes, I did it with State, but I did it in only one traversal by tying the knot.
20:52:34 <dfeuer> Lazy State?
20:52:42 <Zemyla> Yep.
20:53:25 <dfeuer> It seems like a function that should be in Data.Traversable, but not a class method. And I think we still want Data.List.sort, which *should* be faster for lists than a generic thing.
20:53:27 <dfeuer> Anyway!
20:53:33 <dfeuer> Continue explaining this Accumulator?
20:54:01 <Zemyla> Well, you can always add an a to Empty, One, or Two, yes?
20:54:29 <dfeuer> Where adding to Two x y gives you a More of some kind?
20:54:37 <glguy> :t over (partsOf traverse) sort
20:54:38 <lambdabot> (Ord b, Traversable t) => t b -> t b
20:54:40 <dfeuer> I don't quite know what your More represents.
20:55:19 <Zemyla> Yep. And More lt gt is an accumulator where lt is in reverse sorted order, and gt is in sorted order.
20:55:54 <dfeuer> Go on...
20:56:46 <Zemyla> You can add a if a <= head lt or a >= head gt; otherwise, you turn it into a Set or Map as appropriate and start over accumulating with One a.
20:57:18 <Squarism> How should a newcomer interpret this talk about category theory in haskell world? Is it like, 1. we've seen there are many useful properties of certain "categories" and we've modelled everything around it. 2. Or is it like, you need learn your category theory in order to use the language well. 3. Forget all you know about programming, category theory is the only sane abstraction of anything when it com
20:57:18 <Squarism> es to data manipulation.
20:57:52 <dfeuer> Zemyla, you turn both pieces into sets/maps and take their union?
21:00:45 <Zemyla> dfeuer: You can just foldl over lt and then foldr over gt to create the set/map.
21:01:01 <dfeuer> Zemyla, the More fields are potentially large and potentially long-lived temporary values. That doesn't inspire great confidence. I'm guessing it may be better to convert more eagerly into Set/Map pieces, even if some of them are silly.
21:01:05 <prooftechnique> Squarism: None of the above. Category theory might help you understand how some abstraction came about, but it is absolutely not necessary to use it unless you're using a library that insists upon it
21:02:21 <Squarism> prooftechnique, ok. thanks
21:02:34 <dfeuer> Squarism, generally speaking, you only need to know some category theory if you want to write instances for some of Edward Kmett's less-documented classes.
21:03:11 <dfeuer> Or understand the diagrams having to do with bidirectional Proxies in the pipes library.
21:03:34 * hackagebot kawhi 0.1.0 - stats.NBA.com library  https://hackage.haskell.org/package/kawhi-0.1.0 (aaron)
21:04:04 <Cale> Squarism: If you're interested in both Haskell and mathematics more generally, then learning category theory is probably a good idea at some point though.
21:04:44 <Cale> It's one of those things that you absolutely don't need to have to be able to get practical work done, but it's good enrichment, and can provide inspiration towards good design.
21:05:35 <Cale> It's questionable whether it's worth the trouble if you were only ever going to apply it to Haskell though.
21:05:35 <TommyC> Cale: Is that a grad. course thing? :3
21:05:36 <alercah> dfeuer: link to said diagrams?
21:05:52 <TommyC> Cale: I looked that up in my Uni's course catalogue and can't find anything related to "category theory". :(
21:06:05 <Cale> TommyC: Usually... it deserves to be an undergrad thing, imo. But it's not usually considered one.
21:06:20 <dfeuer> alercah, https://hackage.haskell.org/package/pipes-4.2.0/docs/Pipes-Core.html
21:06:42 <Cale> Usually they save it for once you have a bunch of branches of mathematics under your belt, so you can understand all the colourful examples
21:07:05 <Cale> But it's possible to study around the same time you could study group theory, in principle.
21:07:21 <dfeuer> alercah, I don't think those take heavy theory, though.
21:07:22 <TommyC> Cale: Is it easy enough for an undergrad. to understand?
21:07:39 <TommyC> Cale: Like, could it be a undergrad/grad mixed course? :3
21:07:45 <Squarism> Cale, ok.. maybe time ill find that "discrete mathematics" book from uni in the cellar
21:07:58 <Squarism> ...never thought id look in that again
21:09:57 <alercah> dfeuer: I don't think category theory helps with that
21:10:19 <alercah> TommyC: having a diverse background, particularly in algebra, is helpful
21:10:34 <alercah> but you need very little in the way of prerequisites except for mathematical maturity
21:11:08 <TommyC> Heh, well I've only gone up to Abstract Linear Algebra in terms of my Uni.'s mathematical hierarchy.
21:11:37 <Cale> If you pick up group theory or something, it would help, but knowing about vector spaces already gives some nice examples of things along the way
21:12:06 <TommyC> Hrmmm...what about Abstract Algebra (not linear)?
21:12:26 <alercah> That probably covers at least the basics of group theory
21:12:37 <Cale> yeah, "abstract algebra" usually refers to group theory and ring theory, perhaps some field theory
21:12:43 <TommyC> Ah, did not know that.
21:12:47 <TommyC> I'll try and fit that into my schedule.
21:12:49 <Cale> Some combination of those topics
21:12:52 <Cale> heh
21:13:00 <prooftechnique> Galois is where everything gets fun, though
21:13:43 <alercah> never took any Galois theory, though I did do algebraic graph theory, which is pretty wild
21:13:48 <alercah> also some Lie theory
21:13:56 <TommyC> Are thoe classes also proof-writing classes? :3
21:14:48 <prooftechnique> Definitely
21:14:52 <alercah> They had better be
21:15:05 <alercah> If they aren't, I recommend finding a new school.
21:15:21 <prooftechnique> Taking algebra (and a bit of combinatorics) really made my algorithms class much easier
21:15:43 <TommyC> Heh, I'm not a math major and taking Abstract Linear Algebra was tough.
21:15:46 <prooftechnique> Prove something about a data structure, then you don't have to write a bunch of extra code
21:15:46 <alercah> prooftechnique: heh, combinatorics is mandatory where I did my undergrad, it's one of the major obstacles for CS majors
21:16:06 <prooftechnique> Linear algebra is good for your soul
21:16:48 <alercah> TommyC: It will get easier the more you do it.
21:16:53 <TommyC> Heh, it was definitely good for my brain because I had those moments where I could finally connect the proof to the mathematical computations.
21:16:59 <alercah> Algebra proofs tend to be less fiddly than linear algebra
21:17:03 <TommyC> But that class took most of my time that semester.
21:17:06 <alercah> Especially introductory linear algebra
21:17:15 <Zemyla> I know some stuff about group theory, but not Lie groups or such.
21:18:04 <prooftechnique> Getting further in algebra was nice because I started to be allowed to say stuff like "and it follows immediately from blah blah blah" and actually mean it
21:19:46 <Adeon> hey
21:19:57 <Adeon> is there a good list library with the length of the list encoded to the type
21:20:09 <Adeon> I found fixed-vector but it doesn't use GHC numeric literals so you can't write literal numbers
21:20:36 <dolio> Learning more math is typically better, because even though you don't 'need' to, eventually you will probably recognize things that you learned in some problem you want to solve, and it will make the answer easier.
21:21:08 <dolio> And by not learning the math prior, you won't even know what to go learn to find the answer when the time comes.
21:22:03 <tnks> does anyone know with ghcid how you select a test suite if there are more than one defined in the cabal file?
21:24:31 <dolio> And category theory is the king of that sort of thing, in a way, because it is all about tying together seemingly unrelated areas of math into the same abstract structure.
21:38:50 <dfeuer> acowley, you have a PR for vinyl ;-)
21:51:22 <jle`> Adeon: hmatrix has a module with typelits for vectors
21:51:29 <jle`> but they're exclusively vectors for Double's
21:51:41 <jle`> Adeon: but the answer i should have started with is the 'linear' package
21:51:59 <jle`> 'linear' has a newtype wrapper over Data.Vector that includes its length
21:52:11 <jle`> of course these aren't lists
21:52:25 <jle`> there are some issues with having lists w/ typelits for their size
21:53:04 <jle`> lists are inductive data structures and typelits's Nats aren't inductive types, so it's always going to be awkward without typechecker extensions and things like that
21:54:17 <Adeon> well they don't need to be lists in this case technically
21:54:31 <Adeon> didn't know linear had length-encoded vectors
21:54:37 <Adeon> this will get me started, thanks
21:55:04 <jle`> yeah, just making sure because you mentioned lists whether or not you really meant lists or just any sequential data structure
22:08:36 * hackagebot kawhi 0.2.0 - stats.NBA.com library  https://hackage.haskell.org/package/kawhi-0.2.0 (aaron)
22:28:37 * hackagebot hgeos 0.1.1.0 - Simple Haskell bindings to GEOS C API  https://hackage.haskell.org/package/hgeos-0.1.1.0 (rcook)
22:33:37 * hackagebot wai-http2-extra 0.1.0 - WAI utilities for HTTP/2  https://hackage.haskell.org/package/wai-http2-extra-0.1.0 (KazuYamamoto)
22:38:37 * hackagebot mighttpd2 3.3.4 - High performance web server on WAI/warp  https://hackage.haskell.org/package/mighttpd2-3.3.4 (KazuYamamoto)
22:55:09 <angerman> What's the difference between folding and a state monad?
22:55:51 <shachaf> What's the difference between a duck?
22:56:12 <Zemyla> One of its wings is both the same.
22:57:33 <ertes> it would really be useful if Weak from System.Mem.Weak were a functor
22:59:04 <Zemyla> ertes: It'd require unsafePerformIO, though.
22:59:19 <ertes> Zemyla: would it?
22:59:33 <maybefbi> why should IO be in the bottom of the transformer stack?
23:01:18 <angerman> ok. That was not that well phrased. But folding with f :: s -> a -> s over [a] would allow the function to access an initial state, and propagate that through. Having a monad allows to use do notation, but what other additional power do I get, except from not having to have every function splice thread the state explicitly?
23:02:27 <Zemyla> ertes: Everything that creates a Weak is in IO.
23:03:17 <Zemyla> Actually, I can see a way for Weak to be a Functor.
23:03:53 <ertes> Zemyla: dittoâ¦  would probably make it a bit more expensive though
23:04:21 <ertes> my solution now is to just define an existential SomeWeak wrapper, because i don't really need the value
23:04:21 <Zemyla> Coyoneda transform it, and apply the function to it when you use deRefWeak.
23:05:45 <Zemyla> ertes: Actually, Weak could technically become an Applicative.
23:06:10 <shachaf> ertes: Coyoneda Weak?
23:06:19 <shachaf> Yes, Zemyla just said it.
23:07:39 <Zemyla> A WeakApp is a "list" of Weaks and a function applied to the combination of deRefWeaks.
23:07:39 <jle`> maybefbi: nobody is forcing you ... ?
23:07:54 <maybefbi> jle`, ok
23:08:14 <maybefbi> jle`, i will try otherwise and see how it feels
23:08:15 <jle`> you can use any Monad to extend with monad transformers
23:08:22 <jle`> [], Maybe, State, Either e, etc.
23:08:23 <shachaf> angerman: Are you asking about what you're able to do with mapM on a list, or what?
23:08:27 <Zemyla> Weak can't be a Monad, though.
23:08:29 <jle`> you don't have to use IO :)
23:08:38 <jle`> most interesting usages don't involve IO, actually
23:08:49 <ertes> Zemyla, shachaf: yeah, Coyoneda could work, but as said, i don't really need the value anywayâ¦  all i need is 'finalize'
23:08:52 <ReinH> maybefbi: generally speaking, it's because IO can't be a transformer. It must be at the bottom or nowhere.
23:09:11 <maybefbi> ReinH, oh i see now. there is no IOT monad
23:09:20 <ReinH> Yep
23:09:32 <shachaf> ertes: You just want to be notified when something is GCed?
23:09:47 <maybefbi> so if IO is on top of stack i will have to do the plumbing of the bind operator myself
23:10:21 <ertes> shachaf: at a certain point in the application i want to make sure that a finalizer runs, even if the object in question was still aliveâ¦  a rank-2 type makes sure that the scope of these objects is limited
23:10:31 <glguy> There's no IO transformer so if it is on the top of the stack then it's by itself
23:10:38 <jle`> maybefbi: when would IO be at the "top of stack" ? what does that mean?
23:10:57 <maybefbi> jle`, top of the monad transformer stack
23:11:04 <Zemyla> ...actually, join :: Weak (Weak v) -> Weak v produces a Weak that, when derefed, tries to get the first Weak, then tries to get the value of the second Weak.
23:11:07 <ReinH> jle`: The stack of one.
23:11:10 <bernalex> monad transformers aren't stacks.
23:11:16 <jle`> maybefbi: what would that look like?
23:11:24 <jle`> i guess the only case is when IO is your monad itself
23:11:25 <ertes> actually i could just use ResourceT
23:11:28 <ReinH> It wouldn't look like anything, because it isn't possible.
23:12:11 <ertes> hmm, no, i couldn't
23:12:19 <jle`> maybefbi: yeah, your hypothetical question is a bit tricky to answer because it's not even really logically possible :|
23:12:34 <jle`> unless that wasn't a question earlier
23:12:56 <ertes> unfortunately i'm dealing with the world's most terrible API
23:12:57 <Welkin> where is maybecia?
23:13:06 <ReinH> Welkin: more discrete.
23:13:10 <maybefbi> Welkin, thats my alterego
23:13:34 <ertes> aprilbensa
23:13:34 <jle`> freenode is patrolled mostly by maybensa from what i hear
23:13:47 <bizarrefish> Hi all
23:13:50 <Zemyla> Actually, I know what an IOT would look like.
23:14:11 <bizarrefish> Is there some kind of equivalence between meta-circular interpreters and coroutines? You seem to be able to do the same thing with both.
23:14:19 <maybefbi> jle`, i was asking about the disadvantages of having newtype App a = App { runApp :: (Monad m) => IO (ReaderT Config m a) } as your application monad
23:14:31 <bizarrefish> That is, kinda...decouple execution from control flow.
23:14:45 <bizarrefish> Is that a free monad thing, that decoupling?
23:14:55 <Koterpillar> maybefbi: that's not a transformer, is it?
23:15:02 <maybefbi> Koterpillar, it isnt
23:15:05 <Zemyla> newtype IOT a = IOT { unIOT :: forall r. (a -> m r) -> (forall x. FFI x -> (x -> m r) -> m r) -> m r }
23:15:20 <maybefbi> Zemyla, nice
23:15:24 <maybefbi> wish that was there
23:15:30 <ReinH> Zemyla: psst, throw an extra `m' in there.
23:15:30 <jle`> maybefbi: yeah, IO wouldn't really be on "top of the stack" in that case, it's just itself there
23:15:37 <Zemyla> It's basically the free monad transformer on FFI, a list of potential FFI applications.
23:15:54 <ReinH> newtype IOT m a
23:15:59 <ertes> bizarrefish: Free and FreeT are basically Coroutine and CoroutineT
23:16:23 <jle`> maybefbi: also i'm not 100% certain that that has a Monad instance
23:16:52 <maybefbi> jle`, yeah i also dont think IOT exists
23:17:00 <jle`> i mean, the type you wrote isn't a monad
23:17:18 <Zemyla> ertes: Yeah, it's basically "Here's a thing to let you do something else for a while, tell me when you get back".
23:17:20 <jle`> it's just a type ... of questionable usefulness :o
23:17:43 <jle`> i think it's a Functor and Applicative though so you have that going for you
23:17:49 <ertes> bizarrefish: you can go as far as to express your interpreters using Cofree and CofreeT, but regardless, i don't think this is related to metacircular evaluation
23:18:06 <maybefbi> jle`, hmm ok. i cant feel said questionable usefulness, i will have fmap into the IO for anything i want to do
23:18:08 <ertes> bizarrefish: the latter, as far as i see, is rather an evaluation strategy
23:18:29 <jle`> maybefbi: yeah, your type is a Functor and Applicative, so you can sequence them statically and map over results of actions
23:18:29 <Zemyla> jle`: ReaderT is distributive, so IO (Reader r a) = ReaderT r IO a.
23:18:32 <jle`> but you can't bind from it
23:18:35 <jle`> oh neat
23:18:44 <jle`> hm
23:19:03 <Zemyla> Anyways, goodnight all.
23:19:03 <ertes> bizarrefish: also free monads are just one way to express coroutines, and they are cooperative by construction (coroutines in general need not be)
23:19:28 <jle`> maybefbi: but yeah, what is it actually that you want to do?
23:19:34 <Zemyla> ertes: You can't do a preemptive coroutine transformer, can you?
23:19:43 <jle`> maybefbi: if you're trying to figure out a "monad transformer stack" for your program as a first step, that's probably not a good way to go
23:19:47 <ertes> Zemyla: not with monads
23:19:51 <jle`> don't create the stack and write your program after
23:20:11 <ertes> Zemyla: there is no way within the abstraction to enforce preemption points
23:20:13 <maybefbi> jle`, what is the good way to go? write everything without transformers is good way to go?
23:20:50 <jle`> maybefbi: write specific actions and make them polymorphic over monads that have the effects that action needs
23:21:11 <jle`> for example, if you're writing an aciton that needs a configuration, write it foo :: MonadReader Confing m => ... -> m Bar
23:21:27 <jle`> now foo will work over *all* monads that offer Config as an environment you can fetch
23:21:42 <glguy> No, that's not even necessarily good design much less the place to start when you don't understand monad transformers
23:21:57 <jle`> you don't also have to do something crazy, like also allow foo to do IO just because your "app stack" has IO
23:22:00 <ertes> Zemyla: also preemptive coroutines are generally something i'd rather leave to the compiler and RTS and just give me a bunch of IO abstractions (e.g. concurrency)â¦  any EDSL for them is bound to be ugly
23:22:07 <lightandlight> At the end you still have to choose the right monad order
23:22:11 <jle`> glguy: in this way, you don't even ever need to understand monad transformers
23:22:17 <jle`> you don't even ever need to use transformers
23:22:24 <maybefbi> jle`, ok
23:22:28 <glguy> Exposing mtl constraints is a bad habit to start from
23:22:59 <jle`> what would you suggest?
23:23:02 <glguy> If you can write the code without monad transformers go for it, start simple
23:23:32 <lightandlight> Write the program without transformers and then introduce transformers when you notice repetition
23:23:40 <ReinH> glguy: Lets be real, your entire program eventually ends up inside ExceptT . RWST :p
23:23:41 <bernalex> I agree with glguy. I find it absurd that you would start out with so much complexity.
23:23:52 <glguy> If you want to do the constraint style monad structure you should have constraints specific to your problem domain, not the mtl ones
23:24:32 <jle`> sounds fair, but i don't think programming to monad transformers is really a scalable way to do things anyway
23:24:37 <bernalex> software development is an evolutionary process -- not intelligent design.
23:24:55 <jle`> writing constraint-style might not be ideal either
23:24:56 <bernalex> jle`: tbf, I don't like monad transformers at all.
23:25:00 <Welkin> casey muratori has a lot to say about this
23:25:09 <ertes> jle`: there are cases when they make sense as an abstraction, but often abstraction and convenience are confused
23:25:25 <jle`> but i wouldn't start a program by thinking about the monad transformers i'd use
23:25:31 <maybefbi> jle`, i like your think about app monad later idea. im going to try writing with mtl contraints first
23:25:35 <Welkin> he talks about "exploratory programming" where the basic idea is to "do the dumbest, simplest thing that works and then let your program's structure deveop on its own"
23:25:48 <Welkin> develop*
23:25:59 <maybefbi> jle`, that is really more evolutionary than refactor-y
23:26:00 <bernalex> "game development 101: choosing the right monad transformer"
23:26:04 <jle`> `MonadReader Config m => ... -> m Bar` in that sense is the dumbest/simplest thing, because it doens't constrain your future choices at all
23:26:20 <jle`> you write it once and it basically works forever, no mater what you eventually use it in
23:26:24 <maybefbi> jle`, agreed. it is true evolution
23:26:46 <jle`> you're specifying the interface that your function/action expects, and people can later use that in any context that offers that interface
23:26:54 <ertes> jle`: i think (Config -> IO Bar) is even simpler
23:27:05 <glguy> That constrains you to use MonadReader which is this general thing to only use Config
23:27:37 <jle`> `Config -> Bar` might be better in this case, yes
23:27:42 <glguy> Now you cant use that generic constraint for anything else or use code where someone else made the same mistake
23:27:43 <ertes> "MonadReader Config m" is just a clunky way of saying "i'm a function of Config"
23:27:53 <Welkin> start specific, generalize later if necessary
23:27:55 <jle`> MonadReader is a bit silly anyways
23:27:56 <maybefbi> glguy, ertes bernalex https://www.youtube.com/watch?v=GZPup5Iuaqw
23:28:01 <glguy> There function is the right answer
23:28:28 <jle`> maybe the better thing is to just write normal functions
23:28:37 <jle`> and write natural transformations to get them into the context you'd want
23:28:45 <bernalex> time and time again the best solution is to just write a function
23:29:02 <bernalex> it's fp, after all.
23:29:16 <jle`> you'd still have to deal with clunky newtype wrappers to get sensible binds/composition, though, every time
23:29:20 <bernalex> (although I find the same holds true in C++.)
23:29:51 <jle`> you can always just write s -> (a, s)'s, but you'll have to wrap/unwrap to get the sequence, mapM, >>=, fmap, etc. that you want
23:30:00 <jle`> it gets a bit syntactically tedious
23:30:13 <ertes> maybefbi: if you're trying to use a monad transformer to save yourself from passing an argument, let me save you a lot of time now: the return of investment will be negative =)
23:30:43 <Welkin> I learned about monad transformers by creating subsites in yesod...
23:30:49 <Welkin> that was kind of messy
23:30:52 <shachaf> This is kind of a flaw of Haskell and monads and so on, I think.
23:31:10 <bernalex> I learned about monad transformers when my persistent stuff got complicated enough.
23:31:14 <ertes> maybefbi: just compare the ReaderT variant:  "action = do cfg <- ask; â¦ where subaction = do cfg <- ask; â¦"
23:31:27 <ertes> maybefbi: to the regular function variant:  "action cfg = â¦  where subaction = â¦"
23:31:29 <jle`> in this specific case, yeah, i probably don't know any good situations to use ReaderT/MonadReader.  earlier was just a contrived example, sorry :)
23:31:36 <Welkin> but yesod (and anything snoyberg writes) has typeclasses galore
23:31:38 <ertes> maybefbi: less code, faster code, cleaner code
23:32:52 <maybefbi> ertes, as a newbie both your view and jle`'s view are equivalent to me. i treat them both with skepticism at the scale of large programs. i will have to learn by screwing up which option is better
23:33:20 <jle`> the nice thing about haskell is that it's fun to refactor :)
23:33:26 <ReinH> maybefbi: luckily, Haskell is in general very good at scale.
23:33:45 <ertes> maybefbi: go for itâ¦  i had to learn it the hard way, too =)
23:33:59 <ReinH> You might have to write your own compiler once you get past a few million LoC though...
23:34:05 <maybefbi> lol
23:34:18 <ReinH> No seriously.
23:34:25 <ReinH> That's basically what Standard Chartered did.
23:34:36 <maybefbi> free monad interpreters you mean? or Mu compiler?
23:35:15 <ReinH> They wrote their own haskell compiler, in part to deal with the size of the codebase
23:35:49 <ReinH> Don Stewart talked about it a bit on my podcast http://www.haskellcast.com/episode/002-don-stewart-on-real-world-haskell/
23:35:54 <maybefbi> Mu which is the SCB version haskell is strict by default and was made to work as excel formulas
23:36:40 <maybefbi> my NUS professor recommended me to work there with him. but he is an MIT guy and i cant match with his ivy league team in singapore
23:37:08 <maybefbi> they are too smart
23:37:27 <ReinH> I think the best way to describe Mu is as a Haskell dialect.
23:38:13 <ReinH> And yes, Lennart is wicked smart. Maybe we'll have him on the podcast some time.
23:39:12 <ReinH> (FWIW there's some more info about Mu in this old CUFP workshop report, if anyone is interested http://anil.recoil.org/papers/2011-cufp-scribe-preprint.pdf)
23:40:37 <maybefbi> brb
23:42:38 <codebje> how would you all recommend applying a function to pairwise elements of a list, that is "foo f (a:b:rs) = f a b : foo f rs", or is that pretty much it?
23:42:52 <codebje> (plus the two cases for zero/one elements)
23:43:10 <ReinH> codebje: zipWith
23:43:20 <ReinH> > zipWith (+) [1,2,3] [3,2,1]
23:43:22 <lambdabot>  [4,4,4]
23:43:32 <codebje> I only have one list: [1,2,3]
23:43:40 <ReinH> Ah, I misread.
23:43:41 <codebje> I want to run f on (1,2), then have 3 left over
23:44:01 <ReinH> zipWith f <*> tail
23:44:06 <ertes> codebje: write recursively
23:44:23 <codebje> reinh, that gives [ 1 `f` 2, 2 `f` 3, ...]
23:44:23 <lpaste> jeroenbourgois pasted âgroup invoices based in clientâ at http://lpaste.net/171033
23:44:28 <codebje> not quite right
23:44:34 <ReinH> codebje: I misread again :)
23:44:44 <lpaste> jeroenbourgois pasted âgroup invoices based in clientâ at http://lpaste.net/171034
23:44:55 <ertes> codebje: although you can iterate with drop
23:44:55 <ReinH> codebje: what do you do with dangling elements (i.e., an odd-length list)?
23:44:57 <rhovland> map f $ chunksOf 2 or something?
23:45:00 <codebje> ertes, that's more or less what I thought, but was hoping there'd be something as stupidly clever as "zip <*> tail" is
23:45:08 <ertes> > map (take 2) . iterate (drop 2) $ [1..]
23:45:09 <lambdabot>  [[1,2],[3,4],[5,6],[7,8],[9,10],[11,12],[13,14],[15,16],[17,18],[19,20],[21,...
23:45:23 <ertes> > takeWhile (not . null) . map (take 2) . iterate (drop 2) $ [1..10]
23:45:25 <lambdabot>  [[1,2],[3,4],[5,6],[7,8],[9,10]]
23:45:25 <codebje> rhovland, more or less that, yes
23:45:42 <ertes> codebje: but again, beware of edge casesâ¦  you're not really saving much code that way
23:45:42 <codebje> reinh, in this case, f must be a -> a -> a, and a dangling element is unmodified
23:45:50 <jeroenbourgois> sorry for the double paste... but I am a bit stuck... I have a list of Invoices, each with a list of tasks and a client name. I would like to get one list of all tasks accross a list of invoices for a given client
23:45:54 <codebje> ertes, yes, and I lose a lot of readability
23:45:57 <ReinH> codebje: write your own function using recursion
23:46:00 <codebje> I'll go with the readable recursive one
23:46:11 <ertes> codebje: good choice =)
23:46:33 <jeroenbourgois> but I just cannot get it to work. I thought the pattern match was ok, first hit the actual correct case with one item, and for the rest of the list recurser again with one item
23:47:34 <pavonia> jeroenbourgois: Do you want concat instead of sum maybe?
23:47:44 <rhovland> > map sum . chunksOf 2 $ [1,2,3,4,5]
23:47:46 <lambdabot>  [3,7,5]
23:47:48 <ReinH> jeroenbourgois: tasks <=< invoices
23:48:09 <jeroenbourgois> euhm yeah that might be it. I will try! I am such a beginner, struggling with paradigms and syntax :)
23:48:10 <ReinH> where tasks :: Invoice -> [Task] and invoices :: Client -> [Invoice]
23:48:26 <ertes> has chunksOf finally made it into the base library?
23:48:47 <jeroenbourgois> ReinH thanks I will try that
23:48:52 <rhovland> ertes: ha dunno
23:49:00 <pavonia> jeroenbourgois: Err, you can't use map like this because you have to map a function, which in your case it isn't one
23:49:01 <codebje> not 4.9, I think
23:49:39 <ertes> it's one of the few functions i believe really should be in base
23:50:38 <jeroenbourgois> pavonia: ok, I will split it up and first try to traverse the list of invoices and just keep the ones that match the passed client name
23:51:15 <jeroenbourgois> pavonia: but I am afraid I will bump into the same problem... :D
23:51:55 <pavonia> I think it's best to split the recursive part and the checking part into two functions, where the first uses the second
23:51:55 <jeroenbourgois> let's say my function is invoicesByClient :: [Invoice] -> String -> [Invoice] (string = client name)
23:54:24 <ReinH> you can: tasks <=< flip invoicesByClient "foo" . invoices
23:54:56 <ReinH> Wait, is the fixity right or do you need parens?
23:56:49 <jeroenbourgois> pavonia: in javascript I would just do: tasksForClient = invoices.filter(i => i.client === clientName).map(i => i.tasks)
23:57:20 <jeroenbourgois> maybe I focus to much on this syntax in order to get it done in Haskell?
23:57:46 <pavonia> Uh, I don't know JS very well
23:58:14 <pavonia> I think the problem is that you are trying to do two things in once
23:59:03 <ReinH> jeroenbourgois: so you start with a list of invoices and you want a list of tasks?
23:59:20 <jeroenbourgois> yes, but the invoices are different clients
23:59:25 <pavonia> What you want is mapping a function, that does the checking and returns a (possibly empty) list of tasks, and then concatenate all the results
23:59:31 <jeroenbourgois> say one invoice for sony, one for nintendo, etc
23:59:31 <ReinH> your javascript would give you an array of arrays of translate, and translates directly to Haskell
23:59:42 <jeroenbourgois> yes indeed
