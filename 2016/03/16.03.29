00:02:34 <Cale> Newby: lol, I've almost finished translating your thing
00:02:55 <Cale> though, it's kind of mangled
00:03:03 <Cale> was this copy-pasted from a PDF?
00:03:12 <Newby> Cale: haha and i finished my sleepless night... xD
00:03:19 <Newby> Yes
00:04:16 <Newby> Cale: if you need some help to translate ;)  to late to sleep...
00:04:18 <Cale> On d√©nit H0 et V 0 √† partir de H et V de la fa√ßon suivante : H0 = [h2; : : : ; hn] et V 0 = [v01; : : : ; v0m ], o√π v0j = vj  1 si j est √©l√©ment de L1 et v0j = vj sinon (1  j  m). -- there are missing characters here...
00:04:38 <Cale> I have no problem with the French words, but when symbols are missing...
00:05:04 <u_> so um
00:05:07 <u_> can anyone explain this:
00:05:10 <u_> GHCi, version 7.10.2: http://www.haskell.org/ghc/  :? for help
00:05:10 <u_> Prelude> let numbers = iterate (\x -> x*x*x*677 + x*x*9 + x*82 + 31) 938
00:05:10 <u_> Prelude> map even numbers
00:05:12 <u_> [True,False,False,False,False,False,False,False,False,False,Bus error: 10
00:05:58 <Newby> Cale: "On d√©finit" 
00:06:25 <Cale> Newby: yeah, heh, I sort of realised that's what that was
00:06:37 <Cale> (it left out the fi every time)
00:07:33 <ahihi> u_: looks like a bug :)
00:07:39 * hackagebot wai-app-static 3.1.5 - WAI application for static serving  https://hackage.haskell.org/package/wai-app-static-3.1.5 (MichaelSnoyman)
00:07:39 * hackagebot conduit-extra 1.1.12 - Batteries included conduit: adapters for common libraries.  https://hackage.haskell.org/package/conduit-extra-1.1.12 (MichaelSnoyman)
00:08:31 <hjulle> Cale: It's because fi is printed as a ligature in the pdf
00:08:42 <lazyWriter> among the concatenative languages (forth, factor, etc ...) can any of them support haskell like (1) pattern matching or (2) type system ?
00:08:42 <Cale> u_: did you run out of memory?
00:08:49 <lazyWriter> or do those langauges inheriently can not do so?
00:08:50 <Newby> Cale: and it's H' and V4 (not H0 and V0) ^^     "o√π v'j = vj - 1 si j est √©l√©ment de L1 et v'j = vj sinon (1<= j <= m)
00:08:53 <Cale> u_: those numbers get large quite rapidly
00:08:57 <lazyWriter> [I'm trying to build a concatenative DSL inside haskell]
00:09:00 <Newby> Cale: V'*
00:09:09 <Cale> oh, interesting
00:09:13 <u_> Cale: doesn't it say something else when you run out of memory?
00:09:22 <u_> like just "heap exceeded" or something
00:09:51 <hjulle> u_: Many strange things can happen when you run out of memory.
00:09:53 <Cale> u_: I dunno, all kinds of things can happen on Linux when you run out of memory, because the kernel likes to allow things to allocate too much and then kill them later.
00:10:21 <u_> meh, i guess that's all there is to it
00:10:30 <ahihi> I see this behavior on my OS X system with 8GB, my linux box with 1GB gets a bit further before dying with "GNU MP: Cannot allocate memory (size=537133072)"
00:10:31 <u_> happens for anything that makes a large number
00:10:38 <u_> ahihi: yeah i'm on os x too
00:10:49 <u_> must be an os x thing
00:10:53 <Cale> Newby: here's how far I've gotten :) http://lpaste.net/157417
00:12:03 <Cale> Newby: Of course, the most important part of the text would be the most mangled by copy/paste from PDF.
00:12:54 <Newby> Cale: yes :/ parts with symbols
00:13:50 <ahihi> googling seems to indicate that "Bus error: 10" is something like a segmentation fault, rather than running out of memory
00:14:27 <Newby> Cale: But your comprehention is pretty good :o
00:15:02 <Cale> Newby: Well, I'm trained as a mathematician, so I know what kinds of phrases to expect.
00:15:38 <Cale> (and I live in Canada, we had French classes in elementary school)
00:16:01 <Newby> Cale: Canada! You are so lucky :p
00:16:16 <Cale> I can't really speak or write French, but I can read French mathematics pretty well.
00:19:08 <Newby> Cale: it's like me with English. I've a really good compehension but i'm terrible at expresion. But French is way harder to learn
00:29:13 <kamog> hmm, I'm trying to enumerate prime numbers with haskell. that's problematic...
00:34:09 <hjulle> ...because?
00:36:06 <bartavelle> hjulle, well, there are a lot of them
00:37:15 <hjulle> lol :P
00:39:51 <EvanR> then it should be even easier in haskell because it supports infinite!
00:41:05 <hjulle> But I want a function that calculates the last prime. :-/
00:41:21 <jle`>  > last primes
00:41:44 * jle` 1897387434
00:41:48 <jle`> hm that wasn't so bad
00:41:54 <EvanR> would you believe there isnt one
00:42:12 <EvanR> also how would a finitist deal with this question
00:42:31 <jle`> there should be a last prime.  the frequency of primes decreases as you go higher and higher so of course, it'll eventually be zero
00:42:37 <hjulle> EvanR: But jle` just calculated it. So you must be wrong.
00:42:47 <EvanR> he gave an even number
00:43:00 <jle`> that wasn't me that was lambdabot
00:43:24 <hjulle> EvanR: So what? There are even primes. :)
00:43:28 <jle`> > last primes
00:43:29 <lambdabot>  15890734039
00:43:31 <EvanR> thats not one of them
00:43:57 <EvanR> jle`: pay no attention to jle` behind the curtain!
00:44:20 <hjulle> EvanR: How do you know? There are *very* many primes. ;)
00:44:36 <Rotaerk> better test all of them
00:44:39 <EvanR> > 1897387434 / 2
00:44:40 <lambdabot>  9.48693717e8
00:44:51 <jle`> lol
00:44:52 <kamog> hjulle: the cute version is slow, the fast version is ugly. I hoped it'd become cute with "while" thing, but it's still as long as it was with iter subfunctions
00:46:53 <kamog> https://gist.github.com/anonymous/9daaedc9efa1859bd34d
00:46:56 <hjulle> kamog: Which are "the Cute, the Fast and the Ugly" versions?
00:47:03 <kamog> what's wrong with them?
00:49:33 <kamog> hjulle: the fast one was with tail recursive helper functions for iterations. (it was faster than ocaml and almost as fast as c++!) but it was rewritten into the "while" version which is 3 times slower.
00:54:33 <hjulle> kamog: Why are you not stopping att sqrt(p) when checking if p is prime? (or did I missread the code?)
00:56:24 <hjulle> oh it's a sieve, that explaines it.
00:57:21 <hjulle> kamog: Or not quite that either. What algorithm are you using?
00:57:39 <kamog> hjulle: it stops at the square root, but it's determined by when quotient of integer division becomes smaller than a prime divisor. (I was initially curious whether it costs the same to calculate mod as divMod).
00:58:00 <hjulle> aha ok
01:02:10 <kamog> hjulle: though, it doesn't work for the functional version of the program (it scans up to the square root but from the wrong side which can probably explain why it's slow).
01:04:17 <kamog> the version which produces increasing list of primes needs to reverse it many time and somehow it consumes too much memory, so I can't tell how fast it is
01:07:29 <kamog> and it's all because I'm doing it wrong...
01:29:22 <suppi> if I have a haskell shared library and i want to call a haskell function from C or something and also have some RTE options, is there a way to do that?
01:29:39 <suppi> RTS*
01:29:43 <merijn> suppi: Specifically which RTS options?
01:29:52 <merijn> The GHC specific API lets you control lots of things
01:31:31 <suppi> merijn, for example stack size
01:32:18 <FeyFre> noob in haskel. how explicitely specify return type of function?
01:33:59 <FeyFre> have this: let foo  x y = x / y / (x-y) - known to be always Integer, but produces flaot result type
01:34:32 <MichaelK> FeyFre: you want integer division `div`
01:35:08 <MichaelK> @ty (/)
01:35:09 <lambdabot> Fractional a => a -> a -> a
01:35:25 <MichaelK> ^ (/) always returns a fractional type
01:35:53 <merijn> suppi: I think it still parses RTS flags from the commandline when you call "hs_init(&argc, &argv);"
01:36:19 <merijn> Manual says "We pass references to argc and argv to hs_init() so that it can separate out any arguments for the RTS (i.e. those arguments between +RTS...-RTS)."
01:37:03 <FeyFre> it fails to accept definition
01:37:59 <EvanR> :t let foo x y = x `div` y `div` (x-y) in foo
01:38:00 <lambdabot> Integral a => a -> a -> a
01:38:34 <suppi> merijn, great. thanks! can you link me the manual?
01:38:43 <merijn> https://downloads.haskell.org/~ghc/7.0.2/docs/html/users_guide/ffi-ghc.html
01:38:47 <FeyFre> ah got it. used prefix form: let foo = div(div n k) (n-k)
01:39:57 <merijn> suppi: I had a minimal example of using a C main with haskell modules (not library, but should be similar) here: https://gist.github.com/merijn/4a0fee2b3a5ef3476aa4
01:40:42 <suppi> merijn, thank you very much
01:40:54 <MichaelK> Does anyone know why "f $ x" would not only be not equal to "f $! x" but throw an error while "f $! x" works (no IO whatsoever)? Could an extension I'm using do it or should I submit a bug report?
01:42:27 <merijn> MichaelK: What error?
01:43:24 <MichaelK> Couldn't match type ‚ÄòFWrapper z w‚Äô with ‚ÄòFix t0 -> FWrapper (b0 -> Bool) Bool‚Äô where Fix is basically Maybe (but without all of Maybe's instances) and FWrapper is "data FWrapper a b = FWrapper a b"
01:44:24 <merijn> MichaelK: lpaste a minimal exmplae + error, because all anyone can do now is guess
01:44:49 <MichaelK> merijn: ok
01:53:46 <hjulle> kamog: Why not just do something like "makePrimeList n = let primeList = take n $ 2:filter (isPrime primeList) [3,5..] in primeList
01:54:46 <hjulle> kamog: It's both simpler and faster according to my test.
02:03:31 <hjulle> kamog: Actually, it's even faster than the list_primes version that uses IOUArray.
02:06:36 <lpaste> MichaelK pasted ‚ÄúWhy does strict matter here?‚Äù at http://lpaste.net/157423
02:07:08 <MichaelK> merijn: I think that's decently minimal
02:08:02 <MichaelK> Now ($) gives a "No instance" error and ($!) returns properly
02:09:58 <hjulle> I'm tempted to say "UndecidableInstances and OverlappingInstances? Not reading any longer."
02:10:54 <hjulle> But it is still strange that one gives a type error and the other do not. :/
02:11:23 <merijn> $ has ugly hacks in the typechecker to make it accept Rank2Types, not sure if that plays a part
02:11:57 <MichaelK> merijn: wouldn't that require those extensions? or is it always active?
02:12:23 <merijn> No, $ is literally special cased in the type checker for some things
02:12:38 <merijn> Although I don't think it should effect this
02:12:48 <merijn> But otoh, I'm not quite sure what this code is even doing
02:12:53 <MichaelK> Oh, ok. Possibly weirder is that let f = cfun id dum in f Nothing works..
02:13:09 <hjulle> (My mind model for those two extensions is "MAGIC" and "Here be dragons!")
02:14:02 <merijn> MichaelK: let bindings with GADTs results in monomorphisation, I think?
02:14:28 <kamog> hjulle: aww! it is fast here too. unfortunately, I have problems with reasoning about lazy recursion...
02:14:36 <EvanR> its monomorphin time!
02:15:15 <MichaelK> NoMonomorphismRestriction does nothing (I can tell) to it
02:15:18 <tdammers> monomorphism means you can only use one kind of morphine at a time, yes?
02:15:35 <merijn> That's because there is MonoLocalBinds implied by GADT, iirc
02:16:07 <MichaelK> hm
02:16:19 <hjulle> kamog: Well, the recursion is going to be lazy most of the time anyways, so you better start getting used to it. ;)
02:17:26 <MichaelK> the gist of the code is to apply a function "directly" to the Wrapped part
02:17:42 <hjulle> kamog: What specifically is hard to understand?
02:18:05 <EvanR> is de bruijn really pronounced "de brown" ?
02:18:23 <tdammers> EvanR: no. It's pronounced "de bruijn"
02:18:33 <EvanR> ok, these notes suck then
02:18:36 <tdammers> where "uij" is an old spelling for "ui"
02:18:53 <tdammers> a good approximation for the "ui" sound is "try to say all the vowels you know at once"
02:19:03 <EvanR> lol
02:20:53 <EvanR> wow this super british woman on youtube is going full "de bruaine"
02:21:24 <EvanR> might be a voice synth
02:23:27 <merijn> EvanR: People saying "de brown" are about as wrong as people saying "van go", in other words, they're not even in the same solar system as the correct pronounciation >.>
02:24:02 <merijn> EvanR: Additional nitpick, people incorrectly writing "de Bruijn" when refering to him by just last name, as opposed to properly capitalised "De Bruijn" :p
02:24:33 <merijn> Google Translate appears to do an adequate pronounciation
02:25:06 <EvanR> in dutch?
02:25:13 <Hafydd> Vincent van AlphaGo.
02:25:14 <merijn> Yeah
02:25:44 <merijn> EvanR: It should auto-detect Dutch
02:26:13 <merijn> Mind you, my experience is that most native English speakers aren't even able to hear the correct pronounciation, let alone reproduce it :p
02:26:33 <EvanR> where the hell did "de brown" come from
02:26:34 <kamog> hjulle: hmm, it takes an initial sublist of length n each iteration filtering odd numbers with a smaller list of primes. It's difficult to find the base case but I understand that when it tries to compute the first prime, it looks at 2 and never bothers with this question, so 3 becomes a new prime it knows about. I'd also think that taking sublist would make it slow (but it did magic with fusion probably). It's all so unusual.
02:26:41 <merijn> They seem to hear "ui/eu/oe/ou/au" identically
02:26:50 <merijn> EvanR: Bruin is literally brown in Dutch
02:26:53 <EvanR> ah
02:27:22 <Hafydd> User Interface/European Union/Oxford English/Open University/Australia.
02:28:02 <kamog> hjulle: but yeah, it's small, beautiful, and very fast.
02:28:18 <merijn> oh, I guess I forgot ei/ij*/ie as digraphs, but those are less commonly confused :p * - technically a letter and not a digraph, the more you know...
02:28:24 <Hafydd> Damn, I thought this was #haskell-blah. Please excuse my more-inane-than-usual comments.
02:28:44 <EvanR> all these speakers on youtube randomly choose a pronounciation, like the exact choice doesnt matter since theyre not dutch. but... seriously if youre going to say so many times its distracting
02:29:13 <jophish> http://forvo.com/word/nicolaas_govert_de_bruijn/
02:29:16 <hjulle> kamog: Try to not view it as iterations. It is just one list, which happens to refer to itself. ;)
02:29:28 <jophish> The pronunciation sounds pretty compressed...
02:29:45 <merijn> jophish: It's well pronounced, but so many artefacts...
02:30:03 <EvanR> they must have used 99.999999999% compression
02:31:07 <EvanR> im going with de bruh ijn
02:31:35 <tdammers> "de brooophphphththth"
02:31:42 <hjulle> kamog: Moving the take n outside of the "loop" would give the same result and approximately the same preformance.
02:31:44 <tdammers> good enough
02:34:02 <MichaelK> merijn: I'm pretty stumped on it. Do you think it's an actual bug I should submit?
02:34:28 <hjulle> kamog: You could even remove "take n" entirely and get similar performance. But it would be more difficult to mesure, since the program never stops. ;)
02:34:29 <EvanR> is there any consequence of counting de bruijn indices from zero instead of 1 like on wikipedia
02:35:02 <jophish> https://youtu.be/YLTQv8RH1TE?t=197
02:36:05 <cocreature> EvanR: yes, lua people hate you
02:36:21 <jophish> EvanR: I think that's the only sensible way of doing it :)
02:36:38 <EvanR> 1 made no sense to me
02:37:24 <jophish> well, I suppose it counts how many lambdas you need to wrap it in until it's free
02:37:56 <jophish> but that would just change > to >=
02:38:45 <kamog> hjulle: it's difficult to think about performance if I don't use operational point of view. Yes, it's an infinite list of prime numbers without 'take' (I tried to write it but couldn't, maybe because I can only think of growing lists explicitly out of nils by consing).
02:38:53 <hjulle> kamog: The key feature of this code is memoization*, meaning that there is only ever one copy of the list primeList in memory, and it is never changed, there is only more that's evaluated. Most of the time it looks like 2 : 3 : 5 : <unevaluated thunk>.
02:39:11 <merijn> It's not really memoization...
02:39:12 <hjulle> *That's not actually what memoization means.
02:39:39 <merijn> Oh, I wasn't referring to broken validation
02:39:47 <merijn> But the inability of any human to type ƒ≥ :p
02:39:55 <liste> merijn: wrong channel?
02:40:01 <merijn> yeah
02:40:10 * merijn blames irssi
02:40:18 <hjulle> kamog: But the operational point of view for haskell is not loops, it's partial evaluation.
02:40:41 <EvanR> ƒ≥ >_> ƒ≥ƒ≥ƒ≥
02:40:49 <EvanR> the width of this ligature is weird
02:41:03 <EvanR> de bruƒ≥n
02:41:06 <EvanR> ouch
02:42:17 <merijn> EvanR: Why? It's single space, unless your font is wonky
02:42:31 <merijn> Because it's not a ligature, it's a letter
02:43:45 <EvanR> the dont looks fine but the renderer decided to use 1.4324354 squares instead of 1
02:43:49 <EvanR> the font*
02:44:11 <merijn> Looks fine here
02:44:15 <hjulle> kamog: http://blog.ezyang.com/2011/04/the-haskell-heap/
02:44:18 <merijn> Monaco font, best font ;)
02:44:26 <EvanR> let me guess not using a 1970 terminal
02:45:02 <kamog> hjulle: partial evaluation? in the sense of laziness or partial application?
02:45:14 <merijn> EvanR: Terminal.app :)
02:45:18 <hjulle> kamog: Laziness
02:46:11 <hjulle> kamog: If you want to think about performance for haskell, you need an accurate mind model. I personally like the series of blog posts that I linked above.
02:50:09 <kamog> hjulle: hmm, so there is an initial segment of primeList, but how can it be immutable? If you add an element to the end of a list, you copy the whole list building upon that element at the end.
02:50:36 <EvanR> not always
02:50:50 <hjulle> kamog: The list is infinite from the beginning :)
02:51:09 <EvanR> let ones = 1:ones in ones
02:51:16 <EvanR> only creates 1 list
02:52:21 <hjulle> In this case I take the infinite list [3,5..] and filter it, which returns a new infinite list.
02:53:20 <kamog> hjulle: so, it's more like a piece of code that generates the numbers + already found prime numbers.
02:53:38 <hjulle> If you want to evaluate 'ones', it is done in the following way:
02:54:24 <hjulle> or wait, skip that
02:56:05 <merijn> Bah
02:56:19 <merijn> Weak pointers aren't Ord? How am I supposed to put them in a map now? :(
02:57:13 <rydgel> merijn: I guess by doing the Ord instance yourself?
02:57:21 <hjulle> the memory structure of ones after evaluating is {ones} = {{pointer to the number 1} : {pointer to {ones}}}
02:57:56 <opqdonut> wow, Weak isn't even Eq?
02:57:59 <MichaelK> kamog: It's like a generator in Python
03:01:03 <merijn> rydgel: That's not possible
03:01:11 <merijn> opqdonut: I know :\
03:02:22 <EvanR> puttem in an Eq map
03:02:45 <EvanR> > lookup 3 [(1,'a'),(3,'b')]
03:02:47 <lambdabot>  Just 'b'
03:03:12 <EvanR> ah no Eq
03:03:37 <EvanR> you can create a stable name for each one and pair it with the weak ref
03:04:01 <EvanR> which also seems to not have Ord but does have Eq
03:04:07 <hjulle> kamog: And in the case of prime list, the evaluation steps are approximately: primeList = 2 : <unevaluated function "filter (isPrime primeList) [3,5..]"> = 2 : 3 : <unevaluated function filter (isPrime primeList) [5,7..]> = ...  Where primeList is always a pointer to the same memory location, that gets more and more evaluated over time.
03:06:12 <hjulle> The reason for the second evaluation step is that filter is defined as recursion over the list it was given.
03:12:24 <hjulle> kamog: Another key concept that you need to learn is WHNF (Weak Head Normal Form). It is what expressions are normally evaluated to.
03:19:00 <kamog> hjulle: So, when print requests an integer to print, it'll go and execute an iteratation which generates a new element of the infinite list? Where can I read about WHNF?
03:19:21 <hjulle> kamog: Also try changing it to this: "makePrimeList n = take n $ 2:filter (isPrime (makePrimeList n)) [3,5..]". The performance will be (much) worse. Try to figure out why.
03:20:34 <hjulle> makePrimeList n = let primeList = take n $ 2:filter (isPrime primeList) [3,5..] in primeList
03:20:42 <hjulle> http://stackoverflow.com/questions/6872898/haskell-what-is-weak-head-normal-form
03:21:58 <mike993> hi, I'm doing some basic exercises to learn HS but I'm stuck with some nested constructors
03:22:07 <mike993> http://pastebin.com/ASySNgS9
03:22:24 <hjulle> https://en.wikibooks.org/wiki/Haskell/Laziness#Thunks_and_Weak_head_normal_form
03:22:30 <mike993> I don't understand hot to tell to check for the field Year of 't'
03:22:37 <mike993> how *
03:23:09 <liste> mike993: you're missing a \
03:23:15 <liste> and ->
03:23:27 <liste> mike993: are you familiar with lambdas?
03:23:58 <mike993> \liste not too much
03:24:07 <liste> mike993: line 17, after `filter'
03:24:21 <liste> you've got ((Trans _ year _) == y)
03:24:33 <liste> maybe you're after (\(Trans _ year _) -> year == y) ?
03:27:47 <mike993> it seems to work
03:27:49 <mike993> thank you
03:28:28 <liste> mike993: you're welcome! get to know lambdas, they're absolutely essential
03:28:37 <liste> > (\x -> x*2 + 1) 15
03:28:39 <lambdabot>  31
03:28:54 <mike993> how does it know to get that field from 't' though?
03:29:07 <mike993> throught type checking?
03:29:53 <liste> mike993: it's in the top level pattern
03:30:03 <mike993> oh nevermind
03:30:13 <kamog> hjulle: hmm, here is a guess: it's slow because it grows a new prime list each time?
03:31:24 <hjulle> yes. Which is because a function is called every time, instead of just evaluating a known value.
03:33:26 <mikail_> Hi, I'm new to Haskell and one thing that puzzles me is how Haskell projects are structured. I come from Java land and there is a certain convention that most projects follow there. If I take the following project as an example: https://github.com/tebello-thejane/bitx-haskell/blob/master/src/Network/Bitcoin/BitX.hs. Why do authors include this file with a list of just imports?
03:33:50 <hjulle> kamog: A key detail about WHNF is that evaluation stops whenever the evaluation gets to a constructor, unless an element of the constructor is forced.
03:35:46 <pavonia> mikail_: It's a convenient module to import (possibly) the complete API from that package
03:36:17 <hjulle> mikail_: It's for reexporting functions from other modules, so people don't have to have a long list of imports every time they use the library.
03:36:47 <mikail_> oh right - simple as that
03:38:11 * xa0 is trying to comprehend coffee comonads
03:38:22 <xa0> *cofree
03:38:38 <hjulle> mikail_: The list in parentheses at the top are the exports.
03:39:27 <hjulle> It's for co-drinking. :)
03:39:55 <mikail_> Thanks hjulle. Please could you give some advice on some Haskell I have written. I have simulate function and I would advice on the layout. It does alot and I have split it out on a number of lines. Have I followed Haskell convention here? Code is at: http://lpaste.net/157426
03:40:09 <merijn> So...how do I maintain a set of elements so that I can delete them without having access to an Eq/Ord instance? :\
03:41:26 <hjulle> mikail_: You are not actually using the do notation
03:41:56 <mikail_> oh yes, this is a silly mistake
03:42:06 <mikail_> i will take that out
03:43:10 <hjulle> mikail_: Also, try to avoid very long subexpressions, it's better to break it out into functions/"variables" using let or where
03:44:28 <mikail_> so if I break this up so that the foldr is in a separate function, is that better?
03:45:00 <hjulle> Yes. Especially the lambda.
03:45:12 <mikail_> oh right
03:45:17 <mikail_> yes that's nice
03:45:19 <mikail_> I will do that
03:45:33 <mikail_> thank you
03:45:35 <hjulle> That will also give you more chances to name stuff, which will make the code more readable.
03:45:45 <mikail_> yes I see your point
03:45:54 <mikail_> thank you for your advice
03:46:05 <_nate_> even if you left it the way it is i think do notation would be more readable than >>= and lambda
03:47:22 <mikail_> @_nate_, maybe you are right but I was reading an article on Mr Paul Hudak and he says that he never liked do notation as it was hiding the functional nature of Haskell. I am agreeing with him
03:47:22 <lambdabot> Unknown command, try @list
03:49:36 <hjulle> mikail_: you could also eliminate the lambda by changing order of the arguments to newPrice so rnd and price are last, and then do eta reduction, to get point free style.
03:50:04 <hjulle> Eta reduction = change "\x -> f a x" to "f a"
03:50:19 <mikail_> @hjulle, is this a recommended approach?
03:50:19 <lambdabot> Unknown command, try @list
03:50:40 <mikail_> i'm thinking it might confuse people who read the code?
03:50:41 <xa0> @list
03:50:41 <lambdabot> What module?  Try @listmodules for some ideas.
03:51:18 <mikail_> it seems a nice way thought
03:51:26 <mikail_> *though*
03:51:53 <hjulle> mikail_: It's usually recommended, but sometimes it is good to be explicit.
03:52:24 <Jinxit> pointfree style is good when it's simpler
03:52:52 <Jinxit> gets you thinking about function composition
03:53:19 <hjulle> It leads to less code, which often makes it easier to read, which usually compensates for the lack of explicitness.
03:53:34 <mikail_> Yes it's very nice
03:55:25 <mikail_> Thank you for all your advice - it's very useful to me. Bye
04:12:13 <Gurkenglas> @tell mikail_ Since newPrice just multiplies a factor onto the existing price, you could replace the foldr with product, and take the price argument out of the newPrice function, perhaps renaming newPrice to something involving the word factor.
04:12:13 <lambdabot> Consider it noted.
04:13:55 <EvanR> question about free variables. is (\x -> y x) (\z -> y) = y (\z -> y), i.e. the final answer has two `y's and they are the same variable?
04:14:23 <lyxia> yes
04:14:32 <EvanR> ok so renaming would be wrong
04:14:45 <hjulle> Because both are free
04:15:08 <lyxia> renaming would have to rename y in the context as well
04:19:16 <xa0> :t (<*)
04:19:17 <lambdabot> Applicative f => f a -> f b -> f a
04:23:40 <makalu> stack builds binaries in a completely nonsense directory. "stack install" puts them in ~/.local/bin. Can I configure where stack copies the binaries?
04:26:29 <liste> makalu: --local-bin-path
04:27:08 <liste> more info: stack --help, Available options: section
04:27:32 <makalu> thank you
04:27:47 <hjulle> makalu: That sounds like a completely normal directory to put binaries.
04:29:09 <Xandaros> hjulle: It is... all my scripts are in there
04:29:12 <makalu> hjulle: I meant the .stack-work/dist/x86_64-linux/your-cabal-version-which-will-change/build/binary-name/binary-name
04:31:11 <hjulle> makalu: That (assuming the lack of ~/ was intentional) sounds like the lokal build for the sandbox of a specific project?
04:32:16 <liste> hjulle: that's stack's internal working directory, and it's inside the project directory
04:32:22 <makalu> yes, I wanted to get my binary out of there without having to know the exact path. "stack install --local-bin-path=/foo/bar" does what I need. Thanks liste :)
04:33:00 <hjulle> aha. nice
04:38:49 <saurabhnandan> EvanR, hey, the MyApp approach seems to be working. And while implementing a type for my own app, I seem to have understood monad transformers better. Apparently, It's not necessary to use all the monad-transformers given in the yesod examples. I tried "type NwApp = SqlPersistT IO" and stuff just worked. 
04:39:07 <saurabhnandan> EvanR, where SqlPersisT is a "ReaderT SqlBackend" internally
04:39:34 <saurabhnandan> EvanR: so, the runResourceT given in the yesod examples **seems** optional
04:41:15 <saurabhnandan> btw, is stack recommended over cabal?
04:41:33 <Kakadu> Folks, can I write combinators which preapply last element of tuple of size n to all another elements and get tuple of size n-1? With something like church numbering ? https://paste.in.ua/1526/?as=haskell#27
04:41:59 <Xandaros> saurabhnandan: Many people like stack. I'm personally quite happy with just cabal, so I'd say you'll have to decide for yourself
04:44:30 <saurabhnandan> Xandaros, I'm in the process of installing cabal on a new machine
04:44:51 <saurabhnandan> I cloned my repo and init-ed the sandbox and got a bunch of scary errors
04:45:14 <pavonia> Kakadu: What type would that function have?
04:45:42 <Kakadu> pavonia: Don't really know, very complex one.
04:45:44 <saurabhnandan> cabal: The following packages are likely to be broken by the reinstalls: // tf-random-0.5 // QuickCheck-2.7.6 // HTTP-4000.2.20
04:45:52 <Kakadu> with this hack types are always say nothing
04:46:12 <saurabhnandan> Xandaros, how is that possible on an absolutely clean machine, while installing in a cabal sandbox?
04:46:41 <dcoutts> saurabhnandan: if you just did a sandbox init, you can ignore those warnings
04:46:44 <pavonia> Kakadu: Not sure what you'Re trying to do, but if you want your function to be able to handle tuples of different lengths, you need a typeclass
04:47:02 <Xandaros> saurabhnandan: I've heard of that bug... never experienced it myself
04:47:03 <saurabhnandan> dcoutts, but how is that possible? where are those other packages coming from?
04:47:08 <dcoutts> saurabhnandan: it just means it's masking those packages from your global env
04:47:29 <dcoutts> saurabhnandan: those ones will not then be available inside the sanbox, but that's perfectly ok
04:47:31 <saurabhnandan> dcoutts, so, my global install is not going to get messed-up right?
04:47:37 <dcoutts> saurabhnandan: correct
04:47:38 <Kakadu> pavonia: But I can write uncurry for tuples of different lenghts, why I can't do this in that case?
04:47:41 <saurabhnandan> dcoutts, yes, that's cool
04:47:42 * hackagebot post-mess-age 0.2.1.0 - Send messages to a handle concurrently without getting them mixed.  https://hackage.haskell.org/package/post-mess-age-0.2.1.0 (DanielDiaz)
04:47:51 <Kakadu> pavonia: for example, type for uncurry_succ is
04:48:11 <Kakadu> :t (\ k f (x, y) -> k (f x) y )
04:48:12 <lambdabot> (r1 -> t1 -> r) -> (t -> r1) -> (t, t1) -> r
04:48:15 <EvanR> saurabhnandan: nice
04:48:25 <saurabhnandan> btw, is GHC faster on Ubuntu compared to OSX? Or is 7.8 faster than 7.10? I'm installing on an ubuntu PC after working for a few weeks on Mac OSX and Haskell seems to be flying here.
04:48:48 <pavonia> Kakadu: That only works for tuples of length 2
04:49:43 <saurabhnandan> so, one advantage of stack is that is has a bunch of binary packages? doesn't install everything from source?
04:50:33 <Kakadu> pavonia: No, see https://paste.in.ua/1526/?as=haskell#22
04:50:59 <Kakadu> I can apply uncurry_succ a few times  and get larger tupel
04:51:12 <bennofs> saurabhnandan: it caches packages that you've build once, assuming that the dependencies versions stay the same (for example, if you're sticking to a particular stackage release)
04:51:16 <Kakadu> I just don't understand method for generating these functions
04:51:21 <Kakadu> or writing
04:51:25 <Kakadu> maybe I just stupid
04:51:39 <bennofs> saurabhnandan: GHC 7.8 might be faster than GHC 7.10 in some cases
04:51:45 <pavonia> Kakadu: Yes, but you can'T have one generiv function, that works for arbitrarily nested tuples
04:52:06 <Kakadu> pavonia: yes, I understand
04:52:08 <pavonia> Kakadu: You defined different uncurryX functions there
04:52:46 <Kakadu> pavonia: I defined uncurry_succ which allows to declare required functions using obvious syntax
04:53:00 <Kakadu> I'm curious in which cases I can't declare uncurry_succ
04:53:22 <Kakadu> for example if I want to apply deepest element of tuple to all the others ... Is it possible?
04:54:13 <pavonia> It works whenever you know how deep your tuples are nested in advance, i.e. at compile time
04:54:20 <saurabhnandan> bennofs, is there  an easy to reach changelog between 7.8 and 7.10?
04:55:29 <Kakadu> pavonia: I can pass this 'number' and tuple as arguments to another function foo, and this foo will not depend on concrete tuple size
04:55:44 <Kakadu> i.e. there will not be explicit tuple size in the signature of foo
04:55:58 <Kakadu> It only will have very polymorphic type
04:56:25 <EvanR> if its totally polymorphic you cant do anything with it, since its not even necessarily a tuple
04:56:43 <pavonia> Kakadu: No, you can't the length is determined by the type, that's why you need to define all the different X functions
04:56:56 <Kakadu> Oh, man
04:56:59 <EvanR> however you can have ...
04:58:19 <pavonia> Kakadu: You should add type annotations to all top-level function to get a better feel for what that function really does
04:58:27 <EvanR> foo :: IsNestedTupleAndHasDesiredProperty t => t -> X
04:59:00 <EvanR> but it doesnt feel very good to use functions like this since its a kind of opaque name in the type
05:00:22 <EvanR> you can use a GADT to form a hetero list in a way that is nicer to deal with
05:00:56 <EvanR> then foo :: MyHList <your properties here> -> X
05:01:19 <Kakadu> With type annotations: https://paste.in.ua/1527/
05:01:54 <EvanR> simply having arbitrary nested tuples is usually not enough to do anything useful, you also want supporting operations available at each node
05:02:07 <EvanR> so GADTs
05:02:16 <EvanR> possible with rank2
05:02:20 <EvanR> possibly*
05:03:06 <Kakadu> EvanR: Yeah, but I don't want typeclass. I can write uncurry_succ in a way above but I can't write uncrurry_succ which preapplies deepest value to previous ones. Is it possible? If not, why
05:03:34 <EvanR> just now i was referring to gadts and possibly rank2 not typeclasses
05:04:16 <EvanR> you are trying to group a function at the end of the tuple with arguments before it?
05:04:23 <neutronest> Hot to convert IO[()] to IO () if I use a forM in Haskell ...
05:05:01 <pavonia> neutronest: use forM_ instead
05:05:17 <neutronest> OK, let me check the type signature ...
05:05:22 <bennofs> :t forM_
05:05:23 <lambdabot> (Monad m, Foldable t) => t a -> (a -> m b) -> m ()
05:06:26 <Kakadu> EvanR: I'm trying to write nicely application of (a -> b -> c -> d ) to (base->a, (base->b,(base->c,base))) and get d
05:06:57 <EvanR> so you have a -> b -> ... -> d, and (a,b,...) and you want d
05:07:10 <neutronest> OK I've got that. Thank you everyone :)
05:07:23 <Kakadu> EvanR: No, tuple is a little bit different: it is nested pairs
05:07:34 <Kakadu> (a,(b,(c,....)))
05:07:42 <EvanR> in the end you want d?
05:08:29 <Kakadu> Yeah, after application I want d. I mean that d is not int the 'end' of tuple
05:08:30 <_nate_> that's what she said
05:08:45 <EvanR> alright
05:10:55 <EvanR> try...   apply :: (a -> b) -> T a b d -> d
05:12:29 <Kakadu> what is T?
05:13:10 <EvanR> its a type which will be 1 or more arguments that eventually produces d
05:13:30 <EvanR> the base case is that there is 1 argument of type a and b=d
05:14:00 <EvanR> and there is a "next level" operation which prepends more arguments when b=another function
05:14:24 <EvanR> next level is the other constructor
05:14:32 <EvanR> so this is a GADT with two ctors
05:15:30 <EvanR> Base :: forall a b . a -> T a b b
05:16:12 <EvanR> Next :: forall a b d . a -> T a b d
05:16:13 <EvanR> hmm
05:16:25 <EvanR> probably not right, havent had breakfast yet
05:17:03 <EvanR> apply f (Base x) = f x
05:17:27 <EvanR> apply f (Next x xs) = apply (f x) xs
05:17:43 * hackagebot atndapi 0.1.1.0 - An interface of ATND API  https://hackage.haskell.org/package/atndapi-0.1.1.0 (ynishi)
05:17:44 <EvanR> so Next needs another argument, which i forgot. another T with the proper return type
05:18:25 <EvanR> Next :: forall a b c d . a -> T b c d -> T a b d
05:20:17 <EvanR> so in your example... you have (a -> b -> c -> d) and T a (b -> c -> d) d
05:20:29 <EvanR> probably a more compact way to write this
05:22:03 <EvanR> Next x (Next y (Next z (Base w)))
05:22:50 <xa0> is putStrLn platform agnostic or am is it no better than just using \n
05:23:53 <Kakadu> EvanR: There is some type error which I don't get how to fix easily. https://paste.in.ua/1528/#42
05:24:43 <EvanR> put a type sig on apply first
05:24:50 <EvanR> then see what the error is
05:25:16 <puregreen> xa0: \n is automatically converted to whatever newline is on the target platform
05:25:35 <xa0> oh fantastic
05:26:33 <EvanR> .oO( t0 is untouchable error ...)
05:27:22 <EvanR> Kakadu: im not sure your data declaration is right... data T :: * -> * -> * -> * where
05:27:23 <Kakadu> Oh, adding type helps
05:27:38 <EvanR> maybe it is
05:27:50 <EvanR> but those letters in the head are confusing
05:28:01 * Kakadu does stupid joke about existance type inference in Haskell :)
05:28:41 <EvanR> if this type were to be inferred i would eat my hat
05:29:37 <Kakadu> Oh, type annotation helps to compile 1st clause but second fails
05:31:19 <EvanR> message?
05:31:33 <Kakadu> https://paste.in.ua/1529/#37
05:33:03 <EvanR> probably cause my ass
05:34:18 <EvanR> so yeah theres a bug here in my idea, involving the type of the function and the exact arrangement of variables
05:34:25 <EvanR> thinking
05:35:38 <EvanR> Kakadu: try removing one of the parameters to T
05:36:36 <EvanR> hrm
05:40:56 <Kakadu> I think that is weird that type of Next 1 (Next 'c' (Next "." (Base 1.0))) is 
05:40:57 <Kakadu> Next 1 (Next 'c' (Next "." (Base 1.0))) :: Num a => T a Char d
05:43:43 <mniip> seems only rational
05:44:17 <EvanR> alright next try
05:45:54 <EvanR> Kakadu: http://lpaste.net/157428
05:47:30 <Kakadu> Some type error again :) https://paste.in.ua/1531/#61
05:47:31 <EvanR> now it should look ever weirder
05:47:46 <Kakadu> Well, I have weird task
05:47:59 <mettekou> Is there an idiomatic way to compose steps of a computational process (such as interpreting/compiling source code) with distinct monad transformer stacks other than just piling them on top of each other? Case in point: a parser which uses ParsecT, a type checker which uses TypeT (ExceptT with StateT), and so on.
05:48:17 <neutronest> well.. how to update.. on no, rebind some variable's value during the forM_ ..... I think it's a necessary feature .......
05:48:23 <EvanR> Kakadu: its not the same error, heh
05:48:47 <EvanR> "probably cause f applied to too many arguements" opposite message, though similarly irrelevant to the problem
05:49:09 <EvanR> the could not deduce types being equal is different
05:49:22 <saurabhnandan> hit by cabal hell pretty solidly. Trying stack. Although stack also crapped-out due to HsOpenSSL on MacOSX
05:50:03 <EvanR> Kakadu: well.. ill think about this later. is your actual question at the bottom?
05:50:10 <EvanR> remove the last element of a tuple?
05:50:32 <Kakadu> It is the most simplified version. 
05:50:51 <EvanR> in this experiment were trying to support a hetero list of arguments that you can apply
05:51:08 <EvanR> if you just want to have a hetero list that does nothing but you can drop the last element, thats easy
05:51:09 <Kakadu> More concretely I want to apply this value at the bottom to all values of mega-pair
05:51:55 <Kakadu> I probably can prepare detailed description a little bit alter
05:52:05 <EvanR> yeah im still not too clear on the goal
05:52:08 <Kakadu> need to have dinner, I need to have breakfast:)
05:52:15 <Kakadu> s/I/you/
05:55:15 <Xandaros> The wikipedia article on Hindley-Milner states that a (not quantified) type "a -> a" can be expressed in Haskell. What does that even mean, if a is not quantified?
05:55:48 <Xandaros> Correction, it says it can "practically occur", but cannot be expressed
05:55:56 <EvanR> heh...
05:56:24 <EvanR> when you get a type error and it says a0 and a1 cant unify, where foo :: a1 -> a1
05:56:31 <EvanR> these arent quantified
05:56:47 <hpc> scoped type variables?
05:56:51 <EvanR> maybe this counts as practically occurring
05:56:57 <mniip> those are exists-quantified, not forall-quantified
05:57:01 <mniip> ?
05:57:20 <EvanR> i dont see why you need exists, they are names for concrete types
05:57:37 <EvanR> which you may or may not know specifically yet but you should be the end of the checking
05:57:42 <EvanR> by*
05:57:45 <hpc> mniip: with nested definitions
05:57:51 <hpc> like, foo :: forall a. a -> ...
05:58:00 <hpc> where otherthing :: a -> a
05:58:20 <Xandaros> I don't really get it. In a type "a -> a", the two a's obviously need to be the same. But if they aren't quantified, they can't really be anything, can they?
05:58:23 <mniip> scoped tyvars?
05:58:32 <hpc> they're quantified, but further out
05:58:54 <hpc> they're free in otherthing's type signature
05:59:05 <Xandaros> Ah, I see. With ScopedTypeVariables, there is a difference between "a -> a" and "forall a. a -> a"
05:59:14 <EvanR> Xandaros: once you instantiate a in forall a . a -> a, you have x -> x
05:59:16 <Xandaros> At least if they are nested
05:59:39 <EvanR> x is some type to be determined
05:59:46 <Xandaros> EvanR: Yeah, they'd effectively be different
06:00:00 <Xandaros> s/effectively//
06:00:19 <EvanR> x = x
06:00:32 <Xandaros> Yes, but I mean x ‚â† a
06:00:57 <EvanR> a is bound there, its like you substituted and it got rid of the binder
06:00:59 <Xandaros> It may still be called a, but by quantifying it, it's bound
06:02:05 <Xandaros> Ugh, terminology. Anyway, at least with ScopedTypeVariables, I get it
06:03:28 <EvanR> any idea why this dont work http://lpaste.net/157429
06:03:30 <merijn> Xandaros: In haskell without extensions all free type variables are quantified with forall on the left-outermost scope, and as such the language doesn't bother making you write them down (in fact, there's no syntax for that in standard haskell)
06:04:28 <merijn> EvanR: Why the explicit foralls?
06:04:34 <EvanR> no reason
06:04:38 <Xandaros> merijn: Yeah, which is why something like ScopedTypeVariables needs to exist. Though, I suppose ExplicitForall solves that problem, as well?
06:05:24 <EvanR> http://lpaste.net/157429
06:05:31 <hpc> ScopedTypeVariables implies ExplicitForall
06:05:36 <merijn> Xandaros: ScopedTypeVariables solves a different problem, it solves the problem that in standard haskell type variables in let/where clauses are not lexically below the top level
06:05:56 <merijn> Xandaros: i.e. 'a' in the top level signature are unrelated to a's in where/let, which people find confusing
06:06:55 <Xandaros> hpc: Oh, ExplicitForall only allows you to use explicit forall, it doesn't require it, right? Got that mixed up...
06:07:23 <merijn> EvanR: You're second case of "apply" requires that 'b' is some function type
06:07:33 <merijn> EvanR: But there is no constraint/way to prove/infer that
06:08:13 <merijn> EvanR: Incidentally, doing what you want is fairly straightfoward using Type Families, and I have an example of that in my HList gist :)
06:08:16 <merijn> EvanR: https://gist.github.com/merijn/dc00bc7cebd6df012c5e
06:09:10 <merijn> EvanR: Your function requires that the arity of 'f' is known at compile time, but your types don't allow for GHC to infer that
06:09:38 <EvanR> ... i dont quite understand that. the arity is = 1 as always
06:10:09 <EvanR> i was trying to encode that "eventually the function produces a d" into the T type
06:10:32 <EvanR> the HList example looks a lot nicer though
06:10:33 <merijn> EvanR: No, the intent is that if you have a function of two arguments you get 1 Next and 1 Base, right?
06:10:42 <EvanR> yes
06:12:18 <merijn> EvanR: But how do you know the expected arities match with the runtime list values?
06:13:11 <EvanR> there has to be a Base at the end
06:13:32 <EvanR> with an argument for a->b that produces a b
06:13:52 <merijn> EvanR: What is there is no Base?
06:13:58 <merijn> s/is/if
06:14:14 <EvanR> well wouldnt that require an infinite type
06:14:23 <merijn> The problem is that 'b' is more restricted than it appears to be
06:14:31 <EvanR> the phantom parameters there are all linked together
06:14:47 <merijn> EvanR: In practice, yes, but how does GHC see whether that requires an infinite type?
06:15:01 <EvanR> i dont think ghc is using this reasoning to reject my program either
06:15:22 <EvanR> theres some sort of issue unifying the middle parameter in Next .... i get the feeling
06:15:34 <merijn> EvanR: Anyway
06:15:43 <EvanR> this would lead to an "it doesnt know the arity of your function" hand waving
06:15:48 <EvanR> but i dont quite get it
06:15:59 <merijn> I'd say that the explicit unrolling of the function type via type families is nicer to read anyhow
06:16:06 <EvanR> yes
06:26:31 <sachs4> hi, can anybody give me some feedback whetever the use of UndecidableInstances is safe in the following code?
06:26:58 <sachs4> http://lpaste.net/157431
06:27:05 <Xandaros> sachs4: Does it compile? Then it's safe :P
06:28:13 <sachs4> It compiles but i have only one test case, and i would like to know if this holds generally for every case
06:28:27 <hpc> sachs4: in a bit more detail, the danger of undecidable instances is that compilation can potentially not terminate
06:28:35 <hpc> sachs4: but all terminating compilations result in valid code
06:28:42 <hpc> er, valid programs
06:29:14 <hpc> sachs4: make a few more test cases and see!
06:31:28 <rydgel> Some people are saying that functors are containers. I think it's confusing. What can be the simplest example of a Functor where this analogy fails?
06:31:55 <hpc> probably (e ->)
06:32:07 <opqdonut> (e ->) is kinda like a map though :)
06:32:25 <hpc> imo you have to squint too hard to see that formulation
06:32:26 <opqdonut> IO might be a better example
06:32:34 <rydgel> I thought of Parser
06:32:42 <hpc> ooh, that's actually pretty good
06:32:43 <opqdonut> Parser is good too
06:32:55 <hpc> probably not the simplest, but it's very conceptually obvious
06:33:19 <hpc> you'd be hard-pressed to call it a box containing a value
06:33:57 <hpc> Cont maybe?
06:35:53 <EvanR> "functors are containers" isnt confusing as long as the only functor types involved are containers
06:36:01 <EvanR> but those are so simple its boring!
06:36:26 <EvanR> rydgel: another one is promises
06:36:38 <hpc> it breaks down as you learn more advanced type classes too
06:36:39 <EvanR> which arent containers unless its the movie primer
06:37:05 <hpc> EvanR: have you seen the tardis monad?
06:37:09 <EvanR> lol
06:37:15 <merijn> hpc: Is that reverse Cont?
06:37:16 <hpc> i shit you not, it exists
06:37:22 <hpc> there's State, right?
06:37:22 <merijn> I know there's a reverse State monad
06:37:30 <hpc> yeah, and reverse State
06:37:45 <merijn> Reverse state is confusing voodoo :p
06:37:48 <hpc> which is where you just get s and s' backwards in a few definitions
06:37:59 <hpc> reverse state is the "tying the knot" monad
06:38:05 <hpc> tardis is the combination of both
06:38:17 <hpc> one state value which can be sent forwards and backwards in time
06:38:24 <EvanR> tardis isnt even a joke
06:38:26 <hpc> it's very easy to loop
06:38:57 <Xandaros> rydgel: I think with a bit of imagination, you can see any functor as a container. For the parser, you can say that it 'contains' the parsed value
06:39:38 <rydgel> Xandaros: yeah, but newcomers always ask "how do I unbox the stuff in the box"
06:39:49 <EvanR> what is the value of this sort of language?
06:39:55 <EvanR> everything is a container
06:39:59 <Xandaros> Well, that's the thing... in general, the box is not 'openable'
06:40:45 <hpc> or at least, the box opens in a different way every time
06:40:47 <hpc> IO never opens
06:40:52 <Xandaros> Some containers can always be opened (including Parser), others sometimes (Maybe), other never (IO)
06:40:55 <hpc> opening the box is executing code
06:40:58 <EvanR> i think maybe its all coming from a confusion between actual container structures and the unrelated mechanism of using newtype wrappers
06:41:08 <EvanR> which are two different things
06:41:08 <hpc> which can't happen in-language
06:41:24 <hpc> parsers can't always be opened
06:41:27 <EvanR> by putting a wrapper on a function value, you dont suddenly turn the function into a container
06:41:40 <hpc> parsers are locked containers where the key is a stream of somethings
06:41:40 <rydgel> EvanR: yeah. And most of the time, in other languages, fmap exists but only usable on Arrays of similar structures
06:41:46 <EvanR> by renaming the ls command to box, its not a container
06:41:49 <Xandaros> hpc: Fair enough. The parse could fail. Identity is probably the best example for a box that can always be opened
06:42:10 <hpc> [] is an unknown number of boxes
06:42:26 <jophish> Worth mentioning the "no-box" container Const
06:42:44 <hpc> in any event, it's really easy to come up with these analogies
06:42:50 <hpc> but try going backwards to the data type
06:43:05 <hpc> what's the box that requires a list of functions to open?
06:43:14 <Xandaros> Yeah, that doesn't make much sense
06:43:22 <hpc> (answer: ContT [])
06:43:44 <hpc> @unmtl ContT []
06:43:45 <lambdabot> Plugin `unmtl' failed with: `ContT []' is not applied to enough arguments, giving `/\A B. (B -> A []) -> A []'
06:43:46 <mniip> no?
06:43:52 <hpc> @unmtl ContT [] r a
06:43:52 <lambdabot> (a -> r []) -> r []
06:43:53 <mniip> that's (a -> [r]) -> [r]
06:44:04 <hpc> erp, ListT Cont
06:44:12 <hpc> which... ListT isn't even the right one
06:44:13 <EvanR> i hate here this handheld calculator, by pressing the buttons i am opening the answer and letting it fly free onto the LCD display
06:44:17 <EvanR> have*
06:44:29 <hpc> oh, LogicT is what it was
06:44:39 <mniip> LogicT? :o
06:44:39 <hpc> the listlike transformer that doesn't have major commutative issues
06:44:51 <EvanR> by moving my mouse, it is opening delta xy values onto the computer...
06:44:58 <hpc> mniip: it's a whole thing
06:45:15 <EvanR> the mouse contains delta xy values
06:45:18 <EvanR> its a container
06:45:34 <EvanR> of course, you simply cant put the values back in
06:45:55 <EvanR> this rock is a container, it just doesnt have any container functionality
06:46:23 <Xandaros> EvanR: Sounds like Proxy
06:46:27 <hpc> heh, Const is the ultimate middle finger to the container analogy
06:46:40 <merijn> hpc: It's just a container of 0 elements
06:46:44 <Xandaros> What's Const?
06:46:44 <merijn> :D
06:46:44 <EvanR> lol
06:46:50 <EvanR> @src Const
06:46:50 <lambdabot> Source not found.
06:46:55 <hpc> everything's a container of zero elements if you give it a phantom type variable
06:47:06 <mniip> Const r a = Const r
06:47:07 <hpc> it breaks the analogy in the stupidest way
06:47:17 <Xandaros> ah
06:47:32 <hpc> and maybe it makes the learner think about what's actually going on?
06:47:34 <EvanR> a container that cant hold anything, i dont see this fixing the issue
06:47:35 <Xandaros> It's obviously a box with a phantom element in it
06:47:40 <hpc> it's pretty funny anyway
06:47:57 <mniip> Xandaros, we're talking about functoriality over a, not over r
06:48:11 <EvanR> doesnt plan9 actually think of their files and devices this way?
06:48:31 <EvanR> containers
06:48:33 <mniip> formally we are calling 'f' a container if 'f a' contains some 'a's in some way
06:48:45 <Xandaros> mniip: Yes.
06:48:57 <EvanR> and the way could be complete nonsense
06:49:10 <mniip> 'Const r' is a container
06:49:21 <mniip> can't say the same about 'Œõr. Const r a' because that's not even a type
06:50:37 <EvanR> except what if someone asks you to define contains values, and you accidentally say "well theres an operation where you can get the values, if any"
06:51:11 <EvanR> otherwise not sure how to axiomatize containment
06:52:23 <sqrt2> i want to read a configuration file at program startup, and from then on i'd like to treat configuration values as pure, as they will never change over the course of a program. is it good practice to just run my configuration parser with unsafePerformIO, or are there pitfalls?
06:52:42 <EvanR> read the configuration file at program startup, then pass it into your pure function
06:52:51 <EvanR> no pitfalls
06:53:06 <sqrt2> but then i need to pass configuration around as a parameter always
06:53:23 <EvanR> only to the things that use it
06:53:51 <sqrt2> and to the things that call the things that use it, etc.
06:53:53 <EvanR> and if you have other environmental stuff, you can put it in there to cut down on parameters, or use ReaderT
06:54:08 <EvanR> well yes, which is luckily toward the top of the program not every leaf
06:55:04 <sqrt2> i'm not sure what you mean. the pure functions tend to be the leaves of a program, so effectively i need to pass configuration everywhere, do i not?
06:55:26 <EvanR> probably not, and if you only have a few pure functions... whats the point?
06:55:41 <EvanR> you could re-read the config anywhere you like in IO
06:56:14 <EvanR> there are actual issues with attempting to use unsafePerformIO fo doing actual I/O
06:56:34 <sqrt2> i was hoping i could read the configuration only once and not duplicate code
06:56:49 <EvanR> thats exactly what you should do
06:57:04 <Shou> Anyone know if there's a "listToMaybe" with type :: [a] -> Maybe [a] rather than just taking head if it's non-empty?
06:57:50 <mniip> I think it's fairly safe to unsafePerformIO readIORef if you writeIORef at the start of the main?
06:57:56 <EvanR> -> Maybe (a,[a]) would be an interesting type, since you have done a check to guarantee its non-empty
06:58:00 <sqrt2> but then i'm actually stuck with passing configuration along every path of the program tree that needs it
06:58:03 <mniip> and provided no other modifications to the IORef are made
06:58:39 <EvanR> sqrt2: which is actually really good for making sure your code works, but also theres the Reader monad if you like monads
06:59:12 <sqrt2> EvanR: in my case that would mean stacking a ReaderT on top of an ExceptT
06:59:40 <EvanR> so youre already doing monads
06:59:43 <sqrt2> yes
06:59:48 <EvanR> might as well use them 
06:59:49 <ertes> sqrt2: i just joined, but from the context so far i infer that you have a long-running program that needs to be reconfigured at run-time‚Ä¶  if that's the case, i would most likely do it with FRP
06:59:59 <mniip> no
07:00:13 <sqrt2> ertes: it's the opposite, i'd like to read configuration once and then treat it as pure
07:00:24 <mniip> the configuration is claimed to be so static that its reading can be unsafePerformIO'd and considered to be pre
07:00:24 <EvanR> what you mean to say is, you want a global variable
07:00:33 <ertes> sqrt2: in that case i usually just pass it everywhere by explicit argument
07:00:44 <sqrt2> EvanR: a global constant, more like
07:00:46 <ertes> it's usually not that bad
07:00:51 <EvanR> except its not constant
07:00:58 <mniip> yes it is?
07:01:00 <sqrt2> ertes: i was just wondering if that can be avoided
07:01:22 <sqrt2> EvanR: it is after i've read configuration
07:01:32 <EvanR> assuming you successfully read the configuration
07:01:41 <ertes> sqrt2: sure, ReaderT was suggested to you, but note that you get to do other things explicitly if you do that, most notably liftIO
07:02:24 <sqrt2> EvanR: that's the kind of pitfall i thinking about. i'd like to evaluate the entire configuration before i continue with the actual program
07:02:30 <ertes> personally in most cases i find it easier to just pass the configuration around‚Ä¶  many functions don't need it anyway, and in many cases you can use quite a large scope for the variable, so you don't have to pass it around too much
07:02:47 * hackagebot operational-alacarte 0.2 - A version of Operational suitable for extensible EDSLs  https://hackage.haskell.org/package/operational-alacarte-0.2 (EmilAxelsson)
07:03:12 <EvanR> sqrt2: well, you can use a template haskell hack to create a global IORef then write the successful value to the ref during startup, its just not very haskelly
07:04:09 <sqrt2> ok, i'll look into that and see how much uglier ReaderT or additional parameters make my code
07:04:13 <sqrt2> thanks for the suggestions
07:04:23 <ertes> sqrt2: really, try the explicit way‚Ä¶  it sounds a lot worse than it is, and it gives you very simple types and engineering, probably even simpler than a global variable in certain respects
07:05:16 <ertes> ReaderT is mostly useful when developing an *abstraction* that requires global context, but for *applications* that require it, explicit arguments work surprisingly well
07:05:21 <EvanR> https://wiki.haskell.org/Global_variables
07:06:54 <EvanR> that page reminds me, there exists an extension called implicit parameters
07:07:17 <EvanR> try that if you like adventure
07:07:55 <ertes> if you're going the implicit route, i would go with reflection‚Ä¶  that's the other common way i do it, because it beautifully cooperates with most base type classes
07:08:09 <ertes> (implicit parameters do not)
07:08:48 <ertes> but again: mostly useful for abstractions, not that useful for application code
07:09:15 <merijn> I'm just finishing up some ugly ImplicitParams hack to build trees of threads :p
07:09:43 <merijn> It's actually surprisingly neat
07:13:25 <sqrt2> implicitparameters looks interesting, and it looks like reflection has a nice paper
07:13:37 <sqrt2> i'll definitely look into that. thanks, ertes
07:19:21 <ertes> sqrt2: if you can make sense of the module documentation <https://hackage.haskell.org/package/reflection-2.1.2/docs/Data-Reflection.html>, i would skip the paper =)
07:20:37 <vektorweg1> wasn't there an extension to use a constructor in a polymorph type like a type?
07:20:53 <ertes> not that it's bad, but it doesn't quite reflect the state of the art as implemented in the library‚Ä¶  also it takes quite a detour to explain how it works, so you'll find it interesting, if you're interested in fundamentals, not so much if you need to Get Stuff Done (TM)
07:21:01 <ertes> vektorweg1: you mean DataKinds?
07:22:31 <vektorweg1> thank you. i'll check it.
07:32:24 <infinity0_> anyone use leksah? i'm getting "packageInfo not found" for all my packages :(
07:35:06 <hamishmack> infinity0_: Was leksah built using the same version of GHC that is in your PATH?
07:36:14 <average> https://storify.com/realtalktech/taking-down-haskell
07:36:22 <average> so... because I've read through this..
07:36:29 <average> why is Haskell getting so much hate these days ?
07:36:52 <average> I am reading a lot of blog posts with a negative vibe about Haskell
07:37:50 <marcx> last time i saw someone hate on haskell was because she didn't like how (-1) works. it was a deal breaker. *shrug*
07:38:43 <Sornaensis> I've never met anyone who hated haskell who could actually use it to some degree
07:38:53 <hpc> that's pretty much it
07:39:13 <hpc> hating haskell is a trend that comes and goes as someone fails to understand something and publicly rails on it
07:39:27 <Sornaensis> mostly I see complaints that it takes a lot of theoretical knowledge to start writing things that are considered 'trivial' in other languages, like writing a tic tac toe game
07:39:37 <Sornaensis> just mutating things
07:39:43 * Sornaensis shrug
07:40:07 <hpc> there's probably some legitimate criticisms of haskell out there, but i would wager they all come down to "have you tried idris/agda/coq?"
07:40:11 <EvanR> which is sort of funny because i demonstrated an almost trivial conway life which used a mutable vector and gloss
07:40:13 <infinity0_> hamishmack: yes i only have one copy of ghc
07:40:28 <hpc> EvanR: ooh, paste?
07:40:29 <infinity0_> unless cabal installed its own copy... which i can't see in .cabal/bin so i guess not
07:40:30 <average> Sornaensis: actually.. have you skimmed through the link I just mentioned ?
07:40:40 <Sornaensis> nah I didn't
07:40:40 <EvanR> and i got flak for it not being haskelly because of the mutable vector
07:40:51 * Sornaensis skim
07:40:52 <average> Sornaensis: don't you think you should.. so we can be on the same page ?
07:41:00 <hpc> i love mutation in haskell
07:41:01 <average> thanks for taking some time to skim through it tho
07:41:02 <hpc> it's so explicit
07:41:07 <infinity0_> it seems that leksah can't detect source code for debian system haskell packages though, i can't control-click on Data.Monoid, but i can cotrol-click on Control.Monad.Trans.Error
07:41:12 <EvanR> parental advisory
07:41:32 <hpc> hehe
07:42:50 <merijn> hpc: tbh, there's legitimate criticism of haskell when it comes to (soft) real-time, parallel scalability, and difficulty of finding space leaks/tracing. But those are 1) not applicable to the vast majority of programmers or 2) not unsolvable
07:43:08 <hpc> EvanR: but seriously, having some reference graphical code that actually works would be wonderful
07:43:34 <hpc> merijn: also haskell is ridiculously parallel scalable
07:43:39 <merijn> hpc: Not really
07:43:46 <hpc> no?
07:43:50 <merijn> hpc: Runtime breaks down at about 12-16 cores, depending on workload
07:43:54 <EvanR> hpc: its not really curated for public consumption but heres the relevant bits http://lpaste.net/157432
07:44:04 <merijn> At that point global GC stop kills you dead
07:44:11 <hamishmack> infinity0_: Are you using version 0.15.2.0 of Leksah?
07:44:13 <hpc> oh ouch
07:44:26 <merijn> hpc: But that's not unsolvable, just engineering
07:44:39 <hpc> is there anything coming up in ghc to alleviate that?
07:44:45 <average> merijn: surely Docker can fix that !
07:44:46 <merijn> hpc: When the next leap is made, ala the new IO manager, everything will automatically become faster
07:44:48 <hamishmack> infinity0_: If you launch it with leksah --verbosity=DEBUG
07:44:56 <average> it has fixed everything from broken windows, to cars and airplanes
07:45:02 <average> and worn out shoes
07:45:03 <hamishmack> infinity0_: It might have some clues
07:45:08 <merijn> hpc: Not particularly, because if you care about throughput rather than latency, it's not such a big issue
07:45:23 <average> jk
07:45:26 <merijn> average: I would say that you see more haskell hate because haskell is getting more popular
07:45:27 <hpc> merijn: makes sense
07:45:44 <EvanR> hpc: the executeTransition is the magic, the lambda passed to the simulateIO is swapping two IOVectors to use as src/dest
07:45:49 <EvanR> each step
07:46:14 <EvanR> pay no attention to the fact that each cell is a float 
07:46:15 <merijn> average: People who have invested into existing ecosystems or somehow made their programming language a matter of identity will aggressively reject anything better as worse, due to cognitive dissonance
07:46:38 <merijn> average: And lots of people seem to have axes to grind with functional programming in general
07:47:04 <Rotaerk> it's "impractical"
07:47:11 <hpc> merijn: i read "axes" as "axes of a graph" first there
07:47:32 <EvanR> haha
07:47:51 * quchen_ thinks multiparadigm is impractical. But regardless, "functional programming" has come a long way: nobody fears lambdas anymore, for example. Many libs inspired by FP are hip, many mainstream even.
07:48:18 <average> mind you, I am constantly coming in this channel, drawing attention at such blog posts that rail against Haskell
07:48:23 <average> but.. I do it for a noble cause
07:48:36 <average> which is.. to get a second opinion on said blog posts
07:48:38 <ertes> average: my take: anything that starts to become popular will receive hate, mostly by advocates of the status quo
07:48:44 <EvanR> from what ive been told by outsiders there is a stereotypical haskell user somewhere who is hyperintelligent, elitist, derogatory, and right about everything
07:48:47 <average> from people who have hands-on experience with Haskell in real-world situations
07:48:52 <EvanR> which people hate, and then hate the language
07:48:56 <quchen_> There are many terrible, terrible monad tutorials with Javascript as the language of choice, but if it makes people fear monads less - and if only because they get used to the name - that's probably a win
07:48:59 <ertes> unlike most new languages, haskell is not "a new C++" or "a new python"
07:49:22 <hpc> ertes: unlike most new languages, haskell is not new ;)
07:49:27 <EvanR> oh and that person thinks there is only 1 way to do something
07:49:33 <Sornaensis> EvanR: I've heard that before
07:49:36 <ertes> hpc: and i didn't imply that =)
07:49:36 <mauke> ... ok, that's not me
07:49:38 <average> to me, the biggest lie of them all is a Perl book called "Higher Order Perl"
07:49:41 <Sornaensis> "My problem with haskell is the typical haskell user"
07:49:44 <hpc> ertes: yeah, i just couldn't resist the joke
07:50:12 <average> the book describes some awesome things, but instead of going over them without any programming at all, which is .. what I would actually like
07:50:15 <hpc> average: that book is pretty deficient in functional programming stuff, but is a good book for "oh, you can actually do real programming in perl"
07:50:20 <hpc> it's much like SICP
07:50:23 <average> the book uses Perl.. which is probably the worst language to do FP in..
07:50:29 <hpc> oh boy
07:50:29 <ertes> i've seen this a lot with technology that i would consider modern by my standards‚Ä¶  mostly haskell and nix though
07:50:34 <hpc> so i say this probably way too often
07:50:34 <mauke> perl is far from the worst language for FP
07:50:36 <EvanR> Sornaensis: we have complained about OOP from time to time in this channel, momentarily... but i still havent seen this haskell user
07:50:39 <hpc> perl is my favorite functional programming language
07:50:47 <average> let me just state that again: Perl is the *worst* language to do any FP in
07:50:49 <hpc> even more than haskell, which is my favorite imperative language
07:50:58 <quchen_> ‚Ä¶ that quote ‡≤†_‡≤† 
07:51:03 <mauke> average: you're wrong
07:51:14 <average> mauke: dude..
07:51:20 <average> let's not go there ok ?
07:51:27 <average> I like mjd and what he wants to describe
07:51:34 <marcx> is it even worse than python?
07:51:35 <rom1504> hpc: and c is your favorite for logic programming ?
07:51:37 <average> but Perl.. really.. let's not go there
07:51:45 <mauke> also, are you seriously complaining that a book called "higher order perl" uses perl examples?
07:51:50 <hpc> rom1504: c is my favorite assembly language
07:52:01 <hpc> agda is my favorite logic language
07:52:05 <Zemyla> Okay, question. If I'm doing a loop in the IO monad, is it better to have the loop variable be a parameter (go i = dostuff i >> go (i + 1)) or a mutable variable (go = read loopIndex >>= (\i -> doStuff i >> write loopIndex (i + 1) >> go))?
07:52:07 <EvanR> i prefer the illogic paradigm
07:52:15 <average> mauke: is that your conclusion from what I've said ?
07:52:20 <mauke> yes
07:52:21 <average> mauke: because it's not what I said at all
07:52:36 <mauke> that's the only criticism you offered
07:52:42 <EvanR> Zemyla: i would think it would be a parameter or recursive parameter
07:52:44 <srhb> Zemyla: If you don't _need_ an IORef, I certainly wouldn't use one.
07:52:54 <hpc> average: take it from someone who has written lots of functional perl that you are wrong
07:52:55 <EvanR> IORefs require special treatment by the GC
07:52:58 <average> mauke: man.. did you look how hard mjd is trying to do FP in that book ?
07:52:59 <srhb> Zemyla: I never think "oh, this is IO anyway, might as well cram some more in there" :-)
07:53:03 <mauke> average: no
07:53:14 <average> mauke: he's like trying to lift some 400kg of weight or something
07:53:16 <srhb> (... I totally do, but not in this case.)
07:53:30 <EvanR> Zemyla: IORefs have at least an extra write barrier so the gc can collect stuff without the aid of immutability
07:53:49 <hpc> perl's anonymous subs and treatment of lists combine to make an extremely flexible programming style
07:53:54 <Zemyla> The advantage I was thinking with the latter is that go only needs to be evaluated once, and thereafter it's just called.
07:54:00 <ertes> i believe the main problem is that people generally don't associate haskell programmers with pragmatism
07:54:21 <average> mauke: I like mjd's blog better than that book
07:54:22 <hpc> i am confident saying perl's a better functional language than any lisp
07:54:33 <EvanR> Zemyla: when you increment a loop variable, youre not only allocating a new value but also writing to a thing managed in a special region of memory
07:54:34 <mauke> hpc: even scheme?
07:54:43 <EvanR> so just dont do that and pass it on
07:54:47 <merijn> Is there a nicer way to do a single mfix binding than introducing a "rec" just for that?
07:55:07 <hpc> scheme's actually not half bad
07:55:10 <marcx> clojure > scheme
07:55:17 <hpc> but i like perl's unique features over scheme's
07:55:18 <ertes> and to be honest, we do tend to get carried away =)
07:55:32 <EvanR> if only clojure wasn't equal to java
07:55:43 <marcx> java is great
07:56:01 <merijn> How do I stop it marching right like this: http://lpaste.net/157433
07:56:02 * EvanR drops an IDE on marcx 
07:56:03 <hpc> java is my favorite ide
07:56:41 <merijn> mfix feels awkward, but rec nesting looks bad too for single entries
07:57:10 <average> another little something I dislike in HoP is how people say "reading that book has made me a better programmer"
07:57:11 <hpc> merijn: get comfortable with mfix, imo
07:57:12 <ertes> merijn: i'd use mfix
07:57:15 <hpc> functions > syntax
07:57:16 <average> or "FP has made me a better programmer"
07:57:34 <average> that is on a level of bs that's just off the charts
07:57:41 <ertes> merijn: unless you need the tid further down in the action
07:57:45 <merijn> ertes: I do
07:57:47 <EvanR> merijn: theres also mdo
07:57:55 <srhb> merijn: Or mdo!
07:57:55 <hpc> average: what makes a programmer better then, if not learning things?
07:57:58 <srhb> Meh
07:58:01 <merijn> EvanR: rec is the replacement of mdo, I thought?
07:58:10 <Sornaensis> I learn everything a priori
07:58:12 <hpc> learning php made me a better programmer
07:58:23 <Sornaensis> I just sit in a room and derive the entire universe
07:58:24 <average> hpc: well.. here's the thing. "learning things" is a good hideout, it's very general
07:58:29 <hpc> not /that/ much better, but i know more things about how a set of semantics can go wrong
07:58:39 <ertes> merijn: to my eyes your code doesn't look that bad‚Ä¶  you could improve it slightly by writing forkFinally infix
07:58:39 <EvanR> merijn: now that you mention it, like rec more
07:58:40 <average> let's talk about "FP making someone a better programmer because they learned FP"
07:58:42 <hpc> learning haskell made me a much better programmer
07:58:45 <average> not about "learning things"
07:59:09 <average> I can learn to tie my shoestrings faster.. that's "learning things" too
07:59:12 <ertes> merijn: action1 `forkFinally` {- line feed and align with action1 -} action2
07:59:15 <EvanR> average you seem to be greatly affected by this supposed anti-haskell movement
07:59:21 <nitrix> average: Who are you quoting there?
07:59:28 <average> nitrix: the shoestring ?
07:59:34 <nitrix> It seems like that's a deformation of words.
07:59:37 <average> EvanR: no..
07:59:45 <EvanR> haskell user affected
07:59:51 <average> nitrix: not sure what you mean
08:00:09 <merijn> Ok, this conversation has a terrible signal-to-noise ratio
08:00:13 <nitrix> average: A quote has to be be quoted exactly.
08:00:37 <EvanR> this is like a bizzaro reading rainbow about higher order perl
08:00:48 <ertes> merijn: alternatively you could eliminate the necessity of the tid in 'handler' and work by resources rather than threads ‚Äì that's what i would do
08:00:50 <nitrix> You have two variants of the same quote and it's troubling me. What is the original statement and what is your claim? Can you distinguish both?
08:00:54 <merijn> In fact, that's a charitable interpretation of something that I would more often interpret as trolling
08:01:17 <merijn> ertes: I need the tid in the handler because it's unregistering the thread as being alive
08:01:33 <merijn> ertes: i.e. I'm building task/supervisor trees and track which threads are still alive
08:01:49 <ertes> ah, i see
08:01:49 <merijn> ertes: Oh, actually I guess I can just use "myThreadId"
08:01:59 <ertes> yeah, that gets rid of the tid
08:02:05 <average> the only good thing I'd like to learn from Haskell is this:
08:02:48 <average> How to efficiently and completely convince people that using a programming language is going to solve everything faster, better, cheaper and safer.
08:03:03 <EvanR> sales is that way
08:03:06 <average> somehow Haskell does great in the marketing department
08:03:07 <hpc> lol
08:03:08 <average> yeah
08:03:21 <average> you have the best possible marketing and sales people ever
08:03:33 <EvanR> thanks
08:03:40 <merijn> hmm
08:03:47 <merijn> I still end up with a potential race condition
08:03:59 <merijn> But I think I'm just going to risk it and assume that never happens :p
08:04:10 <ertes> average: really?  compared to python haskell's marketing performs terribly‚Ä¶  and python can be summarised as HashMap String Dynamic
08:04:46 <average> ertes: Haskell sold 'Monads' ...
08:04:55 <merijn> To whom?
08:04:58 <ertes> average: monads sold monads
08:05:01 <average> to pretty much .. a lot of people
08:05:03 <average> including Facebook !
08:05:08 <ertes> monads sold monads to us haskellers =)
08:05:14 <EvanR> HashMap String Dynamic is a unifying force, there is utmost beauty and simplicity inspired by purity of form
08:05:14 <average> there's a lady @Facebook in Sydney Australia who works for Facebook
08:05:26 <merijn> Anyway
08:05:35 <merijn> This entire conversation is just looking to pick a fight
08:05:35 <average> and she's made this presentation where she says "Haskell is so awesome, I'm not gonna cover monads in this presentation but.. they're cool [..]"
08:05:44 <average> merijn: I am really not picking a fight
08:05:47 <Ferdirand>  < ertes> [...]  python can be summarised as HashMap String Dynamic <- that quote should be preserved for posterity
08:05:50 <Xandaros> We really need a more friendly term for monads. They are one of the simplest things ever, but that name seems to imply that it's something ridiculously difficult
08:05:54 <EvanR> im planning on not mentioning monads once in my presentation next week
08:06:04 <EvanR> i think it will confuse the audience
08:06:05 <merijn> Xandaros: We really don't
08:06:23 <Xandaros> @quote ertes python can be summarised as HashMap String Dynamic
08:06:23 <lambdabot> No quotes for this person.
08:06:29 <Xandaros> hmm
08:06:33 <average> merijn: you should take into account that I am reading quite a few blog posts about Haskell and watching presentations about it
08:06:37 <ertes> Ferdirand: i believe lambdabot has a quote system‚Ä¶  feel free to regard everything i say as CC-BY-licensed =)
08:06:41 <average> so I would not call myself a troll 
08:06:52 <quchen_> Xandaros: @remember
08:06:56 <Xandaros> @remember ertes python can be summarised as HashMap String Dynamic
08:06:56 <lambdabot> It is stored.
08:06:58 <Xandaros> Yeah
08:07:11 <marcx> python is even worse than C++
08:07:16 <maerwald> EvanR: what presentation
08:07:19 <EvanR> are monads really the simplest thing ever... the categorical version
08:07:26 <average> oh yeah
08:07:32 <average> Haskell was able to sell 'Category Theory' too
08:07:36 <ertes> anyway, i have a feeling that this discussion is pretty pointless
08:07:42 <maerwald> maybe they are technically simple, but not simple to understand properly
08:07:51 <ertes> maybe we need #language-flamewars for these things =)
08:07:51 <average> people suddenly now think that category theory and algebra is cool
08:07:52 <EvanR> maerwald: "not your dad's enterprise integration pattern"
08:07:54 <merijn> Xandaros: See this: http://www.stephendiehl.com/posts/abstraction.html
08:08:04 <average> because Haskell sold it to them
08:08:04 <merijn> average: Because people are easily distracted
08:08:13 <average> merijn: yes but that is very powerful
08:08:21 <merijn> average: People some how associate Haskell with Category Theory, which is stupid
08:08:23 <marcx> python community has a genuine hate for functional programming
08:08:36 <merijn> Because the design of haskell has basically zero links to CT
08:08:40 <average> the power to just sell anything. like those guys could sell my beaten up dirty couch for $10,000
08:08:45 <average> i bet they could
08:08:51 <average> they're really f good
08:08:55 <merijn> In fact, as someone who loves haskell and loves learning CT I would say that CT is the least useful thing to study to learn haskell
08:08:55 <Xandaros> average: Just for the record . I consider myself a pretty decent Haskell developer and I don't know any Category Theory
08:08:59 <EvanR> maerwald: perhaps ironically it will prominently feature monoidal categories
08:09:08 <ertes> average: we haskellers are very reluctant to adopt new technology‚Ä¶  so when we adopt stuff, it's usually an easy sell to others
08:09:21 <ertes> be it something algebraic like category theory or even something very practical like STM
08:09:38 <ertes> (or lightweight threads to begin with)
08:10:44 <maerwald> EvanR: I think the best way is really Monoid -> Functor -> Applicative Functor -> Monad
08:11:04 <maerwald> for practical stuff, not CT
08:11:04 * Xandaros agrees with maerwald
08:11:11 <EvanR> im not actually using any typeclasses at all
08:12:04 <ertes> and i'm very glad that we have algebra‚Ä¶  i see the damage caused by the misbelief that OOP design patterns can scale infinitely almost every day
08:12:07 <maerwald> applicative functor is actually easier to understand than Monad imo... and when you are exposed to the limitations of applicative you also get the idea of the Monad
08:12:35 <average> man, ertes is selling haaaard
08:12:41 <average> he's selling that algebra
08:12:57 <average> I wish I did a presentation and sold some permutation groups to people
08:12:57 <EvanR> im so annoyed with the monad situation i pretend it doesnt exist when explaining haskell
08:13:01 <Xandaros> I think applicative easily follows from functor (two-argument functions). And if you then look at the types of fmap and (<*>), you will soon see what is missing - (>>=)
08:13:13 <maerwald> yeah
08:13:25 <maerwald> the jump from functor to monad is way bigger
08:13:46 <EvanR> yes you see join missing!
08:13:52 <maerwald> exactly
08:14:03 <EvanR> ... just kidding
08:14:14 <EvanR> functor and applicative are all you need
08:14:26 <maerwald> errr
08:14:39 <Xandaros> Often... not always
08:15:02 <Xandaros> I suppose with ApplicativeDo, applicatives will be easier to use, too
08:15:17 <Xandaros> Maybe Monads will be pushed into the background a slight bit
08:15:20 <ertes> average: i realise that i might sound like that, but really i'm simply a software engineer; i don't even have any degrees‚Ä¶  i use what works, and haskell works =)
08:16:00 <ertes> (not that i'm not enthusiastic about it)
08:16:10 <maerwald> EvanR: how do you parse "4 78 19 3 44 3 1 7 5 2 3 2" where the first number tells you the length of the group to parse and the result ought to be: parseFile :: Parser [[Int]]
08:16:21 <average> ertes: how does haskell work for you ?
08:16:26 <maerwald> that's where the Applicative interface is too static in the effect flow
08:16:28 <nitrix> Does functor have a `join` operation?
08:16:43 <Xandaros> nitrix: Nope, you need a monad for that
08:16:44 <average> ertes: have you sold things inside your company so far ? or are you liking haskell as a hobby ?
08:17:06 <EvanR> maerwald: meh, let the library figure that out
08:17:15 <maerwald> EvanR: no, it's not possible.
08:17:29 <average> ertes: also.. in your company, are you in a position to decide whether a project is written in Haskell or not ?
08:17:31 <EvanR> that is how list is encoded with Binary
08:17:34 <ertes> average: as self-employed software engineer, and as a hobby, too
08:17:45 <danilo2> Hello guys! I've got such a typeclass `class Append (a :: [*]) (b :: [*]) where append :: RTuple a -> RTuple b -> RTuple (a <> b)` (the `<>` is a type level list append). This class has instances for all possible cases (whether `a` or `b` are empty or any lists) but we need the vars in the head to choose right instances. 
08:17:56 <average> ertes: were you able to push Haskell anywhere in production code ?
08:18:16 <maerwald> you also can't write a sensible ifM with applicative
08:18:21 <danilo2> I woyld love to write a wrapper around the function to be able to use it without the need to write everywhere the constraint, because it is always met, no mather what data we provide, so iti s (form the user-point-of-view) not necessary there. Is there a ay in haskell to do it or maybe there will be somem echanism in the future allowing osmething like that?
08:18:26 <Xandaros> average: What are you trying to do here, anyway? Convince us that Haskell is bad?
08:18:32 <EvanR> average: i actually did once, that program is still running and is the only program in the entire system that didnt regularly barf
08:18:41 <EvanR> (after i fixed the memory usage issues)
08:19:01 <ertes> average: my haskell+nix solutions are currently powering three data centers‚Ä¶  and i'm working on generalising my backup solution to a point that i can release it as open source
08:19:13 <average> amazing..
08:19:23 <average> i'm blown away every time I hear these stories ertes 
08:19:32 <sm> ertes: ooh.. anything like tarsnap ?
08:20:30 <ertes> average: that sounds misleading‚Ä¶  they are rather small data centers and i have a bunch of solutions for synchronisation and backups as well as a number of bots
08:20:58 <ertes> sm: i've never used tarsnap, so i can't tell
08:21:18 <EvanR> danilo2: hmm http://lpaste.net/157436
08:22:02 <average> Xandaros: you need to understand my point of view. here, I'll go over it again
08:22:14 <Xandaros> I'm good.
08:22:16 <EvanR> lol
08:22:55 <danilo2> EvanR: hmm, no the problem is somewhere else. Oh, I've got a meeting. I\ll write back after it, I'm sorry!
08:23:19 <average> Xandaros: I am not really convinced haskell is any better than perl for example, yes I know.. it has so many goodies and safety checks and etc
08:23:27 <average> what amazes me the most, is how it's being sold
08:23:36 <Xandaros> average: I can tell from your messages that I won't be able to convince you otherwise, so I don't really care
08:23:37 <average> and why people buy into it
08:23:44 <ertes> sm: it's basically a "start and forget" type of thing:  in one case it even learns the best backup period by linear regression
08:23:45 <StoneToad> the single best thing vs perl, is that haskell is compiled
08:23:57 <Sornaensis> lol you cannot even compare perl and haskell what
08:24:02 <Xandaros> average: Have some valid perl: dgherhkfhbkjfhdvjhbkhbhjbhg,h
08:24:03 <Sornaensis> they are in different domains
08:24:06 <ertes> sm: and it's currently heavily btrfs-centric, so it's really a very specialised solution
08:24:13 <sm> ertes: cool
08:24:15 <Xandaros> Damn, didn't want to hit the comma... oh well
08:24:22 <average> Xandaros: I could easily find some equally confusing Haskell code
08:24:22 <EvanR> the only language bashing allowed in here is haskell!
08:24:26 <StoneToad> lol Xandaros 
08:24:31 <StoneToad> not enough symbol chars
08:25:17 <StoneToad> hmm when I say compiled, what I'm really gripping about it how much overhead perl5 function calls have
08:26:55 <ertes> sm: my old backup script <http://hub.darcs.net/esz/btrfs-backup> was the inspiration for it‚Ä¶  it's basically that, but as a daemon with little configuration overhead and multiple hosts
08:27:28 <Rotaerk> EvanR, haskell sucks and is impractical!
08:27:28 <ertes> i like "fire and forget" solutions‚Ä¶  stuff i don't need to maintain, unless it fails for a good reason
08:27:29 <Rotaerk> or something
08:28:42 <puregreen> average: Haskell isn't the best language for every person and every task, but it seems to me that when somebody *does* like Haskell, ne likes Haskell a lot ‚Äì i.e. it's more ‚Äúlove it or hate it‚Äù than with many other languages
08:29:01 <thoughtpolice> ertes: Sounds neat (I used to work in the area, so I too like fire and forget tools). Right now I'm using a combination of my own btrfs scripts + tarsnap. I estimate the amount of one-off 'btrfs backup scripts' is approximately 1-to-1 with the number of btrfs users at this rate. :)
08:29:04 <puregreen> which is why you might see people promoting Haskell so eagerly (it truly seems the best thing since sliced bread for them)
08:29:23 <ertes> thoughtpolice: absolutely =)
08:29:26 <Rotaerk> is "ne" a typo, or a gender-neutral pronoun substitute?
08:29:49 <puregreen> gender-neutral pronoun substitute
08:30:00 <ertes> thoughtpolice: although there is this snapper tool that seems somewhat popular, but i've never used it myself, because i was afraid it would lead to the "doesn't *quite* do what i need" hell
08:31:00 <thoughtpolice> Yeah, mine was something like "Just take diffs and scp them elsewhere, and if anything fails message my phone" I think. I should check on that server... :)
08:31:06 <marcx> lol, "ne"? that is a new one
08:31:33 <puregreen> let's discuss gender-neutral pronouns in haskell-blah, if anywhere
08:31:44 <average> is there a reason people would like "fire-and-forget-tools" ?
08:31:59 <average> afaik .. usually.. if something is use, it does enter the maintenance phase
08:32:03 <marcx> haskell-blah redirects to nossl.. whatever
08:32:06 <average> *used
08:32:07 <EvanR> lol
08:32:11 <ertes> average: unnecessary maintenance costs money that nobody is going to pay
08:32:14 <Kakadu> EvanR: I kind of found more detailed description of what I'm doing... https://gist.github.com/Kakadu/c6243d6e5bf5f228080b
08:32:30 <average> ertes: that's true
08:32:34 <EvanR> marcx: i see you have discovered the secret, the experiment must be terminated
08:32:45 <sm> ertes: I'm very much the same, fire and forget please!
08:32:50 <ertes> average: and in many cases it makes you work on weekends, which SUCKS
08:32:52 <ertes> =)
08:33:13 <average> ertes: so what is the solution ?
08:33:14 <Rotaerk> it's because haskell-blah is for discussing top-secret things
08:33:20 <average> how can we avoid doing maintenance ?
08:33:33 <ertes> average: tools that Just Work
08:33:41 <hpc> i like wordpress for no-maintenance software
08:34:14 <EvanR> Kakadu: so... there might be a way to do this nicely without needing any fancy extensions. but i dont really know whats going on. also for the earlier task, if relevant, merijn has a paste which has a better "apply function to hetero-list of args"
08:34:15 <sm> we currently use tarsnap and attic for backups, plus a "idiot-proof" double-clickable bash script that makes local backups on anybody's machine
08:34:39 <ertes> average: nowdays i don't offer local installations anymore‚Ä¶  i offer containers/VMs, because then i don't have to care about the target system's distro/configuration
08:35:01 <ertes> and containers work almost everywhere these days (linux assumed)
08:35:10 <sm> but back on topic.. self-configuring and just works is a good thing, we should have more of it haskell land
08:35:11 <silver> @botsnack
08:35:11 <lambdabot> :)
08:36:00 <rydgel> sm: stack is a huge improvement in this direction
08:36:26 <ertes> sm: for applications or for development itself?
08:37:42 <sm> rydgel: agreed!
08:37:51 <sm> ertes: both, all
08:38:18 <ertes> sm: i'm actually pretty happy with what we have today
08:38:36 <sm> non-leaky abstractions are something we understand the value of, after all
08:38:37 <rydgel> ertes: doesn't mean we can't do better
08:38:51 <MarcelineVQ> there's propeller too to be aware about, http://hackage.haskell.org/package/propellor though I've not used it myself
08:39:06 <ertes> rydgel: agreed =)
08:43:10 <ertes> sm: i have an idea for a few months now that i'd like to experiment with‚Ä¶  rather than writing another centralised backup solution, make it a P2P solution instead‚Ä¶  members of the network just say which resources they would like to backup and the level of redundancy, and the network does the rest‚Ä¶  what do you think?
08:43:34 <ertes> drawback: it's a lot of work, and little code in that direction is readily available
08:43:44 <rydgel> you can even use bittorent protocol for that
08:43:49 <ertes> (haskell code that is)
08:44:02 <ertes> rydgel: yeah, something along those lines, but it's a lot of work regardless
08:44:18 <rydgel> Wasn't Twitter deploying like that long ago
08:44:20 <sm> ertes: a commercial service, or.. ?
08:44:35 <average> 18:42 ( ertes) sm: i have an idea for a few months now that i'd like to experiment with‚Ä¶  rather than writing another centralised backup solution, make it a P2P solution instead‚Ä¶  members of the network just say which resources they  would like to backup and the level of redundancy, and the network does the rest‚Ä¶  what do you think?
08:44:38 <average> ertes: already exists
08:44:45 <ertes> sm: no, a free solution you can install and operate privately
08:44:55 <average> ertes: https://storj.io/
08:46:25 <ertes> average: that's not quite what i had in mind‚Ä¶  i mean something completely disconnected with no fancy features other than backups
08:46:30 <ertes> basically syncthing, but for backups
08:47:03 <ertes> sm: (free as in beer and speech)
08:47:22 <average> ertes: also exists for real storage spaces(attics typically but also garages etc)  http://www.spaceflex.dk/
08:48:03 <sm> what's a nice more compact way to write http://lpaste.net/157058 ?
08:48:09 <ertes> average: is that available in english or german?
08:48:41 <ertes> sm: bind monadically
08:48:45 <average> ertes: probably not (not sure why)
08:48:57 <sm> I tried for a while but failed
08:49:25 <average> but yeah, in essence, it's an online marketplace(with a real physical component) with providers and customers
08:49:32 <ertes> sm: getArg args (argument "STRIDE") >>= (readMay >=> ...)
08:49:35 <average> providers provider storage space to be rented out
08:49:38 <ertes> something like that?  didn't test
08:49:40 <average> customers rent out the space
08:50:15 <ertes> average: i see‚Ä¶  that's way beyond what i want‚Ä¶  ideally no data ever leaves the private network, not even encrypted data
08:50:42 <ertes> and ideally no communication or even CPU time is needed unless an actual backup action is running
08:51:47 <Xandaros> ertes: But, the cloud!
08:51:54 <ertes> =)
08:52:09 <ertes> there is no cloud‚Ä¶  there is only other people's computers =)
08:55:33 <sm> ertes: thanks. I'm new to >=> .. how would you describe it in english (eg compared to >>=) ?
08:55:57 <hpc> (>=>) is (.) to (>>=)'s ($)
08:55:59 <ertes> sm: monadic composition:  f >=> g = \x -> f x >>= g
08:56:15 <hpc> or rather, to (=<<)'s
08:56:23 <hpc> (and (<=<))
08:56:31 <sm> oh, interesting, thanks
08:56:58 <ertes> sm: the technical term is kleisli composition
08:57:07 <sm> yes I saw that in hoogle
08:57:10 <ertes> because it's (.) for 'Kleisli m'
08:57:20 <sm> and admired it
08:58:27 <hpc> sm: it's much more clear if you look at (<=<) and (=<<)
08:59:08 <ertes> or just look at the definition and think of it as a convenience function to avoid a few lambdas =)
08:59:17 <Xandaros> I've actually only used (>=>) once. I should probably try and get an intuition for it, so I recognize when I should use it more often
08:59:36 <hpc> i understand it intuitively and i have never used it
08:59:40 <hpc> so you're already up on me ;)
09:00:07 <ertes> Xandaros: whenever you use the pattern "\x -> f x >>= ...", you can probably apply (>=>) instead: "f >=> ..."
09:00:23 <ertes> drawback: requires Control.Monad even in 2016
09:00:36 <Xandaros> Control.Monad is a standard import for me :P
09:01:17 <ertes> mine is Data.Monoid‚Ä¶  out of my head i can't come up with a single module of mine that doesn't use it =)
09:01:54 <ertes> (`mappend` isAwkward)
09:02:03 <Xandaros> Definitely. It is beyond me why (<>) is not in the actually typeclass
09:02:20 <hpc> Xandaros: because (<>) = getLine
09:02:28 <Zhell> Hi I am trying to solve Towers of Hanoi
09:02:32 <Xandaros> hpc: wat?
09:02:33 <hpc> http://hackage.haskell.org/package/acme-php-0.0.3/docs/src/Prelude-PHP.html#%3C%3E
09:02:42 <Xandaros> Oh, yes. Of course
09:02:48 <Zhell> I find it really difficult to think functionally
09:03:10 <Xandaros> Zhell: It's odd at first. You'll get used to it pretty quickly, don't worry :)
09:03:24 <Zhell> Xandaros, http://sprunge.us/diFf
09:03:32 <ertes> and by pretty quickly we mean: a few weeks should suffice =)
09:03:46 <Zhell> Xandaros, this won't compile, because it is wrong :/
09:04:17 <Zhell> sorry
09:04:18 <Zhell> http://sprunge.us/eTYL
09:04:31 <Zhell> do you understand my logics ? Am I on the right track here?
09:04:58 <sm> a few weeks, ha
09:05:12 <sm> that is not entirely honest
09:06:35 <Xandaros> Zhell: Well, don't know the problem, so I don't know if the logic is correct. I can, however, tell you that it won't compile because when you recursively call it, it expects (Peg, Peg, Peg), but you only give it (Peg, Peg)
09:06:53 <Xandaros> Zhell: (from, tmp), for example, is not a valid 'Pegs'
09:06:54 <Zhell> first complexity is: Complexity(1) = (From_Peg_one, To_Peg_Two), and then Complexity(2) = Complexity(2-1), Complexity(1), Complexity(2-1); this can be summarized as Complexity(n) = Complexity(n-1),Complexity(1), Complexity(n-1)
09:07:44 <Zhell> Xandaros, that is true
09:08:06 <Zhell> the problem is here that, I need to merge Linked Lists I guess (?)
09:08:28 <Zhell> what will happen here is that: 3:2:[]:3:1:[] . which is invalid.
09:08:51 <Xandaros> Ah, yes. Instead of (:), which prepends an element, you can use (++), which concatenates two lists
09:09:16 <Zhell> Xandaros, The thing is, that I am not allowed to use it
09:09:42 <mniip> foldr (:)
09:09:50 <Xandaros> lol... that works
09:09:51 <Zhell> only what's included in this chapter: http://www.seas.upenn.edu/~cis194/spring13/lectures/01-intro.html
09:10:25 <Zhell> which are too basic constructs (I guess)
09:10:49 <Xandaros> Well, you can define your own (++), can't you?
09:10:58 <Zhell> Xandaros, I don't know how
09:11:53 <Xandaros> Zhell: Start with writing down the type and go from there. I'm sure you'll get there :)
09:11:58 <Xandaros> If you get stuck, ask here
09:12:35 <Zhell> ahh
09:12:39 <Zhell> perhaps I do know
09:18:53 <Zhell> Xandaros, concatLists :: [a] -> [a] -> [a]
09:18:53 <Zhell> concatLists [] ys = ys
09:18:56 <Zhell> ops
09:18:57 <Zhell> sorry
09:19:03 <Zhell> http://sprunge.us/OYNS
09:19:12 <Zhell> would that be a good way to do it?
09:19:31 <Xandaros> Zhell: Perfect :)
09:19:40 <Zhell> thanks!
09:35:45 <Zhell> do you think I did a good job on this exercise? http://sprunge.us/KRbj
09:35:50 <Zhell> http://www.seas.upenn.edu/~cis194/spring13/hw/01-intro.pdf
09:35:52 <Zhell> exercise 5
09:35:56 <Zhell> The Towers of Hanoi
09:36:37 <Rotaerk> heh, someone linked me this:  https://storify.com/realtalktech/taking-down-haskell
09:38:24 <geekosaur> is that the first or the second phase of accepting disruptive tech? >.>
09:38:24 <Xandaros> Zhell: Looks good! Btw, instead of (from, to):[], you can also write [(from, to)]
09:39:15 <Zhell> Xandaros, thanks!
09:42:59 <Xandaros> Rotaerk: I have trouble determining if that guy is serious or attempting satire...
09:43:01 <DubbleSnup> What is this channel about?
09:43:14 <Rotaerk> Xandaros, lol
09:43:20 <Rotaerk> DubbleSnup, the Haskell programming language
09:43:27 <DubbleSnup> Oh okay.
09:43:31 <Xandaros> :D
09:49:22 <zachk> whats dubblesnup
09:49:29 <zachk> is it like blub? 
09:53:11 <aeyalcinoglu> hello, i have a question: at this code answ n = map (*n) primes  	where primes = filterPrime [2..]    		where filterPrime (p:xs) =           		p : filterPrime [x | x <- xs, x `mod` p /= 0] , ghci says f :: Integral b => b -> [b], why b, not a?
09:53:51 <Xandaros> aeyalcinoglu: Please use a pastebin-like service, so we can actually read the code...
09:55:31 <MarcelineVQ> it doesn't matter what letter it is as long as it's consistent,  f :: Integral b => b -> [b] is the same as  f :: Integral a => a -> [a] or  f :: Integral h => h -> [h]
10:01:34 <aeyalcinoglu> http://lpaste.net/157543 why here, ghci says f :: Integral b => b -> [b] with b, not a?
10:08:28 --- topic: 'http://www.haskell.org/ | https://wiki.haskell.org/IRC_channel | Paste code/errors: http://lpaste.net/new/haskell | Logs: http://tunes.org/~nef/logs/haskell/?C=M;O=D http://ircbrowse.net/day/haskell/today?mode=recent | http://reddit.com/r/haskell | Administrative issues: #haskell-ops | Hackage status? http://status.haskell.org | http://downloads.haskell.org'
10:08:28 --- topic: set by quicksilver on [Wed Oct 07 07:39:51 2015]
10:13:03 * hackagebot imperative-edsl 0.5 - Deep embedding of imperative programs with code generation  https://hackage.haskell.org/package/imperative-edsl-0.5 (EmilAxelsson)
10:27:45 <posco> I'm trying to get profiling working in stack
10:28:07 <posco> I did this: http://stackoverflow.com/questions/32123475/profiling-builds-with-stack and I can see the timing from my code
10:28:20 <posco> but no libraries show up
10:31:26 <posco> it is frustrating because I have some parsec code, which I believe is not backtracking, that is taking 7! seconds to parser a few bytes
10:31:47 <posco> (well 1600 bytes)
10:32:02 <bitemyapp> posco: post the Parsec code please?
10:33:02 <posco> https://www.irccloud.com/pastebin/YDeTpahK/
10:33:10 <posco> not too pretty...
10:33:44 <osa1> um why there isn't a version of http://hackage.haskell.org/package/wl-pprint-1.2/docs/Text-PrettyPrint-Leijen.html#v:fill for filling with arbitrary characters?
10:34:53 <posco> https://www.irccloud.com/pastebin/eYXqoh2p/
10:35:16 <posco> that's the profiling info.
10:35:32 <bitemyapp> posco: automatic cost centers I take it?
10:35:41 <posco> yes
10:35:50 <bitemyapp> posco: what's the .basic?
10:36:02 <posco> stack build --executable-profiling --library-profiling --profile --ghc-options="-fprof-auto -rtsopts -O -auto-all"
10:36:03 <bitemyapp> if you split that function apart you'd get better automatic cost centers.
10:36:06 <posco> that is how I built
10:36:22 <bitemyapp> those where clauses can be functions.
10:36:25 <posco> .basic I guess is the basic up there
10:36:30 <bitemyapp> I see.
10:36:35 <bitemyapp> well I'm not surprised that is eating time
10:36:54 <posco> but 7 seconds!
10:36:58 <posco> for 1600 bytes
10:37:08 <bitemyapp> I mean
10:37:12 <greymalkin> So, I have a conundrum.  I have been a linux user for 20 years, an android developer for 5, and I love NixOS except for one thing: I need to get some work done.
10:37:17 <bitemyapp> I can do silly IO in a loop in Scala and get worse than 7 seconds
10:37:42 <bitemyapp> I am trying to figure out what might be eating you alive that isn't the char pos update.
10:38:33 <posco> by the way, that was `oneOf "..."` followed by Map.lookup, but I changed to that, and it made no diff
10:38:38 <bitemyapp> posco: where are the bytes you're parsing coming from?
10:38:42 <greymalkin> Is there a tutorial on a quick and dirty way to set up a nix-shell FHS with a unionfs joined to somewhere in my home directory so that I can allow the android packages to do their updates so that I can get some work done while I hack on the android sdk methods used in Sander's blog (or others)?
10:38:43 <Rotaerk> why does haskell.org still recommend haskell platform, and not stack?
10:39:09 <bitemyapp> Rotaerk: too much respect for official-ness, not enough for working software.
10:39:17 <Rotaerk> heh
10:39:17 <greymalkin> Translation: I will continue to try to do android development the Nix way, but need to complete a contract by the end of the week.
10:39:27 <bitemyapp> posco: I'd really rather a complete picture of what you're doing.
10:39:28 <Rotaerk> btw, I forget, what was the name of that book you're working on, bitemyapp ?
10:39:35 <hpc> bitemyapp: alternatively, because stack isn't yet official?
10:40:00 <bitemyapp> Rotaerk: http://haskellbook.com - Haskell Programming from first principles
10:40:04 <hpc> maybe they'll evaluate it for replacing the platform at some point
10:40:04 <Rotaerk> ah right, thanks
10:40:19 <bitemyapp> posco: where's the data coming from? IO or a static value?
10:40:47 <bitemyapp> posco: example input would go a long way as it'd help me see if an edge case is getting tickled.
10:40:52 <posco> bitemyapp: I read a file with Text.IO.readFile
10:40:59 <bitemyapp> posco: dump the file please?
10:41:18 <posco> https://www.irccloud.com/pastebin/GNvQvXRx/
10:41:53 <posco> (this is a randomly generated input, yes it is json, yes I know about aeson, but reasons....)
10:42:01 <bitemyapp> posco: and those reasons are?
10:42:21 <posco> 1) this is a language that is a superset of json
10:42:37 <bitemyapp> wait so you really need a fast parser then?
10:42:50 <posco> 2) we need to parse many json values in a row.
10:42:56 <bitemyapp> Don't use parsec if perf matters.
10:43:06 <bitemyapp> still going to dig into this, but yeah
10:43:15 <bitemyapp> I usually use parsers and then flip between trifecta/attoparsec.
10:43:19 <posco> I have heard that, but I can't use it at all if 7 seconds for 1600 bytes is normal
10:43:24 <posco> I will be parsing many files
10:43:30 <bitemyapp> trifecta for debug/analysis/initial writing, then attoparsec for prod.
10:43:33 <greymalkin> Nevermind... I'm in the wrong channel, sorry!
10:43:40 <average> https://www.youtube.com/watch?v=mlTO510zO78
10:43:40 <bitemyapp> I'll flip back to trifecta if something fails so I get a nice error message.
10:43:46 <average> ^^ here is the lady that uses Haskell @Facebook
10:43:46 <bitemyapp> but I'm not paying the price for every single parse that way.
10:43:50 <average> she thinks Haskell is awesome and amazing
10:44:11 <average> remember that earlier blog post that said "Haskell sucks, OCaml rox, FP is awesome" ?
10:44:12 <Rotaerk> hmm if performance is a problem with parsec, does it have anything to offer over the other options to compensate?
10:44:12 <average> well..
10:44:20 <Rotaerk> or is it simply inferior to the other options
10:44:32 <bitemyapp> Rotaerk: nicer errors and some other things, but trifecta is better at being the slow-but-nice parser.
10:44:38 <average> what can one even conclude for all this confusing mix of opinions..
10:44:41 <hpc> parsec was also first
10:44:41 <bitemyapp> and I find trifecta and attoparsec are both a bit more predictable.
10:44:43 <average> s/for/from/
10:44:48 <Rotaerk> k
10:44:57 <posco> when you say "slow" I just have a hard time wrapping my head around this
10:45:05 <bitemyapp> we have a chapter on using trifecta and attoparsec in the book, incidentally.
10:45:24 <average> bitemyapp: I've read from your blog recently IIRC
10:45:29 <bitemyapp> posco: what are your GHC options?
10:45:31 <posco> do you know how I can get parsec call sites to appear in the profiling?
10:45:58 <posco> stack build --executable-profiling --library-profiling --profile --ghc-options="-fprof-auto -rtsopts -O -auto-all"
10:46:18 <posco> those are the only options I think I am passing
10:48:34 <blogle> I am on Windows and installed ghc through stack, but seem to be missing header files like Rts.h is there a way to grab all the headers without rebuilding ghc?
10:48:40 <EvanR> i need to try out megaparsec
10:52:08 <average> EvanR: going back to that blog post I read earlier today
10:52:27 <average> EvanR: do you ever feel like you're playing the "spot the abandonware" game when you're trying out these parsing libraries ?
10:52:31 <average> like megaparsec
10:52:50 <EvanR> are you a bot?
10:53:04 <nkaretnikov> slightly off-topic: i'm learning cryptol, anyone familiar with it?  let's chat on #cryptol
10:53:10 <average> wow, why do people pick on me ? I was just refering to a blog post written by someone else..
10:53:13 <MarcelineVQ> average: typically they have github links so it's fairly straightforward to see how active their dev is
10:53:40 <MarcelineVQ> packages in general I‚Äã mean, I'm not sure about the parsing ones specifically
10:54:16 <EvanR> im weird in that i dont think all software should be constant hammered on inceasantly. when its done its done
10:54:38 <EvanR> unfortunately ghc tends to pull the rug out from time to time on you, or your dependencies
10:54:59 <posco> bitemyapp: should one expect library cost centers to show up in profile output?
10:55:52 <EvanR> case in point the time library in haskell is fine, why should anyone continually update it? is it useless after being "abandoned" for so long? no
10:56:00 <bennofs> posco: if the library does not explictly set cost centres, then no
10:56:48 <posco> bennofs: so, automatic ones can't be placed?
10:57:04 <bennofs> posco: well, only if the library itself is compiled with -fprof-auto
10:57:20 <posco> but isn't stack compiling the library?
10:57:32 <posco> stack build --executable-profiling --library-profiling --profile --ghc-options="-fprof-auto -rtsopts -O -auto-all" 
10:57:50 <posco> isn't --library-profiling doing that?
10:57:51 <bennofs> posco: the library is compiled, but only once. The ghc options  only apply to your current project (afaik. not a stack user myself)
10:58:06 <posco> I see.
11:04:06 <posco> bitemyapp: would you expect trifecta to parse 1000 bytes in seconds of milliseconds or microseconds in a similar case?
11:04:50 <posco> I don't care if this is "fast", but to to me that means it can be 10-100 times slower than optimal
11:04:53 <osa1> does anyone know a printer library that allows me to say "right align this text and fill the gap with this character to fill N characters in total" }
11:05:10 <bitemyapp> posco: there's a fair bit wrong with the code, I'm throwing out suggestions as I get a bench set up.
11:05:22 <posco> but my guess it that this is more like 10-100k times slower than it should be
11:05:32 <posco> bitemyapp: thanks
11:09:37 <bitemyapp> posco: getting ambiguous types.
11:09:48 <bitemyapp> posco: now, I can pin these down myself
11:10:23 <bitemyapp> posco: but I'd ask that you try to smooth the way better next time someone goes to help you out with your code and post a complete working example
11:10:27 <posco> we are using Data.Map.Strict, but other that that, should be normal Parsec code
11:10:33 <bitemyapp> posco: preferably a repo that can get checked out and then 'Make'd
11:10:43 <bitemyapp>     No instance for (Stream s0 m0 Char) arising from a use of ‚Äòchar‚Äô
11:10:56 <bitemyapp> http://lpaste.net/934325978686029824
11:11:01 <bitemyapp> did this without overloaded strings as well.
11:11:24 <bitemyapp> now it's probably because I'm not applying it to input, but I'm still annoyed. Strongly recommend assigning top-level type signatures.
11:12:30 <bitemyapp> especially with something like Parsec where things are overloaded
11:13:18 <bitemyapp> yep, that was it.
11:13:29 <bitemyapp> running it concretized the types and eliminated the ambiguity.
11:13:35 <posco> Parsec T.Text () String
11:13:39 <posco> I think is the type
11:13:49 <sachs4> Does anybody know code where the ST monad is being used?
11:14:03 <bitemyapp> posco: not if you're running it in IO, but I can fix it.
11:14:27 <posco> we are not (running it in IO)
11:14:38 <bitemyapp> my benchmark has it: justStringP :: ParsecT T.Text () IO String
11:14:44 <bitemyapp> just because I am lazy and don't want to fold the identity.
11:15:01 <posco> ok
11:15:17 <bitemyapp> posco: well
11:15:21 <bitemyapp> posco: I just tried it in GHCi
11:15:29 <bitemyapp> posco: it ran nearly instantaneously.
11:15:47 <bitemyapp> but I'm going to setup the bench harness to see if I can quantify "instantaneously" for you.
11:16:17 <posco> you are passing it something that won't parse maybe?
11:16:26 <posco> the whole json blob?
11:16:39 <bitemyapp> I'm reading the file you gave me
11:16:43 <bitemyapp> and passing it to the parser
11:16:46 <posco> taking all the strings in that file and concatenating it
11:16:57 <bitemyapp> all the strings in what file?
11:17:03 <bitemyapp> you gave me an example input to try
11:17:08 <bitemyapp> I put that in a file named input.txt and parsed it
11:17:28 <bitemyapp> it does have an error, yes.
11:17:41 <bitemyapp> unexpected "#"
11:17:45 <bitemyapp> expecting "\""
11:17:49 <posco> I was not clear enough: that file, when passed to a much larger program and profiled gives this function as the major cost
11:18:01 <posco> that file has many string literals inside
11:18:05 * hackagebot react-flux 1.0.6 - A binding to React based on the Flux application architecture for GHCJS  https://hackage.haskell.org/package/react-flux-1.0.6 (JohnLenz)
11:18:09 <bitemyapp> okay
11:18:29 <bitemyapp> I realize it's hard when you're heads down on something to step back and take a breather
11:19:05 <bitemyapp> but you need to post a working repro of the perf problem you have if you want to get maximally useful help.
11:19:17 <posco> you mentioned there are many things wrong with the code, can you share those?
11:19:21 <bitemyapp> There is not one weird trick required to fix your parser as far as I can see, it's just sorta weird.
11:19:42 <bitemyapp> I'd rather not send you on a wild goose-chase. I wanted to analyze it for myself so I could be sure where the 80% was.
11:19:51 <bitemyapp> however, I'll give you a couple
11:19:56 <bitemyapp> str <- many ((noneOf "\\\"") <|> escaped)
11:19:59 <bitemyapp> that's hella suspect
11:20:05 <posco> why?
11:20:20 <saurabhnandan> hey, has anyone managed to install haskell-mode (emacs/spacemacs) with Stack?
11:21:06 <bitemyapp> posco: also, try comparing it with attoparsec since you're perf sensitive.
11:21:28 <posco> I may have to, but that is a non-trivial rewrite
11:21:30 <bitemyapp> posco: I don't think parsec's a good idea if you care how it'll behave. It's not as simple as a constant factor slower, Parsec has more perf death traps.
11:21:36 <posco> the semantics are a bit different
11:21:43 <bitemyapp> posco: that's why I usually use the parsers library and stick to trifecta/attoparsec.
11:21:51 <bitemyapp> posco: trifecta and attoparsec more or less match each other.
11:21:56 <posco> ok.
11:21:58 <bitemyapp> posco: I can flip between them.
11:22:15 <posco> ok. thanks for the suggestions
11:22:28 <bitemyapp> posco: I know others will disagree, but parsec is a newbie trap, IMO.
11:22:30 <posco> it sounds like one should basically never use parsec
11:22:40 <bitemyapp> posco: not unless you know it really well and hate switching.
11:22:43 <johnw> one advantage to parsec at least is that you can control backtracking
11:22:49 <bitemyapp> that much is true.
11:23:03 <johnw> https://www.quora.com/Haskell-programming-language-What-makes-Attoparsec-more-than-an-order-of-magnitude-faster-than-Parsec-3
11:23:14 <posco> yeah, so we have almost no backtracking
11:23:16 <bitemyapp> however the reasons people _have_ for wanting to control backtracking are covered other ways in trifecta (error provenance) and attoparsec (speed)
11:23:30 <posco> which I thought would help avoid the perf issues
11:23:45 <bitemyapp> there are worse/bigger perf traps in Parsec than backtracking, although 'try' will definitely cost you.
11:24:07 <bitemyapp> posco: are you sure the noneOf or'd with escaped in the many has the semantics you want?
11:24:20 <bitemyapp> not trying to second guess, just checking.
11:24:37 <bitemyapp> because parsec doesn't backtrack by default, I usually find <|> in parsec surprises people.
11:24:54 <mike993> :q
11:24:56 <bitemyapp> posco: it's a relatively minor perf note, but I'd replace that Map with a function.
11:25:23 <posco> yes, this passes a ton of tests
11:25:27 <bitemyapp> cool
11:25:52 <posco> basically, string content should either not be \ or " of it must be escaped
11:26:08 <posco> those are single char, so you don't need to backtrack
11:26:11 <posco> <|> works
11:34:30 <obadz> is there some guarantee when I print from two different threads that the characters aren't interleaved somehow?
11:35:03 <monochrom> no, I think this is not guaranteed
11:35:11 <obadz> but seems to happen a lot
11:35:44 <monochrom> there is probably enough buffering that interleaving is less often
11:35:44 <rydgel> obadz: There will be interleaved, without proper management
11:35:51 <obadz> ok thx
11:35:54 <rydgel> they*
11:36:15 <Zemyla> obadz: Have a single thread that does the printing.
11:36:28 <Zemyla> And have the other threads send messages to it.
11:41:09 <obadz> somehow messaging the results back to the main threads seem to make my race condition go away
11:41:09 <hamid> Do expressions gets valuated inside the threads or before entering it? maybe something like this: forkIO (print $ map (+ 1) [1..10]) 
11:41:51 <hamid> > forkIO (print $ map (+ 1) [1..10])
11:41:52 <obadz> hamid: compiler might turn map (+ 1) [1..10] into a constant no?
11:41:52 <lambdabot>  Not in scope: ‚ÄòforkIO‚Äô
11:42:08 <hamid> obadz, it might... it might memoize it too
11:42:18 <EvanR> hamid: generally the whole thing is evaluated in the other things
11:42:20 <EvanR> other thread
11:42:57 <EvanR> and if you put something in an MVar that isn't evaluated, it can be evaluated by whatever thread takes it and uses it
11:43:17 <monochrom> hamid: that's an ill-defined question, you have to refine it too: "assume the expressions involved are invisible from other threads". then the expressions are evaluated in the forked thread.
11:43:21 <obadz> hamid: don't know how it could memoize given that you haven't assigned it to a symbol
11:43:34 <monochrom> s/too/tp
11:43:40 <EvanR> lazy evaluation isnt memoization
11:44:21 <hamid> i assumed "referential transparency" can memoize things... replace the expression with a value
11:44:41 <hamid> Am I wrong?
11:44:43 <EvanR> ghc doesnt make anything memoize automatically
11:44:51 <EvanR> you have to do it yourself
11:45:03 <EvanR> youre thinking of lazy evaluation
11:45:23 <hjulle> The only thing that is automatically memoized is single bound values.
11:45:23 <hpc> you're confusing it with compile-time evaluation or commonsubexpression elimination
11:45:27 <rydgel> GHC can inline stuff at compile time
11:45:45 <EvanR> none of that is memoizing
11:45:54 <rydgel> exactly
11:47:19 <Cale> hamid: It's valid to memoise functions from the point of view of the semantics, but it's rarely a good idea. If all functions were automatically memoised, the garbage collector would never be able to collect anything.
11:47:59 <Cale> (pretty much)
11:48:04 <hamid> Oh Now I'm convinced :)
11:48:06 * hackagebot prometheus 0.3.0 - Prometheus Haskell Client  https://hackage.haskell.org/package/prometheus-0.3.0 (LukeHoersten)
11:48:11 <hamid> thank you
11:48:33 <EvanR> it can evaluate stuff at compile time too, early. but does it even do that? not sure
11:48:41 <Cale> So it's best to save that kind of thing for manual application. There's a nice library called data-memocombinators which gives you handy pure functions that memoise.
11:48:42 <EvanR> that could blow up in your face
11:48:58 <Cale> http://hackage.haskell.org/package/data-memocombinators-0.5.1/docs/Data-MemoCombinators.html
11:49:09 * hamid opens the link
11:49:44 <Cale> This takes advantage of the fact that any given bound variable will be evaluated at most once, in order to build memo tables for functions. It's a very clever and careful use of lazy evaluation.
11:49:45 <EvanR> compileTimeNumber = 44 `div` complexExpressionWhichEvaluatesToZero
11:50:20 <EvanR> does this crash the compiler... or right when your program boots up or...
11:50:32 <Cale> If you want to start understanding how it works, click the source link for 'bool', which memoises a function on booleans
11:50:38 <hamid> monochrom, im still struggling with this "assume the expressions involved are invisible from other threads"... can you give me 2 examples which one is and other is not?
11:51:21 <dolio> EvanR: It should never crash the compiler.
11:51:34 <monochrom> if you say "forkIO (print [1..10])" the [1..10] is visible to the forked thread only. the forked thread is the only one that will ever evaluate it
11:52:03 <EvanR> i guess laziness saves us again, it will throw an exception if its ever used, when its used. now im wondering what happens in C
11:52:21 <monochrom> but if for example you define x=[1..10] elsehwere and you say "forkIO (print x)" and then "forkIO (print x)" again, now you have two threads that are interested in evaluating x
11:52:32 <dolio> EvanR: In C the compiler might get to do whatever it wants.
11:53:06 * hackagebot react-flux 1.0.7 - A binding to React based on the Flux application architecture for GHCJS  https://hackage.haskell.org/package/react-flux-1.0.7 (JohnLenz)
11:53:08 <hamid> monochrom, so the "x" gets evaluated before entering any one those two threads?
11:53:14 <Cale> bool h = cond (h True) (h False) where { cond t f True = t; cond t f False = f }
11:53:22 <hamid> s/one/of*
11:53:26 <monochrom> no. define time is not evaluate time
11:53:48 <monochrom> whichever thread that needs x will happen to evaluate it
11:54:16 <dolio> EvanR: Probably still not crash, though. Just generate whatever code it wants.
11:54:20 <hamid> monochrom, so what if both threads needs x at the same time? does it get evaluated twice?
11:54:39 <EvanR> dolio: spooky
11:54:41 <monochrom> I don't know
11:54:47 <Cale> hamid: It depends on exactly what "the same time" means. There's a one-clock-cycle window where both threads may evaluate x
11:55:06 <Cale> (this turns out to be more expensive to eliminate in general than it costs to leave in)
11:55:20 <hamid> Oh smart!
11:55:34 <Cale> Apart from the time wasted, it's okay if both threads evaluate x because they must obtain the same result.
11:55:39 <EvanR> really? there will be duplicate work? in the end though there will just be 1 object right
11:55:45 <Zemyla> But one thread will probably evaluate x, and the other will find x already evaluated?
11:55:47 <geekosaur> dolio, EvanR, there are known cases where gcc with optimization will compile such things to code that throws an exception immediately
11:55:57 <geekosaur> that is, jumps to the exception handler
11:56:04 <hpc> Cale: and that works because thunks are usually very small?
11:56:18 <monochrom> yes Zemyla
11:56:29 <Cale> Okay, so to explain what happens it's important to know that x is represented by a pointer to code
11:56:33 <hpc> in some highly optimized code you can have evaluations with no allocation that go on for quite a while, and repeating one of those might cost dearly
11:56:56 <monochrom> yeah you have to know lazy evaluate by heart and then add multithreading
11:57:28 <Cale> The first thing that happens when that code is entered the first time (in the threaded runtime), is that it rewrites the pointer to point to a "grey hole", which is a piece of code which will wait for the evaluation to finish
11:58:05 <hamid> Zemyla, guessing that whethere evalution of pure functions is processed atomically :/ or at least replacing the thunk with the value... im not sure if im even asking a correct question or
11:58:09 <hamid> not
11:58:10 <Cale> and then it computes the value of the expression bound to x, and rewrites the pointer again to point at a piece of code which will immediately return the result of evaluation on subsequent entries
11:58:46 * hamid hugs Cale 
11:59:11 <hamid> Cale, Thank you.
11:59:16 <Cale> So usually what will happen is that one thread will wait for the other to finish computing the value, and then use the completed result.
11:59:26 <Zemyla> Cale: Also, in GHC, the last 2 or 3 bits of the pointer are nonzero if the thunk points directly to a constructor.
11:59:41 <Cale> yeah, if there are few enough constructors in the type
11:59:43 <hjulle> And a second thread tries to evaluate before the gray hole is written?
11:59:46 <saurabhnandan> hey, has anyone managed to install haskell-mode (emacs/spacemacs) with Stack?
12:00:05 <Zemyla> Cale: Even if there are more, the last bits are 3 or 7.
12:00:05 <rydgel> Cale: thanks for the explanations, it's interesting
12:00:19 <Cale> Zemyla: ah, cool
12:00:28 <Cale> Zemyla: er... that's interesting actually
12:00:53 <Cale> Zemyla: I wouldn't have thought that was worth the trouble if you're not going to know which constructor it is without entering.
12:01:26 <Zemyla> Nah, it's basically just "this is a constructor, not a thunk".
12:01:37 <Cale> Well, that doesn't help you though.
12:01:59 <Zemyla> The constructor number is still in what is pointed to.
12:02:02 <EvanR> heh, wouldnt a pointer to data be better than a pointer to code
12:02:21 <Zemyla> Yeah, it shows it's a data pointer.
12:02:29 <Cale> Ah, right, I suppose it just looks at the table before the code then
12:02:39 <Cale> which avoids a jump
12:03:12 <hjulle> What happens if two thread tries to make the gray hole "at the same time"? Is that operation completely atomic?
12:03:29 <Cale> hjulle: both threads will write it, and compute x
12:03:31 <posco> bitemyapp: by the way, adding a SCC to noneOf reveals that as the main cost. FJ
12:03:39 <Cale> It's not completely atomic, which is what I was referring to before
12:03:48 <hjulle> Cale: So one will overwrite the other?
12:03:53 <Cale> hjulle: with the same value, yes
12:03:58 <posco> bitemyapp: rewriting it without lists helped somewhat...
12:04:24 <Cale> hjulle: Of course, purity of evaluation is very important there.
12:04:52 <Cale> unsafePerformIO has some extra (and more costly) safeguards inside it, so as to sidestep that problem.
12:04:53 <hjulle> Cale: So the gray hole is identical regardless of who makes it?
12:04:56 <Cale> yeah
12:05:18 <Cale> hjulle: Not only is the grey hole pointer the same
12:05:28 <Cale> hjulle: but also the result of evaluation is the same
12:06:25 <hjulle> Cale: But I guess it could point to different pieces of memory, with the same result?
12:06:29 <Cale> If both threads start evaluating the thunk at the very same time (there's a one or two clock cycle window), then both will evaluate it independently, and overwrite each other in one order or the other
12:07:26 <Cale> Yeah, I suppose they may both allocate some space for the result, and the one which is overwritten will get garbage collected.
12:07:59 <Cale> Basically, you have a slight probability that work is repeated, but it's hard to get this to happen even if you're trying to make it happen.
12:08:02 <hjulle> This is really interesting
12:08:07 <bitemyapp> posco: so I was right about noneOf? :)
12:08:16 <Cale> So it doesn't turn out to be worthwhile doing anything more costly to prevent it.
12:08:22 <bitemyapp> posco: without lists makes sense.
12:08:24 <obadz> I'm trying to show a race condition in a program compiled with GHC: https://gist.github.com/obadz/bf5a3eb07f664e78cf8a74918b877ea3
12:08:39 <obadz> What I don't understand is why "mainShowRace" works but "mainWontShowRace" doesn't
12:08:52 <bitemyapp> posco: I know the posts are about attoparsec, but it's worth reading Bryan O'Sullivan's blog posts on speeding up parsers generally and speeding up attoparsec specifically
12:08:57 <obadz> (where "work" where means "shows race condition"
12:09:02 <bitemyapp> posco: you pick up some nice intuitions for what might be slow, even in things like parsec.
12:09:21 <posco> bitemyapp: my fear is that many is pretty bad news.
12:09:31 <hjulle> Cale: Yeah, 2 clock cycles is a _very_ small time frame.
12:09:41 <posco> especially on long [Char] 
12:09:58 <bitemyapp> I personally would expect it to be.
12:10:04 <bitemyapp> but YMMV.
12:10:37 <bitemyapp> I try to stick to cursor bumping around a bytestring or text value when I need speed.
12:11:03 <Cale> hjulle: But implicit in this is the assumption that we really must obtain the same result if it does happen. Things like unsafePerformIO and unsafeInterleaveIO break that assumption, and so require more expensive synchronization to ensure that nothing else is evaluating the same thunk.
12:11:20 <posco> bitemyapp: thanks for looking at this
12:11:21 <hjulle> Of course.
12:12:01 <Cale> There's unsafeDupablePerformIO which skips that synchronization at even greater risk :D
12:12:02 <bitemyapp> posco: np
12:12:29 <geekosaur> ...which is useful with the FFI, when you are calling a known-pure C function
12:12:31 <Cale> It was actually not realised for quite some time that this was a problem with unsafePerformIO and that the check needed to exist.
12:12:40 <hjulle> Cale: But the overwrite operations themselves must be atomic at least, so two overwrites don't interfere with each other and give a result none of the threads wanted.
12:13:06 <Cale> hjulle: Yeah, they're ultimately just writing a single machine word, so that's atomic.
12:13:21 <aweinstock> accursedUnutterablePerformIO: https://github.com/haskell/bytestring/blob/master/Data/ByteString/Internal.hs#L553
12:13:31 <Cale> (it's a pointer to code, with some flag bits in its least significant bits that would otherwise be unused)
12:14:28 <obadz> is there a way to send a message to many listener threads at once?
12:14:32 <Cale> "If you think you know what you are doing, use 'unsafePerformIO'. If you are sure you know what you are doing, use 'unsafeDupablePerformIO'. If you enjoy sharing an address space with a malevolent agent of chaos, try 'accursedUnutterablePerformIO'." 
12:14:44 <obadz> like a "peekMVar" kind of construct?
12:15:10 <obadz> oooh there is readMVar
12:15:24 * geekosaur likes how the trailing #-} comes across as a malevolent grin emoji :p
12:15:33 <geekosaur> in that context
12:16:03 <EvanR> Cale: it just happens to be atomic on x86
12:16:13 <EvanR> other very special archs can tear words...
12:16:38 <Cale> EvanR: Well, okay, on such architectures, the reimplementation of the runtime system would need to take care then :)
12:16:58 <EvanR> yes all the myriad archs that haskell runs on
12:17:14 * bitemyapp can taste the salt from here
12:17:56 <Cale> I think we're doing pretty well... Javascript counts as an architecture, right?
12:18:07 * hackagebot tasty-hspec 1.1.3 - Hspec support for the Tasty test framework.  https://hackage.haskell.org/package/tasty-hspec-1.1.3 (mitchellwrosen)
12:18:09 <EvanR> ... unfortunately
12:18:30 <obadz> anyone interested in helping me investigate this ghc bug?
12:18:47 * EvanR preorders the new intel chips that use javascript
12:19:34 <hpc> i can't wait to use the new XHRPTFBLB call
12:19:45 <hpc> (xml http request post to facebook long buffer)
12:19:57 <hjulle> obadz: There's also http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Concurrent-Chan.html#v:dupChan if you actually want to send *messages*.
12:20:29 <divVerent> Who deleted https://hackage.haskell.org/package/left-pad-0.0.3 ?!?!?!?!?!?! Now all my code doesn't build...
12:20:31 <divVerent> ;)
12:20:42 <obadz> hjulle: I'm trying to make sure my threads start their evaluations in as close of a timeframe as possible
12:20:58 <Cale> lol, someone should make Acme.LeftPad
12:21:10 <Elision> lol
12:21:16 <hpc> don't tempt me
12:21:33 <hpc> although if someone writes it, i will 100% make acme-php depend on it
12:21:37 <divVerent> ;)
12:21:46 <hjulle> obadz: Yes, as a one-time flag mvar will work fine. :)
12:21:48 <thoughtpolice> IDK, GHC actually does run surprisingly well on the common ones you'll find. We have at least itanium, ppc[64] (big/little endian), armv7, aarch64, and mips coverted on Linux I think.
12:22:08 <thoughtpolice> (Lots of these are maintained/tested by slyfox as part of the Gentoo hardware farm). But we have a few of our own.
12:22:17 <ShockMe> Do any of the cool cats here know the coolest way of getting command line arguments of different types?
12:22:28 <ShockMe> From checking online there's more than a few ways of getting command line args
12:22:47 <divVerent> hpc: cool, the TDWTF reference in acme-php :)
12:22:49 <obadz> hjulle: well as I understand readMVar = takeMVar + putMVar :-( so in some ways the threads are being sequenced rather than syncronized..
12:23:14 <Cale> ShockMe: I haven't explored it really extensively, but optparse-applicative is quite nice (just remember to set the config options explicitly, since the defaults have automatic help disabled)
12:23:18 <thoughtpolice> There's even a patch for AIX/PPC right now. But not all of them have all the various features/compatibility you'd expect from a regular Linux machine.
12:23:23 <ShockMe> For example I have "(fileName:functionFilter:seperation:_) <- getArgs", this is from http://learnyouahaskell.com/input-and-output#command-line-arguments
12:23:29 <divVerent> hpc: your PHP emulation is bad and you should feel bad - it returns bottoms ;)
12:23:31 <thoughtpolice> In theory, all most of these platforms need is just someone dedicated to them...
12:23:37 <ShockMe> But searching for my issue I found https://stackoverflow.com/questions/17993074/haskell-how-to-read-in-command-line-args-as-int which is totally different
12:23:38 <divVerent> a true PHP emulation would do something like ON ERROR RESUME NEXT ;)
12:24:16 <Cale> thoughtpolice: What does the bootstrapping story look like at the moment?
12:24:43 <hjulle> obadz: It's actually only semantically equivalent. "readMVar is multiple-wakeup, so when multiple readers are blocked on an MVar, all of them are woken up at the same time." :) http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Concurrent-MVar.html#v:readMVar
12:24:57 <posco> bitemyapp: I'm still fearful there is some kind of massive recomputation going on here. 200 characters per sec, and allocating 15GB to parses 1600 bytes seems pretty bonkers
12:25:14 <hjulle> (or perhaps I'm missusing the word "semantic" here)
12:25:24 <posco> bitemyapp: on a 2.8 GHz machine
12:25:27 <bitemyapp> That it does! Never seen any thing like it before. So goes Parsec and the myriad performance death-traps therein.
12:25:36 <posco> ha
12:25:43 <bitemyapp> http://haskelliseasy.readthedocs.org/en/latest/#parsing
12:25:55 <bitemyapp> I do my best to steer people away. Can't do anything if nobody asks.
12:25:57 <obadz> hjulle: I see, but then it doesn't explain https://gist.github.com/obadz/bf5a3eb07f664e78cf8a74918b877ea3 :-(
12:26:32 <Cale> posco: That sounds like something incorrect is happening, even for parsec.
12:27:03 <Cale> Parsec is not really tuned for efficiency, but at the same time, it's not *that* bad
12:27:13 <divVerent> hpc: here's a constructive suggestion
12:27:26 <divVerent> add a crazy-wrong (==) to acme-php
12:27:32 <divVerent> and define (===) to work somewhat right
12:28:01 <thoughtpolice> Cale: Cross compiling with a dash of unregisterized compilation at the moment, I think.
12:28:14 <divVerent> I suggest (==) a b = intval a == intval b (even though that's Perl's ==, not PHP's)
12:31:07 <hjulle> obadz: I'm assuming STRefs are not thread safe?
12:31:18 <obadz> hjulle: that's what I'm trying to show
12:31:18 <monochrom> in fact, Parsec is tuned for a balance of memory efficiency and generality
12:31:26 <obadz> hjulle: mainShowRace shoes that
12:31:43 <obadz> hjulle: but I wanted to "scale" that example to arbitrary number of threads and not print directly from the threads
12:31:53 <obadz> hjulle: somehow the race condition never happens when I do that‚Ä¶
12:32:35 <posco> what do "entries" mean on profiling output? that can's be the number of times it was called
12:32:48 <monochrom> lately I've been TAing complexity at school, and it is amazing how much we tolerate, say, quartic time algorithms in order to not exceed logarithmic space
12:33:10 <Rembane> monochrom: What's a quartic time algorithm?
12:33:15 <monochrom> n^4
12:33:23 <posco> actually, looks like it is: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html
12:33:34 <river_> is it possible to declare the type of something inside a do block (for example x :: Int) ?
12:33:47 <posco> bitemyapp: I'm seeing some of these functions called like 10 million times. I don't get that at all.
12:35:20 <hjulle> obadz: Just use a single MVar instead of 30? Your current code literately resumes each thread in order.
12:35:31 <Rembane> monochrom: That's nasty.
12:36:07 <obadz> hjulle: these threads are writing to their respective MVars, not reading, why would they wait?
12:37:17 <hjulle> obadz: Aha, those are for delaying the main thread
12:38:21 <EvanR> river_: yes
12:39:47 <obadz> ¬´withMVar is an exception-safe wrapper for operating on the contents of an MVar. This operation is exception-safe: it will replace the original contents of the MVar if an exception is raised (see Control.Exception). However, it is only atomic if there are no other producers for this MVar.
12:40:04 <obadz> ¬ª ‚áí so it's not atomic then? ¬Ø\_(„ÉÑ)_/¬Ø
12:41:09 <hjulle> obadz: It could be atomic with respect to multiple readers?
12:41:49 <obadz> readers on other threads will either get the value before or the value after, I suppose you could call that atomic?
12:42:22 <obadz> but if there are two swapMVars operating at the same time, it's possible that ¬´your counter only gets incremented once¬ª no?
12:42:43 <river_> EvanR: thanks
12:42:56 <bitemyapp> posco: ?_?
12:45:43 <monochrom> obadz: "takeMVar, then putMVar" is not atomic. because takeMVar alone is atomic, putMVar alone is, but nothing says that sequential execution is atomic
12:48:29 <hjulle> obadz: My guess is that seq doesn't evaluate it sufficiently
12:50:08 <monochrom> obadz: however, you can still be saved if "every thread does 'takeMVar, then putMVar' in that order. no one usurps that order."
12:50:45 <monochrom> actually you probably also need "no one does 'takeMVar, then die or hang'"
12:51:21 <monochrom> withMVar helps with that last one
12:52:04 <Zemyla> Cale: I have a thing I'm doing that uses unsafeDupablePerformIO.
12:52:41 <Cale> Zemyla: is it safe? :)
12:53:21 <Zemyla> Well, it does no writing, so it should be safe.
12:54:03 <monochrom> it is safe iff duplicate executions are safe
12:54:18 <hjulle> obadz: Try deepseq
12:54:30 <monochrom> it's why the name contains "dupable" to express your belief
12:54:33 <dolio> I don't think "does no writing" is sufficient to be safe.
12:55:06 <monochrom> yeah, if you read a file, duplicate readings are different
12:55:42 <monochrom> you exactly want an idempotent operation
12:55:46 <Zemyla> It reads from an array where each entry is written in order exactly once.
12:55:47 <dolio> Yeah.
12:56:48 <Zemyla> And the array itself is guaranteed not to be bottom.
12:57:48 <obadz> hjulle: I did already :-/
12:58:06 <Zemyla> Since if it were, the whole thing would have bottomed.
12:58:26 <obadz> hjulle: shouldn't matter anyway as seq will get to the constructor of the 3000000th element, take 3 more elements is unlikely to make a difference
13:00:06 <Zemyla> Actually, is reading a single element from an array that typewise is mutable safe enough to be done with accursedUnutterablePerformIO/unsafeInlineIO?
13:00:10 <int-e> Zemyla: is it okay if the IO action silently dies in the middle?
13:00:13 <hjulle> obadz: Perhaps there is some semirandom delay from the print?
13:00:26 <int-e> Zemyla: I'm unclear about where the mutation happens.
13:01:05 <int-e> Zemyla: just reading should be fine... the mutable flag mainly concerns the garbage collector
13:01:27 <int-e> (and, of course, makes reading impure)
13:01:38 <obadz> hjulle: that would tend to cause the opposite phenomenon if that was the case.. the prints are more synchronized right now
13:01:41 <Zemyla> Okay. Basically, there is a Mutable v RealWorld a which (along with a current max length) is wrapped in an MVar.
13:02:38 <hjulle> obadz: The print might cause the thread to suspend in the middle of a calculation?
13:04:09 <Zemyla> It's appended by a function called from pure code, and returns either an altered vector pointing to the same MVar or to a new vector in a new MVar.
13:05:21 <hjulle> obadz: It still raceconditions if the threads print after the putMVar. Even print (length x) works.
13:05:31 <int-e> Zemyla: I'd be worried about that MVar. cf. https://ghc.haskell.org/trac/ghc/ticket/8502
13:05:51 <Zemyla> Any copies of the vector created before the append operation will be unable to see the new element, because it stores the length.
13:05:54 <obadz> hjulle: just switching to forM makes the race co go away: forM_ [1..5 :: Int] $ const . forkIO . print . take 3 . drop skip $ l
13:07:18 <Zemyla> int-e: So unsafeDupablePerformIO is currently even less safe than usual with MVars?
13:07:51 <int-e> Zemyla: it's as safe as it has always been.
13:07:56 <monochrom> Zemyla: if you have an array, mutable near the beginning, but it's write-once and very soon the writing is over. then after the writing is finished, you should be using "freeze" or "unsafeFreeze" to turn it into an immutable array, and live happily with it thereafter forever
13:08:20 <obadz> hjulle: argl even do { x; x; x } where x = blah seems to be different from do { blah; blah; blah }
13:08:59 <monochrom> rather than naval-glazing on the question "it is ok to read it by unsafeDupableIO?"
13:09:03 <river_> does anyone know how i could cast between basic types in the OpenGLRaw package (need to use a GLint as a GLuint)
13:09:06 <Zemyla> monochrom: I want to be able to have O(1) lookup and O(1) amortized append.
13:09:32 <monochrom> immutable arrays certainly enjoy O(1) lookup.
13:09:47 <monochrom> your array is write-once, no? what append?
13:09:53 <hjulle> forM_ mvars $ \ mvar -> forkIO (do { let {x = (seqit . take 3 . drop skip) l}; putMVar mvar x; print . length $ x})
13:10:10 <hjulle> Shows the race condition though
13:10:40 <obadz> hmmmm
13:11:02 <monochrom> but after you finish an append, you can freeze or unsafeFreeze again
13:13:02 <obadz> hjulle: you're right, the print does something somehow
13:17:30 <Zemyla> monochrom: snoc for a normal vector is O(n). I need O(1) snoc, and I can't just wrap it in ST because the data is coming from another monad.
13:18:31 <shachaf> @botsnoc
13:18:31 <lambdabot> :)
13:19:06 <Zemyla> Specifically, the Get monad from binary.
13:20:31 <hjulle> obadz: But it is very strange that changing it to a loop makes it stop. :/
13:21:18 <Zemyla> I need to parse data, append it, parse, append, and so on, and then only at the end freeze it to an immutable vector.
13:21:40 <obadz> hjulle: yes :-(
13:21:56 * obadz off for a bit. thanks hjulle for sharing my pain‚Ä¶
13:33:08 <hjulle> obadz: Aha. Debug.Trace to the rescue. The content of the loop is only evaluated once.
13:36:42 <hjulle> obadz: (That is to say, everyting after the print)
13:36:46 <ph88> what should i put as type signature when an attoparsec parser doesn't return anything ?
13:37:53 <dmj> ph88: Parser () ?
13:38:41 <maerwald> @hoogle skipSpace
13:38:42 <lambdabot> Text.ParserCombinators.ReadP skipSpaces :: ReadP ()
13:38:55 <maerwald> rather: skipSpace¬†::¬†Parser¬†()
13:39:02 <maerwald> so yes, attoparsec already does that
13:39:25 <maerwald> read the doc! :P
13:46:29 <int-e> Zemyla: Btw, I don't expect this to be an issue for you, but it's in principle possible to fork a Get computation, since internally it processes partial inputs; if one has inputs xs ++ ys and xs ++ zs, then one can feed xs to a Get parser, and then continue feeding ys and zs to the resulting, partially evaluated, Get parser.
13:50:49 <Zemyla> int-e: That's why I keep a record of how far it's written with the array itself, and a record of how long a specific "window" is.
13:51:30 <Zemyla> If an append would result in rewriting a section, it copies the vector instead.
14:10:53 <M-schmittlauch> ohai there
14:12:03 <M-schmittlauch> I'm trying to apply Data.List.concat to a list multiple times. Is there a way to apply a function n times without having to write it n times?
14:12:36 <pavonia> Not with the standard list type
14:13:00 <HallaSurvivor> maybe iterate?
14:13:01 <HallaSurvivor> :t iterate
14:13:03 <lambdabot> (a -> a) -> a -> [a]
14:13:09 <M-schmittlauch> I've already tried iterate, but it doesn't work as the types don't match: concat is :: [[a]] -> [a]
14:13:43 <M-schmittlauch> is it okay to paste small code samples directly into the chat?
14:13:45 <HallaSurvivor> maybe write a secondary function concat' :: [[a]] -> [[a]]
14:13:52 <HallaSurvivor> concat' just wraps concat in a list
14:16:47 <lyxia> it wouldn't do the same thing then
14:16:51 <M-schmittlauch> HallaSurvivor: You mean concat2 xs = concat xs : []? That'd be quite useless as wrapping the result of concat wouldn't decrease the nesting-level of the list
14:18:35 <lyxia> I'd use template haskell
14:19:22 <M-schmittlauch> It's quite frustrating that concat $ concat lll works without a type error if lll is a 3-times nested list, but that using iterate gives type errors
14:19:49 <HallaSurvivor> M-schmittlauch, you could then pattern match [xs] when you next call in order to retrieve just the list you want. 
14:19:51 <lyxia> this is one part where the type system is simply not expressive enough
14:20:25 <lyxia> you'll need dependent types if you want a generic iterate function
14:20:28 <HallaSurvivor> M-schmittlauch, I wish I Could help more, but I have a midterm in 10 minutes. Good luck!
14:20:45 <M-schmittlauch> HallaSurvivor: So I'd need yet another function?
14:20:59 <ahihi> you can use TH, but it seems overkill just to avoid repeating "concat" a few times
14:21:02 <lyxia> but what kind of data do you have that this is necessary
14:21:11 <M-schmittlauch> HallaSurvivor: good luck as well
14:21:29 <dolio> Iterating concat would only make sense if you have an infinitely nested list.
14:22:05 <dolio> So I don't see how it's a failure of expressiveness, unless that's what is under question (which I'm pretty confident isn't).
14:22:14 <mniip> @src sort
14:22:14 <lambdabot> sort = sortBy compare
14:22:24 <mniip> ugh
14:22:44 <mniip> sort [] = []; sort (x:xs) = filter (< x) xs ++ x:filter (>= x) xs
14:22:46 <Cale> M-schmittlauch: Well, iterate continues applying the function forever -- imagine what happens once you have just a simple list -- what would concat do then? It would try to append the first element of its argument to the concat of the rest, and the first element wouldn't be a list... so (++) would then try to pattern match, but it would be getting something else, like an Integer as its left argument
14:22:47 <mniip> which sort is that?
14:23:01 <M-schmittlauch> lyxia: I'm currently reading lyah and while reading about iterate and concat I thought "Hey, I may use this to flatten a multiple-nested list"
14:23:07 <lyxia> dolio: you iterate it a certain number of times, but it's still finite at any point
14:23:28 <Cale> concat [1,2,3,4] doesn't make very much sense
14:23:46 <mniip> M-schmittlauch, not really
14:23:53 <mniip> iterate only works on endofunctions
14:24:00 <Cale> and so iterate requires the function you give it to have the same type of input and result:
14:24:02 <Cale> :t iterate
14:24:03 <lambdabot> (a -> a) -> a -> [a]
14:24:04 <lyxia> if your lists are very very nested you probably should be using another type...
14:24:05 <mniip> iterate concat is not well-typed
14:25:41 <hjulle> obadz: Ok, I think I have figured it out now. There were multiple problems. For starters, seqit doesn't actually do anything. If seqit x is evaluated to WHNF, then its parameter gets evaluated to WHNF. :P
14:26:05 <dolio> lyxia: Only an infinitely nested list is able to be flattened all finite number of times.
14:26:20 <M-schmittlauch> @freenode_Cale:matrix.org: Yeah, you're right. I thought about the lazy evaluation so if I take 2 of the infinite list it would work for lists nested more than three times. But as it is  runtime-specific whether that works (depending on the input data) and the type checks are done at compile time it's probably the right decision not to allow this.
14:26:20 <lambdabot> Unknown command, try @list
14:26:25 <dolio> Unless you're an ultrafinitist, or something.
14:26:30 <lyxia> oh right
14:27:05 <lyxia> I don't really like iterate producing a list instead of taking the number of iterations directly...
14:27:53 <M-schmittlauch> Is there a way to apply a function n times which doesn't create infinite lists like lyxia proposed?
14:28:01 <hjulle> obadz: To solve that, either use evaluate or seq outside of the monadic action: "evaluate x >> putMVar mvar x" or "x `seq` putMVar mvar x"
14:28:12 * hackagebot google-oauth2 0.2.1 - Google OAuth2 token negotiation  https://hackage.haskell.org/package/google-oauth2-0.2.1 (PatrickBrisbin)
14:30:10 <hjulle> obadz: The other problem is that the expression containing l is only evaluated once. This can be solved by having a NOINLINEd function "ll = const l" and calling it with a different argument every time.
14:31:47 <deepfire> xplat|work: hi
14:32:19 <deepfire> xplat|work: google says you had a GHC8 fix for Shelly
14:32:43 <hjulle> obadz: The first problem is the "Gotcha" mentioned in http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Concurrent-MVar.html
14:33:00 <deepfire> xplat|work: would you mind releasing that as a github branch?
14:34:16 <mniip> sort [] = []; sort (x:xs) = filter (< x) xs ++ x:filter (>= x) xs
14:34:21 <mniip> what sort is that?
14:35:12 <hjulle> obadz: Debug.Trace is good for debugging the second problem.
14:35:32 <monochrom> it has a resemblance with quicksort. but there are contentions on what quicksort means.
14:35:41 <mniip> M-schmittlauch, what type would such application have
14:35:56 <mniip> I've seen this algorithm a few times
14:36:00 <mniip> does it have a name?
14:36:32 <mniip> (I've mistaken it for mergesort just now, and was wondering what it is called, if not that)
14:37:44 <M-schmittlauch> mniip: Well, I think it may have a type of :: Integral n => n -> (a -> a) -> a -> a
14:38:28 <mniip> @let something :: Integral n => n -> (a -> a) -> a -> a; something = error "urk"
14:38:30 <lambdabot>  Defined.
14:38:33 <mniip> :t something 3 concat
14:38:34 <lambdabot>     Occurs check: cannot construct the infinite type: a ~ [a]
14:38:35 <lambdabot>     Expected type: [a] -> [a]
14:38:35 <lambdabot>       Actual type: [[a]] -> [a]
14:38:59 <mniip> (that type wouldn't work)
14:39:21 <shachaf> You could call it miragesort.
14:39:36 <mniip> shachaf, yeah, it's not even N^2 is it
14:39:54 <mniip> M-schmittlauch, you need dependent typing for that,
14:40:04 <mniip> or, otherwise, a formal explanation of nested lists to the typechecker
14:40:22 <Cale> mniip: I'd call it quicksort. Time-wise it's similar to quicksort.
14:40:26 <mniip> with GADTs or something
14:40:29 <Cale> (asymptotically)
14:40:35 <Cale> It uses more memory
14:40:48 <Peaker> Cale: so many sorts are very different yet have similar asymptotics
14:40:56 <M-schmittlauch> mniip: This whas just an assumption: If I want to apply a function multiple times, it has to be :: (a -> a) and get an argument of :: a, a number of times it has to be applied and return an :: a
14:41:15 <Cale> Well, not only is it similar in terms of asymptotics, but it's essentially the same idea.
14:41:22 <Cale> (which is the important thing)
14:41:43 <mniip> M-schmittlauch, that can't be
14:41:51 <M-schmittlauch> mniip: K, as a bloody beginner I wait before using dependent typing (;
14:42:06 <mniip> if you say (a -> a), the argument of the function has to be the same as the result
14:42:10 <Cale> It's possible to execute that idea in a somewhat better-performing way, but it isn't really affected very much by that transformation, apart from being made somewhat harder to understand why it works.
14:42:11 <mniip> which is not the case with 'concat'
14:43:46 <M-schmittlauch> mniip: Yeah, I already found out and I also understand why it works that way (can't be checked at compile time). I was just wondering whether there is something for functions :: (a -> a)
14:43:59 <hjulle> I think hlint or perhaps ghc should warn whenever someone writes the function "join seq", or a variant of it. It's such a common newbie mistake.
14:44:04 <mniip> iterate
14:44:10 <mniip> a you were already told
14:44:21 <Peaker> hjulle: I hear adding hlint warning rules is really easy :)
14:44:33 <M-schmittlauch> mniip: Ok, thx
14:44:39 <mniip> hjulle, that's just id
14:44:58 * M-schmittlauch continues reading Learn You A Haskell
14:45:03 <hjulle> mniip: that's my point
14:45:05 <Cale> hjulle: yeah, it's funny how it's not more obvious that x `seq` x is only going to evaluate x before evaluating x if x would have been evaluated on its own.
14:45:26 <hjulle> Peaker: Can't tell if ironic
14:45:34 <mniip> Cale, before?
14:45:42 <mniip> (it's not before :) )
14:45:52 <Cale> mniip: Well, it's surely before in this case ;)
14:45:59 <mniip> hmm, yeah
14:46:06 <mniip> but which of the x do we return
14:46:15 <mniip> the one we evaluated before the other or the one after? xD
14:48:40 <dfeuer> http://stackoverflow.com/questions/36274369/what-are-some-types-that-discriminate-between-categories asks, among other things, about Functors that are not valid Apply instances. I haven't been able, yet, to think of an example of a valid Functor that *cannot* by made a valid (even if strange) Apply. Anyone have any ideas?
14:49:17 <dfeuer> (where Apply is Applicative without pure)
14:49:18 <Peaker> hjulle: nope -- I think hlint has a nice declarative language you add hints with -- so should be easy
14:50:40 <dfeuer> Cale, maybe?
14:51:11 <hjulle> Peaker: Do you think "warn = join seq ==> id" is a good rule to use? ;)
14:52:06 <Cale> dfeuer: For a semigroup which isn't also a monoid, consider Integer with max
14:52:35 <dfeuer> Cale, that's good too, but my brain's stuck on a Functor that *can't be* an Apply :P
14:52:46 <Cale> Apply is which?
14:52:54 <Cale> It's like, part of Applicative, right?
14:53:02 <dfeuer> Apply is Appliative but without pure, and with just an associative law.
14:54:00 <Cale> Okay, what examples of a functor which isn't also a monad do you have?
14:54:16 <Cale> Start there, since Monad is far more demanding.
14:54:38 <Peaker> hjulle: perhaps an explicit warning is better than telling the user to replace with "id"? Replacing with "id" is not really what they want
14:54:43 <dfeuer> Lots of things are Applicative but not Monad, such as ZipList, regex-applicative parsers, ...
14:55:25 <Cale> Right, so those are Applicative, and so you'd have Apply instances as well
14:55:57 <Cale> I don't know of many functors in Haskell for which we wouldn't also be able to define an Applicative instance somehow.
14:56:21 <Cale> But for some it would be quite unnatural
14:56:27 <dfeuer> McBride offers newtype Dead x = Oops {oops :: Void}
14:56:30 <Cale> Consider for example, graphs
14:56:50 <dfeuer> But that's problematic because   oops (pure ()) :: Void
14:56:54 <Cale> Well, that will fail to be pointed
14:56:55 <Cale> yeah
14:57:11 <dfeuer> Apply doesn't give you points, so that counterexample is useless.
14:57:19 <Cale> Graphs is a better example I think.
14:57:41 <Cale> There's probably a couple instances you could get, but none of them stand out as really great.
14:57:50 <hjulle> Peaker: Yes, it was mostly a joke. But I am not sure how to do that. All the rules I find are replacement rules.
14:57:57 <Cale> To the extent that you'd actually want to define the instance.
14:58:12 <dfeuer> What sorts of graphs are Functors, and why can't they be law-abiding Apply instances? I already came up with the example of Handler (exception handlers) as Functors with no *sensible* Apply instance.
14:58:25 <Cale> dfeuer: Pretty much anything labelled with values of an arbitrary type
14:58:29 <dfeuer> Now I just want one that can't be a valid instance at all.
14:58:31 <Cale> Let's say edge-labelled graphs
14:59:06 <dfeuer> Hmm... That does sound tough.
14:59:19 <Cale> So, if you have a graph whose edges are labelled by functions (a -> b) and a graph whose edges are labelled with values of type a, what do you do?
15:00:22 <Cale> Well, there are some things actually which you could do, but they tend to result in rather large unwieldy graphs which don't tend to be much use.
15:00:22 <dfeuer> Cale, how are you representing these?
15:00:27 <Cale> Doesn't matter.
15:00:28 <hjulle> Peaker: This rule is present, so I guess I could add a similar one: warn "Redundant seq" = x `seq` x ==> x
15:00:38 <lkj> is there a way to use the chart library without rendering to a file?
15:01:04 <dfeuer> Cale, my point was going to be that once you gave me a concrete representation, I could probably give you a law-abiding but *completely meaningless* Apply instance.
15:01:17 <mniip> Apply instances?
15:01:19 <Cale> Oh, well, law abiding is not hard
15:01:21 <mniip> you mean applicative?
15:01:29 <dfeuer> mniip, Applicative - pure = Apply
15:01:34 <Cale> You can always have any combination just result in the empty graph
15:01:38 <mniip> ah
15:01:40 <Cale> and that'll be associative
15:01:43 <dfeuer> Yeah, for example, that.
15:01:45 <Cale> and dumb
15:01:55 <Cale> But it's not helpful in any way
15:02:11 <dfeuer> You can't do *that* for graphs constrained not to be empty, but you can likely do something equally dumb.
15:02:57 <mniip> I have an idea
15:03:12 <dfeuer> Oh?
15:03:38 <mniip> if you have an edge from X to Y called f, and an edge from X' to Y' called a, then the resulting graph will have an edge from (X,X') to (Y,Y') called f a
15:04:11 <mniip> where X, Y, etc are random temporary labels for vertices (they are unlabelled, right?)
15:04:40 <Cale> The better instance is, given graphs (V,E) and (V',E') to form a graph whose vertices are V x V', and such that there is an edge (u,u') to (v,v') in the product whenever there is an edge u to v in E and an edge u' to v' in E', and then the label can be formed by application of the function to the corresponding argument
15:04:52 <mniip> yeah
15:05:00 <Cale> ah, you figured it out while I was writing it too :)
15:05:05 <mniip> huh
15:05:44 <Cale> So, yeah, there is that, the tensor product of graphs, but I don't know if it's worth defining most of the time.
15:05:51 <Cale> Probably in some cases
15:06:23 <dfeuer> OK, so we've excluded graphs from things that are Functors but *can't* be Applys. Next!
15:06:30 <Cale> So long as you're guaranteed that the thing is nonempty, you can always define an associative operation.
15:06:37 <monochrom> it is important when the graphs are automata
15:06:39 <mniip> ah there's a problem
15:06:52 <Cale> Just pick an element arbitrarily
15:07:01 <mniip> such a thing is only defined for directed graphs
15:07:15 <Cale> It still works for undirected ones
15:07:19 <mniip> no
15:07:22 <monochrom> indeed if you talk about intersecting two regular languages, you build this product automaton
15:08:00 <osa1> where do I send "looking for maintainer" mails? cafe or libs?
15:08:13 <mniip> consider a graph X---Y---Z times A---B
15:08:14 <Cale> mniip: Undirected graphs are a special case of directed graphs which always have an edge v to u whenever there is an edge u to v, and such that the label on each of these will be the same
15:08:26 <mniip> it is either AX---BY    AY---BZ
15:08:31 <mniip> or AX---BY---AZ
15:08:35 <hjulle> obadz: Btw, running hlint on your code will give some suggestions.
15:08:37 <mniip> and the two are not isomoprhics
15:08:40 <mniip> isomorphic
15:08:58 <Cale> mniip: If you form the product of the underlying directed graph, you'll see that it also qualifies as an undirected one.
15:09:03 <mniip> Cale, then there is no identity graph
15:09:17 <mniip> and it's not applicative
15:09:19 <Cale> hm?
15:09:33 <dfeuer> mniip, we're talking about Apply, not Applicative, so that's quite irrelevant.
15:09:38 <Cale> One vertex with a self loop would be the identity
15:09:53 <mniip> it would double every edge though
15:11:11 <danza> hello, can anybody recommend a package for client-side authentication with OAuth 1 ? 
15:12:32 <Cale> mniip: I don't see it
15:12:40 <Cale> mniip: Seems like it works to me
15:13:30 <mniip> well, what's identity * identity
15:14:57 <Cale> I suppose if you want to admit self-loops in the first place, you have the question regarding whether you're allowed more than one or not.
15:17:17 <Cale> You have a single vertex in the product, which has an edge to itself, since the corresponding vertex in each factor has an edge to itself, and it's labelled with f x, where f is the label on the first graph's self-loop and x is the label on the second graph's self-loop
15:17:38 <Cale> (There's only one edge for the self-loop)
15:20:29 <mniip> so you're saying that because the two ways of combining the edges are the same, the output should only have one edge?
15:20:38 <mniip> that's a slippery slope
15:20:47 <mniip> I'm sure I can come up with a counterexample to that
15:21:55 * mniip haskells
15:35:30 <danilo2> Hello guys! I;ve got a problem with Haskell type system being too explicit (heh, thats a rare problem I think). Anyway I've got a typeclass: `class Append (a :: [*]) where append :: RTuple a -> RTuple b -> RTuple (a <> b)` and I've got 2 instances that define it working for all possible arguments (empty list and any non-empty list). 
15:36:24 <danilo2> I would like to be able to translate it somehow to pure function: "append :: RTuple a -> RTuple b -> RTuple (a <> b)" without any context, because it is useless for the users to type the context everywhere if its guaranted its met. Is it or would it be possiblei n the new GHC? here is some minimal example code:
15:36:39 <danilo2> http://lpaste.net/157575
15:37:08 <danilo2> I would like to just be able to purely cocnat two RTuples together without writing context's because its just too chatty and explicit for the user
15:38:31 <dfeuer> danilo2, tough noogies :-(. Unfortunately, your two instances *don't* cover all the possibilities, because I can give you an exception:   type family Oops :: [*] where {}
15:39:17 <dfeuer> danilo2, this feature has its advantages, but it seems rather sad as well.
15:39:52 <danilo2> dfeuer: `type family Oops :: [*] where {}` uh ...
15:40:23 <danilo2> dfeuer: ok, but you see why I'm looking for it and why I want to have it? Do you think is there ANY way to clean this API somehow?
15:41:33 <danilo2> dfeuer: In fact I want this typeclass be hidden for the user - I want only expose the functionality of add and then - it'll be safe, because you're code will give error when trying to use the `<>` in the type level
15:43:30 <dfeuer> danilo2, I'm looking at this now, and I don't understand your types. How is RTuple '[Int, Char] a thing?
15:44:24 <danilo2> dfeuer: RTuple '[Int,Char]   will be a wrapper around (Int,(Char,()))
15:44:41 <danilo2> dfeuer: Lst2RT defines the transition, do you see it?
15:44:56 <dfeuer> Oh, you've changed your types since Hackage.
15:45:12 <danilo2> dfeuer: I think we will be able to remove the ocntext using some fancy existential datatype,s but it will hit us in the runtime performance though
15:45:46 <danilo2> dfeuer: what do you mean by "since hackage" ? :)
15:46:02 <dfeuer> danilo2, could you switch to an HList-style GADT?
15:46:19 <danilo2> dfeuer: sure
15:46:59 <danilo2> dfeuer: but will it give us anything regardign this issue? I think this will lead us to exactly the same think if I'm not wrong here
15:47:00 <dfeuer> Because pattern matching on the HList will give you the evidence you need. This type family ... I think not.
15:47:14 <dfeuer> danilo2, you are wrong :-)
15:47:32 <danilo2> dfeuer: let me think about it, brb! :)
15:47:38 <dfeuer> I should not be here!
15:47:49 <dfeuer> Why am I here?
15:47:53 <dfeuer> RGH.
15:51:58 <dfeuer> Also, danilo2, I firmly believe that overlapping instances are a way to shoot yourself in the foot and nothing more. You shouldn't really need them!
15:53:20 <monochrom> I believe that it is something more. for example "data type a la carte" needs it
15:53:27 <danilo2> dfeuer: of coure, the overlapping isntances here anre not needed and are placed by accident
15:53:45 <danilo2> dfeuer: I've implemented it using GADTs, still I've got the same issue, coudl you please take a look?
15:53:53 <dfeuer> monochrom, in that case, "data type a la carte" is wrong :)
15:53:56 <danilo2> dfeuer: http://lpaste.net/157579
15:54:20 <dfeuer> danilo2, you have two instances. Make just one!
15:55:08 <danilo2> dfeuer: wait, how
15:55:11 <danilo2> dfeuer: ?
15:55:44 <c_wraith> danilo2, that <> in the type doesn't look right.. unless you've declared it as a type function somewhere outside that paste. 
15:56:03 <danilo2> c_wraith: I've declared it in my previous paste
15:56:27 <danilo2> c_wraith: http://lpaste.net/157575
15:57:15 <danilo2> dfeuer: Are we able to declare only one instance to do what I want? I don't see it to be honest with you :/
15:57:17 <dfeuer> danilo2, appendHL :: HList xs -> HList ys -> HList (xs <> ys); appendHL Null ys = ys; appendHL (Cons x xs) ys = Cons x (appendHL xs ys)
15:57:35 <dfeuer> No class needed.
15:58:35 <dfeuer> This assumes    type family (<>) xs ys where '[] <> ys = ys; (x ': xs) <> ys = x ': (xs <> ys)
15:59:20 <danilo2> dfeuer: ah! without the typeclasses at  all! I didnt though GADTs will allow for it (but they'll of course will). Ha! great, this is exactly what I was looking for and I was a little blind here. I started to appreciate GADTs much more now than before! Thank you very much dfeuer ! :))))
15:59:52 <dfeuer> danilo2, no problem.
16:01:14 <dfeuer> danilo2, by the way, note that it's often more useful to use   data HListT t lst where Null :: HListT t '[]; Cons :: t a -> HListT t lst -> HListT t (a ': lst)
16:01:35 <dfeuer> Well, sometimes, anyway.
16:01:42 <danilo2> dfeuer: Ok, but if we went so deep with it, could you provide one more info to me please? Do you tihnk there is ANY way to tell Haskells type system about all these things it wants to know to allow the creation of such pure function but without using GADTs or GADTs are the only way here and there will be no other?
16:01:50 <Zemyla> dfeuer: Why so?
16:02:49 <dfeuer> Zemyla, well, sometimes useful. Lets you easily talk about ways to map over HLists.
16:03:08 <dfeuer> danilo2, let me think about that for a sec.
16:03:17 <danilo2> dfeuer: ok, If you want to use different bases for these HLists thats indeed a good solution. I dont need it atm, but thank you for the tip! :)
16:03:21 <danilo2> dfeuer: of course! :)
16:04:18 <Zemyla> danilo2: Can you use a data family instead of a GADT?
16:05:53 <dfeuer> Zemyla, a data family will have the same problems as the type family here, I'm quite sure.
16:07:04 <danilo2> Zemyla: Sure, I can use whatever I want. I was in fact trying to accompish it using type families and wrappers on the begining (http://lpaste.net/157575) and I'm just wondering what are the factors we cannot do it with TFs but we can do it with GADTs. I compeltely see it, but I'm just wondering if the tpe system in Haskell will eventually allow us to do it in the future
16:07:31 <danilo2> dfeuer: I'm sure it will have the same problem too
16:07:31 <dfeuer> danilo2, I don't think there's a way to do what you want without something like a GADT. You could use a tagless-final approach to express much or all of it, but I don't think you'll be able to write any *instances* without a GADT.
16:08:19 <dfeuer> Well, unless you constrain the operations you want.
16:08:38 <danilo2> dfeuer: ok, that's interesting. What is the "limiting factor" here? Is it something we want to improe /add to GHC in the future? I don't quite see if it will be helpfull in other use cases, but I assume that there will be some interesting examples
16:08:56 <mniip> Cale, wow
16:09:12 <Cale> mniip: hm?
16:09:39 <dfeuer> You *could* include cons, nil, and append if you wanted ...    class hlist where nil :: hlist '[]; cons :: a -> hlist as -> hlist (a ': as); append :: hlist as -> hlist bs -> hlist (as <> bs)
16:09:49 <dfeuer> But I don't think this is likely to get you where you want.
16:10:30 <danilo2> dfeuer: yep. Heh, thank you again very much for help and the conversation! :)
16:10:35 <dfeuer> danilo2, I'm not a type system expert! Ask someone like Richard Eisenberg (goldfire here sometimes).
16:11:02 <dfeuer> I like to try to be useful where I can though.
16:11:18 <danilo2> dfeuer: I'm ntot either, but I've written really lot of compelx stuff using Haskell's type system, still I never appreciated GADTs so much and always prefered to use TFs instead
16:11:48 <danilo2> dfeuer: Thank you once again! :)
16:16:51 <danilo2> dfeuer: by the way, an interesting fact is that the Data.HList is implemetned as data family (https://hackage.haskell.org/package/HList-0.4.1.0/docs/Data-HList-HList.html) and suffers from the same problem we were thinking about
16:17:24 <dfeuer> danilo2, there are two implementations of HList in that package; one as data family and one as GADT. Yeah, same issue.
16:30:09 <numee> ertes: I've got point-free transformation steps for the expression you gave to me: http://pastebin.com/CtBP642p I've written a program that makes a given expression point-free just for producing this.
16:33:32 <Peaker> why does cabal build rebuild everything if any dep changed? :(
16:34:54 <ertes> numee: ouch
16:38:13 <ertes> numee: well done‚Ä¶  probably was a lot of work to do that
16:40:35 <numee> ertes: thanks. I considered writing an imitation of the @pl command for a while so it was a good opportunity anyway.
16:42:39 <Gurkenglas> numme, source?
16:45:04 <Peaker> arrg.. spent ~30 minutes adding drag&drop support to GLFW-b, only to discover it was already implemented in some hidden git branch that's waiting for unrelated stuff to be put on hackage
16:47:28 <numee> Gurkenglas: I'm not proud of how the code looks now. I'd publish it if I've managed to make the code beautiful
16:47:35 <Peaker> on the plus side, the maintainer is amazingly responsive in minutes(!!) and will publish what he has, yay :)
16:48:08 <ertes> numee: don't worry too much, unless you're putting it on hackage or something
16:48:16 * hackagebot timelike-clock 0.1.0 - Timelike interface for the clock library  https://hackage.haskell.org/package/timelike-clock-0.1.0 (esz)
16:48:24 <ertes> i've pasted plenty of horribly ugly code =)
16:49:33 <Gurkenglas> numee, I wanna help :D paste it paste it
16:52:51 <ertes> released and builds, good night =)
16:58:16 * hackagebot astar 0.3.0.0 - General A* search algorithm.  https://hackage.haskell.org/package/astar-0.3.0.0 (JohannesWeiss)
17:04:52 <Gurkenglas> In http://lpaste.net/150858 , if I replace "instance Monad m => PointedAlternative (MaybeT m) m" with "instance Monad m => PointedAlternative (MaybeT m) (IdentityT m)", I could add the fundep g -> f, which would make the types of expressions using PointedAlternative look better, but people would keep having to unwrap IdentityTs. Is there a third way?
17:06:17 <spades-k_> ?
17:15:41 <dmwit_> chipb: pong
17:16:33 <dmwit> ?free f (a -> b) -> f a -> f b
17:16:34 <lambdabot> Extra stuff at end of line
17:16:39 <dmwit> ?free apply :: f (a -> b) -> f a -> f b
17:16:39 <lambdabot> Extra stuff at end of line
17:20:51 <Turbo_Pascal> hey
17:22:02 <Turbo_Pascal> is there a good/standard composable combinator approach to constructing json data?
17:22:45 <Turbo_Pascal> i'm piecing together some large json structured that isn't statically fixed
17:23:35 <hjulle> aeson
17:23:41 <solrize> @pl \p -> filter p ps
17:23:42 <lambdabot> flip filter ps
17:24:05 <Turbo_Pascal> hjulle how would you do it with aeson? seems like either you define fixed types
17:24:27 <Turbo_Pascal> or you use a map, but maps don't allow for nested heterogeneous types
17:25:33 <puregreen> Turbo_Pascal: you just generate your objects with ‚Äòobject‚Äô and ‚Äò.=‚Äô
17:26:08 <puregreen> Turbo_Pascal: ‚Äò.=‚Äô can be used on anything that can be converted to JSON, so you don't have to have heterogeneous types
17:26:37 <hjulle> `object ["name" .= name, "age" .= age]` or `pairs ("name" .= name <> "age" .= age)`
17:27:04 <mniip> Cale, http://i.imgur.com/4609SGv.png
17:28:17 <puregreen> this is... beautiful
17:28:20 <puregreen> mniip++
17:30:24 <lpaste> mniip pasted ‚Äúgraphs‚Äù at http://lpaste.net/157583
17:30:27 <hjulle> Now, someone build that applicative instance using 'diagrams'. :)
17:30:56 <Turbo_Pascal2> got disconnected
17:31:22 <Turbo_Pascal2> wait aeson for dynamically structured json, i still don't think it will work..
17:31:25 <monochrom> rename to Borland_Pascal :)
17:31:57 <Turbo_Pascal2> monochrom :D
17:32:19 <mniip> I really like this graph representation though
17:32:20 <Turbo_Pascal2> I need to be able to construct json fields dynamically. I don't think aeson can do that right?
17:32:26 <hpc> for a moment i read that as broderbund_pascal
17:32:26 <mniip> data EGraph e where EGraph :: Eq v => [Edge v e] -> EGraph e
17:32:58 <hjulle> Turbo_Pascal2: I think it can. Do you have a more concrete example?
17:33:26 <Turbo_Pascal2> for example
17:33:36 <Turbo_Pascal2> i have some data say a list of numbers [1,5,2,3]
17:33:50 <Turbo_Pascal2> i need to be able to add structure to the json that is data dependent
17:34:06 <Turbo_Pascal2> so, say, add fields named by each of the list elements
17:34:30 <hjulle> ... so you would get?
17:34:30 <puregreen> object [show n .= n | n <- [1,5,2,3]]
17:34:52 <puregreen> will generate {"1":1, "5":5, "2":2, "3":3}
17:34:58 <puregreen> (well, okay, T.pack (show n))
17:36:25 <Turbo_Pascal2> hmm let me play with that..
17:37:35 <Turbo_Pascal2> hm i guess that does work
17:38:21 <Turbo_Pascal2> how do i geta json string out of this?
17:38:39 <hjulle> encode
17:39:01 <Turbo_Pascal2> nice ... now ... almost got this
17:39:28 <Turbo_Pascal2> now i have to figure out how to get this into a spock endpoint for use with plotly
17:43:29 * hackagebot GLFW-b 1.4.8.0 - Bindings to GLFW OpenGL library  https://hackage.haskell.org/package/GLFW-b-1.4.8.0 (SchellScivally)
17:45:51 <Turbo_Pascal2> weird aeson is working in ghci
17:46:03 <Turbo_Pascal2> but copying the expression to the source file verbatim
17:46:10 <Turbo_Pascal2> and i'm getting ambiguous type variable errors
17:46:22 <mniip> probably because the expression is polymorphic
17:46:25 <Turbo_Pascal2> is there a particular extension that I'm missing?
17:46:31 <monochrom> ghci has extra defaulting that resolves ambiguity
17:46:51 <monochrom> it is better to add type annotations
17:47:43 <Turbo_Pascal2> i added explicit type annotations ot every field
17:47:57 <Turbo_Pascal2> and i'm still getting type errors
17:48:23 <Turbo_Pascal2> oh wait
17:48:29 * hackagebot bindings-GLFW 3.1.2.0 - Low-level bindings to GLFW OpenGL library  https://hackage.haskell.org/package/bindings-GLFW-3.1.2.0 (SchellScivally)
17:48:39 <monochrom> ok, either understand the error message, or paste code and error message
17:49:38 <Turbo_Pascal2> i see the problem
17:49:44 <Turbo_Pascal2> needed some perenthesis around the annotations
17:50:02 <Turbo_Pascal2> the .= had higher precedence
17:50:05 <Turbo_Pascal2> than the annotation
17:51:50 <Turbo_Pascal2> now i'd like to serve this json as the data for a plotly plot
17:51:57 <Turbo_Pascal2> thinking of using spock for that
17:52:29 <Turbo_Pascal2> how do folks usually go about munging aeson json into data for html+js that gets served up by spock (or alternatively some other lightweight web server)?
17:52:52 <puregreen> the ‚Äòjson‚Äô function in Spock sends a JSON value
17:54:03 <Turbo_Pascal2> puregreen i'm not seeing json in the hackage docs
17:54:36 <puregreen> Turbo_Pascal2: http://hackage.haskell.org/package/Spock-0.10.0.1/docs/Web-Spock-Shared.html#v:json
17:56:10 <Turbo_Pascal2> ah so object  constructs a value with ToJSON defined ..
17:59:55 <Turbo_Pascal2> sweet json is now being served
17:59:58 <blume> :o
18:00:04 <blume> cool
18:00:16 <Turbo_Pascal2> now i have to figure out how to wrap this into some html + javascript scaffolding
18:00:25 <Turbo_Pascal2> so the json data is a plotly plot
18:01:05 <Turbo_Pascal2> do people use blaze-html with spock? or is there a better way of prepping some html structure to serve up?
18:01:33 <ertes> Turbo_Pascal2: note that you don't *need to* go through the type classes‚Ä¶  you can construct as well as parse Value directly
18:01:36 <Turbo_Pascal2> also how does one compose / connect / serve up js code with spock typically?
18:01:52 <ertes> so aeson can really handle any JSON you need
18:01:55 <Turbo_Pascal2> ertes yes i'm not, thanks to the comments earlier about the Value type via object
18:02:15 <Turbo_Pascal2> ertes yeah this is excellent so far
18:02:20 <Turbo_Pascal2> who needs dynamic typing
18:03:29 * hackagebot phone-numbers 0.0.6 - Haskell bindings to the libphonenumber library  https://hackage.haskell.org/package/phone-numbers-0.0.6 (ChristianMarie)
18:04:01 <ertes> Turbo_Pascal2: Value basically *is* dynamic typing =)
18:04:22 <Turbo_Pascal2> man i'm super excited ... almost there
18:05:14 <mniip> restricted dynamic typing
18:05:22 <Turbo_Pascal2> needed some simulations for work. wanted to do some inference and visualizations..
18:05:32 <Turbo_Pascal2> instead of using matlab or python like a sane man
18:05:36 <mniip> for unrestricted dynamic typing see Typeable and Dynamic :p
18:05:43 <Turbo_Pascal2> or R and shiny like a half-reasonable man
18:05:47 <mniip> well, actually, it needs to be a monomorphic type, but yeah
18:06:56 <Turbo_Pascal2> I'm learning C FFI and spock so I can do C gnu science library backend - spock - plotly visualizations and interactions like a crazy person
18:07:53 <Turbo_Pascal2> because who needs a scientific computing ecosystem when you can plug C into a webserver with haskell :P
18:09:05 <Turbo_Pascal2> think i've almost got it end-to-end, have to figure out how to glom on the frontend. oh and also how to get spock to serve up functions that return monads..
18:25:09 <dmwit> mniip: s/cy/yc/g
18:25:44 <dmwit> Also, does this mean we need biapplicative so that we can have a combining function for node labels, too?
18:25:59 <dmwit> Well, "want" more than "need", I guess.
18:34:02 <dmwit> mniip: Dunno if you worked this out yet, but I think your claim that the product for "A --- B" and "X --- Y --- Z" could be one of two things and still meet all of Cale's rules isn't quite right, because your two proposed products have 3 and 4 vertices, respectively, but the product is supposed to have 6 vertices.
18:34:44 <dmwit> (In the real product all the edges in both your graphs are present.)
18:39:47 * dmwit discovers to his delight that `data Foo = Foo (forall a. [a] -> [a]) deriving Typeable` Just Works
18:40:22 <dmwit> Now I have an answer to "oh well Dynamic only allows monomorphic values", namely, "yeah, but your monomorphic value can contain a polymorphic value".
18:41:44 <shachaf> It can even be a newtype.
18:42:05 <dmwit> Even better!
18:42:21 <TruboPascal> file endpoints in spock have two arguments, text and filepath
18:42:25 <TruboPascal> what's the text argument for?
18:46:01 <puregreen> TruboPascal: see the source
18:46:03 <puregreen> http://hackage.haskell.org/package/Spock-0.10.0.1/docs/src/Web-Spock-Internal-CoreAction.html#file
18:46:12 <puregreen> it's ‚ÄúcontentType‚Äù
18:46:19 <dfeuer> Hi, dmwit!
18:48:11 <blume> so monomorphic is polymorhpic in this case?
18:49:20 <geekosaur> blume, in this case there is a monomorphic value (Foo) that "hides" the polymorphic value inside itself (non-top level forall)
18:52:10 <geekosaur> (this comes at a price: you can't do much with the polymorphic value)
19:04:40 <posco> bitemyapp: you're not still around are you?
19:12:33 <lpaste> grandpascorpion pasted ‚ÄúWhere does the dump-simpl output go?‚Äù at http://lpaste.net/157584
19:12:57 <TheGlidingGirl> What is haskell?
19:13:03 <grandpascorpion> Hello, I'm building a package via "runhaskell Setup.hs build" and a question about core:    http://lpaste.net/157584
19:13:17 <maerwald> TheGlidingGirl: a functional programming language
19:13:27 <TheGlidingGirl> Hmmm
19:13:43 <TheGlidingGirl> Examples? Plz
19:13:47 <nineonine> hi everyone
19:14:00 <TheGlidingGirl> hi nineonine
19:14:07 <maerwald> TheGlidingGirl: https://github.com/bitemyapp/learnhaskell
19:14:14 <nineonine> some Free Monad questions
19:14:42 <TheGlidingGirl> Thanks maerwald
19:14:48 <nineonine> please have a look at this RedditF m a  type
19:14:54 <nineonine> https://github.com/intolerable/reddit/blob/master/src/Reddit/Types/Reddit.hs
19:15:32 <nineonine> q 1 : what is the reason of having theses arguments in Data Constructor types ?  --- (b -> a)
19:15:45 <nineonine> this function argument
19:15:51 <grandpascorpion> ... Thanks for any assistance
19:16:08 <nineonine> and why do I often see id function in smart constructors ?
19:16:33 <nineonine> q 2) this Functor instance does not make sense (for me)
19:16:54 <nineonine> if I look at the Data constructor type
19:17:05 <hjulle> grandpascorpion: Try -fforce-recomp
19:17:11 <nineonine> x happens to be of type ( a -> b )
19:17:22 <nineonine> in the Functor instance 
19:17:45 <nineonine> how can we fmap over (a -> b)  ?
19:17:50 <nineonine> how does it even typecheck
19:18:02 <grandpascorpion> Thanks, hjulle!
19:18:16 <ReinH> nineonine: because ((->) r) is a Functor
19:19:02 <ReinH> > fmap (+ 1) (+ 2) 3
19:19:04 <lambdabot>  6
19:19:11 <ReinH> > ((+ 1) . (+ 2)) 3
19:19:11 <nineonine> I agree
19:19:13 <lambdabot>  6
19:19:32 <nineonine> but
19:19:38 <nineonine> RunRoute :: FromJSON b => Route -> (b -> a) -> RedditF m a
19:19:47 <nineonine> fmap f (RunRoute r x) = RunRoute r (fmap f x)
19:20:04 <nineonine> x is not ( (->) r) here
19:20:12 <nineonine> its (b -> a)
19:20:40 <ReinH> :t fmap `asAppliedTo` (++ "foo")
19:20:41 <lambdabot> Functor f => ([Char] -> [Char]) -> f [Char] -> f [Char]
19:20:47 <ReinH> Well, that's an annoying example
19:21:38 <nineonine> hmm
19:21:44 <ReinH> How would you write fmap for ((->) r) ?
19:21:48 <ReinH> fmap f g = ??
19:22:23 <ReinH> What is the type of fmap?
19:22:26 <ReinH> :t fmap
19:22:27 <lambdabot> Functor f => (a -> b) -> f a -> f b
19:22:28 <nineonine> fmap f g = (.)
19:22:28 <nineonine> ?
19:22:34 <ReinH> what would f be in the above?
19:22:37 <nineonine> fmap f g = f . g
19:23:08 <ReinH> if fmap :: Functor f => (a -> b) -> f a -> f b, then what is `f' in this case?
19:23:21 <ReinH> We know the answer, since it's given: f is ((->) r)
19:23:23 <ReinH> so what is f a?
19:23:33 <ReinH> f a is ((->) r) a, which is r -> a
19:24:03 <ReinH> fmap is applied to a value of type (b -> a) because that's a value of type f a for the f and a in question.
19:24:57 <ReinH> Sorry, which is a -> r
19:25:04 <hackrilege> :t (\ l -> zipWith (+) l (tail l))
19:25:05 <lambdabot> Num c => [c] -> [c]
19:25:15 <ReinH> Wait, no, got it right the first time, sorry
19:25:16 <nineonine> my head needs to cool down, i need time :))
19:25:45 <ReinH> nineonine: You don't apply fmap f to a value of type ((->) r). ((->) r) does not have any values.
19:26:09 <nineonine> ok got it
19:26:12 <ReinH> You apply fmap f to a value of type r -> a for whatever a you fixed before
19:26:17 <nineonine> its a functorial structure, right ?
19:26:33 <ReinH> It's a type of kind * -> *, which is the kind of Functor instances.
19:26:56 <ReinH> You could write the class definition explicitly as class Functor (f :: * -> *) where
19:34:08 <blume> thanks reinH
19:34:43 <hackrilege> > foldl1 (zipWith (+)) $ takeWhile (\a->length a > 4) $ (scanl1 (\ a _ -> tail a)) (repeat [1..7])
19:34:45 <lambdabot>  [6,9,12,15,18]
19:36:09 <geppettodivacin> Are there kinds that use symbols other than *?
19:36:11 <hackrilege> how can i evaluate the repeated elements only once? folding using (zipWith (+)) the successive tails of a list access the same ellement multiple times, how can i ensure it is only evaluated once?
19:37:41 <hackrilege> (\ l -> zipWith (+) l (tail l)) [1,2,3]
19:37:45 <hackrilege> > (\ l -> zipWith (+) l (tail l)) [1,2,3]
19:37:47 <lambdabot>  [3,5]
19:39:03 <hackrilege> =[1+2,2+3], here the ellement 2 is accessed twice, how do i ensure if its value was expensive to compute, that it was done once, or is this automatic?
19:40:23 <hackrilege> the example with scan above accessed the same value perhaps very many times
19:40:58 <geppettodivacin> I would think that it would reuse the same list for (tail l) that it uses for l, so it should only compute it once because it's lazy like that.
19:41:17 <hackrilege> yay!
19:41:18 <geppettodivacin> Although it will access the value multiple times, it should reuse the computed value and not the thunks.
19:41:31 <hackrilege> nono, i want to access it once
19:41:48 <hjulle> geppettodivacin: There is the kind Nat
19:41:56 <geppettodivacin> hackrilege: How do you access it once, if you're going to add it to two different things?
19:42:31 <hackrilege> assume the list is so large access is expensive, i know where the element is, its adjacent somehow, in c i could simply increment a pointer to the address and get that of the next
19:43:28 <Cale> The elements of the list are located at arbitrary places in memory
19:43:30 <hackrilege> i would go through the list making copies, so that while i had the value to hand i could send it to where it would be used instead of going to fetch it each time its called
19:43:56 <geppettodivacin> So you want to compute it once (because this is expensive) and access it twice (an inexpensive operation that allows you to use the value a second time)?
19:44:12 <Cale> (in fact, the tail pointer isn't even a pointer to the cons cell directly, it's a pointer to code which will return the cons cell when entered, computing it only if needed)
19:44:35 <hackrilege> compute it once, access it once to make copies, access each copy once
19:44:55 <Cale> huh?
19:45:05 <Cale> Why would you make a copy of it?
19:45:15 <hackrilege> so i didnt need to access it again later
19:45:28 <Cale> How is accessing the copy any different?
19:45:50 <Cale> That's just a waste of memory
19:45:52 <hackrilege> id go through saying, ok i know im going to need 6 of these later, so ill make 6 now and plae them somewhere neat, like adding them to a partial sum
19:46:07 <hackrilege> updating the output list instead
19:46:13 <hackrilege> as it might be considerably shorter
19:46:14 <Cale> 6 copies of the exact same thing?
19:46:20 <geppettodivacin> Cale: So if you compute the thunk the first time, because it's a pointer to the thunk you'd have to recompute it for the second use?
19:46:24 <Cale> with the same pointers in them and everything?
19:46:25 <hackrilege> im thinking like a finite difference stencil
19:47:29 <hackrilege> i have a pointer to an ellement in the list, i check the value, and eg, add this to each of 6 output lists
19:47:58 <hackrilege> rather than reading it 6 times when generating each of these output lists
19:47:59 <geppettodivacin> hackrilege: You may want to use seq to process the elements first.
19:48:02 <exio4> what do you want to do? avoid indirections in a tight loop? or what? 
19:48:16 <hackrilege> > foldl1 (zipWith (+)) $ takeWhile (\a->length a > 4) $ (scanl1 (\ a _ -> tail a)) (repeat [1..7])
19:48:18 <lambdabot>  [6,9,12,15,18]
19:48:40 <hackrilege> > (\ l -> zipWith (+) l (tail l)) [1,2,3]
19:48:41 <lambdabot>  [3,5]
19:48:51 <hackrilege> =[1+2,2+3], here the ellement 2 is accessed twice, how do i ensure if its value was expensive to compute, that it was done once, or is this automatic?
19:49:05 <Cale> geppettodivacin: There's code at the start of the thunk which will rewrite the pointer to point at either a black hole, which reports an error (detecting a loop), or waits for the result to be evaluated (in the case of the threaded runtime). Then, once the value is fully evaluated, the code pointer is rewritten again to point at a shorter piece of code which returns the result directly.
19:49:07 <geppettodivacin> Yeah, use `seq` to compute it once.
19:49:33 <exio4> you don't need to do anything
19:49:44 <hackrilege> yeah this is the question
19:49:54 <hackrilege> to seq or not to seq
19:50:18 <geppettodivacin> Mm. Well, if what Cale just said is true, then you shouldn't have to use seq.
19:50:26 <exio4> you don't need to do anything
19:50:37 <hackrilege> exio4 seems quie adamante
19:50:45 <hackrilege> adamant
19:51:00 <geppettodivacin> So we now have both Cale and exio4 on the side of not doing anything.
19:51:04 <hackrilege> so whats all the fuss about repa stencils?
19:51:22 <Cale> hackrilege: huh? That's kind of far afield.
19:51:42 <monochrom> how did we jump from scanl to repa?
19:51:59 <geppettodivacin> Also, Cale, that's the most detailed description of how thunks work that I've personally encountered. Thanks!
19:52:14 <hackrilege> http://research.microsoft.com/en-us/um/people/simonpj/papers/ndp/Stencil.pdf
19:52:19 <Cale> geppettodivacin: Oh, if you're interested in the details, there's a really nice paper
19:52:36 <geppettodivacin> Cale: That would be nice.
19:52:46 <Cale> http://www.dcc.fc.up.pt/~pbv/aulas/linguagens/peytonjones92implementing.pdf
19:52:53 <hackrilege> what i did using tail was like a stencil, combining adjacent ellements
19:52:58 <hackrilege> basically a convolution
19:53:04 <Cale> It's a bit out of date with respect to GHC
19:53:08 <Cale> but it's a good foundation :)
19:53:28 <Cale> GHC also does pointer tagging now, and it's also not exactly spineless
19:54:02 <hackrilege> sooo, whats the deal with the stencil and why cant i just do zip if its lazy enough to be fine?
19:54:26 <Cale> (but it does both of these things differently from the spines and tags which the spineless tagless G-machine doesn't have ;)
19:54:39 <blume> wow
19:54:53 <blume> sounds like ghc is in heavy development.
19:55:31 <Cale> hackrilege: repa is a library which works on packed arrays in parallel, not lists.
19:55:34 <geppettodivacin> Cale: Thanks!
19:56:14 <hackrilege> so i should expect a repa implementation on one core to behave as well as the naieve implementation?
19:56:26 <Cale> Implementation of what?
19:56:31 <hackrilege> stencil
19:57:01 <Cale> and what are you comparing to?
19:57:09 <hackrilege> http://research.microsoft.com/en-us/um/people/simonpj/papers/ndp/Stencil.pdf
19:57:12 <Cale> What's the naive implementation do?
19:57:18 <hackrilege> > foldl1 (zipWith (+)) $ takeWhile (\a->length a > 4) $ (scanl1 (\ a _ -> tail a)) (repeat [1..7])
19:57:20 <lambdabot>  [6,9,12,15,18]
19:57:44 <hackrilege> > (\ l -> zipWith (+) l (tail l)) [1,2,3]
19:57:46 <lambdabot>  [3,5]
19:57:46 <Cale> Oh, it should probably be orders of magnitude faster than using lists across a wide range of scales
19:58:05 <hackrilege> !? i thought you said it would be fine
19:58:15 <Cale> What would be fine?
19:58:21 <hackrilege> so long as i dont need to recompute those same values every time
19:58:25 <hackrilege> should i use seq now?
19:58:27 <exio4> one thing is sharing a thunk, the other is being cache-friendly, working with unboxed data, avoiding indirections, etc
19:58:32 <Cale> It has nothing to do with the recomputation of the elements
19:58:33 * hackagebot jsaddle 0.3.0.3 - High level interface for webkit-javascriptcore  https://hackage.haskell.org/package/jsaddle-0.3.0.3 (HamishMackenzie)
19:58:35 * hackagebot ghc-imported-from 0.3.0.1 - Find the Haddock documentation for a symbol.  https://hackage.haskell.org/package/ghc-imported-from-0.3.0.1 (CarloHamalainen)
19:58:45 <Cale> Lists are linked lists, they have terrible memory locality
19:59:02 <monochrom> also terrible overhead
19:59:24 <Cale> Yeah, what is it, like 24 bytes of overhead per list element?
19:59:29 <hackrilege> when you say "wide range of scales" it seems like you are accessing the smaller lists, if i traverse it scattering the data to the output then i only access each value once
19:59:46 <hackrilege> which is it
19:59:51 <Cale> hm?
20:00:10 <monochrom> yes, 24 bytes, and this hasn't counted actual items
20:01:18 <hackrilege> Cale, i donnt understand how what i have written is not meaningful, could you be more clear?
20:01:36 <Cale> When I say "wide range of scales" I'm not accessing anything.
20:01:43 <Cale> I don't understand that comment at all.
20:02:26 <hackrilege> the slowness does not result from access?
20:02:29 <hackrilege> ok fine
20:03:02 <Cale> The slowness results from the fact that you have to access way more memory, and that memory isn't likely to be in your cache because it's spread out all over the heap
20:03:03 <hackrilege> its about boxes?
20:03:14 <hackrilege> no what!?
20:03:33 <Cale> List elements aren't adjacent in memory
20:03:57 <Cale> A cons cell consists of an integer tag, and two pointers to code, one for the element and one for the tail
20:04:17 <monochrom> no no, the tag is also a code pointer
20:04:34 <hackrilege> but they are adjacent as they are linked, in some sense they are easy to find anyway, like i can find my neighbor more easily than its neighbor
20:04:42 <Cale> Hah, right
20:05:01 <Cale> hackrilege: uhhh
20:05:05 <exio4> hackrilege: there's an indirection
20:05:08 <MarcelineVQ> but if your neighbor has 7 doors
20:05:11 <exio4> hackrilege: that's how they are `linked`
20:05:28 <Cale> hackrilege: In that you only have to jump into some code and then when it returns, you get an address to go find the next list cell
20:05:38 <monochrom> in fact it is the other two pointers that can be data pointers (more precisely, pointers to heap objects or static objects) because evaluation has happened
20:05:47 <hackrilege> okok
20:05:52 <Cale> hackrilege: whereas with a repa array, it can do pointer arithmetic
20:06:04 <hackrilege> yuk
20:06:11 <Cale> what?
20:06:20 <monochrom> MarcelineVQ: if Monty Python opens one of the doors to show a goat, should I switch?
20:06:46 <hackrilege> its an onomatopoeic exclamation of derision
20:06:56 <exio4> monochrom: yes! 
20:07:06 <MarcelineVQ> monochrom: I had to look that up but then I liked it :>
20:07:19 <c_wraith> Monty Hall and Monty Python are the same?  The things I learn here never cease to astound me.
20:07:37 <monochrom> wait, is it Monty Python or is it Monty Hall?
20:07:47 <hackrilege> uncle monty
20:08:10 <monochrom> time to make a movie "Monty Python and the Monty Hall problem"
20:08:11 <Cale> monochrom: Well, they're still really code pointers, but if they have their low order bits set, then the real data is at an offset from them...
20:08:18 <hackrilege> will my ziplike stencil ruin my code?
20:08:19 <Cale> right?
20:08:26 <monochrom> no!
20:08:34 <Cale> wat
20:08:40 <hackrilege> how much am i saving by keeping things pure?
20:08:42 <exio4> Cale: ghess, the idea of using Haskell was to avoid playing with pointers! :P 
20:08:56 <Cale> exio4: Well, the implementation contains lots of pointers :P
20:09:01 <hackrilege> > range (0,0) (2,2)
20:09:03 <lambdabot>      Couldn't match expected type ‚Äò(Integer, Integer) -> t‚Äô
20:09:03 <lambdabot>                  with actual type ‚Äò[Integer]‚Äô
20:09:03 <lambdabot>      The function ‚Äòrange‚Äô is applied to two arguments,
20:09:12 <monochrom> I'll see if I can show you Cmm or asm code that says what I said
20:10:18 <hackrilege> > curry range (2,2)
20:10:20 <lambdabot>  <(Integer,Integer) -> [(Integer,Integer)]>
20:10:28 <hackrilege> > curry range (0,0) (2,2)
20:10:30 <lambdabot>  [(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)]
20:10:49 <hackrilege> here is a nice little 2d stencil
20:11:04 <hackrilege> i wish to convolve it
20:12:59 <hackrilege> rather that is a way of generating indexes
20:13:27 <hackrilege> or i could zip 9 copies of the array to itself...
20:13:31 <hackrilege> do you see what i mean?
20:13:46 <hackrilege> shifting them left right up and down
20:14:55 <hackrilege> i can dispense with the indexing using zipping i think, but im scared this will make so many extra work
20:15:19 <Cale> How big is the image you're doing convolution on?
20:15:35 <hackrilege> billions of pixles
20:15:50 <hackrilege> pixels* lol
20:16:03 <dougia> Hi, I am missing something:  How do express a type constraint in a type of a function.  This doens't compile: type  FuzzyMap a =  (FuzzyValue a) => Double->a
20:16:43 <Cale> In that case, you probably don't want to be repeatedly walking along a list -- well, it depends on how important performance is. You certainly don't want the image to be a list.
20:17:04 <exio4> maybe it's a billion of pixels which can be lazily generated! :P
20:17:10 <Cale> exio4: heh
20:17:38 <hackrilege> {-# LANGUAGE ScopedTypeVariables #-}
20:17:38 <hackrilege> {-# LANGUAGE ScopedTypeVariables #-}
20:17:38 <hackrilege> {-# LANGUAGE ScopedTypeVariables #-}
20:17:38 <hackrilege> i really want to use lists or other simple datastructures
20:17:46 <hackrilege> oops sorry for the tripple post
20:18:24 <hackrilege> i know some things have fast random access, but im not doing that, im stepping to each ellement exactly once in the fastest order indicated by the Traversable instance
20:19:14 <exio4> a list will probably have too much overhead and too many indirections
20:19:39 <hackrilege> dougia you could try using a :: instand of an =
20:19:58 <hackrilege> oh no sorry
20:20:00 <Cale> uhhh
20:20:06 <hackrilege> perhaps use newtype
20:20:25 <hackrilege> how could list be slow!?
20:20:43 <exio4> dougia: the type of a function? that's a type synonym
20:21:32 <exio4> hackrilege: Cale just said how a cons cell is represented in memory in GHC
20:21:58 <Cale> dougia: You'll need RankNTypes to define that as a synonym
20:22:01 <exio4> hackrilege: it isn't a very cache-friendly representation, either, so you will also suffer from cache misses
20:22:26 <exio4> hackrilege: which are expensive in modern architectures
20:22:43 <hackrilege> whatever, thats someone elses fault not mine, the Mu datatype is key to my discussion so i will use lists
20:22:48 <Cale> Yeah, monochrom thinks I might be off about it -- and I might be, it's been a while since I really looked at the details, but regardless, it won't change the point about cache misses
20:23:48 <Cale> hackrilege: You can expect perhaps a couple orders of magnitude difference in terms of time performance between using lists and packed arrays.
20:23:57 <lpaste> monochrom pasted ‚Äúpointers‚Äù at http://lpaste.net/157597
20:24:12 <monochrom> Cale: that's an example
20:24:35 <hackrilege> if i was doing a billion random access i could understand, but since lists are easy to traverse, and i will visit each node once, i cant see it being super slow. its not like im doing (!!) all the time, im doing map, or fold, to get to each ellement
20:25:20 <exio4> hackrilege: also, elements of lists are boxed
20:25:44 <hackrilege> why isnt the default container fast!?
20:26:19 <hackrilege> the discussion is boring, its a bunch of dumb work identifying the correct internal representation of list
20:26:21 <Cale> monochrom: Interesting, and fair enough :)
20:26:27 <exio4> lists aren't very good general purpose data structures, they're quite nice for control flow though :) 
20:26:33 <Cale> hackrilege: What's the default container?
20:26:46 <hackrilege> > [1..0]
20:26:48 <lambdabot>  []
20:26:49 <hackrilege> sugar
20:26:59 <monochrom> how dare you call my favourite discussion dumb. in fact, why isn't yours dumb.
20:27:06 <hackrilege> but also Free is key to the discussion
20:27:16 <hackrilege> Free Monoid is List, its key
20:27:24 <Cale> Yeah, lists have a bit of syntax sugar associated to them, because they're extremely well suited to many kinds of iteration
20:27:35 <Cale> They are *not* well suited to high-performance inner loops
20:27:39 <hackrilege> right at the heart of all the hylo rational
20:28:16 <monochrom> list is the default control-flow structure. not the default data structure.
20:28:22 <hackrilege> im going to have to have one implementation to comunicate with recursive types the programming paterns for understanding the flow of the program, and another one for speed...7
20:28:26 <Cale> yeah, that's a good way to put it
20:28:50 <Cale> hackrilege: Possibly
20:29:11 <Cale> hackrilege: It's quite reasonable to test a high performance implementation which is difficult to understand using a slow one which is easy to understand
20:29:26 <monochrom> there is no default data structure. Haskell is not trying to be Perl.
20:29:43 <hackrilege> anyway im using data Cycamore a = Branches a [Cycamore a] [Cycamore a]
20:30:43 <hackrilege> ok, so ill just forget everything pertinent and just do it with plain old slow list and my dumb intuative folding thing
20:30:47 <hackrilege> ziping*
20:30:59 <Cale> hackrilege: Give it a try, and you'll see what we mean :)
20:31:16 <hackrilege> i guess thats a danger with haskell, its great for intuition, but thats always slow, and whats fast is always incomprehensible
20:31:36 <Cale> Well, incomprehensible is a bit of an overstatement
20:31:38 <hackrilege> i know what you mean, its slow
20:31:43 <hackrilege> no
20:31:45 <monochrom> speak for yourself. many fast ways are comprehensible to me.
20:31:50 <hackrilege> these guys are chemists ffs
20:32:12 <hackrilege> the free monad blew their minds
20:32:15 <exio4> it'll probably be incomprhensible if you try to make sure the only remaining speed improvement is rewriting it into assembly
20:32:32 <hackrilege> i dont want to talk about boxed values
20:32:33 <monochrom> in fact many slow ways are unintuitive to me, as in "why would anyone sane do this slow way?!"
20:32:54 <exio4> because no compiler managed to see the perfect way to do register allocation for your algorithm, obviously!
20:33:27 <Cale> hackrilege: There's no need to expose users of your library to the internal representations you're using.
20:33:47 <hackrilege> all the discussion is around recursive types
20:33:59 <monochrom> if Project Euler on April 1st posed this problem: "count how many even primes there are in [100...1000000]", I fully expect a lot of people to use the slow, unintuitive way of "use trial division to generate primes in that range, then count".
20:34:00 <andromeda-galaxy> Cale: alternatively, a number of mindsets: if it is written the clear way and is slow, the correct answer is not to rewrite it; the correct answer is to improvre the compiler until it is fast anyway
20:34:06 <hackrilege> rather, im obliged to Not use crazy internal representations
20:34:20 <monochrom> it is unintuitive because the intuitive answer is "simply 0"
20:34:37 <exio4> there's just one even prime
20:34:37 <Cale> andromeda-galaxy: mmm... that's not always reasonable
20:35:20 <andromeda-galaxy> Cale: I know, but it's a fun mindset (and especially in a few academic circles, it can often turn out to be close...)
20:35:28 <hackrilege> so how would you guys do convolution?
20:35:35 <Cale> andromeda-galaxy: GHC does do a pretty good job of finding a lot of optimisations these days -- but it's not going to say "Oh, what you really want is this completely different data structure"
20:36:08 <hackrilege> do you support my fold using zipWith approach?
20:36:11 <monochrom> I would FFT, multiply, inverse FFT
20:36:18 <hackrilege> no
20:36:23 <hackrilege> not that kind of convolution
20:36:37 <hackrilege> http://research.microsoft.com/en-us/um/people/simonpj/papers/ndp/Stencil.pdf
20:36:54 <andromeda-galaxy> Cale: that's true enough
20:36:55 <mgsloan> monochrom's still right :-)
20:37:04 <hackrilege> > (\ l -> zipWith (+) l (tail l)) [1,2,3]
20:37:06 <lambdabot>  [3,5]
20:37:18 <monochrom> wait, still right? I haven't even read that stencil paper
20:37:19 <exio4> if you are doing an O(1) operation once and an O(n) operation multiple times, it won't try to guess if you maybe meant another data structure with different complexity for cons and indexing
20:37:24 <hackrilege> here i am convolving using a stencil of width 2
20:37:40 <mgsloan> monochrom: I haven't either, but I know that convolution in that context is indeed the same as signal convolution
20:37:44 <mgsloan> You just need to do 2D FFT
20:37:45 <andromeda-galaxy> Cale: I just think it's dangerous to potentially give the impression that it's always okay to say "well, this looks nice but might be slow, so I'll do this other thing instead".  a different datastructure is a good idea, a different but incomprehensible datastructure is a bad idea
20:37:50 <monochrom> neat
20:37:57 <Cale> andromeda-galaxy: for sure
20:38:08 <mgsloan> But that's only helpful for a large kernel, it's faster to not do the FFT if using a small kernel like in hackrilege's acse
20:38:26 <hackrilege> no fft stop
20:38:27 <Cale> andromeda-galaxy: But hackrilege is talking about doing image processing on gigapixel images using lists rather than arrays
20:38:56 <Cale> That's... just not going to turn out well, I'm afraid
20:39:00 <hackrilege> not my fault ur lists suck
20:39:07 <hackrilege> seriously
20:39:18 <mgsloan> hackrilege: http://stackoverflow.com/questions/21751908/2d-circular-convolution-vs-convolution-fft-matlab-octave-python
20:39:22 <andromeda-galaxy> Cale: yes, that's a good point, arrays are definitely better.  I just noticed hackrilege's comment about the intuitive way always being slow, and the fast way being incomprehensible, and wanted to help point out that we can often make more comprehensible fast ways
20:39:23 <hackrilege> anyway it will be fine trust me
20:39:28 <monochrom> http://www.vex.net/~trebla/humour/tautologies.html #3
20:39:39 <Cale> hackrilege: You can't blame your table saw for being a bad bandsaw.
20:39:49 <dougia> cale: hackrilege: I am trying to define a type i can then use to declare functions i.e.  f::fuzzyMap, f = ...
20:40:16 <Cale> dougia: Did you try adding {-# LANGUAGE RankNTypes #-} to the top of your file?
20:40:24 <hackrilege> yeah a synonym
20:40:51 <hackrilege> did you try using newtype or data instead?
20:41:27 <hackrilege> ok fine ill fft
20:42:15 <hackrilege> but no because iv been thining alot about this zipWith fold thing
20:43:29 <hackrilege> so now not only do i not get a nice intuitive datatype i also have to transform my temperature field into Frequency space (!?!?)
20:43:35 <exio4> hackrilege: linked lists have indirections nearly by definition, the normal "Data structures course in C" definition is going to be struct List { int head; List* tail; } ; too :) 
20:43:49 <andromeda-galaxy> Cale: can we convince lambdabot to remember that quote of yours a minute ago (table/band saw)? I really like it
20:44:33 <hackrilege> i can blame the dude who included it in my toolset...
20:44:46 <monochrom> @quote Cale You can't blame your table saw for being a bad bandsaw.
20:44:46 <lambdabot> No quotes match. My mind is going. I can feel it.
20:44:51 <monochrom> err
20:44:52 <hackrilege> supposed to be higher order...
20:44:56 <monochrom> @remember Cale You can't blame your table saw for being a bad bandsaw.
20:44:57 <lambdabot> Done.
20:44:58 <monochrom> there
20:45:18 <monochrom> use "@quote Cale bandsaw" to recall
20:45:19 <andromeda-galaxy> monochrom: thanks! I'm still mildly afraid of lambdabot
20:45:48 <exio4> @quote Cale bandsaw
20:45:48 <lambdabot> Cale says: You can't blame your table saw for being a bad bandsaw.
20:45:52 <exio4> nice =) 
20:46:12 <hackrilege> @remember hackrilege i dont want to talk about boxed values
20:46:13 <lambdabot> I will never forget.
20:46:57 <andromeda-galaxy> hackrilege: you can't blame the person who put it in the toolbox, because sometimes table saws are important or good.  it's just that they're not band saws
20:47:03 <hackrilege> does anyone want to talk about boxed values?
20:47:21 <andromeda-galaxy> (I would say yes, except that I don't know much about them)
20:47:36 <hackrilege> its like some obscure chinese saw
20:48:27 <hackrilege> its an ornament not a tool
20:48:58 <hackrilege> how can i talk about hylomorphisms and Arrays... its nasty
20:49:10 <hackrilege> are Arrays even recursivly defined?
20:49:17 <hackrilege> whats the Free definition of Array?
20:50:47 <nshepperd> why would you try to define an array recursively
20:51:01 <andromeda-galaxy> hackrilege: iirc Arrays are implemented with primitives defined by ghc. they are just contiguous regions of memory
20:51:19 <nshepperd> being flat structures is the whole the point of arrays
20:51:20 <andromeda-galaxy> hakcrilege: this gives them nice properties like good cache coherence, etc. and lots of operations (including indexing) can be heavily optimized
20:51:27 <andromeda-galaxy> if you were to try to define them recursively, this would not be possible
20:51:42 <donald_trump> hey
20:51:46 <andromeda-galaxy> indexing is an important thing with arrays because it's O(1): past optimization, it's just memory_at(base_address+index)
20:51:59 <andromeda-galaxy> hackrilege: if you were to define it recursively, you'd have lists
20:52:16 <hackrilege> what is Array#
20:52:17 <hackrilege> ?
20:52:18 <andromeda-galaxy> the problem with lists and similar recursively defined data structures is that they have to be traversed
20:52:23 <andromeda-galaxy> probably an unboxed array
20:52:34 <hackrilege> http://hackage.haskell.org/package/base-4.0.0.0/docs/src/GHC-Arr.html
20:52:50 <donald_trump> question about spock - how do i have a route run a function that returns an IO monad?
20:53:16 <andromeda-galaxy> hackrilege: you probably don't want to use GHC.* if you can avoid it
20:53:25 <hackrilege> !!!!!!!!1
20:53:33 <hackrilege> ill use hugs instead
20:54:03 <andromeda-galaxy> hackrilege: an Array# is the rather unsafe and totally unportable ghc primitive 
20:54:15 <andromeda-galaxy> hackrilege: modules like Data.Array provide safer and marginally more portable interfaces
20:54:24 <hackrilege> data Ix i => Array i e
20:54:25 <hackrilege>                  = Array !i         -- the lower bound, l
20:54:25 <hackrilege>                          !i         -- the upper bound, u
20:54:25 <hackrilege>                          !Int       -- a cache of (rangeSize (l,u))
20:54:25 <hackrilege>                                     -- used to make sure an index is
20:54:25 <hackrilege>                                     -- really in range
20:54:25 <hackrilege>                          (Array# e)
20:54:38 <exio4> it'd be nice if you didn't flood the channel
20:54:43 <boccato> Quick question, the best way to configure my stack to use a different LTS (for when I have no project) is by changing .stack/global/stack.yaml (Im on a mac, btw).
20:54:51 <andromeda-galaxy> hackrilege: @where lpaste
20:54:55 <andromeda-galaxy> @where lpaste
20:54:55 <lambdabot> http://lpaste.net/
20:55:13 <exio4> hackrilege: even so, the idea of repa, vector, etc, is to provide nicer abstractions over primitive interfaces
20:55:24 <andromeda-galaxy> exio4: hackrilege just quit
20:55:34 <mgsloan> boccato: Yup.  Note that there's nothing special about the global project.  It's just what's used if there isn't a stack.yaml
20:55:34 <donald_trump2> rats
20:55:45 <donald_trump2> disconnected
20:55:51 <donald_trump2> any spock users?
20:56:03 <exio4> andromeda-galaxy: I realized after I pressed enter :P 
20:56:20 <andromeda-galaxy> exio4: just wanted to make sure.
20:56:33 <andromeda-galaxy> exio4: in case you wanted to @tell, etc.
20:56:46 <boccato> mgsloan: Was just wondering if it was good practice to change it or if a stack upgrade could override it (it being some kind of template or default)
20:56:47 <exio4> ah, nah, it's not worth it, heh
20:57:03 <Lewis> yo
20:57:11 <donald_trump2> hi lewis
20:57:19 <Lewis> donald_trump2: use haskell? wow
20:57:44 <nshepperd> I see he's still under the misapprehension that indexing into an array is *slower* than following boxed pointers >_>
20:57:54 <Lewis> can you give me a well known website that use haskell from the website? or mobile app?
20:58:29 <donald_trump2> lewis what do you mean as the web server?
20:58:37 <Lewis> web site - sorry
20:58:46 <donald_trump2> facebook uses haskell for their spam detection
20:59:06 <Lewis> I'm really considering using haskell but I usually build web sites
20:59:11 <donald_trump2> mobile app - i don't think there are any major mobile apps that use haskell
20:59:20 <donald_trump2> lewis haskell is great for building websites
20:59:28 <Lewis> donald_trump2: can you point me to a few?
20:59:58 <donald_trump2> that use it? or frameworks to build websites with?
21:00:08 <donald_trump2> for frameworks, if you're a beginner, i might try something like scotty or spock
21:00:28 <Lewis> no , example of websites built with haskell frameworks
21:00:58 <donald_trump2> for major websites like facebook, haskell is part of the backend infrastructure
21:01:38 <donald_trump2> for just straight examples of haskell websites there's https://www.haskell.org/
21:01:53 <andromeda-galaxy> @tell hackrilege Indexing into an array is much faster than following boxed pointers because it only involves one fetching one thing from memory, while the alternative involves fetching 'n' things and doing a fair bit of computation on each one to figure out what to fetch next
21:01:53 <lambdabot> Consider it noted.
21:02:20 <donald_trump2> i don't know if you're looking for some website to blow you away, but the advantage is really the speed and reliability of development
21:02:35 <donald_trump2> given enough time and people, you can make a website look like anything with anything.
21:04:40 <lpaste> dougia pasted ‚ÄúWhat is wrong with Instance Functor line?‚Äù at http://lpaste.net/157617
21:05:08 <nshepperd> frequently, indexing into an array involves fetching 0 things from (main) memory, because they're already in cache
21:06:32 <andromeda-galaxy> nshepperd: hackrilege seemed sufficiently confused that I thought I should stick with the conceptually simple if very slightly inaccurate model. that is a good point, however
21:07:13 <dougia> i am missing something very simple i think http://lpaste.net/157617
21:07:48 <andromeda-galaxy> @tell hackrilege Also,a structure defined by a string of pointers that consists of relatively random free blocks all over the place in memory has much worse caching properties: arrays will often fit into the cpu cache, so list indices can often even involve zero memory accesses, versus still quite a few for lists
21:07:48 <lambdabot> Consider it noted.
21:08:22 <andromeda-galaxy> duogia: you can't make a class an instance of another class!
21:08:29 <nshepperd> *array indices
21:09:06 <andromeda-galaxy> as nshepperd: oops, that's right
21:09:19 <andromeda-galaxy> @tell hackrilege (sorry, array indices can often even involve zero memory accesses)
21:09:19 <lambdabot> Consider it noted.
21:09:54 <andromeda-galaxy> duogia: as it is, the FuzzyValue 'type' is actually something that takes in another type and produces a constraint (the sort of thing that you can stick before an '=>')
21:10:48 <andromeda-galaxy> dougia: Functor expects its argument to be something that when given a type produces another type, so that, for example, you can have values that inhabit it (so that it makes sense to talk about a value of type 'f a' at all)
21:11:07 <andromeda-galaxy> dougia: a class doesn't do that, it just produces a constraint, thus the problems.
21:11:35 <andromeda-galaxy> dougia: in general, there's no good way to say "everything that is an instance of this class is an instance of that class", which is one of the more annoying things that I've run into abou tthe whole class system
21:12:20 <andromeda-galaxy> dougia: if you use, for example, 'instance FuzzyValue f => Functor f', a rather annoying bit of ghc's class resolution algorithm shows up: it only checks the instance heads, when resolving constraints. it then uses constraints on the instances later
21:12:49 <andromeda-galaxy> that instance therefore means that ghc should use that for any type at all (since the type variable 'f' can be unified with any type at all)
21:13:54 <andromeda-galaxy> dougia: ghc then promptly tries to solve the FuzzyValue f constraint, and, for most values fails, or alternatively notices that there are two possible instances (for 'Maybe', for example) and promptly complains
21:15:12 <nshepperd> the usual way to say "everything that's an instance of X is an instance of Y" is to create some newtype wrapper and declare the instance for that
21:16:31 <andromeda-galaxy> nshepperd: that technique is useful, but there are a number of cases where it can fall through, usually related to making eDSLs with fancy type systems and wanting to spare the user any extra function applications while preserving (for the most part) type inference
21:16:45 <dougia> ok, what I am really trying to do is have two types that wrap Double, that have different behaviors for intersection and union but same function name.  Both of them may take a function Double->Double and modify it to Double->Wrapped Type.  am I expressing this reasonably well, and Functors just a red herring here?
21:16:48 <andromeda-galaxy> (which also happens to be where I've been spending most of my time lately, so my view might be a bit biased)
21:16:57 <nshepperd> instance FuzzyValue f => Functor (FuzzyFunctor f)
21:18:34 <andromeda-galaxy> (I will now leave this discussion in nshepperd's probably-more-capable hands. this seems to happen to me every time I answer a question in here...)
21:18:38 <nshepperd> dougia: Functor is probably a red herring here
21:19:09 <nshepperd> dougia: you want to convert a (Double -> Double) into (Wrapped -> Wrapped)?
21:20:10 <nshepperd> that's a bit more specific than Functor, because Functor has to work on any (a -> b) not just with Doubles
21:20:53 <nshepperd> I would just add a function to your FuzzyValue class like 'under :: (Double -> Double) -> (a -> a)'
21:22:20 <dougia> nshepperd:thanks.
21:24:00 <codebje> @pl \c -> isDigit c && isSpace c
21:24:01 <lambdabot> liftM2 (&&) isDigit isSpace
21:24:27 <codebje> well of course.
21:28:09 <montanonic> Sorry if this is a repost but I lost my connection earlier and am not sure if anyone saw:
21:28:11 <montanonic> would someone familiar with Persistent like to take a look at the following two functions and explain to me why the second one throws an exception every time it is called, no matter what? It really threw me for a spin, as that was my original implementation, and I had no idea why my queries were failing.
21:28:15 <montanonic> http://lpaste.net/5193097553763106816
21:28:18 <montanonic> > fromMaybe undefined (Just 3)
21:28:23 <lambdabot>  mueval-core: Time limit exceeded
21:28:31 <montanonic> weird... that works in ghci
21:30:24 <montanonic> So in my ghci, fromMaybe undefined (Just 3) works fine, but liftM2 fromMaybe undefined (Just (pure 3)) throws an error
21:30:30 <orzo__> There seems to be a lot of options for libraries enabling parallel execution of IO actions.  My use case is that I've a bunch of URL's to fetch.  I'm interested in default-opinions.  Anybody?
21:30:40 <Hafydd> The timeout is probably a transitive condition in lambdabot.
21:30:48 <Hafydd> > fromMaybe undefined (Just 3)
21:30:50 <lambdabot>  3
21:30:54 <montanonic> That would seem to be the issue with the second function defined in that lpaste, and explain why it always errored out, but I don't understand why lifting fromMaybe leads it to short-circuit
21:31:04 <montanonic> I assume this has to do with Laziness and Bottom
21:31:13 <montanonic> Hafydd: ah, thank you
21:31:24 <montanonic> @ty undefined
21:31:26 <lambdabot> t
21:31:41 <montanonic> > liftM2 fromMaybe undefined (Just . pure $ 3)
21:31:43 <lambdabot>  *Exception: Prelude.undefined
21:31:48 <montanonic> > liftM2 fromMaybe (pure undefined) (Just . pure $ 3)
21:31:50 <lambdabot>  Just 3
21:31:52 <montanonic> hmmm
21:32:27 <Hafydd> > liftM (fromMaybe undefined) (Just . pure $ 3)
21:32:29 <lambdabot>  Just 3
21:34:39 <Hafydd> (When you liftM2 fromMaybe, it evaluates the first argument, by necessity, in order to decide whether to continue the computation.)
21:35:20 <montanonic> Hafydd: right. damn. This is the first time my playing with bottom values has screwed me over
21:36:21 <Hafydd> For the record, something with equivalent behaviour to fromMaybe undefined is fromJust.
21:37:52 <montanonic> Hafydd: I'm specifically using throwM from Classy-Prelude, to interop with Monad.Base.Control.Exceptions
21:38:38 * hackagebot texmath 0.8.6.1 - Conversion between formats used to represent mathematics.  https://hackage.haskell.org/package/texmath-0.8.6.1 (JohnMacFarlane)
21:38:39 <montanonic> sorry, I mean LiftedBase exceptions
21:39:00 <montanonic> http://hackage.haskell.org/package/lifted-base-0.2.3.6/docs/Control-Exception-Lifted.html
21:44:03 <Hafydd> montanonic: in your second implementation, you'd rather use: fromMaybe (throwM NeverFriends) =<< selectFirst.
21:44:55 <Hafydd> Er, or rather... maybe (throwM NeverFriends) return =<< selectFirst.
21:45:33 <Hafydd> With the appropriate arguments to selectFirst included.
21:45:53 <montanonic> Hafydd: yeah, there we go, that one works. Thank you
21:46:27 <montanonic> Hafydd: I think I started off with that (using do notation though), and I just hated the "return" argument in maybe, and so ended up with the liftM2 version
21:46:43 <Hafydd> The inclusion of "return" is not very pleasant, I agree.
21:47:04 <Hafydd> It feels like it should collapse into something smaller.
21:47:04 <montanonic> But I've learned my lesson: don't use multi-argument lifts when one of the args short-circuits computation
21:47:11 <montanonic> indeed
21:48:00 <Hafydd> A shorter version might be achieved with... try.
21:48:01 <montanonic> Maybe I shouldn't be using throwM's everywhere, either. But for me it's just very helpful to create a datatype specific to the types of errors that can occur
21:48:44 <andromeda-galaxy> by the way, does anyone know of a decent implementation of Van Laarhoven lenses (ideally with something like the ecosystem of Control.Lens, although that's a rather tall order) but at the type level?
21:51:05 <montanonic> Hafydd: try just turns it into the same thing, except with the either function instead of maybe, as far as I can tell
21:52:34 <orzo__> does the http package not provide a way to indicate a maximum wait time for a response?
21:53:08 <montanonic> Hafydd: I think the best solution here is to just create another function. Agda has the right implementation for this: http://haddock.stackage.org/lts-5.10/Agda-2.4.2.5/src/Agda-Utils-Maybe.html#fromMaybeM
21:53:48 <montanonic> Hafydd: I'm shocked that this isn't a part of other Haskell packages. 
21:56:24 <Hafydd> Right...
21:56:40 <andromeda-galaxy> also: can anyone properly explain the difference between HSpec and HUnit?
22:00:31 <nineonine> well , HSpec is inspired bu Rspec 
22:00:40 <nineonine> and HUnit is inspired by JUnit
22:00:45 <nineonine> :)
22:01:37 * dmj wonders if DuplicateRecordFields should be on by default
22:01:46 <dmj> for 8.0
22:13:38 <kadoban> dmj: Seems like quite a jump from nonexistence of a feature to on by default.
22:13:52 <ReinH> You can easily turn it on by default in your own projects.
22:24:26 <montanonic> If I wanted to pull request in some lifted Maybe functions, which library/libraries should I open a request with?
22:24:57 <montanonic> Data.Maybe in base Prelude would seem to be the obvious spot, but I'm not sure that module welcomes monadic code
22:26:00 <montanonic> This is the type of stuff I'd like to see included in Prelude: http://haddock.stackage.org/lts-5.10/Agda-2.4.2.5/Agda-Utils-Maybe.html
22:26:30 <montanonic> Specifically: 'maybeM', and 'fromMaybeM'
22:27:31 <montanonic> Those functions are both implemented in Agda and Purescript, amusingly enough. But clearly an entire language isn't worth importing just to get a few utility functions.. :)
22:40:21 <nineonine> can anyone recommend some good tutorials / code examples of FreeT usage ? The only thing I can find is Gabriels blog post. 
22:43:51 <Zemyla> :t ((=<<) .) . maybe -- montanonic 
22:43:52 <lambdabot> Monad m => m b -> (a -> m b) -> m (Maybe a) -> m b
22:50:17 <montanonic> Zemyla: I appreciate that, but that's quite inscrutable compared to a named function like fromMaybeM, which is obviously just fromMaybe lifted to monadic values
22:51:28 <montanonic> Zemyla: liftM2 fromMaybe was my go-to instinct, but it forces evaluation of the default value argument, which is absolutely not desired when your default throws an error/exception 
22:54:54 <Zemyla> montanonic: Not really. It's got a (=<<), so it has something to do with monads, and it's got a "maybe", so it has something to do with Maybe.
22:58:15 <MarcelineVQ> montanonic: did you look at the source for those?
22:58:24 <montanonic> MarcelineVQ: I did
22:58:38 <montanonic> copied the source over as a local import
23:03:59 <nomotif> Dumb question: what's the next step after going through the basics of Haskell and getting through the 99 problems?  Find an open source project and start hacking?
23:04:27 <jle`> montanonic: i feel like functions like those exist at the barier of the fairnbairn threshold
23:04:43 <Ashy> nomotif: play with servant or anything else that seems fun
23:04:54 <Ashy> nomotif: been through ocharles 24 days of hackage series?
23:04:57 <jle`> montanonic: it's in general faster to just write out the whole inlined version than to take the time to remember what it's called, look it up, etc.
23:05:08 <nomotif> Ashy: Oooh no, haven't heard of it.
23:05:20 <Ashy> nomotif: https://ocharles.org.uk/blog/
23:05:25 <jle`> and it's easier for someone reading the code to understand `maybe n j =<< mm` than looking upp maybeM
23:05:41 <jle`> if i saw maybeM in code, i'd have to go look it up, add it to my list of things to remember, things to juggle, etc.
23:05:48 <jle`> but maybe n j =<< mm, i can understand and see immediately
23:06:06 <jle`> or even do { x <- mm; maybe n j x }
23:06:08 <nomotif> Ashy:  Awesome, thanks!
23:06:15 <montanonic> jle`: I feel like the M-affixed functions are pretty easy to understand though
23:06:25 <jle`> it's not obvious to me at first what maybeM/mapMaybeM would do
23:06:37 <Ashy> nomotif: thank ocharles_ not me
23:06:41 <jle`> even from looking at the type signature immediately
23:07:02 <jle`> but i guess this is a single data point :3
23:07:08 <montanonic> jle`: true, but it wasn't obvious to me that, liftM2 fromMaybe, would always force evaluation on the default value param
23:07:29 <Ashy> nomotif: also if you havent started using stack yet you should, and you should set up ghc-mod with your editor (or something similar)
23:07:42 <jle`> that kind of comes from people's expectations of applicative combinators though
23:07:45 <jle`> (+) <$> x <*> y
23:07:46 <montanonic> jle`: maybe at that level it's commonly understood that using liftM's does that, but I didn't realize that, so my (throwM SomeExceptionDataType) would get thrown everytime, no matter what the maybe value was
23:07:50 <Hafydd> montanonic: you keep saying "force evaluation" as if it has something to do with non-strict evaluation. It doesn't. It's to do with monadic effects and the order in which liftM2 performs them.
23:07:56 <jle`> of course it's going to execute x, then y, and then map (+) over the results
23:08:19 <jle`> fromMaybe <$> x <*> y is going to execute x, then y, and then map fromMaybe over the results
23:08:35 <Hafydd> @source liftM2
23:08:35 <lambdabot> Unknown command, try @list
23:08:36 <nomotif> Ashy: I've got it set up, but I'm not sure I did it right, so I was going to double check.
23:08:40 <Hafydd> @src liftM2
23:08:40 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
23:08:51 <jle`> or, it might not even execute them in "that order", it's up for <*> to define it, heh
23:08:54 <Hafydd> montanonic: perhaps if you look at that, you will understand why, if you did not already.
23:08:55 <montanonic> jle`: okay; I just think I was behind on learning that. I guess it wouldn't be an issue in general.
23:09:57 <jle`> liftA2 etc. are about "sequencing" actions :)
23:10:09 <montanonic> Hafydd: I remember the implementation, so I guess then that when it hits, throwM Exception >>= ..., it operates under the semantics of MonadThrow? 
23:10:23 <nomotif> Ashy: I'm a vimmer, but it seems E(vil)macs tooling is better, so I'll keep toying with the integration some more.
23:10:40 <montanonic> which I think is a CPS based transformer
23:11:04 <Ashy> nomotif: i'm a vimmer aswell, syntastic works quite well and ghcmod is nice with some leader mappings
23:11:44 <montanonic> which would make sense, since throwM is just as many lifts as it takes to get to the Exception handling monad in the stack, and since it throw an exception, the "action" performed will be to return the exception value
23:11:50 <montanonic> that actually makes a lot of sense if that is the case
23:11:53 <Ashy> nomotif: there's also hlint, hasktags and codex you can setup
23:11:59 <nomotif> Ashy: Maybe I botched those too, I won't write Vim off so quickly then.
23:12:16 <jle`> montanonic: think of what `throwM exception >> foo` would do
23:12:23 <Ashy> nomotif: hlint gives you suggestions (through syntastic), and hasktags and codex give you tags for your code and for the libraries you're using too
23:12:29 <Hafydd> montanonic: that depends whether your MonadThrow instance obeys the relevant laws, of course.
23:12:32 <Hafydd> But one would hope so.
23:12:37 <montanonic> jle`: right, yeah, I can see that now
23:12:48 <jle`> if `do throwAnError; foo` was able to reach foo, it might not be a very useful MonadThrow instance
23:12:55 <nomotif> Ashy: Definitely useful.
23:13:01 <montanonic> Hafydd: I'm doing all of this in Yesod, so my assumption is that the included Monads and Library monads are solid
23:13:46 <montanonic> jle`: I agree. That helps. I lapsed in what "lifting" actually does. This is helpful.
23:13:52 <jle`> for something like fromMaybeM there; i'd do { x <- mm; fromMaybe y x } ... instantly readable to anyone, really
23:14:01 <jle`> and easily writable
23:14:40 <nomotif> Ashy:  Thanks for the push in the right direction.
23:16:03 <Ashy> nomotif: no worries
23:27:28 <FAuUiDkld> http://pastebin.com/pUwUbQzZ
23:28:02 --- mode: ChanServ set +o mauke
23:28:02 --- kick: FAuUiDkld was kicked by mauke (spam)
23:30:02 --- mode: mauke set -o mauke
23:31:06 <jle`> montanonic: it's also easy to forget that intuitions/principles of "laziness" don't translate directly to values inside monadic/applicative contexts.  the functor itself gets to decide how evaluation works w.r.t. its "values"
23:34:34 <OhTrueful> @pl \i -> if (i == 'a') then "aa" else (repeat i)
23:34:34 <lambdabot> ap (flip if' "aa" . ('a' ==)) repeat
23:59:19 <zRecursive> Several days passed, but ghc.exe still cannot find the already installed packages, i.e. ghc.exe: unable to load package `time-1.5.0.1'
