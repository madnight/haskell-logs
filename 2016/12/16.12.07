00:53:07 <moet> what's the right way to add documentation to a reexported definition?
00:53:37 <moet> if you add it under the reexported name in the export list, haddock still lists that name as not covered
00:57:45 <lyxia> you can't
00:57:50 <lyxia> unfortunately
01:00:31 <moet> sounds good! thanks. :)
01:08:09 <cocreature> lyxia: are you sure about that? https://hackage.haskell.org/package/megaparsec-5.1.2/docs/Text-Megaparsec.html#v:many seems pretty close
01:09:00 <lyxia> it's a reexported identifier and the docs come from where it was defined
01:09:06 <lyxia> not where it is being reexported
01:09:21 <tdammers> you can import it qualified, define an unqualified alias and document that
01:09:30 <lyxia> oh is that doc added
01:09:34 <cocreature> lyxia: the docs come from megaparsec but the function is defined in Control.Applicative?
01:09:51 <cocreature> maybe I‚Äôm missunderstanding what the problem is
01:10:02 <tdammers> I think if you document in the module header, it should override the existing documentation
01:10:14 <tdammers> failing that, make an alias
01:10:15 <lyxia> Oh I see how they did that.
01:10:40 <lyxia> That's neat.
01:11:08 <lyxia> A bit hackish.
01:11:28 <cocreature> sure, but it works :)
01:12:56 <lyxia> Okay I know what to tell future askers.
01:13:02 <MarcelineVQ> tangentially ReadP is pretty neat
01:26:10 <tabaqui1> what means Data Foo where?
01:26:20 <tabaqui1> union or intersection?
01:26:41 <tabaqui1> I've never seen this syntax in books
01:28:01 <cocreature> tabaqui1: "Data Foo where" is not valid syntax, do you have an example of code you‚Äôre looking at?
01:28:57 <tabaqui1> data SF' a b where
01:29:03 <tabaqui1> SF' :: !(DTime -> a -> Transition a b) -> SF' a b
01:29:10 <tabaqui1> SFArr   :: !(DTime -> a -> Transition a b) -> !(FunDesc a b) -> SF' a b
01:29:13 <cocreature> that‚Äôs GADT syntax
01:29:13 <tabaqui1> for example
01:29:23 <tabaqui1> GADT?
01:29:31 <cocreature> generalized algebraic data type
01:29:45 <cocreature> tabaqui1: it‚Äôs the same as writing | between the individual constructors
01:30:04 <tabaqui1> cocreature: ah, union then
01:30:07 <tabaqui1> ok, thanks
01:30:11 <cocreature> so data SF' a b = SF' !(DTime-> ‚Ä¶) | SFArr ‚Ä¶
01:30:35 <cocreature> tabaqui1: what GADTs allow you is to specialize the type variables but this is not used here
01:30:45 <cocreature> so in this case it‚Äôs purely a different syntax
01:31:16 <tabaqui1> specialize - you mean "SF' :: Ord a => ..."?
01:31:52 <cocreature> tabaqui1: tabaqui1 so normally when you have "data X a = ‚Ä¶" all constructors need to create something of type "X a"
01:32:07 <cocreature> what GADTs allow you is to make constructors that return something of type "X Int"
01:32:13 <cocreature> or "X Bool", ‚Ä¶
01:32:33 <tabaqui1> cocreature: ah, nice feature, I'll try it
01:33:01 <cocreature> tabaqui1: the classic example is something like https://en.wikibooks.org/wiki/Haskell/GADT#GADTs
01:33:23 <tabaqui1> ok, thank you
02:17:04 <kqr> [Yesod] does anyone know whether there is a way to type-systematically ensure that some handlers can only be accessed by authenticated users? and would it in those handlers be possible to call some sort of "maybeAuthId" except without the maybe?
02:17:25 <kqr> feels a bit un-haskell-like to check for authentication first when the handler is dispatched, and then again when I want to access the user ID in the handler
02:17:40 <mettekou> How do I deal with discerning keywords from variables when using Megaparsec, other than manually banning keywords from the parser for names?
02:18:41 <mniip> parse them before variables?
02:19:55 <mniip> usually this is split into a separate tokenizer stage, but the two can be integrated if needed
02:21:19 <merijn> mettekou: Never have a case where a keyword of a variable could appear in the same position?
02:21:41 <merijn> Although, of course, that fails in a language like Haskell, where function application is just a space
02:22:21 <mettekou> merijn: Or in mine, which has exactly the same terms as Coq (though not declarations).
02:22:50 <lyxia> startswithkeyword <|> variable
02:23:41 <merijn> But explicitly banning keywords is the main sane way to go
02:23:49 <merijn> Makes debugging and error reporting much easier
02:25:35 <mettekou> mniip lyxia: That seems like a reasonable approach.
02:26:01 <mettekou> mniip lyxia merijn: Thanks for the tips!
02:28:40 <mettekou> mniip lyxia: One concern though: If I add a startsWithKeyword parser before variable, it consumes the keyword, but my other parsers require it.
02:28:57 <merijn> mettekou: Also, I haven't looked at megaparsec, but parsec had builtin stuff to avoid this
02:29:24 <mniip> no, I meant, like, don't let your variable parser fire before all keyword parsers do
02:29:58 <mniip> e.g, 'ifStatement <|> assignment' instead of 'assignment <|> ifStatement'
02:30:35 <merijn> Parsec had makeTokenParser
02:30:56 <merijn> But megaparsec seems to have removed that
02:32:37 <mniip> well, in tokenizer you would likewise have something like '(string "if" *> IfToken) <|> (VarToken <*> varName)'
02:32:43 <kqr> actually never mind my question. requireAuth was what I wanted
02:33:50 <merijn> mniip: TokenParser didn't necessarily tokenize
02:34:27 <merijn> mniip: But it'd give you combinators for "variable" which would automatically disallow keywords
03:16:28 <arianvp> how do I make sure that all my child threads can know that Ctrl+C was pressed?
03:16:37 <arianvp> I want to gracefully shut down all my threads when I close my application
03:16:48 <arianvp> I tried forkFinally, but it seems to miss some of the CTRL+cs?
03:16:51 <arianvp> for some weird reason?
03:18:45 <yulax> arianvp: time to learn gdb :p
03:19:25 <Reisen> Is there some generalised concept of inserting into a container? Like, insert :: (Traversable t) => t a -> a -> t a?
03:23:56 <verement> arianvp: you should signal your child threads from the main thread when it receives the ^C interrupt signal, then wait for them all to terminate before exiting
03:24:32 <orion> What is the difference between "ccall" and "capi" in GHC 8?
03:25:50 <arianvp> verement: so the exception does not automatically propagate?
03:27:07 <verement> arianvp: no, if the main thread terminates for any reason then the child threads are aborted
03:27:22 <arianvp> ah I see
03:27:27 <arianvp> so I cannot capture that abort? 
03:27:44 <verement> not without a main thread to manage it
03:27:49 <arianvp> great thanks
03:29:26 <arianvp> and UserInterrupt async exception is always sent to main thread?
03:29:33 <verement> yes
03:29:34 <arianvp> it's not possible that the child thread accidentally catches it?
03:29:48 <verement> I don't think so
03:41:55 <merijn> You can change what ctrl+c does
03:42:22 <merijn> orion: capi produces a wrapper C function that is compiled by the C compiler and called by GHC, ccall calls the C function directly
03:42:42 <merijn> orion: This means that capi can access, for instance, CPP macro's and constants
03:43:12 <merijn> verement: Why signal the child from the main thread, you can just change Ctrl+c to signal the child directly
03:44:31 <verement> that starts to get less portable, doesn't it?
03:45:23 <arianvp> how would I do that?
03:45:41 <verement> and if there are multiple threads you'll still need to propagate the signal anyway
03:45:49 <arianvp> I have many threads,
03:45:57 <arianvp> but the problem is, I dont store their PIDs
03:46:08 <arianvp> but if I do I could do this right:
03:46:15 <verement> arianvp: you can install a signal handler to change the behavior of ^C
03:46:38 <arianvp>  `catch` \e ->   forM threadIds \pid -> throwTo pid e
03:47:02 <merijn> verement: signals like ctrl-c aren't really portable anyway
03:47:25 <arianvp> `catch` 
03:47:30 <arianvp> \e :: UserInterrupt that is
03:47:50 <verement> merijn: no, but presumably the UserInterrupt async exception is
03:48:14 <arianvp> Okay so I think this is the way to go
03:48:19 <arianvp> keep a set of pids of child threads
03:48:26 <arianvp> and on receiving UserInterrupt in the main thread
03:48:34 <arianvp> rethrow that exception in each of the threads
03:48:42 <arianvp> then the threads can do their own cleanup and whatnot
03:48:50 <arianvp> by handling UserInterrupt
03:48:51 <arianvp> ?
03:49:06 <arianvp> using throwTo :: Exception e => PID -> e -> IO ()
03:50:34 <verement> arianvp: I think that could work
03:51:05 <verement> I think you mean thread id rather than pid
03:52:02 <arianvp> yes
03:52:37 <verement> you'll still need to wait for the child threads to terminate before you exit the main thread‚Ä¶ the async library could be helpful
04:29:59 <kuribas> why does compiling dash-haskell give me: rejecting: base-4.9.0.0/installed-4.9... (conflict: dash-haskell => base>=4.7 && <=4.9)
04:30:09 <kuribas> isn't 4.9.0.0 <= 4.9?
04:33:54 <hpc> what do you get when you run ghc-pkg list | grep base?
04:34:18 <kuribas> base-4.9.0.0 base-compat-0.9.1 base-orphans-0.5.4 base16-bytestring-0.1.1.6 base64-bytestring-1.0.0.1 lifted-base-0.2.3.8 regex-base-0.93.2 transformers-base-0.4.4
04:34:18 <kuribas>  
04:34:57 <cocreature> kuribas: is that the only output you‚Äôre seeing?
04:35:10 <kuribas> yes
04:35:19 <cocreature> how are you trying to install dash-haskell?
04:35:27 <kuribas> cabal install dash-haskell
04:35:40 <cocreature> hm weird
04:35:42 <kuribas> now I am trying from git
04:38:19 <hpc> try it with verbose too
04:40:23 <hpc> the constraint for dash-haskell probably should be >=4.7 && <5 or something
04:40:41 <hpc> (which is what containers does)
04:41:11 <augur> dcoutts: hey
04:47:35 <kuribas> I removed the constraints: "Not in scope: type constructor or class ‚ÄòGhc.PackageKey‚Äô"
04:52:46 <kuribas> Strange, pkg::PackageKey doesn't seem to be used: https://github.com/jfeltz/dash-haskell/blob/master/src/Haddock/Artifact.hs
05:04:28 <kuribas> hm, it seems dash-haskell doesn't work with ghc-8.0
05:06:53 <mettekou> Still struggling with parsing an application as a whitespace operator (as in Haskell, ML dialects, Coq...): http://lpaste.net/6039715386822230016. Does anyone see a solution?
05:08:29 <merijn> mettekou: Unrelated, but fix is a bad name for a combinator as it's already a common function
05:09:12 <mettekou> merijn: I want to stay true to Coq's syntax for anonymous fixed-point combinators for now.
05:09:59 <byorgey> mettekou: I think the problem is that term is trying to consume too much.  Typically the way this is handled is to have a parser atomicTerm which only parses terms consisting of a single token, OR terms in parentheses --- the point being that you can tell what it is just by looking at the first token
05:10:24 <byorgey> mettekou: then the 'expression' parser parses an expression of *atomic* terms
05:10:26 <merijn> mettekou: As for how to implement it: https://github.com/merijn/lambda-except/blob/master/Parser.hs#L87-L106
05:10:35 <byorgey> and then the term parser parses expressions and other more complex terms
05:11:19 <byorgey> mettekou: you probably also want to look into how parsec, megaparsec, etc. are set up to do lexing, so you don't have to keep explicitly consuming spaces everywhere
05:19:03 <dcoutts_> augur: hello
05:23:58 <byorgey> mettekou: by looking at merijn's parser I remembered that chainl1 is also a good way to parse applications, if you don't have any other sort of infix operators to parse
05:34:14 <kuribas> Does anyone know of an alternative to lookup documentation in the browser from emacs?
06:07:43 <mettekou> merijn: Thanks for the pointers! I still have one question: what, if anything, does the following expression parse to in the language in your lambda-except repository: \x : T -> x y?
06:08:26 <merijn> mettekou: you mean how is it bracketed?
06:09:03 <mettekou> merijn: Yeah, I suppose the brackets are around the entire thing (or absent, that's really the same I guess)?
06:09:43 <mettekou> merijn: The x y part being an application of x to y, I mean. Instead of the entire lambda being applied to y.
06:10:57 <merijn> mettekou: That parses as (\x : T -> (x y))" unless I fucked up :p
06:12:06 <mettekou> merijn: Exactly as it does in Haskell, great, thanks! üòú Gonna check what happens to that in Coq, to be sure I don't mess it up myself.
06:18:29 * ski . o O ( `\(x : (T -> (x y)))' )
06:23:57 <lonokhov> Is there a package with shared/exclusive locks?
06:25:20 <ongy> on what? memory, files, something else?
06:25:59 <lonokhov> on like anything. `withShared lock $ do` `withExclusive lock $ do`
06:27:21 <lonokhov> I believe it's sometimes called read/write lock
06:28:02 <merijn> lonokhov: You're looking for Semaphore
06:28:25 <lonokhov> and I thought about https://hackage.haskell.org/package/concurrent-extra-0.7.0.10/docs/Control-Concurrent-ReadWriteLock.html
06:28:43 <merijn> Control.Concurrent.QSem
06:29:19 <merijn> And/or an MVar or "TVar Bool"?
06:29:28 <lonokhov> merijn: That's only one part of lock
06:29:35 <merijn> lonokhov: How so?
06:30:08 <merijn> oh, yeah, QSem is
06:30:15 <merijn> But TVar should be pretty easy
06:30:16 <lonokhov> I need lock to protect tests which can run in parallel and tests which want exclusive access to RealWorld
06:30:41 <lonokhov> So parallel ones would grab shared lock and sequentials will grab exclusive
06:30:57 <ongy> if I got STM correctly, you can't use it to protect IO though (even if there's liftIO in STM)
06:31:15 <merijn> ongy: You're assuming the entire computation is in STM
06:31:17 <merijn> ongy: It's not
06:31:56 <lyxia> STM is not MonadIO
06:32:14 <merijn> grabLock :: TVar Foo -> IO (); grabLock l = atomically . *do stuff with lock*
06:32:21 <lonokhov> lyxia: doesn't matter. if you do `atomically $ readTVar a` it will be in empty state
06:32:45 <merijn> ongy: Your STM (and thus the atomically) will block until the transaction completes
06:33:02 <ongy> hm, right. I was under the impresison that I did some IO with STM before... probably did something stupid
06:33:07 <merijn> And then you "releaseLock :: TVar Foo -> IO ()" directly
06:41:43 <mniip> How taboo would it be to use unsafePerformIO catch to test whether a function is lazy in some arguments
06:42:38 <mniip> I don't think I'm breaking RT here so inlines aren't much of a problem?
06:43:43 <merijn> mniip: How would unsafePerformIO test that?
06:43:50 <mniip> 'unsafePerformIO catch'
06:44:13 <merijn> I don't understand what that's supposed to mean?
06:44:29 <ongy> :t catch
06:44:31 <lambdabot> Exception e => IO a -> (e -> IO a) -> IO a
06:44:42 <ongy> this catch?
06:44:51 <mniip> yes
06:45:17 <mniip> unsafePerformIO $ catch (f (x:throw Evaluated)) (\Evaluated -> return True)
06:45:26 <mniip> hm no
06:45:31 <mniip> unsafePerformIO $ catch (evaluate $ f (x:throw Evaluated)) (\Evaluated -> return True)
06:50:16 <lyxia> You probably need to return something after evaluating, but it looks okay otherwise
06:50:45 <mniip> well, f :: ... -> Bool
06:55:18 <RasmusWL_> Is there any convension for naming values of type @Maybe a@? -- lets say I would call the value x if it is actually present, is there a good way to indicate that it might not be there?
06:56:01 <mniip> the letter m?
06:56:09 <RasmusWL_> so mx?
06:56:26 <mniip> I would use that
06:59:21 * ski often does that
07:00:58 <mniip> hmm, I wonder if I'm reinventing the wheel here by using (Set t, Maybe (t -> Bool)) as a predicate instead of (t -> Bool)
07:01:20 <mniip> since like, optimizations
07:01:55 <mniip> no wait, that's the wrong word
07:01:59 <mniip> algorithmic complexity
07:11:43 <fabian__> Hi, I am new to haskell so this may sound stupid. I have to write a function, wich takes an function as an argument and applys it to every n-th element of a given list (the other elements stay untouched). Now I am wondering if there is an better/faster/whatever way to do this. My solution: http://lpaste.net/2485805226997579776
07:13:48 <pavonia> Has anyone here solved the today's AoC part 2 puzzle and is willing to share their input and answer?
07:18:17 <glguy> pavonia: my aoc solutions are all on github
07:18:52 <hexagoxel> fabian__: heh, you cycle a one-element list and then concat for performance? if that was indeed faster, wouldn't cycle be implemented that way already?
07:19:27 <glguy> https://github.com/glguy/advent2016
07:19:53 <pavonia> glguy: Are the answeres listed somewhere too?
07:21:03 <ski> fabian__ : shouldn't it apply `f' to the element at index `0' (since `n' divides `0') ?
07:21:38 <glguy> pavonia: no, but you can run it
07:28:29 <pavonia> glguy: Okay, thanks. Seems I missed the "anywhere *in the hypernet* sequences" part :/
07:32:54 <kuribas> :t \n f -> over (ifiltered (\i -> const (i `rem` n == (n-1)))) f
07:32:56 <lambdabot> error:
07:32:56 <lambdabot>     ‚Ä¢ Couldn't match type ‚ÄòIndexed a b (Identity b)‚Äô
07:32:58 <lambdabot>                      with ‚Äòs -> Identity t‚Äô
07:34:17 <kuribas> :t \n f -> iover (ifiltered (\i -> const (i `rem` n == n-1))) f
07:34:19 <lambdabot> error:
07:34:19 <lambdabot>     ‚Ä¢ Couldn't match type ‚ÄòIndexed i b (Identity b)‚Äô
07:34:19 <lambdabot>                      with ‚Äòs -> Identity t‚Äô
07:37:12 <yulax> lol
07:37:22 <yulax> lambdabot went to pot there
07:49:41 <tsahyt> Hello! I want to use a custom monad for a high level binding to a C library which will hold a handle in a ReaderT internally so the user doesn't have to supply it everywhere. What's the least-effort way to work with a ReaderT inside a newtype here without making a MonadReader instance, or at least without making it available to the user. As far as I understand once the instance is there, the user can access
07:49:44 <tsahyt> it.
07:50:57 <Cale> tsahyt: You just don't export the data constructor for your newtype from the module in which you define it
07:51:42 <Cale> tsahyt: i.e. you just list the type name in the export list, without the (..) after it which exports the constructor(s)
07:52:01 <tsahyt> but the functions working on it are spread out over a bunch of modules, so I'd need it myself to work with it there
07:52:13 <tsahyt> this is part of a refactor btw, so there's quite a lot of stuff already written
07:52:25 <Cale> I suppose what you can also do is define it in some .Internal module
07:52:26 <tsahyt> which is why I'd like to keep effort minimal
07:52:49 <Cale> and have things which need access to the constructor import the .Internal module, but not re-export the constructor.
07:53:37 <Cale> This also makes advanced users happier, because they don't need to fork your library to get low-level access to what's going on if they really want it.
07:54:04 <tsahyt> huh, so when I have newtype T a = MkT { ReaderT Foo Identity a } deriving (MonadReader Foo), and I don't export the MkT, the MonadReader is really not available?
07:54:16 <tsahyt> I'm pretty sure I've seen opaque types with instances before
07:54:21 <lyxia> why do you need a MonadReader instance
07:54:35 <tsahyt> lyxia: it's just less effort to work with during the refactoring
07:54:42 <tsahyt> it's not strictly necessary I suppose
07:54:43 <lyxia> You can define your own ask
07:55:10 <tsahyt> I think that's what I'll do
07:57:51 <nshepperd1> Yes, the MonadReader instance would be available even if you hide the constructor
08:02:08 <Aleksejs> Hi, why can't I use "_" character as infix function?
08:03:47 <mmaruseacph2> because it usually means something else
08:03:48 <geekosaur> because it's considered a "letter" character for the purpose of identifiers
08:03:49 <ski> `_' is not considered to be a symbolic character, can't be part of an operator name. it can be part of ordinary (non-operator) identifiers
08:04:22 <ski> (also, a sole `_' is the "wildcard/anonymous/ignore/don't care/anything goes" pattern)
08:05:12 <kuribas> and _name stops ghc from warning against unused "_name"
08:41:23 <haskell> Hey guys! Let's say I want to apply a function to all elements in a list, and print the result of the computations as they are finished. I know that my list might contain elements which makes the function take a long time. Is there an easy way to try to apply the functions to many elements in the list at the same time? I've tried using the forM_ method from the Control.Monad.Parallel package, and that kind of seems to work. However m
08:42:28 <haskell> as they are printed in parallel. I tried solving this by instead appending the results to a text file, but then another problem occurred. As I try to read and write to the same file at the same time (due to using forM_ from the parallel package), it says that the file is busy in an exception.
08:42:38 <haskell> Do you have any clues on how I could fix this?
08:43:24 <lyxia> your function does IO?
08:45:30 <haskell> The function I do in my forM_ is a lookup. But I also append the results from the lookup to a file, so that is IO
08:45:51 <lyxia> Is the lookup in IO?
08:46:13 <lyxia> I suppose it's the part that takes most time
08:46:45 <lyxia> So you would do these computations in parallel, and write the result sequentially
08:46:57 <haskell> No, the lookup itself shouldn't be IO. But yeah, it can get stuck in the lookup if the key is not found in the list (which is kind of huge).
08:47:16 <haskell> Yes! Maybe using some kind of queue/printer thread?
08:47:45 <lyxia> Nah, to parallelize pure computation you can just use parallel
08:48:16 <lyxia> and the printing part doesn't need anything fancy.
08:49:33 <haskell> Let's say I return "aaa" in the first iteration of my forM_, and "bbb" in the second. Then when I print I will see stuff like "abbbaa". How can I make sure that it will be printed as either "aaabbb" or "bbbaaa"?
08:50:24 <haskell> They get mixed up while printing in parallel, that's what I'm trying to say
08:50:30 <lyxia> you have a lookup function, and a print function, and you just don't put them together.
08:50:39 <lyxia> don't print in parallel, print sequentially
08:51:34 <haskell> a
08:51:49 <haskell> Sorry, but how would I achieve that?
08:52:04 <haskell> I'm new to concurrent programming and lazy IO
08:53:07 <haskell> In pseudo code I have something like: forM_ list $ \x -> do let solution = show (lookup x); print solution
08:54:18 <glguy> haskell: That code prints the solutions sequentially
08:54:20 <pavonia> Separate the pure and the IO parts
08:54:57 <haskell> By the way, it's not the Prelude forM_, it's the Control.Monad.Parallel
08:55:30 <glguy> ok, use the one from Control.Monad
08:56:03 <haskell> Will that let me do the lookups in parallel?
08:56:30 <glguy> No, if you want to do them in parallel, you'll need to do that first, and then print them sequentially second
08:58:32 <haskell> So if I have something like: forM_ list $ \x -> do let solution = show (lookup x); print solution. I want to do the lookups in parallel (as some lookups will take very long time (some won't even finish at all)), and print the solutions when they are found (in any order).
08:58:56 <haskell> Just to make myself more clear!
08:59:29 <ongy> do you need to print the first results before you got all of them?
08:59:31 <pavonia> haskell: Don't use lookup and print in the same action
08:59:52 <nshepperd1> Ah
09:00:09 <lpaste> lyxia pasted ‚Äúhaskell for haskell on #haskell‚Äù at http://lpaste.net/349635
09:00:23 <ongy> lyxia++
09:00:32 <glguy> haskell: If you want to print them in the order they are computed you'll need to do something extra
09:00:37 <haskell> Yes, I want to print the results as I get them, as I don't want to wait for some lookups which might take a very long time
09:00:47 <glguy> You can use a parallel forM_ to  evaluate the lookups and write them into a channel
09:01:03 <glguy> and then a second forM_ to read the solutions as they appear on the channel
09:01:06 <glguy> and print them in sequence
09:01:23 <nshepperd1> In another thread
09:03:39 <haskell> Won't output = parMap rseq f input have to be computed before I can print it?
09:04:25 <nshepperd1> You will require Control.Exception.Base.evaluate
09:04:32 <glguy> Trying to print it will cause it to evaluate in parallel, but it won't help to print the results as soon as they're done, it will print them in the original order. Fast results laster in the list will be blocked by slow ones earlier
09:06:16 <haskell> So what happens if when I try to map my lookup function to the first element in my input list, and that one takes a very long time to finish. Will nothing be printed until that one has been found in the lookup?
09:06:56 <glguy> read my last message
09:07:06 * ski . o O ( <https://www.haskell.org/ghc/docs/latest/html/libraries/base-4.9.0.0/Control-Concurrent-Chan.html> )
09:08:29 <haskell> They way I interpret what you wrote above says that nothing after a "slow input" will be printed, until that slow input has been found in the lookup table. Or did I get it wrong?
09:10:22 <nshepperd1> That's right
09:11:58 <haskell> Hmm, but that's not what I want to do. I want to print anything it can find in the lookup as soon as it finds it. In that way the slow ones will be printed at last, as I'm doing it in parallel. I don't want the slow ones to block the quick ones
09:13:09 <glguy> Yeah, that's why we're talking about writing the answers to a channel as they are evaluated
09:13:27 <haskell> Alright! I'll look into that, thanks!
09:13:44 <mniip> hmm, is there a trick to make a typecon have an implicit parameter of sorts
09:15:20 <mniip> I have a datatype with combinators to manipulate it, and the types involved are pretty complicated, so I would like to exclude them from the type signature somehow
09:15:31 <mniip> and let inference do the thing
09:15:53 <tsahyt> is there a way to make a type that you can pattern match on the constructors without being able to inspect their arguments?
09:16:15 <tsahyt> and more importantly, without being able to build something of that type
09:16:53 <maerwald> sounds like patternsynonyms/viewpatterns
09:16:56 <maerwald> but they are evil
09:17:21 <tsahyt> patternsynonyms do allow construction to some degree though
09:17:31 <maerwald> just write a "isFoo" function and don't expose the constructor at all
09:17:33 <haskell> So in my forM_ (from the Control.Monad.Parallel package) I will do my lookups and send them to the channel. How would you suggest I continuously print the stuff from my channel, at the same time as my forM_ loop is running? 
09:17:34 <lyxia> mniip: Have you tried PartialTypeSignatures
09:17:46 <maerwald> tsahyt: unidirectional pattern synonyms? no
09:18:19 <tsahyt> maerwald: I use pattern synonyms a lot in the raw bindings to this C library, and I can use the synonyms where an integer is expected just fine
09:19:40 <maerwald> tsahyt: so you are using bidirectional ones?
09:20:09 <tsahyt> maerwald: I didn't know there was a way to make unidirectional ones
09:21:39 <tsahyt> now I do know. but I think I'll do something less complicated
09:23:26 <hackrilege> Can I use DataKinds to promote a value level Int to Type level by prefixing with a '
09:23:28 <hackrilege> ?
09:24:37 <tsahyt> hackrilege: integer literals all exist on the type level with this extension
09:24:42 <tsahyt> no prefixing required
09:25:18 <tsahyt> :k 1 returns 1 :: GHC.TypeLits.Nat when you try it in ghci with DataKinds enabled
09:25:20 <lambdabot> error: parse error on input ‚Äò::‚Äô
09:25:32 <tsahyt> :k 1
09:25:34 <lambdabot> GHC.Types.Nat
09:25:41 <tsahyt> oh, nice. lambdabot can do that too
09:25:45 <hackrilege> I'm trying to figure out how I could make Nat labeled difference lists, can I find these anywhere?
09:26:05 <tsahyt> I haven't seen them yet
09:26:27 <lyxia> haskell: just have another sequential loop that reads from the channel
09:29:54 <hackrilege> I want to make a rose tree of difference lists... Something like data DifferenceRose a = DifferenceRose a [(Int,DifferenceRose a)] but I haven't quite got my head round it yet
09:33:24 <orion> Hey, does anyone know how to install cabal-install on a raspberry pi? I am getting errors: http://lpaste.net/7135518220143820800
09:34:25 <hackrilege> Maybe a single self intersection would be easier to consider first, data Intersect a = End | Construct a (Intersect a) | Intersect a (Intersect a) (Intersect a)
09:34:58 <geekosaur> looks to me like you have a ghc that generates code for the wrong ARM CPU level
09:35:14 <geekosaur> or possibly does not pass the appropriate level to the assembler
09:36:06 <hackrilege> The idea is that Intersect is like Construct except that it also holds a difference list style traversal
09:36:25 <puregreen> how can I make GHC use cpphs instead of gcc's cpp for all files in my package?
09:36:29 <suppi> fellow haskellers, do you do web dev? what is your framework of choice?
09:36:41 <orion> suppi: Scotty.
09:36:48 <hackrilege> data Intersect a = End | Construct a (Intersect a) | Intersect (a , (Intersect a)) ((Intersect a),(Intersect a))
09:36:58 <hackrilege> That might be more like it
09:37:37 <hackrilege> Probably should wrap the Construct in a tuple too...
09:39:18 <geekosaur> puregreen: ghc-options: -pgmPcpphs
09:39:36 <haskell> lyxia, do you have any suggestions on where in my code to create the chan? Somehow I will need to access that chan "object" in the print function as well, right?
09:39:59 <hackrilege> I'm trying to figure out how to get the type level Nat to hold the length of the difference (the length of fst of the second argument to Intersect)
09:40:15 <suppi> orion: thanks. looking for more opinions if possible :)
09:41:59 <puregreen> suppi: I like Spock (and I think it's supposed to be better than Scotty, given that it's an advanced fork of Scotty or something like that). I dislike Snap and I know one person who hates Snap with passion. I haven't managed to figure out how to use Yesod after several hours of trying.
09:42:22 <puregreen> that's all anekdata I have
09:42:33 <suppi> puregreen: why hate snap?
09:43:32 <puregreen> suppi: it was a couple of years ago but I remember that I was trying to do something very simple and even people at #snapframework couldn't help me. As for the other person I mentioned, no idea.
09:43:58 <haskell> Totally new to the concept of channels, but right now I've just tested it out as "do  ch <- newChan;   writeChan ch "Message 1";   msg <- readChan ch;   print msg;". Where do I want to do "ch <- newChan"? In the function where I have my forM_ that does all the lookups? Or where do I want to put it? I haven't really figured it out how both the parallel forM_ loop will use the ch variable, as well as the sequential printing method I'm 
09:44:03 <suppi> puregreen: i see. thanks :)
09:44:38 <hackrilege> Can I write something like, data Intersect n a = End | Construct a (Intersect (n-1) a) | Intersect (a , (Intersect (n-1) a)) ((Intersect m a),(Intersect (n-m) a)) -- I don't get how to introduce m...
09:48:47 <geekosaur> hackrilege, you're doing type level math?
09:49:36 <hackrilege> I'm new to it, hence the failed attempts...
09:50:17 <tsahyt> when I have a type that should be opaque, can I still derive Generic for it without leaking any abstraction out? The use case for me is to derive NFData
09:52:15 <thepreacher> Boy I've not felt my neurons fire this rapidly in a long time. This is how I read the following "(\x y -> x + 2*y)": a function that takes x and returns a function that takes y and add x to the result of 2*y. Am I correct?
09:52:53 <cocreature> thepreacher: yep
09:53:11 <haskell> For clarification, here is a part of the code I have right now: http://pastebin.com/FjXHmint If anyone could guide me on how to implement the printing method that would be greatly appreciated! Also, I'm not sure if that's the place where I want to create my chan?
09:54:30 <thepreacher> cocreature: Thanks. I'll get there in the end :)
09:55:39 <hackrilege> Maybe I should start with Nat parameterised difference lists before I make this hybrid structure.. I want to be able to express a "figure of eight" shaped collection using it
09:57:16 <hackrilege> I thought as well as storing a tail, a difference list could be used to navigate to the point the list intersects itself
10:05:23 <hackrilege> Maybe I parameter could be supplied to store the points of intersection as a type level list of pairs type level Nats...
10:13:10 <zipper> Is there another way to pattern match an "otherwise" other than `f _ = <return value>` ?
10:14:22 <kadoban> I think you can do something with record syntax, but not sure why you would.
10:15:54 <MarLinn> There's always `f a = case a of b -> case b of c -> case c of d -> case ... -> case z of _ -> <return value>`
10:21:42 <kadoban> zipper: What's wrong with  f _ =  ?
10:22:05 <lpaste> mniip pasted ‚Äútype inference misbehaving (?)‚Äù at http://lpaste.net/349637
10:22:15 <mniip> anyone see what I'm missing in the above?
10:22:25 <zipper> kadoban: At the time I was getting some warning when I was pattern matching it. I can't remember but after I deleted the function and rewrote it the warning went away
10:22:31 <zipper> I really wonder what I did :)
10:22:33 <mniip> it's like the typechecker is refusing to use testEquality at a different type there
10:23:08 <zipper> Wait I remember kadoban let me reproducr
10:23:54 <kadoban> zipper: Maybe it was that your cases before that actually handled every case, so that was redundant. That's a warning I believe, rightfully because it usually means one of your cases was more broad than you intended.
10:24:47 <lpaste> mniip revised ‚Äútype inference misbehaving (?)‚Äù: ‚Äútype inference misbehaving (?) [minimal case]‚Äù at http://lpaste.net/349637
10:25:55 <zipper> kadoban: On L23 http://lpaste.net/349639#line23
10:26:21 <zipper> kadoban: See I know the typechecker has my back on that but still. I don't see why the warning
10:26:27 <c_wraith> mniip, something looks funny about that instance. 
10:26:29 <kadoban> zipper: Right, that'll be a warning because that line does nothing, you've already matched everything.
10:27:03 <zipper> kadoban: Oh that makes sense :) and the typechecker can see that all the possible enums are matched
10:27:09 <kadoban> zipper: Another way to write isVehicle is just    isVehicle = const True
10:27:16 <zipper> kadoban: hahaha the typechecker is smart than I expected
10:27:24 <geekosaur> mniip, granting that I am no expert at type level, but it looks to me like "a" is forall-ed so it can't know that it's the same "a" in (SN x) and (SN y)?
10:27:26 <kadoban> Right. It can't always tell, but in simple cases it can
10:28:19 <geekosaur> (technically it can never be the same "a" since its scope is only inside each of those parens?)
10:28:44 <mniip> geekosaur, sure is, but pattern matching on (SN x :: S a) brings (x :: b) and (a ~ KN b) into scope
10:28:52 <mniip> since GADTs
10:29:06 <mniip> oops, x :: S b
10:29:19 <c_wraith> mniip, I think the problem is the polymorphism is wrong. 
10:29:45 <geekosaur> ok, I think c_wraith is seeing what I'm trying to see but has more idea of what they are talking about >.>
10:29:57 <c_wraith> mniip, testEquality requires that the caller can choose any types for a and b
10:30:07 <mniip> and they can
10:31:57 <c_wraith> mniip, but the Refl you return is on the wrong types. 
10:32:06 <mniip> no?
10:32:12 <mniip> the Refl line works just fine btw
10:32:21 <mniip> you can comment out the other one and see
10:32:26 <c_wraith> no, in the recursive call. 
10:32:39 <mniip> oh
10:32:43 <mniip> I see
10:32:48 <mniip> I need a, what is it,
10:33:13 <mniip> apply
10:33:24 <mniip> Data.Type.Equality.apply Refl
10:34:18 <mniip> indeed
10:34:19 <mniip> thanks!
10:34:31 <c_wraith> you're welcome 
10:41:39 <mdgeorge> I'm having trouble using collections; it seems to not be installed, and cabal install collections-api fails to compile
10:41:55 <mdgeorge> I just want my Map, man =)
10:42:11 <sras> Is there a library similar to Mime.Mail, but also allow to assign Content-Id to attachments?
10:42:51 <geekosaur> o.O (Data.)Map is in the containers package which usually comes with the compiler
10:43:25 <mdgeorge> I guess google led me astray
10:43:44 <cepp> whooooooaaaa, 1,670
10:43:55 <cepp> duuuudebrrroooooo
10:43:58 <kadoban> mdgeorge: I usually just look on hayoo or stackage's hoogle for the module name I'm trying to get and find the package that way, when I don't know it.
10:44:24 <geekosaur> oh, I see, collections-api is sorta take two on the Edison concept (collection types with a common API)
10:44:26 <mdgeorge> I accidentally searched for Collections instead of Containers
10:44:49 <mdgeorge> rip =)
10:44:59 <geekosaur> the experience of Edison is the idea is nice but the performance hit is excessive
10:45:11 <geekosaur> although the compiler's advanced a bit since then
10:46:08 <mdgeorge> what's the best way to find the "right way" to do something?  I'm a haskell beginner so searching for collections seemed sensible
10:46:40 <mdgeorge> then I spent a day reading about the type theory behind collections-api because there's no docs, and then discover it doesn't work
10:46:47 <mdgeorge> so I feel like I should be looking elsewhere
10:47:09 <sras> What is a good library for creating html emails with attachments. I have tried Mime.Mail, but it seems that it does not provide a function to assign Content-Id's to attachment.
10:47:22 <geekosaur> probably the documentation for containers (and unordered-containers) should mention collections more prominently, since Haskell isn't using the common terminology (often there are reasons for that, but in this case I'm not sure there's a good enough reason)
10:49:03 <mdgeorge> thanks for your help; I'll go figure out Containers now =)
10:49:32 <mniip> hmm
10:49:36 <mniip> that was some magic
10:51:11 <mdgeorge> unrelated: is there a way to put multiple hierarchical modules inside the same file?  I'd like a single file Automata.hs that defines Automata.DFA and Automata.NFA
10:51:33 <mdgeorge> It was quite hard to find any documentation at all on hierarchical modules
10:52:04 <mdgeorge> as a recovering Ocaml programmer it was a little jarring since everything there is modules
10:52:25 <kadoban> mdgeorge: Naw, AFAIK modules have to always be in their own file
10:52:37 <kadoban> Which is somewhat unfortunate, but it's understandable as well.
10:53:06 <mdgeorge> does that mean it's impossible to have a module that contains some submodules and some stuff at the top level?
10:53:11 <mniip> mdgeorge, the answer is no
10:53:32 <mniip> not yet, support for that is planned in ghc
10:53:40 <mdgeorge> I see
10:53:45 <whittle> I‚Äôm trying to write a function that takes an Aeson `Value` and‚Äîbased on a label field‚Äîreturns a type belonging to a particular type class. How do I write a function signature that allows the function to determine the type of its own result? 
10:53:50 <mmaruseacph2> mdgeorge: you can fake it by having a module Automata which imports and exports Automata.DFA and Automata.NFA and hide the last 2 in the cabal file
10:54:11 <mdgeorge> ah, I see
10:54:25 <mniip> whittle, sounds like you are trying to do something wrong
10:54:34 <mniip> there isn't a direct way to do what you're saying
10:54:39 <mmaruseacph2> or, you can also expose them and let the users choose if they want the top-level module or a specialized one
10:54:46 <mmaruseacph2> like they do with .Internal modules
10:54:53 <mdgeorge> ghc is smart enough to look both at Automata.hs and automata/DFA.hs then?
10:55:14 <mmaruseacph2> mdgeorge: afaik, yes
10:55:20 <mniip> mdgeorge, when you say 'import Automata.DFA' it will look at Automata/DFA.hs
10:55:28 <mniip> and you can include the former in Automata.hs
10:55:33 <whittle> mniip: So I should just go with my backup plan to make the different types of message that my program can accept different constructors for the same type? 
10:55:36 <mdgeorge> anyway, I'm mostly interested in it from the perspective of putting related code in one file.
10:55:57 <mdgeorge> but I think I have a better understanding of how it works now
10:56:08 <mniip> whittle, remember, type information is erased at runtime
10:56:37 <mdgeorge> I guess thinking of A and A.B as unrelated names is the way to go?
10:56:46 <mniip> yeah
10:57:00 <mdgeorge> ok, thanks for your help =)
10:57:24 <mdgeorge> "hierarchical modules" is a misnomer =)
10:57:54 <geekosaur> it's true but only in a lexical sense
10:59:21 <ezyang> Hi Haskell: should I name my package "str-sig" or "str-signature" 
11:03:45 <mniip> ski, I found a nice way to EDSL LR parsing in haskell :D
11:04:04 <mniip> well, nice from the outside. The implementation details are pretty edwardkese
11:06:42 <mmaruseacph2> interesting adjective
11:07:09 <mniip> if you've ever seen his code you know what I mean
11:07:12 <geekosaur> edwardk is the new oleg >.>
11:07:19 <whittle> ezyang: I vote for "str-signature": "str-sig" might be about signals. 
11:08:05 <mmaruseacph2> I know, mniip
11:08:17 <mmaruseacph2> ezyang: str-signature
11:08:52 <jle`> how about hignature
11:10:46 <ezyang> coolio! 
11:10:56 <ezyang> well, str-hsig could be an alternate name 
11:15:35 <orion> Does anyone know what the requirements are for c2hs to work with stack?
11:16:14 <orion> I added "build-tools: c2hs" to the "library" dict of package.yaml.
11:17:21 <hololeap> i'm looking at applying <*> and =<< to functions. (=<<) :: (a -> b -> c) -> (b -> a) -> b -> c  and  (<*>) :: (a -> b -> c) -> (a -> b) -> a -> c   ... so they just switch which argument of the first function the second function is applied before
11:17:34 <orion> I tried naming my file src/Foo.chs but stack/cabal doesn't recognize it as a module that's part of my project.
11:18:04 <hololeap> so could you write an implementation of `on` using <*> and =<< ?
11:23:19 <jle`> well, you can technically write anything with <*> and pure, i think.
11:23:20 <jle`> https://en.wikipedia.org/wiki/SKI_combinator_calculus
11:23:40 <jle`> but i don't think it'll be clean
11:25:14 <mniip> interesting
11:25:15 <hololeap> jle`: which functions do S K and I correspond to
11:25:31 <mniip> I made ghc hang without any of the hanging extensions?
11:25:50 <jle`> hololeap: S is <*> and K is pure
11:26:25 <mniip> oh it's just eating gigabytes of ram
11:26:58 <mniip> still, that shouldn't happen, right
11:27:09 <jle`> hololeap: I is id, of course, but it's als pure <*> pure
11:28:38 <hololeap> jle`: that explains to me a little bit about Applicative that I wasn't understanding. it is supposed to be able to represent SKI calculus (or lambda calculus? all of this is pretty new to me)
11:29:10 <jle`> to be clear, what you're studying actually doesn't have to do with Applicatives in general
11:29:18 <jle`> it's just with the specific instance for `(->) r`
11:29:32 <jle`> the relationship between (=<<) and (<*>) that you're observing is unique to that one instance
11:29:42 <hololeap> makes sense
11:29:49 <jle`> so in a sense, it's a 'concidence'
11:30:52 <hololeap> where does the name Applicative come from? because you are applying functions within the context of a Functor?
11:31:16 <mniip> awwwww
11:31:22 <mniip>     ‚Ä¢ Could not deduce: TIndex (f i) (TKeyMap f m) ~ t     from the context: TIndex i m ~ t
11:32:38 <jle`> here's the original paper if you're interested http://www.staff.city.ac.uk/~ross/papers/Applicative.html
11:33:47 <jle`> hololeap: but yeah, my original point was that between S and K you can express any computable function, so it wouldn't be surprising if you could express 'on' with them
11:33:55 <whittle> Blergh. Having a single type with a different constructor for each and every message this server might receive just feels terrible. 
11:34:19 <monochrom> Do you have a better way?
11:34:38 <jle`> but this isn't a property about Applicatives ... just a property about the functions that happen to be the methods in a specific Applicative instance
11:36:17 <hololeap> jle`: ok. i suppose this wasn't by accident? it "feels" strange that ((->) r) would be defined as a instance of Functor, Applicative and Monad. i understand that it could be, but the reasons for implementing it elude me.
11:36:25 <whittle> What if I had a function like :: (ByteString -> forall a. (Message a, Typeable a) => Maybe a)? Then I could disambiguate types at run-time. 
11:37:01 <whittle> hololeap: Isn‚Äôt that a primitive ancestor of Reader? 
11:37:07 <mniip> on = \o f g x -> o (f x) (g x) = \o f g x -> (o . f) x (g x) = \o f g -> S (o . f) g = \o f -> S (o . f) = \o f -> (S . (o .)) f = \o -> S . (o .) = \o -> ((S .) . (.)) o = (S .) . (.) = S(KS)K (S(KS)K S) (S(KS)K)
11:37:29 <hololeap> whittle: no, it's the arrow that defines a function, e.g. (->) a b === a -> b
11:37:43 <whittle> hololeap: Ah. My bad. 
11:37:58 <hololeap> (Int -> a) is a Functor, Applicative and a Monad
11:38:12 <mniip> hololeap, you mean (Int ->)
11:38:22 <jle`> hololeap: well, a lot of things are instances
11:38:26 <jle`> Maybe is an instance of all three
11:38:28 <jle`> so is IO
11:38:37 <jle`> so is Proxy, List, etc.
11:38:51 <monochrom> I disbelieve that postponing things to run time is an improvement.
11:39:09 <jle`> each of the methods of those types in Functor/Monad/Applicative all have "meaning", and they'd all be very useful combinators in their own right, independent on functor/applicative/monadness
11:39:21 <monochrom> And I have doubts about whether "ByteString -> forall a. (Message a, Typeable a) => Maybe a" is actually doable.
11:39:45 <jle`> hololeap: for example, concatMap and map on lists are pretty useful for lists, even if the Monad/Functor typeclasses don't exist
11:39:57 <hololeap> those make sense to me for the practical purposes, but defining (<$>), (<*>), pure, and bind for (->) r ... i don't see the practical reasons. that's what i'm curious about
11:39:59 <mniip> monochrom, ooh there was a combinator for this
11:40:02 <jle`> hololeap: same for S and K.  they'd be useful functions for ((->) Int), whether or not Applicative existed
11:40:04 <mniip> the conjugate of =>
11:40:42 <hololeap> i want to know how to use this particular instance to write cleaner code
11:40:55 <mniip> basically you want "ByteString -> Maybe (a, Dict (Message a, Typeable a))
11:40:56 <mniip> "
11:41:10 <mniip> exists. instead of forall.
11:41:39 <whittle> :t Dict
11:41:40 <lambdabot> error: Data constructor not in scope: Dict
11:42:03 <jle`> @let data Dict c where Dict :: c => Dict
11:42:04 <lambdabot>  .L.hs:168:22: error:
11:42:04 <lambdabot>      ‚Ä¢ Expecting one more argument to ‚ÄòDict‚Äô
11:42:04 <lambdabot>        Expected a type, but ‚ÄòDict‚Äô has kind ‚Äòk0 -> *‚Äô
11:42:05 <jle`> oops
11:42:07 <jle`> @let data Dict c where Dict :: c => Dict c
11:42:09 <lambdabot>  Defined.
11:42:13 <mniip> yeah that
11:42:45 <ezyang> Hmm, foundation strings don't have very many ops defined on them 
11:42:57 <mniip> from edwardk's category of constraints
11:43:46 <whittle> I hadn‚Äôt seen Data.Constraint before. Thank you, mniip and jle`, I‚Äôll dig into that now. 
11:43:46 <ezyang> oh they're all in typeclasses 
11:44:27 <jle`> i didn't find it a very useful package until i actually had a use for it, heh.
11:44:36 <jle`> "why would anyone ever need this"
11:44:39 <jle`> "oh i need it."
11:44:53 <mniip> 99% of edward's code
11:47:28 <whittle> monochrom: FWIW, I agree that postponing decisions regarding types to run time is generally not an improvement. I was just scared of creating an unmaintainable nightmare by going in the other direction. 
11:47:59 <whittle> Happy to discover that there may be a middle path, and singularly unsurprised that edwardk paved it. 
11:49:30 <whittle> Thank you all for your patience. 
11:49:56 <monochrom> What does "maintenance" mean in this case? What is there to maintain?
11:51:11 <monochrom> The only two kinds of maintenance I can think of are: You made a mistake in the past and now you have to fix it; You made no mistake, it's just that the server side changes its messages so you have to change your code too.
11:51:58 <monochrom> The thing is that postponing things to run time makes both harder. It's why I actually think that postponing things to run time is the unmaintainable nightmare.
11:54:20 <whittle> I agree with you, it‚Äôs just that from past experience (in other programming languages) putting every possible message into a single data structure that can‚Äôt be examined or tested piece-wise tends to also become unmaintainable quickly. I‚Äôm looking for a solution that avoids both. 
11:54:39 <monochrom> It is easy to feel that an algebraic data type of one million cases, one case for each message category, feels unmaintainable.
11:54:43 <pikajude> there must be an easier or more performant way to write this. what is it? http://lpaste.net/5094389013343633408
11:55:13 <mniip> ugh
11:55:36 <mniip> 		r = Reduce (IndexL IndexH) (IndexR IndexH) IndexH : map (\(Reduce i j k) -> Reduce (IndexL i) (IndexL j) (IndexL k)) rf ++ map (\(Reduce i j k) -> Reduce (IndexR i) (IndexR j) (IndexR k)) rx
11:55:57 <mniip> I wish I could define a helper function for this but there's too much existential quantification and type transformation going on
11:56:02 <monochrom> But objectively it is going to be (as opposed to feel) more maintainable because the compiler has an unexhasutiveness warning when you forget to handle one case.
11:56:39 <maerwald> types are not the only way to you can achieve that
11:59:02 <whittle> monochrom: I agree with you. That why using one giant data type is my fall-back plan if I can‚Äôt find a way to get the same compile-time guarantees in a way that I can spread out over multiple modules. 
11:59:57 <maerwald> use a language with a proof assistant to defer that problem to the proof-checker without encoding it into the actual API
12:00:38 <maerwald> but I'm not sure how feasible that is for your actual case
12:01:25 <yiimi> what is the latest version of cabal?
12:01:26 <whittle> I understand that the solution I proposed using Typeable and RankNTypes was inappropriate in a number of ways, and I‚Äôm glad to have received a suggestion of a possible solution in Data.Constraint. 
12:01:52 <yiimi> i am looking at a project that requires version >= 1.8 of haskell 
12:02:10 <yiimi> the version i have (installed with haskell platform about a week ago) is 1.24.0.0
12:02:20 <yiimi> oh, that's large enough :)
12:02:37 <mniip> yea numeric compare, not lexicographical
12:02:40 <whittle> maerwald: I like that idea, but I haven‚Äôt gotten good enough with any proof assistants yet to make that work inside my schedule. 
12:03:17 <whittle> I hope to get there some day. 
12:13:35 <pikajude> is there any library that can convert a byte string to an Integer?
12:13:45 <int-index> attoparsec
12:14:07 <monochrom> bytestring has a "readInt" function.
12:14:35 <pikajude> i'm not talking about reading a textual representation of the integer
12:14:46 <nomeata> Hi. Is there a tool that traces cabal dependencies, fetches the code, and dumps all source files in one directory, to make something self-contained?
12:14:47 <pikajude> i'm talking about packing/unpacking an integer as a string of bytes
12:14:52 <pikajude> like my paste above shows
12:15:24 <pikajude> binary provides Word64 unpacking but the integer I'm trying to read is 309 digits long and Word64's maxBound is 20
12:16:04 <mniip> 20?
12:16:08 <mniip> I think it's a bit higher?
12:16:20 <Tuplanolla> Digits obviously, mniip.
12:16:22 <pikajude> meh, on my machine maxBound::Word64 is 18446744073709551615
12:16:23 <mniip> oh
12:16:28 <pikajude> which is 20 digits
12:16:37 <mniip> I didn't realize you meant 20 digits
12:17:04 <pikajude> the int I'm trying to read is the p*q of an RSA key
12:17:06 <monochrom> yeah, one byte is 3 digits. :)
12:17:13 <ab9rf> up to 73 books in the library now
12:17:17 <pikajude> so it doesn't quite fit in a Word64
12:17:17 <ab9rf> garf
12:17:50 <Tuplanolla> It should only take a fold, pikajude.
12:18:02 <pikajude> i'm already doing a fold, I just hoped there was something more efficient
12:18:28 <ab9rf> pikajude: is the number written in the bytestring in ascii or in raw bits?
12:19:03 <pikajude> :/
12:19:04 <ab9rf> how many of these numbers do you have to read? don't optimize prematurely.
12:19:33 <pikajude> it's raw bits. i'm basically unserializing an RSA key
12:19:59 <monochrom> If you go small endian, you'll never have to exponentiate.
12:19:59 <ab9rf> i'd just do a fold
12:20:15 <pikajude> ok
12:20:45 <ab9rf> it's be "more efficient" if you did it 4 or 8 bytes at a go, but the difference performancewise will not be discernable unless you intend to read in thousands of these keys
12:20:52 <ab9rf> are you going to be reading thousands of keys at a time?
12:21:05 <pikajude> probably not
12:22:42 <monochrom> Or rather, if you go small endian and use Horner's rule, you'll never have to exponentiate.
12:24:33 <monochrom> Horner's rule means a*x^3 + b*x^2 + c*x + d = ((a*x + b)*x + c)*x + d
12:25:15 <ab9rf> monochrom: i've been writing aton like that since i can't remember, but never knew it had a name :)
12:25:25 <monochrom> I guess Horner's rule works a bit better with big endian.
12:26:11 <ab9rf> monochrom: it's harder with little-endian representations of unspecified sisze
12:26:54 <yulax> ping fsf.org
12:26:57 <yulax> oops
12:27:01 <yulax> xD
12:27:03 <athan> Anyone here happen to know if SK1M machines are still made? Or something SK combinator machine?
12:27:05 <maerwald> yulax: do you use irssi?
12:27:10 <yulax> maerwald: no
12:27:18 <yulax> ii :-)
12:27:22 <monochrom> OTOH we could use foldr if small endian and let foldr worry about it.
12:27:42 <hackrilege> Would anyone be able to help me represent polygons which join at the corners?
12:28:00 <pikajude> so would `foldr (\w n -> fromIntegral w + n `shiftL` 8) 0` be correct?
12:28:06 <kirillow> Why is pure called pure?
12:28:11 <athan> hackrilege: in 2d?
12:28:19 <hackrilege> Yeah to start
12:28:22 <pikajude> I guess that depends on endianness doesn't it
12:28:35 <athan> it sounds like a graph or something hackrilege
12:28:37 <monochrom> yes, "pure" could have two reasonable names, one is "pure" the other is "impure".
12:29:03 <monochrom> "pure" means "I'm injecting a pure thing into an impure context".
12:29:19 <monochrom> "impure" means "I'm injecting a pure thing into an impure context" too. :)
12:29:21 <hackrilege> I want a recursive definition with a polygon type represented as a list
12:29:37 <kirillow> hmmm
12:29:44 <kirillow> makes sense
12:30:41 <pikajude> > (foldl1 (+) [a,b,c,d], foldr1 (+) [a,b,c,d])
12:30:43 <lambdabot>  (a + b + c + d,a + (b + (c + d)))
12:31:02 <monochrom> the most reasonable name should be "pure_to_impure" but it was vetoed by both camps.
12:31:18 <ab9rf> monochrom: too many underscores
12:31:26 <hackrilege> data Polygons a = Polygons [(Maybe (Polygon a),a)] -- how does that sound?
12:31:45 <monochrom> You could change it to camel case but I'm sure the two camps would still veto it.
12:32:05 <hackrilege> Polygons*
12:32:06 <maerwald> monochrom: then pure2impure must work
12:32:19 <ab9rf> hackrilege: "join at the corners"? is there any guarntee that a single polypolygon is connected, or can you have, say, three polygons with no common vertices?
12:32:48 <hackrilege> It should be connected
12:33:13 <ab9rf> hackrilege: because the list of polygons you propose doesn't enforce that
12:34:14 <ab9rf> seems to me that you really just have a undirected graph with a constraint that every vertex has to have degree 2 or greater
12:34:14 <hackrilege> I guess by appearing alongside a corner of the polygon it represents connectivity...
12:35:02 <monochrom> No, mine is only the 2nd most reasonable name.
12:35:10 <ab9rf> vertices with degree >2 are shared between multiple polygons
12:35:15 <monochrom> The most reasonable name should be "impure_from_pure".
12:35:18 <ab9rf> monochrom is the grand arbiter of nomenclature
12:35:49 <mniip> monochrom: impurify
12:35:56 <ab9rf> i like impurify
12:36:05 <monochrom> No, I am the Delphi. I am right but no one believes me.
12:36:13 <hackrilege> It's like a (cyclic) linked list with an optional linked list as a branch.
12:37:10 <monochrom> ŒîŒ¶
12:37:20 <hackrilege> The vertices have only degree 2 or 3
12:37:56 <ab9rf> hackrilege: hm, you're sure that none have degree 4 or greater?
12:38:27 <Tuplanolla> Doesn't OpenGL have this figured out, hackrilege?
12:38:32 <mniip> hmm I need a structure like (C a i, C b j, C c k, ... C r z) => ([i, j, k, ...], z, a -> b -> c -> ... r)
12:38:40 <Tuplanolla> You have triangle fans and strips and such.
12:38:46 <mniip> does anyone have a link to the zipWith paper? I think it did something similar?
12:38:52 <ab9rf> Tuplanolla: yeah, if that's what's he's trying to do.
12:39:03 <ab9rf> Tuplanolla: i assumed he wanted a more general polygon, and not just triangles
12:39:31 <hackrilege> Polygon fan is a good term
12:40:10 <Tuplanolla> It's the same thing, except you skip some nodes or connect some extra nodes with polygons.
12:41:03 <haasn> shouldn't GHC automatically be capable of desugaring something like  proc x -> f x -< z  to  proc x -> app <- (f x, z)  ?
12:41:06 <hackrilege> I think it's degree 3 not 4 since it's a shared 0 length edge between 2 nodes of order 3 that represents what seems to be an order 4 node at the intersection at a corner
12:41:19 <haasn> i.e. use ArrowApply's ‚Äòapp‚Äô automatically where you try to use an arrow input in the computation of an arrow
12:41:50 <ertes> haasn: there is a separate arrow for that
12:41:59 <hackrilege> You can progress through the linked list around the polygon, or step into another one
12:42:02 <ertes> haasn: "-<<", i think
12:42:39 <haasn> ertes: ah, indeed. thanks!
12:42:51 <ertes> haasn: although if you need that, you don't need arrows to begin with
12:42:57 <haasn> It's for HXT
12:43:35 <ertes> haasn: ah, my condolences
12:43:37 <haasn> In which case I also don't know why they use arrows if they could use monads as well
12:43:41 <grahamhutton> zipWith paper: http://tinyurl.com/hnvs3xy
12:44:02 <haasn> not my code, I was just helping a friend bash his head against HXT and wondered ‚Äúhmm, shouldn't GHC be capable of automatically using `app`?‚Äù
12:44:09 <ertes> haasn: yeah, i'd generally avoid that library, if you have other options (like xml-conduit or xmlhtml)
12:44:13 <haasn> Which I still wonder, why is -<< a separate syntax form when GHC could very easily just know something is bound from the left side
12:44:45 <ertes> haasn: i don't know the official reasoning, but my own reasoning is that it's an indicator that you don't need arrows =)
12:45:03 <monochrom> ease of implementation. raises reader awareness. best of both worlds.
12:48:10 <ertes> (it's time for hxt 10.0 with the changelog entry: "finally switched to monads, as we should have done like 10 years ago")
12:50:26 <barrucadu> I haven't used any other xml libraries, but I found the arrow interface rather pleasant when I last used hxt
12:50:44 <hackrilege> Oh I guess you could have order 4 node like; Polygon [(Just (Polygon [(Just (Polygon [(Nothing,3)]),2)],1)]
12:50:52 <ertes> barrucadu: an equivalent monadic interface would be far more pleasant
12:51:35 <hackrilege> Probably with more corners per polygon :/
12:51:39 <haasn> You can turn any monad into an arrowapply, can you do the reverse?
12:51:48 <haasn> (the forward transformation is with Kleisli)
12:51:57 <ertes> haasn: see‚Ä¶  i think‚Ä¶  WrappedMonad?
12:52:03 <ertes> (yes)
12:53:03 <monochrom> ArrowMonad
12:53:22 <haasn> Ah, found it simultaneously with monochrom :)
12:53:26 <haasn> Yeah that makes sense
12:54:01 <haasn> I guess the function you'd want is unkleislify :: Arrow a => a b c -> b -> ArrowMonad a c
12:54:05 <monochrom> both Kleisli and ArrowMonad are in Control.Arrow
12:54:36 <haasn> unkleislify a b = ArrowMonad $ arr (const b) >>> a
12:55:06 <monochrom> someone should make a joke about unkleisified ads
12:55:45 <ertes> i'm in favour of getting rid of arrows entirely and make proc notation desugar to Applicative+Category
12:56:06 <ertes> (proc x -> c -< f x) = f <$> c
12:56:39 <monochrom> but I have proc x -> c -< f -< x+1
12:57:23 <ertes> while doing that generalise all the Monad* classes (especially MonadFix) to Functor* classes
12:58:20 <haasn> ertes: Wasn't the point of Arrow to have more laws than the ‚Äúequivalent‚Äù Functor-like abstraction?
12:58:42 <haasn> Or can you find analogs to all of the arrow laws?
12:59:46 <ertes> haasn: if you ignore the laws, then Applicative+Category is exactly as expressive as Arrow, but if you take laws into account, then one of them is stronger (i don't know which one)
12:59:54 <monochrom> HXT is a poor example of Arrow because it ends up being all ArrowApply
13:00:25 <monochrom> The most compelling examples are things like Lava (circuit modeling) but Lava moved away from Haskell altogether.
13:01:35 <hodapp> what is Lava now?
13:02:13 <ertes> anything with meta-data is also compelling (like parsers)‚Ä¶  and some monads are better not used as monads (like mealy machines)
13:02:45 <haasn> yeah static metadata seems like the motivating use case for arrows
13:03:03 <MarLinn> If (proc x -> c -< f x) = f <$> c is correct, why ask for Applicative or Category constraints?
13:03:09 <haasn> anything where the structure of the ‚Äúcircuit‚Äù is constant
13:03:24 <ertes> MarLinn: you don't have to, but Applicative+Category would cover all of proc/do
13:03:31 <haasn> (in the sense that it doesn't depend on inputs to the circuit)
13:04:12 <haasn> (I think syntax should desugar with as few constraints as necessary, that way we get to do stuff like using do notation for applicatives)
13:04:44 <ertes> haasn: (if you weren't aware of it already: -XApplicativeDo)
13:05:48 <nitrix> ezyang: Nice proposal.
13:05:55 <byorgey> Simon Marlow gave a nice talk about ApplicativeDo at this year's Haskell Symposium, there should be a video of it online
13:05:58 <nitrix> ezyang: Love the cute puzzle pieces.
13:09:46 <MarLinn> ertes, `pure` would take on the role of `arr`, right? So generalized braided categories without "generators" like `arr $ \x -> (x,x)` and "destructors" like `arr $ \(x,_)->x` would not be possible?
13:10:09 <ongy> nitrix: can you post a link? to the proposal
13:15:29 <ertes> MarLinn: no, 'pure' would be unused by desugaring
13:15:35 <reactormonk> Is ghc supposed to just allocate 1 TB of RAM?
13:15:47 <ezyang> nitrix: Haha, yay! 
13:16:02 <shapr> reactormonk: depends on what you're doing
13:16:10 <reactormonk> shapr, compiling something via cabal
13:16:17 <reactormonk> something as in elm platform
13:16:25 <ertes> MarLinn: arr f = f <$> id
13:16:50 <shapr> reactormonk: last time ghc did that to me, I had less than a gig of ram
13:16:53 <mmaruseacph2> reactormonk: on Mac it always shows that the virtual memory requested is 1TB
13:17:03 <shapr> I haven't tried to build elm, I should try that after work.
13:17:04 <mmaruseacph2> but it doesn't get to ask all of that
13:17:12 <reactormonk> mmaruseacph2, naturally.
13:17:44 <mmaruseacph2> like, I have a stack ghci opened and the ghc process spawned by it asks for 1TB
13:17:50 <monochrom> I would word it as "requests an address space of 1TB"
13:17:56 <mmaruseacph2> but resident is only 400MB
13:18:05 <mmaruseacph2> what monochrom says
13:18:32 <glguy> It's normal that it reserves 1TB of address space. Lucky it's not all backed
13:18:34 <monochrom> but if you actually know of a way to use that much memory for real, everyone would love to know
13:18:55 <haasn> monochrom: we have a few server clusters with several TB of RAM in use
13:18:59 <haasn> not on haskell, sadly
13:19:29 <monochrom> yeah, I heard that they tend to be caused by multi-threaded Java programs :)
13:20:15 <monochrom> also it will not be just ghc. it is any program that uses ghc's rts, so ghc and ghci themselves are just easy examples
13:20:56 <monochrom> they did this to buy something about more convenient or efficient pointers. I forgot how.
13:21:24 <geekosaur> it means they can allocate by pages instead of by malloc chunks
13:22:36 <geekosaur> if they need more memory they can just madvise() on the next free page to actually map it; if they are done with a page they can do another madvise() to release the mapping and then add it to the free list
13:22:52 <MarLinn> ertes, Mh, that makes sense. I guess the ideal I have in my head is a way to use proc notation without even a Functor instance then. It should possible, but probably not in such a simple, generalizable way.
13:23:04 <geekosaur> or they can be even more clever and arrange that the first use of any page allocates a real page
13:23:20 <geekosaur> so they only need to worry about the free-a-page case
13:23:28 <ertes> MarLinn: how would you translate (proc x -> c -< f x) without Functor?
13:23:49 <geekosaur> it also makes it easier to release memory back to the OS, which standard Unix/libc memory management is kinda bad at
13:24:07 <geekosaur> because it's designed to work with mostly small (<< page size) allocations
13:24:17 <ongy> is there a way to get a record modify syntax? So instead of Record { field = val } where val :: a, Record { field <- f } where f :: a -> a? or do I hvae to use lenses for that?
13:24:48 <ongy> also I'm not sure if record modify syntax is used somewhere, I just used it here because it makes sense for me (also made up syntax for it)
13:25:06 <ertes> ongy: lenses are basically that
13:26:00 <ezyang> If I want to link to an identifier with a tick in it in Haddock, how do I do it? 'foo\'' doesn't seem to be right 
13:26:05 <ertes> ongy: (r { x = f (x r) }) becomes ((x %~ f) r)
13:26:18 <glguy> ezyang: Did you try: 'foo'' ?
13:26:23 <ezyang> nope :) 
13:26:27 <ertes> ongy: or (r & x %~ r) if you will
13:26:35 <glguy> I'm not certain that that's right, but it feels right
13:26:54 <ongy> I know it's easy with lenses. Can I give the normal record to it? so can I use it without special support from the record? and is there a lens-library that's rather minimal?
13:27:13 <Tuplanolla> There's `microlens`, ongy.
13:27:53 <ertes> ongy: lenses are just regular functions with a certain type schema
13:28:02 <ertes> no special support needed
13:28:22 <ertes> all a lens library provides is type aliases for that schema and some functions to apply lenses
13:29:24 <ertes> (it provides more, but everything apart from that is convenience‚Ä¶  strictly speaking even the type aliases are convenience)
13:30:45 <ongy> doesn't really answer my question, maybe I worded it badly. Can I pass record fields into it, or will I/the library have to provide a lens function?
13:31:13 <ertes> you have to provide the lenses
13:31:48 <monochrom> the library has a module that uses TH to do the lens for your record fields, if you don't want to do it yourself.
13:33:52 <MarLinn> ertes, (proc x -> c -< f x) could cause a Functor constraint the same way (-<<) causes an ArrowApply constraint. But maybe there could be a way to translate (proc (x,y) -> {v <- c -< x; w <- d -< y; e -< (w,v)}) without arr-injection despite the tuples
13:35:33 <hackrilege> data Stick a = Branch [a] (Stick a) (Stick a)
13:35:43 <ertes> MarLinn: i see‚Ä¶  you want to be able to build circuits =)
13:36:23 <MarLinn> ertes, yes. Including reversible ones if possible
13:36:35 <hackrilege> I think that's the same as Polygons from before...
13:37:36 <ongy> hackrilege: how do you end the structure? or is it supposed to be infinite?
13:37:47 <ertes> MarLinn: there is an equivalent formulation of Applicative using tuples that can get away without using functions, and as long as you only ever wrap/unwrap tuples, you could make such a class independent of Functor‚Ä¶  i haven't seen that in action though
13:38:02 <hackrilege> Except here representing the edges between branch points as potentially empty lists...
13:38:14 <hackrilege> (hackrilege) data Stick a = Leaf | Branch [a] (Stick a) (Stick a)
13:39:22 <hackrilege> Probably should call it Tree..
13:42:07 <hackrilege> Being able to have empty lists kind of makes it the same as data Tree a = Tree [a] [Tree a]
13:42:33 <codedmart> I need to parse an svg (XML) file, manipulate a few attributes, then write to file. What is my best option for that? tagsoup?
13:45:49 <mutantmell> does base's sort method in Data.List use constant space?
13:46:05 <maerwald> it's mergesort isn't it?
13:46:12 <mutantmell> maerwald: yeah
13:46:28 <mutantmell> I think it does, just want to make sure
13:47:14 <maerwald> well, then worst space complexity would be O(n)
13:47:18 <kirillow> I'm trying to import Test.QuickCheck.Checkers and so I put QuickCheck into my build-depends. However, the compiler is complaining about there being no such interface and asks whether I meant Test.QuickCheck.Modifiers. Is Checkers deprecated? What am I doing wrong?
13:47:22 <kadoban> It seems like it'd at least have to use Œ©(lg n) space, unless I'm missing something.
13:48:25 <mutantmell> Sorry, I asked the wrong question
13:48:39 <mutantmell> does the merge implementation in the sort use constant space
13:49:12 <MarcelineVQ> kirillow: Test.QuickCheck.Checkers comes from the checkers package not QuickCheck
13:49:29 <mutantmell> all I need to do is merge two lists together, not sort
13:49:46 <kadoban> mutantmell: Does it expose just the merge?
13:50:00 <mutantmell> kadoban: it does not
13:50:02 <kirillow> MarcelineVQ: ooooooooooooh
13:50:06 <kirillow> thank you
13:50:08 <MarLinn> ertes: Ah yes, I've seen that somewhere. Interesting thought. And now that I think about it there was even a category version in one of the alternative preludes if I'm not mistaken. Gotta investigate if that's usable for the purposeÖ
13:50:14 <kadoban> mutantmell: Are you ... looking at the code for it then and going to copy it for your uses?
13:50:16 <MarcelineVQ> kirillow: http://hackage.haskell.org/package/checkers  You'll probably want QuickCheck and checkers in your build depends
13:51:05 <mniip> augh
13:51:13 <mniip> ifcxt depends on base=4.8
13:52:05 <mniip> I could really use some right now
13:52:09 <mutantmell> kadoban: probably, it's small enough that it isn't problematic.  I was about to analyze the core dump of that fucntion to check performance, and I figured I'd ask here first
13:52:35 <kadoban> mutantmell: Trying to understand the context of your question to gives a reasonable answer. I'm not really clear what you're attempting. If you're just going to ++ two lists and then 'sort' it, there's no way it can just merge, it'll have to actually sort them, unless it's using something other than mergesort.
13:53:25 <mutantmell> kadoban: I'm trying to merge two already sorted lists
13:54:03 <kadoban> mutantmell: I would just write code to do that, unless there's a library that exports that somewhere. Unless Œ©(n lg n) time is good enough, in which case you might want to just do that and skip the coding/debugging.
13:54:04 <mutantmell> One is calculated internally, one is sourced from somewhere else, I need to merge them
13:54:53 <hiptobecubic> that merge function is just a few lines, i'd just write one
13:55:21 <mutantmell> that's the plan, I just wanted to know the space complexity.
13:55:29 <mutantmell> I'll take a look at the core dump :)
13:55:47 <mekeor> does anybody a have a simple yet functional emacs configuration for haskell online?  i'm using intero but i don't like the flychecking. also i'd like to try out structured-haskell-mode. also my haskell-indent config sucks badly
13:56:32 <hiptobecubic> i would expect it to be doable in no worse than linear time and space
13:56:35 <kadoban> mutantmell: Anyway, a merge in haskell could only be constant space if GHC realizes that it doesn't need the original lists anymore.
13:56:55 <ertes> MarLinn: unlikely, because proc/do still desugars to Arrow
13:56:57 <hiptobecubic> (which is true basically everything in haskell)
13:56:58 <Koterpillar> mekeor: Spacemacs comes with support for intero and hindent
13:57:02 <kadoban> A merge of [] anyway.
13:57:15 <Koterpillar> mekeor: you can also set the flycheck to use ghc-mod instead
13:57:57 <ertes> mekeor: here is mine, but i have a lot of unpushed local changes right now: https://github.com/esoeylemez/config/blob/master/files/.emacs
13:58:07 <ertes> it's haskell-mode + haskell-interactive-mode
13:58:15 <mekeor> ertes: you could just push 'em ;)
13:58:36 <ertes> mekeor: oh, you also need: https://github.com/esoeylemez/config/blob/master/emacs/ertes-haskell.el
13:58:55 <mekeor> thanks, ertes
13:59:18 <ertes> mekeor: not right now‚Ä¶  it's a mess that i need to clean up, because i briefly switched to nix+cabal-repl, which turned out not to work as well as i hoped
14:09:12 <zebr> is there a standard function :: (b -> c -> d) -> (a -> b) -> (a -> c) -> a -> d ?
14:09:55 <mniip> yes
14:09:56 <mniip> liftA2
14:10:31 <MarLinn> ertes: Yes ñ but there was actually some movement about that on the ghc-devs mailing list less than a week ago. For now it's about investigating what the hell the requirements are to use proc with RebindableSyntax, but you never know
14:10:55 <zebr> mniip: ah! thanks :)
14:11:03 <kadoban> mniip: Cute
14:11:21 <mniip> kadoban, what is, liftA2?
14:11:28 <kadoban> Ya, for that
14:12:04 <orion> Does anyone know of a very complex library that uses c2hs?
14:12:11 <orion> I need spiritual guidance.
14:12:43 <yushyin> cairo bindings?
14:12:49 <yushyin> maybe
14:13:49 <orion> http://projects.haskell.org/gtk2hs/ -- "Error establishing a database connection"
14:14:18 <niko> /10/10
14:14:38 <mniip> hmm, I wonder
14:15:18 <mniip> > let f x y = nub (x:y); a = f 1 b; b = f 2 c; c = f 3 a in (a, b, c)
14:15:24 <lambdabot>  mueval-core: Time limit exceeded
14:15:49 <mniip> hmm, I guess it doesn't reach the []
14:16:05 <maerwald> kadoban: weird, I consider using the Applicative/Monad instance for (->) r deliberately for such simple stuff ugly and obfuscation
14:16:56 <kadoban> maerwald: It's not really great coding practice in some contexts, but it's still cute. Like a puzzle.
14:17:08 <glguy> mniip: I get ([1,2,3^CInterrupted.
14:17:25 <maerwald> kadoban: giving puzzles as solutions is not that great though
14:17:26 <mniip> yeah, it's (1:2:3:undefined, 2:3:1:undefined, 3:1:2:undefined)
14:17:51 <mniip> I can't quite get the layout in my mind,
14:18:38 <mniip> if I have a recursive definition x = f(y), y = f(z), ... z = f(x)
14:18:52 <mniip> I could use a special marker to let f know about recursion
14:19:06 <mniip> e.g, x = R[f(y)], y = f(z), ... z = f(x)
14:19:11 <mniip> how would I need to modify f though?
14:19:54 <kadoban> maerwald: *shrug* I didn't suggest it, and probably wouldn't usually either without a disclaimer. But I'm not really about to argue against it either, I don't care that much.
14:37:08 <joe9> when using haskell gloss, how do I output a static image (I see an option to output to a window. But, nothing to output to a .png or .bmp file.)
14:38:50 <dedgrant> joe9: I see that JuicyPixels supports loading and saving, but the gloss-juicy bindings don't export any saving APIs.  Maybe something that could be added?
14:39:05 <ezyang> Hmm, I still don't understand why lazy bytestrings return int64s 
14:42:54 <joe9> dedgrant: I want to build the Picture using gloss. But, I want a .png or .svg output  and not just displayed in a window.
14:48:04 <hpc> joe9: consider using rasterific
14:48:36 <byorgey> hpc: I don't think that really helps joe9
14:49:14 <hpc> it has an api that's reasonably close to what gloss does and it outputs as a juicypixels image
14:49:46 <hpc> gloss uses a glut or sdl2 windowing system plus opengl rendering
14:49:56 <hpc> so the best you're going to get with that package is pressing printscreen
14:50:00 <mniip> newtype Recursive m a = Rec ((m -> Bool) -> a); instance Functor (Recursive m) where fmap f (Rec g) = Rec (f . g); mark neut m (Rec g) = Rec (\s -> if s m then neut else g (\n -> s n || m == n))
14:50:06 <mniip> why hasn't enyone thought of this before
14:50:17 <byorgey> I don't think the Rasterific API is close to the gloss API at all.
14:50:52 <byorgey> gloss is a DSL for compositionally describing pictures.  Rasterific is a DSL for imperatively describing drawing operations.
14:52:27 <hpc> byorgey: you can use withTransformation to get back composition
14:52:35 <dedgrant> joe9: Unforunately I don't think there is a nicely packaged set of APIs in gloss for saving. You can go to OpenGL and read pixels from the buffers, then use another library to write the data out to various image file formats, but it will be fairly involved :(
14:52:55 <hpc> and gloss's Pictures constructor is sequential
14:53:32 <hpc> byorgey: they present their most basic interface differently, but there's still an easy correspondence
14:53:40 <usr> w/i n35
14:53:43 <byorgey> joe9: check out gelisam's answer in this reddit conversation, perhaps: https://www.reddit.com/r/haskell/comments/3u5s4e/is_there_a_way_to_write_the_frames_of_a_gloss/
14:55:03 <joe9> byorgey: I guess diagrams is my only option. I have used diagrams before and know how it works.
14:55:20 <Tuplanolla> Wouldn't it be easier to put a function that outputs an SVG file as a string after the drawing function?
14:55:22 <byorgey> joe9: sure, I was just going to suggest diagrams
14:55:52 <joe9> from my experienc, gloss seemed easier to use than diagrams. hence, wanted to check gloss out before trying diagrams.
14:56:00 <byorgey> joe9: it's much more complex than gloss of course, but that's the point.  gloss was put together specifically to be simple for beginning students to get started with, it was never intended to have lots of features
14:56:18 <byorgey> joe9: agrees, gloss is much easier to use than diagrams
14:56:22 <byorgey> *agreed
14:56:33 <c821> can someone help me rewrite sumFood using case of? (so that sumCond is no longer required) http://pastebin.com/ihmhuftK
14:56:38 <joe9> byorgey: ok, Thanks.
14:57:01 <byorgey> joe9: feel free to ask questions in #diagrams of course
14:57:03 <hpc> c821: is this homework?
14:57:24 <Tuplanolla> Did you read my comment, joe9?
14:57:26 <hpc> c821: in a real project i would say that's currently better than anything you'd be able to mush up in a single definition
14:57:43 <c821> hpc yeah kind of, you don't need to write it for me, i just need some tips
14:57:57 <c821> i a beginner with haskell
14:58:02 <joe9> Tuplanolla: yes, writing out a string as an svg file.
14:58:25 <Tuplanolla> The operations shouldn't require much translation.
14:58:30 <joe9> Tuplanolla: sounds like a good idea. but, that is what diagrams/gloss do.
14:58:39 <hpc> c821: start by writing sumCond as case-of first
14:58:46 <joe9> Tuplanolla: oh, you mean Show the Picture ?
14:58:51 <Tuplanolla> Yes.
14:58:57 <hpc> c821: and then thanks to referential transparency you'll be able to just substitute that definition in at the call site
14:59:00 <joe9> Tuplanolla: cool, good idea. will try that.
14:59:33 <Tuplanolla> SVG should have enough features that you can just wrap things inside angle brackets and call it a day.
14:59:37 <hpc> c821: basically, splitting the problem into two easier problems ;)
15:00:30 <joe9> makes sense. or, I think there is an lucid-svg  (I think) package
15:00:39 <mniip> is there a nicer way too write (<*>) <$> f <*> x
15:01:00 <Tuplanolla> `liftA2 ap`?
15:01:12 <mniip> hmm, no ap (not Monad)
15:01:20 <howdin> Good evening. Hopefully an easy conduit question. I have `myFilter :: ConduitM Word8 Word8 IO ()` that I would like to use within a conduit of ByteStrings. Is there an easy way to transform a stream of bytestrings into a stream of word8 so I can use it with this function?
15:01:26 <Tuplanolla> Guess: no.
15:01:35 <hpc> liftA2 (<*>) f x
15:02:24 <pavolzetor> hi, i am trying to use this package https://www.stackage.org/haddock/lts-7.12/clustering-0.2.1/AI-Clustering-KMeans.html
15:02:26 <hpc> :t liftA2 (<*>)
15:02:27 <lambdabot> (Applicative f1, Applicative f) => f (f1 (a -> b)) -> f (f1 a) -> f (f1 b)
15:02:40 <pavolzetor> but there is no example
15:02:44 <usr> win 35
15:03:01 <hpc> :t (?x, (<*> ?x))
15:03:02 <lambdabot> (?x::f a, Applicative f) => (f a, f (a -> b) -> f b)
15:03:03 <pavolzetor> and I am stuck at getting the first argument to kmeans fuction
15:03:23 <hpc> mniip: f <*> (<*> x)?
15:03:31 <hpc> :t \f x -> f <*> (<*> x)
15:03:32 <lambdabot> Applicative f => (f (a -> b1) -> f b1 -> b) -> f a -> f (a -> b1) -> b
15:03:37 <hpc> eeew
15:03:49 <pavolzetor> it seems it should be some sort of random generator as kmeans++ needs that
15:03:52 <hpc> :t \f x -> f <$> (<*> x)
15:03:54 <lambdabot> Applicative f => (f b1 -> b) -> f a -> f (a -> b1) -> b
15:04:32 <athan> Is there an Applicate newtype? Something like instance Monad m => Applicative (Applicate m)?
15:05:08 <athan> Well, how do I say this... It pretends to use only Applicative of the Monad 
15:05:16 <hpc> LiftedMonad or something like that
15:05:31 <athan> Ahh thanks hpc
15:05:45 <hpc> you're probably the first person in years to actually need it ;)
15:06:10 <athan> :D
15:06:41 <monochrom> How do you break your pretense by adding my Monad m => Monad (Applicate m) so now I use >>= on it too?
15:06:56 <monochrom> err, there are lots of typos there.
15:07:12 <monochrom> How do you prevent me from breaking your pretense by ... ?
15:07:27 <hpc> monochrom: "applicate" as a verb for "make into an Applicative"
15:07:43 <hpc> i assume athan is on a ghc that predates AMP
15:07:46 <monochrom> Yes yes meaningful names.
15:07:54 <c821> hpc: can you tell me more about the referential transparency?
15:08:31 <monochrom> Even GHC 4.* is not going to prevent my instance.
15:08:51 <athan> monochrom: eh it's just a convenience like Sum
15:09:07 <athan> so you can be confident there's no join operation in the monad
15:09:09 <monochrom> No, it is totally unlike Sum.
15:09:15 <athan> idk there might be a use
15:09:36 <mniip> monochrom, I think they mean newtype Applicate a = Applicate a; instance Monad m => Monad (Applicate m) where pure x = Applicate (return x); Applicate f <*> Applicate x = Applicate (ap f x)
15:09:59 <ezyang> I wonder why bos got rid of the elem function in Text 
15:10:19 <athan> :O ezyang nooooo
15:10:26 <monochrom> I give up.
15:10:40 <athan> thanks monochrom for the advice anyway :)
15:11:16 <monochrom> Monad is an open typeclass, meaning you can never be confident that someone will not add an instance against your will.
15:12:01 <pavolzetor> i use different package; or python
15:12:14 <monochrom> Monoid and Sum are great examples too. The existence of Sum does not prevent me from adding a Max newtype that uses max for <>
15:12:47 <monochrom> And you will not prevent this by "newtype PleaseNoMax a = PleaseNoMax a"
15:13:12 <mniip> I never implied that?
15:13:27 <mniip> I think the original question isn't clear enough on what the author actually wants
15:13:29 <monochrom> No, you didn't, by athan did.
15:13:47 <monochrom> "so you can be confident there's no join operation in the monad" is pretty unambiguous.
15:14:07 <erisco> I have created a 0-64 element set with a Word64. To find the cardinality I count the bits but this is slow. I want to record the length but I have no more room in the Word64. Seeing as I want unboxed data, what are my options?
15:14:58 <ezyang> erisco: There should be quick ways to count bits 
15:15:08 <erisco> it is still too slow
15:15:46 <erisco> counting bits is consuming 25% of my time
15:15:48 <ezyang> even if you can use the POPCNT instruction?! 
15:16:25 <c821> hpc: can you check if this is correct? http://pastebin.com/fwJEwvnc
15:16:38 <erisco> I am using the divide and conquer method as written in Hacker's Delight
15:17:33 <hpc> c821: not quite
15:17:45 <monochrom> I'm hungry. Is Hacker's Delight something edible like Turkish Delight and Greek Delight?
15:17:52 <hpc> c821: when you substitute in the definition of sumCond, you do it replacing where you use sumCond
15:18:10 <erisco> monochrom, it talks about bytes and nibbles a lot, so maybe
15:18:11 <hpc> so right now, sumCond = \food (f, v) -> body of sumCond
15:18:19 <glguy> ezyang: https://github.com/bos/text/commit/a2a45248e6ce7363cbf99c29896940bdef7e99b0 It looks like he prefered going through isInfixOf, an efficient elem version is available via a rewrite rule
15:18:28 <hpc> so you put (\food (f, v) -> body of sumCond) where you previously were using just sumCond
15:18:34 <hpc> it'll get ugly
15:18:41 <mniip> is there a datatype out there somewhere that looks like 'data Cached a b = Cached (a -> b) b' where b is a cached result of (a -> b) at some fixed a?
15:18:43 <erisco> I was looking at https://hackage.haskell.org/package/structs but it is difficult to understand
15:18:44 <hpc> and you'll probably have to do a lot of reformatting
15:19:15 <c821> hpc: so what should i change now?
15:20:29 <ezyang> glguy: Huh, ok 
15:20:43 <ezyang> does it rewrite to elemIndex? 
15:20:54 <erisco> I do not need mutability, I just need a way to have an unboxed struct of a length (an Int8#) and a set (a Word64#)
15:20:59 <ezyang> not obviously 
15:22:13 <ezyang> ugh, text and bytestring don't agree on split naming 
15:22:20 <glguy> ezyang: https://github.com/bos/text/commit/e0ef874e25b06bbb7b1556fd354ac16529f17f4f
15:22:26 <glguy> No helpful additions in that one
15:22:46 <ezyang> yeah it's kind of puzzling 
15:23:40 <monochrom> indeed it's all about deletion :)
15:28:15 <hpc> c821: so, basically what you have now is
15:28:20 <hpc> x = definitionOfX
15:28:30 <hpc> y = something something x something
15:28:47 <hpc> c821: you're substituting x into y, which means you get
15:28:50 <ClaudiusMaximus> erisco: https://hackage.haskell.org/package/base-4.9.0.0/docs/src/GHC.Word.html#line-866 popCount on Word64 should be quite efficient i'd have thought?
15:28:54 <hpc> y = something something definitionOfX something
15:29:25 <hpc> in this case x = sumCond, y = sumFood
15:29:51 <erisco> it is, it is probably using the same method as I am given that we both use the same time
15:30:51 <hpc> and sumCond = \food (f, v) -> what you had before
15:36:23 <c821> hpc: so i should substitute sumCond (the part that i rewrote with case of) into the old sumCond's position in sumFood?
15:45:09 <erisco> despite all the low level tricks employed, the alternative program started out slower and after tweaking has only managed to be on par with the original
15:46:18 <monochrom> yikes
15:47:08 <erisco> I clearly have a lot yet to learn about optimising Haskell code
15:48:23 <monochrom> If you ask for popcount very often, but you have to go through a lot of function-call abstractions before you hit the PNPCNT instruction, it probably sucks.
15:49:16 <hpc> c821: right
15:49:40 <monochrom> It is like your TA is teaching a tutorial (so you shouldn't have to go to school) but you take your 1-hour bus ride to go to school anyway just so you can count how many students show up, and then you take your 1-hour bus ride to go home.
15:50:17 <erisco> the problem is that until you remove all the bricks you won't see much improvement
15:50:28 <erisco> and I am unable to identify all of them, it seems
15:50:37 <c821> hpc: but sumCond now has many lines, how do i format sumFood now?
15:51:17 <hpc> carefully
15:51:23 <hpc> this is the part where it would have been neater before
15:51:54 <monochrom> Actually I wonder why you want to inline sumCond apart from academic curiosity
15:52:17 <monochrom> Because if it's just academic curiosity, you wouldn't worry about formatting.
15:52:38 <erisco> I am going to also write the program in C so I know what my performance target actually is
15:53:39 <c821> seriously i have no idea what to do now lol
15:53:59 <hpc> c821: change it back? ;)
15:54:09 <monochrom> You can always make it one line (but very long): case x of { Apple -> (f+1, v); Orange -> (f+1, v); etc }
15:54:28 <monochrom> And don't forget to add parentheses: (case x of { etc })
15:55:12 <monochrom> It is totally ugly but you wouldn't inline at all in practice to begin with, so the question of "readable practical code" is moot.
15:55:57 <monochrom> The easy way out is to simply pay money to someone to do it for you.
15:56:30 <erisco> it is amusing how fantastically slow Vector is without O2
15:56:40 <c821> sorry but i'm just a beginner and English is not my first language so i'm having a really hard time understanding everything you guys say haha
15:56:42 <recursion-ninja> I got an error: "Could not deduce: m ~ Maybe from the context: (MonadParsec e s m, Token s ~ Char)". I don't use Maybe anywhere in this module. Why am I getting this type error?
15:57:01 <monochrom> Is Vector fast with just O1?
15:57:17 <recursion-ninja> How do I locate which line of code is causing this attempted deduction?
15:57:19 <Koterpillar> recursion-ninja: post code
15:57:37 <Koterpillar> recursion-ninja: replace chunks of code with undefined until the problem goes away :)
15:58:10 <monochrom> It is also possible that the Maybe is inflicted by some code outside.
15:58:22 <recursion-ninja> It would be nice if the compiler could tell me "I think this needed to be deduced to a Maybe because you wrote this over here."
15:58:35 <c821> monochrom: can you help me substitute sumCond into sumFood, i really don't know what to do
15:58:37 <monochrom> Yes
15:59:01 <hpc> recursion-ninja: the error gives a line number
15:59:07 <erisco> monochrom, nope
15:59:26 <recursion-ninja> hpc: And none of those line number involve the type Maybe.
15:59:29 <hpc> recursion-ninja: if you write reasonably-sized definitions with top-level type signatures for what you intend, the error messages should be much clearer
15:59:36 <hpc> and yeah, post code
15:59:44 <monochrom> My rate is cdn$40 per hour.
15:59:55 <erisco> monochrom, I am guessing some magical inlining and fusion and so on goes on in O2
16:00:17 <hpc> recursion-ninja: what generally ends up happening with ghc type errors is that unification creates an equation x = y
16:00:31 <hpc> recursion-ninja: and then ghc has to guess if you wanted to write x instead of y, or y instead of x
16:01:00 <monochrom> Yes O2 does more but I usually suspect that it usually doesn't matter. However I trust them (authors of bytestring, text, etc) when they say it matters in their cases.
16:01:00 <hpc> (the equation thing is not a metaphor, it's actually how unification works)
16:02:25 <orion> I am using the FFI to call a function in which one parameter is of the type "const uint8_t *" It's supposed to be a C-style string. How do I pass a Haskell String to this?
16:02:49 <orion> withCString doesn't seem to be helpful, because it converts to CStrings which are Ptr CChar, not Ptr CUChar.
16:02:51 <c821> ok guys thanks for all the help, i think i should go to sleep, it's 2 already and i can't think much more, i will get back to this sumFood next morning
16:02:53 <c821> bye
16:03:21 <acowley> orion: use withCString, then cast the pointer it gives you
16:03:39 <monochrom> I agree with acowley.
16:04:02 <monochrom> They should be doing char* not uint8_t* in the first place.
16:04:10 <recursion-ninja> hpc: It was a namespace collision. Shadowed bindings. I figured it out when I added more compilation warning flags.
16:04:45 <hpc> ah, that'll do it
16:05:12 <hpc> i imagine it's something like when you write naive database code in haskell and use identifiers named "id" everywhere?
16:05:27 <monochrom> The problem with meaningful names. There are so few meaningful names, you will have name clashes. And because they are so meaningful, you don't even realize you have name clashes.
16:05:36 <ClaudiusMaximus> orion: perhaps you want to go via Text and ByteString with an appropriate encoding too (eg UTF-8)  i think withCString silently truncates?
16:06:59 <recursion-ninja> hpc: I had a custom parser combinator 'nonEmpty :: m a -> m (NonEmpty a)' which was shadowed by Data.List.NonEmpty.nonEmpty
16:07:17 <hpc> monochrom: clearly haskell should use a naming scheme more like https://support.microsoft.com/en-us/kb/269181
16:07:17 <recursion-ninja> hpc: The Maybe was coming from the latter definition.
16:07:40 <monochrom> No, withCString uses your locale to determine whether it's UTF-8 or funny things etc.
16:08:06 <monochrom> withCAString is the one truncating to iso-8859-1
16:08:19 <ClaudiusMaximus> monochrom: oh glad to be enlightened :)
16:08:56 <recursion-ninja> hpc: That naming seems like a terrifying idea.
16:08:59 <monochrom> This is several-years-recent. withCString used to be iso-8859-1 a long time ago, when I learned Haskell.
16:09:58 <monochrom> OTOH "current locale" can also be a pretty fragile and uncertain thing, you may not like it.
16:10:29 <monochrom> As in, if you're in a Windows console, it is going to be funny thing like windows-1252.
16:11:27 <hpc> also you'll have a hell of a time interacting with anything that isn't testing the same locale
16:11:40 <hpc> like maybe another user on the same machine with a different locale
16:11:55 <hpc> now to pass information you need to convert it
16:15:00 <kadoban> Heh ... my heap implementation performs >10x as bad on a sorted list as it does on a reverse sorted one. That's unfortunate.
16:15:17 <unskill> :(
16:38:07 <kadoban> Hah, and the main way I'm actually using this heap uses it in sorted-ish order xD *grumble grumble*
16:39:30 <hpc> it's obvious
16:39:34 <hpc> reverse your heap property
16:40:56 <kadoban> Ya, that'd fix that. I want to more generally improve it though. Really just messing around with profiling and such ...
16:43:14 <hpc> oh i was actually joking, i figured you picked the heap property the way you did to get something out of it ;)
16:44:27 <kadoban> Well, I think I could reverse it *inside* the heap and get to switch which case my structure handles well while still getting the same output, but maybe I'm misthinking that.
16:55:03 <ByronJohnson> Ls
16:57:58 <pavolzetor> UA.listArray ((0, 0), (3600, 3600)) . runGet (replicateM ((3601*3601)) getInt16le)
16:58:27 <pavolzetor> this kills my machine
16:58:43 <pavolzetor> basically it exhaust all RAM
16:59:06 <pavolzetor> I do not get why
16:59:45 <pavolzetor> the memory usage should be around 25 MB
16:59:47 <monochrom> replicateM for most monads is going to build the whole list.
17:00:18 <monochrom> > 3601*3601*16
17:00:20 <lambdabot>  207475216
17:00:47 <pavolzetor> interesting
17:00:49 <monochrom> No, 200MB.
17:01:13 <pavolzetor> it is 2 bytes per value
17:01:23 <pavolzetor> on disk it is 25 MB
17:01:50 <pavolzetor> what is better approach to read it?
17:01:51 <monochrom> Do you believe that Haskell data structure mimicks your file format?
17:02:19 <pavolzetor> unsure, basically it is brick of 16 bit signed ints
17:02:45 <monochrom> OK, in the future please tell me what you're sure of only.
17:02:46 <pavolzetor> lets say it does not, how would one go about it?
17:03:18 <pavolzetor> okay, the data is 3601*3601 of shorts comprising a heightmap
17:03:33 <pavolzetor> i need to read it preferably int a 2d array
17:03:45 <pavolzetor> *in to
17:04:12 <monochrom> You are going through a list, and it happens to be a list built fully before being consumed and thrown away. So let's take a look at how much space it takes.
17:04:42 <monochrom> You are looking at "data L a = Nil | Cons a (L a)" except for syntax. 
17:05:12 <pavolzetor> 3601*3601*(3*8 + 8+2)
17:05:35 <pavolzetor> > 3601*3601*(3*8 + 8+2)
17:05:37 <lambdabot>  440884834
17:06:08 <monochrom> In "Cons a (L a)", the Cons tag takes 64 bits, the "a" pointer takes 64 bits, the "L a" pointer takes 64 bits. This is already 24 bytes. This hasn't count the actual 16-bit numbers you store yet.
17:07:17 <pavolzetor> are those 16bit numbers boxed by default?
17:07:46 <monochrom> For Int16 you're looking at "data Int16 = Int16# (a field that stores the actual number)". The Int16# tag takes 64 bits, the number field takes 64 bits because alignment. (Do not yell at me on how only 16 of them are used, I already know that, don't I?)
17:08:00 <monochrom> So you're looking at:
17:08:16 <monochrom> > 3601^2 + (24 + 16)
17:08:18 <lambdabot>  12967241
17:08:27 <monochrom> > 3601^2 * (24 + 16)
17:08:28 <lambdabot>  518688040
17:09:13 <monochrom> That is not the end. Before GHC uses a garbage collector that does double-buffering, the memory footprint is usually twice that.
17:09:18 <pavolzetor> interesting, I did not know about padding
17:09:26 <monochrom> Do you happen to have 1G RAM free?
17:09:30 <pavolzetor> no
17:09:39 <monochrom> s/Before/Because/
17:10:16 <monochrom> What you should do, is to either go through a lazy list, or no list at all.
17:10:35 <pavolzetor> I have 4 GB on the system and other parts consume RAM (parsing of JSON) and then firefox showing data
17:10:38 <monochrom> replicateM on the Get monad is not going to do lazy list.
17:11:32 <pavolzetor> how would I construct the array without the list?
17:11:39 <monochrom> conduits and pipes may help, but I don't know them.
17:11:55 <erisco> well, my C program very quickly crashes
17:12:25 <Cale> I think unboxed Vector might help
17:12:30 <monochrom> Another option is to start with a mutable array first. When you finish reading the file and writing to the array, there is a "freeze" function to lock it into an immutable array.
17:12:30 <Cale> You could use generate
17:12:45 <Cale> (even with immutable Vector)
17:13:05 <monochrom> Yes, another option is to use the vector library and read its doc and read all its functions and see your options.
17:13:07 <Cale> Oh, sorry, I missed part of the context here
17:13:20 <ClaudiusMaximus> pavolzetor: depending what you need to do with your arrays once you load them, maybe repa is an option; see https://hackage.haskell.org/package/repa-io-3.4.1.1/docs/Data-Array-Repa-IO-Binary.html for some "just load this data as an array" stuff; or look at the source for inspiration how to port it to storable vectors
17:13:29 <monochrom> there is a "generateM" or something like that too
17:13:33 <Cale> yeah
17:13:55 <Cale> That's what you need -- it can run in the Get monad
17:14:29 <pavolzetor> what is "generate"?
17:14:42 <monochrom> read the docs of vector
17:15:08 <pavolzetor> thanxs
17:18:06 <Cale> pavolzetor: http://hackage.haskell.org/package/vector-0.11.0.0/docs/Data-Vector-Unboxed.html#v:generate if you were having trouble finding it
17:18:34 <Cale> pavolzetor: See also generateM just below, which is what you probably really want, given that you're using Get.
17:18:54 <pavolzetor> Thanks, I found it. I am exploring if the repa will work
17:19:09 <pavolzetor> as I want to avoid rewriting the array lookups
17:19:42 <Cale> Ah, you're using indices which aren't Int values?
17:19:50 <monochrom> It is true that repa also provides many other speedy operations you will like.
17:20:38 <Cale> You should be able to rig up something with the Ix operations fairly easily if you want them. https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.9.0.0/Data-Ix.html
17:20:59 <pavolzetor> Cale: yes, I can write f to convert to linear order
17:21:01 <Cale> index :: (Ix a) => (a, a) -> a -> Int  will compute the index for you
17:21:22 <Cale> > index ((0,0),(100,100)) (64,12)
17:21:25 <lambdabot>  6476
17:21:53 <pavolzetor> great, this seems least painful
17:36:21 <pavolzetor> runGet (V.generateM ((3601*3601)) (\_ -> getInt16le))
17:36:27 <pavolzetor> did not help
17:36:36 <pavolzetor> I am trying unboxed now
17:37:02 <pavolzetor> how do you decide if to use array or vector?
17:37:47 <c_wraith> Generally, you just go with "use vector", unless there's some huge in-your-face reason not to
17:39:13 <Braunscheisse> hi guys
17:39:22 <Braunscheisse> I like to feel hot salty cum shoot into my mouth
17:39:39 <monochrom> perhaps it's replicateM not generateM
17:39:54 <Braunscheisse> monochrom  do you like to suck dick too?
17:40:01 --- mode: ChanServ set +o monochrom
17:40:04 <Braunscheisse> i especially like hairy uncircumsized ones
17:40:05 --- mode: monochrom set +b *!*@46.45.177.99
17:40:05 --- kick: Braunscheisse was kicked by monochrom (Braunscheisse)
17:40:40 --- mode: monochrom set +b-b $a:BraunScheisse *!*@46.45.177.99
17:40:47 --- mode: monochrom set -o monochrom
17:46:06 <pavolzetor> let me try it
17:51:36 <pavolzetor> still exhaust memory
17:53:02 <monochrom> that's strange and bad.
17:57:27 <pavolzetor> if I change the dimensions to something small, it consumes little memory
17:57:46 <pavolzetor> so it is definitely that parsing
17:59:32 <pavolzetor> what next thing to try?
17:59:41 <pavolzetor> readInts16 = runGet (VU.replicateM (3601*3601) getInt16le)
17:59:50 <pavolzetor> above is the current code
18:01:53 <digitalmentat> does anything in the cabal and ghc toolchain perform stripping of build products by default?
18:03:42 <monochrom> "cabal install" does
18:04:31 <monochrom> I forgot whether "cabal build" does.
18:04:34 <digitalmentat> monochrom, can I disable it via the .cabal config file?
18:05:21 <monochrom> yes, look for "-- executable-stripping: True"
18:05:54 <digitalmentat> got it, thanks
18:06:01 <digitalmentat> monochrom, I appreciate the help
18:06:22 <monochrom> you're welcome
18:08:10 <geekosaur> iirc stack always strips? unless they fixed that within the past week or so (was an open bug on it because ghc HEAD can actually use the debug info; don't recall if that is getting into 8.0.2)
18:15:44 <dazednconfused> hello room
18:17:45 <lambdafan> I have a Map Foo Bar that I want to traverse and compute a [(Baz,Bin)]. I'm playing around with traverse but I'm not getting the right results. Is traverse what I want, or some other function?
18:18:40 <erisco> the C version runs in 0.67% of the time of the Haskell version ... this is surprising to me
18:20:12 <Rotaerk> the C version of what
18:20:26 <erisco> the original Haskell version uses Map and Set and so on, all the easy straight-forward stuff
18:21:22 <erisco> my attempt to optimise the Haskell version switches to using a bit field for sets and mutable unboxed arrays, but the speed is just the same
18:21:38 <erisco> then the C version is only 0.67% of the time, and it clearly has no fanciness at all
18:21:44 <pacak> lambdafan: toList ?
18:22:14 <pacak> erisco: Did you tried profiling? Or compiling with optimizations enabled?
18:22:19 <erisco> both, yes
18:22:33 <lambdafan> toList would require the result to be [(Foo,Bar)], I want [(Baz,Bin)]
18:23:05 <monochrom> lambdafan, I'm pretty sure no one understands the question.
18:23:15 <pacak> lambdafan: and map
18:24:30 <kadoban> lambdafan: Where Baz and Bin are ... what?
18:24:44 <lambdafan> monochrom: I have a Map Foo Bar. I want to do *something* list toList, except my conputation will result in a [(Baz,Bin)], not a [(Foo,Bar)]
18:25:07 <lambdafan> kadoban, other types that aren't Foo or Bar.
18:25:13 <lambdafan> I'm trying to stay generic
18:25:22 <Koterpillar> lambdafan: const [] :: Map Foo Bar -> [(Baz, Bin)]
18:25:35 <dfeuer> lambdafan, you probably want to map something over the result of toList.
18:25:39 <Koterpillar> lambdafan: in other words, how are you using Foo and Bar to get (Baz, Bin)?
18:25:48 <dfeuer> or, better,
18:25:53 <dfeuer> use foldrWithKey.
18:25:57 <dfeuer> Yeah.
18:26:00 <pacak> :t unsafeCoerce :: Map Foo Bar -> [(Baz, Bin)]
18:26:01 <lambdabot> error:
18:26:01 <lambdabot>     Not in scope: type constructor or class ‚ÄòMap‚Äô
18:26:01 <lambdabot>     Perhaps you meant ‚ÄòM.Map‚Äô (imported from Data.Map)
18:26:10 <lambdafan> specifically, my Map is a Int [Int], that I need to be a (Text,[Text])
18:26:18 <dfeuer> Er...
18:26:20 <dfeuer> Yeah.
18:26:40 <dfeuer> lambdafan, use foldrWithKey. That will definitely be sufficient.
18:27:10 <dfeuer> You can also get away with just using map yourFavoriteFunction . toList
18:27:48 <lambdafan> I was trying to avoid using toList, but will if I have to :)
18:27:48 <dfeuer> (where toList is the one in Data.Map, *not* the somewhat different one in Data.Foldable)
18:27:56 <lambdafan> it seemed more expensive that nessecary
18:27:57 <dfeuer> You don't have to.
18:28:01 <dfeuer> You can use foldrWithKey!
18:28:21 <lambdafan> I'm looking into foldrWithKey :)
18:29:26 <pavolzetor> I cant get it to consume less memory
18:29:30 <lambdafan> dfeuer: thanks that's what I wanted. :)
18:29:38 <pavolzetor> is there a simple way to do fread?
18:30:03 <dfeuer> Great, lambdafan.
18:30:33 <pavolzetor> something like, give me address of the vector and directly write to that memory address
18:30:53 <pavolzetor> the data.binary is useless it seems
18:31:40 <dazednconfused> Hi guys. I'm trying to write a function to unify two expressions but I'm stuck in an infinite recursion. I'm a newb so can someone experienced please give me some advice?
18:31:58 <lpaste> dazednconfused pasted ‚ÄúStuck in a recursive loop‚Äù at http://lpaste.net/349651
18:33:18 <dazednconfused> Once i unite the forst two terms and obtain a new substitution list, i want to apply it on the whole list and proceed to unite the next two terms
18:33:59 <savrem> can hoogle search for packages that list a specific package as a dependency?
18:34:46 <kadoban> savrem: I think if you look on hackage at the package it tells you what depends on it
18:35:02 <erisco> I guess the only explanation is that I am overvaluing the significance of accessing and updating the map versus the array
18:35:49 <erisco> they must both be drowned in other costs
18:35:55 <erisco> as well as the C version
18:38:03 <kadoban> Playing around with criterion is far too much fun
18:38:33 <geekosaur> savrem, I think you want http://packdeps.haskellers.com/reverse ?
18:39:48 <Koterpillar> that should really exclude acme-everything...
18:39:56 <Sinestro> When working with type-level Bool, is there any way to get GHC to examine the types deeper? It's getting to a point of If ((A == A) && (B == B)) C D but can't work out that the predicate is true and C is the result
18:40:37 <savrem> geekosaur, that is what I was looking for, thanks!
18:45:15 <erisco> another thing I may be forgetting is that you have to load instructions as well, not just data
18:47:08 <erisco> I wonder if the divide and conquer bit count really is faster for 64 bits, due to how many 64 bit words it has to load
18:47:13 <erisco> for masking
18:49:55 <Sinestro> Never mind, it turns out that having an a == b instance for the kind at hand is helpful. WEIRD
18:53:15 <erisco> haha, well, the loop version multiplied execution time by 4 XD
18:54:18 <erisco> will try cached counts now...
18:55:13 <pacak> :t popCount
18:55:14 <lambdabot> Bits a => a -> Int
18:55:27 <pacak> > popCount (14 :: Int)
18:55:29 <lambdabot>  3
18:55:32 <erisco> I am aware
18:55:49 <pavolzetor> i will report bug for the replicateM case as it should use less memory
18:55:50 <pavolzetor> https://gist.github.com/nkpart/d884dc2d400adc05cb57
18:56:12 <pavolzetor> for anybody doing this, above link has byteStringToVector
18:56:25 <pavolzetor> that works as expected
19:00:18 <pavolzetor> thanks all for help :)
19:04:32 <ezyang> this is odd, why aren't there any instances for Show for Text 
19:04:57 <ezyang> see here: https://hackage.haskell.org/package/text-1.2.2.1/docs/Data-Text.html#t:Text 
19:05:28 <ezyang> ditto on Stackage: https://www.stackage.org/haddock/lts-7.12/text-1.2.2.1/Data-Text.html#t:Text 
19:06:09 <ezyang> agh! They're orphans?! 
19:07:08 <Koterpillar> instance Show Text -- Defined in ‚Äòtext-1.2.2.1:Data.Text.Show‚Äô
19:16:43 <erisco> caching the count made it slower D:
19:17:30 <kadoban> erisco: What code/problem are you working on?
19:20:59 <erisco> kadoban, it is part of a constraint solver. I just have it counting all solutions with no constraints
19:21:14 <erisco> so it is basically how fast it can compute the factorial
19:24:34 <erisco> and one of the biggest costs, amusingly, is counting how many elements are in a set
19:25:46 <kadoban> How is the set implemented?
19:25:59 <erisco> it is a 64-bit word
19:26:17 <kadoban> Oh, so it's just counting how many bits are set?
19:26:24 <erisco> yes
19:26:36 <erisco> it isn't going to get any faster than it is, so I just have to find ways to do less counting
19:28:25 <kadoban> erisco: http://graphics.stanford.edu/%7Eseander/bithacks.html#CountBitsSetNaive <-- you know about these?
19:28:50 <kadoban> Not exactly revolutionary algos for this, but maybe one you haven't thought of
19:33:00 <erisco> I am using the "Counting bits set, in parallel" method
19:33:17 <erisco> I can shave a few instructions off of it
19:33:39 <erisco> though perhaps I'll try the lookup table
19:37:17 <erisco> the lookup table is marginally faster than my not quite optimal parallel algo
19:37:57 <kadoban> Interesting
19:40:12 <erisco> Brian Kernighan's algorithm is substantially faster
19:40:35 <erisco> this is being influenced strongly by my test case which only uses 9 element sets out of a possible 64 element set
19:41:04 <erisco> however, as the solver works, the sets will decrease in size, and so perhaps it overall can still win
19:41:26 <kadoban> That's fairly surprising, I would have guessed that one was pretty bad in practice.
19:41:41 <erisco> the naive method is ludicrously slow, multiplying execution time of the whole program by 4, and this degenerates to the naive method
19:42:55 <kadoban> Can you do something cute like switch which algo you use as the solver works?
19:44:20 <mniip> I might have come up with something real fancy!
19:49:22 <erisco> I am not sure. It isn't obvious to me how to do it at no cost
19:52:14 <erisco> by "substantial" I mean it took it from ~55% running time to ~%33 running time (compared to the Haskell version)
19:52:37 <erisco> the Haskell version is using the parallel counter
19:52:57 <erisco> the improvement I was looking for was more like an order of magnitude
20:17:20 <kadoban> Is there any cute tooling to do something like criterion, but I want to see the changes in the report after I change code. So, comparing criterion outputs over time maybe?
20:21:38 <grantwu> I need to adapt my compiler to use LLVM on the backend for a class, but can't use the LLVM bindings
20:21:46 <grantwu> Is shelly the best way to invoke the CLI tools?
20:29:30 <mekeor> yo, what do you think about my new library for pretty printing tables? :D take a look at the examples ‚Üí https://github.com/mekeor/hable
20:30:08 <tnks> man, I wish there was a Data.Aeson.TH that was based on explicit dictionaries, rather than type classes.
20:30:32 <tnks> saying there's one and only one JSON representation for a class seems wrong.
20:30:38 <mekeor> PS: unicode box characters look nicer in the terminal than on github
20:30:53 <ogkloo> mekeor: Nice, much more readable than list vomit
20:30:53 <tnks> sorry, I not class -- data type (slip)
20:35:16 <tnks> wait, I see stuff about Encoding now in the library.
20:35:33 <tnks> maybe just need to read the docs more.
20:37:33 <tnks> hmm, I think maybe Encoding stuff more more internal.
20:51:13 <kadoban> Oh good, criterion is getting NaN for some numbers on output and it's screwing up the output HTML :-/ that's annoying.
20:59:53 <ertes> mekeor: pro: good coding style; con: desparately needs haddock comments =)
21:00:34 <mekeor> ertes: haha, yeah, it's on the todo-list. thanks =)
21:01:06 <ertes> mekeor: better do it sooner than later: https://www.haskell.org/haddock/doc/html/index.html
21:01:17 <ertes> it's surprisingly easy
21:01:37 <mekeor> i know, but it's late here. shit. it's 6 am. fuck
21:01:48 <ertes> sure =)
21:23:29 <BaneAliens> "Generally, you will have to split the list into two smaller lists, put the new element to in the middle, and then join everything back together.‚Äù
21:23:33 <BaneAliens> how do you split a list???
21:24:16 <kadoban> BaneAliens: What's this for?
21:24:31 <BaneAliens> oh duh, there is a builtin function, splitAt
21:24:40 <BaneAliens> kadoban: remember how I said I had a week to learn everything about haskell?
21:24:48 <kadoban> Haha, yes.
21:24:50 <kadoban> How's that going?
21:24:54 <BaneAliens> instead of a week, it‚Äôs 2 days
21:25:00 <kadoban> Uh oh :)
21:25:01 <BaneAliens> going terribly
21:25:17 <kadoban> :(
21:27:03 <BaneAliens> so yea I am doing practice homework problems to prepare
21:28:00 <kadoban> Sounds like a good idea
21:30:13 <ab9rf> is this some sort of hazing exercise?
21:30:29 <kadoban> I think it's a procrastination exercise
21:33:32 <BaneAliens> naw, Professor lectured it for a week, the prior weeks were spent on prolog
21:33:52 <BaneAliens> though it‚Äôs my fault for not studying haskell over the summer like I should have 
21:36:22 <kadoban> Oh is that it? Then you can't be expected to know a whole lot.
21:36:53 <BaneAliens> expectations are high
21:41:33 <BaneAliens> doing permutations of tuples is pretty easy in haskell
21:41:37 <BaneAliens> [(x,y) | x<-[1..3], y<-[1..2]]
21:42:04 <Axman6> > (,) <$> [1..3] <*> [1..2]
21:42:07 <lambdabot>  [(1,1),(1,2),(2,1),(2,2),(3,1),(3,2)]
21:42:19 <Axman6> > (,,) <$> [1..3] <*> [1..2] <*> [6..9]
21:42:21 <lambdabot>  [(1,1,6),(1,1,7),(1,1,8),(1,1,9),(1,2,6),(1,2,7),(1,2,8),(1,2,9),(2,1,6),(2,...
21:42:46 <BaneAliens> impressive
21:43:01 <Axman6> not quite permutations, more like cartesian product
21:44:33 <Guest29375> Anyone here?
21:45:19 <Koterpillar> > pure "a few people" :: Maybe String
21:45:21 <lambdabot>  Just "a few people"
21:45:53 <sras> What is a good Haskell lib for creating html emails that is a bit more high level that the Mime.Mail library?
21:47:09 <Guest29375> Are there any other lively channels?
21:47:34 <BaneAliens> Guest29375: I‚Äôm here, I can help
21:47:37 <Koterpillar> Guest29375: yes, but what do you want to talk about?
21:47:47 <glguy> This isn't a network directory
21:48:07 <Guest29375> I want to connect with other hackers.
21:50:11 <BaneAliens> Guest29375: you sire are connected
21:53:03 <BaneAliens> when you write a function signature like this ‚Äúaverage :: Float -> Float -> Float‚Äù Since output can only have well.. one output, the first Floats are considered input always right?
21:54:11 <kadoban> BaneAliens: That's one way of looking at it, yes.
21:54:49 <glguy> The first two Float types are in a "negative" position, so you can think of them as inputs
21:54:58 <glguy> f :: (Int -> a) -> a; f g = g 10
21:55:17 <glguy> consider the type of f, you might consider the Int an output
22:04:21 <BaneAliens> I‚Äôm not sure what you mean by ‚Äúnegative‚Äù position?
22:04:42 <Axman6> BaneAliens: you should read that type as Float -> (Float -> Float), given a float, return a function which, when given a float, returns a float
22:04:50 <BaneAliens> and for that function f, to me it reads to me as a function that takes no input and outputs an int
22:05:11 <ab9rf> "a function that takes no input"? isn't that just a value?
22:05:22 <BaneAliens> ab9rf: uhh yea you are right
22:05:55 <ezyang> What would you say that asymptotic complexity of 'xs ++ [x]' is? 
22:06:10 <ezyang> The obvious thing is O(n), but I feel like you could make an argument for amortized O(1) 
22:06:20 <ab9rf> O(size(xs)) + O(size(x))
22:06:26 <glguy> If you trace your way through a type keeping track each time you move to the "left side" of an arrow (->) you can determine if an argument is in a "positive" or "negative" position
22:06:32 <glguy> you start with positive (output)
22:06:32 <Axman6> the size of x has nothing to do with it
22:06:36 <ab9rf> sorry, yeah, it doens't
22:07:08 <ab9rf> iirc, xs ++ [x] always has to evaluate the entire spine of xs
22:07:21 <glguy> so:   A -> (B -> C)   is one the whole in a positive position, go down one arrow and you have A in a negative position (input) and B -> C in a positive one
22:07:29 <glguy> go down again and you ahve B in negative, and C is positive
22:07:32 <ezyang> but if you claim it's amortized O(1), it's obvious that if you repeatedly apply this, in the end you'll pay O(k) (where k is the number of applications) each cons cell you force 
22:07:34 <Axman6> well no, if you run head on that, it'll only cost slightly more than calling head hx would have
22:07:45 <ab9rf> the compiler may be able to avoid retraversing xs, but you're depending on the compiler realizing that it can do so
22:07:57 <Axman6> ezyang: laziness is hard :(
22:08:15 <ezyang> sloppy terminology is sin 
22:08:20 <ezyang> I wonder if Okasaki properly addresses this 
22:08:27 <ab9rf> it very much depends on how much of xs ++ [x] you ultimately evaluate
22:08:39 <Axman6> like, if you run m (++[x])'s, you're pauing O(m) for each (:) you evaluate right?
22:08:48 <ab9rf> and then you have to talk about space complexity for all the stored thunks
22:08:49 <Axman6> paying*
22:08:50 <ezyang> Axman6: Right 
22:09:18 <Axman6> aftually, big-O notation is about worse case, so it must be O(n) right?
22:09:39 <Axman6> in the worse case, where you evaluate the whole list, you pay O(n) cost
22:09:50 <kadoban> big-O notation isn't really about worst case. It's about whatever you say it is.
22:10:37 <Axman6> but in the best case you pay O(0) by not evaluating anything
22:17:41 <ezyang> Maybe the answer is, it's not amortized O(1), because the distribution of work in a lazy setting has nothing to do with amortization 
22:18:00 <ezyang> you're not paying off cost of op using credits you saved up 
22:24:26 <kadoban> I'm not sure it makes sense to ask the cost of (++) in isolation. You can either assume it's strict, in which case it's Œò(n) in the size of the first list, or you have to consider it in the context of if you're actually using the result or not, or how much of the result you're using.
22:25:10 <ezyang> well, the cost of ++ is very clear; you pay O(1) for every element of the first list's spine you force 
22:25:28 <ezyang> There's just... not a concise way of stating this 
22:25:33 <kadoban> Ya
22:26:17 <kadoban> It seems like mostly people just assume stuff is strict when giving costs, which is a bit weird honestly.
22:26:28 <kadoban> But maybe just for concision? *shrug*
22:30:18 <ezyang> OK 
22:30:36 <ezyang> I hereby dub (++) to be "lazy O(n)", and reverse to be "strict O(n)" 
22:31:35 <kyousanshugi> i'm reading http://www.haskellforall.com/2012/08/the-category-design-pattern.html and i'm confused about a statement there
22:31:51 <liste> kyousanshugi: which statement
22:32:04 <kyousanshugi> it says that categories obey the left and right identity laws (`id . f = f` and `f . id = f`)
22:32:22 <kyousanshugi> and then it says that the definition of a category does not say anything about what `id` is
22:32:47 <kyousanshugi> but if `id . f = f` and `f . id = f` then that appears to me as if `id` has to be a no-op?
22:33:07 <kyousanshugi> because if you can just take it away and nothing changes, then it did nothing
22:34:12 <glguy> the point being made is that you don't get to assume anything about what id is other than that it satisfies the given identity laws
22:34:14 <kyousanshugi> (i barely got through secondary school mathematics, so apologies if i'm being silly here)
22:34:29 <BaneAliens> okay I have an idea of how to insert into an ordered list. Write a function to find the placement, then do the split and merge, ez pz
22:34:44 <glguy> "no op" assumes more than what categories promise to be, they don't have to have "ops"
22:41:48 <kyousanshugi> glguy: okay, just spent 6 minutes thinking about your reply lol. i think i understand now. thank you.
22:49:41 <evvq> Am I missing an existing `newtype EndoKleisli`?
23:23:37 <jle`> it'd be nice
23:23:41 <jle`> i've wanted one for a while
23:23:46 <jle`> but yeah there is none in base
23:26:28 <Axman6> BaneAliens: a probably simpler way to do that would be to iterate over the list until you find an element which is larger than the element you want to insert and then put the element there. no need to split
23:26:56 <BaneAliens> posted in #haskell-beginners but this is what I ended up doing http://lpaste.net/349653
23:28:57 <nshepperd> . o O (it should really be 'data Endo c a = Endo (c a a)', then 'Endo Kliesli a')
23:30:06 <jle`> and the normal Endo can be Endo (->).  sounds cool.
23:30:17 <jle`> oh and Endo (Kliesli m) a
23:30:42 <M2tias> skrollin fb-postauksessa p√∂it√§is varmaan olla "galaktista menoa"
23:32:49 <nshepperd> er, yeah that
23:33:05 <M2tias> oops, wrong channel :D
23:34:14 <jle`> i have definitely wanted to mconcat a bunch of (a -> m a)'s or foldMap them several times
