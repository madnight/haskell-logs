00:00:02 <bollu> cocreature: how do I ask stack to compile with DWARF info?
00:00:12 <cocreature> --ghc-options=-g should do the trick
00:02:38 <cocreature> bollu: if you can’t figure it out, ping me again and I’ll try looking into it (when I find the time)
00:03:56 <bollu> cocreature: sure
00:04:00 <bollu> cocreature: much appreciated :)
00:22:06 <riaqn> Hi, I'm looking for language model for preemptive multi-tasking, like continuation is model for cooperative multi-tasking.
00:26:50 <liste> riaqn: thread?
00:27:13 <liste> or do you means something like Communicating Sequential Processes
00:29:12 <riaqn> liste: yes, thread. but this is just a thin wrapper around OS thread. I was king of looking for more things implemented by language itself. Say, we can only register a hook with a timer, and implement a whole set of thread facility.
00:30:26 <riaqn> preemptive means there are timers and interruptions.
00:30:58 <bollu> okay what the fuck, I'm this close to giving up :(
00:31:10 <bollu> I can't for the life of me figure out where memory is getting corrupted
00:32:41 <ClaudiusMaximus> bollu: are you compiling with -threaded and the foreign code is not thread safe?  /guess
00:33:09 <bollu> ClaudiusMaximus: I added a CMAKE flag to force it to be thread safe
00:33:16 <bollu> ClaudiusMaximus: unless I messed up CMAKE generation
00:33:53 <EvanR> riaqn: also pi calculus
00:34:30 <riaqn> EvanR: sorry I wasn't clear. Please see my following explantions.
00:35:09 <riaqn> Or: what is a good language abstraction of timers and interruptions?
00:37:36 <EvanR> riaqn: well theres this https://github.com/evanrinehart/interruption
00:38:49 <riaqn> EvanR: Thanks! I will have fun after I get the answer to my question.
00:39:09 <ClaudiusMaximus> riaqn: GHC Haskell has  forkIO, threadDelay, throwTo, catch  not particularly elegant/minimal/pure - you could probably build something semantically nicer on top if you're careful about masking and so on
00:39:11 <EvanR> the spirit of this is that all processes or threads choose (in zero time) an action and future time to do it
00:39:39 <EvanR> but only the soonest time wins, which is interpreted as interrupting everyone else
00:40:23 <EvanR> its an abstraction over preemptively multitasked concurrency, plus real life users
00:40:59 <riaqn> EvanR: wow, I didn't realize the deep meaning. 
00:41:05 <riaqn> EvanR: I will check it out.
00:41:17 <EvanR> i brought it up because its literally what you were asking about
00:41:25 <EvanR> unless i still dont get it
00:43:02 <riaqn> EvanR: lucky me, rushing into a person having the answer.
00:43:38 <bollu> cocreature: okay, minimal test case: literally creating them and doing nothing with them
00:44:56 <bollu> cocreature: https://github.com/bollu/symengine.hs/blob/master/test/Spec.hs#L75
00:45:10 <bollu> and everyone ^ my FFI code is dying, I'm simply creating objects and then releasing them
00:45:42 <bollu> oh wait no
00:50:18 <bollu> OMFG
00:50:19 <bollu> I want to shoot myseflf
00:50:19 <bollu> it was divide by zero
00:50:22 <bollu> it was divide. by. fucking. zero
00:50:42 <bollu> the FFI simply crashes if you try to divide by zero
00:50:42 <bollu> :(
00:50:56 <bollu> thanks for all the help guys
00:51:02 <EvanR> division by zero in C
00:51:04 <bollu> (not sarcastic) :)
00:51:09 <EvanR> dont try this at home
00:51:23 <bollu> EvanR: yeah, the library is a symbolic math library though. it's "supposed" to return a runtime error and not peace out
00:51:36 <EvanR> oh really
00:51:39 <bollu> yeah
00:51:46 <bollu> so I guess it's time to file a bug report
00:51:46 <EvanR> what does it do?
00:52:10 <bollu> EvanR: it's supposed to return an enum with SYMENGINE_DIVIDE_BY_ZERO. right now, it crashes best I can tell
00:52:22 <bollu> EvanR: maybe I'm messing up my contract
00:52:25 <bollu> EvanR: let's see :)
00:52:35 <EvanR> then maybe the issue is elsewhere
00:52:39 <bollu> perhaps
00:52:45 <bollu> no, but I can repro the crash consistently
00:52:54 <bollu> if I remove the "multiplicative inverse" test case
00:52:56 <bollu> it doesn't crash
00:53:02 <bollu> even for 500000 inputs
00:53:17 <EvanR> do you have a minimal C program using this lib and fails to return that error code, and just crashes
00:53:28 <bollu> yes, now I'll work on that
00:53:42 <bollu> EvanR: I think I'm not handling the exception correctly on the haskell side
00:53:58 <bollu> EvanR: I was sloppily coding to "get minimal version done". Serves me right
00:54:04 <bollu> EvanR: OK, time to go back and catch all exceptions :)
00:55:59 <delYsid> Is there a way to parallelize Alternative?
00:56:28 <EvanR> exception?
00:56:53 <EvanR> i didnt know FFI threw exceptions
00:57:15 <bollu> EvanR: uh, well, it returns an int code
00:57:23 <bollu> EvanR: it does this by catching the actual C++ Exception
00:57:28 <EvanR> C++ o_O
00:57:35 <bollu> EvanR: and inspecting it (to see what the return code should be)
00:57:41 <bollu> EvanR: the FFI is a C wrapper around C++ code, yes
00:57:51 <bollu> EvanR: so it's haskell <—> C <—> C++
00:58:09 <ClaudiusMaximus> bollu: -Wall can help you track down unused return values in the middle of do blocks
00:58:16 <lyxia> delYsid: b `par` (a <|> b) ?
00:58:26 <bollu> ClaudiusMaximus: interesting
00:58:50 <ClaudiusMaximus> -Wunused-do-bind or similar
00:58:58 <bollu> lyxia: I don't know what I'm talking about , but doesn't Haxl let you parallelise over Applicative and Alternative?
00:59:42 <lyxia> I've never heard about parallelizing over alternative before but I don't see why it couldn't be done.
01:03:26 <delYsid> I have this napsack-alike algorithm which basically has a list of input elements, and produces a non-deterministic result of all the possible versions of all the elements, with certain constraints which limits the exponential explosion.  I managed to code this in C++ in a parallel way, basically with something like a thread pool and a big lock around my final results.  The algo looks a lot different implemented in Haskell with StateT
01:03:26 <delYsid> and ListT, so I am really wondering if I can bring the parallelism to haskell as well.
01:14:08 <lyxia> You'll need IO to get the kind of non-determinism you're looking for.
01:15:03 <lyxia> That is, if you need only the result of the first computation which finishes
01:15:39 <lyxia> ListT will just list all of them.
01:17:51 <EvanR> if the result is independent of which one finishes first, you can use unamb
01:17:55 <EvanR> which hides the IO
01:24:15 <delYsid> I actually need all results, so in my sequential haskell impl. ListT is just what I need.
01:31:45 <dredozubov> anyone uses intero-mode in emacs?
01:32:07 <Akii> I use that in spacemacs
01:32:16 <dredozubov> it's transferring focus to the intero buffer on C-c C-l and it annoys me a lot
01:32:22 <dredozubov> how do i disable it?
01:32:58 <Akii> cool :D
01:33:00 <Akii> thx
01:33:18 <Akii> I was always typing SPC m s b and had to manually switch
01:33:42 <dredozubov> can you show what you execute on SPC m s b?
01:33:59 <dredozubov> you can probably do C-h k SPC m s b
01:34:11 <Akii> intero-repl-load
01:34:20 <Unhammer> dredozubov,  you could redefine intero-repl-load without the final pop-to-buffer
01:34:30 <Unhammer> (or, define your own copy)
01:34:32 <Akii> I'm brutally new to spacemacs, emacs and all that so no idea
01:34:57 <Unhammer> or you could advice the function to pop back after it's done …
01:34:58 <dredozubov> Unhammer: that's my currenty thought as well
01:39:29 <dredozubov> do i have to do (add-hook 'haskell-mode-hook ..) to override the default handler?
01:39:35 <dredozubov> i don't have a clue :)
01:40:30 <dredozubov> i think it should be (define-key intero-mode-map (kbd "C-c C-l") 'my/intero-repl-load) 
01:44:57 <Unhammer> dredozubov,  I'd eval-after-load 'intero
01:45:10 <Unhammer> in case you ever start haskell-mode without intero loaded
01:45:22 <Unhammer> alternative:
01:45:23 <Unhammer> (eval-after-load 'intero
01:45:25 <Unhammer>   '(defadvice intero-repl-load (around my-intero-repl-load first nil activate)
01:45:27 <Unhammer>      (let ((b (current-buffer)))
01:45:29 <Unhammer>        ad-do-it
01:45:31 <Unhammer>        (pop-to-buffer b))))
01:46:02 <dredozubov> it works as it is
01:46:34 <bollu> what is the "correct" way to nope out of execution? FFI returns me a custom int for exceptions such as divide by zero, and I want to exit out correctly
01:46:43 <dredozubov> but i like your solution as a more future-proof
01:46:57 <dredozubov> i basically edited intero-repl-load to my needs
01:47:29 <dredozubov> bollu: System.Exit
01:47:33 <merijn> bollu: Do you want to handle it at all? Or just crash?
01:47:42 <bollu> merijn: crash cleanly
01:47:45 <ClaudiusMaximus> bollu: throw a divide by zero exception (or whatever is appropriate)
01:47:59 <bollu> ClaudiusMaximus: yes, what is the correct way to throw said exception? :)
01:48:11 <merijn> bollu: You can throw an exception which should exit nicely if you use bracket for allocation/freeing
01:48:22 <ClaudiusMaximus> https://hackage.haskell.org/package/base-4.9.0.0/docs/Control-Exception-Base.html#t:ArithException
01:48:23 <merijn> bollu: throwIO from Control.Exception
01:48:34 <bollu> merijn: do tell. This case, I want to throw an exception for divide by zero, runtime error, etc
01:48:35 <merijn> Or throwM from the exceptions package
01:49:17 <bollu> uh, throwIO returns IO a
01:49:20 <bollu> I need it to return "a"
01:49:30 <bollu> since I'm implementing a Num instance, I can't have (*) return IO a
01:49:33 <bollu> I need it to return "a"
01:49:38 <bollu> but still provide a way to crash out
01:49:43 <bollu> if you try things like divide by zero
01:50:01 <merijn> bollu: Not using throwIO makes exceptions as miserable as using unsafePerformIO as your exceptions may escape your exception handlers due to laziness
01:50:01 <ClaudiusMaximus> bollu: your num instance is already doing unsafePerformIO, so you can stick the throwIO in there
01:50:19 <bollu> ClaudiusMaximus: fair enough
01:50:22 <bollu> ClaudiusMaximus: okay, will do
01:50:33 <bollu> merijn: hm, really? unsafePerformIO and throwIO interact weirdly?
01:50:51 <bollu> merijn: and the bug that was around yesterday was because of divide by zero
01:50:58 <bollu> not foreignPtr :)
01:51:09 <merijn> bollu: No, I'm saying there are ways to throw other than throwIO but they will fuck you over
01:51:12 <merijn> So don't use them
01:51:13 <bollu> ClaudiusMaximus: will it interact "correctly" with unsafePerformIO?
01:51:17 <bollu> merijn: ah okay
01:51:52 <ClaudiusMaximus> bollu: it'll probably interact better than using "throw" would, but i've not used exceptions much at all
01:51:53 <merijn> Exceptions thrown outside IO are "friends" in the same way Double's are. Seems friendly and reliable at first, but when you're not looking...
01:52:08 <bollu> xD
01:52:09 <bollu> OK
01:52:11 <merijn> @quote mantissa
01:52:11 <lambdabot> quicksilver says: <jatqceer> i love them.  Double is my friend <quicksilver> You think he is, sure <quicksilver> he says nice things about you <quicksilver> but one day, when your back is turned, he
01:52:11 <lambdabot> will stab you in the back with a mantissa
01:55:43 <bollu1> where is throwIO implemented?
01:56:42 <b0llu> ooh, "GHC.IO"
01:58:07 <dredozubov> Unhammer: i ended up using your solution, works perfectly, thanks
02:13:33 <Unhammer> np dredozubov 
02:14:07 <dredozubov> anyway, haskell support in emacs feels fragile these days
02:14:19 <dredozubov> maybe my projects just got bigger
02:56:26 <tdammers> then again, one of Haskell's selling points is that it's concise and expressive enough to not really require much editor support
02:56:31 <tdammers> my $0.02 anyway
02:58:27 <Gurkenglas> :t alaf Alt foldMap pure -- We need asumMap so this is asumMap pure and can replace maybe empty pure for lifting Foldable Alternatives
02:58:29 <lambdabot> (Alternative g, Foldable t) => t b -> g b
02:58:52 <jle`> i always wondered why there's no asumMap
02:59:09 <jmnoz> what should I use to validate http input? check that a value is a given url for example?
03:04:34 <Gurkenglas> jmnoz: What do you want to use the url for? Fetching the website? I'd push the responsibility for validating the url on the library that does the fetching.
03:05:21 <jmnoz> Gurkenglas: it's a user submitted url via get parameter, 
03:05:40 <Gurkenglas> Not where does it come from, but where does it go
03:06:03 <jle`> deep question
03:06:11 <jmnoz> the user adds urls (feeds). it's like a feed reader
03:07:55 <Gurkenglas> (Also you might not want to fetch user-given arbitrary websites even if they're syntactically valid)
03:08:39 <jmnoz> I guess *deletes project*
04:05:31 <Unhammer> can I derive generic on data defined elsewhere?
04:08:07 <Unhammer> oh I can "deriving instance Generic Foo" but what if Foo takes an argument?
04:14:13 <Unhammer> … but I can't derive generic for hidden constructors, bah
04:19:19 <lyxia> deriving instance Generic (Foo a)
04:21:15 <Eduard_Munteanu> Is JWT verification in https://hackage.haskell.org/package/jose vulnerable to header manipulation?
04:22:56 <Eduard_Munteanu> It seems to get the algorithm form the header.
04:47:48 <phiberjenz> Hi! I've a quick question. Just started learning Haskell.
04:48:14 <phiberjenz> Why won't this compile:
04:48:19 <phiberjenz> fifthChar :: String -> String
04:48:25 <phiberjenz> fifthChar y = y !! 5
04:48:32 <phiberjenz> Error:
04:48:45 <yushyin> !t (!!)
04:48:51 <cocreature> phiberjenz: because the fifth character in a string is of type Char not of type String
04:48:51 <yushyin> :t (!!)
04:48:52 <lambdabot> [a] -> Int -> a
04:48:59 <cocreature> eh 6th
04:49:02 <phiberjenz> Of course.. Thank you!
04:49:17 <cocreature> your function name is misleading :)
04:49:22 <phiberjenz> So it should be fifthChar :: String -> Char
04:49:27 <cocreature> yep
04:49:37 <cocreature> but your code returns the sixth char
04:49:42 <cocreature> indices start at 0
04:49:44 <phiberjenz> Yes it does ;)
04:49:53 <phiberjenz> Thanks!
04:49:55 <cocreature> np
04:50:38 <curry> You guys seen this? https://www.youtube.com/watch?v=RqvCNb7fKsg
04:59:26 <mniip> yeah and it is great
04:59:30 <mniip> just like hskell is
05:00:40 <effectfully> those swedish greetings are really funny
05:05:34 <Uplink|DMD> hello
05:05:53 <magthe> effectfully: what greetings?
05:06:04 <Uplink|DMD> Is there any way to get at the latest version of jhc ?
05:06:13 <effectfully> magthe: in the video curry has posted
05:15:50 <magthe> oh well
05:35:46 <whis0> Hello, could I have some help here?
05:36:45 <kuribas> whis0: perhaps
05:37:09 <whis0> Can i just paste a stackoverflow link here? Instead of trying to explain
05:37:10 <kuribas> whis0: hard to say without more info...
05:37:19 <kuribas> you can
05:37:35 <whis0> im kinda new to haskell so :) http://stackoverflow.com/questions/41164856/how-to-solve-a-haskell-excercise
05:52:45 <Cale> whis0: hello
05:52:57 <whis0> hello Cale
05:54:28 <Cale> whis0: So the idea there is that you're going to do the same sort of thing as you just did, but  getLine  will be replaced with the first argument, the (== 0) predicate for when to stop will be replaced with the second, the (+) will be replaced with the third
05:55:23 <Cale> Actually, it's getInt as a whole which will be replaced by the first argument
05:55:57 <whis0> Okay, I'm trying to do it now actually, I'll let you know how I'm doing in a moment
06:00:45 <quchen> I’m looking for a fuzzy substring matching algorithm like Levenshtein, but instead of the total editing distance from s1 to s2, I’d like to know the editing distance from s1 to s1', where s1' is a substring of s2.
06:00:53 <quchen> Does anyone know an algorithm to do this?
06:04:06 <lyxia> Do you mean "substring" as in "isInfixOf"?
06:04:31 <quchen> lyxia: Yes
06:05:00 <quchen> lyxia: For example, ›quchenDistance "ab" "xxxxbaxxx"‹ == 1
06:05:07 <Tuplanolla> You need to extend your concept of editing with truncation, quchen.
06:05:22 <kuribas> what's the ratio of lines of code c/haskell?  3? or 10?
06:05:47 <kuribas> How can you compare codebase size of haskell vs C/Java/C++?
06:06:11 <quchen> You have to write a small well-defined program of a couple of hundred of lines to find out.
06:06:24 <quchen> The well-definedness is usually the problem that makes people go mad on the internets.
06:06:52 <whis0> Cale: so got stuck a bit with the folding, can you help me out? http://lpaste.net/444852242705547264
06:07:13 <Tuplanolla> I can imagine doing that being computationally demanding, quchen.
06:07:37 <quchen> Tuplanolla: Yes, probably :-/ On the plus side, I expect my strings to be somewhat short
06:07:59 <Tuplanolla> I worry about `quchenDistance "ab" "abbabaaba"`.
06:08:07 <Cale> whis0: Well, before, you applied (+) to x there, now you want to analogously apply foldF to element.
06:08:11 <Tuplanolla> Which one of the substrings do you choose?
06:08:27 <whis0> Cale: so just (element foldF)?
06:08:52 <Cale> foldF element
06:09:05 <Cale> element isn't necessarily a function (it could be, but that's unlikely)
06:09:13 <whis0> Cale: oh right, my bad
06:09:15 <hashme> I come from the imperative world, and I have a question - Why should arrays be immutable? Isn't a mutable array much more efficient when you have to keep modifying the data (which happens in most practical cases)?
06:09:45 <hashme> I know that there are mutable arrays too in Haskell, but still I want to know the answer
06:09:45 <lyxia> Haskell has mutable arrays.
06:09:59 <Tuplanolla> We don't use arrays that often, hashme.
06:10:00 <hashme> Yeah but why should there be immutable arrays?
06:10:03 <lyxia> It's much more convenient to read a pure value.
06:10:10 <whis0> Cale: ill try testing it now
06:10:38 <hashme> What if you're implementing an algorithm where time efficiency is what matters?
06:10:45 <hashme> And space efficiency?
06:10:51 <lyxia> then don't modify an immutable array
06:10:54 <quchen> hashme: Sure, mutable updates are much faster, but introduce lots of problems. Haskell can leverage the immutability to greatly simplify multiple »inefficient, copying« operations automatically though. For example, »map f . map g« loops over the input only once, despite the fact that each map is a loop of its own.
06:12:17 <hashme> What kind of problems? I know you guys say "pure"? Can you give me an example where this immutablity might be an advantage?
06:12:53 <merijn> Mutable updates *can* be faster
06:12:59 <quchen> hashme: »Is this correctly initialized« is something I spend a *lot* of time on in mutable languages. In Haskell, that almost never happens.
06:13:12 <merijn> Also
06:13:24 <quchen> Everything is always initialized. There is no builder pattern, for example, because that only makes sense in a mutable context.
06:13:27 <merijn> I just did some python, spend ages trying to figure out whether should be copied, deepcopied, or reused
06:13:58 <merijn> In Haskell you never have to worry about using directly, copying, or deepcopying
06:14:10 <merijn> Also, Lack of mutable state makes threading easy
06:14:17 <quchen> hashme: »Is this aliasing this other thing« is also a problem of mutability.
06:14:23 <kuribas> hashme: you can safely reuse a pure array, without worrying it will be modified by a different part of the code.
06:14:38 <hashme> Yes one advantage is parallelising the code (this is a big one though) :)
06:14:43 <merijn> hashme: Only reason threading is hard is because shared mutable state is harder than mutable state. Multithreading with immutable data is easy
06:14:52 <quchen> Even better, you can safely use both the modified (new) array and the unmodified (old) one :-)
06:15:24 <merijn> hashme: Haskell isn't about "no mutability", but having the right default (immutable) and only making things mutable if you have to/need to, thus limiting the amount of stuff you need to worry about
06:15:48 <hashme> Yes, I understand now :) thanks!
06:16:12 <merijn> hashme: Similarly, I can honestly say the vast majority of Haskell I personally write is IO code, because that's the kinda code I write. But the ability to *not* write IO code is what's nice :)
06:16:25 <quchen> To be fair, mutability in Haskell is fairly heavy on syntax, so the »default« is what you usually choose unless you’re really sure.
06:16:47 <quchen> Compare that to Rust for example, where mutability is very easily introduced.
06:16:53 <merijn> hashme: If you're familiar with C++ you must be familiar with how pleasant "const foo&" is vs "foo*" or "foo&" :)
06:18:50 <kuribas> hashme: a nice thing about haskell is that you can see from the type when a function mutates state.
06:18:59 <kuribas> hashme: there are no surprises.
06:19:11 <quchen> hashme: Having everything immutable makes your programs pretty slow, but also allows the compiler to modify code very easily to make it efficient again. Dead code elimination is trivial in Haskell, for example. It’s nontrivial in C++ for example, because every unused object might do stuff in its constructor, so its unused initialization cannot be thrown away.
06:20:20 <quchen> »Can I inline this« is equally hard in C. In Haskell, it’s »yes«.
06:20:33 <kuribas> well, sort of...
06:20:42 <quchen> (Always yes. Unless you’re deep into unsafeMordor.)
06:20:47 <kuribas> ghc will not inline everything...
06:21:01 <quchen> The problem reduces to »should I«, because some inlining might make your program less efficient.
06:21:11 <quchen> But it’s never wrong to do it anyway.
06:21:15 <Tuplanolla> There was some theoretical talk about each mutable-storage algorithm having an immutable-storage counterpart that's at most logarithmically slower. Does anyone remember the details?
06:21:34 <merijn> Tuplanolla: Yes, the basic sketch of the proof is simple
06:22:16 <merijn> Tuplanolla: Thread a "Map" of "variable -> value" mappings through the imperative algorithm, then you have log n slowdown because inserting/reading Map entries is O(log n)
06:23:05 <quchen> That has a nontrivial space overhead as well though.
06:23:29 <kuribas> IMO gains get larger as the programs get bigger.
06:23:31 <c_wraith> It's not trivial, but it's constant-factor.
06:23:53 <c_wraith> tree overhead is just a constant multiple of the number of elements in it.
06:23:56 <merijn> quchen: Not that much overhead, tbh
06:24:04 <quchen> Shouldn’t it be linear?
06:25:47 <merijn> quchen: In the number of variables, yes, but you generally don't need that many
06:26:13 <merijn> quchen: 100 variables is already a lot for most algorithms. 100 Map entries are barely a relevant space consumer
06:27:09 <merijn> quchen: Anyone, the storage overhead doesn't really change the log n worst case computational impact
06:27:09 <quchen> Ah, I see. I thought you wanted to store all intermediate states, not just the current program state.
06:27:38 <merijn> quchen: You don't have to store intermediate state for the program to finish, only the current value of a variable to simulate mutable memory
06:27:50 <kuribas> it's a lot of garbage collection...
06:28:41 <kuribas> Does ghc allocate stuff on the stack sometimes?
06:28:41 <c_wraith> It's not a *good* way to implement most algorithms
06:28:57 <c_wraith> But it's a nice fallback theory
06:29:22 <c_wraith> ghc never allocates constructors on the stack, but it often can optimize out allocating constructors at all
06:29:32 <merijn> kuribas: GC is, in general, cheap in GHC
06:29:46 <merijn> kuribas: Actually, for GHC's design more garbage == better
06:30:05 <c_wraith> uh.  with some provisos.
06:30:10 <merijn> c_wraith: Sure :)
06:30:14 <kuribas> merijn: hm, strange
06:30:22 <c_wraith> don't generate garbage just for fun.  That doesn't speed up anything. :)
06:30:28 <whis0> Cale: im quite stuck with testing it, thought I know on how to do it, but feel miserable now... :c
06:30:32 <merijn> I have seen profiled GHC programs with allocation rates of up 1.4GB/s and up :p
06:30:58 <c_wraith> The important thing to remember is that GHC's GC runtime is proportional to the number of pointers in the live set
06:31:09 <c_wraith> So if the live set stays small, GC stays fast.
06:31:10 <Cale> whis0: Did you get it to typecheck with the appropriate type? What are you trying?
06:31:21 <kuribas> whis0: it's just a puzzle, put it the right pieces, and ... it works!
06:31:34 <merijn> kuribas: GHC doesn't do mark&sweep, so it doesn't have to traverse all the allocated memory, only the bits that AREN'T garbage. So if the vast majority of your allocations quickly turn into garbage, that's good, because you don't have to look at them during GC
06:31:43 <kuribas> whis0: look at the types
06:31:50 <whis0> kuribas: yes I know its a puzzle, but I am new to this, not really good at it either, just trying not to give up, but already spent too much time with this one
06:32:05 <Tuplanolla> Have there been plans to introduce partitioned heaps?
06:32:14 <c_wraith> merijn: uh, it definitely has to traverse all allocated memory - at least in the generation it's working on.
06:32:20 <kuribas> whis0: what have you got?
06:32:29 <whis0> one moment, ill paste it
06:32:37 <c_wraith> merijn: oh,  it has to traverse *live* allocated memory, not *all* allocated memory.  That's what you meant.
06:32:57 <whis0> the problem is, cant even compile my tests lol
06:33:14 <Tuplanolla> I could imagine large programs benefiting from memory regions that don't have mutual references.
06:33:42 <kuribas> whis0: I have to go, I'll be back later to look at it...
06:33:55 <whis0> okay
06:34:02 <merijn> c_wraith: Exactly
06:34:13 <c_wraith> Tuplanolla: there's a feature planned for GHC 8.2 that will let copy a data structure into a single contiguous block of memory, that the GC treats as a single unit (and has no outbout pointers, so GC never looks inside it, just checks to see if it's live)
06:34:21 <Cale> whis0: You should just load the function into ghci and try supplying one argument at a time, checking the type of the result with :t as you go
06:34:29 <c_wraith> *outbound
06:35:14 <whis0> well im trying to write "test" functions
06:35:18 <Tuplanolla> That's not quite a separate partition, but still something.
06:35:19 <whis0> dont I need em?
06:35:25 <whis0> like these: http://lpaste.net/349973
06:35:25 <Cale> hm?
06:35:44 <whis0> I might be going totally the wrong path right now, lol
06:35:50 <Cale> whis0: Well, you're going to pick a = Integer
06:36:00 <merijn> Tuplanolla: Separate partitions are tricky combined with laziness
06:36:02 <Cale> your foldF can just be (+)
06:36:18 <merijn> Tuplanolla: I imagine you're thinking of something like Erlang with per-thread independent heaps so you don't need a global GC pause?
06:36:19 <Cale> if x == 0 then True else False  means the same thing as  x == 0
06:36:35 <Tuplanolla> Can you elaborate, merijn? I thought the big problem was scheduling and ffi.
06:36:43 <Cale> and so you can write that function Integer -> Bool as simply (== 0)
06:36:45 <whis0> well right, im quite silly, need coffee i guess
06:36:54 <whis0> okay, ill try, one moment
06:37:17 <Cale> (barely needs giving a name to it)
06:37:25 <merijn> Tuplanolla: Well, for per-thread heaps you can't have shared references, right? So if I send data X from thread A to thread B I need to copy, rather than sending a shared reference
06:37:45 <Tuplanolla> Naturally.
06:37:55 <merijn> Tuplanolla: The problem is that in haskell you generally don't have actual values
06:38:17 <merijn> Tuplanolla: Suppose I have "reallyExpensiveFunction True Foo" <- I just allocate a thunk
06:38:37 <whis0> oh silly me, it works, LOL
06:38:40 <Cale> whis0: It's important to understand what return is. It's a function that constructs an action that does nothing except to produce the given value when executed.
06:38:45 <merijn> Tuplanolla: Now I communicate that thunk to another thread...do I force it? Duplicate the thunk? Duplicating means also duplicating all data the thunk has references to
06:39:12 <Cale> whis0: If you're not trying to construct an IO action, or an action of some other monad, you won't want it.
06:39:36 <whis0> i see
06:40:01 <Tuplanolla> Just choose one?
06:41:24 <merijn> Tuplanolla: But duplicating a potentially huge set of references is crazy expensive and if I force it, well...that means communicating becomes much slower
06:41:42 <Cale> (note that it is *not* a keyword, and has no special control effects, like return in other imperative languages has -- return v won't abort some surrounding IO action early, it just returns v in place, and if it's in the middle of a do-block, it basically won't serve any purpose.)
06:41:47 <merijn> Tuplanolla: It's a trade-off, fast communication or independent heaps, can't really have both
06:42:30 <merijn> Tuplanolla: Similarly, GHC's GC design optimises for high throughput, and as a result is bad for low latency things.
06:42:49 <Tuplanolla> How should this scenario be handled in a Haskell operating system with a central garbage collector? Think Lisp machines.
06:43:03 <merijn> Tuplanolla: It's not that there's no merit to a design like that of Erlang, but it comes with pretty fundamental trade-offs :)
06:43:35 <merijn> Tuplanolla: Oh, you could easily make a Haskell implementation that does have separate heaps. It's not a fundamental Haskell limitation
06:43:58 <merijn> Tuplanolla: So you *could* do this in, e.g., a Haskell OS. It's just that GHC doesn't
06:44:00 <whis0> Cale: http://lpaste.net/349976 so am I doing this right? the lpaste suggested me to remove the input after (+) but then its not working, and also, any way to simplify it?
06:56:01 <quchen> Is there a test framework that can run tests depending on other tests’ results? Tasty always runs everything, but when my tiny core test is broken, I’d like to skip the bigger ones.
06:59:55 <berndl> quchen: Isn't there an option to stop on the first failing test?
07:01:07 <quchen> berndl: I don’t want to stop everything, just some of them. ›runIfSuccessful :: TestTree -> TestTree -> TestTree; runIfSuccessful precondition moreTests‹ is what I envision.
07:01:21 <Cale> whis0: You'd have to remove input from both sides of the equation
07:01:33 <whis0> Cale: i did that, it worked
07:01:53 <whis0> Cale: now im trying to get the getIO_Int into the sumInt2 (trying to get rid of additional function)
07:03:42 <Cale> There's a function readLn which ought to work
07:03:46 <Cale> :t readLn
07:03:47 <lambdabot> Read a => IO a
07:04:01 <Cale> (you can use it at type IO Integer, and it'll do the appropriate thing)
07:09:40 <whis0> thanks Cale! That was great help. +100 Kkarma
07:12:01 <Cale> (Actually, I shouldn't have called it a function -- it plainly isn't one :)
07:14:24 <Rembane> Even if you squint?
07:15:31 <kuribas> whis0: DO you want to read at least one number?
07:16:12 <whis0> kuribas: with Cales help we've done it
07:27:17 <Nicmavr> Can someone tell me how you can convert a Maybe type into it's original type?
07:27:21 <Nicmavr> eg. Maybe Int to Int?
07:27:45 <Cale> Nicmavr: Usually by case analysis:
07:27:58 <Cale> case someMaybeInt of
07:28:02 <Cale>   Nothing -> ...
07:28:05 <Cale>   Just n -> ...
07:28:20 <Nicmavr> Cale, so say I have Maybe Int = num
07:28:26 <Cale> hm?
07:28:29 <Nicmavr> what do I put in the cases?
07:28:41 <Nicmavr> can I PM you actually?
07:28:44 <Cale> What you want the result of the computation to be
07:28:58 <Cale> Perhaps you'd like to share some code on lpaste.net?
07:29:13 <Nicmavr> it's work for an assignment so I can't post code publicly
07:29:20 <Nicmavr> but to summarise it
07:29:34 <Tuplanolla> Rules for the sake of having rules, I see.
07:29:42 <Nicmavr> I have a FunctionA which is Int -> Int -> Maybe Int
07:29:53 <Nicmavr> And then A functionB which takes Int -> Int -> Maybe Int
07:30:02 <Nicmavr> the second argument of FunctionB is the result of functionA
07:30:04 <Cale> So, when you have a value of type Maybe Int, it's either going to be the value Nothing, or it's going to be a value of the form Just n, where n :: Int
07:30:17 <Nicmavr> pretty much
07:30:28 <Cale> So in order to use such a thing, you need to say what you want to produce in the case that it's Nothing
07:30:35 <Nicmavr> Haskell is complaining that when I pass the Maybe Int into functionB, that its a Maybe Int instead of an Int
07:30:41 <Cale> Of course.
07:30:57 <Nicmavr> so what can I put on the argument to insure its converted from Maybe Int to Int?
07:31:16 <Cale> You should case on your value of type Maybe Int
07:31:19 <kja> Hello! Any STM wizards who can help me figure out why my program doesn't work?
07:31:35 <Nicmavr> Cale, are there any examples I can look at? I haven't done this before
07:31:45 <Cale> and this will give you the opportunity to specify what the result of the computation will be when the Maybe Int happens to be Nothing
07:32:09 <Nicmavr> FunctionB also uses guards, will case work if guards are in use?
07:32:27 <Cale> case is an expression form, it can be used anywhere that you would put an expression
07:33:43 <Nicmavr> any examples I can look at? :P
07:34:26 <Cale> uh, I dunno, any book on Haskell should cover this somewhere, it's one of the most basic parts of the syntax...
07:34:41 <Nik05> is there a problem with the certificate on haskell.org?
07:35:12 <Nicmavr> Cale, would I use the case inside of functionA then? Or in functionB?
07:35:17 <Nicmavr> I'm kinda confused about it
07:35:39 <Cale> Nicmavr: In functionA, where you have the Maybe Int
07:35:45 <Nicmavr> ok
07:35:47 <fryguybob> kja: Ask away
07:35:53 <Cale> Suppose you have x :: Maybe Int
07:35:59 <Cale> then you can write
07:36:02 <Cale> case x of
07:36:09 <Wizek> > length (3, 4)
07:36:11 <lambdabot>  1
07:36:18 <Cale>   Nothing -> ... whatever you want the result of the expression to be when x = Nothing ...
07:36:35 <Cale>   Just n -> ... use n :: Int here to specify the result of the expression when x = Just n
07:36:36 <Wizek> Hey, anyone knows why `length (3, 4) = 1`?
07:37:07 <ab9rf> i wasn't aware that length was defined on tuples
07:37:10 <Cale> Wizek: Because a pair is treated uniformly as a container with one element (its second part)
07:37:17 <Cale> Consider what fmap does
07:37:19 <Gurkenglas> > foldMap (:[]) (3,4) -- Wizek
07:37:21 <lambdabot>  [4]
07:37:24 <merijn> ab9rf: Length is Foldable and length is now Foldable
07:37:41 <Cale> :t length
07:37:42 <lambdabot> Foldable t => t a -> Int
07:37:46 <ab9rf> merijn: ah, ok, that makes sense then
07:37:54 <Cale> So here, if we set  t = (,) s
07:38:08 <Cale> Then it becomes length :: (s,a) -> Int
07:38:22 <Cale> and length's job is to count the number of values of type a in whatever structure it is :)
07:38:51 <Cale> (well, that's an odd way to put it -- the result doesn't change when s happens to be equal to a, but hopefully it makes sense)
07:40:23 <Gurkenglas> > [sequenceA (1, Just 2), sequenceA (1, Nothing)] -- We want this to work, so tuples need to be Traversable, so we have to be able to answer the question of how many elements we are traversing over, which length asks
07:40:26 <lambdabot>  [Just (1,2),Nothing]
07:41:47 <Gurkenglas> > lengthOf _1 (2,3) -- At least you can get at the length of the left side of the tuple too :D
07:41:49 <lambdabot>  1
07:43:33 <Gurkenglas> :t maybe -- Nicmavr, you could try using this to construct FunctionB
07:43:34 <lambdabot> b -> (a -> b) -> Maybe a -> b
07:43:50 <Gurkenglas> @src maybe
07:43:50 <lambdabot> maybe n _ Nothing  = n
07:43:50 <lambdabot> maybe _ f (Just x) = f x
07:48:58 <kja> fryguybob: worked it out with some help from #haskell-beginners, thanks for offering!
07:50:34 <fryguybob> kja: Great!
07:59:09 <Nicmavr> Cale, do i need to put anything after that? Just because it's giving me a parse error
07:59:52 <Nik05> https://www.ssllabs.com/ssltest/analyze.html?d=haskell.org&s=23.253.242.70 just a C...
08:00:03 <Nik05> my firefox doesn't like it
08:02:41 <Profpatsch> :exf Monad m => (a -> m b) -> m a -> m b
08:02:42 <exferenceBot> \ f1 b -> b Control.Monad.>>= f1
08:03:01 <quchen> In Aeson, can I somehow disallow present-but-unused values? Normally, I can just add nonsensical fields wherever I like in my input, as long as they’re well-formed.. Is there a way to control this?
08:03:14 <marcx> :t mfilter
08:03:15 <lambdabot> MonadPlus m => (a -> Bool) -> m a -> m a
08:03:19 <marcx> :t mfilter isDigit
08:03:20 <lambdabot> MonadPlus m => m Char -> m Char
08:03:25 <marcx> :t mfilter isDigit (Just 1)
08:03:26 <lambdabot> error:
08:03:26 <lambdabot>     • No instance for (Num Char) arising from the literal ‘1’
08:03:26 <lambdabot>     • In the first argument of ‘Just’, namely ‘1’
08:03:39 <marcx> oh nm
08:03:40 <c_wraith> quchen: well, you could do it the hard way.  Look at the keys in an object and see if any are unexpected
08:03:54 <marcx> this worked in my ghci, and i wondered why. i know now 
08:04:40 <quchen> c_wraith: Yes, but ideally I’d like to say »this converter looks at all keys, if you find others please fail«
08:04:50 <quchen> Just wondering whether there was an easy path :-)
08:05:49 <c_wraith> Not built in.  I did logic similar to that for testing a web service once.  Turns out to be reasonable to write a set of combinators that does that.
08:06:41 <quchen> c_wraith: Open source?
08:06:47 <c_wraith> no
08:06:56 <quchen> Pity. Alright, reinventing it :-)
08:19:58 <Profpatsch> What’s a good alternative for Read that goes from Text instead of String?
08:20:44 <c_wraith> If you're using Read, you obviously don't care about performance and might as well just convert to String. :P
08:21:08 <maerwald> a parser?
08:25:19 <Profpatsch> maerwald: which one would you recommend?
08:25:37 <Profpatsch> maerwald: Also: even for very small strings, like fields in csv?
08:26:38 <Profpatsch> c_wraith: I’m asking exactly because I don’t want to convert to String first.
08:27:28 <glguy> Profpatsch: Read is a debugging tool. What are you Read'ing?
08:27:52 <Rembane> Profpatsch: What's the 10k feet overview of what you want to do?
08:27:57 <c_wraith> Profpatsch: if you're reading a csv, you should use a csv library
08:28:11 <Profpatsch> I am using cassava
08:28:30 <glguy> Alternatives include things like parsec,megaparsec,attoparsec,alex/happy
08:28:44 <Profpatsch> But I have a few types that require a more elaborate parsing process.
08:29:14 <pmade> Profpatsch: Then you should use the ToField and FromField or whatever cassava calls it
08:29:35 <pmade> They are type classes for parsing fields out of csv.
08:30:06 <pmade> https://hackage.haskell.org/package/cassava-0.4.5.1/docs/Data-Csv.html#g:14
08:30:10 <Profpatsch> pmade: I know, but I’m not going to create dozens of stray types
08:30:51 <infandum> Can someone explain why some parallels work and some don't?
08:31:05 <infandum> http://lpaste.net/56296296717221888
08:31:13 <Profpatsch> I want it to give me Text which I then can use as UTF-8 primitive to parse stuff.
08:31:22 <infandum> Obviously I need the monad version to work, but only the non-monad works
08:31:39 <infandum> and if I try it and sequence it then it doesn't work anymore
08:31:51 <c_wraith> infandum: what does "work" mean?
08:31:55 <infandum> as in, it clearly works sequentially, not parallel
08:32:42 <infandum> c_wraith: The computation is sequential, not parallel, so it goes 500000500000 then another then another instead of all at once which is what is supposed to happen
08:32:43 <pmade> Profpatsch: well, cassava will give you Word8 ByteString, so you're already converting that to Text for UTF-8 right?
08:32:44 <bollu> so, how does hmatrix do "+", "*", etc?
08:32:48 <infandum> (and much faster)
08:32:50 <bollu> doesn't it conflict with Prelude?
08:33:13 <Faucelme> What is the most lightweight library that has "Elem" for type-level lists?
08:33:24 <pmade> Or, I guess if you are asking cassava for a Text it will do the conversion for you.
08:33:33 <Profpatsch> pmade: yes
08:33:57 <cocreature> infandum: why are you passing f to mapM? it just returns an a not an m a
08:34:33 <c_wraith> infandum: well, the mapConcurrently version is because of laziness
08:34:46 <c_wraith> infandum: you're creating thunks in parallel, but not evaluating them until you print them
08:34:57 <Profpatsch> hrmph, cassava should just expose its attoparsec parser.
08:34:59 <pmade> Profpatsch: are the types you're looking to parse your own custom data types?
08:35:29 <bollu> I'm writing bindings to SymEngine, and I would like to be similar to hmatrix
08:35:37 <bollu> so where are the typeclasses that hmatrix uses?
08:35:52 <c_wraith> infandum: if you actually did the printing *inside* the mapConcurrently, you'd see different results
08:36:24 <pmade> bollu: I think you want the Num class from base
08:37:14 <c_wraith> infandum: and I have no idea where Control.Monad.Parallel is coming from, but it's almost certainly the same thing.  You have to understand what you're asking to be evaluated in parallel
08:37:28 <bollu> pmade: oh, interesting, but some of Num doesn't work 
08:37:44 <bollu> pmade: like, fromInteger, and abs
08:37:48 <whis0> Does anybody here know Prolog well?
08:37:48 <bollu> pmade: so are those partial?
08:38:07 <infandum> c_wraith: Same thing as what?
08:38:17 <pmade> I don't know what SymEngine is, but if you can't implement those then you shouldn't implement Num.
08:38:26 <c_wraith> infandum: same as the reason mapConcurrently isn't doing anything useful in parallel
08:38:32 <infandum> I mean, Control.Parallel.Strategies is working fine (on the non-monad stuff)
08:38:46 <c_wraith> infandum: you're asking it to do a different operation in parallel.
08:39:12 <infandum> c_wraith: But shouldn't it be "performing all the IO actions concurrently"?
08:39:26 <c_wraith> infandum: it is.  The IO actions are "generate a thunk"
08:39:32 <cocreature> bollu: shouldn’t you be able to represent constant integers in your symbolic math expressions?
08:39:34 <infandum> I see
08:39:41 <infandum> then sequence would still be sequential
08:39:44 <infandum> ?
08:39:49 <pmade> bollu: What you might consider instead is just implementing your own operators like (<+>)
08:39:55 <c_wraith> infandum: change the IO action to print the value instead of just returning it.
08:40:02 <c_wraith> infandum: then something actually interesting will be happening
08:40:07 <bollu> pmade: right, but I wanted to maintain compatibility with existing libraries
08:40:13 <bollu> pmade: so it's as "drop in" as possible
08:40:23 <infandum> c_wraith: I can't, in my actual use case I'm not printing it
08:40:23 <infandum> well I am, after a billion other steps
08:40:38 <bollu> does "Alberto Ruiz" hang out on IRC?
08:40:47 <infandum> c_wraith: But doesn't rseq also generate thunks in parallel?
08:41:29 <whis0> Is anyone here good with prolog?
08:41:39 <infandum> oh, to whnf I guess
08:41:51 <glguy> whis0: This channel is for Haskell discussion
08:42:08 <whis0> glguy: yes i know, just was wondering if anybody has knowledge :)
08:42:23 <glguy> Yeah, there are people who know Prolog
08:42:31 <infandum> c_wraith: Also, what about the example in async?  pages <- mapConcurrently getURL ["url1", "url2", "url3"]
08:42:36 <infandum> how is that different?
08:42:45 <c_wraith> infandum: the difference is that the IO action does something.
08:43:05 <c_wraith> infandum: mapConcurrently is for doing IO actions concurrently.  Things that actually do IO.
08:43:24 <infandum> oh, as opposed to IO a
08:43:27 <pmade> bollu: But it won't be "drop in" if someone is using `abs', right?
08:43:35 <infandum> (no IO actions, just within the monad)
08:43:49 <infandum> then what would I want?
08:43:51 <c_wraith> infandum: more specifically, as opposed to just using return
08:44:25 <infandum> I have no idea what I would need then
08:44:48 <bollu1> pmade: I don't think abs has a sensible interpretation for matrices. If it does, I'll do what hmatrix does...
08:45:02 <c_wraith> what's wrong with parMap?  Though I think that should be parMap rseq, not parMap rpar
08:45:18 <cocreature> random abs fact:
08:45:25 <cocreature> > abs (-2^63) :: Int
08:45:27 <lambdabot>  -9223372036854775808
08:45:31 <infandum> c_wraith: rseq does the same thing
08:45:46 <infandum> c_wraith: the code would be: sequence . parMap rseq f . replicate 10 $ 1000000
08:45:57 <infandum> although obviously the sequence part makes it sequential (I think)
08:46:11 <infandum> right, because it just returns an IO thunk?
08:46:31 <c_wraith> infandum: rseq is more correct.  You want to actually evaluate those things, not create nested sparks to maybe evaluate them.  (parMap already creates a spark per list element)
08:46:37 <Tuplanolla> Random `abs` fact:
08:46:37 <Tuplanolla> > abs (surprise :: Double) >= 0
08:46:38 <ertes> helo
08:46:39 <lambdabot>  False
08:47:00 <infandum> c_wraith: Then why isn't it working?
08:47:01 <c_wraith> Tuplanolla: is surprise NaN?
08:47:07 <Tuplanolla> Yes.
08:47:26 <Cale> > surprise == surprise
08:47:28 <lambdabot>  False
08:47:30 <c_wraith> Tuplanolla: that's how IEEE754 defines floating point should work.
08:47:41 <Tuplanolla> Yes.
08:47:44 <c_wraith> Tuplanolla: not great, but at least Haskell is following the spec there.
08:48:23 <ertes> nitrix: there is an interesting difference between monadic FRP and AFRP there:  in AFRP you really want switching
08:48:35 <bollu> ertes: what is AFRP?
08:48:52 <c_wraith> infandum: your paste says that the parMap version does work
08:48:57 <infandum> ??
08:49:00 <nitrix> bollu: Arrowized FRP.
08:49:03 <infandum> oh yes
08:49:10 <infandum> that's not the monad version though
08:49:19 <infandum> that's (a -> a)
08:49:23 <infandum> not (a -> IO a)
08:49:29 <ertes> nitrix: in monadic FRP (reactive-banana, reflex) the story is a bit different:  without switching you may need to define a few more primitives, but other than that you can get very far without switching
08:49:40 <c_wraith> infandum: Ok, going to need to back up a few steps and be more precise.
08:49:40 <infandum> when I do the monad version it becomes sequential
08:50:17 <nitrix> ertes: Interesting.
08:50:24 <nitrix> ertes: I'm designing an FRP language.
08:50:54 <nitrix> ertes: Something with possibly only first-class behaviors and events.
08:51:29 <ertes> nitrix: most stateful systems can be expressed in terms of event scans (a.k.a. accumE, foldDyn, etc.)
08:52:01 <nitrix> I have to figure out the details, I'm still in the exploration phase, but I want to detatch from Haskell a little.
08:52:05 <ertes> nitrix: if you want to learn more get the source code of reflex and look into the Reflex.Class module
08:52:18 <nitrix> ertes: The biggest observation was that purity isn't a necessary with FRP.
08:52:19 <ertes> nitrix: see which combinators are defined in terms of 'switch'
08:52:28 <ertes> nitrix: these are the combinators you may need to make primitive
08:52:42 <ertes> nitrix: actually it is
08:52:55 <ertes> impure FRP is bound to go wrong in subtle ways
08:53:24 <ertes> the same way unsafePerformIO goes wrong
08:53:54 <nitrix> I think if you have a good topological sort and an intuitive way of explaning what will propagate and when, you're fine.
08:54:36 <ertes> nitrix: what is a Behaviour in "impure" FRP?  is it not something that acts like a function of time semantically?
08:54:39 <c_wraith> infandum, are you trying to speed up a pure computation, or run a bunch of IO actions at the same time? 
08:54:41 <nitrix> Which means looking at push,pull,push+pull and thinking outside the box, as well as changing the primities of the language. I'm actually keen to go with IO as uniqueness types.
08:54:52 <infandum> c_wraith: Uh...both?
08:54:58 <nitrix> ertes: It is.
08:55:14 <infandum> c_wraith: I'm trying to speed up a map on a list
08:55:23 <ertes> nitrix: and what is Event?  is it not something that acts like a function from time to a Maybe type?
08:55:26 <c_wraith> infandum, because haskell treats those as different things. 
08:55:39 <infandum> each function application takes seconds to run and I have thousands of them
08:55:45 <ertes> nitrix: or alternatively a potentially infinite time-ordered list of occurrences?
08:55:56 <nitrix> ertes: I guess my point is that you essentially have an entirely pure language, and even airbitrary mutations would be a non-issue, as the changes get propagated.
08:56:08 <infandum> and it's a function that takes a pure value and returns an IO
08:56:21 <ertes> nitrix: i think you want pure semantics with effects…  that's not impure
08:56:26 <ertes> the same way IO is not impure
08:57:16 <c_wraith> infandum, that doesn't sound like looking for speedup on a pure computation. 
08:57:34 <ertes> nitrix: consider this: creating an Event in reflex can introduce additional effects at certain points in your program…  so an Event is not necessarily effectless, but its semantics is pure
08:57:35 <infandum> c_wraith: No, in the end it returns IO [a]
08:57:35 <nitrix> ertes: I guess you're right. Excepted I get rid of all the monadic. I'm going with uniqueness types like Clean and the token for the RealWorld will end up being an Event of events possibly.
08:58:15 <nitrix> ertes: Again, really exploring at the moment.
08:58:25 <c_wraith> infandum, so the remaining thing to do is make sure your IO actions are actually doing all the work you want them to be doing. 
08:58:31 <infandum> so it goes basically slowF :: (a -> IO b) -> [a] -> IO [b]
08:58:34 <ertes> nitrix: yeah, with uniqueness types you could do something like that, but then you need to be careful how you connect the pure FRP model to the impure world
08:58:52 <infandum> c_wraith: And the IO comes from random sampling
08:59:02 <infandum> so it's not just a return
08:59:06 <ertes> nitrix: in particular i don't like how Clean does effects…  the idea that applying a function to a value could cause effects is weird to me
08:59:14 <infandum> but there are pure functions being used within that impure one
08:59:16 <nitrix> ertes: I just like the idea that I can arbitrarily update data structures in-place because I'm guaranteed they're unique, which haskell can't do, and the codebase would still remain manageable, the effects are well captured within the FRP framework.
08:59:23 <infandum> it's not a small function basically
08:59:40 <nitrix> ertes: Agreed.
08:59:47 <ertes> nitrix: yeah, that's totally fine, but even in a language with uniqueness types i'd still want monads for impure things
09:00:00 <c_wraith> infandum, then make sure that if evaluating the result is part of the IO action, it actually does so. 
09:00:08 <ertes> s/for impure things/to express real-world effects/
09:00:10 <nitrix> ertes: Isn't it possible to make all impure things appear pure?
09:00:21 <nitrix> ertes: Afterall, I have an event of events as input :P
09:00:33 <infandum> c_wraith: What do you mean?
09:00:34 <nitrix> (of the program)
09:00:41 <ertes> nitrix: how do you make, say, getLine pure?
09:01:02 <ertes> it's an observable effect
09:01:06 <infandum> like sum [1..x] isn't an evaluation, so I should fully evaluate it and return that result?
09:02:07 <nitrix> ertes: Sure, but that happens outside the FRP framework. Kinda like Haskell's IO. I'd just have getLine be some Stream String, an event of a String.
09:02:08 <ertes> nitrix: the idea of making in-place updates entirely effectless is fine with me, because it's something that is completely in our control and not visible from the outside modulo time/memory consumption
09:02:35 <ertes> nitrix: what if nobody consumes that stream?
09:02:41 <c_wraith> infandum, basically, yes. but beware of what it takes to evaluate more complex data structures than an Integer
09:02:41 <ertes> nitrix: then you never read?
09:02:53 <nitrix> ertes: It is blocking and when it gets a line, it presumably pushes to your... "application graph". I know you hate that term :P
09:03:22 <nitrix> ertes: That's what I need to figure out. I probably want a mix of push and pull.
09:03:29 <infandum> c_wraith: AHAH! That did it! f x = evaluate . sum $ [1..x] works!
09:03:32 <ertes> nitrix: you're basically doing lazy I/O there
09:03:38 <nitrix> ertes: I'm actually greedy enough that I want to allow events to be also synchronous & asynchronous.
09:03:52 <infandum> but now the question is whether there are unexpected side effects, like memory consumption
09:04:04 <ertes> nitrix: whether an effect happens depends on whether you apply a certain function to a certain value…  doesn't that feel "wrong"?
09:04:59 <c_wraith> infandum, that will work in some cases. sometimes you'll need a more complex way to evaluate the result. 
09:05:05 <ertes> nitrix: perhaps my point is: your language should have sane I/O semantics, and even in your language FRP should probably be a library rather than something built-in
09:05:10 <nitrix> ertes: Is it any different than the operational semantics of haskell where evaluation triggers the lazy IOs?
09:05:14 <c_wraith> infandum, it depends on the result type. 
09:05:40 <ertes> nitrix: no, and you probably know the general opinion on lazy I/O =)
09:05:55 <infandum> c_wraith: But the input type and intermediates don't matter? Then it should be fine
09:05:59 <c_wraith> infandum, if you want something that takes multiple types into account, look at the NFData class 
09:06:34 <c_wraith> and the associated deepseq package. 
09:06:38 <nitrix> ertes: You're right that it is quite painful, but I can't really see how to prevent that. I can make it non-lazy by pushing eargerly. But I can't think of how you'd remove the side effect part.
09:06:59 <infandum> my final type is (Double, Double)
09:07:00 <ertes> nitrix: i feel like you will basically reinvent haskell with uniqueness types, and then just to be safe implement FRP as a library (there is no reason for it to be part of the language, so better don't bloat it with it)
09:07:07 <nitrix> ertes: Clearly, you need to allow branching and certain functions to conditionally have IO effects.
09:07:17 <c_wraith> infandum, evaluate each double separately 
09:07:36 <ertes> nitrix: sure, and for those you need semantics…  IO has a really solid semantics
09:07:39 <c_wraith> infandum, or else all evaluate will do is make sure the (,) constructor was evaluated. 
09:07:43 <infandum> c_wraith: Yeah, I've run into NFData issues in the past, as there were no instances for some nested types
09:08:00 <ertes> nitrix: the thing is:  in haskell some things are IO (or ST) that really should be pure, but we lack uniqueness
09:08:09 <nitrix> ertes: I was told there's very little hope to see uniqueness make its way in Haskell. The GHC runtime has made too many assumptions.
09:08:34 <ertes> nitrix: i'm not saying you shouldn't do it…  i'm just telling you what you might end up with =)
09:08:52 <nitrix> It's very likely; but I might also be able to simplify a lot the language.
09:09:24 <ertes> nitrix: start with one simplification right away:  don't build FRP into your language =)
09:09:34 <nitrix> Working in a language that's make FRP as its main paragdim would turn out really interesting imo.
09:09:40 <nitrix> ertes: Why D:
09:09:57 <ertes> nitrix: because FRP is an abstraction
09:10:01 <ertes> it should be a library
09:10:11 <ertes> write some language/RTS support to make FRP easy and efficient to implement (and then there is little reason *not* to have switching either)
09:10:13 <berndl> ^
09:10:45 <ertes> then implement it as a library…  as a bonus it will make FRP not something magic, but something that can be understood in terms of your simple language and its semantics
09:11:15 <nitrix> ertes: That has always been my general take on building frameworks like those and coming from you, I know I should really value this advice, but my heart can't help but get excided at an FRP language.
09:11:51 <ertes> nitrix: the problem is:  there is no such thing as an FRP language…  it's just a programming language with a certain abstraction awkwardly built-in and non-optional =)
09:12:01 <berndl> What would make the language FRP? I don't even see how that could work.
09:12:10 <ertes> again: FRP is just an abstraction…  would you want the Monad class to be built into haskell?
09:12:15 <nitrix> ertes: I'm essentially making the statement of "let's think outside the box and see what would X or Y imply if it was a language construct".
09:12:47 <ertes> nitrix: if your core language is as expressive as haskell, then it fully covers FRP
09:13:11 <ertes> in other words: i can tell you right now that it won't make a difference, except that it will bloat your language =)
09:13:13 <berndl> nitrix: Do you consider Elm to be an FRP language?
09:14:32 <nitrix> ertes: I want to play with various ideas, like, what if you cannot have functions? Nothing takes arguments :P
09:14:37 <nitrix> brb meeting
09:14:47 <ertes> nitrix: again ask yourself: what is Behaviour?  is it not a type constructor that denotes varying values?  what is Event?  is it not a type constructor that denotes discrete occurrences?  what is, say, 'hold'?  is it not a function?
09:15:11 <ertes> nitrix: if you can't have functions, you can't have 'hold' =)
09:19:25 <Cale> hold is not quite a function, since its result depends on the moment at which it occurs: occurrences of the Event prior to that moment are disregarded
09:20:57 <ertes> Cale: last time i checked the top-level type constructor of 'hold' is (->) =)
09:21:04 <Cale> Well, fair enough :)
09:21:30 <Cale> But it's a function producing an action which when executed will create the Behaviour then :)
09:22:02 <infandum> c_wraith: Ah, bang patterns work as well. That was definitely the issue, it was evaluating the IO thunk whereas the other went the whole way through. Thank you for your help!
09:22:26 <Cale> Or you might regard the current moment as being an argument to that function, but it's tough to make that actually work.
09:22:32 <ertes> Cale: that was a response to nitrix: "what if you cannot have functions? Nothing takes arguments :P"
09:23:16 <ertes> i think a function is the most general thing that can take something and give something back in return
09:24:45 <Cale> Reading over the conversation, I agree with you on *that* point, but I do think there is lots of room for compilers that have specific knowledge of some various FRP primitives.
09:25:21 <ertes> Cale: sure, build special support for FRP into the language/RTS, but don't make the actual FRP a language feature
09:25:57 <Cale> Hmm, what do you mean there?
09:26:17 <ertes> Cale: the problem i see with building the actual abstraction into the language is complexity of semantics…  you can no longer reduce the FRP semantics to core semantics…  you need to actually specify it
09:26:35 <nitrix> (back)
09:26:51 <ertes> Cale: that makes the language semantics very complicated
09:27:25 <nitrix> ertes: I was just trying to show how unrestrictive I'm trying to go with this thinkering.
09:27:39 <nitrix> ertes: Of course, you elimited functions, your language breaks rather quickly.
09:27:56 <Cale> It would certainly involve quite an engineering effort on multiple fronts to do in a way that would be worthwhile.
09:28:09 <ertes> imagine IO would be a language construct…  it's not quite a type constructor, but something that looks like one
09:28:21 <Cale> I wouldn't recommend doing this right at the moment, but I think it'll eventually need to be done.
09:28:31 <Cale> Well, IO right now is more or less built in.
09:28:42 <ertes> but in haskell IO is not part of the language…  it just has lots of support from the language/RTS
09:28:48 <Cale> uhhh
09:28:58 <Cale> I'm not sure you can say that, it's basically part of the language.
09:29:05 <Profpatsch> pmade: Nope, the types I want to parse into are e.g. Maybe Int.
09:29:22 <Profpatsch> And the strings might have a formatting of "24 5 6 6   66543"
09:29:32 <Cale> Unless you're referring to GHC's hackery with State# RealWorld
09:29:34 <ertes> Cale: i mean from a language viewpoint…  a haskell user doesn't have to even acknowledge that it's built-in
09:29:41 <Profpatsch> That’s always the problem with human-generated string content.
09:29:57 <Cale> Just because something is built-in doesn't mean it has to be poorly designed.
09:30:30 <nitrix> ertes: Cale: My reasoning is, I want in-place updates, to do in place updates in a pure setting, I need uniqueness types. Already Haskell falls short here. Then if I have the user "mutating" things at will, I want to avoid issues that'd be akind to global variables or side-effects, and actually notify the application about these changes, and so, if FRP is enforced, now you end up with a very robust language.
09:31:46 <nitrix> One that's entirely reactive; I/O are modelled withing the FRP framework as events, you also allow async events and now you have concurrency, etc.
09:32:11 <ertes> let me simplify my point:  i like the way IO is done in haskell…  if you understand how types and functions work, you can learn how IO works…  semantically it reduces to a very small core language…  does that make sense?
09:32:13 <Cale> nitrix: Haskell can do in-place updates... it's just you need to specify explicitly what's supposed to occur when you're doing it.
09:32:31 <ertes> of course IO is built-in, but you don't see it (unless you look behind the curtain)
09:32:43 <Cale> Writes to mutable unboxed arrays will be in-place.
09:33:22 <Apocalisp> So, following https://en.wikipedia.org/wiki/Initial_algebra, I don't think I understand why `Nat` forms an initial algebra for `Maybe`
09:34:08 <ertes> nitrix: oh, BTW, you really don't want to build all of I/O on top of FRP, because then you end up with something horrible that we already had in haskell =)
09:34:14 <Cale> Apocalisp: Well, what does it mean that something is an initial algebra for Maybe?
09:34:17 <ertes> nitrix: main :: [Response] -> [Request]
09:34:31 <ertes> nitrix: that was the way I/O was done before IO
09:34:45 <ertes> (one of the ways…  i think there were others as well)
09:34:49 <nitrix> ertes: main :: Stream (forall a. Stream a) -> Stream (forall b. Stream b) ?
09:34:55 <nitrix> Ahah
09:35:16 <nitrix> ertes: Curiously, what were the issues with it?
09:35:40 <ertes> nitrix: try to write an interactive command line application using 'interact'
09:35:50 <ertes> to get an idea of what's wrong with it =)
09:36:15 <nitrix> Do I understand this right that it freezes the whole app?
09:36:24 <Apocalisp> Cale: if `f: Maybe a -> a` is an initial algebra, then for every other algebra `g: Mabe b -> b` there's a unique `h` such that  m . f = g . fmap m
09:36:27 <ertes> nitrix: nope, haskell is lazy
09:36:37 <Cale> Apocalisp: First of all, Nat is a Maybe-algebra with the map Maybe Nat -> Nat which sends Nothing to Zero, and Just n to Succ n
09:36:40 <nitrix> :t interact
09:36:41 <lambdabot> (String -> String) -> IO ()
09:36:47 <ertes> nitrix: you can send a prompt, then depend on more of the input string
09:36:53 <Apocalisp> Cale: Yes, totally buy that :)
09:37:09 <ertes> nitrix: but don't cheat…  no monads allowed =)
09:37:13 <Cale> So, let's call that function n : Maybe Nat -> Nat
09:37:29 <Cale> So for any other Maybe algebra, say, A with f: Maybe A -> A
09:37:45 <Cale> there's supposed to be a unique Maybe algebra homomorphism Nat -> A
09:37:59 <nitrix> ertes: Ah you can't loop?
09:38:06 <Apocalisp> right, but do I believe that?
09:38:15 <ertes> nitrix: sure you can…  here is 'cat':  interact id
09:38:17 <Cale> let's say h: Nat -> A
09:38:19 <ertes> nitrix: that's a loop
09:38:32 <Cale> So, let's figure out what properties that h would have, according to the laws for a Maybe-algebra homomorphism
09:38:47 <Cale> and see that they actually determine it uniquely
09:39:17 <Apocalisp> h . n = f . fmap h, right?
09:39:25 <Cale> right
09:39:38 <Cale> These are both functions of type Maybe Nat -> A
09:39:58 <Apocalisp> yes
09:40:09 <Cale> So we have  h (n Nothing) = f (fmap h Nothing)
09:40:25 <Cale> We know what n Nothing is, it's Zero
09:40:34 <Cale> and fmap h Nothing is Nothing
09:40:48 <Cale> So h Zero = f Nothing
09:40:48 <ertes> nitrix: try this exercise:  write a program that repeats the following procedure forever: ask for the user's name (with a prompt), read the name, then greet the person using their name
09:40:52 <Apocalisp> so `h Zero = Nothing`
09:40:53 <Cale> yes?
09:40:58 <Apocalisp> sorry, f Nothing
09:41:01 <ertes> nitrix: template:  main = interact _f
09:41:12 <Cale> and now for the Just case...
09:41:22 <Cale> h (n (Just x)) = f (fmap h (Just x))
09:41:29 <Cale> n (Just x) = Succ x
09:41:36 <Cale> and fmap h (Just x) = Just (h x)
09:41:41 <Cale> So we get:
09:41:49 <Cale> h (Succ x) = f (Just (h x))
09:42:08 <nitrix> ertes: GHCi is complaining about semi-closed handles.
09:42:17 <Cale> So, between these two equations, we have a recursive definition of h
09:42:22 <ertes> nitrix: if you use GHCi, use :main
09:42:52 <Apocalisp> Cale, that's awesome
09:43:24 <Apocalisp> what if we didn't already know that Nat is initial? Could we find it just from these properties?
09:43:59 <nitrix> ertes: Oh I kind of see what the problem is. You cannot read more from stdin once you've output to stdout in a back-and-forth fashion?
09:44:20 <ertes> nitrix: no the program is possible
09:44:29 <nitrix> ertes: I'd expect a lazy lan -- ok okay.
09:44:47 <nitrix> I wish I could attempt it but I'm having issues with STDIN being empty now.
09:44:52 <ertes> nitrix: the trick is to pattern-match on the remaining input string at the right time
09:45:14 <Cale> Well, Nat is a fixed point of Maybe, up to isomorphism.
09:45:55 <Cale> Like, if we define  data Fix f = In (f (Fix f))
09:46:04 <Cale> Then Fix Maybe is roughly the same thing as Nat, right?
09:46:21 <Cale> (perhaps that should be newtype)
09:46:22 <Apocalisp> yes, alright. That's easy
09:46:29 <Apocalisp> very cool
09:46:38 <mpickering> Is there a nix expression which builds all stackage packages? 
09:47:55 <Cale> mpickering: Looking to turn your computer into a space heater? :)
09:48:14 <mpickering> That's the plan..
09:51:19 <nitrix> ertes: Does your FRP library lets you make a data structure containing behaviors? These behaviors would be able to react to events as well as trigger other events if it was a Dynamic, right?
09:52:37 <nitrix> Maybe I don't need in-place updates, if my values are all time-varying ._.
09:52:55 <Profpatsch> mpickering: It’s unfortunately not really possible with nix-build
09:53:06 <Profpatsch> Because abort and assert are too strict.
09:53:21 <Profpatsch> But nix-env skips over broken packages via a C++ escape hatch.
09:53:46 <mpickering> What do "abort" and "assert" do?
09:53:55 <ertes> nitrix: you mean wires?  sure, but of course only within Wire
09:53:56 <Profpatsch> Which should totally be forbidden and eschewed.
09:54:03 <ania123> can one send me a link where I can see problems related to higher order functions?
09:54:21 <mpickering> I want to build all the packages and measure the size of the hi files specifically 
09:54:26 <Cale> nitrix: Behaviours don't generally *trigger* Events, but sure, you can put Behaviours and Events and other FRP things into data structures.
09:54:32 <mpickering> so setting up an environment with all the external deps would be enough
09:54:35 <Profpatsch> mpickering: you might get lucky with nix-env.
09:54:51 <Profpatsch> Or deploy Hydra. :P
09:55:02 <mpickering> Whatever someone says is best 
09:55:11 <Cale> I guess it's a little weird with Arrow-y FRP
09:55:12 <mpickering> I don't know the differences yet
09:55:14 <Profpatsch> Hm, or if you can get a list of all package names you can loop with bash.
09:55:46 <mpickering> I did that before with a dockerfile
09:56:27 <mpickering> but how does nix deal with c dependencies for haskell packages?
09:56:40 <mpickering> I assume that information is in the nix expression for that package?
09:56:58 <Profpatsch> mpickering: The C dependencies? Yeah.
09:57:09 <Profpatsch> Or systemDependencies in general.
09:57:17 <mpickering> So it would be way more convenient to say "build these 1000 expressions" 
09:57:20 <Profpatsch> mpickering: generic-builder.nix
09:57:24 <mpickering> but you say that isn't possible?
09:57:32 <Profpatsch> Well, it is probably possible.
09:57:37 <Profpatsch> Since Hydra can do it as well.
09:59:23 <Profpatsch> mpickering: nix-instantiate --eval -E 'builtins.attrNames (import <nixpkgs> {}).haskellPackages'
09:59:28 <Profpatsch> There you go.
09:59:50 <Profpatsch> Add --json
09:59:58 <Profpatsch> And you are good to go.
10:00:17 <mpickering> great thanks
10:00:28 <Profpatsch> Should be an aeson-lens one-liner from there.
10:00:50 <domenkozar> anyone compiled a static binary with GHC on OSX?
10:00:51 <mpickering> --json tells me where the build products are put?
10:01:01 <Profpatsch> Just execute it.
10:01:15 <mpickering> ok
10:02:40 <mpickering> So that tells me all the haskell packages, then I can loop over them and build each one or is there a more principle way to build an expression?
10:03:17 <ertes> nitrix: in case you're curious: https://gist.github.com/esoeylemez/74cc64a760373ff23521b0aa879ffeaa
10:04:16 <nitrix> ertes: Turn that into an Event String and it seems reasonable :P
10:05:55 <ertes> nitrix: turn that into a state-monadic action and you have what we basically have now, except with that weird "state of the universe" notion and heavy reliance on lazy I/O
10:08:28 <nitrix> Wouldn't an Event String model this better?
10:15:37 <ania123> can one send me a link where I can see problems related to higher order functions?
10:18:15 <c_wraith> ania123, do you mean some sort of exercise set? 
10:18:27 <ania123> right
10:18:38 <ania123> I just want to play on it
10:18:40 <Tuplanolla> One vote for löb.
10:21:12 <c_wraith> ania123, well, there's https://en.m.wikibooks.org/wiki/Haskell/Higher-order_functions but other people may have better suggestions. 
10:22:43 <Tuplanolla> Here's the exercise: implement `loeb :: Functor f => f (f a -> a) -> f a` and see if your solution has any useful applications.
10:23:11 <c_wraith> Tuplanolla, that one is a bit more advanced than most. :P
10:23:33 <Tuplanolla> It's a bit tricky.
10:23:50 <Tuplanolla> There's an even trickier variant with error handling.
10:24:22 <byorgey> that also requires understanding Functor.  Presumably if someone is just starting out with higher-order functions they haven't seen Functor yet.
10:24:39 <c_wraith> it's better to not need to worry about higher kinded types at the same time you're just trying to get a grasp on higher order functions 
10:38:00 <Profpatsch> mpickering: You go over them and build haskellPackages.${package}.
10:38:21 <Profpatsch> It’s all just dynamic string concatenation anyway.
10:39:25 <ertes> nitrix: not in this case…  try to write a REPL-style application using FRP…  you're basically reinventing 'interact' and then modelling a state monad on top of it
10:39:39 <ertes> nitrix: in other words: FRP is not good for everything =)
10:55:17 <nitrix> :(
10:58:17 <Sonolin> ertes: why does interact (unlines . map (++"!") . lines) not work, but interact (unlines . map (show . length) . lines) does?
10:58:21 <dfeuer> Don't worry about the time zone, phadej. You emailed the answer :-)
10:58:35 <dfeuer> Sonolin, what does "not work" mean?
10:58:36 <Sonolin> I'm assuming something to do with laziness, but I tried map ("Hello, " ++) and still not working as I want it to
10:58:56 <Profpatsch> Can I get some feedback on the API of https://github.com/Profpatsch/libnix-haskell
10:59:00 <nitrix> ertes: Can I ask for a little extra since me getting up to speed with wires is going to require a considerable investment in my part and I kind of need a proof of concept... could you devise an example of a stateful program which has a data structure like Map and Behaviors as values in it, and two updates performed on a given value, one by looking up the data structure O(log n) and the other, directly
10:59:02 <nitrix> touching the behavior O(1)?
10:59:08 <Profpatsch> Especially how I do errors.
10:59:10 <Sonolin> well the first one just spits out everything I type, then when I hit enter it outputs a "!" on a single line
10:59:33 <dfeuer> Sonolin, the problem is that you're trying to add "!" to the *end* of the output. That's necessarily strict. You need to add it to the beginning instead.
10:59:50 <nitrix> ertes: Maybe both would print to stdout or something, I just want to see O(1) in-place updates within a data structure, without the O(log n) cost of rebuilding it, which should be feasible with time-varying values, right?
10:59:53 <monochrom> !indeed :)
11:00:06 <Sonolin> well, interact (unlines . map (show . length) . lines) is not lazy (the show . length part at least)
11:00:19 <glguy> Sonolin: Perhaps you're confused by the standard input being echoed back to the screen?
11:00:34 <dfeuer> Sonolin, you're *mapping* show.length over the lines, so you only deal with one line at a time.
11:01:10 <dfeuer> Sonolin, try ("!"++) instead. Does that work?
11:01:27 <Sonolin> it outputs, but it begins outputting *before* my newline is  entered
11:01:35 <Sonolin> which I suppose makes sense since its lazy
11:01:52 <Sonolin> but I just don't understand why interact (unlines . map (++"!") . lines) doesn't work
11:02:01 <glguy> It does work
11:02:13 <dfeuer> Sonolin, think about what (++"!") does.
11:02:42 <Sonolin> ok, well it has to parse the entire list in order to append the "!" to the end
11:02:51 <dfeuer> Yup.
11:02:54 <Sonolin> but, show . length has to parse the entire list too, right? 
11:03:22 <dfeuer> Sonolin, the "list" it's parsing entire is a single line.
11:03:24 <glguy> Sonolin: ++ doesn't have to consume the whole list to start producing its result
11:03:38 <nitrix> ertes: If it can do that, I'm sold to haskell for a lifetime :P
11:03:52 <nitrix> ertes: (And FRP :P)
11:04:15 <Sonolin> glguy hmmm.. in the case of "Hello,"++ that makes sense to me, but (++"!") would have to parse the whole list to produce output right?
11:04:18 <dfeuer> There don't seem to be a lot of people in #ghc right now. Is there someone here who could try to compile http://lpaste.net/6557471048655175680 under GHC HEAD and let me know if it crashes with a GHC panic?
11:04:23 <glguy> Sonolin: ++ doesn't have to consume the whole list to start producing its result
11:04:44 <glguy> (x:xs) ++ ys = x : (xs ++ ys)
11:05:00 <Sonolin> ah, I see
11:05:14 <glguy> as soon as that first (:) can be determined, ++ can produce output
11:05:20 <dfeuer> Unless I'm confused, that's still the source of the problem. Let's consider what we get.
11:05:49 <dfeuer> Oh wait.
11:05:52 <Sonolin> so it starts to produce output, but its doesn't append the "!" until the whole string is parsed
11:05:53 <dfeuer> No, I'm very confused.
11:05:56 <dfeuer> Sorry.
11:06:05 <Sonolin> its starting to make sense now :)
11:06:21 * dfeuer shouldn't give advice before he's finished waking up.
11:06:46 <dfeuer> Sorry, Sonolin.
11:07:28 <Sonolin> np
11:16:50 <ertes> nitrix: FRP can do it in principle, but wires can't without actually building the necessary support in
11:17:07 <nitrix> >:(
11:17:15 <ertes> nitrix: unfortunately haskell has no uniqueness…  otherwise there would be no need for special support
11:21:19 <ertes> nitrix: that support is planned, but i haven't done it yet…  it requires some engineering
11:21:39 <nitrix> So, roll my own language. Gotcha :P
11:21:39 <ertes> nitrix: i think none of the current FRP implementations i know support it right now
11:22:24 <ertes> nitrix: i really don't want to design my own language, but if you do it and get something practical, i'll be happy to use it =)
11:22:37 <ertes> nitrix: but please don't omit functions =P
11:23:09 <nitrix> Ahah. I'll make it a compiler flag. -ertes :P
11:24:14 <nitrix> Even if I end up re-inventing the wheel, I'll actually learn and understand the decisions involved in the design in the process.
11:24:27 <nitrix> So regardless how far I get, it'll still be a fun experiment.
11:26:19 <mmachenry> When I switched to Stack from just installing GHC I lost a piece of my workflow. Basically ghci <file>. I notice that many people complained https://github.com/commercialhaskell/stack/issues/1361 and it was reported fixed on that page. But it still doesn't work for me. I get "cannot find direcory" what am I doing wrong?
11:26:52 <ertes> nitrix: i wonder if i should be evil now and tell you about locally nameless bindings =)
11:27:05 <mmachenry> I am prepared for evil
11:27:27 <ertes> mmachenry: that wasn't for you though =)
11:27:39 <ertes> mmachenry: but i can be evil to you as well and tell you about nix ;)
11:27:49 <mmachenry> I still request evil treatment to the best of your ability on my own question.
11:28:24 <mmachenry> ertes: I know about Nix. I'm trying to get this working on a Mac
11:28:40 <ertes> ah…  does nix have issues on mac?
11:28:53 <ertes> (does it even work?)
11:29:16 <mmachenry> Not sure. I have heard stack is the recommended way. I'm not using NixOS for sure. 
11:29:27 <kobalt_> how can I add a constraint on an associated type ? e.g. class X a where { type T a :: Monad }
11:29:37 <mmachenry> I know you can install just the package manager but I've never tried or heard about it on a Mac
11:30:07 <sm> mmachenry, doesn't stack exec -- ghci <file> work ?
11:30:36 <ertes> mmachenry: it depends a lot on what you're doing (basically *why* you're using stack), what platforms you want to develop/deploy on (yourself, not your user) and what learning curves you're willing to climb
11:30:40 <mmachenry> sm: Ah yes, thank you.
11:31:02 <mmachenry> Is that what everyone does if they are just playing around with a simple module they have written?
11:31:29 <ertes> mmachenry: if you're using stack, because "it's the recommended way", then perhaps you should just go back to your own workflow…  stack is not the new cabal-install, but it solves a different problem, and it does so with a few trade-offs
11:31:54 <mmachenry> much of my common workflow got more complicated to type out on the command line when I installed stack. I'm looking to create some aliases. Are there a common set of aliases that people use? Does anyone alias ghci=stack ghci?
11:31:56 <ertes> s/own/old/
11:32:01 <sm> pretty much, until "stack ghci" gets a bit smarter
11:32:18 <mmachenry> ertes: I do need stack for what it does well.
11:32:30 <mmachenry> Reproducible builds in my projects has been very helpful.
11:32:45 <mmachenry> I just miss "ghci" oh hey what's 13*85?
11:32:54 <mmachenry> And sure I can do stack ghci
11:33:01 <mmachenry> And now I know how to load a file with that.
11:33:10 <ertes> yeah, then stack and nix are your friends…  which one is really up to you…  nix has a few trade-offs of its own (doesn't work everywhere, steeper learning curve)
11:33:15 <mmachenry> Maybe I'll alias ghci = stack —exec ghci
11:33:20 <dfeuer> mmachenry, how do you load a file with that, other than :l ?
11:33:48 <mmachenry> dfeuer: Yes, I do that a lot. 
11:34:11 <kadoban> It looks like 'stack ghci somefile.hs' is supposed to work, maybe it got broken
11:34:48 <dfeuer> kadoban, it's broken on whatever version I'm using. :/
11:35:02 <kadoban> Appears so on mine as well.
11:35:13 <kadoban> I'll check if that issue has been noted yet later, if nobody else does.
11:35:51 * sm suggests alias stack-ghci="stack exec -- ghci"; alias stack-pkg="stack exec -- ghc-pkg"; alias stack-list="stack-pkg list"
11:36:22 <kadoban> Does one need 'stack exec -- ghc-pkg' ever?
11:37:37 <sm> for unregistering things, perhaps
11:39:18 <sm> I've wanted that once or twice (but didn't remember the stack-pkg alias)
11:39:43 <sm> I use stack-list often enough to justify the alias
11:41:11 <Tuplanolla> I never use aliases since I always forget they don't work with `xargs`.
11:41:30 <kadoban> sm: I don't think I've ever used that either, maybe I should look into it.
11:47:16 <abhiroop> I was wondering how do stream programming libraries like conduits/pipes handle back pressure
11:47:17 <abhiroop> ?
11:47:49 <rhzz> hello
11:48:05 <abhiroop> Especially in a language where laziness is inherently a property how does it deal with back pressure
11:48:51 <Bor0> what's pressure in that context?
11:49:36 <sm> I'd like to share a small haskell success. I just managed to script downloading data from my bank, something I've wanted for years, with http://hackage.haskell.org/package/webdriver
11:49:39 <bollu> how does quickCheck figure out the arity of the function you pass to it?
11:49:48 <jle`> sm: congrats :)
11:50:09 <jle`> bollu: it doesn't figure it out directly
11:50:19 <jle`> bollu: what are you referring to, exactly?
11:50:27 <jle`> remember that in Haskell, all functions have arity 1
11:50:34 <abhiroop> @Bor0 doesn't backpressure has a universal meaning in the context of stream programming
11:50:34 <lambdabot> Plugin `more' failed with: Prelude.init: empty list
11:50:48 <glguy> abhiroop: @ is for bot commands
11:50:55 <Bor0> abhiroop, probably. I need to read up on that
11:51:03 <bollu> jle`: ah
11:51:09 <bollu> jle`: it does the printf tricj?
11:51:11 <bollu> trick*
11:51:30 <abhiroop> basically when the producer is producing at a faster rate than the consumer can consume
11:51:32 <bollu> jle`: the fact that I can give testProperty a function of whatever arity and it tests it
11:51:46 <jle`> bollu: ah, yeah.  it's a little similar but different than the printf trick
11:51:48 <abhiroop> I think its avery general situation in any stream systems
11:51:59 <bollu> jle`: could you elaborate?
11:52:02 <Bor0> abhiroop, I assumed it was about rates, thanks for the explanation ;)
11:52:31 <rhzz> I'm trying to make haskeline bind my home key to go to the beginning of the line but I'm so far unsuccessful... I tried with "bind: home ctrl-a" in emacs mode
11:52:42 <jle`> bollu: any 'Testable' instance can be tested
11:53:02 <jle`> and if 'p' is testable, and there's an Arbitrary instance for 'a', then you can test an 'a -> p', right?
11:53:18 <jle`> just generate an arbitrary a, and apply it to the function, and test the 'p' you get
11:53:42 <bollu> jle`: right
11:53:51 <jle`> Bool is testable, and Int is an instance of arbitrary, so you can generate random Int's.  so (Int -> Bool) is testable
11:53:56 <jle`> and yeah, that's all you need
11:54:01 <Tuplanolla> In fluid mechanics back pressure is at the other end, abhiroop.
11:54:09 <jle`> (Int -> (String -> Bool)) is testable
11:54:23 <jle`> because Bool is testable, so (String -> Bool) is testable, so Int -> (String -> Bool) is testable
11:54:37 <jle`> and Double -> (Int -> (String -> Bool)) would also be testable
11:54:40 <bollu> right, that clicks :)
11:55:29 <rhzz> anyone knowledgeable in haskeline?
11:55:41 <abhiroop> Yeah well in fluid mechanics I guess back pressure is basically the pressure felt by the fluid while traversing through pipeline
11:55:42 <jle`> bollu: to test a (Arbitrary a, Testable p) => a -> p, you'd just get an arbitrary 'a', apply it to the function, and test the 'p' that results
11:56:03 <abhiroop> Am I right?
11:56:19 <jle`> the instance is recursively defined, so it just repeatedly does that until it sees a base case for p, like Bool
11:56:40 <Tuplanolla> abhiroop: http://www.engapplets.vt.edu/fluids/CDnozzle/fig1.gif
11:56:52 <jle`> bollu: so it doesn't exactly calculate the arity and then generate the right amount of arguments.  it just keeps on generating arguments and applying them until it hits a base case, like Bool
11:56:53 <abhiroop> Most of stream programming use terminology pertaining to fluid flow like conduits, pipes, back pressure sprouts, bolts etc
11:57:10 <jle`> rhzz: best to just ask :)
11:57:13 <bollu> jle`: I see, right
11:57:14 <jle`> (your question)
11:57:55 <verement> rhzz: what do you want to know?
11:58:03 <abhiroop> Oh right
11:58:19 <rhzz> verement: I'm trying to make haskeline bind my home key to go to the beginning of the line but I'm so far unsuccessful... I tried with "bind: home ctrl-a" in emacs mode
11:59:10 <abhiroop> Well in distributed streaming systems generally each consumer would specify their max buffer and generally there would be a coordinator orchestrating the back pressure among a series of nodes.
11:59:21 <abhiroop> Wonder how conduits/pipes handle all that
11:59:49 <jle`> what is backpressure here?
12:00:09 <jle`> ah wait, i see
12:00:22 <abhiroop> Back pressure is when producer is producing at a rate faster than the consumer can consume
12:00:51 <jle`> are you asking about semantics, or implementation?
12:01:22 <abhiroop> I guess implementation
12:01:36 <glguy> there's no back pressure, things aren't produced until the consumer requests something
12:01:42 <jle`> like, how they chose to handle it and what behavior they want to have, or how they implement their handling/behavior?
12:01:46 <c_wraith> abhiroop, conduit/pipes both are pull-driven 
12:02:12 <abhiroop> Basically I am not that experienced with conduits/pipes I was just wondering does laziness gives an advantage to such systems.
12:02:21 <abhiroop> Oh I see
12:03:46 <verement> rhzz: not sure if the home key would be visible to haskeline… probably depends on the environment; for example my home key is intercepted by my terminal app to scroll the window
12:04:26 <rhzz> verement: I don't think my home key is intercepted, I can pass it to other programs
12:07:25 <verement> rhzz: maybe this will help: http://stackoverflow.com/questions/33720430/how-to-write-haskeline-so-that-ghci-or-haskeline-can-behave-properly-on-home
12:09:08 <hashme> Hey guys, I'm learning haskell and I've to learn Monads right now
12:09:22 <hashme> Can you suggest me good links where I can do it ^
12:09:48 <hashme> Somewhere I can learn quickly?
12:10:13 <jle`> my suggestion is to not learn about monads directly, and to just learn about how to use its instance, like Maybe, [], IO
12:10:19 <rhzz> verement: thanks! :)
12:10:30 <jle`> eventually you'll understand what monads are without even trying :)
12:11:29 <jle`> in fact, once you understand Maybe, etc., then the idea of monads will be rather anticlimactic and boring
12:12:32 <maerwald> Monads can be taught directly as well, it's just that most resources do a poor job at it and that is usually escalates in too much info when tried in this channel
12:13:01 <jle`> they can be taught directly, but nowadays i don't really see any benefit in it
12:13:07 <vshatskyi> Hi. Can I have a value type of which would contain a type level list? Like `a :: (Foo '[Int, String])`?
12:13:11 <maerwald> the approach: functor -> applicative -> monad -- is a pretty good chain to understand why we even want Monads
12:13:30 <maerwald> seeing the limitation of applicative
12:13:30 <jle`> vshatskyi: yes, it just depends on the definition of Foo
12:13:35 <jle`> vshatskyi: for example:
12:13:41 <jle`> :t Proxy :: Proxy '[Int, String]
12:13:42 <lambdabot> Proxy '[Int, String]
12:13:48 <jle`> there's an example :)
12:13:55 <maerwald> you won't understand all the properties just by staring at simple instances like Maybe
12:13:59 <hashme> Monads came first right? Then functors if I'm not wrong
12:14:27 <maerwald> that's not a chronological, but an educational order
12:14:30 <jle`> maerwald: yeah, of course; you'd have to work with and look at many different instances
12:14:34 <hashme> Ahh
12:14:42 <vshatskyi> Thanks, jle`.
12:14:45 <jle`> vshatskyi: it all comes down to how Foo is defined, basically
12:14:53 <jle`> just like any other type
12:15:30 <hashme> Can you guys give links? I mean other than Real World Haskell and Learnyouahaskell?
12:15:31 <maerwald> and just by looking at instances, chances are high you won't get familiar with Monad laws and will break them yourself
12:15:37 <Berra> What's a good use-case example for STM that isn't money transfer?
12:16:01 <maerwald> @where learnhaskell 
12:16:01 <lambdabot> https://github.com/bitemyapp/learnhaskell
12:16:16 <glguy> Berra, reading from one or more channels with time out
12:16:34 <maerwald> ignore the note about the haskell platform there, it's wrong
12:17:28 <Berra> glguy: Thanks - I'm not sure it's as conceptually simple as money transfer ( as an example that is )
12:18:48 <ertes> abhiroop_: backpressure isn't possible with stream frameworks (at least conduit, enumerator, iteratee, machines, pipes)
12:19:10 <ertes> abhiroop_: the *consumer* is primary, and the producer doesn't actually run until the consumer asks for input
12:20:21 <ertes> abhiroop_: stream processing works using deterministic coroutines, not concurrency
12:21:25 <ertes> Berra: money transfer is probably the least useful, but most intuitive example =)
12:22:33 <Berra> ertes: Right - the "least useful" factor is key there. Something a little more "everyday handy" would be good to give as an example.
12:22:42 <abhiroop_> ertes can you elaborate a little more on "stream processing works using deterministic coroutines"
12:22:43 <ertes> Berra: if you have ever created an auxiliary thread (one that does nothing other than concurrency coordination) or coded some locking mechanism (example: a third MVar to synchronise changes to two other MVars), then STM will be useful
12:23:03 <Berra> ertes: I can imagine that, but have not done it.
12:23:56 <ertes> abhiroop_: the best way to understand that is to implement a really simple variant of it yourself:  data Pipe a b r = Done r | Get (a -> Pipe a b r) | Put b (Pipe a b r)
12:24:17 <ertes> abhiroop_: this is a "concatenation" monad and a "producer/consumer composition" category
12:25:32 <rhzz> verement: it worked! thank you so much!
12:25:52 <jbayardo> Hey. I'm confused about strings. I want to write an IRC bot to play with sockets, and have to choose what representation I'm going to use. It seems that I have to choose between String, ByteString and Text, but I'm not sure which one to choose
12:26:22 <ertes> abhiroop_: the latter basically runs the consumer until it finds a Get, at which point it runs the producer until it finds a corresponding Put
12:26:42 <cocreature> jbayardo: these three types can be separated in two categories
12:26:53 <cocreature> jbayardo: ByteString is basically just a list of bytes
12:27:06 <ertes> abhiroop_: so you have two interlocked "procedures", and a common term for that is "coroutines"
12:27:08 <cocreature> jbayardo: so no character encoding or decoding is performed
12:27:24 <cocreature> jbayardo: String and Text both actually represent textual strings
12:27:48 <cocreature> jbayardo: String is a linked list of [Char], the problem with that is that is horribly inefficient.
12:27:54 <qmm> is there a reason to use type synonyms besides simply to make your code readable?
12:28:02 <cocreature> jbayardo: so basically there is very little reason to use String over Text
12:28:28 <cocreature> jbayardo: whether Text or ByteString is appropriate depends on whether you want to do decoding or whether you want to work on an array of bytes
12:28:36 <ertes> jbayardo: the relevant RFCs suggest that you should use ByteString, because IRC is actually not encoding-aware except that it uses ASCII for its protocol syntax…  the actual text has no specific encoding
12:28:50 <cocreature> qmm: nope, that’s literally what type synonyms are for
12:29:44 <jbayardo> Alright, and how do you deal with printing and so on?. I attempted to use OverloadedStrings, but even a simple print $ "Something" ++ bytestringhere didn't work
12:29:46 <bollu> ertes: sorry, I DCd
12:29:51 <ertes> jbayardo: you might prefer to use Text anyway and *assume* a certain encoding, perhaps with a fallback…  that's how most IRC clients work
12:30:05 <abhiroop_> ertes: what do the type parameters a b and r stand for
12:30:06 <ertes> bollu: hmm?  i didn't say anything
12:30:21 <ertes> abhiroop_: input, output, result respectively
12:30:31 <cocreature> bollu: hey, did you solve your issue? I have a few minutes so I could take a look now
12:30:34 <qmm> cocreature: thanks :)
12:31:01 <kadoban> jbayardo: The type of ++ only works on lists, so that'll really only work for String.  Since you have a ByteString on the right, that's definitely going to be broken.
12:31:09 <cocreature> qmm: you might be interested in "newtype" which is somewhat similar to type synonyms but actually creates a distinct new type
12:31:28 <kadoban> :t (++)
12:31:28 <ertes> abhiroop_: example:  lines :: Pipe Char Text r  -- this is a pipe that consumes Char and produces Text (at a lower rate most likely)…  and since it will never stop (streams don't "end"), it's polymorphic in the result type
12:31:29 <lambdabot> [a] -> [a] -> [a]
12:31:34 <qmm> cocreature: i'm aware of newtype, but that's something i haven't spent time understanding why i'd want to use it
12:31:46 <qmm> cocreature: iirc, it is useful for reducing memory
12:31:47 <jbayardo> kadoban: yeah, I figured as much, but I can't find similar functionality
12:32:05 <kadoban> jbayardo: You might be looking for (<>), from Monoid
12:32:25 <kadoban> (Data.Monoid that is)
12:32:31 <kadoban> :t (<>)
12:32:32 <lambdabot> Monoid m => m -> m -> m
12:32:38 <cocreature> qmm: it prevents you from accidentally mixing up things because they now have a different type
12:32:59 <cocreature> qmm: but they are represented identically at runtime so if you do need to convert between them there is no runtime cost associated with them
12:33:03 <jbayardo> Nice. Didn't know they did that. Thanks to all of you! :D
12:33:09 <ertes> abhiroop_: you should know that this version of Pipe cannot have effects, so you can't actually read a file or write to stdout *within* the chain
12:33:15 <kadoban> jbayardo: For Text/String/ByteString you can see (<>) as a generalization of (++). It'll work for any of those. 'welcome
12:33:28 <cocreature> I so want <> in the Prelude
12:34:49 <dfeuer> cocreature, yes, me too.
12:34:58 <abhiroop_> ertes: so to attain side affects say writing to 2 separate sinks what would the type Pipe look like
12:35:00 <qmm> data Point = Point { x :: Integer, y :: Integer } ; p = Point { x = 3, y = 4 } ; addCoords Point { x=x, y=y } = x + y ; addCoords' p = (x p) + (y p) -- is there a more concise way of writing an addCoords?
12:35:39 <qmm> cocreature: thanks for that explanation
12:35:42 <ertes> abhiroop_: there are a number of ways to introduce effects
12:36:18 <byorgey> qmm: you could also write  addCoords (Point a b) = a + b
12:36:31 <byorgey> i.e. you are not required to use the record field names.
12:37:17 <ertes> abhiroop_: the safest is a pair of corecursive types:  data Step a b m r = Done r | Get (a -> Pipe a b m r) | Put b (Pipe a b m r);  newtype Pipe a b m r = Pipe { runPipe :: m (Step a b m r) }
12:37:44 <qmm> byorgey: that's also the most readable, thanks!
12:38:26 <ertes> abhiroop_: a more convenient and also faster option is to add an extra constructor for effects:  data Pipe a b m r = Done r | Effect (m (Pipe a b m r)) | Get (a -> Pipe a b m r) | Put b (Pipe a b m r)
12:39:19 <ertes> abhiroop_: but that one has a caveat:  it's not the same thing, and it actually isn't a proper monad transformer…  you need to hide part of the API to make that lawful
12:40:22 <bollu1> typeApplication is part of which GHC version?
12:40:25 <ertes> abhiroop_: the fastest option that is also safe is probably the most mind-bending as well, if you're not used to it:  church encoding
12:40:26 <bollu1> is it only 8 and above?
12:41:14 <byorgey> bollu1: yes
12:41:23 <ertes> abhiroop_: newtype Pipe a b m r = Pipe { runPipe :: forall x. (r -> m x) -> ((a -> m x) -> m x) -> (b -> m x -> m x) -> m x }
12:41:28 <bollu1> byorgey: damn :/ I'm using it heavily in my library
12:41:44 <bollu1> byorgey: you can "disable" (conditionally compile) parts of your library right?
12:41:47 <ertes> abhiroop_: if that type didn't make any sense to you, just ignore it
12:42:31 <abhiroop_> ertes: Yeah the church encoded one didn't make much sense
12:42:49 <abhiroop_> But i was looking at conduit's base data type:
12:42:50 <abhiroop_> https://github.com/snoyberg/conduit/blob/master/conduit/Data/Conduit/Internal/Pipe.hs
12:42:59 <abhiroop_> It looks similar
12:43:16 <abhiroop_> I think I am getting a somewhat hang of it
12:44:30 <ertes> abhiroop_: try to implement the composition operator
12:45:01 <ertes> abhiroop_: (>->) :: Pipe a b m r -> Pipe b c m r -> Pipe a c m r
12:45:24 <ertes> abhiroop_: (>->) :: (Monad m) => Pipe a b m r -> Pipe b c m r -> Pipe a c m r
12:45:26 <ertes> sorry
12:46:21 <abhiroop_> Thanks ertes. Let me give it a shot.
12:47:18 <ertes> abhiroop_: there is a catch with pipes-style semantics:  if any link is Done, the whole chain is Done (you really have no other option using the type i gave you)
12:48:14 <Naughtmare[m]> :q
12:49:29 <abhiroop_> "if any link is Done" so ertes: you are talking about a chain of pipes and one of Pipes signal Done?
12:49:40 <ertes> abhiroop_: yeah
12:56:23 <DemiMarie> Are there any streaming parser combinator libraries?
12:56:23 <DemiMarie> Streaming = bounded memory use
12:56:24 <DemiMarie> in the library itself
12:57:42 <ertes> DemiMarie: attoparsec for machine-written stuff (protocols, file formats), trifecta for user-written stuff (source code, markup)
13:00:33 <jbayardo> Hey. So I have a list of servers, and I want to attempt connecting to each one of them in sequence, one after the other, and only do so if the previous one fails to connect. I could write this with a foldM, but is there something already done for this kind of pattern?
13:01:12 <Berra> I'm sure I've heard that do notation acts as a model for allowing better parallelism, but now I can't find any good sources for it. Is it not correct?
13:01:45 <byorgey> Berra: http://research.microsoft.com/en-us/um/people/simonpj/papers/list-comp/applicativedo.pdf ?
13:02:41 <byorgey> Berra: there's also a video of Simon Marlow's Haskell Symposium talk about it somewhere on youtube
13:03:43 <Berra> byorgey: I'm curious if do notation give any parallelism for free that is left out if explicitly hand-writing >>= or <$>
13:04:43 <byorgey> Berra: no, because do notation just desugars directly to >>= and >> (and you could easily translate uses of >>= and >> the other way into do-notation)
13:05:06 <Berra> byorgey: That answers my question, thanks.
13:05:37 <Berra> byorgey: Nothing special under hood for do notation in terms of parallelism that is
13:05:47 <byorgey> Berra: well, except for the paper I linked
13:06:05 <Berra> But that doesn't apply to vanilla Haskell
13:06:34 <byorgey> Berra: the point is that if you turn on that extension then do-notation can be desugared using Applicative operations when appropriate.
13:07:01 <byorgey> There's no reason in principle uses of >>= could not be similarly analyzed and turned into Applicative operations, but that is not done.
13:07:25 <byorgey> Berra: indeed, it requires an extension.  According to the Haskell standard, do-notation just desugars directly to >>= .
13:07:31 <maerwald> byorgey: except when the monad instance and applicative instance have fundamentally different behavior, which I believe, is the case for haxl
13:08:23 <byorgey> maerwald: right, good point.
13:09:00 <kobalt_> how can I add a constraint on an associated type ? e.g. class X a where { type T a :: Monad }
13:12:51 <hexagoxel> kobalt_: class Monad (T a) => X a where ..
13:12:52 <Berra> byorgey: Can I somehow prove or test that some applicative composition is run in parallel?
13:14:18 <kobalt_> hexagoxel: thanks a lot
13:22:51 <mtjmullen> maerwald: they have fundamentally different performance characteristics, but I believe that `<*>` and `ap` result in the same value, modulo IO
13:26:15 <maerwald> mtjmullen: well, the applicative is run in parallel I believe and I'm not really positive that it doesn't effect the value somehow (since it involves DB queries)
13:27:25 <dfeuer> If the instances are valid, <*> and ap should be observably equivalent.
13:28:21 <dfeuer> maerwald, what does haxl do fundamentally differently with them?
13:28:28 <maerwald> dfeuer: what I just said
13:28:33 <Michael-Dot> https://drive.google.com/open?id=0B9cg8ZXscw-bVGtpRjREbFYzZDA
13:29:24 <maerwald> as in: if someone would randomly change the code to use the Monad instance, it might very well change semantics of what happens at runtime
13:29:45 <grantwu> @ops
13:29:46 <lambdabot> Maybe you meant: pl oeis docs
13:29:52 <grantwu> er
13:29:59 <dfeuer> maerwald, ah, so the order of the queries may be different, which will affect behavior if someone changes the database in between?
13:30:12 <maerwald> we are talking about facebook :D
13:30:18 <maerwald> the data changes "in between" ;)
13:30:29 <grantwu> !ops
13:31:04 <mtjmullen> maerwald: that's what I meant by modulo IO
13:31:10 <lep-delete> :t \x -> \f -> f x
13:31:11 <lambdabot> t -> (t -> t1) -> t1
13:31:21 <mtjmullen> if the store is static, output should be the same
13:31:32 <sbrg> @where ops
13:31:33 <maerwald> mtjmullen: well, except you can't do "module IO" if it's inherently about IO :P
13:31:33 <lambdabot> byorgey Cale conal copumpkin dcoutts dibblego dolio edwardk geekosaur glguy jmcarthur johnw monochrom quicksilver Saizan shachaf shapr ski
13:31:36 <mtjmullen> but it's hard to have reasonable guarantees about IO regardless :P
13:31:41 <sbrg> grantwu: ^?
13:31:58 <Cale> sbrg: ?
13:32:07 <Cale> oh, grantwu ?
13:32:10 --- mode: ChanServ set +o glguy
13:32:10 --- mode: glguy set +b *!*@202.131.75.94
13:32:10 --- kick: Michael-Dot was kicked by glguy (link spam)
13:32:29 <Cale> ah, I missed whatever that was
13:32:46 <mtjmullen> maerwald: fair enough :P
13:32:49 <grantwu> Something to do with Crash Bandicoot
13:33:11 <Kuros`> Crash Bandicoot Adventure Installer.exe
13:33:18 <qmm> > map length $ Just "testing"
13:33:18 <mtjmullen> I think fraxl was the library that was designed to be a re-implementation of haxl?
13:33:20 <lambdabot>  error:
13:33:20 <lambdabot>      • Couldn't match expected type ‘[[a0]]’
13:33:20 <lambdabot>                    with actual type ‘Maybe [Char]’
13:33:35 <mtjmullen> I think fraxl, if IO is not involed, `ap` has the same results as `<*>`
13:33:43 <qmm> > fmap length $ Just "testing"
13:33:46 <lambdabot>  Just 7
13:34:36 <ertes> haxl probably just shouldn't insist on (<*>) being concurrent
13:35:33 <dfeuer> Or should work in a transaction or whatever?
13:36:13 <ertes> what does haxl actually bring to the table except an improper monad?  async already does the concurrency bit, and it does it properly
13:37:01 <ertes> (see the Concurrently type)
13:38:45 <mtjmullen> ertes: One of the main points of haxl was to make it usable in do notation
13:39:43 <shlevy> Is there a good pattern for printing a warning only the first time a given code path is hit?
13:39:54 <shlevy> (I'm in IO)
13:40:57 <shlevy> I can just stuck an IORef Bool in the right place but I didn't know if there's a better way
13:41:52 <sbrg> shlevy: you could add a boolean parameter, maybe? 
13:41:56 <Jello_Raptor> Hmm, I need some design help :/ 
13:42:05 --- mode: glguy set -o glguy
13:42:06 <shlevy> sbrg: Heh, just got there myself :)
13:42:07 <sbrg> if it's calling itself recursively, only do recursive calls with the boolean set to false. the first call with true.
13:42:14 <shlevy> Yeah
13:42:15 <ertes> shlevy: you need state anyway, so use whatever feels most comfortable
13:42:50 <ertes> IORef, TVar, a recursive boolean, or even pass the log action explicitly and make it rewrite itself after the first output
13:44:21 <ertes> shlevy: i'd most likely go with the last option:  myFunc log = log "a" >> log "b"
13:44:29 <ertes> makeLog :: IO (Text -> IO ())
13:48:38 <infandum> Is it possible that some libraries I am using use parallelism even if I am not? I ask because all cores are used when supplied -N even if I have no parallelism that I put in the program.
13:48:50 <sbrg> yep
13:48:54 <infandum> drat
13:49:01 <infandum> that would explain everything
13:49:04 <infandum> in a bad way
13:49:25 <sbrg> anything can happen in code that runs IO 
13:49:38 <sbrg> so if they're doing that, then yes. if they're pure, then still yes, but probably not.
13:50:39 <infandum> When I put in my parallelism I halve the time of my program, but when I have it in my big program with -N everything slows to a crawl
13:50:39 <infandum> probably because their code works poorly with large numbers of threads
13:50:40 <infandum> because of fine grain
13:51:45 <infandum> can I tell which libraries use parallel computation?
13:52:10 <sbrg> i think maybe with profiling yeah. but you'd need to build all the dependencies with profiling I believe. 
13:52:28 <houli> https://wiki.haskell.org/ThreadScope should help
13:53:06 <infandum> unfortunately that's not possible
13:53:23 <infandum> haskellR doesn't play nice with profiling enabled
13:55:51 <infandum> With parallelization, specifically mapConcurrently f, if I supply -N2 would ONLY TWO instances of f be running at the same time? So if f was a memory hog I could use -NX to change the memory usage?
13:56:13 <infandum> in my tests the timing makes sense, but I don't know about memory
13:56:35 <Jello_Raptor> Hmm, I've got a problem where there's a structure (call it V containing other, possibly recursive elements A, B, C) I want to convert into a set of statements for an SMT solver. SBV provides a monad `Symbolic` that is perfect for this, if I had a bunch of functions `V -> Symbolic V`, `A -> Symbolic A'` (etc..) I could just construct the entire structure V in the Symbolic monad and be on my way. Problem is, each of those conversion 
13:56:35 <Jello_Raptor> functions requires some global information about the fully constructed V. I'd like to able to slap a RWST over Symbolic and use the information collected in the RWST to generate each of the transformation functions, but Symbolic has no MonadFix instance to let me do this (and adding one is infeasible). Is there some other way that lets me describe constructing V once, but get two passes, one to collect the global information needed, 
13:56:35 <Jello_Raptor> and one that (when given the transformations generated from the global information) will generate the SMT solver problem?
13:58:29 <Jello_Raptor> here's my toy example http://lpaste.net/349991 , it assumes that Symbolic has a monadFix instance (the simple ones I define don't work) but captures what I want to do 
14:00:04 <Jello_Raptor> It's sorta as if (a :*: b) somehow let me use the output of a in the input of b while being a coherent monad in its own right 
14:01:47 <Jello_Raptor> I can describe all my construction actions as a pair of (m1 (a,d) , d -> m2 b) where m1 collects information about the structure I'm building, and m2 is the one turning that into a SMT problem 
14:07:46 <hexagoxel> Jello_Raptor: why is monadfix infeasible?
14:08:29 <Jello_Raptor> hexagoxel: Symbolic is very strict in a lot of what it does and there's no good way to fix that without completely redesigning/rewriting it
14:10:39 <Jello_Raptor> basically, it uses a lot of IORefs for efficiency but those create lots of non-obvious data dependencies
14:18:42 <eiger> hey TUmuch, who did 9/11?
14:19:46 <maerwald> wrong channel
14:22:39 <hexagoxel> Jello_Raptor: just to confirm: a newtype-derived instance does not work?
14:23:14 <Jello_Raptor> hexagoxel: yup
14:23:27 <Jello_Raptor> I mean, it doesn't work
14:30:00 <qmm> i'm looking for a simpler method of creating an instance of show for the Integer type:  https://hackage.haskell.org/package/base-4.9.0.0/docs/src/GHC.Show.html#showsPrec
14:30:49 <qmm> how might you create an instance of show for an Integer type?
14:30:59 <qmm> which tutorial might explain this? 
14:31:50 <byorgey> qmm: I'm not sure what you're asking.  Are you just asking how to convert an Integer into a String of digit characters?
14:32:05 <byorgey> or are you asking something more specific about the Show class?
14:32:20 <qmm> byorgey: the first guess
14:33:04 <qmm> oh, maybe i can do this with read
14:33:11 <hexagoxel> Jello_Raptor: sorry, i cannot think of any way in which what you are asking for is weaker than MonadFix.
14:33:15 <qmm> but then, that's kind of a hack without really understanding the solution
14:33:19 <byorgey> qmm: given a number, you can find out what digit it ends with using 'mod'
14:33:27 <byorgey> and you can get rid of the last digit using 'div'
14:33:46 <byorgey> this is the basis of a simple recursive algorithm that gets one digit at a time
14:33:48 <Sonolin> man that was way harder than expected
14:34:00 <Sonolin> I can tell why lazy IO isn't the norm :)
14:34:13 <qmm> byorgey: thank you again
14:34:56 <aidecoe> hi
14:36:04 <monochrom> lazy I/O is pretty hard to use right
14:38:14 <Sonolin> yea, if anybody wants to see what I got: http://lpaste.net/349997
14:38:26 <Sonolin> sure it could be done better but I'm happy its working at least... taught me a bunch
14:46:25 <Jello_Raptor> hexagoxel: aha, I can get away with creating a monad instance for `data Foo a = Foo (Monad1 (a, Monad2 ()))` if Monad2 has some State that can allows it store and retrieve data 
14:47:39 <monochrom> that is a very compound construction.
14:47:50 <monochrom> but you will want s/data/newtype/
14:47:54 <Jello_Raptor> yeah :/
14:48:22 <Jello_Raptor> but the semantics are the same regardless 
15:00:36 <alx741> hello everyone, I'm trying to write a Yesod app but getting "not in scope: img_image_jpg" , I have a static/img/image.jpg file, what should I do?
15:06:14 <Axman6> alx741: I think there's a #yesod that's more likely to be helpful
15:06:46 <alx741> Axman6: Will try there, thanks
15:21:46 <dmwit> Sonolin: Why is `+!` needed?
15:21:53 <dmwit> Replacing it with `++` appears to work fine here.
15:24:47 <Axman6> what's +!?
15:25:02 <Sonolin> dmwit: hmm I had a discussion earlier about it
15:25:03 <dmwit> http://lpaste.net/349997
15:25:41 <Sonolin> I could've fixed the issue since, but the issue was ++ is lazy in resolving since it can output without recieving the full input 
15:25:54 <monochrom> because it uses lazy I/O and therefore needs to control lazy evaluation by hand
15:26:54 <Sonolin> dimwit: so, with using ++ there it starts saying "Hello, " without waiting for the newline
15:26:58 <dmwit> monochrom: What input shall I give that will demonstrate the need for +!?
15:27:05 <monochrom> although it should use tools from Control.DeepSeq rather than a space-intensive double-reverse.
15:27:08 <dmwit> Every input I tested worked the same with +! or ++.
15:27:38 <Sonolin> for me (using ghc 7.1) it starts saying "Hello, " after typing any 1 character
15:28:19 <glguy> 7.1 o.O
15:28:28 <glguy> development branch and outdated?
15:28:29 <monochrom> 7.1? 7.10? 7.100?
15:28:38 <dmwit> Sonolin: How are you running the program?
15:28:44 <Sonolin> 7.13
15:28:44 <dmwit> I tried `runhaskell test.hs`.
15:28:53 <Sonolin> I'm running using stack ghci
15:29:04 <glguy> 7.13? development branch and nonexistent?
15:29:13 <Axman6> there is no 7.13
15:29:17 <Sonolin> lol, strange
15:29:19 <Axman6> so you mean 7.10.3?
15:29:21 <Sonolin> that's what stack chose by default
15:29:23 <Axman6> do*
15:29:37 <Axman6> oh, you mean LTS-7.1, that's not GHC
15:29:50 <Sonolin> sorry, yea the stack resolver is "lts-7.13"
15:29:53 <monochrom> Still.
15:29:59 <dmwit> Interesting. ghci does indeed have funny behavior with ++.
15:30:10 <Axman6> stack ghc -- --version  will tell you what version of GHC
15:30:23 <monochrom> I normal expect a programmer to have a higher precision.
15:30:33 <Cale> How did they end up with that version number anyway?
15:30:57 <Cale> Stack is relatively new, so that's a fairly arbitrary number, and yet it doesn't quite align with anything else.
15:30:59 <dmwit> ghci, runhaskell, and the compiled version all behave differently.
15:31:12 <dmwit> I feel like `interact` ought to be setting things up appropriately so that's not the case.
15:32:34 <monochrom> Cale, I think human nature is such that independent invention (including that of version numbers) is the default, it takes efforts and politics to sync version numbers with other people.
15:33:06 <monochrom> but darn, that's a long way to say "not invented here"
15:33:09 <Sonolin> yea, I just tried using ghc 8.0.1 and ghci has the same results using ++
15:33:21 <dmwit> Manually setting the buffering makes the behavior consistent across methods of running.
15:33:24 <dmwit> So there's that.
15:33:35 <Sonolin> ah good to know
15:33:45 <monochrom> ghci tinkles with stdio buffering
15:33:49 <Cale> It's like someone saw the completely arbitrary association between the base package version and GHC's version, and said "you know what, we need more of this."
15:33:53 <monochrom> err, tinkers
15:33:54 <dmwit> Gotta set both input and output buffering, though. =P
15:35:18 <monochrom> ghci tinkers with a lot of things (including Haskell semantics) for the well-intention purpose of giving you more convenience.
15:35:44 <monochrom> but the road to hell is paved with well intention. the very tinkering implies that ghci is not to be trusted.
15:36:17 <monochrom> because ghci test results is going to be different from, say, compiled program test results.
15:36:43 <EvanR> i can hear a rubyist or similar calling for more tinkering with semantics
15:36:45 <Cale> The road to hell is paved with well-orderings.
15:36:47 <monochrom> and it is compiled program behaviour that matters at the end, because that's what you deliver. this means ghci is always wrong.
15:37:09 <dmwit> Sonolin: You might like ```xs +! ys = last ys `seq` (xs ++ ys)```
15:37:23 <EvanR> haskell is really special in having predictable semantics
15:37:28 <EvanR> ironically
15:37:32 <dmwit> then again you might not
15:37:44 <dmwit> Perhaps `length` is more trustworthy than `last`.
15:37:45 <monochrom> No no, just use the stuff from Control.DeepSeq, more disciplined, less homebrew cleverness that doesn't scale.
15:37:49 <Cale> GHCi has been moving in the direction of more magic for a long time
15:37:55 <Sonolin> erm yea, my head hurts enough to try to figure that out lol >.>
15:38:09 <Sonolin> but hSetBuffering proved to be much better, thanks for the tip
15:38:14 <EvanR> in light of common criticism that I cant predict memory usage
15:38:32 <glguy> Even better would be not to try to craft special behaviors with strictness while using interact
15:38:40 <Sonolin> ah ok that function makes sense dmwit
15:38:55 <Sonolin> I was trying to use seq but gave up
15:39:05 <monochrom> yeah intereact belongs to an old time when they thought lazy I/O was a good idea.
15:39:05 <Cale> It used to be pretty easy to express what GHCi would do with an expression: if it was an IO action, it would run it. Otherwise, it would try to apply print to your expression and run that.
15:39:30 <monochrom> it is a good idea for a niche of very simple tasks that you won't care about in the long run.
15:39:56 <monochrom> the thing is that controlling lazy evaluation by hand is pretty fragile.
15:42:54 <kcodrgkimd> #perl6
15:43:10 <Axman6> try #pugs
15:43:12 <Axman6> :P
15:43:42 <dmwit> Cale: Is that not true any more?
15:43:42 <Cale> Does pugs still exist?
15:44:18 <Cale> dmwit: Well, now if it's an IO action it might also try to print the result, but only if that's something with a Show instance and only if it's not ()
15:44:45 <dmwit> Ah, okay.
15:45:03 <monochrom> simply take the sentence and apply s/run/ruin/ and you're set :)
15:45:08 <Cale> and well, there's a lot of other sorts of things that are not expressions which you're allowed to type there
15:45:15 <dmwit> I still think it's pretty easy to explain: first unify with `IO ()`, then `Show a => IO a`, then `Show a => a`.
15:45:25 <Cale> Most sorts of declarations are now allowed
15:45:33 <dmwit> First one, run it; second one, run and print; third one print.
15:46:04 <EvanR> ghci should have a hair shirt mode which doesnt let you do all these nice things ;)
15:46:14 <Cale> Thankfully declarations are not usually easy to confuse with expressions.
15:46:42 <dmwit> Oh, are there four things? `IO ()`, `Show a => IO a`, `IO a`, `Show a => a`?
15:46:49 <monochrom> But this is the easy part where the well-intended convenience is valuable and not quite hell.
15:47:01 <Cale> Yeah, I'm not saying it's necessarily bad (though sometimes it can be mildly annoying that it'll immediately try to print the result of your IO action)
15:47:19 <dmwit> Okay. I agree it's hard to explain.
15:47:26 <Cale> Just that it definitely used to be simpler
15:47:42 <monochrom> What I have in mind are more treacherous things such as ExtendedDefault which completely ruin your attempt at using ghci for reliable predictions.
15:47:53 <Cale> Oh right, and then there's that :)
15:50:23 <dmwit> There ought to be a rule against having a bunch of people whose nicks hash to the same color being allowed to speak at once.
15:50:44 <monochrom> yes, use a different hash function
15:51:22 <monochrom> in fact, use a randomly chosen member of a univeral family of hash functions
15:51:26 <lordcirth> dmwit, what client are you using, btw
15:51:59 <Rembane> Use machine learning to rehash based on when people talk
15:52:02 <dmwit> I use irssi because I am too lazy to learn how to use glirc's fancy features.
15:52:03 <monochrom> yeah, which client? so I can contact its authors and offer them a course on universal hashing functions for a price :)
15:52:18 <lordcirth> I think the problem is the small number of colors.  They should make the first half 1 color and the second a second, squaring the combos
15:52:26 <lordcirth> But maybe that's too cluttered
15:52:35 <pikarudolph> why don't IRC clients have 16.2 million colors in the year 2016?
15:52:48 <dmwit> Some do. =)
15:52:53 <monochrom> no, that's not too cluttered, that's too Joseph's Technocolor Dream Coat :)
15:53:09 <lordcirth> pikarudolph, it's irrelevant if they do, the eye can't tell
15:53:14 <pikarudolph> then again, nicks with colors #000000 and #000002 are hard to distinguish
15:53:19 <Axman6> dmwit: I'm finding glirc much iesier to use than irssi for most things. doesn't quite have as many features, but the config makes a lot more sense. I switched from irssi to glirc after using irssi for 10-15 years this week
15:53:22 <lyxia> most of these colors are also ugly
15:53:30 <Rembane> Does glirc remember the order of the windows? Or doesn't it care?
15:53:38 <Axman6> my only (non-) issue is the memory usage
15:53:41 <Rembane> Axman6: How did you manage to use irssi for 10-15 years this week?
15:53:51 <pikarudolph> time dilation
15:53:51 <EvanR> dmwit: irssi has colored nicks? o_O
15:54:09 <MarcelineVQ> back in my day we had green and black and we were glad we had green and we had to read people's names, uphill, in a snowstorm
15:54:12 <pikarudolph> does glirc have a buffer list or a fuzzy finder for buffers? I need one of those two things
15:54:19 <dmwit> EvanR: It does if you stick `nickcolor.pl` in `~/.irssi/scripts/autorun`.
15:54:23 <lordcirth> irssi has most things, with the right settings/plugins/scripts
15:54:24 <Axman6> Rembane: no, I kinda wish it did, but it just orders them alphabeticaly within networks
15:54:37 <monochrom> Yes! You can easily fit million lines of code on one screen by this easy scheme: Use one pixel per character, use colour to indicate which character.
15:54:39 <Axman6> Rembane: I switched this week, apologies for the ambiguous grammar
15:55:21 <EvanR> pixels? old
15:55:22 <lyxia> don't forget to use a compression algorithm
15:55:23 <EvanR> subpixels
15:55:26 <ab9rf> i'm trying to remember when i switched from ircii to irssi
15:55:28 <Rembane> Axman6: I'm just being silly. It was a golden opportunity, so I hade to take it. :)
15:55:34 <monochrom> Someone should make a movie based on this and completely misinform movie goers on how programmers do their job.
15:55:46 <EvanR> call it the matrix
15:55:54 <ab9rf> monochrom: heh
15:55:54 <monochrom> YES!
15:55:58 <MarcelineVQ> monochrom: actually that sounds like it could be a fun thing to do to make a code-to-image thing
15:56:05 <Rembane> Axman6: Ah, I wonder if it matters really, the order of channels. It does in irssi. Hm...
15:56:06 <glguy> pikarudolph: It has a /buffers list and tab completion on switching channels and keyboard shortcuts for jumping to the first 20 (by default) windows
15:56:25 <c_wraith> the matrix was that famous linear algebra movie, right? 
15:56:31 <lordcirth> monochrom, well, in Star Trek TOS, Spock had a custom display that used geometric shapes rapidly changing + colors to increase bandwidth
15:56:33 <ab9rf> monochrom: i though programming mainly involved typing rapidly on multiple keyboards while seizure-inducing visual displays flash by on dozens of monitors in front of you
15:56:33 <Axman6> http://imgur.com/a/UXk2N for some idea of how glirc looks
15:56:39 <glguy> pikarudolph: and if there's some other excellent way to switch windows it can have that, too
15:56:57 <pikarudolph> tab completion on switching channels is good
15:56:58 <Axman6> when I get some time there's a few features I'd like to add (like indenting wrapped lines)
15:57:06 <pikarudolph> glguy: fuzzy finder
15:57:08 <EvanR> ab9rf: thats not entirely out of the question
15:57:19 <pikarudolph> i have 40+ buffers and i don't want to bind most of my keyboard to buffers
15:57:25 <Tuplanolla> I'd never run an IRC client in a terminal where I could accidentally paste things.
15:57:26 <pikarudolph> i find it faster to type them
15:57:34 <glguy> Tuplanolla: glirc helps with that, too. it never sends on paste
15:57:37 <dmwit> glguy: That reminds me, does glirc do logging, or do you rely on znc for that?
15:57:42 <Axman6> Rembane: it annoyed me a little at first but I'm getting used to it
15:57:50 <lordcirth> glguy, that's a nice feature!
15:57:50 <glguy> dmwit: There's some logging supported. I use ZNC for that, however
15:58:05 <Tuplanolla> How does it distinguish manual line breaks from pasted line breaks, glguy?
15:58:12 <pikarudolph> IRC messages don't have line breaks
15:58:14 <glguy> Tuplanolla: The terminal tells it
15:58:17 <ab9rf> in my experience, of course, programming mainly consists of staring at a screenfull of code while muttering "why the hell doesn't this work?"
15:58:18 <pikarudolph> oh
15:58:22 <pikarudolph> I misunderstood the question
15:58:54 <dmwit> ab9rf: I don't know. Sometimes you get a break and stair at a screenful of code while muttering "why the hell does this work?"
15:59:00 <dmwit> s/stair/stare/
15:59:04 <mtjmullen> Ive been using weechat for irc, been reasonably happy with it
15:59:13 <glguy> Tuplanolla: the text input area can handle multiple queues up lines
15:59:15 <ab9rf> dmwit: true true
15:59:17 <pikarudolph> I like the way weechat right-aligns nicks
15:59:22 <pikarudolph> I wish glirc did that
15:59:29 <Tuplanolla> I see, glguy. I didn't know that's possible.
15:59:29 <ab9rf> change it so it does :)
15:59:47 <glguy> pikarudolph: It'd be easy to change it to do that if you know any Haskell
15:59:57 <glguy> There's about one line you'd have to edit
15:59:57 <EvanR> you could use acme-left-pad 
16:00:16 <pikarudolph> I know a moderate amount of Haskell
16:00:32 <Axman6> the code for glirc isn't hard to read
16:00:52 <pikarudolph> I guess it is about the time in my life where I need to start maintaining a fork of the IRC client I use
16:01:15 <glguy> If you made it configurable I'd just merge it in
16:01:17 <dmwit> Submit a pull request instead...?
16:01:27 <pikarudolph> :P
16:01:37 <pikarudolph> dmwit: the first change is a gateway drug
16:01:40 <glguy> It's also pretty easy to add new configuration settings
16:02:08 <glguy> and I'm happy to walk you through stuff like that if you actually get interested
16:02:20 <sbrg> well shit. why didn't i know about that client
16:02:51 <Axman6> Y'all should join #haskell-irc
16:02:53 <glguy> glirc has a number of features that someone other than me wanted and helped add
16:03:20 <Koterpillar> glguy: on the scale of impossible to forget it... XMPP chats?
16:04:13 <glguy> I wouldn't make tha the first feature that you try to add
16:04:26 <glguy> I can visual a path to it working in my head
16:04:29 <glguy> visualize
16:04:37 <glguy> but you're going to have to touch a lot of stuff
16:04:42 <mtjmullen> glguy: is glirc scriptable?
16:04:54 <Axman6> wow, the extensions API looks pretty simple
16:05:09 <glguy> yeah, it has a C api and I wrote a loadable lua module that uses that API
16:05:17 <mtjmullen> nice
16:05:24 <mtjmullen> surprised no hs api :D
16:05:25 <glguy> so if you don't mind Lua, use that, if you want a different language, you'd have to write your own loadable module
16:05:38 <mtjmullen> I actually like Lua for the most part
16:05:42 <mtjmullen> junky stdlib aside
16:05:46 <glguy> modules can be changed at runtime so you can swap it out as you develop it
16:06:02 <glguy> and if you need more API features that I have so far we'll add them for the most part
16:06:16 <glguy> the current featureset exists to support the things people wanted to do with it
16:06:35 <mtjmullen> ah, it does have znc support
16:06:56 <glguy> yeah, the znc support is pretty good, you can have it automatically request playback history from the last time you were connected on reconnects
16:07:03 <glguy> it knows about znc timestamped messages
16:07:44 <glguy> and it can reinterpret the znc buffextras stuff as native joins/parts/etc
16:08:05 <pikarudolph> does it have a buffer list?
16:08:23 <glguy> you can type /windows and it shows all the windows
16:08:28 <pikarudolph> ok
16:08:35 <pikarudolph> but not a pane with buffers in it
16:08:42 <glguy> it has syntax highlighting on /commands
16:08:45 <mtjmullen> weechat has a separate notion of /buffer and /window
16:08:47 <mtjmullen> andything like that?
16:08:58 <glguy> No, I don't think so
16:09:02 <mtjmullen> ok
16:09:24 <mtjmullen> a window is composed of several buffers
16:09:32 <pikarudolph> oh, I don't know about this
16:09:34 <mtjmullen> and killing a window doesn't kill a buffer
16:09:34 <glguy> you can do split - screen
16:09:42 * Axman6 mentions #haskell-irc again
16:09:46 <mtjmullen> heh
16:09:56 <glguy> OK, I'll chill out :)
16:10:29 <Axman6> oh no, I want the discussion to continue, but it's probably less appropriate in here
16:10:30 <ggVGc> > let haskell = "irc" in haskell
16:10:32 <lambdabot>  "irc"
16:10:40 <dmwit> I'd be more upset about it if it seemed like there were folks with other more directly-Haskell-related things to talk about. =P
16:20:00 <orion> :t ($)
16:20:01 <lambdabot> (a -> b) -> a -> b
16:25:26 <grantwu> That's not the right type right
16:25:31 <grantwu> er, the real type
16:26:48 <hpc> it's a certain perspective on what it has in the newest ghcs
16:27:05 <grantwu> hahaha
16:28:40 <texasmynsted> Where can I find more information about fmapping over an hlist?
16:29:18 <hpc> ooh, i just remembered i have stack on my main machine, i can update the lts version
16:32:43 <c_wraith> ($) doesn't have a real type expressible in GHC's type system, even with levity polymorphism enabled. 
16:33:37 <hpc> oh right, i forgot levity polymorphism isn't even the only special thing
16:33:48 <hpc> it's got a hack for dealing with ST
16:33:49 <c_wraith> at least, not when used infix. when it's used infix, it's treated as a syntax hack. 
16:33:55 <Tuplanolla> We wouldn't need the higher-rank stuff with `ArgumentDo`...
16:33:56 <hpc> which exists solely so you can write "runST $ do"
16:34:49 <hpc> levity polymorphism is a more general mechanism for dealing with unboxed types
16:34:59 <hpc> which have a slightly different kind from regular (boxed) types
16:38:46 <c_wraith> levity polymorphism also fixes the kind of (->), which is nice. 
16:40:16 <hpc> :k (->)
16:40:18 <lambdabot> * -> * -> *
16:40:22 <hpc> oh that's nice
16:42:24 <EvanR> texasmynsted: fmapping? not sure that makes sense. but you could hzip with an exactly matching sequence of functions
16:46:12 <texasmynsted> if I fmap over a tuple, pair, it always attempts to fmap for the right element.
16:46:23 <Rembane> That's how it is defined.
16:46:25 <texasmynsted> rather than the left element
16:46:31 <texasmynsted> right.
16:46:53 <texasmynsted> What if all but the last element are ints and I want to (+1) all the ints?
16:47:00 <Koterpillar> texasmynsted: the left element might be a different type
16:47:22 <Koterpillar> ...do it yourself, there's no support for triples and further
16:47:25 <EvanR> thats complicated
16:47:40 <EvanR> but you could hypothetically do it with enough logic baked into type classes
16:47:43 <Koterpillar> do you at least know how many of them are there?
16:47:48 <pacak> texasmynsted: That's how Functor instance for a pair is defined.
16:48:00 <jmcarthur> :t first.map
16:48:01 <lambdabot> (a -> b) -> ([a], d) -> ([b], d)
16:48:07 <Rembane> texasmynsted: There are two solutions that are slightly better: 1. Create your own datatype that is perfectly suited for this. 2. Use a list instead.
16:48:09 <jmcarthur> That is at least pretty close.
16:48:22 <EvanR> texasmynsted was asking about HList
16:48:57 <Rembane> Oh
16:49:58 <jmcarthur> The answer is the same anyway.
16:50:02 <EvanR> "all but the last element of the HList are Int" could be represented as a typeclass of some sort
16:50:11 <EvanR> but yeah
16:50:39 <EvanR> create a datatype like ([Int], NotInt)
16:58:49 <AndreasK> I think i've hit a case where -O2 corrupts my program
16:59:26 <AndreasK> I use sdl2 I guess time to check if there are any known instabilities :D
17:17:52 <texasmynsted> hm
17:18:10 <texasmynsted> Ok, what if the left element of a pair is an int and the right element is a string
17:18:44 <texasmynsted> Is it possible to fmap over the pair and (+1) to the left element of the pair?
17:19:12 <glguy> No, that's not what fmap means, but you can write a function that does it or use Data.Bifunctor.first
17:19:37 <texasmynsted> fair enough
17:19:54 <hpc> :t \f -> right (+1) . fmap f
17:19:55 <lambdabot> Num b => (a -> b) -> Either d a -> Either d b
17:20:05 <hpc> :t \f -> first (+1) . fmap f
17:20:06 <lambdabot> Num b => (a -> b1) -> (b, a) -> (b, b1)
17:20:54 <uiop> :t fromList
17:20:55 <lambdabot> IsList l => [Item l] -> l
17:21:16 <uiop> those sly foxes
17:21:34 <uiop> :t Item
17:21:35 <lambdabot> error: Data constructor not in scope: Item
17:21:38 <uiop> :i Item
17:21:43 <hpc> :k Item
17:21:44 <lambdabot> * -> *
17:21:50 <hpc> Item is a type family
17:22:01 <uiop> i wAS HOPING THE DATA CONSTRUCTOR WAS EPONYMOUS
17:22:06 <uiop> oops accidental caps lock
17:22:16 <hpc> it has no data constructors on its own
17:22:19 <uiop> yeah
17:22:34 <uiop> :t undefined :: Map () ()
17:22:36 <lambdabot> error:
17:22:36 <lambdabot>     Not in scope: type constructor or class ‘Map’
17:22:36 <lambdabot>     Perhaps you meant ‘M.Map’ (imported from Data.Map)
17:22:46 <uiop> just trying to see whats in scope
17:22:52 <glguy> You can play with lambdabot with /msg
17:22:57 <uiop> will do
17:23:04 <hpc> @hackage lambdabot
17:23:04 <lambdabot> http://hackage.haskell.org/package/lambdabot
17:23:05 <hpc> also
17:23:12 <uiop> nice thx
17:23:46 <xocolatl> texasmynsted: a simple (first (1 +)) should do the trick
17:24:11 <xocolatl> texasmynsted: import Control.Arrow
17:24:18 <texasmynsted> yeah, my question was more about why it does not work, than how to make it work.
17:24:39 <glguy> texasmynsted: fmap is from Functor, Functor is for things with kind * -> *
17:24:46 <glguy> (,) a  :: * -> *
17:25:01 <glguy> That's a 2-tuple constructor applied to one type
17:25:02 <texasmynsted> so why the second element of the tuple and not the first?
17:25:23 <uiop> texasmynsted: you cant "switch" on the type of anything in code, so an fmap that operates on fst or snd depending on the type is impossible
17:25:29 <glguy> because (,) has to be applied to its arguments in order
17:25:38 <glguy> (,) left right
17:25:57 <texasmynsted> ok
17:26:06 <glguy> (,) :: * -> * -> * ; (,) leftside :: * -> * ; (,) leftside rightside :: *
17:26:08 <uiop> texasmynsted: and mapping over snd is chosen because that's the only way to give the correct kinded type in the class instance for "(,) a" without using a newtype
17:26:18 <glguy> there's no version with (,) and rightside that gets you a type with kind * -> *
17:26:22 <xocolatl> unless you flip it
17:26:28 <glguy> and there's no flip
17:26:35 <xocolatl> what?
17:26:40 <texasmynsted> flip it?
17:26:44 <xocolatl> flip (,)  is a thing
17:26:45 <uiop> xocolatl: not at type level
17:27:04 <glguy> xocolatl: Yeah, these are types (type have kinds)
17:28:49 <glguy> Still 10 days left in adventofcode.com , still time to play along on the #haskell leaderboard! Key is in /topic
17:29:36 <uiop> glguy: cool hadnt seen that
17:30:04 <xocolatl> what does one do with that key?
17:30:27 <glguy> http://adventofcode.com/2016/leaderboard/private , type it in , click [Join]
17:30:34 <uiop> xocolatl: gives glguy control of you webcam :D
17:30:53 <glguy> yeah, I'm very powerful. Just looking at that key gives me control of you
17:30:56 <xocolatl> done!
17:31:17 <xocolatl> I wasn't able to do the last few days, but I got today's fairly easily
17:31:53 <glguy> xocolatl: "wasn't able to" as in "didn't have time" or "didn't know how" ?
17:31:59 <xocolatl> and some of my code worked for the example but never finished for the real input :(
17:32:01 <xocolatl> didn't know how
17:32:25 <xocolatl> still don't :)
17:33:08 <uiop> someone should make an iohcc international obfuscated haskell code contest
17:33:22 <uiop> by free association i went from aoc to ioccc to iohcc
17:34:03 <glguy> There's more than enough obfuscated Haskell available. A contest for clean code would be better
17:35:06 <xocolatl> glguy: ha! and yet I'm 8th on that board
17:35:40 <glguy> Like I said, it's not too late ;-)
17:35:53 <Koterpillar> when are the new ones unlocked?
17:36:02 <glguy> midnight eastern time
17:36:14 <Koterpillar> what offset is that?
17:36:16 <xocolatl> which is totally a bad time for me
17:36:19 <xocolatl> -05
17:36:30 <uiop> glguy: i dunno, i can imagine the bar to win such a contest being..... beginner is to master  as  pointfree is to iohcc winner
17:36:31 <xocolatl> I live in +01
17:36:32 <glguy> It's in 3.5 hours
17:36:52 <pavonia> Aww, that AoC leaderboard scoring is weird. I lost my 2nd place just because new users have joint? :(
17:37:24 <glguy> You get your points from when you finished each problem independently of whether you were on the leaderboard at that point or not
17:37:32 <uiop> glguy: and also there's at least one multiple-time ioccc winner in haskell community
17:37:43 <uiop> i bet iohcc would be ballz to the wall
17:37:52 <uiop> to put it that way :p
17:38:15 <xocolatl> all of my haskell code seems to be obfuscated :/
17:38:49 <xocolatl> I was even able to do day 6 in sql ;)
17:38:50 <pavonia> glguy: I mean the #haskell one, the number of points change whenever new users join or leave
17:39:16 <glguy> pavonia: Yeah, it's a touchy system
17:39:37 <glguy> Now first place is worth 26 points, before it was worth 25
17:40:08 <sm> AoC is great
17:40:10 <uiop> how the hell do i play AoC, do i need to enable javascript
17:40:29 <glguy> quite possible
17:40:38 <uiop> oh nm, i gotta log in with my cia identity
17:41:43 <glguy> only 73 slots left on the board ,  get'em while they're available ;-)
17:41:58 <uiop> get em while theyre hot
17:42:19 <xocolatl> I get the feeling there's a simple equation for today's puzzle, instead of brute forcing it like I did
17:42:52 <uiop> who's anonymous user in 3rd place
17:42:58 <uiop> i dont see anon login option
17:43:19 <glguy> uiop: look at http://adventofcode.com/2016/settings
17:43:31 <uiop> glguy: ahh, gotcha
17:43:37 <ezyang> Some day, I will memorize the argument order of the function in fold 
17:43:45 <uiop> : fold
17:43:47 <uiop> :t fold
17:43:49 <lambdabot> (Monoid m, Foldable t) => t m -> m
17:43:55 <glguy> :)
17:44:02 <glguy> it's got one argument...
17:44:02 <uiop> ezyang: wait you mean foldl foldr?
17:44:07 <ezyang> I mean foldl ;) 
17:45:57 <ezyang> btw, what do people think about this proposal for handling upper bounds: https://github.com/haskell/ecosystem-proposals/pull/1#issuecomment-267467115 
17:49:37 <mtjmullen> Seems decent
17:52:52 <ezyang> mtjmullen :) 
17:53:22 <mtjmullen> read that as: I don't have anything to complain about :)
17:53:52 <hodapp> huh, I am liking Frames so far
17:54:09 <hodapp> though I may need to grok pipes, microlens, and vinyl better in order to use it effectively
17:54:20 <uiop> ezyang: skimming it, it sounds sane. too-strict upper bounds are total pita's
18:07:48 <Zach32> Howdy hey
18:08:20 <Zach32> anyone about?
18:08:29 <dfeuer> Yes.
18:09:09 <Zach32> is this irc usually so quiet?
18:09:32 <koz_> Zach32: No, but we tend to keep idle chatter low.
18:09:40 <pacak> Zach32: Ask a question about Haskell.
18:09:41 <koz_> If you have questions, better to ask and wait for someone to chime in.
18:09:50 <Zach32> I do have a question!
18:09:54 <koz_> Then ask. :)
18:10:02 <Zach32> So I wrote this in ghci: fib n | n==1 =0 | n==2 =1 | n>2 =fib(n-1)+fib(n-2)
18:10:13 <Zach32> but it's soooooo much slower than other optimized codes I saw,
18:10:20 <Zach32> like fib = 1 : 1 : [a+b | (a,b) <- zip fib (tail fib)]
18:10:22 <dfeuer> Yes, that's very very slow.
18:10:29 <koz_> Zach32: That'd be slow in *any* language.
18:10:31 <dfeuer> Do you understand *why* it's so slow?
18:10:37 <Zach32> that's why im here
18:10:51 <Zach32> does bruno mars is optimized?
18:11:00 <dfeuer> Does WHAT?
18:11:43 <Zach32> lol. I just dont see why it's so slow. Doesnt is just recurse this? or does it like, not keep a list of it's generated values?
18:12:08 <koz_> Zach32: Think about what that version will do given an input, of, say, 7.
18:12:09 <Zach32> is that it, do I need to keep a list of all the factorials prior to fac(n)?
18:12:36 <dfeuer> Zach32, Haskell evaluation procedes by "graph reduction". Basically, you start with a term, say  fib 7
18:12:43 <Zach32> righty
18:12:55 <dfeuer> Then you work your way into it starting from the outside.
18:13:06 <pacak> >  take 10 $ fix (scanl (+) 0 . (1:))
18:13:08 <lambdabot>  [0,1,1,2,3,5,8,13,21,34]
18:13:12 <Zach32> oh, yeah, thiss functional programmingism
18:13:33 <Zach32> yeah, I think I understand that. The way f(x) and g(x) and be used as f(g(x))
18:13:38 <dfeuer> Each time you have to evaluate an application, you do it *almost* by syntactic substitution.
18:13:53 <Zach32> *almost*
18:14:00 <dfeuer> Except not quite, because references to variables stay references.
18:14:03 <dfeuer> Hrm...
18:14:09 <Zach32> lol nvm
18:14:14 <dfeuer> No, it's fine.
18:14:22 <dfeuer> I need to practice explaining this better.
18:14:46 <Zach32> Yeah, I need to learn these functions, zip, scanl, and the like
18:14:48 <dfeuer> So you have fib 7.
18:15:12 <dfeuer> 7 > 2, so you get   fib (7-1) + fib (7-2)
18:15:21 <Zach32> righty
18:15:23 <dfeuer> To evaluate that, you need to evaluate both pieces.
18:15:38 <Zach32> Yep yep. Same with other languages I've studied
18:15:45 <dfeuer> To evaluate fib (7-1), you need to check if 7-1 == 0 or ==2 or >2
18:15:48 <Zach32> I got it to run fast in javascript actually
18:15:48 <Cale> Zach32: When you define fib in that doubly-recursive way, it's ultimately adding up occurrences of fib 0 and fib 1, so fib n will chew through about fib (n+1) applications of fib -- you know it's got to be at least fib n applications of fib, since it eventually has to add up that many 1's
18:15:54 <dfeuer> So you rewrite 7-1 to 6.
18:16:18 <dfeuer> What Cale says is true.
18:16:20 <Cale> Zach32: and since fib grows exponentially, that's not terribly efficient
18:16:22 <Zach32> So it's the process of doing all the if-thens that adds to the recursion time?
18:16:31 <Zach32> right
18:16:31 <mtn`> I'm a bit confused about how I could find the "maximum character" in a list using a foldr
18:16:40 <dfeuer> Well...
18:16:50 <dfeuer> Zach32, you could put it that way.
18:17:01 <dfeuer> There are other "administrative" costs too.
18:17:16 <Cale> No, it's the fact that you're adding up 1's over and over, rather than constructing larger numbers which then get added together, or otherwise using the mathematics of the situation to obtain the result more efficiently
18:17:19 <Rotaerk> mtn`, why use foldr rather than something a little more specific?
18:17:32 <Zach32> OhHHHH
18:17:34 <dfeuer> Well, the adding *and* the ifs.
18:17:36 <dfeuer> It all adds up.
18:17:45 <mtn`> Rotaerk, As a learning exercise. I have something like foldr max ' ' "some string"
18:18:02 <mtn`> Rotaerk, The problem is, that's not a great base case. Maybe I could use the minBound for char?
18:18:04 <Zach32> Yep. Well now I just feel dumb. Yeah, i was lazy and figured that avoiding these higher order functions wouldnt cost performance, like in C
18:18:24 <travv0> can you use foldr1?
18:18:32 <dfeuer> The zip approach works by saving the previous results.
18:18:47 <mtn`> travv0, I suppose, and that would make it easier. But I'm curious to know if there's a way to do it with just a fold
18:18:47 <RageD> Zach32, a concept that may be useful here is memoization. when you're not storing previous results, you're continuously recomputing sub-branches of the tree (if you think of each function call as a branch) and that tree is exponentially large
18:18:48 <Rotaerk> mtn`, what's the max char of an empty string?
18:18:50 <dfeuer> It's a good way if you need to produce the whole sequence.
18:19:04 <dfeuer> If you only need to calculate arbitrary values of fib,
18:19:12 <mtn`> Rotaerk, well, i suppose that should return an error
18:19:16 <Zach32> gotcha. Yeah, we almost got to that kind of dynamic programming in my Java class, but not quite :p
18:19:24 <mtn`> Rotaerk, Which, I think, foldr1 might do
18:19:24 <Rotaerk> mtn`, so the result is actually Maybe Char, right?
18:19:34 <dfeuer> then it's much faster (in practice at least) to use exponentiation-by-squaring of matrices.
18:19:37 <Rotaerk> in which case the default would be Nothing
18:21:22 <mtn`> Rotaerk, Yep, that would make sense
18:27:09 <Lokathor> StateVar, IORef, and Ptr all seem to be about the same type. Is there an obvious winner? Or just whatever the lib uses?
18:27:36 <Lokathor> (that is, whatever lib you're relying on for a project)
18:32:05 <uiop> Lokathor: lets focus on IORef and Ptr, and IORef is a mutable cell containing a reference to a haskell object in the haskell heap, a Ptr is a nonmutable machine pointer sized word pointing to memory in the C heap, and you need a Sotrable instance to be able to reconstitute the "a" in "Ptr a" as a haskell object.
18:33:06 <uiop> Lokathor: in other words, you only use Ptr when 1) you need to put data in the C heap, and 2) you have a way to serialize and deserialize that data to/from the C heap
18:33:26 <Lokathor> So, IORef over Ptr by default. Simple enough
18:33:30 <uiop> on the other hand, IORef just gives you a mutable cell to hold a reference to a haskell object
18:33:59 <c_wraith> uiop, 1a) or get data from the C heap
18:34:10 <uiop> Lokathor: yeah you could say it that way, also noting that when Ptr is *needed* IORef isnt a possibility
18:34:11 <Lokathor> StateVar seems like a  hybrid approach
18:34:33 <uiop> c_wraith: yeah, peek or poke
18:34:46 <Lokathor> By using arbitrary get/set operations, you have a cell that could also be on the C heap
19:01:50 <Zach32> oh jeez, does anyone know a good way to write a polyvariadic function?
19:04:45 <geekosaur> there are no "good" ways. there are some hacky ones involving typeclasses
19:04:55 <geekosaur> see for example PrintfType in Text.Printf
19:05:10 <Rotaerk> I googled polyvariadic function and the top results were haskell-specific
19:05:21 <Rotaerk> well, duckduckgoed, not googled
19:05:49 <pavonia> He already left
19:05:56 <geekosaur> bleg
19:06:00 <geekosaur> *bleh
19:46:30 <dont-panic> Is haskell relatively easy to get set up and use on a ubuntu or debian net install?
19:47:23 <dmwit> Yes. You can `apt-get install` GHC and most of the packages available on Hackage (at some old version number, of course).
19:47:57 <dmwit> After that, you can `cabal install` just about anything on Hackage at whatever the newest version number is, if you need the bleeding edge. Once you do so, it is not recommended to `apt-get install` any further Haskell packages.
19:48:07 <dmwit> ?where sicp for details on this latter recommendation
19:48:07 <lambdabot> http://mitpress.mit.edu/sicp/ | http://swiss.csail.mit.edu/classes/6.001/abelson-sussman-lectures/ | http://www.vex.net/~trebla/haskell/sicp.xhtml -- "Storage and Identification of Cabalized
19:48:07 <lambdabot> Packages"
19:48:17 <dmwit> The third link there.
19:48:19 <dont-panic> dmwit: I've been told that functional programming is a bit easier to grasp with haskell.  I come from the scripting world and don't necessarily always like classes and objects
19:48:43 <JSharp> dont-panic: I found it quite easy to get up and running on ubuntu with Stack (<https://www.haskellstack.org/>). You can also install via the package manager but it'll be system wide, and many Haskell projects use stack for snapshot and package database management.
19:49:05 <dmwit> stack is an alternative as well, yes.
19:49:45 <dont-panic> that's similar to virtual envs for python?  (localized bin and packages)
19:50:17 <dmwit> It's like virtual environments + a curated set of packages.
19:50:33 <dmwit> cabal sandboxes are like virtual environments with all of Hackage.
19:50:35 <dont-panic> Yay!  That's basically what I hope for with any decent language
19:50:53 <dont-panic> we like to hack
19:51:57 <JSharp> yes, I highly recommend stack; manages multiple isolated haskell versions as well -- it's been a pleasure (mostly, some but very few rough edges mostly related to fringe use cases) to use.
19:52:45 <dmwit> I boggle at how often "manages multiple Haskell versions" gets touted as a feature.
19:53:28 <dfeuer> dmwit, what do you mean by that, exactly?
19:53:31 <dmwit> I was using multiple Haskell versions for ages before stack came around. GHC and cabal both paid careful attention to that need for me.
19:53:32 <glguy> /r/wheredidthesodago
19:53:52 <JSharp> well, I'm working on LiquidHaskell which, atm, only works on 7.10.3 and some of my other projects are on latest; some on head
19:53:58 <dont-panic> lol
19:54:12 <glguy> Yeah, it used to be that you'd specify which version to use when you configured your project with the -w flag
19:54:21 <dont-panic> pro's and cons guys, don't care what you favor, just which one has sweet features and not headaches lol
19:54:33 <JSharp> *shrug*
19:54:37 <dont-panic> trying to avoid carpal tunnel
19:54:56 <dfeuer> cabal-install seems simpler.
19:55:10 <dfeuer> But it can be hard to figure out how to do stuff like manage multiple ghc versions....
19:55:14 <JSharp> choose what works for you; like most advice, it's just a form of nostalgia. I found stack easy to use when getting started; it's not that it's the best
19:55:21 <dont-panic> by simple you mean less complex, or more headaches later and easy now?
19:55:24 <dfeuer> The fact that stack can actually install ghc *for you* is rather convenient.
19:55:43 <dont-panic> maybe stack is a good starting place for now?
19:55:55 <dfeuer> But stack is really primarily designed for something very different from what I actually use it for.
19:56:04 <dont-panic> I'm an automation and efficiency engineer.  Used to work in proofpoints noc
19:56:10 <dmwit> stack is a fine starting place. Many people will recommend it. cabal is also a fine starting place, and many people will recommend it.
19:56:34 <dfeuer> And it does some weird stuff like hiding output from ghc -ddump-* in weird places.
19:56:40 <dfeuer> Which is obnoxious.
19:56:42 <dont-panic> so both are good research ave's to go down
19:56:48 <JSharp> *nods* yes
19:57:13 <dont-panic> what's haskell usually used for?  or is it super general purpose too?
19:57:23 <dmwit> You can browse Hackage.
19:57:23 <JSharp> I've found stack to be useful in terms of "easy to get started and installs haskell for you". It uses cabal under the covers, so, either way, you'll benefit from learning both
19:57:24 <dmwit> ?where hackage
19:57:24 <lambdabot> <http://hackage.haskell.org/package/>, also see `revdeps',`status'
19:57:40 <dfeuer> stack's curated package sets are *very* nice if your development doesn't require a particular bleeding-edge version of something.
19:57:44 <dmwit> It's used for a pretty fair variety of stuff.
19:58:23 <dfeuer> But that's largely orthogonal to its primary goal of fixing dependencies/build environments.
19:58:32 <dont-panic> might get into binary options automation or something else that will be generating patterns over and over
19:59:04 <dont-panic> but I also want to learn functional programming better and I've heard haskells the language
19:59:31 <dfeuer> I believe neither stack nor cabal-install has sufficiently good documentation, but stack's is probably worse.
19:59:49 <dont-panic> hmmmmm
20:00:06 <dont-panic> maybe that's something I can contribute in the process of learning
20:00:11 <dmwit> dont-panic: For the really beginner stuff, where you don't need any libraries, you might consider just invoking ghc(i) yourself.
20:00:48 <dont-panic> haskell console?
20:00:48 * dfeuer summons wrengr_away 
20:01:26 <mtjmullen> There's also the #haskell-beginners channel
20:01:54 <dont-panic> ^golden ticket, thanks for getting there, be back in a few hours
20:02:40 <dont-panic> I'm a mid/senior dev, its easier to just ask those guys for a direction when you know kind of what you're looking for and they'll tell you pretty quick
20:03:07 * JuanDaugherty curious what that means in people years
20:03:53 <dont-panic> 29, my planet, roughly 130 or somewhere closer to 245... its been a while since i've been there
20:04:08 <Koterpillar> JuanDaugherty: I think a better analogy is the "Mostly Harmless" scale
20:04:18 <dmwit> Am I missing some messages? Or is this conversation just confusing?
20:04:19 <dont-panic> ^winner, chicken dinner
20:04:35 <dont-panic> I'm edward, I'll go play with Ein and the kidz
20:04:39 <dont-panic> buh byeeee
20:05:26 <JuanDaugherty> let's talk about levity polymorphism
20:05:44 <dmwit> Who are "those guys"? What is the "that" in "what that means in people years"? Why are we suddenly talking about planets? What are the units on "130" and "245"? Just... what the heck happened to this conversation at the end?
20:06:18 <mtjmullen> Cowboy Bebop joke methinks
20:07:37 <sanett> Hey folks. Is there any recommended book to learn haskell with?
20:07:59 <dmwit> so many
20:08:01 <dmwit> ?where tutorials
20:08:02 <lambdabot> http://haskell.org/haskellwiki/Tutorials
20:08:27 <dmwit> I encourage everybody who's thinking about saying something in-channel to improve that page, too. ;-)
20:09:34 <sanett> Thanks, and yes there's way too many..
20:10:44 <JuanDaugherty> ⟦ that ⟧ was 'mid/senior dev' in terrestrial years
20:11:05 <JuanDaugherty> (on the job)
20:12:11 <dmwit> Hm. Is there an "official language" on the Haskell wiki?
20:12:42 <dmwit> It just seems like something has gone drastically wrong with https://wiki.haskell.org/Gentle
20:14:26 <yulax> ucould just be a Romanian page?
20:15:07 <Koterpillar> advertising Mandriva with a GIF?
20:15:50 <sanett> lol
20:19:34 <zacharybechhoefe> testing
20:19:53 <Zach> testing
20:20:18 * Zach
20:20:33 <dmwit> hm
20:23:10 <Guest22490> Does anyone know a good way to do polyvariadics?
20:23:28 <roboguy`> A *good* way? Maybe not...
20:23:38 <Guest22490> ugh
20:23:41 <EvanR> a what?
20:23:50 <Guest22490> a function with a variable number of inputs
20:23:59 <EvanR> all functions have only 1 input
20:24:07 <EvanR> but see also the printf function
20:24:19 <Guest22490> will do, thanks
20:24:22 <roboguy`> Guest22490: what are you trying to do/is there a larger context to the question?
20:25:11 <Guest22490> @roboguy I was hoping to do a zip function with more than two sets
20:25:12 <lambdabot> Unknown command, try @list
20:25:19 <Guest22490> ugh how do I message lol
20:25:22 <Guest22490> first day on irc
20:25:38 <EvanR> > transpose [[1,2,3], [4,5,6], [7,8,9]]
20:25:40 <roboguy`> Guest22490: ahh, don't worry. You can just put my screenname and a colon
20:25:40 <lambdabot>  [[1,4,7],[2,5,8],[3,6,9]]
20:25:43 <roboguy`> it will let me know
20:25:44 <EvanR> zipped
20:26:12 <Guest22490> I see. I guess I should just make a list of lists
20:26:40 <dmwit> > liftA3 (\x y z -> x*y+z) (ZipList [1,2,3]) (ZipList [10,20,30]) (ZipList [100,200,300])
20:26:42 <lambdabot>  ZipList {getZipList = [110,240,390]}
20:27:41 <dmwit> There's also a freely extendable version.
20:27:47 <dmwit> > pure (\x y z -> x*y+z) <*> ZipList [1,2,3] <*> ZipList [10,20,30] <*> ZipList [100,200,300]
20:27:49 <lambdabot>  ZipList {getZipList = [110,240,390]}
20:28:05 <Guest22490> I'll look for ziplist.. probs in data.list?
20:28:11 <dmwit> Give the first function however many arguments you want, and then provide that many `ZipList`s and you're good to go.
20:28:28 <dmwit> ?hoogle ZipList
20:28:28 <lambdabot> Control.Applicative newtype ZipList a
20:28:29 <lambdabot> Control.Applicative ZipList :: [a] -> ZipList a
20:28:29 <lambdabot> Control.Applicative getZipList :: ZipList a -> [a]
20:29:24 <Guest22490> ooh neat. Yeah, I'm new to haskell too, I hadnt heard of .Applicative
20:30:17 <Guest22490> it sounds like you guys really have this figured out. What are yall using hs for? I just wanted it to help do proofs with math hw
20:32:02 <roboguy`> Guest22490: ooh, for math proofs you might want to look into Coq at some point. It's very similar to Haskell in a lot of ways, but it is designed to be a proof assistant as well as a functional programming language
20:33:34 <Guest22490> roboguy' oh that does look handy
20:34:25 * zach32
20:37:53 <dmwit> I'm kind of surprised that I haven't really needed a tool that maps module names to package names before.
20:38:08 <dmwit> I wonder how often it would get used if \bot grew a plugin for that.
20:40:55 <geekosaur> well, @index is already often useful (even if limited) for mapping a standard function to the module it comes from (as is hayoo/hoogle)
20:41:16 <geekosaur> and I do often look up a name on hayoo just to get the package and module
20:41:22 <glguy> ghc-pkg find-module
20:41:33 <geekosaur> only helps if it's already installed though
20:42:15 <geekosaur> unless we want to find a way to ship a populated database with just that information like debian/fedora ship prepropulated package dbs for such queries
20:43:27 <dmwit> I mean, I guess cabal already has a copy of every `foo.cabal` lying around somewhere already, right?
20:43:37 <dmwit> So the database is "there" in some sense. Just the query tool hasn't been written yet.
20:47:16 <dmwit> e.g. `cabal info` will list the modules available even in packages I've never fetched, unpacked, installed, etc.
20:48:46 <geekosaur> yes, there's a database under ~/.cabal/lib. iirc it's not especially friendly in raw form but the information is there
20:49:19 * geekosaur wonders if it can be parsed using the Cabal library or if cabal-install could stand being split into a metadata library + executable
20:49:34 <geekosaur> I think at one point there were plans to do that
20:50:05 <geekosaur> (may still be such plans but I think new-build and friends got higher priority)
20:54:47 <sophiag> geekosaur: i'm still trying to debug that half-working regex code from yesterday :p
20:56:06 <sophiag> *think* i know what the problem is, but am a bit confused...
20:56:37 <sophiag> line 14 here seems unnecessary since i already match for both lists to be empty, but commenting it out i get a non-exhaustive patterns error: http://lpaste.net/350010
20:57:02 <sophiag> can't understand what's going on with that
20:57:21 <glguy> sophiag: It's the cases when both lists are not empty that you aren't handling
20:58:04 <codygman> So, does anyone know how to actually umm... fold with the foldl package? I see it has foldMap but I don't see just 'fold'
20:58:43 <zach32> I mean, you're not gonna fold just a single variable
20:58:57 <dmwit> codygman: What type do you want `fold` to have?
20:59:11 <roboguy`> codygman: this? http://hackage.haskell.org/package/foldl-1.2.1/docs/Control-Foldl.html#v:fold
20:59:17 <codygman> dmwit: (b -> a -> b) -> b -> t a -> b
20:59:20 <sophiag> glguy: well i've only tested it where it contains one of the regex characters i'm parsing...don't i cover all of those?
21:00:40 <dmwit> codygman: \f z -> fold (Fold f z id) -- ?
21:01:21 <codygman> dmwit: That doesn't typecheck for me.
21:01:31 <sophiag> i was thinking it should loop through until it matches either of those three of either of the two empty lists
21:01:35 <geekosaur> sophiag, one case you don't handle is the regex having $ followed by a character (which could be considered an error case, or treated as literal $)
21:01:52 <sophiag> ah, i did alter that line
21:02:02 <geekosaur> hm, maybe that case is matched after all
21:02:07 <MarcelineVQ> sophiag: matchHere (x:xs,y:ys) | x == '.' || x == y = matchHere(xs,ys) the case warning is if this fails there's a missing case for what happens
21:02:08 <codygman> I'll clarify, I'm trying to take a Foldable and then use a value from each row as the key in a Map, set the value to 0, and then do a lookup on the map.
21:02:24 * geekosaur asks ghc for its opinion ... or, ok, MarcelineVQ can do it :p
21:02:48 <roboguy`> codygman: are you sure? It looks like it typechecks to me...
21:02:49 <sophiag> originally line 11 was: matchHere (['$'],y) = y == []
21:04:06 <MarcelineVQ> sophiag: you probably want an    | otherwise = False for that guard at the end
21:04:20 <sophiag> MarcelineVQ: yes, that makes sense
21:04:27 <MarcelineVQ> Well, more correctly I should say that will silence the error, I don't know if that's the behavior you want
21:04:42 <sophiag> no, that's correct
21:04:53 <sophiag> it's not an error, it's just not a match
21:05:40 <MarcelineVQ> it's a warning with -Wall on allthough the error is pretty hard to read since it's trying to be specific
21:06:13 <MarcelineVQ> *the warning :>
21:06:41 <MarcelineVQ> in my head missing or unreachable patterns are an error so I keep doing that
21:07:08 <sophiag> hmm, okay well that answers my question...but the code still is half-broken :/
21:08:13 <codygman> roboguy`: It didn't typecheck for me with fold being L.fold from Control.Foldl, perhaps the fold was meant to be from traversable?
21:08:42 <roboguy`> codygman: I'm using the fold from Control.Foldl as well
21:09:12 <pacak> > let (🐸) = (+) in 1 🐸 2
21:09:14 <lambdabot>  3
21:09:25 <roboguy`> codygman: and I'm getting \f z -> fold (Fold f z id)  :: Foldable f => (b -> a -> b) -> b -> f a -> b
21:10:23 <codygman> roboguy`: I had Lens' Fold in scope ;)
21:10:31 <roboguy`> ahhh, that'll do it =)
21:10:51 <sanett> Hey folks, what's the difference between x <- ['A'..'Z'] and x `elem` ['A'..'Z']? I feel like the former lists all letters from A to Z but I'm not sure.
21:12:02 <geekosaur> sanett, the former only works in a list comprehension or the list monad
21:12:08 <roboguy`> sanett: the first one is used as part of a list comprehension or in do-notation. The second one is just calling the elem function on two arguments, which just tells you if x is in the list ['A'..'Z']
21:12:33 <roboguy`> > 'C' `elem` ['A'..'Z']
21:12:35 <lambdabot>  True
21:12:40 <geekosaur> and those contexts give it not only that meaning but also other behavior (lists get Cartesian join behavior)
21:23:28 <glguy> AoC day 16 is out, 2 #haskellers done, 3 half way!
21:24:14 <sanett> um... lambdabot stopped responding to me in pm
21:25:16 <glguy> ?bot
21:25:17 <lambdabot> :)
21:26:12 <sanett> Does the bot give you error messages if your expression doesn't make sense?
21:27:19 <dmwit> should do
21:27:22 <dmwit> > 3 + "hi"
21:27:24 <lambdabot>  error:
21:27:24 <lambdabot>      • No instance for (Num [Char]) arising from a use of ‘+’
21:27:24 <lambdabot>      • In the expression: 3 + "hi"
21:27:53 <sanett> > length xs = sum [1 | _ <- xs]
21:27:55 <lambdabot>  <hint>:1:11: error:
21:27:56 <lambdabot>      parse error on input ‘=’
21:27:56 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
21:28:07 <geekosaur> however it depends on the error
21:28:36 <geekosaur> if you dropped the space after the > you get no response. likewise if you typo :t as :y, or accidentally type it out :type as would work in ghci
21:28:48 <sanett> ahhh right
21:29:09 <geekosaur> (it's kinda bad for bots to respond to all input, it leads to them constantly spurting garbage)
21:35:30 <sophiag> ah...i'm almost there with that pattern matching :p
21:35:54 <sophiag> realized the problem is both . and $ won't match if there are characters before what they're searching for
21:59:05 <emmanuel_erc> hello there has anyone here installed inline-java or any of the related libraries before?
22:02:02 <qmm> the underhanded haskell contest, anyone?
22:03:11 <dmj`> emmanuel_erc: I’m sure someone has, why?
22:03:32 <emmanuel_erc> I'm getting error messages during the installation that I don't quite understand
22:03:44 <emmanuel_erc> well I don't understand how to deal rectify the situation I have
22:05:10 <geekosaur> @paste
22:05:11 <lambdabot> Haskell pastebin: http://lpaste.net/
22:05:48 <dmj`> emmanuel_erc: if you could paste them using the service @geekosaur linked to, that would be very helpful
22:06:27 <emmanuel_erc> ok
22:07:34 <lpaste> emmanuel_erc pasted “inline-java (error messages)” at http://lpaste.net/350013
22:08:03 <geekosaur> what platform are you on and what java do you have installed?
22:08:51 <geekosaur> also, is it a JRE or a full JDK? you will need the latter for this
22:09:06 <lpaste> emmanuel_erc pasted “platform and java information” at http://lpaste.net/350014
22:10:08 <emmanuel_erc> geekosaur, will that information suffice?
22:10:26 <geekosaur> you probably need to install jdk7-openjdk
22:11:08 <geekosaur> (you likely have only jre7-openjdk installed, which is just the runtime parts; but inline-java needs to be able to access a java environment in-line and so needs the developer bits to build)
22:11:39 <emmanuel_erc> I just ran "pacman -Qi jdk7-openjdk"
22:11:40 <geekosaur> splitting them up is somewhat unusual for arch but normal for java, since most people don't need the full JDK and it's much larger than the JRE
22:11:45 <emmanuel_erc> it is already on my machine
22:12:16 <emmanuel_erc> I probably fucked up somewhere though
22:13:04 <geekosaur> oh, wait, that's java 8 you show in your info there
22:13:24 <emmanuel_erc> yes
22:13:29 <geekosaur> archlinux-java status
22:13:55 <geekosaur> (probably need to @paste the result as it'll be more than one line)
22:14:04 <emmanuel_erc> https://thepasteb.in/p/zmh8QnWBJX0CZ
22:14:06 <emmanuel_erc> yeah
22:14:43 <geekosaur> ... sigh. browser just fell over again (reported bug)
22:14:58 <geekosaur> ok, so your java 8 is default and is a jre only
22:15:29 <emmanuel_erc> I ran pacman -Qi jdk8-openjdk, apparently it is already on my machine
22:15:45 <geekosaur> not in that listing it wasn't, it showed a jre only
22:15:55 <emmanuel_erc> ok
22:15:55 <geekosaur> unless you did it after generating that status listing
22:16:06 <emmanuel_erc> I think that might be the case@
22:16:21 <geekosaur> in which case, well, should mention you just changed the status I asked for :)
22:16:42 <geekosaur> because I was about to tell you how to activate the jdk7 but if you have the jdk8 now...
22:17:12 <geekosaur> archlinux-java set java-8-openjdk
22:17:18 <emmanuel_erc> ok
22:17:22 <geekosaur> then: archlinux-java status
22:17:34 <geekosaur> and make sure it says that the jdk, not the jre, is default
22:18:05 <emmanuel_erc> https://thepasteb.in/p/oYhlj82n8jQCZ
22:18:31 <emmanuel_erc> if that is correct  I'm going to try and install inline-java
22:18:51 <geekosaur> that looks correct
22:19:12 <geekosaur> it now has a java8 jdk as default so -ljvm should be present
22:19:13 <emmanuel_erc> I am still getting the exact same error as before
22:20:06 <geekosaur> hm
22:20:27 <geekosaur> ok so what I am seeing is you need to log out and back in because they set up a bunch of shell functions to point stuff to the development bits
22:20:48 <geekosaur> and it's easier to log out and back in than figure out which files to "source" to fix your current login
22:20:59 <emmanuel_erc> that seems odd that I would have to do that, but I'll give that a try
22:21:26 <emmanuel_erc> if it works, I might not log back into the erc chat, so in advance, thanks for the help]
22:21:30 <emmanuel_erc> help!*
22:21:42 <geekosaur> sadly java tends to be set up in ways that are convenient for windows (where the vars would go in the registry and be instantly available
22:21:50 <geekosaur> and less so for unix
22:22:11 <emmanuel_erc> now I know better
22:22:24 <emmanuel_erc> alright I'm going to do my thing
22:22:26 <emmanuel_erc> catch you later
22:22:26 <geekosaur> same way swing was built around windows gui assumptions (and working around that on unix means it behaves oddly in nonreparenting window managers). etc/
22:28:01 <lpaste> dfeuer pasted “Constraints on components of type applications” at http://lpaste.net/350015
23:10:34 <amx> somehow AOC is writing a bunch of attoparsec parsers and a few lines of glue
23:19:55 <pavonia> plus having a fast processor and huge memory for part 2 :S
23:20:56 <glguy> today's part 2 needed neither at least
23:23:29 <amx> but I like it. It's not like project euler where you need to be an expert in number theory pretty soon.
23:23:31 <pavonia> Your solution obviously works efficently then :p
23:24:39 <glguy> took about 0.2 seconds and 80mb
23:26:24 <pavonia> My first version crashed at 700MB, the second one only needed 200 something
23:26:40 <dmwit> My latest version uses 7s and 5mb. So definitely possible to do in cheap memory constraints.
23:42:36 <haskell182> is there a way of generating a graph of all module dependency within a project?
23:43:24 <haskell182> stack dot only show the external dependency of the project, I just want to see which module import are used in my project
23:45:26 <dmwit> ?hackage graphmod
23:45:26 <lambdabot> http://hackage.haskell.org/package/graphmod
23:46:24 <haskell182> thanks :)
