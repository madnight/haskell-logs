00:19:54 * hackage pandoc-include-code 1.5.0.0 - A Pandoc filter for including code from source files  https://hackage.haskell.org/package/pandoc-include-code-1.5.0.0 (owickstrom)
00:25:57 <iqubic> I would love a "mapMaybe :: (a -> Maybe b) -> Set a -> Set b" for sets, so that I can do a mapping operation while dropping certain items out of the container
01:00:16 <bunnyocto> what do I do with No instance for (NFData (IO String)) ?
01:00:44 <jle`> bunnyocto: whatever you are giving an 'IO String', you should probably give a 'String' instead if possible
01:00:53 <bunnyocto> yeah.. that's the obvious part:)
01:01:05 <mpickering> Does anyone know how to translate the phrase "content addressable store" into python? 
01:01:09 <bunnyocto>  timeout 31100 $ evaluate $!! foo
01:01:17 <bunnyocto> the problem is foo is an IO String not a String.
01:01:25 <EvanR> iqubic: it seems all map does is rebuild the whole set, so at least it's not hard to make your own
01:01:36 <jle`> bunnyocto: try (evaluate =<< foo) instead
01:02:00 <jle`> assuming evaluate from Control.Concurrent
01:02:08 <jle`> (or Control.Exception?)
01:02:13 <jle`> not sure what ($!!) is, though
01:02:13 <bunnyocto> it's Control.Exception
01:02:30 <bunnyocto> That code is years old and I have no idea anymore how it worked :)
01:02:47 <jle`> ah :) yeah you can probably replace it with timout 31100 =<< evaluate =<< foo
01:02:51 <bunnyocto> it's part of an interpreter 
01:03:06 <bunnyocto> which can run arbitrary commands and I want to eliminate endless loops by using a timeout
01:03:08 <jle`> er
01:03:13 <bunnyocto> (or just a general time limit on user run commands)
01:03:14 <jle`> timeout (evaluate =<< foo)
01:03:21 <jle`> * timeout 31100
01:03:56 <jle`> this will evaluate the final 'String' that foo produces
01:05:08 <bunnyocto> jle: thx the =<< works
01:06:56 <bunnyocto> hm. System.Time isn't supported anymore.
01:06:59 <bunnyocto> puuh
02:19:41 <rwmorrison84> Hello, I have a data structure with `TVar`s inside it. Is it right to think that I should use `atomically` to first create it, and only then work with it? Or am I missing something
02:19:58 <rwmorrison84> There is also `newTVarIO` but I don't think I understand the comment...
02:20:10 <rwmorrison84> > IO version of newTVar. This is useful for creating top-level TVars using unsafePerformIO, because using atomically inside unsafePerformIO isn't possible.
02:20:12 <lambdabot>  <hint>:1:12: error: parse error on input â€˜ofâ€™
02:20:48 <rwmorrison84> I don't need global variables!
02:21:33 <iqubic> atomically inside unsafePerformIO isn't possible??
02:22:12 <madnight> Hi, how can I force a specific version in stack's package.yaml definition? My "==" or ">=" seems to be ignored, because of another version constrain from one of my packages, although I'm quite sure that the version that I want to force should work.
02:22:38 <merijn> rwmorrison84: newTVarIO is just a convenience version of "atomically . newTVar"
02:22:59 <bunnyocto> Does anybody now why Data.Bits.rotate 13 1 results in 26?
02:23:09 <merijn> iqubic: No, because that's likely to ruin everything
02:23:41 <merijn> madnight: The entire point of stack is that it fixes all your dependencies to the specific version in a stack snapshot/LTS
02:23:47 <__monty__> madnight: Stack doesn't care about bounds. It just uses the version in the snapshot, so you'll have to override that.
02:23:52 <bunnyocto> 1101b rotated to left by 1 is 1011b which isn't 26
02:23:59 <merijn> madnight: So it sounds like you either want 1) a newer/different snapshot or 2) not stack
02:24:06 <rwmorrison84> merijn, than it's fine create a bunch of `TVar`s using `newTVarIO`, bundle them together into an ADT and then use it?
02:24:12 <merijn> rwmorrison84: Sure
02:24:16 <rwmorrison84> thank you
02:24:25 <iqubic> bunnyocto: data.bits inserts a 0 at the right.
02:24:58 <iqubic> 1101b -> 11010b. All it does is adds a 0 to the right, which shifts everything to the left one place.
02:25:01 <merijn> rwmorrison84: There's some other subtle reasons why you might *have to* use newTVarIO because you can't atomically (as referenced by the docs), but you can mostly just ignore that complication :)
02:25:07 <bunnyocto> but that's not a rotation operation.
02:25:11 <bunnyocto> that's a sfit
02:25:13 <bunnyocto> *shift
02:25:19 <iqubic> It's a poorly named operation then.
02:25:27 <merijn> bunnyocto: What type are you rotating?
02:25:27 <madnight> merijn: 1. okay how can I upgrade my snapshot?  2. BTW, I experimented with Nix as package manager, is it any better than stack?
02:25:55 <bunnyocto> merjin: Int32
02:26:00 <__monty__> madnight: I like it better.
02:26:02 <merijn> madnight: I don't use stack, but I think you're supposed to edit stack.yaml? And I don't use Nix, so I can't say :p
02:26:12 <bunnyocto> oh wait
02:26:13 <bunnyocto> no
02:26:15 <rwmorrison84> merijn, I once used `unsafePerformIO` to create a global variable with `MVar`. Does it exist for the same reason then?
02:26:30 <bunnyocto> ah yeah for int32 26 is correct.
02:26:41 <iqubic> global variables in haskell are a sin.
02:26:49 <merijn> bunnyocto: You forgot that it's not just rotating the numbers in the literal? ;)
02:27:01 <iqubic> It's rotating all the bits.
02:27:16 <bunnyocto> yeh I'm an idiot :D
02:27:25 <merijn> rwmorrison84: Similar yes, except (as the docs note) you can't use atomically within unsafePerformIO, so you can't write that yourself directly without newTVarIO
02:27:42 <iqubic> 00001101b == 13. One of those 0s at the left gets rotated to the right.
02:27:54 <bunnyocto> I thought for Integer it would only work on bits used
02:28:00 <bunnyocto> but the doc says it'll insert just a 0
02:28:08 <bunnyocto> and for int32 that boils down to the same thing with leading zeroes
02:28:39 <merijn> For small numbers of bits you might be better of just operating on a [Bool] for rotations like this :p
02:29:04 <Ailrun[m]> madnight: 1. Change the resolver field in your stack.yaml, if you meant stackage snapshot. 2. Stack is not a package manager, and rather it is a build tool.
02:29:14 <iqubic> int32, by definition is 32 bits. So it's rotating all 32 bits. Even those many unused 0s.
02:29:21 <__monty__> Because there's infinite leading zeroes, unless the number's negative depending on the representation.
02:38:32 <madnight> Ailrun[m]: merijn: thx, 
02:38:33 <madnight> upgrade of the stack resolver solved the issue
03:30:12 <sim590> I have coded 2 slightly diffrent approaches at finding the nth prime number. See the code https://paste.debian.net/1122397. The first approach is to call nthprime isPrime and the second is nthprime isPrime' (notice the apostroph). On input 10001, the first apporach takes 150 seconds and the second takes 1 second. I'm wondering why that big leap between both. I know that the second takes advantage
03:30:13 <sim590> of the fact that prime numbers are congruent to 1 or -1 modulo 6 (increment by 6). That does cut the number of checks by 3 compared to the first approach which looks at all odd numbers (increment by 2). But, why would that make the code run 150 times slower than the second approach?
03:31:49 <merijn> sim590: First of all: Did you compile with -O2?
03:31:55 <sim590> The haskell related part of the question: In the first approach I take advantage of the laziness of the language. I use `head` to get only the first factor of the list computed by `trial`. Since it's lazy, it should only look at the first element and not bother computing the rest of the list.
03:32:18 <sim590> merijn: I did not. I just did test in ghci.
03:32:32 <sim590> Can I specify to compile with -O2 in ghci ?
03:32:37 <merijn> sim590: Ok, any numbers from ghci are, essentially, worthless
03:32:49 <merijn> Not easily
03:33:09 <merijn> ghci compiles to a bytecode and interprets that, which mean it doesn't optimise nearly as well/reliably as actual compilation with ghc
03:33:35 <sim590> Oh OK. So, I should test them by compiling -O2, then use `time` from command line and check the time, right?
03:33:40 <merijn> For example
03:33:48 <__monty__> Otoh -O2 sometimes slows code down...
03:34:13 <merijn> sim590: Anyway, the first version does a whole lot of list constructions which introduces allocations and overheads, compared to the 2nd
03:34:52 <merijn> sim590: I can see the second version being optimised to a completely strict unboxed loop rather easily, the first one not so much
03:35:11 <merijn> With -O2 it might speed up all the allocations in the first one considerably, though
03:35:26 <merijn> __monty__: Seems unlikely for this code
03:36:43 <sim590> But, just from the point of view of the analysis of the code. Can we say that writing `head (trial n) == n` "transforms" the algorithm in one that only bothers returning a Bool like if I did code it in the same fashion as isPrime' (not taking into account the cuts in the numbers of tests with modular analysis). 
03:36:50 <__monty__> merijn: Yes but smarter people than me have said it's bad to let new people think "more O's = more better" when it comes to GHC. "-O unless you benchmark" seems like the best recommendation.
03:37:18 <sim590> OK, I understand that I did some list construction that overloads. That's a good point, but I thought that using `head` would really just create singletons.
03:37:31 <merijn> sim590: It's hard to say
03:38:10 <merijn> sim590: If you compile with "-rtsopts" you can run the executable with -sstderr to get a GC/productivity report, which will tell you how much time is spent GCing stuff vs computing
03:38:15 <__monty__> sim590: The "The *Real* Sieve of Eratosthenes" functional pearl's a good read.
03:38:31 <merijn> I expect the productivity of the first is quite low if it's taking 150 seconds
03:39:11 <merijn> sim590: There's a bunch of ways of diving into details of why things are slow, but how deep to go depends on how much you like low level details
03:39:41 <sim590> I do like low level details.
03:40:06 <merijn> sim590: For example, you can ask GHC to output Core (the intermediate language GHC compiles too) and see how the two different isPrime functions are optimised
03:41:02 <merijn> sim590: Ever gone through the GHC user's guide?
03:41:35 <merijn> sim590: It has quite a lot of stuff on how to profile/inspect/etc. the code you're compiling
03:42:08 <sim590> merijn: not really. :/ I have followed a course on wikibook and played with ghci without really looking at documentation except :help ;)
03:42:32 <merijn> @where userguide
03:42:33 <lambdabot> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/
03:42:36 <sim590> OK, so I could first compile to core and see what are the optimisations.
03:43:04 <merijn> sim590: It has a lot of stuff, 6.13 covers outputting Core/C-- stuff, chapter 7 talks about profiling code, 8 on how to get smaller/faster/etc. programs
03:43:54 <sim590> Alright. That's a good place to look for an answer.
03:45:59 <merijn> GHC User Guide should be mandatory reading for everyone, IMO (at least skimming it)
03:48:15 <sim590> One optimisation that I have just made is getting out of the loop the computation of the square root of N which is always the same. That,s one thing that I did in the second implementation. For input 1000, I now have 0.9seconds instead of 1.4 seconds.
03:49:46 <sim590> Could it be that dividing n' by f every iteration in `trial` would account for a good portion of the overload because that's one thing that I don't do in the second approach since I'm only after a boolean answer.
03:52:51 <sim590> Actually, no. I'm never going to dividing more than once since I'm using `head` on the call of the function, so it doesn't make sense.
03:56:27 <merijn> sim590: Well, it's not clear whether it's repeatedly recomputing "floor (sqrt (fromIntegral n :: Double)" for example
03:57:32 <sim590> merijn: even though I have noticed a speed up as noticeable as almost half the time?
03:58:10 <sim590> I know that ghci time is not the best reference, but still.
03:58:45 <merijn> Unrelatedly, I find the isPrime' version much more readable, tbh :)
03:59:47 <sim590> Yeah, it's just that the first is based on an algorithm that finds all the factors so it's kind of reusing existing and useful code so I thought that it would be nice if I could manage the same speed.
04:01:02 <nyc> It might be good to familiarize oneself with Data.List library functions.
04:02:23 <nyc> filter, takeWhile, any, etc.
04:02:52 <sim590> nyc: I know those functions. Where do you see that I could be using them and gain performance?
04:03:22 <sim590> You're speaking about the last $ take ? 
04:03:30 <sim590> Yeah, I could have used takeWhile.
04:04:20 <nyc> I don't entirely understand how isPrime or isPrime' are supposed to work.
04:05:08 <merijn> nyc: How so?
04:05:13 <sim590> nyc: isPrime is taking advantage of the fact that each primes are congruent to 1 or -1 modulo 6. So we can skip numbers by incrementing by 6.
04:05:19 <sim590> I mean isPrime'
04:06:08 <__monty__> sim590: The square root is an example of something the compiler would normally extract from the loop automatically. So if that makes for a big difference in performance in ghci then you have an indication of how unreliable those numbers are.
04:06:31 <nyc> I think I see that it's using recursion instead of Data.List.any
04:07:31 <__monty__> sim590: That sounds like a very small prime wheel and you can use bigger wheels for even greater speedups.
04:09:01 <sim590> __monty__: yes. But the square root part doesn't account for all the overload since, I'm on input 10001, isPrime is still taking much more than 1 second while isPrime' takes no more than a second or so.
04:10:06 <__monty__> sim590: You're missing my point. That's just the most obvious optimisation, and ghci can't take advantage of it. Let alone more powerful optimisations.
04:10:13 <sim590> Indeed, may be there's a bigger optimization I could take advantage of, but my question is more about the difference of overload which doesn't seem consistent with the optimization that is present in isPrime' compared to isPrime.
04:10:56 <sim590> OK. I will compile both with -O2 and see what are the timings I get.
04:16:04 <sim590> By compiling with -O2 and running with `time`, I got 4,7 seconds for isPrime while I got 1 second with isPrime' in ghci.
04:16:29 <sim590> 0.17 second with isPrime' and -O2.
04:16:43 <sim590> So, numbers are still consistent.
04:17:28 <__monty__> Yes, but now you have a level playing field.
04:18:38 <sim590> So there's something inherent in my code that is less efficient in isPrime compared to isPrime' since after ghc's optimisations, I still get a great deal of time consumption difference.
04:19:25 <__monty__> Make sure to time each a few times, btw. Wouldn't want the cache to interfere with data.
04:19:55 <sim590> nyc: after reading again, I don't think that takeWhile could have been used after all. So I'm not sure what Data.List function I'm really missing out on.
04:21:47 <merijn> sim590: First simple step, compile them with -rtsopts and then use "+RTS -sstderr" when running the code, you should get a basic GC profile that way
04:24:48 <sim590> I got that https://paste.debian.net/1122536/
04:30:41 <merijn> sim590: Right, the the most important bit is at the bottom: "Productivity  26.4%"
04:31:13 <merijn> sim590: i.e. only 26.4% of the time was spent on "doing stuff", the remaining 73.6% of the time it was busy garbage collecting
04:31:28 <sim590> Hmmm
04:31:40 <merijn> That's basically, pretty damn terrible
04:32:19 <sim590> With isPrime', I get `Productivity  40.8% of total user, 70.4% of total elapsed`.
04:32:19 <merijn> And pretty much what I was guessing earlier saying that all the list allocations in the first version (this is the 'trial' based one, right?) slowing things down
04:32:37 <sim590> merijn: Yeah
04:34:44 <merijn> sim590: The numbers at the top indicate how much memory you allocated, how much was copied during GC steps, and max residency (i.e. "the maximum amount of memory in use at the same time")
04:35:42 <merijn> sim590: isPrime' doesn't really allocate anything (really only it's one argument and the 'r' value, so that's pretty small and constant)
04:36:22 <merijn> sim590: And what I mentioned earlier I suspect GHC's strictness analyser is trivially able to see the entire isPrime' as being a strict numeric loop that it can aggressively simplify and make strict
04:36:48 <nyc> I'm using a Newton's method square root to try to take an arbitrary-precision multiplication out of a takeWhile loop and for some reason testing whether the square is less is faster than computing the isqrt and just bounds checking against that.
04:37:23 * hackage mmsyn7ukr 0.2.0.0 - A simple basic interface to some SoX functionality or to produce a close to the proper Ukrainian speech (if you pronounce sounds properly) with your own recorded voice.  https://hackage.haskell.org/package/mmsyn7ukr-0.2.0.0 (OleksandrZhabenko)
04:37:24 <merijn> nyc: sqrt is an extremely slow operation (compared to basic arithmetic) on modern CPUs
04:38:00 <merijn> nyc: So if you end up recomputing the sqrt due to inadequate sharing then the multiplication one is going to be faster
04:38:21 <merijn> But you should be able to lift the sqrt out from the loop and only do it once
04:38:39 <nyc> It may be that I'm doing it in small enough ranges that it's all just happening as a single multiplication. And I pulled out the square root from the loop and it's still getting beaten by the multiplication in the loop.
04:38:57 <merijn> nyc: Pastebin the code?
04:39:02 <sim590> merijn: So nthprime isPrime is creating singleton lists in the following manner [[3], [7], [11], ...] and since I'm using head, it's transforming it to [3, 7, 11, ...], but that allocation/deallocation of a list is what is making it take so much more time ?
04:40:45 <nyc> merijn: https://paste.debian.net/1122537/
04:41:01 <merijn> sim590: You're building up a (thunk of a) list in the recursion of 'go' on line 14, you're building a list that contains all factors and then forcing (part) of it when you do "head"
04:41:46 <merijn> sim590: But for large primes that "factors" list gets quite big (how many primes are there below 10001? a couple hundred?) every time GC triggers those are all copied
04:42:18 <sim590> merijn: But I thought that since the language is lazy, it would stop after finding the first element.
04:42:24 <sim590> Not bothering creating the rest of the list.
04:42:34 <merijn> nyc: Why do you have that super complex nested if/then/else instead of using guards?
04:42:57 <merijn> sim590: It stops after evaluating the head of the list, but you're still making a "computation that will build a list" and that one gets larger
04:43:02 <nyc> merijn: I think where clauses don't scope well against guards.
04:43:25 <merijn> nyc: You can mix where and guards just fine?
04:43:30 <__monty__> sim590: That's true but it does have to create a thunk to hold "how to find the tail".
04:44:05 <merijn> sim590: So you have "a computation that will produce a list of factors" and when you lazily append a new factor you get "a computation that will append to the computation producing a list of factors", etc.
04:44:09 <__monty__> I think they want a local binding for a single guarded equation? You'll want let.
04:44:47 <merijn> __monty__: Only reason I've ever found for let is "I wanna bind something relying on a monadic bind earlier" >.>
04:45:27 <__monty__> I meant "let in".
04:45:29 <merijn> sim590: Once you call head you only evaluate the very last append (and not the entire computation)
04:45:49 <merijn> __monty__: That example uses let in, but it's not very readable
04:45:53 <__monty__> Do you have a way of scoping where over just a single guard clause?
04:46:19 <merijn> sim590: But until you finally evaluate the 'head' call you need to copy the entire "potential factor list" around
04:47:14 <sim590> merijn: I thought that lists and other data structures in haskell were persistent therefore enabling not copying elements, but reusing memory
04:48:45 <__monty__> sim590: The GC is a copying GC. It copies everything that survives a collection into a new section of memory, condensing it in the process.
04:49:08 <merijn> sim590: They are, but GHC uses a "copy & compact" GC strategy. Which works as follows: When you run out of heap and need to collect, you copy all the "live" (i.e. still used) things to a new heap, and when done you say "the entire old heap is now free"
04:50:02 <merijn> sim590: The advantage is that GC time scales with "amount of live data" instead of "amount of garbage", which is good because lazy evaluation produces lots of garbage
04:51:19 <merijn> sim590: The other advantage is, since your heap isn't fragement there is no need for an expensive allocation algorithm. When you allocate memory you just say "I want N bytes" and you can simply "add N to the pointer that points at the end of the heap", so allocation is *super* cheap (which is good, because lazy evaluation *also* does lots of allocation)
04:51:53 <merijn> It's not weird to see Haskell programs allocate several gigabytes per second (and immediately GCing, which is very cheap, usually!)
04:53:33 <merijn> sim590: So every time GC triggers during your program the "factor list" (or, the computation that might become the factor list) has to be copied, which quickly becomes slower than the isPrime' version which 1) almost never allocates and 2) has almost no data to copy during GC
04:56:03 <sim590> Wouldn't an imperative and mutable data structure based language avoid all of that copying? If so, how does haskell avoids that problem ? I thought that the answer was persistent data strcutures, but it seems it's not really the case.
04:56:10 <merijn> nyc: I'd do something like https://paste.debian.net/1122538/ (although I think you can easily simplify it further)
04:56:46 <merijn> sim590: Haskell also uses a generational GC, the idea behind generational GC is "the longer data stays alive, the longer it is likely to stay alive"
04:57:22 <merijn> sim590: So, once data has been GCed a few times it moves to an "older generation" and older generations are GCed less often (and thus copied less often)
04:57:47 <merijn> sim590: Since data is immutable this is easy, because older generations can only refer to even older ones and not newer generations (because they're immutable)
04:58:12 <merijn> sim590: Java has a limited form of generational GC, but it's much harder in a mutable language
04:59:42 <sim590> But wouldn't it be possible in Java (for instance) to have a mutable array of factors which is global and therefore avoiding any copying and finally just changing the values in that array and not waste as much time GCing as in Haskell? 
04:59:58 <merijn> sim590: Garbage collectors are always about trade-offs: GHC's GC is generally quite good for throughput (i.e. it allocates fast, doesn't have to run very often, works well if you have lots of garbage and/or very little live data), it's not so good for, for example, low latency (since GC pauses can be long and it has to copy a lot for large live sets)
05:00:15 <merijn> sim590: Sure, but you can also do that in Haskell :p
05:00:31 <merijn> sim590: Both Array and Vector provide mutable arrays :)
05:00:43 <sim590> Yeah, so the answer is mutable data structures.
05:00:48 <merijn> sim590: Sometimes
05:01:00 <merijn> sim590: I actually have a relevant example
05:01:25 <sim590> Therefore the persistent data structure concept is not able to porvide the same amout of productivity as mutable data structures.
05:01:43 <solonarv> "very little live data" - if you have large long-lived data you can stuff it into compact regions to make the GC's job easier, too
05:02:07 <merijn> sim590: So, I have this code that does a streaming analyses on data. My data consists of several million arrays/vectors that I'm summing. So everyone of those million steps it's copying/recreating the aggregation vector
05:02:24 <merijn> sim590: So I thought I'd optimise things by switching to accumulating in a single mutable array
05:02:51 <merijn> sim590: That mutable version ended up being a bunch slower than the immutable
05:03:21 <merijn> sim590: The real answer is "microbenchmarks are a terrible way to analyse the impact/problems that occur in large programs" :)
05:03:42 <sim590> But is that a result of the mutability implementation in haskell? Would the same approach implemented in C for instance be much slower likewise?
05:04:29 <solonarv> that's a terrible comparison: optimized C generally beats or equals anything else you can do in a higher-level language
05:04:38 <merijn> sim590: There's no reason to expect mutable Storable Vector to be more than, say 5-10% slower than C (and even that is pessimistic, I'd expect it to be the same)
05:04:46 <merijn> solonarv: pfft, bs
05:05:12 <solonarv> eh?
05:05:18 <merijn> C is super hard to optimise well and the commonly accepted fact that "higher-level" == "slower" is nonsense
05:05:26 <solonarv> oh, of course
05:05:38 * sim590 Ê˜â€¿Ê˜
05:05:45 <solonarv> it may well not be practical to write C optimized to that level
05:05:55 <merijn> There's higher level GCed languages that can regularly beat C just fine, because they have proper support for (multi-dimensional) arrays and vectorisation
05:06:03 <solonarv> oh, that's a good point
05:06:23 <merijn> And once you're manually writing SIMD intrinsics and inline ASM in C you're really not writing C anymore
05:06:35 <solonarv> fair enough
05:06:52 <merijn> Plus, you can manually write SIMD intrinsics in GHC too :p
05:07:25 <merijn> oooh...
05:07:43 <merijn> I should rewrite my vector accumulation loops manually with SIMD instructions, like a masochist!
05:07:51 <solonarv> what? how? I never knew this!
05:07:53 <nyc> Cache and TLB hierarchies are of great interest to me, and SIMD comes into play when using the data structures for them.
05:08:05 <merijn> solonarv: ghc-prim
05:08:12 <merijn> solonarv: You might need to use LLVM, though
05:08:42 <nyc> So, for instance, you would want to bear in mind cachelines and pages and large pages and such.
05:08:47 <solonarv> oh, I did not know that had SIMD intrinsics
05:08:53 <solonarv> very cool!
05:08:54 <merijn> solonarv: https://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:broadcastInt8X16-35-
05:09:27 <merijn> solonarv: They need more love, but if you wanna play with them I'm sure carter can help brainstorm ways to improve them that he doesn't have time for himself :p
05:09:34 <solonarv> yeah, I found them already
05:10:07 <solonarv> I knew there was some sort of support for them but thought they were languishing in a half-bitrotten package
05:10:08 <merijn> Anyway, I should get back to writing my paper so I finish before christmas, instead of procrastinating here >.>
05:12:07 <nyc> On a 64-bit SPARC there are page sizes every power of 8 up from 8KB, so one would want to bear in mind structure at 8KB, 64KB, 512KB, 4MB, 32MB, 256MB, etc. in addition to cacheline sizes within pages (which I don't recall but suspect are something like 256B).
05:12:54 * hackage mmsyn2 0.1.7.0 - The library that can be used for multiple (Ord a) => a -> b transformations  https://hackage.haskell.org/package/mmsyn2-0.1.7.0 (OleksandrZhabenko)
05:13:37 <nyc> B trees and B+ trees are good for that. Then once those are arranged, SIMD instructions to do multiple key comparisons in a single instruction are worthwhile. So I'm not sure how to make arrangements for cache and TLB locality.
05:15:09 <sim590> merijn: why is my case different than yours ? Why is it that in your case you mentioned that immutable arrays are faster than mutable. If I understand correclty, you're saying that in your big program, even though mutable arrays would be faster locally, it isn't once you consider the final program in its whole. But what was the reason it would be so? In my case, though the answer, if we restrict
05:15:10 <sim590> ourselves to computing `nthprime`, a mutable array is just necessary to have the same efficiency, right ? So locally speaking, mutable data structures concept is just more efficient than persistent data structures, at least in the case of Haskell, righ?
05:18:13 <sim590> For curiosity, I'll implement trial function with mutable vectors and see if it's better.
05:19:54 <merijn> sim590: Real applications have lots of other things slowing them down, which may result in the slowdown of GC becoming unnoticeable
05:20:56 <merijn> sim590: Just consider an application reading from disk/the network. You regularly spend *much* more time waiting for IO than you spend GCing. In a bigger application those things can overlap, so despite doing more GC the actual runtime might not be affected at all
05:22:14 <sim590> merijn: alright, but the argument seems to still be in favor of mutable arrays. In that case, if you want efficiency and don't want to worry about the time that GCing will become a relevant issue, then you should use mutable arrays.
05:24:23 * hackage mmsyn3 0.1.4.0 - A small library to deal with executable endings  https://hackage.haskell.org/package/mmsyn3-0.1.4.0 (OleksandrZhabenko)
05:25:10 <nyc> 27.38user 0.07system 0:27.57elapsed vs. 44.26user 0.19system 0:44.56elapsed
05:25:18 <merijn> sim590: Mutable arrays are also copied during GC though, the only difference is you don't have to copy them on every update/change
05:25:55 <sim590> merijn: but since in my case I wouldn't do more than one update/change, is using mutable array just not helping?
05:25:57 <nyc> Something is wrong when an O(lg(n)) algorithm pulled out of a loop is slower than O(n) multiplications in a loop.
05:26:57 <sim590> merijn: Therefore, how can I fix `trial` to not take so much time like I would in an imperative language accessing a global array for example?
05:29:08 <merijn> sim590: Well, writing it like isPrime' would work (i.e. only returning a predicate, rather than a list of all factors...) it basically depends on what you care most about
05:36:16 <sim590> So there are some things that you can't do efficiently in haskell compared to imperative language. What I mean is that you may begin creating the function `trial` before creating isPrime. Then in imperative setting, the most intuitive way of writing isPrime quickly would be to modify `trial` with a return statement as soon as it finds a factor. Then calling this new version of `trial` with a check
05:36:17 <sim590> like I did in isPrime, i.e. checking if the first factor found is the number itself. That is intuitive change. In the imperative setting, there is no loss of efficiency. In the haskell setting though, you suffer from the limitations of persistent data structures and GC.
05:37:21 <merijn> sim590: I think this isn't an issue of "imperative vs functional/haskell"
05:37:55 <merijn> sim590: This is an issue of "this is something you can't do with GHC's (current) GC and could do in another language with a different GC"
05:38:23 <sim590> That is kind of paradoxal phenomenon since Haskell is supposed to thrive with using reusing and composing functions, but yet reusing functions can create loss of efficiency while it is not really the case in the imperative case as I described.
05:38:25 <merijn> sim590: If you had an imperative language with the same GC design as GHC, you'd have the same issue. And if you had a Haskell implementation with a different GC design that GHC this problem would also not occur
05:38:42 <sim590> right
05:39:35 <merijn> In fact, GHC 8.10 has a different/alternative GC implementation in it (although the current one performs better for most usecases), so there aren't any conceptual problems with Haskell the language
05:39:45 <sim590> So, it seems to be really tied up to the opposition of the concepts of persistent data structures and mutable data structures.
05:39:54 <merijn> Also not really
05:40:01 <nyc> I've got enough going on that I'm probably not going to chase down the mystery of why the isqrt pulled out of the loop is slower than squaring in the loop.
05:40:23 <merijn> sim590: Why do you think persistent data structures matter here?
05:41:23 * hackage mmsyn4 0.1.5.0 - The "glue" between electronic tables and GraphViz  https://hackage.haskell.org/package/mmsyn4-0.1.5.0 (OleksandrZhabenko)
05:41:24 <merijn> sim590: Mutable data structures also have to be copied in GHC's GC design and with a different GC you wouldn't have to copy persistent data structures
05:41:44 <merijn> Really the only issue/trade-off here is "what do you optimise your GC implementation for?"
05:42:39 <solonarv> actually, isn't there a way to allocate a pinned mutable byte array?
05:42:39 <sim590> merijn: because persistent data structure is the only way for haskell to avoid copying stuff. Yet, it's not sufficient to get to the same efficiency that mutable counter part can have.
05:43:06 <merijn> sim590: And I'm not convinced imperative languages do better, you could try to do the same in python and I'd be surprised if the python version was faster using mutability
05:43:08 <sim590> merijn: You don,t have to copy the mutable array if you make it global or just pass a pointer.
05:43:35 <merijn> sim590: The copy&collect GC GHC uses means you *do* have to copy the mutable array
05:43:49 <merijn> sim590: Since every GC *all* data that's still used is copied, this include mutable arrays
05:43:54 <merijn> solonarv: Sure
05:44:08 <merijn> solonarv: Storable Vector is just a thing wrapper for ForeignPtr
05:44:13 <merijn> s/thing/thin
05:44:19 <ClaudiusMaximus> you can use pointers to foreign memory in haskell, but you can't store haskell values inside it, it may be an option if you have storable...
05:44:22 <merijn> solonarv: And ForeignPtr is pinned by definition
05:44:32 <solonarv> yep that's what I was thinking of
05:44:41 <merijn> I think you can also have pinned byte arrays within GHC, though
05:45:04 <solonarv> I know ByteString is pinned but I can't remember if there is a mutable variant
05:45:14 <merijn> solonarv: ByteString is just ForeignPtr too
05:45:28 <solonarv> oh, hm
05:45:32 <merijn> solonarv: I know, because I have horrific "Storable a => ByteString -> Vector a" code ;)
05:45:46 <merijn> solonarv: https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/src/Utils/Vector.hs
05:46:20 <solonarv> a-ha! a quick look into ghc-prim finds 'newPinnedBYteArray# :: Int# -> State# s -> (# State# s, MutableByteArray# s #)'
05:49:49 <Phyx-> 13:05:23 < solonarv> it may well not be practical to write C optimized to that level
05:49:52 <Phyx-> <-- o.O
05:50:06 * solonarv doesn't write much C
05:50:29 <solonarv> for it is certainly more practical to write Haskell and let the optimizing compiler sort it out! ;)
05:50:30 * Phyx- spends all day in C or Asm so found that curious :)
05:50:39 <solonarv> *for me
05:51:44 <Phyx-> fair enough
05:52:21 <merijn> Phyx-: Most people who spend their day writing C for max performance do not, in fact, spend their day writing C >.>
05:52:36 <sim590> nyc: I've just tested your version of isPrime and it is really fast.
05:52:44 <sim590> Compared to isPrime.
05:52:52 <sim590> (Mine)
05:52:55 <merijn> Phyx-: They write some custom, ad-hoc implementation defined dialect of a language somewhat resembling C that just happens to be compiled by a compiler claiming to be a C compiler :p
05:53:30 <merijn> Phyx-: Consisting of compiler intrinsics, inline asm, and other hacky non-standard stuff :p
05:54:14 <sim590> it seems that it is confirming that it's really about the list construction issue that were talking about.
05:54:25 <phanimahesh[m]> That's one way to put it. I've never seen much production C code. Besides curious readings of oss during college
05:54:25 <nyc> sim590: I think the one with the square instead of the isqrt is faster for mysterious reasons.
05:55:10 <sim590> nyc: I just substituted isqrt by Prelude.sqrt and it runs as quickly as my isPrime'.
05:55:19 <merijn> phanimahesh[m]: Well, there's C code that doesn't look like that, but that has no business being written in C ;)
05:55:53 * hackage mmsyn6ukr 0.6.1.0 - A musical instrument synthesizer or a tool for Ukrainian language listening  https://hackage.haskell.org/package/mmsyn6ukr-0.6.1.0 (OleksandrZhabenko)
05:56:33 <sim590> nyc: Your version is even better than my isPrime' (using 6k+1 checking).
05:57:27 <phanimahesh[m]> merijn are you mayhaps referring to the beautiful horrors over yonder at ioccc?
05:57:48 <Phyx-> merijn: I write C.. plain old C.
05:57:50 <sim590> For calling nthprime with input 100001, It terminates in 0.74s while my approach with 6k+1 checking takes 1.26 seconds.
05:58:07 <phanimahesh[m]> Can't find the two versions of is prime being discussed, point me at those please
05:58:23 <yasar> Should I compile haskell-ide-engine myself? I can't find an installer (using windows)
05:59:01 <nyc> I touched things up a little bit at https://paste.debian.net/1122540/
05:59:06 <Phyx-> yasar: yes, and good luck! :)
05:59:16 <sim590> yasar: You should check the instruction on the README page. On GNU/Linux with Vim, the instructions I read were to compile the project.
06:00:00 <Phyx-> haskel-ide-engine is a typical project that should do binary releases. compiling it from source is a pain
06:00:20 <Phyx-> its dependency chain is so freaking long
06:00:21 <yasar> sim590 I saw that, but I thought maybe that was for the contributors :)
06:00:34 <merijn> Phyx-: Yeah, but whose going to build those releases, on which machines and in what time :)
06:01:13 <yasar> at least 32/64 bit windows, 32/64 bit debian would be nice :)
06:01:25 <Phyx-> merijn: use one of those fancy cloud based CI ya'll so fond off? :)
06:02:23 <Phyx-> it's not hard to set things up to build tags and deploy them as releases to github.
06:02:46 <sim590> isPrime, isPrime' :: Integer -> Bool
06:02:50 <nyc> sim590: https://paste.debian.net/1122540/ more clearly breaks up the isqrt vs. squaring issue.
06:02:53 <sim590> ^ Didn't know you could use commas there.
06:03:51 <phanimahesh[m]> The second is sieve of erasthones. I expect it to be faster than the first
06:05:06 <int-e> nyc: I guess what you're seeing is that p*p is ridiculously cheap as long as the result fits into a machine word.
06:05:16 <yasar> https://github.com/xmonad/xmonad/blob/master/src/XMonad/Core.hs#L69 -> what is up with that exclamation mark (!)
06:05:17 <merijn> Phyx-: Sure, but someone needs to do that in their unpaid free time. Time they might rather spend on getting things working better
06:05:36 <merijn> yasar: Strictness annotation
06:06:30 <nyc> int-e: That's my suspicion, too, but the threshold where things cross over has weird sharp knees and takes long enough to overheat my laptop.
06:06:33 <merijn> Phyx-: Like, I get why people get frustrated with how hard things are to build, but OTOH I empathise with people running these projects. It's easy to complain when you're not the person you're expecting to maintain a release pipeline in their spare time
06:08:27 <Phyx-> merijn: oh please, don't come talk to me about spending free time on haskell 
06:08:58 <Phyx-> if you want someone to use the project, it shouldn't be *so hard* to actually do it. You're expecting a beginner to spend hours getting an IDE to work?
06:09:54 * hackage hvega 0.4.1.2 - Create Vega-Lite visualizations (version 3) in Haskell.  https://hackage.haskell.org/package/hvega-0.4.1.2 (DouglasBurke)
06:10:03 <merijn> I'm not expecting beginners to anything. I'm expecting unpaid volunteers to work on whatever they like to work on, rather than "what other people want/need"
06:10:10 <sim590> nyc: I'm wondering why is your code faster than the one only checking 6k +/- 1 values ?
06:10:32 <Phyx-> good for you
06:10:35 <sim590> I mean, the values congruent to +/- 1 modulo 6.
06:12:15 <nyc> sim590: Generating the wheel involves enough arithmetic and list or stack manipulation to be an issue, so I basically just use odd numbers.
06:13:48 <sim590> that's funny since the projecteuler.net's solution suggests that using the wheel avoids checking too many values, then is more efficient, but it's not the case!...
06:13:54 <infinisil> Phyx-: merijn: I'm providing prebuilt HIE binaries for Linux and macOS
06:14:09 <|Lupin|> Hello, friends
06:14:17 <infinisil> https://github.com/Infinisil/all-hies/
06:14:19 <merijn> "It shouldn't be so hard to use it" <- this assumes people working on the project care more about "other people using it" rather than "making the project work (feature-wise)". If someone cares more about adoption, I'm sure their help will be welcomed with open arms
06:14:23 <|Lupin|> I'm an OCaml programmer learning Haskell
06:14:23 <merijn> infinisil: Cool :)
06:14:34 <Phyx-> win 1
06:14:36 <|Lupin|> As an exercise I'd like to implement a little Connect4 game
06:14:48 <nyc> Hallo |Lupin| !
06:14:50 <merijn> |Lupin|: You probably wanna avoid 90% of the texts than and just head over to the original tutorial :)
06:14:53 <merijn> @where tutorial
06:14:53 <lambdabot> http://www.haskell.org/tutorial/
06:14:56 <|Lupin|> I'm wondering what would be the best data structure / package to use to represent the board?
06:15:07 <infinisil> Not windows because Nix doesn't work well on windows, and I don't have windows nor do I want to use it
06:15:21 <|Lupin|> Something like an array /matrix if that exists, but I'm not sure whether it should be mutable or not?
06:15:47 <merijn> |Lupin|: I'd default to immutable for something so small/simple
06:16:22 <merijn> |Lupin|: There's a simple Array type in Data.Array in the array package
06:16:49 <__monty__> sim590: You should really read the functional pearl I mentioned. You can do an efficient wheel.
06:16:56 <|Lupin|> nyc: hi
06:17:03 <dazage> hiya.
06:17:17 <|Lupin|> merijn: taking notes, thanks! I started with learn you a haskell because I like being considered as a noob, I have to say
06:17:30 <int-e> nyc: Oh did you see that your `drv` doesn't use nthPrime' (in https://paste.debian.net/1122540/)?
06:17:39 <merijn> |Lupin|: I don't think LYAH is particularly good, tbh
06:18:08 <nyc> int-e: good catch
06:18:29 <|Lupin|> merijn: oh really? May I ask why?
06:18:31 <merijn> |Lupin|: Anyway, the tutorial was written for people learning Haskell coming from (S)ML, so focuses a lot on the details of "how is Haskell different from SML?" rather than "here's how you do basic recursive stuff", so that might be good coming from Ocaml
06:18:44 <sim590> __monty__: Do you mean "The [Genuine] Sieve of Eratosthenes" by Melissa E. O'Neill?
06:18:57 <__monty__> Yep, that's the one.
06:18:58 <merijn> |Lupin|: It glosses over many details, doesn't have any exercises, and is by now rather dated
06:19:18 <sim590> __monty__: aight. Thanks. I'll check it.
06:19:43 <|Lupin|> merijn: pretty convincing I have to say
06:19:51 <sm[m]> 2c: haskell on windows needs champions and mentors to make it a smoother experience, but windows-based haskellers don't get much support. We should try to help them out when we see them. It's in our interest to make haskell enjoyable on all platforms
06:19:51 <|Lupin|> merijn: yes, I admit I find it a bit "boring" sometimes
06:20:02 <|Lupin|> merijn: I'll have a look to the tutorial
06:20:12 <|Lupin|> Is real world haskell a better resource?
06:20:32 <int-e> nyc: Anyway, using `rem` instead of `quot` is a small improvement. But a proper array-based Sieve of Erathostenes will blow it out of the water. (I have one that sieves in chunks of size 16, 32, 64, ... and produces an [Int] list, and it takes 0.34 seconds for the 1e6-th prime compared to 16s for the square-test based one.
06:20:44 <yasar> real world haskell is kind of old, but some people are currently updating it
06:21:04 <yasar> https://github.com/tssm/up-to-date-real-world-haskell
06:21:05 <merijn> |Lupin|: Normally I'd say no, but I think with an OCaml background the tutorial + the updated RWH would be a good way to get started
06:21:07 <__monty__> sm[m]: Many believe that passively killing windows is the better path forward.
06:21:29 <int-e> nyc: And then there's the Sieve of Atkin which would be even faster (and is implemented in, I believe, several Hackage packages. I mentioned arithmoi the other day.)
06:22:02 <dazage> sm[m]: <--- what this guy said.
06:22:13 <sm[m]> monty: macos too then ?
06:22:24 <dazage> *shrug*.
06:22:41 <kangyu> @|Lupin| https://haskellbook.com/
06:22:41 <lambdabot> Unknown command, try @list
06:22:47 <|Lupin|> okay thanks! 
06:22:52 <|Lupin|> I'll give those a try
06:22:58 <yasar> __monty__ some people has to use windows for various reasons and don't want to dual boot just to for haskell (e.g. myself)
06:23:09 <|Lupin|> Many thanks for taking me to the right direction
06:23:11 <merijn> kangyu: I don't think Haskell from First Principles is a good fit for people coming from OCaml
06:23:23 <__monty__> sm[m]: Yep, don't see much effort being spent in that direction either. It just so happens that it's more similar and therefore requires less effort to begin with.
06:23:29 <merijn> Way too slow and verbose, imo
06:23:38 <nyc> int-e: I'm mostly hoping to keep it comprehensible to beginners and I can't rattle off Atkin's off the top of my head.
06:23:49 <int-e> nyc: And it's not about using Int (the list is producing Int-s because we'll likely run out of memory before exhausting the primes; the sieving uses Integer...  https://paste.debian.net/1122547/
06:24:01 <__monty__> Depending on how experienced |Lupin| is the Gentle Introduction may be suitable.
06:24:27 <int-e> nyc: I'm just wondering why you're spending so much time tuning clearly suboptimal code.
06:24:32 <|Lupin|> I'm part of the team that develops OCaml actually :)
06:24:43 <sm[m]> if haskell doesn't care to provide a good experience for people, where they are, some other language will show up that does
06:24:53 <dazage> j a v a
06:25:10 <|Lupin|> Isn't the gentle intro quite old, too?
06:25:37 <sm[m]> I'm going to throw out my usual (faster haskell intro):
06:25:40 <sm[m]> @where HTAC
06:25:40 <lambdabot> "Haskell Tutorial and Cookbook" by Mark Watson in 2017-09-04 at <https://leanpub.com/haskell-cookbook>
06:26:27 <__monty__> sm[m]: I said nothing about "haskell," SPJ is employed by MS, I'm telling you *why* it's neglected and that simply saying "Someone should take care of the windows users." doesn't help. Actually contributing to taking care of windows users is what would help.
06:26:30 <sim590> nyc: actually, on my side, using sqrt is faster than using p*p <= n as predicate.
06:26:58 <int-e> nyc: That code I posted is still naive, of course... it's common to work with coprime residues modulo 30 (because there are 8 of them, which fit nicely into a byte) rather than all numbers to be sieved.
06:27:09 <sim590> I get 0,76s with sqrt and 0,99s with the square.
06:27:09 <nyc> sim590: But that's a floating point square root as opposed to an integer square root, no?
06:27:20 <merijn> |Lupin|: The gentle intro is old, but still like, 95% relevant, if not more :p
06:27:41 <|Lupin|> merijn: okay fine
06:27:41 <sim590> nyc: it's an integer square root I'm using
06:27:51 <sim590> I do use floor . sqrt
06:27:51 <|Lupin|> Now I have a lot to read for Christmas!
06:27:54 <|Lupin|> Thanks a lot guys
06:28:04 <merijn> |Lupin|: Honestly, if you're on the OCaml dev team you might consider going straight to the Haskell Report :p
06:28:07 <__monty__> |Lupin|: Yes it's old too. But new material's mostly directed at beginners. I'm assuming you can find your way around hackage and don't need a "these are the libraries to use."
06:28:14 <|Lupin|> I'm gonna disconnect, because I tend to be easily distracted, but will come again when I have read a bit more!
06:28:15 <sm[m]> monty (I can't type your nick in Riot), ok. I'm telling stuff too. Consider us told. :)
06:28:50 <merijn> |Lupin|: It's one of the most readable language specs I know, and should be quite accessible to anyone whose seen a compiler and functional language before :p
06:28:59 <__monty__> Great! Happy holidays : )
06:29:05 <merijn> @where report
06:29:05 <lambdabot> http://www.haskell.org/onlinereport/haskell2010/ (more: http://www.haskell.org/haskellwiki/Definition)
06:29:57 <|Lupin|> okay now I'm wellequiped!
06:30:11 <phanimahesh[m]> sm (@simonmic:matrix.org): just tap username
06:30:23 <kangyu> My hie can not start up with yesod project in vscode, but it works well in small files
06:30:34 <sim590> nyc: The line I use is `sqrtn = floor $ sqrt (fromInteger n :: Double)` with predicate `<= sqrtn`. In the square version, I have (\ p -> p*p <= n) with no square root.
06:31:13 <sm[m]> phanimahesh: Riot added interpretation of markup recently, which monty's'
06:31:17 <|Lupin|> See you later all, thanks again!!
06:31:25 <sm[m]> underscores trigger, and the bridge to IRC corrupts
06:31:32 <phanimahesh[m]> Oh. Didn't know.
06:31:37 <nyc> sim590: Maybe it's my isqrt being slow.
06:31:44 <__monty__> phanimahesh[m]: That makes for a terrible experience on the other end of the irc bridge: "< phanimahesh[m]> sm (@simonmic:matrix.org):"
06:32:05 <phanimahesh[m]> What's the preferred way then?
06:32:18 <__monty__> phanimahesh[m]: Which combines with the markdown interpretation for no good way to mention my nick : )
06:32:25 <phanimahesh[m]> Just manually typing it out?
06:32:39 <__monty__> Does tab-completion work? Otherwise it'll just be manual typing I guess.
06:33:01 <phanimahesh[m]> I'm on mobile. I can get a tab on my keyboard and check though :P
06:33:27 <sm[m]> yes, manually type the nick and use tab completion if it works (seems intermittent for me)
06:34:02 <__monty__> Maybe open an issue for the Riot team?
06:34:12 <phanimahesh[m]> Okay. I'm liking matrix but it has its quirks. Off topic probably.
06:34:36 <sm[m]> +1 for opening an issue, if there's not one
06:36:01 <int-e> nyc: you can just plug in the  floor . sqrt . fromInteger  version to see. (The numbers you're dealing with have less than 53 bits, so rounding is not an issue.)
06:36:19 <Phyx-> __monty__: The problem is, people like to complain and contribute bad code into the compiler or related tools that break on windows
06:36:31 <Phyx-> and their complaint is "It's a Windows problem"
06:36:35 <Phyx-> not, it's a problem of bad design
06:37:14 <__monty__> You can't expect developers that don't care about windows to learn the ins and outs of windows though. What you need is windows developers that can take those contributions and make them work on windows too.
06:37:44 <Phyx-> I expect, that since Windows is a "first class platform" that Bad commits get reverted
06:37:47 <Phyx-> end of story
06:38:08 <Phyx-> I don't care if it happens to Work in Linux, if it's a bad commit, revert it, if you can't submit a better on, don't submit
06:38:42 <Phyx-> I spend the majority of my time fixing things others broke
06:38:49 <int-e> nyc: so the answer is... yes, it is slow.
06:39:07 <yasar> Phyx- you weren't kidding, haskell-ide-engine compilation takes forever
06:39:19 <__monty__> I'm not sure that's the best strategy. But I'm not familiar with how the GHC team deals with such issues so I don't really have anything to contribute.
06:40:22 <jollygood2> __monty__, I don't think you had much to contribute to  begin with. starting with <__monty__> sm[m]: Many believe that passively killing windows is the better path forward.
06:41:07 <__monty__> Well that's jolly good.
06:41:38 <yasar> what is haskell's equivalent of thread safe que?
06:41:57 <kangyu> What is the recommended development environment for Haskell? IDE or editor plugin
06:42:14 <merijn> yasar: We have tons...what do you need it for? :)
06:43:06 <merijn> kangyu: People here seem to be about 1/3rd vim, 1/3rd emacs, 1/3rd misc (I think VS Code and Intellij are the hot things?)
06:43:19 <yasar> I am trying to convert my Python scripts as an exercise, I have one scripts that reads a txt file with urls, and download them using a number of threads
06:43:33 <solonarv> oh, you don't even need a queue for that
06:43:35 <sim590> nyc: I've just realized that last $ take is simply !! or genericIndex...  lol... I feel a little dumb. ;)
06:43:40 <merijn> solonarv: You do, though >.>
06:43:51 <merijn> solonarv: I once accidentally took down a webcomic host
06:43:52 <solonarv> async-pool?
06:44:05 <merijn> solonarv: Because my parallel haskell crawler overwhelemed the server >.>
06:44:18 <solonarv> there might be a queue internally, but you certainly don't have to touch it explicitly
06:45:08 <merijn> There's also the concurrency stuff I did in broadcast-chan and broadcast-chan-conduit because async-pool didn't exist when I needed it :p
06:45:45 <solonarv> should be as simple as: withTaskGroup 4 $ mapConcurrently downloadURL listOfUrls
06:46:06 <merijn> Although I guess async-pool is targetting a slightly different API
06:46:25 <nyc> Okay, I wrote something that switches between isqrt, fsqrt, and squaring at https://paste.debian.net/1122548/
06:46:40 <merijn> solonarv: If you ever need that, but inside a conduit I've got you covered ;)
06:47:03 <yasar> solonarv there is no withTaskGroup in hoogle :)
06:47:19 <merijn> yasar: Hoogle doesn't index all of hackage
06:47:23 <jollygood2> yasar, depending on how many URLs you have in a file, or in other words, if it is reasonable to fetch them all at once, a simple mapConcurrently  call will do the trick
06:47:48 <solonarv> @hackage async-pool -- it's in here
06:47:48 <lambdabot> http://hackage.haskell.org/package/async-pool -- it's in here
06:47:55 <kangyu> merijn uhm... Hie doesn't work well in VScode. I mentioned the issue on github and it has not been resolved. Can you recommend some vim haskell plugins?
06:48:27 <yasar> jollygood2 I don't want to fetch them all at once, sometimes there are hundreds, sometimes there are thousands of them
06:48:30 <merijn> kangyu: I've been using ghcide (which implements LSP) together with ALE's LSP support
06:49:15 <jollygood2> yasar then see solonar's suggestion.
06:51:37 <phanimahesh[m]> Neovim head has built in LSP. I haven't tried it yet though. Have to move away from coc eventually. Hie with coc works okayish for me
06:52:55 <sim590> nyc: results on my end: https://paste.debian.net/1122550/. So yeah, isqrt is less efficient.
06:53:53 * hackage mmsyn7ukr 0.2.1.0 - A simple basic interface to some SoX functionality or to produce a close to the proper Ukrainian speech (if you pronounce sounds properly) with your own recorded voice.  https://hackage.haskell.org/package/mmsyn7ukr-0.2.1.0 (OleksandrZhabenko)
06:55:47 <yasar> I have installed "haskell language server" in VS Code, also compiled and put "hie" on path. But when I edit any Haskell files, I don't find anything new
07:00:57 <yasar> This is the output of hie: https://paste.debian.net/1122551/
07:01:50 <yasar> Operating system:mingw32 line looks weird, shouldn't it say windows?
07:03:34 <solonarv> mingw32 does indeed mean windows
07:04:24 <p0lyph3m> phanimahesh[m] : i am using neovim with coc and hie , you mean i dont need coc with neovim to use hie ?
07:08:34 <int-e> nyc: With https://paste.debian.net/1122552/ the isqrt version actually becomes faster (and quite a bit faster if you enabled the commented out parts.)
07:10:03 <int-e> nyc: oops, minus the traceShow
07:10:10 <merijn> yasar: mingw32 is a compiler/linker distribution for windows
07:38:25 <nyc> int-e: That probably is faster than a bunch of divisions.
07:42:57 <int-e> nyc: The main point is that Newton's iteration needs far fewer iterations than bisection. There's still room for improvement; the code wastes a lot of effort by working with full precision all the way. But then again, GMP provides an integer square root function which will be much faster anyway.
07:43:32 <int-e> (Those improvements would be relevant for big numbers only anyway.)
07:44:49 <nyc> I guess my isqrt skills need improvement.
07:50:23 <nyc> My patience is insufficient for a document chase for getting at the gmp isqrt.
07:51:02 <int-e> (Oh, forgot one important point: Newton's method needs a decent starting point. If you just start at n for sqrt(n) then the first iterations will approximately halve the estimate until they reach the vicinity of the square root; from that point on, the number of correct bits will approximately double in every iteration. This is why I bother with the binary search for finding the bit width of...
07:51:08 <int-e> ...sqrt(n).)
07:58:53 * hackage alg 0.2.13.1 - Algebraic structures  https://hackage.haskell.org/package/alg-0.2.13.1 (MatthewFarkasDyck)
08:06:24 * hackage mmsyn6ukr 0.6.2.0 - A musical instrument synthesizer or a tool for Ukrainian language listening  https://hackage.haskell.org/package/mmsyn6ukr-0.6.2.0 (OleksandrZhabenko)
08:09:38 <Phyx-> yasar: mingw32 is named after the original port used to create GHC support on Windows. i.e. the target triple in GCC, i686-unknown-mingw32
08:10:11 <Phyx-> yasar: GHC switched to *mingw-w64 a while back but we kept the target name for compatibility
08:10:47 <ClaudiusMaximus> @hackage hgmp -- nyc, this plus an FFI import should work for getting at gmp isqrt  (I wrote hgmp, so if it doesn't work yell at me)
08:10:47 <lambdabot> http://hackage.haskell.org/package/hgmp -- nyc, this plus an FFI import should work for getting at gmp isqrt  (I wrote hgmp, so if it doesn't work yell at me)
08:14:21 <int-e> ClaudiusMaximus: you even import mpz_sqrt, cf. http://hackage.haskell.org/package/hgmp-0.1.1/docs/Numeric-GMP-Raw-Safe.html#v:mpz_sqrt
08:23:36 <nyc> ClaudiusMaximus: Thank you!
08:40:07 <yasar> Does haskell ide engine work over tcp? I failed to make it work on windows, I am thinking of installing it into a virtualbox and using it from windows
08:54:54 * hackage category 0.2.5.0 - Categorical types and classes  https://hackage.haskell.org/package/category-0.2.5.0 (MatthewFarkasDyck)
08:59:15 <hololeap> that mmsyn7ukr package has me really confused
09:00:37 <Phyx-> yasar: what's the issue you're having?
09:01:04 <hololeap> A simple basic interface to some SoX functionality or to produce a close to the proper Ukrainian speech (if you pronounce sounds properly) with your own recorded voice.
09:01:05 <hololeap> wat?
09:03:11 <c_wraith> would it help to know that SoX describes itself as an audio swiss-army knife?
09:05:36 <yasar> Phyx- Everything seems like it should be working, but nothing happens :)
09:06:59 <Phyx-> yasar: try starting hie with --debug
09:07:19 <hololeap> i actually know about SoX, but that description... produces close to the "proper Ukrainian speech"... but only if you already pronounce the sounds correctly
09:07:58 <Phyx-> i locals
09:16:35 <phanimahesh[m]> p0lyph3m not needed with latest head on neovim. Not released yet. Built in language server. Usable. Good enough apparently but won't be as feature complete. It's expected that community builds on top of its low level api.
09:19:27 <phanimahesh[m]> Of course you need to pronounce them correctly. It doesn't do magic
09:29:22 <hololeap> i thought it was some "deep fakes" level stuff :)
10:13:50 <p0lyph3m> phanimahesh[m]: ahh , ok thanks 
10:19:54 * hackage threepenny-gui 0.8.3.1 - GUI framework that uses the web browser as a display.  https://hackage.haskell.org/package/threepenny-gui-0.8.3.1 (sjakobi)
10:55:07 <ddellacosta> is regex-base + some backend the most commonly used regex library? If you were going to do a regex replace on a Text value as part of a one-off piece of code what would you use?
11:04:13 <hololeap> ddellacosta: most people use parsec or one of its variants, but it's not regex
11:05:36 <hololeap> it uses parser combinators which are different but serve essentially the same purpose
11:05:55 <sm[m]> ddellacosta: http://hackage.haskell.org/package/regex probably
11:06:55 <sm[m]> with TDFA backend if portability is desired
11:27:23 <dmwit> I like regex-applicative. But it doesn't do Text.
12:29:24 * hackage ihaskell-hvega 0.2.1.0 - IHaskell display instance for hvega types.  https://hackage.haskell.org/package/ihaskell-hvega-0.2.1.0 (DouglasBurke)
12:49:18 <yasar> I have enabled debug info for haskell ide engine and this is what I get -> https://paste.debian.net/1122575/
12:49:27 <yasar> as far as I can tell, hie side of things are working
12:49:55 <yasar> but in VS Code, it is not working, any ideas?
13:03:23 * hackage mmsyn7h 0.1.0.0 - A program that is used in mmsyn7ukr and is similar to mmsyn6ukr executable.  https://hackage.haskell.org/package/mmsyn7h-0.1.0.0 (OleksandrZhabenko)
13:15:41 <habib> am i wrong in thinking that if i peek a CString which supposedly contains utf-8 text, i can just Text.pack it and get a valid Text value?
13:17:07 <habib> or even pass it to another function exposed through ffi that takes a CString containing utf-8 with a conversion to String then back to CString (and no other manipulations in between)?
13:17:18 <merijn> habib: I honestly have no idea, but it seems unlikely
13:17:27 <merijn> habib: It depends on how peek returns the String
13:18:05 <merijn> Oh, there's a peekCString that takes an explicit encoding
13:18:20 <merijn> If you use that (with the correct encoding, obviously) then packing should be fine
13:19:36 <habib> where do you see that? I see peekCAString, which claims to be a variant of peekCString for use with c functions ignorant of unicode.
13:20:10 <merijn> GHC.Foreign
13:20:19 <merijn> "peekCString :: TextEncoding -> CString -> IO String"
13:20:50 <shachaf> Wouldn't going through String to get from CString to Text be very inefficient?
13:21:36 <merijn> Whether that matters depends
13:22:15 <merijn> This is the simplest approach that's guaranteed to be correct, so unless this is super frequent/huge amounts of text it seems fine
13:22:23 <habib> well, I'd either go through Text or String. i'm wondering if i should dig deeper and find the right functions, or if i'm looking at the right functions and i can just convert to String and then back to CString
13:22:38 <dmwit> But... why do that?
13:22:41 <habib> let me set up the context
13:22:49 <dmwit> We've got perfectly good types for representing bytes.
13:22:54 <merijn> shachaf: You're gonna have to copy the Text at least once, even when decoding for ByteString
13:23:54 <habib> sorry, i just realised i was saying text, you're right. i was actually looking for a peekByteString or something
13:24:06 <habib> but i'm getting ahead of myself, let me explain what i'm doing first
13:24:56 <dmwit> http://hackage.haskell.org/package/bytestring-0.10.10.0/docs/Data-ByteString.html#g:22
13:25:22 <habib> i'm writing a gui app and interfacing directly with Xlib (for learning purposes, and it's a fairly simple app, so i decided to forgo gui toolkits and work directly with Xlib and the core X11 libraries) [cont]
13:26:36 <habib> there's an event loop where i inspect key events and use the Xlib function Xutf9LookupString which populates a char * buffer
13:26:41 <yasar> After trying to make haskell ide engine work for VS Code, I realized there is an extension called Haskero that just works :)
13:27:02 <yasar> spent so much time on hie :/
13:27:53 <habib> there's also XmbLookupString which is a generic multibyte that uses the user's preferred encoding and XwcLookupString which does the same as XmbLookupString but populates a w_char_t * buffer instead of char *.
13:32:30 <habib> there's another function called Xutf8DrawString which i suppose draws the utf-8 string that Xutf8LookupString returns from the key event (there's also XftDrawStringUtf8, and i think that's just a wrapper, but i'm not sure, but that's by the by).
13:32:56 <habib> Xutf8DrawString (and XftDrawStringUtf8) take a char * string to draw
13:33:23 <habib> in C, i would just pass the string directly, i guess
13:33:42 <habib> in Haskell, since i'm using the FFI, i'm writing higher level equivalents of the c functions i'm exposing
13:34:07 <ddellacosta> sm[m]: thanks
13:34:39 <habib> the c ffi functions take `CString`s and the Haskell wrappers take Strings because they peek (or poke) the C strings into Strings or vice versa
13:35:24 <merijn> habib: CString is just an alias for "Ptr CChar"
13:35:24 <habib> i'm wondering if i should peekByteString or something and if i'm destroying any information by peeking a supposedly utf-8 CSring into String
13:35:45 <merijn> habib: Peek is just "copy value from pointer into GCed memory"
13:36:15 <habib> yeah, i get that, i've been digging through the docs for a while trying to understand
13:36:27 <habib> if i understand correctly, there should be no loss of information
13:36:43 <habib> it just confuses me that the c function would return utf-8 data in char * form
13:36:49 <habib> but let's say i trust them
13:36:52 <merijn> How else would it return it?
13:37:26 <merijn> There's no other way for C to return strings
13:37:47 <habib> right, but there's a w_char_t for wide character encodings (utf-16, for example)
13:37:57 <Clint> wchar_t
13:38:22 <merijn> utf-8 was explicitly designed to be backwards compatible with ascii and function inside char* without breaking existing code
13:38:56 <habib> i guess utf-8 in char * form would be char elements for ascii characters, and any multi-byte characters would just be multiple char * elements
13:39:08 <habib> just trying to understand how c does unicode with utf-8
13:39:42 <habib> technically 0x80 to 0xFF (128-255) are invalid utf-8 byte sequences
13:39:50 <habib> 0-127 are the usual ascii characters
13:40:18 <merijn> C doesn't really do anything smart with strings
13:40:25 <Clint> or utf-8
13:40:35 <merijn> C the only "special" thing is that most C functions treat \0 as string termination
13:40:43 <habib> it's all handled by tae library, right
13:41:02 <habib> so utf-8 is really just char *?
13:41:03 <merijn> null bytes are not valid within utf8, so anything utf8 string can be safely copied/handled by C code expecting a "regular" string
13:41:19 <Clint> no, utf-8 is an encoding
13:41:21 <merijn> Note that C doesn't guarantee to support ascii strings to begin with :p
13:41:32 <habib> really?
13:41:51 <merijn> The format used by C is implementation defined
13:42:20 <merijn> And when, say, IBM's EBDIC or whatever it was called encoding was used some systems would, for example, use that
13:42:22 <habib> Clint, what i mean is that the libraries can just handle char * as utf-8
13:42:45 <habib> the library knows what sequence of bytes corresponds to what codepoint
13:43:04 <habib> and ascii-encoded strings and utf-8 encoded strings can both be stored in char * buffers
13:43:15 <habib> it's how the library handles the buffer that makes it
13:44:36 <habib> char is 0-255 (usually?) and there are only 128 ascii characters, but utf-8 characters are just encoded as multiple char sequences outside of the ascii characters
13:45:12 <merijn> habib: Sure, but the value of 'a' is not guaranteed to correspond to the ascii value 'a' by C :p
13:45:35 <merijn> habib: anyway, char* in C parlance is just "pointer to bytes"
13:45:50 <habib> right, i get it now
13:45:52 <merijn> Since byte (as used in the C standard) is defined to be equivalent to char
13:45:55 <habib> i'm misreading the char as a character
13:46:06 <habib> but it's just a data type which is guaranteed(?) to be at least a byte
13:46:11 <habib> but can be more
13:46:23 <merijn> Guaranteed to be 7bits, for max confusion :p
13:46:29 <habib> oh god
13:46:45 <habib> but anyway, that's why char * doesn't necessarily mean ascii-only
13:46:54 <habib> it's just the equivalent of a bytestring
13:46:59 <habib> and bytestring is encoding-less
13:47:48 <habib> so i guess i should also clarify: bytestring in haskell is just a more efficient form of string, right?
13:47:55 <merijn> No
13:47:56 <habib> neither have any particular encoding attached
13:48:01 <monochrom> If you code to the minimum guarantee, you almost never get things done.
13:48:03 <merijn> ByteString's name is horrible historical mistake
13:48:16 <merijn> habib: Just pretend ByteString is actually named "Bytes"
13:48:32 <habib> but isn't that what string is as well? just a linked list of bytes
13:48:35 <habib> ?
13:48:41 <merijn> habib: String, on the other hand, like Text is "unicode text" (note that unicode text doesn't have an encoding)
13:48:43 <habib> whereas bytestring is efficiently packed
13:48:58 <monochrom> Yeah two biggest historical misnomers: "effectful functions" and "byte strings".
13:49:00 <merijn> habib: No, String is a linked list of unicode characters (codepoints? something)
13:49:13 <habib> ah, of course, the whole "unicode isn't an encoding, utf-8 or utf-16 or utf-32 or ucs etc. are)
13:49:52 <monochrom> Although, there are mathematicians who take "string" to mean sequences, no particular attachment to characters.
13:49:53 <merijn> Encoding only come into play when you have Text/String, but want Bytes
13:50:06 <sm[m]> yasar: haskell IDEs are like wifi routers - if one is giving you trouble, the quickest way to solve it is switch to another..
13:50:19 <maerwald> monochrom: I consider returning a value an effect
13:50:34 <monochrom> Naw, haskell IDEs are like diamonds. You don't need it.
13:51:10 <habib> merijn so an encoding is a description of how to convert a high-level construct into bytes and vice versa? does that definition sound reasonable?
13:51:29 <habib> utf-8 describes how to convert unicode text into bytes
13:51:39 <habib> and how to decode bytes into unicode text
13:52:08 <merijn> habib: Correct
13:52:21 <habib> and String is actually a linked list of Char, which is not analogous to char * because Char isn't a byte in Haskell, but a single Unicode codepoint
13:52:25 <habib> is that right
13:52:47 <maerwald> also right is: don't use String for anything non-trivial :P
13:52:50 <dmj`> > sizeOf (undefined :: Char)
13:52:52 <lambdabot>  error:
13:52:52 <lambdabot>      â€¢ Variable not in scope: sizeOf :: Char -> t
13:52:52 <lambdabot>      â€¢ Perhaps you meant one of these:
13:52:57 <merijn> Yes (modulo technical details on the difference between unicode characters and unicode codepoints that I'm currently unsure of)
13:53:14 <monochrom> Char is a codepoint.
13:53:29 <monochrom> There are characters made of two codepoints.
13:53:33 <yasar> Can haskero be made to show haddock information?
13:53:47 <habib> i see, okay. i was under the misunderstanding that it was just a linked list of bytes and the inefficiently structured form of bytestrings
13:54:01 <maerwald> so it's not a char then!
13:54:14 <dmj`> Char is 64 bits
13:54:17 <maerwald> oh boy, everything is a lie
13:54:21 <monochrom> And it gets better.  There are characters admitting two representations, one representation uses one codepoint, another uses two codepoints, and programmers are supposed to consider them equal when, e.g., asked to compare strings.
13:54:51 <monochrom> (You can guess that no programmers actually bother.)
13:55:04 <habib> ha ha, yes, and there are at least 4 different schemes of normalising that you can use
13:55:06 <maerwald> is there any Eq instance that does that?
13:55:19 <merijn> maerwald: text-icu has stuff for normalisation
13:55:20 <monochrom> No I think not. (I haven't checked.)
13:56:26 <monochrom> For example something as simple as Ã©
13:57:49 <habib> so long story short, since i'm not touching the strings on the haskell side, and i assume the conversion between CString and String loses no data, so i can just do the Xutf8LookupString via the Haskell wrapper which returns a String and pass it to the XftDrawStringUtf8 function via the Haskell wrapper which takes a String and everything should just work.
13:57:51 <maerwald> so there are 6 normalisation modes... I pick a random one? lol
13:58:23 <habib> i'm not doing anything wrong there?
13:58:29 <merijn> habib: Yes. Although if you only need to pass them on, you don't even need to convert?
13:58:31 <habib> and the Haskell wrappers i'm referring to are just higher level haskell functions which call some FFI'd C functions which take and return CStrings
13:58:53 <maerwald> https://hackage.haskell.org/package/text-icu-0.7.0.1/docs/Data-Text-ICU.html#v:compare
13:58:56 <maerwald> this looks like it
13:59:02 <merijn> habib: btw, the char* being returned who is responsible for free'ing those? i.e. avoid a memory leak :p
13:59:09 <habib> yeah, i guess so, but i am writing wrapper functions to make the apis a little nicer to use and id prefer that wrapper functions didn't take low level CStrings
13:59:17 <habib> maybe i'll just pass them directly on
13:59:52 <Clint> what is this FCD abomination
13:59:53 <merijn> habib: If you're supposed to free the strings returned by the C API you should make sure you do so
13:59:59 <monochrom> Anyway I guess I mistook Christmas Eve for Halloween in telling you these horror stories!
14:00:06 <habib> but i also thought it might be better to have wrapper functions that take and return bytestrings since that actually describes the type better
14:00:08 <c_wraith> maerwald: assume normal form C unless something says otherwise.
14:00:18 <merijn> monochrom: Natural mistake, given the fact that Dec 25 = Oct 31 ;)
14:00:39 <habib> monochrom right now i just have a big TODO comment at the top of the file that says, free(3) stuff lol
14:01:17 <habib> i will add all of that at the end, writing these ffi functions is tedious enough without the free malarchy
14:01:33 <habib> i have to use XFree in some scenarios, not free in others, and normal free(3) in some
14:01:47 <habib> it's just another layer i don't want to get bogged down in yet
14:02:02 <merijn> habib: Just a heads up, you're aware of ForeignPtr? :)
14:02:08 <habib> but i won't push a commit without proper frees to master
14:02:47 <habib> merijn yes, i am. i discovered it whilst digging around into... things. lots of things. i understand they're Ptrs with finalizers attached (free functions).
14:02:57 <merijn> Basically, yes
14:03:09 <habib> they sound useful, and i'll probably fix up the code to use them once i've got it doing what i want
14:03:27 <habib> and am sure i haven't made any other stupid mistakes that i'm liable to make interfacing with c
14:04:50 <habib> anyway, that's pretty much cleared up a lot. i just wanted the peace of mind that CString to String to CString unicode data is okay if i'm not manipulating the unicode in haskell, which it sounds like it is.
14:05:48 <merijn> If you know the correct encoding then it's also fine if you *do* manipulate the data in Haskell
14:05:48 <habib> i'd still like the higher level functions to work with bytestrings so i don't start mucking around with the String values accidentally in future, but i guess you can't have everything.
14:06:01 <merijn> And if you don't know the encoding going via String will likely never be fine :p
14:06:08 <merijn> ByteString should always be fine, though
14:06:21 <habib> lol yeah that makes sense, of course, string is unicode
14:07:25 <habib> i just hate the fact that i'm passing strings around to represent data that i don't care about the encoding of
14:07:29 <habib> feels kinda dirty
14:08:32 <habib> okay, another question, much simpler this time
14:08:59 <habib> does anyone know of a package which has a data AOrBOrNeitherOrBoth data type
14:09:12 <habib> i found These a b = This a | That b | These a b
14:09:22 <habib> which is cool, and i guess i could do Maybe (These a b)
14:10:10 <phadej> (Maybe a, Maybe b)
14:10:24 <phadej> that's really not worth own type
14:10:49 <phadej> (at least general, non application specific one)
14:11:25 <habib> ah, never thought about representing it as tuples. i prefer Nothing to (Nothing, Nothing) as the neither case, so i'll probably stick with Maybe (These a b)
14:11:38 <habib> but yeah, probably not worth its own type, was just curious
14:12:42 <habib> Nothing, Just (This a), Just (That b), Just (These a b)
14:12:44 <habib> beautiful
14:12:57 <maerwald> that's too easy, those should all be transformers
14:13:16 <maerwald> https://hackage.haskell.org/package/monad-chronicle-1/docs/Control-Monad-Chronicle.html
14:15:01 <habib> https://hackage.haskell.org/package/these-0.7.5/docs/Control-Monad-Chronicle.html
14:15:11 <habib> looks like it's been folded in to the these package
14:15:31 <habib> reading into it now tho
14:16:09 <habib> man, i love the names haskellers come up with sometimes
14:16:30 <habib> i mean these is great, but the monadchronicle methods are amazing
14:16:47 <maerwald> imagine that stuff all over your production code base
14:16:49 <habib> dictate, disclose, confess, memento, absolve, condemn, retcon, chronicle
14:16:58 <habib> lol
14:18:03 <habib> it's just another abstraction. like any, the benefits for each use case should be weighed up against the cost of adding that abstraction.
14:18:37 <maerwald> who is doing that evaluation? :P
14:18:41 <habib> i don't work on production haskell, anyway. i wish i did.
14:19:17 <habib> but my hobby projects are littered with heavily abstract, tight code which i fully understand, and then a lot of nested case expressions, for example
14:19:22 <habib> it's a weird mixture
14:19:56 <maerwald> abstraction is overrated, especially poor abstraction
14:20:21 <habib> abstraction or indirection?
14:20:29 <habib> 2 sides of the same coin
14:20:47 <habib> depending on what mood you're in and what connotation you want to use
14:21:08 <maerwald> abstraction isn't something you want, it's something you *see*. Once you are at the "want" train, you'll do all sorts of things, but not useful abstraction
14:21:46 <maerwald> if you don't see it, then leave it, it'll come later
14:21:57 <habib> abstraction isn't something i want, it's a tool to get at what i want, sometimes
14:22:11 <habib> but yes, i agree that no abstraction is almost always better than a poor abstraction
14:23:01 <maerwald> @hackage directory
14:23:01 <lambdabot> http://hackage.haskell.org/package/directory
14:23:05 <maerwald> there you have one ;)
14:24:45 <habib> maerwald is that directed at me? not sure i understand. i'm not looking for a directory abstraction :)
14:25:27 <maerwald> just a prominent example of problematic abstraction
14:25:31 <habib> i don't know who it was that suggested the chronicle monad transformer, but i don't get how it'd be useful in my situation
14:27:13 <maerwald> https://hackage.haskell.org/package/directory-1.3.4.0/docs/System-Directory.html#v:canonicalizePath
14:27:15 <habib> maerwald why do you say the directory package is a problematic abstraction?
14:27:16 <maerwald> my favorite
14:27:51 <maerwald> habib: because linux and windows are sufficiently different that you shouldn't have the same function on both platforms, because they don't do the same thing
14:27:59 <habib> or do you mean directories in general in unix?
14:28:46 <maerwald> once you're done reading that massive piece of documentation and figuring out where the semantic differences are and what exceptions the function can throw on each platform... you'll not remember it tomorrow
14:29:14 <maerwald> it's a "close enough" abstraction
14:29:19 <habib> right, they don't do the same thing, but there's a common core where some of the differences are superficial, such as separators
14:29:54 <habib> i guess the abstraction could be broken down, so directory separators is a tiny abstraction in and of itself that could just come in one library
14:33:05 <habib> that chronicle monad transformer looks really interesting. i don't get it, but it makes me curious what a These monad transformer does and what it is.
14:33:30 <habib> where would it be useful? what problem does it solve?
14:34:21 <maerwald> partial success or error vs warning distinction
14:35:18 <habib> ah, whereas either stops the whole thing at the first sign of trouble, this can keep going in some instances when it's not a critical failure?
14:35:50 <maerwald> I've found myself wanting something like that when dealing with POST endpoints that are actually bulk operations and ExceptT isn't really that great there
14:36:47 <habib> yeah, i've wanted to solve that particular problem myself of partial success. it sounds like a common problem.
14:37:20 <maerwald> but then I realised error handling is annoying anyway and gave up :P
14:41:34 <habib> i'd love to see an example of it in use (maybe that'd even help me understand the method names), but searching for the chronicle monad returns the these package version, the monad-chronicle package version, and typelevel.org/cats-mtl blog post that is not loading for me (crappy internet right now). none of the other results are relevant (ah, nvm, google gives slightly better results; but still, nothing
14:41:36 <habib> explanatory).
14:42:17 <habib> anyway, i have to get back to actually finishing my little Xlib consumer
14:42:37 <habib> definitely bookmarking that tho, cheers :)
14:44:37 <maerwald> I had high hopes for Excepts https://docs.haskus.org/variant/excepts.html but it turns out that catching multiple exceptions is done via pattern synonyms (and as such, no knowledge of partiality)
14:44:37 <maerwald> and second, it doesn't really have a concept of "checked exception" either
14:45:37 <maerwald> Back to Maybe and Either...
14:59:27 <habib> well, looks like that's goodnight from me while my machine is compiling package these and its dependencies
15:05:02 <wildtrees_> Merry Christmas! 
15:15:24 * hackage tonatona 0.1.1.0 - meta application framework  https://hackage.haskell.org/package/tonatona-0.1.1.0 (arowM)
15:20:52 <sm[m]> merry christmas wildtrees_ 
15:54:23 * hackage mmsyn7h 0.2.0.0 - A program that is used in mmsyn7ukr and is similar to mmsyn6ukr executable.  https://hackage.haskell.org/package/mmsyn7h-0.2.0.0 (OleksandrZhabenko)
16:19:53 * hackage mmsyn7ukr 0.3.0.0 - A simple basic interface to some SoX functionality or to produce a voice that can be used by mmsyn7h  https://hackage.haskell.org/package/mmsyn7ukr-0.3.0.0 (OleksandrZhabenko)
17:22:53 * hackage thumbnail-polish 0.0.1.1 - Image thumbnail creation  https://hackage.haskell.org/package/thumbnail-polish-0.0.1.1 (DanielCampoverde)
17:38:24 * hackage directory 1.3.5.0 - Platform-agnostic library for filesystem operations  https://hackage.haskell.org/package/directory-1.3.5.0 (Rufflewind)
19:41:21 <jusss> wow, is that purescript a part of haskell?
19:41:33 <jusss> https://hackage.haskell.org/package/purescript
19:58:02 <phanimahesh[m]> purescript compiler is implemented in haskell.
20:05:22 <slack1256> Has anyone used fltk-hs on windows?
20:05:57 <slack1256> Or should I use gi-gtk for windows? which is easier?
20:12:41 <jusss> how I can turn a unicode emoji to ByteString?
20:16:53 <slack1256> jusss: Should that just be a mattern of seeing with "unicode word" is the emoji, see how to represent that as utf-8 and store that on a bytestring?
20:17:07 <slack1256> "unicode word" -> code point
20:19:08 <jusss> slack1256: eg, \128308 is a codepoint of a red spot, 
20:19:35 <jusss> I can use `unicode 128308` turn it to ?
20:19:52 <slack1256> See how to represent that codepoint on utf8 
20:20:23 <jusss> from http://hackage.haskell.org/package/bytestring-0.10.10.0/docs/Data-ByteString.html?
20:20:28 <slack1256> Then store that representation as a bytestring (it could be 1-2-3-4 bytes depending).
20:31:45 <EvanR> the utf-8-everywhere answer to the question
20:32:14 <EvanR> there are at least 2 other ways you could turn a character into a bytestring
20:32:53 <EvanR> utf16LE and utf16BE :)
20:32:56 <jusss> I saw that `putStrLn "\128308"` can display a red spot in my screen
20:33:34 <EvanR> i think you didn't specify enough how you wanted to convert to byte string
20:46:47 <monochrom> Don't forget base64 :)
20:47:21 <monochrom> Actually, let's take it away.  Don't forget uuencode >:)
21:09:40 <jusss> EvanR:  I'm confused, all the encoded ByteString can transform by word8?
21:09:58 <jusss> what's the relation between word8 and unicode codepoint?
21:10:03 <EvanR> i don't understand
21:10:37 <jusss> EvanR: "8" is a String, it has its codepoint in unicode?
21:10:54 <EvanR> a codepoint is some number, it may take up to 21? bits to express in binary
21:10:59 <jusss> what if we {-# LANGUAGE OverloadedStrings #-}
21:11:09 <EvanR> so doesn't fit in a word8
21:11:52 <EvanR> OverloadedStrings makes some decision on how to encode text as a ByteString
21:12:24 <EvanR> i think the idiom is don't use characters past 255
21:12:37 <EvanR> or 127?
21:12:54 <EvanR> this gives you C-like behavior for strings
21:13:17 <jusss> when it's over 255, how I can represent a unicode '\128308' with utf-8 encoding in ByteString way?
21:13:26 <EvanR> ah so you wan't utf8
21:13:29 <EvanR> want*
21:13:33 <jusss> yeah
21:13:48 <EvanR> Data.Text.Encoding has a utf8 encoder
21:14:04 <jusss> http://hackage.haskell.org/package/bytestring-encoding-0.1.0.0/docs/Data-ByteString-Encoding.html
21:14:24 <EvanR> there are other packages but text is more standard for this
21:14:57 <jusss> EvanR: what is this "\128308" ?
21:15:09 <EvanR> a string literal?
21:15:23 <jusss> putStrLn "\128308" will display a red circle in my terminal
21:15:38 <EvanR> yeah and the reason is not simple
21:15:40 <jusss> not the literal string "\128308"
21:16:02 <EvanR> er it does display the literal string "\128308"
21:16:12 <EvanR> do you mean it doesn't display "\\128308"
21:16:37 <EvanR> or "\"\\128308\""
21:17:18 <EvanR> when you write "\128308" you are denoting a length 1 string 
21:17:31 <EvanR> not 7
21:18:11 <jusss> EvanR: https://img.vim-cn.com/4f/58f21605a7c6d4732aaa8ee6c01c9a1bb235a6.png 
21:18:23 <EvanR> it's an emoji
21:18:54 * hackage mono-traversable 1.0.15.1 - Type classes for mapping, folding, and traversing monomorphic containers  https://hackage.haskell.org/package/mono-traversable-1.0.15.1 (MichaelSnoyman)
21:19:12 <EvanR> you could also have (perhaps) wrote putStrLn "ðŸ”´"
21:19:29 <EvanR> with the actual emoji between quotes
21:20:05 <jusss> EvanR: I want to represent this emoji with the ByteString way
21:20:53 <EvanR> so use Data.Text.Encoding.encodeUtf8 like slack1256 said
21:20:53 <jusss> encodeUtf8 "\128308" would do it?
21:21:31 <jusss> EvanR: is there a function to show ByteString, like putStrLn?
21:21:32 <rwmorrison> Hello! Is there a way to atomically write a value into an unboxed mutable IO vector? 
21:21:42 <EvanR> yes
21:21:54 <EvanR> putStrLn in Data.ByteString
21:28:43 <jusss> Data.ByteString.putStrLn $ Data.Text.Encoding.encodeUtf8 "\128308"
22:41:04 <nil> say module A imports module B; is there a way to have a function in module B that, when used in module A, gives module A's name?
22:42:20 <nil> Language.Haskell.TH.location seems to provide the location at which the splice occurs
22:53:52 <c_wraith> You want...  the module that was imported to get the name in scope?
22:54:14 <c_wraith> that's a bit awkward, as it's neither the current module nor the defining module.
22:54:37 <c_wraith> I have no idea if it is available.
22:59:17 <c_wraith> I don't see anything for that in template haskell.  You might be able to get it through the ghc api, but that's wandering into painful areas.
23:07:48 <iqubic> Is there a nice conduit way to do read some input from the terminal and pass it through a pipe line, then write some output to the terminal?
23:10:58 <iqubic> I have this: ConduitT Int Int m (Either VMError Memory). I want the input of that to be read from stdin and I want the output to be written to stdout. And then I want to ignore the final output with void.
23:11:02 <iqubic> :t void
23:11:05 <lambdabot> Functor f => f a -> f ()
23:11:51 <iqubic> s/final output/pipe
23:12:05 <iqubic> s/final output/pipe's return value/
23:24:14 <nil> c_wraith: i think i want the current module
23:24:32 <nil> not the defining one
23:26:31 <nil> the idea is, i have src/AOC.hs and src/2019/Day{01..25}.hs, and each of the Day* modules import AOC. i'd like AOC to export a function readInput that, when called from DayN, reads the file inputs/2019/N
23:27:48 <nil> i could also use an environment variable, or use the preprocessor, or call readInput with the day number explicitly, but i was wondering if there was a neater way
23:34:14 <iqubic> I call readInput with the day number.
23:42:24 * hackage hs-bibutils 6.8.0.0 - Haskell bindings to bibutils, the bibliographyconversion utilities.  https://hackage.haskell.org/package/hs-bibutils-6.8.0.0 (wilx)
