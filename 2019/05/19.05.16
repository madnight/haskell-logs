00:04:04 <zincy_> Obviously two of Vector Card 'Z are being combined at the type family using the Plus type family to compute the new Nat length.  I am wondering if I am using the wrong kind of type family and shouldn't be using associated types. Perhaps Data Families would give what I need?
00:04:07 <MarcelineVQ> zincy_: I would guess line 54
00:05:05 <zincy_> Yay! That is it
00:05:22 <dminuoso> zincy_: The entire Game GADT looks wrong.
00:05:32 <zincy_> tell me more
00:05:36 <zincy_> :)
00:05:53 <dminuoso> zincy_: PreFlopGame/FlopGame/TurnGame/RiverGame *all* demand a `Vector Card 1`
00:06:52 <zincy_> Thanks! 
00:26:36 <absence> is there a language extension that lets you match multiple values in each case, e.g. case x of;  A1, A2, A3 -> "case 1"; A4, A5 -> "case 2"
00:27:13 <ski> Haskell (even with extensions) unfortunately doesn't have "OR" / disjunctive patterns
00:27:41 <ski> you can perhaps use a guard with `elem', in case those are constant constructors, rather than arbitrary patterns
00:35:48 <tdammers> a decent enough workaround IMO is to use a two-stage matching
00:36:03 <Phyx-> or use tuples
00:36:29 <ski> tuples ?
00:36:55 <dminuoso> Phyx-: Don't conflate AND with OR.
00:37:30 <Phyx-> ah, he said OR, I was looking at the example code which looked like AND
00:40:03 <absence> ski: thanks
00:40:57 * ski wonders what more precisely tdammers had in mind
00:50:04 <tdammers> something like data Matching = MatchCase1 | MatchCase 2; let m = case x of { A1 -> MatchCase1; A2 -> MatchCase1; A3 -> MatchCase2; ... } in case m of { MatchCase1 -> ...; MatchCase2 -> ... }
00:53:18 <ski> ok (more or less what i suspected)
00:53:41 <tdammers> or you could just wrap the shared branches into functions
00:54:06 <tdammers> case x of { A1 -> case1; A2 -> case1; A3 -> case2; ... } where case1 = ...; case2 = ...
01:27:29 <asheshambasta> hi, has anyone had success with optimising an intero based emacs setup in any way? https://github.com/chrisdone/intero/issues/620 I'm using Intero with emacs and typing is really laggy on an otherwise high end laptop.
01:28:25 <asheshambasta> from that issue report and some googling, it seems like intero tends to rely on some blocking operations (I've not dug into that much)()
01:45:53 <wbeut> Strange.. when I use Haskell Platform's GHCi, I can access folders in my company network like 'file <- readFile "\\\\COMPANY\\Drive1\\text.csv"
01:46:05 <wbeut> But if I use stack ghci, I can't
01:46:30 <wbeut> Generated executable behaves the same
01:48:11 <Solonarv> the same as what?
01:49:12 <wbeut> The same as repl 
01:50:11 <Solonarv> hm, then I'd blame it on stack running things in some kind of msys-like environment; might be a bug?
01:50:33 <wbeut> Probably, it's a windows machine.
01:50:40 <wbeut> maybe that's why.
01:51:07 <Solonarv> well yeah, if it weren't a windows machine those paths would never work
01:51:08 <Solonarv> :P
01:52:32 <Solonarv> a cursory search of the stack issue tracker finds nothing relevant
01:52:53 <wbeut> strange.
01:53:12 <Rembane> That looks like SMB-paths. I wonder if the behaviour is the same on Linux if you have a SMB client running.
01:54:52 <wbeut> I'm not sure if the company will allow to their server via vpn on a linux machine but I might try later.
01:55:12 <Solonarv> I know that all the stack <blah> commands run things in an environment managed by stack, which has the relevant GHC (and tools) as well as your built package(s) in the PATH
01:55:21 <Solonarv> on windows it uses an msys variant to do this
01:57:06 <wbeut> If this is a bug, could it be easily fixed?
01:58:00 <wbeut> Since haskell platform's ghci doesn't have this problem, I guess it could be fixed..
02:00:24 <Solonarv> I have no idea how easily it could be fixed, I don't even use stack
02:00:28 <Solonarv> let alone contribute to it
02:03:24 <f-a> I am running in a weird issue with a parer combinator (megaparsec)
02:03:56 <f-a> while on windows, when running a parser on a literal String, everything is fine 
02:04:12 <f-a> but if I readfile that String, the parses chokes
02:05:02 <f-a> and this does happen only on Windows, not on Linux
02:05:24 <f-a> the offending character being a ®
02:05:30 <f-a> is this a encoding/locale issue?
02:05:44 <Solonarv> probably
02:06:18 <f-a> hello again Solonarv!
02:06:23 <Solonarv> o/
02:07:27 <f-a> I am trying to have this work on various platforms. What's the correct way of handling that?
02:10:00 <wbeut> On Windows, I'd convert the text using to utf-8 bytestring and then unicode using text-icu package and then apply the parser, convert the result back to the original encoding.
02:12:34 <dminuoso> f-a: Im a bit confused, is it the *same* file on both OS?
02:13:24 <f-a> dminuoso: I provided my friend with http://www.ariis.it/link/t/prova-0.1.0.0.tar.gz and asked him to unpack it and new-run it
02:13:48 <f-a> if untarring on win doesn't chance the file, yes, the same
02:14:20 <dminuoso> f-a: I'd rather expect the file being encoded differently for some reason, than megaparsec behaving differently between linux and windows.
02:15:29 <dminuoso> f-a: Can you use chardet/uchardet/file/enca/etc. to detect the file encodings of both files?
02:16:01 <f-a> f@x60s:/tmp/prova-0.1.0.0$ chardet prova.txt
02:16:01 <f-a> prova.txt: utf-8 with confidence 0.87625
02:16:19 <f-a> on my machine, do you happen to know what do I have to run on the windows one?
02:16:37 <dminuoso> f-a: Id just transfer the windows file
02:16:50 <dminuoso> f-a: Though you could use chardet on windows as well, since its just a Python program.
02:17:27 <maerwald> what lens will be created for data Foo = Foo { foo :: a }? As in: without underscore and without abbreviated fields
02:17:34 <dminuoso> f-a: Windows applications have a tendency to still use ISO-8859 for encoding.
02:18:19 <maerwald> it seems to compile, but I have no idea what I just got. Documentation of makeLenses also doesn't tell me
02:18:19 <Solonarv> maerwald: why not just find out using -ddump-splices ?
02:18:22 <dminuoso> f-a: So it would perfectly explain why your application chokes on windows-generated files.
02:18:42 <Solonarv> -ddump-splices will dump all TH-generated code, so you can see what t's doing
02:18:42 <f-a> dminuoso: by generated you mean "uncompressed on"?
02:18:59 <dminuoso> f-a: Oh I misunderstood then. That's interesting.
02:19:56 <dminuoso> f-a: https://www.stackage.org/haddock/lts-7.14/base-4.9.0.0/System-IO.html#g:23
02:20:01 <dminuoso> f-a: There we go. It's all documented. :)
02:23:33 <f-a> dminuoso: many thanks. So I suppose that means if I use latin-1 on where-I-write-the-program them I should be fine, right?
02:23:49 <Solonarv> % writeFile "LensSplice.hs" "module LensSplice where { import Control.Lens.TH; data Foo a = Foo { foo :: a}; makeLenses ''Foo }"
02:23:49 <yahb> Solonarv: 
02:24:09 <Solonarv> %% :! ghc -XTemplateHaskell LensSplice.hs -ddump-splices
02:24:11 <yahb> Solonarv: http://qp.mniip.com/y/9
02:24:29 <Solonarv> aw, it doesn't work :/
02:24:34 <dminuoso> f-a: Right.
02:24:44 <dminuoso> f-a: Well, assuming that latin-1 is the encoding that your system resolves to.
02:25:44 <dminuoso> f-a: If you read carefully, then it defaults to whatever localeEncoding produces, *unless* its an unsupported code page - then it defaults to latin-1
02:26:16 <trcc> Something I find myself having this data structure: x :: String, y :: String, z:: String and then I begin loading stuff, and I have all these steps: x :: LoadedX, y: String, z: String, then x:: LoadedX, y: LoadedY, z: string. and finally  x:: LoadedX, y: LoadedY, z: LoadedZ. Is there a pattern for this: Or should I create a product type, i.e. x :: XType, where data XType = String || LoadedX?
02:26:38 <dminuoso> If only text files were a bit more formalized to include encoding information..
02:27:02 <Solonarv> a-ha, it works in ghci too
02:27:13 <Solonarv> % data Foo a = Foo { foo :: a }
02:27:13 <yahb> Solonarv: 
02:27:23 <Solonarv> % :set -XTemplateHaskell -ddump-splices
02:27:23 <yahb> Solonarv: 
02:27:56 <Solonarv> %% data Pls; $( makeLenses ''Foo ) -- maerwald
02:27:56 <yahb> Solonarv: http://qp.mniip.com/y/10
02:28:02 <dminuoso> trcc: Can you show us a bit more context perhaps?
02:28:21 <Solonarv> ...huh, no output; that seems wrong
02:28:36 <dminuoso> % data Pls; $( makeLenses ''Foo ) -- maerwald
02:28:36 <yahb> dminuoso: <interactive>:219:14-29: Splicing declarations makeLenses ''Foo ======>
02:28:45 <dminuoso> Mmm
02:29:12 <maerwald> dminuoso: I think it just does nothing, because it doesn't find fields with _
02:29:18 <dminuoso> trcc: By the way, `data XType = F String || XLoaded` is actually a sum type, or alternatively called a coproduct type.
02:29:35 <trcc> dminuoso: oh ye, wrote it wrong. I meant sum type. Even looked it up heh
02:29:38 <Solonarv> maerwald: a-ha! if you click through the Control.Lens.TH docs you eventually find out that makeLenses uses 'underscoreNoPrefixNamer', which says "..., and skips the field if it doesn't start with a _"
02:30:19 <trcc> dminuoso: I can try. X Y and Z are initially file paths to different configurations required by the application. These configurations are then parsed at different positions in the program, but always go together. That is why I end up with a new data structure every time I load one configuration. And it is a mess
02:30:20 <dminuoso> Though I guess semantically it contains a product type, where `F String` can be thought of as `() * String`
02:30:37 <trcc> i am not there in my thought process yet dminuoso :) Sum type is fine for me!!
02:31:37 <dminuoso> Actually strike that, Im making no sense.
02:32:56 <dminuoso> trcc: Well you could drag an `data Files = { fileX :: IORef (Maybe File); fileY :: IORef (Maybe File); fileZ :: IORef (Maybe File) }`, drag that data type around as a global environment and modify the parts when you load them?
02:34:00 <trcc> that is a possibility
02:34:22 <dminuoso> trcc: Or instead of `Maybe` perhaps through an intermediate `data FileS = NotLoaded FilePath | Loaded File`, and then `data Files = { fileX :: IORef FileS; fileY :: IORef FileS; fileZ :: IORef FilS }
02:35:55 <trcc> thank you for the input
02:37:34 <dminuoso> trcc: And then once everything is loaded you can transform it into `data LoadedFiles = LoadedFiles { fileX :: File;... }` if you want. 
02:39:00 <dminuoso> trcc: Or perhaps you carry the FilePath around permanently: data Files = { fi_path_x :: FilePath; fi_x_bytes :: IORef (Maybe ByteString); ... }`
02:39:12 <superlinux> free code by me to you guys.  https://pastebin.com/UaPi1g0u
02:39:36 <superlinux> just returning the favor to the haskell comunity
02:44:06 <Phyx-> f-a: You can use utf-8 fine as long as you set the encoding of the handle. if you're using an stdhandle you'll have to set the console's codePage for the process too.
02:45:17 <Phyx-> ghc will change to utf-8 on Windows soon as well, though initially opt-in through the new I/O manager.
02:47:52 <f-a> Phyx-: thanks, I hope notepad++ and other similar Win editor do the right thing® (i.e. don't modify the encoding)
02:48:20 <dminuoso> f-a: And what encoding do they pick?
02:48:41 <Phyx-> f-a: Notepad++ detects the encoding from the content of the file or the BOM. it should do fine
02:48:44 <f-a> dminuoso: I hope the one they guess from the file they just opened
02:48:50 <dminuoso> f-a: They cant, properly.
02:48:59 <dminuoso> It's brittle.
02:49:19 <dminuoso> If we had a file format that contained file encoding that was widely supported we wouldn't have this mess.
02:50:28 <Phyx-> you want it not to guess include a BOM, if you don't it'll guess. but I haven't found many cases where it guessed wrong
03:03:17 <Reisen> For reading a potentially unavailable numeric environment variable, Is there a more idiomatic/less round about way of writing: fromMaybe 0 . (>>= readMaybe) <$> lookupEnv "NUMERIC_ENV_VAR"
03:09:08 <phadej> I haven't found considerably better ad-hoc way
03:09:37 <phadej> I did wrote a small lib to parse env variables in general, which makes that (and other) cases nicer; but that's a library :)
03:13:32 <Unhammer> I have a space leak: fs <- filesOfDir path; ps <- mapM parseXMLFile fs
03:13:54 <Unhammer> since fs might contain duplicates, it seems like ghc retains 'parseXMLFile f' for every f in fs
03:14:04 <Unhammer> until it's done with all files
03:14:38 <Unhammer> fs does not contain duplicates
03:15:23 <Unhammer> and in fact, the result of 'parseXMLFile f' is quite small (in my test case, it is just 'Left "meh"')
03:16:19 <Unhammer> but ghc doesn't just retain the result of parseXMLFile, it seems to store all the intermediate stuff that runConduitRes goes through for some reason
03:16:42 <Unhammer> if I explicitly do let files=["/tmp/f.xml"], the space leak is gone
03:17:59 <Unhammer> if I let files=["/tmp/f.xml", "/tmp/f.xml"], the memory usage looks like ╱̅̅
03:18:47 <Unhammer> How do I tell ghc that there's no point in memoizing 'parseXMLFile f', I know that files is a deduplicated list?
03:19:07 <Unhammer> s/files/fs
03:41:31 <Reisen> phadej, ooh, is that published by any chance?
03:45:42 <phadej> Reisen: no, it probably wont: but it's on github https://github.com/futurice/haskell-mega-repo/tree/master/env-config
05:08:39 <restrictedchoice> crossposted from #purescript -- i have a general FP question - i’m writing an app the requires building some state at boot. doing so involves some side effects. it feels weird to me to have all of this wiring code in the `State` module directly in a `new` function or something. what do most folks do here?
05:14:27 <jgt> I can't speak for most folks, but I do effectful stuff when my application boots
05:14:39 <jgt> I *also* pass flags into basically all of my applications
05:15:03 <jgt> true in my case of both Haskell and Elm projects
05:15:42 <restrictedchoice> jgt: so do you do these effects directly in main and then pass the results to pure functions downstream?
05:15:48 <restrictedchoice> or do you have a module dedicated to this "wiring"?
05:30:31 <jgt> restrictedchoice: it really depends on the application, but generally I'm happy to stick everything in one big function, in one big file, first
05:31:42 <jgt> since the compiler is so good at the kind of refactorings you would typically want to subsequently do, it doesn't make sense to try and architect stuff up front
05:34:23 <jgt> I mean… this stuff has to live _somewhere_
05:56:38 <reibrtn> In Rust all values are stack allocated by default. Values can be boxed (allocated in the heap) by creating a Box<T>. Does this mean Haskell's values are boxed and thus heap based because we have to use UNPACK otherwise?
05:58:14 <ski> i think "boxed" doesn't mean the same in GHC, as `Box' in Rust
05:58:53 <ski> boxing involves having an extra indirection. not having that doesn't mean you're stack allocated
06:00:56 <reibrtn> Right. I'm confused of the same terms meaning different, used in these two languages. 
06:01:29 <reibrtn> Thanks.
06:06:17 <reibrtn> Maybe I need to completely understand exactly how these terms are defined in Rust first, and then do the same for Haskell.
06:12:42 <superlinux> ski, hello. I finished the function num2txt
06:17:56 <ski> superlinux : i see you didn't accept many of my suggestions
06:18:19 <superlinux> ski, yes I did
06:18:26 <superlinux> I fixed the div
06:18:47 <superlinux> but i stayed on the same each 3 numbers pattern
06:19:52 <superlinux> ski, try it.. here : https://pastebin.com/32zcYm6w
06:21:02 <superlinux> I even found more special cases like in the number 1000000020 . many zeros will show Zero Million and Zero Thousand. so I omit them
06:21:30 <ski> you didn't remove the redundant brackets
06:21:49 <ski> and you didn't change the ordering in `each3digits'
06:22:24 <ski> and instead of matching on `"And Zero"', i think it'd probably be better to not generate that in the first place
06:23:02 <Maxdamantus> afaik, "boxed" basically does mean the same thing in Rust and GHC.
06:23:22 <superlinux> ski, but you will get a 3 digit part that will be zero
06:23:23 <Maxdamantus> that is, it's a pointer to something in the heap.
06:24:16 <superlinux> all 3 digits will be zeros
06:24:27 <superlinux> anyway.. it works.
06:25:15 <Maxdamantus> note though that the objects in the heap still store any values.
06:26:38 <Maxdamantus> so a struct value can be stored in an object pointed to by a `Boxed`, and the `Boxed` values can obviously be stored in the heap or in the stack.
06:27:45 <superlinux> but anyway.. this shows I am not bad in Haskell
06:28:08 <superlinux> like I can say I passed haskell level 101 
06:28:53 <ski> Maxdamantus : yea, but then it wouldn't mean that the pointer necessarily lives on the stack .. which was what it sounded that reibrtn was describing
06:29:28 <ski> Maxdamantus : *nod*
06:30:21 <ski> superlinux : "it works" may not be enough. it ought to be elegant, well-balanced, each thing in its proper place
06:31:21 <ski> (striving for that will help with modularity, refactoring, analysis, possibly also composability)
06:42:50 <reibrtn> Maybe I was confused of the definitions boxed/unboxed/heap/stack/reference/value all mixed up in my head.
06:47:11 <gentauro> how do you go from: `[ Just 42, Just 100 ]` to `Just [ 42, 100 ]`?
06:47:21 <gentauro> any fancy operator?
06:48:00 <jgt> > traverse id [ Just 42, Just 100 ]
06:48:02 <lambdabot>  Just [42,100]
06:48:05 <int-e> sequence? (what should [Just 32, Nothing] do?)
06:48:07 <jgt> yeeeaaaahhhhh
06:48:52 <int-e> :t Just . catMaybes -- also plausible
06:48:54 <lambdabot> [Maybe a] -> Maybe [a]
06:51:20 <gentauro> jgt: and we have a winner :)
06:51:36 * jgt ಠ_ರೃ
06:53:30 <c_wraith> just...  use sequence instead of traverse id.  :)
06:54:33 <gentauro> % :t sequence
06:54:33 <yahb> gentauro: forall {t :: Type -> Type} {m :: Type -> Type} {a}. (Traversable t, Monad m) => t (m a) -> m (t a)
06:57:23 <c_wraith> @src sequence
06:57:23 <lambdabot> sequence []     = return []
06:57:24 <lambdabot> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
06:57:24 <lambdabot> --OR
06:57:24 <lambdabot> sequence xs = foldr (liftM2 (:)) (return []) xs
06:57:31 <c_wraith> oops, wrong sequence. :)
06:57:44 <c_wraith> In any case, the default implementation of sequence is literally traverse id
06:59:16 <gentauro> c_wraith: you are right as well :)
06:59:37 <c_wraith> int-e mentioned it first.  It was just easy to overlook, so I echoed it
07:00:12 <gentauro> c_wraith: oh, I just saw the last message with `Just . catMaybes ...` and though "meh"
07:00:53 <jgt> > sequence [ Just 1, Just 2 ]
07:00:56 <lambdabot>  Just [1,2]
07:01:13 <jgt> > Just . catMaybes $ [ Just 1, Just 2 ]
07:01:15 <lambdabot>  Just [1,2]
07:01:18 <int-e> gentauro: that was because you didn't specify what you wanted to happen in the presence of Nothings
07:01:24 <jgt> > sequence [ Nothing ]
07:01:27 <lambdabot>  Nothing
07:01:35 <jgt> > Just . catMaybes $ [ Nothing ]
07:01:37 <lambdabot>  Just []
07:02:51 <gentauro> traverse id [ Nothing ]
07:02:57 <gentauro> > traverse id [ Nothing ]
07:02:59 <lambdabot>  Nothing
07:03:25 <gentauro> int-e: Nothing is fine ;)
07:03:29 <gentauro> so `sequence` it is
07:11:20 <byorgey> const (Just [ 42, 100 ])  also works ;-)
07:12:38 <libertyprime> i wonder if haskell will be more lifechanging than emacs
07:15:35 <tdammers> that depends, but my completely uneducated guess is "yes, it will"
07:16:19 <royal_screwup21> I'm trying to determine a fixed point for the factorial function: `while (x!=1)  { y = y *x; x = x -1; }`
07:16:43 <royal_screwup21> am I right in thinking that `g s = s[x->1, y -> 1] for all (s x)` would be a valid fixed point? 
07:16:51 <royal_screwup21> for more context: https://cs.stackexchange.com/questions/107154/fixed-points-of-factorial-function
07:22:41 <libertyprime> good because im going all-in with haskell. its going to be fun
07:24:09 <tabaqui> cannot understand this notation ([x -> 1, y -> 1])
07:24:47 <royal_screwup21> tabaqui s[x->1, y -> 1] means  the state where x =1, and y =1
07:24:51 <tabaqui> for me personally, very helpful was to inherit *any* factorial with non-typed lambda calculus
07:25:10 <tabaqui> like f n = n * (f (n -1))
07:25:52 <tabaqui> err, forgot :)
07:25:57 <tabaqui> give a sec :)
07:26:41 <tabaqui> fact n = (\f -> n * (f (n - 1))) fact
07:26:53 <tabaqui> so fact = fix (\f n -> n * (f (n - 1)))
07:27:18 <tabaqui> (I avoid break case to simplify)
07:30:05 <tabaqui> yeah, great
07:30:37 <tabaqui> so if you see a recursive call, then try to move it outside the brackets and pass as an argument
07:31:11 <tabaqui> like instead of "fact = \n -> if n == 0 then 1 else (n * fact (n - 1))"
07:31:28 <royal_screwup21> hmm I see 
07:31:52 <tabaqui> moving fact outside gives us: fact = (\f n -> if n == o then 1 else (n * f (n - 1))) f"
07:31:59 <tabaqui> * moving fact outside gives us: fact = (\f n -> if n == o then 1 else (n * f (n - 1))) fact"
07:32:05 <tabaqui> and call fix here
07:32:18 <tabaqui> s/o/0 :)
08:51:34 <bollu> buildTestOutput :: (?colors :: Bool) => OptionSet -> TestTree -> TestOutput 
08:51:37 <bollu> what is the ?colors thing?
08:52:49 <Taneb> bollu: it's an "Implicit Argument"
08:53:11 <Taneb> *Implicit Parameter
08:53:14 <bollu> Taneb oh? this I presume? https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#implicit-parameters
08:53:17 <bollu> Taneb thanks :) 
08:53:29 <Taneb> Yeah, that
08:53:30 <Taneb> :)
08:54:19 <bollu> oh my god, that is _so cool_
08:54:23 <bollu> I had no idea haskell ahad this
08:54:24 <bollu> had*
08:54:35 <Taneb> They can be a bit weird in practise
08:54:49 <Solonarv> yeah
08:55:37 <bollu> OK no, I don't understand
08:56:17 <bollu> so, it's like, a .. typeclass without the typeclass?
08:56:29 <bollu> It's some kind of "statically scoped dynamically scoped value?"
08:56:30 <bollu> WTF
08:58:33 <Solonarv> just put down the GHC manual and step away slowly
08:58:36 <bollu> What are some "legit" uses of this
08:58:49 <bollu> I've seen Tasty using this, which was where I ran across it
08:59:06 <Solonarv> don't come back for it and you'll be safe, might want to sprinkle some holy water though
09:02:07 <bollu> :) Well, thanks for the pointer. 
10:06:40 <jle`> bollu: i use it to pass around global configuration to my app
10:06:50 <jle`> bollu: it's...not uncontroversial :)
10:06:53 <bollu> jle` Like?
10:06:57 <bollu> jle` link*
10:06:59 <bollu> :) 
10:07:00 <jle`> like, host domain/url/etc.
10:07:17 <jle`> my source: https://github.com/mstksg/inCode
10:07:29 <jle`> it's actually a static site but yeah, it needs all that configuration stuff
10:08:12 <jle`> for example here is me using ImplicitArguments to render my home page: https://github.com/mstksg/inCode/blob/master/src/Blog/View/Home.hs#L37
10:08:51 <jle`> * ImplicitParams
10:09:08 <bollu> jle` thanks, that's a useful data point.
10:09:37 <jle`> fair disclosure, it's a controversial extension
10:09:54 <jle`> it's one of the many dependency injection options we have in haskell
10:10:20 <jle`> main competitors are normal explicit functions (Reader), ReaderT, reflections, etc.
10:10:35 <jle`> there are pro's and con's of each
10:10:51 <jle`> hm, actually reflections might have equal feature parity to implicitparams now that we have -XTypeApplications ...
10:11:31 <jle`> the main "pro" of ImplicitParams for me was that it doesn't change anything in the return type, unlike Reader/ReaderT/reflections of olde
10:11:55 <jle`> but in the world of -XAmbiguousTypes + -XTypeApplications we can now use reflections-style configuration passing without changing the return type
10:12:27 <jle`> also it gets around the main drawback of ImplicitParams, which is that you can't use them in typeclass instances.  (you can use reflections-style environments in typeclass insatnces)
10:13:34 <jle`> maybe there's no point anymore
10:14:47 <jle`> time for a rewrite lol
10:16:41 * ski . o O ( "Fun with Linear Implicit Parameters" by Thomas Jäger (TheHunter) in 2005-05 at <https://wiki.haskell.org/The_Monad.Reader/Issue2/FunWithLinearImplicitParameters> )
10:16:53 <gentauro> just changed my laptop and forgot to copy/pasta my bookmarks. What's the `paste.bin` service Haskellers use?
10:17:28 <jle`> these days we just use gist
10:17:33 <Solonarv> gentauro: it used to be lpaste, but that doesn't exist anymore
10:17:47 <jle`> ever since lpaste got killed by spammers
10:18:01 <gentauro> :'(
10:18:22 <ski> implicit parameters is more or less dynamic scoping ("special" or "fluid" variables, in the Lisps)
10:18:29 <gentauro> I think I remember using another service after lpaste ...
10:18:42 <Solonarv> gist is fine, or really anything - just try to avoid bloated sites like pastebin or I-need-5MB-of-javascript-to-even-display-anything
10:18:57 <gentauro> Solonarv: so GitHub :P
10:19:01 * Solonarv looks pointedly at repl.it
10:19:42 * ski . o O ( <paste.debian.net> )
10:19:50 * ski misses <paste.lisp.org>
10:20:18 <ski> (iirc, it's still up, with old pastes available. but you can't make new ones, or annotate old ones)
10:20:30 <Solonarv> well, github gist actually seems to load very fast, and works well even with JS completely disabled
10:20:55 <Solonarv> (I didn't know that last part, but I just checked)
10:21:37 <ski> (it's a bit annoying to have to hunt for a raw link, or worse, have to manually change the URL, in order to be able to see the paste)
10:22:54 <ski> bollu : "statically scoped dynamically scoped value" -- dynamically scoped, more or less. but statically type-checked
10:42:16 <reygoch> Is there some nice way to get image width and height by providing FilePath to that image? Only thing I've found is functions from JuicyPixel library, but that is a bit heavy dependency for what I need to do.
10:50:55 <DigitalKiwi> is there an option (or way to do something) that is sort of the opposite of -ddump-minimal-imports
10:52:03 <dmwit> DigitalKiwi: echo :browse My.Module.Name | ghci ?
10:52:35 <dmwit> Or bhoogle for a more user-friendly experience. Type in a module name, get the haddocks for it.
10:52:50 <dmwit> (Or maybe I've misunderstood what you mean by reverse.)
10:54:29 <gaze___> anyone here an expert with the ad library?
10:55:11 <cocreature> gaze___: you’ll get better answers if you ask your actual question instead :)
10:55:52 <qwebirc44824> hi
10:56:16 <qwebirc44824> Following commands are required, but missing, please install:  xz
10:56:22 <qwebirc44824> got this error
10:56:28 <gaze___> ah you're right. Rookie mistake. I'm thinking of writing a package for optimal control of PDEs. I want to write in my equations in a nice symbolic form and to be able to spit out the derivatives in a similar symbolic form
10:56:46 <glguy> qwebirc44824: Hi
10:56:50 <dmwit> qwebirc44824: What action did you take that caused that error?
10:57:03 <gaze___> I see sort of... a number of different representations of derivatives
10:57:09 <qwebirc44824> just tried the Mac OS X command to install
10:57:09 <gaze___> what might be a good place to start?
10:57:15 <glguy> qwebirc44824: You've been joining and asking that question and then immediately quitting lots of times
10:57:17 <qwebirc44824> like curl .... link ...
10:57:24 <glguy> You have to give people time to see your question
10:57:44 <dmwit> qwebirc44824: What was the exact command? You can use an online pastebin if the command is long, and post a link here.
10:57:57 <glguy> He's trying the ghcup bootstrap script
10:58:24 <glguy> I get xz from: brew install xz
10:59:16 <gaze___> I'm relatively sure I want reverse mode... so it seems my options are Mode.Reverse and Mode.Kahn
10:59:33 <DigitalKiwi> dmwit: https://gist.github.com/Kiwi/c3d02b3addc3d28649668aadef284aab
11:00:04 <gaze___> I'm curious what the relative advantages are if my end target is some generated C++ code
11:01:02 <DigitalKiwi> probably just easy enough to do it by hand *shrug*
11:01:16 <dmwit> DigitalKiwi: Ah. I don't know of a tool to do that.
11:01:28 <dmwit> Seems like it could be a handy thing to have around.
11:02:27 <DigitalKiwi> edwardk said hvr has some tool that he mentioned when he told me about the -ddump-minimal-imports but i don't know the tool to see if it helps
11:03:54 <cocreature> gaze___: reverse mode is usually a good option but the APIs should be sufficiently similar that I would just benchmark. However, note that ad isn’t really targeted at symbolic differentiation. It’s for automatic differentiation.
11:05:25 <gaze___> ohhh I see
11:05:57 <gaze___> there's not a good way to spit out code to actually implement the jacobian?
11:06:19 <gaze___> I think that's kinda what I want
11:09:52 <gaze___> there's still quite a bit I'm confused about with automatic differentiation... what's sorta... the thing that links symbolic and automatic differentation?
11:11:25 <jle`> gaze___: the module Numeric.AD represents the "best" choice for different types of functions
11:11:29 <jle`> gaze___: that's a good question, though :)
11:12:03 <jle`> symbolic differentiation is manipulating your expression algebraically/symbolically to compute derivatives
11:12:14 <jle`> if you're familiar with haskell, it's like manipulating an ADT of an expression
11:12:21 <gaze___> sure. that makes sense
11:12:45 <jle`> gaze___: automatic differentiation is different -- it "hijacks" the process of performing normal numeric operations to compute the derivative numerically as a "side-effect" 
11:13:13 <jle`> so in the process of computing, say, 1 + 2*x, you can also compute the derivative w.r.t. x at the same time, numerically
11:13:16 <gaze___> so forward mode makes quite a lot of sense to me... the idea of making an extension field with epsilon is fine by me
11:13:37 <jle`> yeah, forward mode basically computes the derivative 'alongside' the actual value
11:13:44 <jle`> so there is no manipulation of any sort of expression AST
11:13:52 <gaze___> but reverse is a bit weird for me... it feels just like symbolic differentiation but... not
11:13:54 <jle`> it's just computed, numerically, alongside the normal operations
11:14:00 <gaze___> sure.
11:14:10 <jle`> well, again, reverse mode doesn't have any actual AST that is being manipulated
11:14:26 <jle`> if you look in the algorithm or code, there is no pattern matching on any AST structure
11:14:47 <gaze___> oh wait I see now.
11:14:54 <jle`> so by that standard alone, it's not symbolic differentiation
11:15:06 <gaze___> the wengert tape isn't of the derivatives... it's just a representation of the actual expressions
11:15:17 <gaze___> and then you sorta fill it in as the dependencies are satisfied in reverse
11:15:19 <jle`> well, the wengert tape actually contains the numerical derivatives
11:15:33 <jle`> so, it contains numberical values, just like the epsilon extension
11:16:06 <jle`> on a high level you can say that the 'advantage' is that it doesn't duplicate computations of derivatives, and accumulates them in one central location (the mutable tape)
11:16:11 <gaze___> yes but it never holds symbolic derivatives, right?
11:16:13 <jle`> instead of alongside every single value
11:16:28 <jle`> gaze___: yeah, it holds the numerical derivatives. it can't be populated until you provide the inpuit
11:16:37 <gaze___> got it ok.
11:16:45 <gaze___> the wengert tape just feels like SSA form
11:16:49 <gaze___> is that right?
11:17:52 <gaze___> also, is the wengert tape ever written over higher objects?
11:17:54 <gaze___> like idk... wengert tape of tensors
11:18:08 <gaze___> or do you usually lower all the way to real numbers to write the tape
11:18:34 <jle`> hm, i'm not sure how to answer precisely
11:18:40 <gaze___> I should probably just read the documentation for tensorflow
11:18:40 <jle`> one thing that really helped out for me was to do it "by hand"
11:18:55 <jle`> my 'backprop' library actually does reverse mode AD with a wengert tape on tensors and stuff
11:19:28 <jle`> so, make a simple expression (like 2x + 7xy) and try to evaluate it using reverse mode AD by hand, keeping track of the manual wengert tape
11:19:32 <jle`> on paper and pencil
11:20:05 <jle`> doing that helped me see what actually goes on for the wengert tape
11:20:14 <jle`> and it's just *numbers*, like 1, 7, 8, etc.
11:20:16 <jle`> not variables
11:20:42 <gaze___> hmm okay.
11:22:18 <jle`> the exports of Numeric.AD are actually also pretty useful for getting a high level look at pros/cons of each in different circumstance
11:22:36 <gaze___> gotcha. Thanks!
11:22:56 <jle`> for example, 'diff' takes and differentiates (a -> a) functions, single input, single output
11:23:09 <jle`> and it uses forward mode, which suggests that single-input, single-output, forward mode is the best choice usually
11:23:39 <jle`> 'grad' differentiates a ([a] -> [a]), essentially, which is multi-input, multi-output
11:23:51 <jle`> which suggests that for multi input, multi output, reverse mode is the best choice
11:24:16 <jle`> er sorry, it differentiates a ([a] -> a), which is multi-input, single-output
11:24:22 <jle`> so for multi-input, single-output, reverse mode is the best choice
11:25:01 <jle`> so the implication is that reverse-mode has its gain when you have more than one input
11:25:15 <jle`> (which is why neural network training uses reverse-mode: there are often billions of inputs)
11:25:35 <gaze___> yeah I ultimately have about 100 inputs and 1 output.
11:27:28 <jle`> you *can* use forward mode for multiple inputs and multiple outputs (that's what grad from Numeric.AD.Mode.Forward does). but you find that in doing it, you basically compute each input gradient component "from scratch", in isolation/parallel
11:27:44 <jle`> for reverse mode, the input gradients are computed together, at the same time
11:28:22 <jle`> gaze___: the "SSA" property you might be thinking of might not be the nodes of the wengert tape, but the "edges", the connectiosn between each tape node
11:28:51 <jle`> they tell you how the numerical value of each tape node affects the numerical value of previous tape nodes
11:31:31 <jle`> gaze___: feel free to check out https://github.com/mstksg/backprop, although like with the ad library, it relies on some controller hacks to get an explicit dependency graph
11:32:43 <jle`> and there are some differences with tensorflow and other AD libraries too; backprop makes the design decision to produce wengert tapes and dependency graphs dynamically, re-constructing them for every input given to the functions
11:32:57 <jle`> whereas i believe tensorflow might compute the dependency graph statically and re-use it for every new input
11:37:12 <talqu> What are the downsides when defining a function inside a function(via let) versus at the file level? Is having it at file level more effecient at runtime? 
11:39:24 <zachk> talqu, if you define a function inside a function, you can capture arguments passed in inside the inner function
11:39:25 <geekosaur> the main downside is finding you want it in some other scope later
11:46:14 <oo_miguel> I just found out about haskdogs (simliar to hasktags but taking dependancies into account). But I still have problems to figure out which external library some particular types or functions refer to, in case the name is present in multiple libraries throughout the complete project. Any suggestions how to solve this quesion?
11:49:18 <talqu> zachk, geekosaur if i call a function A in loop, and A defines inside a function B, will it be much less efficient than defining B at file level? I don't use B for closure reason, neither for locking the scope of it. Im just curious of performace at runtime in those cases
11:50:19 <geekosaur> shouldn't be a difference
11:50:23 <zachk> talqu, honestly I am note sure about the performance, my guess is it might not matter much 
11:52:09 <talqu> thanks
11:54:07 <earnestjfk> Any hints or next steps on how to debug this build problem? https://gist.githubusercontent.com/earnestjfk/d10fa0a8362353b5dd13b40aa66975c2/raw/88278ae84181477141f42bcf7611e927c6043fef/parrot-stack-build-powershell-parallels-verbose
11:58:28 <cocreature> earnestjfk: I guess parrot.cabal does exist?
11:59:15 <cocreature> oh that only appears to be a warning not the error
12:00:59 <cocreature> earnestjfk: I would go with "stack clean --full" as a first attempt, if that doesn’t help try switching to a snapshot with ghc 8.6.5 just to make sure that this is not the issue (8.6.4 had various windows-specific problems)
12:01:50 <earnestjfk> I will try those steps and report back. Thanks! I'm also going to try inside VirtualBox instead of Parallels since virtualization can sometimes make things wonky.
12:02:43 <IsProp> Hello all.
12:03:00 <cocreature> earnestjfk: if you’re running in a VM maybe it’s also something like running out of memory?
12:03:24 <cocreature> Despite being the person responsible for having ported our Haskell codebase at work to Windows, Haskell on Windows is still a mystery to me :)
12:05:00 <IsProp> Does anyone have any resources for implementing a non-deterministic finite automaton using tail recursion?
12:05:06 <earnestjfk> I don't think it's a lack of resources—Parallels has a resource configuration slider that's set to "no limit"
12:05:44 <IsProp> In an imperative language I would simply use computed goto and forgo the stack entirely, but I wanted to try to work in an entirely functional paradigm.
12:05:52 <zachk> IsProp, use the list monad and use accumulating variables for state maybe in a recursive function? 
12:05:56 <jle`> IsProp: "using tail recursion" might not be something that makes sense in Haskell, at least the way it does in imperative languages
12:06:22 <jle`> you can just look at ways to implement non-deterministic finite automata
12:06:56 <IsProp> Why would anyone air quote tail recursion? It's a fundamental concept to doing loops in a purely functional manner.
12:07:06 <IsProp> Lol
12:07:07 <c_wraith> it's not in Haskell
12:07:21 <c_wraith> productive corecursion is the core idea in Haskell.
12:07:52 <IsProp> Interesting, hmm.
12:08:23 <IsProp> So how would corecursion help drive an NFA?
12:08:23 <jle`> IsProp: in what sense is tail recursion a fundamental concept to doing loops in a purely functional manner?
12:08:54 <IsProp> jle`, Because is it dual to iteration?
12:08:56 <jle`> i would say that recursion may be considered a fundamental concept to doing loops in a purely functional manner
12:09:01 <sclv> tail recursion often makes sense in haskell too imho
12:09:28 <jle`> it does have some meaning, but it is not the same as it is in imperative languages
12:09:46 <sclv> its not imperative vs declarative but lazy vs strict
12:09:47 <IsProp> It's not pedantic to qualify the type of recursion when you understand doing a 1M orbit recursion without tail optimization will smash the stack.
12:10:12 <jle`> IsProp: right, the difference only makes sense when tail optimization is relevant
12:10:31 <IsProp> For a non-deterministic finite automaton it is highly relevant.
12:10:31 <jle`> if you take away tail optimization, what's the difference?
12:10:48 <jle`> imagine you have a language with no tail optimization
12:11:02 <IsProp> Because there may be situations where the recursive call can not be optimized out and you end up with an implicit bug in the implementation of your state machine.
12:11:28 <jle`> what if no optimization happens in any case?
12:12:34 <IsProp> Either way, I am curious about how one would drive something as complex as an NFA using what someone suggested earlier: corecursion.
12:13:09 <jle`> TCO is used in imperative languages in order to provide constant-space recursion in special cases
12:13:16 <jle`> but haskell already has constant-space recursion, without TCO
12:13:54 <IsProp> Is that because of the way it handles the state monad?
12:14:05 <jle`> no, it's because of the way evaluation is performed in haskell
12:14:12 <jle`> the significant difference is that haskell does not use a call stack
12:14:33 <jle`> instead, evaluation is basically (lazy) tree reduction
12:14:36 <IsProp> Right. Thuks.
12:14:38 <IsProp> Thunks*
12:15:25 <IsProp> I want to think along these lines a moment, then.
12:15:34 <zincy> Is there a version of flip at the type level which flips the order of type parameters for type constructors?
12:15:44 <jle`> IsProp: in any case i don't mean to detract you from your final goal
12:15:53 <jle`> IsProp: just trying to broaden your search beyond just tco-based methods :)
12:15:56 <zincy> I guess that would be a type family that could do that even if it is silly
12:16:07 <jle`> zincy: a few libraries offer that as a newtype wrapper
12:16:16 <jle`> newtype Flip f a b = Flip { getFlip :: f b a }
12:16:28 <zincy> ah cool
12:16:48 <jle`> you probably want a newtype instead of a type family, since the main purpose is for compatibility with typeclass instances
12:16:58 <jle`> *compatiblity with typeclasses, to be used as instances
12:17:12 <IsProp> jle`: Well yes, you have broadened my view now, actually. I just don't have an intuition on how corecursion might apply to a non-deterministic state machine. I am curious to think of it in this way, though.
12:17:32 <zincy> jle: Thanks
12:18:09 <IsProp> jle`: Real world case: building a regex engine from scratch.
12:18:33 <IsProp> I read about the original "NFA Machines" concept from Thompson.
12:18:57 <IsProp> But I prefer the simpler recursive backtracking approach and wanted to see about entailing this in a more functional style.
12:19:14 <jle`> IsProp: for some references, a lot of libraries (like machines, auto) "fake" NDFA's using functions and closures. but also a few regexp libraries program their own ndfa's from scratch with explicit lookup tables
12:20:39 <IsProp> Well I'm not looking to "linearize" the NFA to a DFA like awk and others do. Rather, I would like to think about entailing non-determinism in a monad and "driving" them recursively.
12:20:40 <jle`> and a lot of times people build implicit ndfa's with StateT s Maybe variants
12:21:33 <jle`> hm, well then if you aren't looking for an explicit transition representation, you can try out `StateT s Maybe` or `StateT s []`
12:21:42 <IsProp> And that driver concept has me thinking about the possible relationship to co-recursion, but I've never been able to wrap my head around what corecursion is trying to do. It seems very counter-intuitive, or just really obvious and I'm looking for something complex.
12:22:11 <jle`> with the ALternative instance, like <|>, it builds an implicit NDFA where the states are function pointers on the heap
12:22:41 <jle`> so a lot of people use them without ever thinking about NDFA's
12:22:56 <IsProp> This all sounds like it induces high memory pressure. One of the advantages to a lower level representation is that one can do this entirely on a pre-defined arrangement of memory.
12:23:17 <jle`> it's actually decently cheap because of sharing
12:23:30 <jle`> but you're right, you do loose some explicit control
12:24:04 <IsProp> I mean, it also got me thinking: I felt "bad" for using even goto and conditional jumps, as your nickname implies in Assembly.
12:25:02 <jle`> i think, the explicit arrangement of memory is not something you can get without explicit transition tables and state spaces
12:25:37 <jle`> but trading explicit state for abstract function pointers on the heap, you get a nice shift in thinking while still maintaining the same space. just non-contiguous
12:25:41 <IsProp> You can work within a pre-allocated amount that you must not exceed, but you must be willing to back out if you do reach that limit.
12:25:59 <jle`> it is, at least, a nice learning exercise
12:26:17 <IsProp> For all but the most pathological regexes, you will never reach the upper bound on even a reasonable allotment of a MIB or so.
12:26:23 <jle`> but yeah, you do'nt have that kind of control (explicit memory limitation) with StateT based methods
12:26:52 <IsProp> What are some of the properties that make you recommend StateT?
12:27:20 <jle`> particularly `StateT s Maybe` can be used to basically model an NDFA, and it's a common choice for beginners implementing parsers
12:27:47 <jle`> that's because its Alternative instance, with <|>, gives you backtracking
12:28:07 <IsProp> I feel like a contortionist when I try to fit my rote memorization parser writing LL, LR, etc, into a monad. Any advice?
12:28:08 <jle`> its Applicative instance, with *>, gives you state progression
12:28:57 <jle`> right, it is somewhat of a contortion situation, because most people don't explicitly use StateT s Maybe thinking they are building an NDFA
12:29:20 <jle`> it lends itself to a higher-level thinking, and the NDFA semantics are kind of obscured
12:29:32 <IsProp> jle`: Should I think of making a new type for each grammatical fragment? Are we talking multiple types for each monad that makes up the entire grammar?
12:30:06 <jle`> i actually recently wrote a post about translating a psuedo-regexp (without star) into StateT s Maybe's *> and <|>
12:30:08 <jle`> https://blog.jle.im/entry/free-alternative-regexp.html
12:30:33 <jle`> it's not quite a beginner haskell post (maybe intermediate), but maybe you can see how the translation works
12:31:00 <IsProp> What was the reasoning for not including repetition?
12:31:03 <jle`> IsProp: the trick in translating your nodes in an NDFA turn into functions, and not any explicit state type
12:31:52 <jle`> IsProp: mostly a structural issue with the Free Alternative implementation i was using; the blog post was chiefly a demonstration of that type
12:32:08 <jle`> using regexp/statet as an example usage
12:32:20 <jle`> but an alternative (heh) implementation could have let me handle star
12:32:32 <IsProp> I have been coding for some time and I've never seen anything as mind numbing as implementing a *proper* regex engine.
12:32:54 <IsProp> I would dare say it would make a killer interview question.
12:33:06 <jle`> well, the regexp-without-proper-star in that post is less than 10 lines of code :)
12:33:16 <jle`> in fact i posted it as a tweet
12:33:20 <IsProp> Oh I wasn't making a jab.
12:33:36 <jle`> oh yeah, i mean to say that to say that it actually isn't too mind-numbing
12:34:00 <jle`> the regexp engine in that post has a "fake" star, modeled with infinite (lazy) recursion
12:34:36 <jle`> that is, a* => |a|aa|aaa|aaaa|aaaaa, etc.
12:34:37 <IsProp> The mind numbing bit is recursive repetition of arbitrarily sub-expressions due to grouping.
12:35:16 <IsProp> Like (a*b*)*c
12:36:11 <IsProp> My first attempt was completely procedural, but I don't get to call it "functional" because it was extraordinarily impure.
12:36:27 <jle`> ah, well, one nice advantage is that using StateT, because our nodes are managed by the haskell heap, you get all of that "for free" :)
12:36:51 <jle`> IsProp: one recommendation i have for getting started with this is to try reading a beginner "monadic parsers in haskell" tutorial
12:37:10 <jle`> in reality, regexps are non-monadic. but understanding monadic parsers gives you a good handle to understanding non-monadic ones
12:37:29 <IsProp> How are they "non-monadic" and what do you mean by that?
12:37:44 <jle`> well, it won't tell you how to implement an explicit NDFA. but it tells you how all of this recursive backtracking stuff is handled in a nice/clean way in functional programming
12:38:20 <jle`> IsProp: roughtly monadic means context-sensitive, in the case of parsers
12:38:26 <IsProp> Backtracking is free in the sense that your function calls explore the state space as a simple breadth-first traversal.
12:38:59 <jle`> most tutorial implementations have depth-first backtracking iirc
12:39:04 <jle`> but i get your point
12:39:38 <IsProp> That's how you implement regex, though. It's not simple recursive descent like a context-free grammar.
12:39:49 <IsProp> It's a very specific point.
12:40:42 <jle`> hm, yes that's a good point; i forgot exactly how this distinction is handled
12:40:43 <IsProp> I would be interested in if you have a handy "best of" article for co-recursion.
12:41:23 <IsProp> I could search for it of course but I find that fans of the language tend to be highly curative.
12:41:37 <IsProp> I mean good at curating.
12:42:38 <jle`> hm, i do remember reading an article breaking corecursion down explicitly, but for the most part a lot of haskell posts talking about things like this sort of blend together the difference between corecursion and recursion
12:42:38 <IsProp> But I think there is a bit of double meaning even in my mistake. Hahah.
12:42:53 <koz_> IsProp: 'Curative' means 'healing'.
12:42:59 <koz_> Haskell cures, y'all. :P
12:43:03 <IsProp> koz_: Yes I am making jokes at my expense.
12:43:37 <IsProp> The implication is almost like paladins. Righteously healing the programming lands.
12:43:45 <IsProp> The scourge being state.
12:43:49 <IsProp> It just doesn't die!
12:43:58 <IsProp> (Being funny here.)
12:45:30 <IsProp> jle`: I have a related question about monads and it ties in with your name.
12:45:48 <jle`> we are the knights of mu :)
12:46:21 <IsProp> jle`: On my todo list is modeling a functor, applicative functor, and a monad in x86-64 NASM.
12:46:51 <IsProp> jle`: I wanted to know surely if someone has already written something like this up. I would like to read!
12:46:54 <jle`> that goal seems ill-defined
12:47:07 <jle`> unless you mean "modeling a polymorphic functor abstraction"
12:47:26 <jle`> modeling "a functor" is simple because you can just choose "a functor"...like Identity, and model that
12:47:35 <jle`> in which case, you're already done; since Identity a is a :)
12:47:41 <jle`> * 'Identity a' is 'a'
12:48:05 <IsProp> jle`: That doesn't capture the abstraction, no. So, yes, I mean the generalization.
12:48:13 <koz_> I would be curious how you would go about defining a polymorphic functor abstraction in something as abstraction-resistant as asm.
12:48:17 <koz_> Although C would do too.
12:48:40 <IsProp> I think you mean that it's abstraction universal.
12:48:44 <IsProp> It's too much abstraction.
12:48:52 <IsProp> In the sense that anything is what you want it to be.
12:49:06 <IsProp> And that's the source of all the hate.
12:49:15 <IsProp> Too dangerous.
12:49:28 <IsProp> The same is said of void*.
12:49:31 <jle`> i don't know if it's been done exactly, if it has i aven't seen it pop up in haskell news circles at least
12:49:53 <jle`> but it might be interesting :)
12:49:57 <IsProp> Well I would like to try it one day if I had time. I want to know these things in and out.
12:50:21 <jle`> the thing is that Functor itself cannot exist within ASM (or most languages, for that matter)
12:50:22 <IsProp> Things like a "closure" vanish under "reification" as a function + a structure.
12:50:29 <jle`> you can implement a functor abstraction
12:50:33 <c_wraith> IsProp, really, state is just fine. we just want you to be explicit about it instead of hiding it.
12:50:46 <jle`> but that abstraction cannot be represented as a concept within the language
12:50:54 <IsProp> True.
12:51:03 <IsProp> But it's about working with the *pattern*.
12:51:16 <IsProp> If the pattern is useful we use it and sometimes it's useful.
12:51:20 <jle`> in Haskell, Functor is actually a concept you can define within the language
12:51:27 <jle`> IsProp: yeah, the pattern is useful, and that's why it's *possible*
12:51:30 <IsProp> Of course, and within the type system.
12:51:34 <jle`> it's just going to be weird :)
12:51:44 <jle`> and also, the language doesn't help you use the pattern correctly
12:51:51 <jle`> like it does in haskell
12:52:00 <jle`> this is a flaw with functor/etc. abstractions in js/python, too
12:52:11 <dmwit> I mean, if you think of Functor's translation to dictionary-passing, non-typeclass System F, I could imagine having an ASM analog of it.
12:52:25 <jle`> in practice, it's pretty hard to use monad abstraction properly without the help that haskell's type system provides
12:52:26 <IsProp> But you have to realize that anything that isn't "first-class" in a language is not within the language. And almost all of the important things we all do is implement things in a language that lacks them as first-class citizens.
12:52:38 <dmwit> You'll need an ASM analog of closures first for it to be actually useful, but then it shouldn't be too hard.
12:52:47 <jle`> indeed. i'm not against modeling functor patterns in other languages
12:53:03 <jle`> just trying to shape your expectations of how it's all going to work out :)
12:53:31 <dmwit> IsProp: Are you familiar with the dictionary-passing implementation of typeclasses that GHC uses?
12:53:47 <IsProp> My only expectation is to penetrate the veil of obfuscation and see things as bits and bytes, as opposed to nouns.
12:54:05 <dmwit> (Or, if you've done a bunch of C/C++ stuff, then you can think of dictionary-passing as a sort of vtable-alike.)
12:54:09 <IsProp> dmwit: Smells like a vtable to me!
12:54:16 <dmwit> yes =)
12:54:29 <jle`> oh, i do know Bartosz Milewski has several posts about implementing a Functor and Monad abstraction in C++
12:54:40 <IsProp> C++ is "cheating" because of templates.
12:54:43 <IsProp> In this case.
12:55:25 <dmwit> Well. You're going to need some sort of uniform polymorphism most likely.
12:55:40 <dmwit> Or else a very restricted subcategory on which your functors act. =)
12:55:44 <IsProp> dmwit: There is one, but it's not type safe.
12:55:59 * dmwit nods agreeably
12:56:42 <IsProp> void* is "polymorphic" and even "higher kinded". Perhaps even towers of universes that would make Russel turn in the grave.
12:57:17 <dmwit> void* is not higher-kinded.
12:57:19 <IsProp> Russell, I'm sorry.
12:57:20 <dminuoso> IsProp: It's not really polymorphic.
12:57:26 * IsProp grins.
12:57:32 <dminuoso> IsProp: The reason for that is that you can't ruthlessly typepun in C++.
12:57:38 <IsProp> It's a trick question. It's not typed at all.
12:57:44 <dminuoso> IsProp: Sure it is.
12:57:53 <dminuoso> IsProp: void* is a type.
12:58:11 <IsProp> void* is probably a distant relative of falsum, or bottom.
12:58:25 <dmwit> noooooo
12:58:48 <jle`> void is actually a type that is not bottom (bottom in haskell isn't a type, anyway)
12:58:55 <dminuoso> IsProp: In C at least you can formally have objects of type void.. sort of.. :-p
12:59:05 <dminuoso> It does not hold true for C++ though.
12:59:23 <dmwit> I have occasionally been annoyed that I can't write `void foo() {} void bar() { return foo(); }`.
12:59:27 <IsProp> Yes this is why I say "void*" and not "void".
12:59:32 <dmwit> But that's just a language wart, not fundamental. =)
12:59:43 <jle`> er, hm, i do mean void* too
12:59:52 <dmwit> Anyway void* has got lots of good inhabitants, so it ain't falsum.
13:00:20 <dminuoso> And it's definitely not bottom either, since computations of type `void *` usually terminate.
13:00:29 <IsProp> I wish I were better so I could, from memory, just explain to you why void* is equivalent to falsum.
13:01:00 <IsProp> But you can't have something like void* that has any inhabitants in a proper type system.
13:01:08 <IsProp> It's a backdoor.
13:01:15 <dmwit> um
13:01:26 <dmwit> If you mean C's type system is not sound, well, yeah, we all know that.
13:01:29 <IsProp> I'm talking about C/C++'s void*.
13:01:39 <dminuoso> IsProp: Inhabitants is what excludes it from being falsum.
13:01:49 <dmwit> (Or what do you mean by "proper"?)
13:02:01 <dminuoso> IsProp: If you could produce a value of it, it would be equivalent to proving falsity.
13:02:06 <dminuoso> Which you cant do.
13:02:15 <dminuoso> So `void *` cant be falsum
13:02:41 <MarcelineVQ> you've overloaded 'it' just there I think
13:02:47 <dmwit> dminuoso: (I think you might have gotten turned around somewhere in that argument. It doesn't make sense to me, anyway.)
13:03:02 <dmwit> dminuoso: (Despite the fact that I agree with your conclusion.)
13:03:16 <dminuoso> dmwit: Uh yeah. Something went wrong there. :)
13:03:47 <IsProp> How this relates to monads in Assembly, however, is very interesting.
13:04:19 <dminuoso> IsProp: `void` itself is sort of like `()`, whereas `void *` is a sort of polymorphic pointer type that you can, according to some very bizarre rules, coerce into other pointer types.
13:04:24 <IsProp> If one makes a distinction between representation and interpretation, then you gain the tools to describe the problem.
13:04:57 <dminuoso> Oh ski would slap me now for calling it a "polymorphic pointer type". Perhaps a type schema might be more appropriate.
13:06:13 <LuggageMan> Hello
13:06:19 * dmwit waves vaguely
13:07:28 * dmwit waves goodbye, still feeling a bit vague
13:07:31 <jle`> there is an easy way to disprove that void* is falsum
13:07:36 <jle`> dmwit: you tried :)
13:08:13 <IsProp> If you made a type system that allowed void* it would be inhabtied by the empty type. You now have an inconsistent type system.
13:08:19 <dmwit> I think at this point it will not be useful to argue about whether void* is falsum until we have all agreed on the definition of falsum.
13:08:38 <Phyx-> cocreature: 8.6.4 didn't, that was 8.6.3 :)
13:08:41 <dmwit> Types are (generally) not inhabited by types. So that sentence doesn't make sense to me.
13:08:49 <IsProp> Falsum is the simplest type: it has no inhabitants.
13:09:08 <dminuoso> jle`: Let `x :: void *`, and assume `void *` to be falsum. If we can produce a program for `x`, we prove the proposition. Let `x = null` - since false propositions cannot be proven the assumption is incorrect.
13:09:08 <IsProp> Types of types are inhabited by types. Sometimes we call them "kinds".
13:09:13 <dminuoso> jle`: something along those lines?
13:09:40 <dmwit> (I also don't admit that "if you made a type system that allowed void*" then "'the empty type' is a well-defined phrase".)
13:10:05 <IsProp> I mean you're kinda off already by not accepting that types of types is a thing.
13:10:19 <IsProp> "[16:08] <dmwit> Types are (generally) not inhabited by types. So that sentence doesn't make sense to me.".
13:10:28 <jle`> isn't void* a type, and not a type of types?
13:10:32 <jle`> since inhabitants of void* are values
13:10:34 <IsProp> Dependently typed languages is the exemplar.
13:10:47 <dmwit> IsProp: Okay. Given that choice of terminology, which I think is pretty terrible, I don't admit that if you made a type system that allowed void*, then that type system must necessarily have void* as the type of any type.
13:11:08 <IsProp> I am using the standard terminology.
13:11:13 <dminuoso> IsProp: I think one main issue is conflating the `C/C++` usage of the word `void` with the Haskell name of the type `Void`
13:11:35 <dminuoso> IsProp: C/C++ uses `void` but means the unit type. Haskell uses `Void` but means the empty type (ignoring bottom here)
13:11:51 <dminuoso> IsProp: So I would ask you to define what you mean by `void *`
13:11:56 <dmwit> Standard in what community? Not the PL research community that I have been inhabiting for the last 10 years...
13:12:09 <jle`> void* is trivially not falsum because it has like...millions of inhabitants
13:12:21 <dmwit> (Though I don't really want to argue about terminology. I have tried to adapt my terminology to yours in my discussion.)
13:12:40 <dminuoso> jle`: Mind a quick follow up question on your singletons blog? I think I spotted an error.
13:12:51 <jle`> dminuoso: sure :)
13:13:27 <IsProp> dmwit: What terminology are you referring to that I misused specifically?
13:13:44 <jle`> void* has UINTPTR_MAX values
13:13:46 <IsProp> I always try to see if there is a miscommunication before attacking someone's use of language.
13:14:28 <jle`> a falsum type must have 0 values
13:14:28 <dminuoso> jle`: In https://blog.jle.im/entry/introduction-to-singletons-2.html under "Why do we sing?", you mention a type `forall s. SomeDoor (Sing s) (Door s)` which I cannot make sense of, since that's presuming `SomeDoor :: * -> * -> *`
13:14:34 <dmwit> "If you made a type system that allowed void* it would be inhabtied by the empty type." <- Right here. If you want a hierarchy of types, generally people give them different names (e.g. type vs. kind, or via indexing like type0 vs. type1, or some other mechanism for differentiating)
13:14:49 <jle`> dmwit: SomeDoor is a data constructor there
13:14:56 <IsProp> The important point about void* is that it is inhabited by a "non-value", which you might say is memory outside the valid range of your program. Say, causing a SEGFAULT or an access violation.
13:15:04 <jle`> * dmwit 
13:15:07 <jle`> * dminuoso 
13:15:27 <dminuoso> jle`: Oh, so that's just visually the right hand side of the data declaration?
13:15:28 <jle`> dminuoso: ah i see what you mean
13:15:45 <dmwit> IsProp: Yep. Lots of type systems allow bottom values to be given non-falsum types.
13:15:46 <jle`> dminuoso: yeah, it should be MkSomeDoor
13:15:55 <dmwit> IsProp: These type systems are unsound, for sure.
13:16:00 <IsProp> dmwit: There's nothing non-standard about what I said in that quote, except my misspelling of inhabited.
13:16:06 <dmwit> IsProp: But bottom values and bottom types are very different.
13:16:13 <dminuoso> jle`: Ah that makes perfect sense now. :)
13:16:15 <jle`> IsProp: it is inhabited by a non-value, but it is also inhabited by yes-values too
13:16:17 <dmwit> IsProp: To show that a type is bottom, you must show that it is *only* inhabited by bottom terms.
13:16:45 <jle`> dminuoso: but, thanks for the catch :) i should fix that
13:17:01 <IsProp> Keep in mind I said equivalent, not that it was it. Equals != equivalence unless you subscribe to HoTT abstracta.
13:17:41 <IsProp> That if you allow void* that it leads you to falsum. This would be a more refined way to put it.
13:17:45 <dmwit> I am fine with this change. To show that a type is equivalent to falsum, you must show that it is only inhabited by bottom terms.
13:17:52 <ski> dminuoso : yes, sometimes `void *' is used like `forall<T> T *', sometimes more like `exists<T> T *'
13:17:58 <IsProp> dmwit: Cheers!
13:18:15 <dmwit> IsProp: But you have *not* shown that void* is only inhabited by bottom terms. That's our point!
13:18:15 <dminuoso> ski: The rules of the abstract machine of C++ make it closer to `exists<T> T *`
13:18:27 <IsProp> dmwit: And you are right as well then.
13:18:31 <dmwit> IsProp: void* is not equivalent to falsum in C, because it *is* inhabited by non-bottom terms.
13:18:34 <dminuoso> ski: Since you can usually not wildly cast it around, but only to what the object type is.
13:18:36 <IsProp> That is a valid point I must concede it.
13:18:52 <IsProp> My intent however was to only show that void* is too powerful.
13:19:15 <IsProp> Unlimited power for as much abstraction as you want. That was the intent that began the ... discussion.
13:19:30 <dminuoso> IsProp: If you are this precise, then basically every lifted type is.. "too powerful"
13:19:47 <dminuoso> IsProp: It's not limited to `void *`. Expressions of type `int` can produce segfaults and other errors too.
13:19:50 <ski> dminuoso : in `void *malloc(size_t size);', it's like `template<typename T> T *malloc(size_t<T> size);' where by `template<typename T>' i mean `forall<T>'
13:20:33 <dminuoso> ski: Curious example actually. Until you actually construct an object in place of that memory, using it in any way is not a valid thing to od.
13:20:35 <IsProp> Keep in mind this all began because I wanted to see if we could all work together to see about a *representation* for a monad pattern in Assembly.
13:21:06 <IsProp> But we could do it just as low level "enough" in C.
13:21:06 <dmwit> Well, I can compile Haskell to assembly, so... done? =)
13:21:13 <dminuoso> ski: Though we should be careful to agree to talk on either C or C++.
13:21:13 <ski> dminuoso : while in `struct { void *env; int (*fun)(void *env,char *str); }' it is more like `struct { typename T; T *env; int (*fun)(T *env,char *str); }'
13:21:42 <ski> dminuoso : iirc, BitC, and Cyclone add quantifiers
13:22:21 <IsProp> Okay so the env, environment is the "context" for the function. Together, these form the "closure". Agreed?
13:22:40 <dminuoso> jle`: By the way, you should probably fix the second half of the sentence too then. :o)
13:22:48 <ski> dminuoso : "Until you actually construct an object ..." -- well, you obv. needs to keep track of the instantiation state of the object
13:23:09 <dminuoso> jle`: i.e.  `you should read this as forall s. MkSomeDoor s (Door s) ...`
13:23:40 <dminuoso> ski: My point is, the rules of the abstract machine, if we ignore the char type punning, turn this into a sort of existential type.
13:23:48 <talqu> How should I write this without using T.pack? "/something/" <> (T.pack . show) someId 
13:24:34 <IsProp> dminuoso: Okay, existential type. As in, a dependent pair?
13:24:37 <dminuoso> void *f = reinterpret_cast<void *>(some_T_obj); -- here you could pretend that: f :: exists<T> T *
13:25:58 <ski> dminuoso : "this" being the result type of `malloc' ?
13:26:02 <dminuoso> Though the usage of `some_T_obj` is a bit confusing here. Perhaps `some_F_ptr` might have been more appropriate, where `some_F
13:26:15 <dminuoso> where `some_F_ptr :: F *`
13:26:43 <IsProp> I would like to thank you all for the stimulating discussion/debate.
13:26:48 <dmwit> talqu: I don't think pack is avoidable.
13:26:53 <dminuoso> IsProp: No, not as a dependent sum type.
13:27:15 <dmwit> talqu: You can write another Show-like class which produces Text directly. But I expect instances of that class will use pack in their implementation for various bits anyway.
13:27:19 <dminuoso> talqu: You could write a local binding for `showT = T.pack . show` and then write `"/something" <> showT someId`
13:27:26 <IsProp> dminuoso: Just a type that includes its witness? The essential "proof object", no? 
13:27:29 <ski> dminuoso : hm, iirc, there is no implicit conversion from `void *' to `T *', in C++ ?
13:27:56 <dminuoso> ski: Its not even about the implicit conversion. You can make it explicit using reinterpret_cast
13:28:26 <IsProp> Why bother with the template system for this exercise?
13:28:40 <IsProp> This is still about a representation for monads, yes?
13:29:07 <dminuoso> ski: Let's ignore the special case of malloc, because I dont know how to think about it honestly.
13:29:56 <ski> if you go from `T0 *' to `void *' to `T1 *', you can either interpret `void *' as `exists<T> T *', and then one of those conversions can be implicit, while the other is unsafe. if we instead interpret `void *' as `forall<T> T *', it's the other way around
13:30:05 <ski> dminuoso : sure, ok
13:30:08 <dminuoso> ski: If we say: T *t = new T(); void *f = reinterpret_cast<void *>(t);
13:30:23 <talqu> ok, i thought maybe it was avoidable :) thanks
13:31:34 <ski> dminuoso : so consider `bsearch', then ? in conjunction with the `struct' example
13:31:55 <dminuoso> So now `f :: exists p. p *` with a lot of squinting. This is partially justified by the fact that you can't simply go `Q *q = reinterpret_cast<Q *>(f);` (well strictly speaking you can, you just cant do much with it) 
13:32:32 <dminuoso> With function pointers it's stronger since you are not even allowed to cast a function pointer to an incompatible one (even without using it)
13:33:27 <ski> hm, okay
13:34:19 <dminuoso> ski: Though the whole type system is unsound and hard to reason about. I mean if these properties are not specified or checked, are they properties at all?
13:34:39 <ski> which properties ?
13:36:57 <dminuoso> ski: say this consideration of "... there is an existential type here"
13:37:08 <dminuoso> In what kind of type system is this? Its certainly not in the type system of C++
13:38:20 <dminuoso> Ive had a severe head injury yesterday, Im probably not making any sense.
13:38:50 <ski> i suppose one could possibly say that if one doesn't violate these properties, then UB doesn't result ?
13:39:02 <ski> ouch :/
13:41:16 <infinisil> Is there a standard type that represents two types interleaved with each other? Something isomorphic to `(a, [(b, a)])`, for a interleaved with b
13:41:45 <infinisil> Well, s/standard/well-known
13:43:58 <Cale> infinisil: I don't think so
13:44:19 <dminuoso> % data Interleaved a b = Next a (Interleaved b a) | Nil a
13:44:20 <yahb> dminuoso: 
13:44:23 <dminuoso> Something like this?
13:44:47 <infinisil> Yeah, but like in a library, with instances defined and all
13:45:03 <jle`> dminuoso: ah, thanks for that too :)
13:45:06 <infinisil> E.g. bimap, Foldable
13:45:19 <infinisil> s/bimap/Bifunctor
13:45:50 <dminuoso> infinisil: I suppose Bifoldable would be an option too
13:47:02 <infinisil> Yeah
13:47:07 <infinisil> Guess I'd create my own then
13:48:58 <jle`> infinisil: you can construct it using some generic combinators to get the right instances
13:49:11 <jle`> in particular i think it should be `Biff (,) NonEmpty []`
13:49:23 <jle`> type Interleaved = Biff (,) NonEmpty []
13:49:30 <infinisil> Ohh neat
13:49:57 <jle`> should give you the right Bifunctor, Bifoldable, Bitravresable, Functor, Traversable, Foldable, etc. insatnces
13:50:10 <jle`> you just have to be a little creative with inspecting the elements, heh
13:50:29 <jle`> oh wait, actually that's wrong
13:50:37 <jle`> the two lists have to be exactly one item apart, sadly
13:50:48 <jle`> this doesn't cut it :'(
13:50:53 <infinisil> Wait what do you mean?
13:51:00 <jle`> well it could give too many a's or too many b's
13:51:00 <infinisil> Oh
13:51:04 <infinisil> Yeah got it
13:51:08 <ski> `Interleaved' aka `SwapList'
13:51:26 <jle`> it's still possible, but it's a little uglier
13:52:36 <infinisil> Yeah so maybe the definition dminuoso gave might be the right way to go after all
13:53:38 <jle`> type Interleaved = Product (Joker Identity) (Tannen [] (,))
13:54:09 <infinisil> Okay this is getting out of hand!
13:54:34 <infinisil> You know I just saw Joker before and wonderered how this could ever be used
13:54:50 <jle`> now we know :D
13:54:53 <Solonarv> remind me what Joker and Tannen are?
13:55:11 <jle`> Joker is a bifunctor that ignores the right argument
13:55:24 <jle`> Tannen is like functor-bifunctor composition
13:55:26 * dminuoso mumbles "Clowns to the left of me, jokers to the right..."
13:55:30 <MarcelineVQ> Joker's to the left :> Biff Tannen. People are silly.
13:55:39 <dminuoso> MarcelineVQ: Close!
13:55:42 <Solonarv> ah, and Tannen f p a b ~ p (f a) (f b)
13:55:47 <jle`> so Tannen [] (,) a b ~ [(a,b)]
13:56:04 <jle`> Solonarv: that's Biff actually
13:56:11 <Solonarv> oh right
13:56:29 <Solonarv> my thing isn't Biff though, my thing only takes one functor
13:56:30 <jle`> but yeah, who would know
13:56:32 <Solonarv> Biff takes two
13:56:47 <jle`> oh ah
13:56:55 <dminuoso> What's the deal with Biff and Tannen?
13:56:59 <Solonarv> jle`: so really this is just (a, [(a, b)]) in a trenchcoat
13:57:07 <dminuoso> I mean I know who Biff Tannen is, but what's the story behind the choice here?
13:57:31 <jle`> Solonarv: yeah, it's basically a GeneralizedNewtypeDeriving version of (a, [(ab)])
13:57:38 * Solonarv nods
13:57:56 <Solonarv> this seems entirely sensible and definitely like something I would want to use all the time :P
13:58:01 <infinisil> Would be cool if you could define `data Interleaved a b = (a, [(a, b)])` and then tell it that that's isomorphic to the fancy bifunctor thing to get the instances
13:58:18 <jle`> actually you might be able to do that with DerivingVia
13:58:35 <Solonarv> yes, but you need a pile of newtypes with fancy instances
13:58:53 <Solonarv> this might just already be a thing in lyxia's
13:58:54 <Solonarv> @hackage generic-data
13:58:54 <lambdabot> http://hackage.haskell.org/package/generic-data
13:59:15 <jle`> yeah, you need to get the newtypes because the Bifoldable and Bitraversable instances are not uniquely determined
13:59:21 <jle`> but ghc should be able to DeriveBifunctor
14:00:00 <jle`> although i guess ghc doesn't care about not-unique instances either, since we have DeriveTraversable and DerieFOldable already
14:00:31 <jle`> my poor keyboard
14:00:36 <Solonarv> GHC hasn't cared about non-unique instances for a long time, even something as simple as Ord is non-unique
14:01:18 <jle`> yeah, it shoulllddd be possible to write a ghc-generics way to derive Bifunctor, Bifoldable, Bitraversable
14:01:41 <Solonarv> also even if we had DeriveBifunctor it might get thwarted by the non-regular recursion in the 'data Interleaved a b = Next a (Interleaved b a) | Nil a' version
14:02:05 <jle`> yeah, the (a,[(a,b]) version would play nicer
14:03:27 <Solonarv> you could probably swap a and b in the tuple
14:04:31 <Solonarv> Derive{Functor,Foldable,Traversable} already handle tuples specially (the parameter can appear in any position in the tuple)
14:04:42 <dminuoso> The `a` of the `Nil` should probably disappear. 
14:05:31 <Solonarv> not if you want it to be non-empty
14:05:41 <Solonarv> which (a, [(b, a)]) is
14:07:35 <Solonarv> ...oh huh, that's actually not equivalent to Interleave
14:07:59 <dminuoso> Solonarv: Interleave can have one side too short either way.
14:08:10 <Solonarv> Interleaved a b can end on a or b, which (a, [(b, a)])) can't
14:08:25 <Solonarv> it always ends with an a
14:09:52 <infinisil> Oh yeah I didn't even notice
14:10:09 <infinisil> data Interleaved1 a b = Next a (Interleaved2 b a) | Nil a
14:10:26 <infinisil> data Interleaved2 a b = Next a (Interleaved1 b a)
14:10:42 <Solonarv> well that last one is just infinite
14:10:58 <infinisil> Infinite how?
14:11:23 <ski> Solonarv : mutual recursion
14:12:44 <Solonarv> oooh, I misread
14:12:44 <infinisil> But might as well use `data Interleaved a b = Next a b (Interleaved a b) | Nil a` because there's only one case for Interleaved2
14:12:54 <Solonarv> I didn't see that they were referring to each other
14:13:16 <Solonarv> don't mind me!
14:13:52 <dminuoso> infinisil: And at that point you have your (a, [(b, a)])
14:13:56 <infinisil> Yea
14:14:13 <infinisil> Which would be more comfortable to use than Interleaved too
14:21:23 <infinisil> Oh, I bet in Idris you could define Interleaved and even use the standard list syntax to define values of it
14:21:37 <infinisil> : and [] are overloadable in Idris
14:21:56 <infinisil> (and consequently list syntax)
14:25:58 <dminuoso> infinisil: OverloadedLists is a thing in GHC too.
14:26:53 <Solonarv> yes, but all the list elements must have the same type.
14:27:03 <c_wraith> it's not an especially useful thing in ghc
14:27:21 <dminuoso> I guess there's still the option of a QuasiQuoter if you use this a lot.
14:27:35 <c_wraith> because it's implemented as fromList instead of overloading (:) and []
14:27:35 <Solonarv> you could even use list syntax in the QQ!
14:27:52 <JappleAck> hey guys, what would you recommend for this type? Applicative f => (f a, f b, f c) -> f (a, b, c)
14:27:53 <infinisil> AHh I forgot about OverloadedLists
14:28:01 <infinisil> But yeah it wouldn't work because of the same-type requirement
14:28:06 <dminuoso> JappleAck: liftA3
14:28:09 <Solonarv> [ol| [1, True, 2]|] :: Interleaved Int Bool
14:28:14 <Solonarv> I'm sure you can make this work somehow
14:28:46 <infinisil> Hehe yeah
14:28:55 <Solonarv> unfortunately rampant use of QQs means rampant use of TH, which is annoying for a handful of reasons :/
14:29:14 <infinisil> Which are?
14:29:24 <infinisil> Ungreppability is probably one
14:29:30 <Solonarv> staging/ordering restrictions too
14:29:39 <dminuoso> JappleAck: Pattern match on the tuple, and then just go `liftA3 f g h` I'd say.
14:29:56 <Solonarv> if you have 'foo; $(bar); baz' then foo can't depend on baz
14:30:20 <infinisil> Hmm I see
14:31:03 <Solonarv> which is very annoying because suddenly the order things are defined in your source code matters, when it doesn't normally
14:31:19 <JappleAck> dminuoso: thanks, but i'd prefer to avoid pattern matching, so i guess i have to build my own typeclass if i want it that hard
14:31:50 <dminuoso> % uncurry3 f (x, y, z) = f x y z
14:31:51 <yahb> dminuoso: 
14:32:04 <dminuoso> % :t uncurry3 . liftA3 (,,)
14:32:04 <yahb> dminuoso: (t3 -> a) -> (t3 -> b, t3 -> c, t3) -> (a, b, c)
14:32:10 <dminuoso> Uhh not quite
14:32:18 <Solonarv> % :t uncurry3 (liftA3 (,,))
14:32:18 <yahb> Solonarv: Applicative f => (f a, f b, f c) -> f (a, b, c)
14:32:38 <dminuoso> That. :)
14:32:45 <dminuoso> I was so close.
14:33:27 <dminuoso> JappleAck: This is equivalent to:
14:33:36 <dminuoso> % :t uncurry (liftA2 (,))
14:33:36 <yahb> dminuoso: Applicative f => (f a, f b) -> f (a, b)
14:33:40 <Solonarv> you could probably build "my own OverloadedLists, with blackjack and hookers!" using a source plugin to override the desugaring of [x, y, z]
14:33:41 <JappleAck> oh, okay, thanks
14:33:55 <dminuoso> JappleAck: In a lot of ways, this is the core essence of Applicative.
14:36:33 <dminuoso> Solonarv: I like QQ a lot more than I like TH, honestly.
14:37:00 <dminuoso> Solonarv: Ive grown fond of this little QQ https://hackage.haskell.org/package/hexquote in some of my private packages.
14:37:31 <Solonarv> well, [qq|blah blah|] is the same as $(quoteExp qq "blah blah")
14:37:46 <Solonarv> or one of the other quote* depending on context
14:38:58 <dminuoso> Solonarv: Well sure, I rather meant it as splicing in an expression feels less dirty than splicing in definitions that somehow have far-distance effects.
14:39:05 <Solonarv> ah, yes
14:39:09 <Solonarv> that I agree with
14:39:40 <dminuoso> Interestingly the latter is more frequently used though.
14:39:59 <dminuoso> Perhaps because it's so easy to generate DSLs inside the language?
14:40:38 <Solonarv> yeah, probably
14:41:30 <dminuoso> Can a splice occur in any place?
14:41:31 <Solonarv> and also it's pretty natural IMO to go "ugh, I don't want to write all this boilerplate" and try to somehow handle that automatically, using some sort of macro system
14:42:07 <Solonarv> there are four spliceable things: expressions, declarations, patterns, and types
14:42:35 <dminuoso> I take it types includes kinds?
14:42:39 <Solonarv> so you can't for example write:
14:42:39 <Solonarv> $(foo) :: Foo -> Bar
14:42:39 <Solonarv> $(foo) x = y
14:42:43 <Solonarv> yes, kinds included
14:42:45 <dminuoso> k
14:43:16 <dminuoso> Solonarv: What about type annotations?
14:43:27 <Solonarv> same
14:43:41 <Solonarv> anywhere a type could appear you can have a splice which produces a type
14:43:59 <dminuoso> So I can write something like `$(foo); bar x = z` where `foo` generates a necessary type annotation for bar?
14:44:12 <dminuoso> Or matching type annotation, rather.
14:44:33 <Solonarv> hmm... I don't think that would work
14:44:38 <Solonarv> let me check
14:46:12 <Solonarv> ah, looks like you can indeed do that
14:46:41 <dminuoso> Fancy, mind my asking - how did you check exactly?
14:47:09 <Solonarv> well, I know that a top-level splice has to produce [Dec], i.e. a list of declarations
14:47:26 <Solonarv> then it was a simple matter of looking at the docs - https://hackage.haskell.org/package/template-haskell-2.14.0.0/docs/Language-Haskell-TH-Syntax.html#t:Dec
14:48:13 <Solonarv> and seeing whether there is a single constructor for the entirety of the { foo :: T, foo = .. } construct, or whether that is actually two separate declarations
14:49:12 <Solonarv> I found the SigD constructor for type signatures, and FunD or ValD for the actual value declaration
14:49:44 <dminuoso> Solonarv: Ohh wow. Are these code examples knew?
14:49:46 <dminuoso> *new
14:49:52 <Solonarv> I have no idea!
14:49:58 <dminuoso> When I looked last at TH a few months ago, it was all empty and you had to *guess*.
14:50:03 <dminuoso> This is totally amazing.
14:51:11 <geekosaur> that one was guessable because the type signature and definition can be separated
14:51:38 <Solonarv> dminuoso: it looks like the examples have been there since template-haskell-2.5.0.0
14:51:52 <dminuoso> geekosaur: Perhaps GHC reassociates these at some stage, Im not familiar with GHC much.
14:52:01 <dminuoso> Solonarv: Mmmm 
14:52:13 <geekosaur> it does, but TH is during parsing
14:52:18 <geekosaur> which is why stage restrictions etc.
14:52:38 <geekosaur> if it hasn't parsed it yet, it's not there at TH time to be used
14:54:00 <dminuoso> geekosaur: So the parser stops in the middle of it when it sees a splice or quotation, executes TH, and then resumes the parsing?
14:54:24 <geekosaur> yes
14:54:32 <geekosaur> that's also why splices break up binding groups
14:54:46 <dminuoso> Ahh, Ive actually wondered about that before.
14:54:49 <geekosaur> because it has to complete the current one to be in a state where it can splice
14:56:10 <Solonarv> really? I thought it ran during desugaring, or something
14:58:41 <Solonarv> you could use this to do funny things like { foo :: <whatever>; $(djinn 'foo) }
14:59:06 <Solonarv> although I'd prefer to write that as $(djinn "foo" [| <whatever> |])
15:00:47 <infinisil> The coolest thing (and only thing actually) I did with TH was a state machine with 2^n states (n = 4 in my case), with a function for every one of them, which would go over a sequence and transform it according to some rules
15:15:37 <Deide> Is there a function like sequence that would give me an `Either [a] [b]` instead of an `Either a [b]` for a list of Eithers?
15:16:38 <jle`> Deide: what would it do with [Left 1, Left 2, Right 'a', Right 'b'] ?
15:17:42 <jle`> Left [1,2], or Right "ab" ?
15:18:09 * geekosaur wonders if they really want partitionEithers
15:18:14 <Deide> Left [1, 2] or Right ["a", "b"]
15:18:22 <geekosaur> "or"?
15:18:30 <geekosaur> how does it decide?
15:18:47 <infinisil> % :t partitionEithers
15:18:48 <yahb> infinisil: [Either a b] -> ([a], [b])
15:18:48 <Deide> in the presence of Lefts
15:18:58 <jle`> Deide: right, so I'm giving you a specific list
15:19:00 <jle`> what would it return for that list?
15:19:10 <jle`> do you want the version that would return Left, or the version that would return Right?
15:19:15 <jle`> or a version that flips a coin maybe
15:19:32 <Deide> Oh right, It would be Left [1, 2]
15:20:31 <jle`> hm, so maybe you want something like sequenceA for Accum/Errors
15:20:50 <infinisil> Sounds like Validation
15:21:00 <Solonarv> Validation is similar
15:21:09 <jle`> > runErrors $ traverse eitherToErrors [Left [1], Left [2], Right "a", Right "b"]
15:21:12 <lambdabot>  error:
15:21:12 <lambdabot>      Variable not in scope: runErrors :: f0 [b0] -> terror:
15:21:12 <lambdabot>      Variable not in scope:
15:21:17 <jle`> yeah, validation is 'Errors', but Errors is in transformers
15:21:25 <Solonarv> % import qualified Data.Validation as V
15:21:25 <yahb> Solonarv: ; <no location info>: error:; Could not find module `Data.Validation'; It is not a module in the current program, or in any known package.
15:21:26 <jle`> @let import Control.Applicative.Lift
15:21:28 <lambdabot>  Defined.
15:21:30 <Solonarv> bah!
15:21:30 <jle`> > runErrors $ traverse eitherToErrors [Left [1], Left [2], Right "a", Right "b"]
15:21:33 <lambdabot>  error:
15:21:33 <lambdabot>      Variable not in scope:
15:21:33 <lambdabot>        eitherToErrors
15:22:09 <jle`> % import Control.Applicative.Lift
15:22:10 <yahb> jle`: 
15:22:18 <jle`> % runErrors $ traverse eitherToErrors [Left [1], Left [2], Right "a", Right "b"]
15:22:18 <yahb> jle`: Left [1,2]
15:23:00 <Solonarv> % :t runErrors . traverse (eitherToErrors . first (:[]))
15:23:00 <yahb> Solonarv: ; <interactive>:1:40: error:; * Couldn't match type `([b], d)' with `Either e b1'; Expected type: (b, d) -> Either e b1; Actual type: (b, d) -> ([b], d); * In the second argument of `(.)', namely `first (: [])'; In the first argument of `traverse', namely `(eitherToErrors . first (: []))'; In the second argument of `(.)', namely `traverse (eitherToErrors . first (: []))'
15:23:04 <Deide> I suppose a partition could work
15:23:17 <Solonarv> bah, wrong first
15:23:19 <jle`> if you partition then you'd have to check if the first list is empty to get the same behavior
15:23:24 <Solonarv> % :t runErrors . traverse (eitherToErrors . Data.Bifunctor.first (:[]))
15:23:24 <yahb> Solonarv: Traversable t => t (Either a b) -> Either [a] (t b)
15:23:31 <Deide> Where is partitionEithers?
15:23:32 <jle`> > partitionEithers [Left 1, Left 2, Right 'a', Right 'b']
15:23:34 <lambdabot>  ([1,2],"ab")
15:23:41 <jle`> it's in Data.Either, in base
15:24:00 <Deide> Makes sense
15:24:13 <jle`> @hoogle partitionEithers
15:24:13 <lambdabot> Data.Either partitionEithers :: [Either a b] -> ([a], [b])
15:24:14 <lambdabot> Protolude partitionEithers :: () => [Either a b] -> ([a], [b])
15:24:14 <lambdabot> Streaming.Prelude partitionEithers :: Monad m => Stream (Of (Either a b)) m r -> Stream (Of a) (Stream (Of b) m) r
15:24:26 <Deide> Thanks!
15:24:45 <jle`> that was a better 'teaching how to fish' answer :)
15:26:04 <Solonarv> also available via web interface:
15:26:04 <Solonarv> @where hoogle
15:26:04 <lambdabot> http://haskell.org/hoogle http://hoogle.haskell.org http://fpcomplete.com/hoogle – See also Hayoo, which searches more packages: http://hayoo.fh-wedel.de/
15:26:30 <Solonarv> and you can get it to work locally too but I've never bothered to figure that out
15:26:33 <infinisil> % :t (\(l, r) -> if null l then Right r else Left l) . partitionEithers
15:26:33 <yahb> infinisil: [Either a b] -> Either [a] [b]
15:26:36 <infinisil> This would work too
15:28:46 <Deide> Ah yeah, I can stack hoogle. Always forget.
17:26:09 <hkimhvyh[m]> I've got a meta question. Why are haskell-ers so prevalent on matrix and IRC while these platforms seem to be nearly devoid of other languages? Of the languages with active IRC channels, Haskell is the only group that I've had good interactions with.
17:27:28 <matsurago> Java channel is quite helpful and active on prime time, too
17:28:05 <matsurago> Rust was also extremely active until Mozilla decided to close it, with many people being against such a decision
17:28:32 <matsurago> c++ is quite alive, too
17:28:39 <hkimhvyh[m]> I guess I just don't have enough exposure.
17:29:02 <MarcelineVQ> interesting question, one possible angle is that things are more project centric instead of language centric these days, so you get groups using things more suited to that end, things like discord where you can share media more plainly
17:29:51 <MarcelineVQ> That sort of thing would result in many small hidden places instead of large public places. total guess though, just a thought
17:29:56 <hkimhvyh[m]> The few times I've asked for help from the C++ channel, it's been a pretty terrible experience. That's probably a me problem, but there are some seriously jaded people on the server.
17:30:07 <hkimhvyh[m]> That's a good point.
17:30:45 <matsurago> As to my experience, people on c++ channel were very helpful and possessed deep knowledge
17:31:34 <hkimhvyh[m]> Perhaps I've just run into the nasties who are alive during the wee hours of the morning.
17:32:10 <hkimhvyh[m]> Granted, it's not like the entire planet is asleep at the same time. Maybe it's just me.
17:33:53 <MarcelineVQ> Not far off though. PST and GMT are the major time-axis of software dev, so there are lul periods between the two
17:35:22 <MarcelineVQ> Notably the quality of answers on irc depend entirely on the quality of the question so if you run into resistance that's something to keep in mind
17:38:55 <MarcelineVQ> It's little like SO but there isn't a mod closing every 3:4 questions you ask and redirecting to another question that isn't the same as the one you asked :D
17:39:22 <MarcelineVQ> Where the tradeoff of not being over-moderated is that the onus is on you to ask well in the first place or get ignored/made fun of. In my little view of things anyway.
17:45:05 <hkimhvyh[m]> One problem I run into is that I sometimes struggle with actually identifying what to search for. It's like trying to describe a dream that you can only remember pieces of. When I encounter that kind of struggle, my strategy is usually to just ask for search terms or with help finding the documentation. Whenever I've asked #haskell on freenode in this manner, it's been met with kindness. Elsewhere, it's been met with
17:45:06 <hkimhvyh[m]> spit to the face.
17:45:15 <MarcelineVQ> wot, quickcheck for strictness? https://dl.acm.org/citation.cfm?doid=3243631.3236797
17:48:38 <nshepperd> Is "this question has been closed due to being offtopic for SO" the new "nevermind, I fixed it" (when googling for solutions to obscure problems)
17:50:05 <MarcelineVQ> :>
17:50:30 <hkimhvyh[m]> Which operator is that?
17:51:40 <MarcelineVQ> it's the infix form of 'sly' from my utilities lib
17:51:56 <pavonia> nshepperd: Questions on SO are closed by other users
18:00:29 <iqubic> Oh how I wish we had Dependent Haskell right now.
18:04:15 <hkimhvyh[m]> <iqubic "Oh how I wish we had Dependent H"> I'm not familiar. Is this a proposed system or something?
18:06:01 <MarcelineVQ> yes Depenent Haskell is an extension to the language being worked on
18:07:37 <hkimhvyh[m]> Is there something in particular you're excited for?
18:09:39 <iqubic> I'm just excited to have fully dependent types in Haskell.
18:09:51 <iqubic> When will Dependent Haskell come out?
18:24:33 <rwe> I've been waiting for it (Dependent Haskell) too. Liquid Haskell is an interesting middle ground (but, unfortunately still unstable). In the meantime I've been exploring Agda and honestly falling in love with it
18:38:51 <jusss> ski: "<ski>   data Tree a = Nil | Node a (Tree a) (Tree a)"  Tree a could be Nil, Node a Nil Nil, Node a Nil (Node a Nil Nil), Node a (Node a Nil Nil) Nil, etc...
18:39:11 <jusss> this recursion in data type is too hard
18:41:53 <pavonia> jusss: Do you know how to do pattern matching on data constructors?
18:41:55 <jle`> try thinking about actual values, instead of just 'a' :)
18:42:01 <jle`> for example, what are some values of type Tree Char ?
18:42:06 <jle`> Nil is a value
18:42:22 <jle`> Node 'a' ??? ??? is a value, as long as ?? and ?? both have type 'Tree Char'
18:43:42 <jle`> so, `Node 'a' Nil Nil` is a valid value of type 'Tree Char'
18:44:20 <jusss> jle`: and Nil :: Tree whatever
18:44:35 <jle`> Nil :: Tree Char, Nil :: Tree Bool, Nil :: Tree String, etc.
18:44:41 <jle`> it can be a Tree of any type you want
18:45:00 <jle`> it's kind of like how `[] :: [Char]`, `[] :: [Bool]`, `[] :: [String]`, etc.
18:45:01 <jusss> pavonia: I only know pattern matching on function definition
18:45:04 <jle`> [] is an empty list of any type you want
18:45:43 <jusss> jle`: I wonder how many values can be Tree a?
18:46:12 <jusss> jle`: for example, Maybe a have Just a and Nothing two value
18:46:15 <pavonia> That's what I mean, in a function definition you pattern match on data constructors
18:46:24 <jle`> jusss: that's a good question :)
18:46:45 <jle`> jusss: well, Maybe isn't just two values
18:46:50 <jusss> pavonia: I think only when I know all the values of Tree a, so I can do pattern matching on function 
18:46:55 <jle`> Maybe has two constructors, but it could potentially have many values
18:47:04 <jle`> for example, how many values are of type `Maybe Bool` ?
18:47:09 <jusss> jle`: the form, I think
18:47:13 <jle`> there are three: Nothing, Just False, and Just True
18:47:29 <jle`> how many values are of type `Maybe ()`?
18:48:03 <jle`> and we have data Ordering = LT | EQ | GT
18:48:07 <jle`> how many values are of type Maybe Ordering?
18:48:10 <jusss> jle`: I mean how many forms for Maybe Int,  two, right?
18:48:19 <jle`> jusss: what do you mean by 'forms'?
18:48:29 <pavonia> jusss: You know all the values/constructors
18:48:33 <jle`> there are two constructors, if that's what you mean
18:48:38 <jle`> Nothing, and Just (some int)
18:48:42 <jusss> jle`: yes
18:49:01 <jusss> jle`: not only the constructor
18:49:02 <jle`> or maybe, you want to ask how many "shapes" a Maybe can take
18:49:12 <jle`> in that case, it's useful to look at `Maybe ()`
18:49:28 <jle`> you see that there are only two values of type Maybe (): Nothing, and Just ()
18:49:33 <jusss> jle`: a = b c , is one form, and a = c b is another form with those same elements, but different position 
18:49:48 <jle`> plugging in () lets you investigate the different "shapes" that a parameterized data type might have
18:49:52 <jusss> jle`: yes,
18:49:54 <jle`> we can do the same analysis with list
18:50:15 <jle`> how many "shapes" does a list have?  what is the possible range of its structure?
18:50:20 <jle`> to do that, we can look at [()]
18:50:31 <jusss> jle`: so when a is Int,  data Tree a = Nil  | Node a (Tree a) (Tree a), how many values can be Tree a?
18:50:56 <jle`> jusss: answer the question about lists :)
18:51:01 <jle`> do you know the constructors of lists?
18:51:04 <jle`> *the constructors of list?
18:51:05 <jusss> jle`: depends its elements
18:51:26 <jle`> the list data type only has two constructors
18:51:32 <jle`> but, we're looking specifically at [()]
18:51:36 <jle`> a list of unit
18:51:41 <jle`> what values have type [()] ?
18:52:20 <jusss> [(1)] ？
18:52:52 <jle`> [1] has type [Int] 
18:52:56 <jle`> (or any other number type
18:53:30 <jle`> are you familiar with the constructors for list?
18:53:36 <jle`> there are two of them; do you know what they are?
18:53:53 <jle`> (just asking so i know where to start the discussion)
18:53:56 <jusss> [] and a?
18:54:05 <jle`> close, it's [] and (:)
18:54:15 <jle`> essentially it's data [a] = [] | a : [a]
18:54:24 <jle`> there's [] :: [a], and (:) :: a -> [a] -> [a]
18:54:35 <jle`> [] is commonly called 'nil', and (:) is commonly called 'cons'
18:55:01 <jusss> jle`: names from lisp
18:55:04 <jle`> (:) has two fields: an 'a', and an '[a]'
18:55:14 <jle`> so, we have [] :: [()]
18:55:21 <jle`> [] is a value of type [()]
18:55:29 <jle`> where () is the unit type, the type with a single value, ()
18:55:34 <jle`> but, we also have () : []
18:56:17 <jle`> (also written as [()], it's sugar for a single-item list)
18:56:24 <jle`> and, we also have () : ( () : [] )
18:56:28 <jle`> also written as [(),()]
18:56:50 <jle`> remember the right hand side of : can be any list of the right type.
18:57:39 <jusss> ok
18:57:42 <jle`> and we also have () : ( () : ( () : [] ) ), etc.
18:58:05 <jle`> so the values of type [()] are [], [()], [(),()], [(),(),()], [(),(),(),()], etc.
18:58:48 <jusss> infinity, you want to say?
18:58:56 <jle`> i'm just giving examples :)
18:59:08 <jle`> if you want to count them, then...yeah, it looks like there are infinite possible shapes a [()] can take
18:59:13 <jle`> there's actually one shape for every natural number
18:59:23 <jle`> in fact, [()] is one way some people model natural numbers in haskell
19:00:21 <jle`> do you see how we explored all possible shapes of [()]?  we just looked at every combination we can use the constructors
19:01:19 <jusss> jle`: but data Tree a = Nil | Node a (Tree a) (Tree a),   Tree Int don't have infinity shapes if we just want a be 1
19:01:41 <jle`> let's look at Tree ()
19:01:46 <jle`> what are possible values of type Tree () ?
19:02:03 <jusss> Nil
19:02:30 <jle`> that's one of them :)
19:02:32 <jle`> how about another?
19:02:37 <jusss> Node a Nil Nil
19:02:56 <jle`> what about values of type Tree ()
19:03:02 <jle`> do you mean `Node () Nil Nil` maybe?
19:03:27 <jusss> yeah, if you replace a with ()
19:03:46 <jle`> right, Node () Nil Nil is a value of type Tree ()
19:03:49 <jle`> what about another one?
19:04:10 <jusss> Node () Nil (Node () Nil Nil)
19:04:26 <jusss> Node () (Node () Nil Nil) Nil
19:04:38 <jle`> yeah :)
19:04:49 <jle`> you got it
19:06:41 <jusss> jle`: infinity?
19:12:09 <jle`> yeah, there are infinite possible shapes of a Tree
19:13:22 <jusss> jle`: and we can define a function to handle that infinite shapes of a Tree?
19:13:35 <jusss> <ski>   addToTree :: Num a => Tree a -> a -> Tree a
19:14:16 <geekosaur> yes, because you can combine them in an infinite number of ways, you can handle them recursively and there's only two basic shapes
19:15:48 <jle`> jusss: yeah, just like we can write a function to handle an infinite number of possible lists
19:16:04 <jle`> jusss: for example, the "safeHead" function
19:16:07 <jle`> safeHead [] = Nothing
19:16:11 <jle`> safeHead (x : xs) = Just x
19:16:18 <jle`> bam, we handled all infinite possible list lengths
19:20:29 <rwe> So, I have a quick question maybe someone has a reference handy. Is there anyone working on a proposal for—or more information on why not—a non-flat dependency structure for Haskell? `PackageImports` seems like a vague scooch in that general direction, but has there been any significant work/discussion/investigation otherwise? I can't seem to find anything but may be searching the wrong terms
19:24:06 <orzo> I have some code that chains to Data.Map.lookup for a fallback map after a Data.Map.lookup fails for a prefered map.  Anybody know if it is run-time equivelent to do a single lookup into a temporary union map?
19:25:34 <iqubic> jle`: That was a really cool discussion to read.
19:25:37 <c_wraith> orzo, definitely faster
19:25:59 <iqubic> jle`: The way you take complex things and make them simple is quite cool.
19:26:16 <iqubic> You're so eloquent.
19:26:34 <orzo> c_wraith: which?  The double lookup?
19:26:37 <c_wraith> orzo, it's two O(log n) lookups, vs an O(at least n) construction
19:26:37 <geekosaur> if you unioned them correctly (remember it's left-biased)
19:27:29 <c_wraith> Data.Map is spine-strict, so there's no way laziness can save you.
19:30:01 <orzo> thanks c_wraith 
19:32:36 <rwe> ^ (cont). By "non-flat", I mean, for example, I depend on aeson=1.4. I want to use package B. Package B internally uses aeson==1.1. Right now in GHC, you're stuck, even though the dependencies of package B could be viewed as an internal implementation detail. The way that modern JavaScript development (Yarn etc) handles this works very well. I can see how it could work for Haskell as well in many (most? all?) cases…but I haven't s
19:32:37 <rwe> een this as a priority, despite so many people rightly complaining about Cabal hell. (And this literally seems to be the only reason Stackage exists). Is there work being done on this? Does the Haskell community not consider it a worthwhile problem? Not familiar with alternatives? Too big of a fundamental mountain to climb given other priorities?
19:33:16 <geekosaur> there are details that make it not as solvable
19:33:53 <geekosaur> in particular, cross-module inlining is critical for performance, and means that "internals" aren't necessarily internal at the ABI lvel
19:37:25 <rwe> @geekosaur — Does "GHC Core" count as ABI here? Is that too unstable or not provide enough information for inlining? I'm not as familiar with the implementation details here as I'd like to be
19:37:25 <lambdabot> Unknown command, try @list
19:38:40 <geekosaur> ABI here is "a module that imports another module will get some of the internal implementation of the other module's functions for inlining, and in turn may re-export them for inlining of its own functions"
19:40:36 <rwe> Ok. But in what case is that a problem? (The "obvious" challenge I had in mind was completely different—it was instances, but I think it's fairly straightforward to manage).
19:41:37 <geekosaur> this means that your "viewed as an internal implementation detail" is not internal
19:42:58 <rwe> That seems to me still to be, which means we, so we must have a different interpretation or assumption somewhere.
19:43:14 <geekosaur> and that if you then try to use it with a different version of (again using your example) aeson, you cannot privately link package B to its aeson version reliably, because users of package B may inline its functions including calls to aeson-1.1, so now upstream modules need to link both and not simply rely on B having done so
19:48:38 <rwe> I think I see two mismatches here
19:48:42 <rwe> First: If a downstream packages pull in a dependency like `aeson`, I think it's widely agreed that it's somewhere between bad practice and a crime for *my* package to import `Data.Aeson` without declaring a dependency on it. Implicit transitive dependencies are no bueno regardless of flatness of versions, I think. But that does not seem to be a deep problem.
19:50:15 <rwe> s/downstream/child/ (or whatever…if A depends on B, and B depends on C; then if A uses C for its own uses, it should still be a dependency)
19:51:35 <geekosaur> right, but it can become an implicit direct dependency. and turning this off has severe performance impacts. (you can tell ghc to show what's in a .hi file; you'll see a decent amount of source code if optimization is enabled)
19:51:59 <geekosaur> this can be a problem if you also import directly a different version
19:52:53 <rwe> Second, and related: for stuff like "PackageImports", why is it `aesone` instead of `aeson-1.4`? Ok, you have multiple versions of `aeson` available. So disambiguate them! That leads to the problem that I thought was actually a problem: declaring stuff like:
19:54:07 <rwe> instance "base-4.9.0.0@Data.Monad" "base-4.12.0.0"@Data.Monad
19:54:16 <geekosaur> so, I've been a maintainer of a package that doesn't by default use any kind of package management (xmonad; these days you can tell it to use a build script that can ensure the right packages are in scope). at times, people have had mismatched xmonad and xmonad-contrib binaary packages installed. this leads to *weird* errors, most visibly in instance resolution because the error messages look like they are suggesting the very instance that 
19:54:17 <geekosaur> they claim are missing — but it's from the wrong version of the package
19:54:59 <geekosaur> also I think you can actually use the longer one, and even the ABI has one if you must. but you now have to make source code changes if aeson-1.3 would also work
19:55:15 <geekosaur> so you are unnecessarily pegging to a specific version
19:55:25 <geekosaur> *ABI hash one
19:57:09 <rwe> If _my_ package works (and I mean "my" abstractly), and anyone who imports me is free to use other versions, why is pinning necessarily a problem?
19:58:55 <rwe> I can see the error message thing, but that also seems like a related problem area. The fact that "my-package@1.0.0" and "my-package@999.1" are just known as "my-package"
20:00:18 <rwe> With e.g. JavaScript, using Yarn: it attempts to share packages as much as possible. But otherwise, packages are nested; there's (typically) nothing preventing two packages that depend on different versions of something else from coexisting.
20:01:31 <geekosaur> with javascript tyhere's also that you are not generally loading something that was compiled months earlier and possibly on a different machine (consider distribution binary packages)
20:01:44 <rwe> The only times that that becomes a problem is when the data types interact, and you realize that the type "my-package-1.0.0:GreatFooDatum" is different than "my-package-2.0.0:GreatFooDatum". But that's a legitimate interface boundary that can either be solved with a conversion, or it can't be, in which case, you might as well consider them totally different types to begin wtih
20:03:13 <maerwald> anyone knows if "realpath" is generally available on macosx?
20:03:16 <rwe> Well, that's only partially true. By and large, *most* JavaScript is compiled these days by either Babel or TSC. It's just that the "ABI" is a very plain subset of JavaScript rather than LLVM bytecode or object code.
20:03:31 <geekosaur> it's still rather more flexible than machine code
20:03:57 <rwe> maerwald: It is not, but you can get it via "brew install coreutils"
20:04:27 <rwe> geekosaur: Yes, it is, I agree. And as a tradeoff it lacks type information etc
20:04:37 <rwe> Well, so does the compiled object code…
20:05:21 <rwe> Actually, for a binary package, where *is* type information stored? .hi modules? I'm mostly familiar with source packages
20:06:07 <c_wraith> yes, .hi files store type information, unfoldings, annotations, other things
20:06:10 <geekosaur> that's part of the .hi file, ues
20:06:41 <geekosaur> also, another thing: you mention conversions, but Haskell shies away from implicit conversions of any kind. (there's an exception for some literals)
20:08:57 <rwe> I don't think they'd need to be implicit. Though I could see an argument for "different package version, but same package (name), module, type; same constructors -> instantiate a conversion automatically" type of rule. Which would cover a large number of practical cases, I think
20:11:36 <dramforever> That sounds like it's really difficult to do in general
20:12:14 <dramforever> For example suppose I have a lens: bar :: Functor f => (Bar -> f Bar) -> Foo -> f Foo
20:12:57 <dramforever> How do you convert Functor f => (pkg-1:Bar -> f pkg-1:Bar) -> pkg-1:Foo -> f pkg-1:Foo to Functor f => (pkg-2:Bar -> f pkg-2:Bar) -> pkg-2:Foo -> f pkg-2:Foo ?
20:13:57 <geekosaur> anyway experience has been that it's nnot enough for types to be compatible because of inlining that may mix incompatible implementations even when the types are the same. which has been seen with version skew in the containers library with respect to ghc-api, iirc, and if you try hard enough you can get core dumps
20:14:28 <geekosaur> (because containers is prone to some fairly evil implementations, that "ought to be" hidden but can get exposed for inlining)
20:14:36 <dramforever> I remember seeing people ask about unsafeCoerce-ing between types that are defined similarly
20:15:41 <dramforever> And also someone going as far as claiming that this is safe (No, according to unsafeCoerce's docs it's not safe)
20:15:45 <rwe> "inlining mixing incompatible implementations" seems like it should be impossible. They're different types. If package B imports package C@2 and asks it to inline something, and my package imports package C@3 and asks it to inline something; it shouldn't be ambiguous what is getting inlined. Package B doesn't know or care *what* the parent package is doing
20:16:45 <dramforever> I do feel like it's more work than it's worth
20:17:33 <dramforever> GHC basically doesn't have ABI stability at all, so it's probably best to just not do it.
20:20:41 <geekosaur> it may be possible to deal with cross-module inlining in this case, but difficult enough in other cases that it's n ot clear it's worth it, yeh
20:24:08 <rwe> That is a sad conclusion to come to  :-/ At least in my mental model of software ecosystems
20:44:35 <rwe> Here's why I think it's an important problem to solve, by the way. Maybe wrong, it doesn't seem to resonate with everyone.
20:44:50 <rwe> As development grows in Haskell, there become more "solved problems", packages available to build on top of. More tools for developers and more attractive for newcomers that want to be confident that they can use Haskell to solve whatever they're working on.
20:45:03 <rwe> But the flat version compatibility causes friction against adopting newer libraries, because doing so would prevent you from using older ones. Or from using older libraries, which would prevent you from your newer ones.
20:45:31 <rwe> And the middle ground being to avoid dependencies as much as possible and retread the same ground, which is a waste of effort (except pedagogically) for everyone involved. So the entire ecosystem slows down, relative to its own size, rather than speeding up.
20:46:52 <rwe> This is exacerbated by Haskell drawing in people who are interested-but-dont-have-to-commit, and so practical diffculties cause abandonment; and so you get an even broader spread of semi-abandoned packages; and so Haskell ecosystem becomes incrementally less efficient overall as time goes on, unless most development is centralized on those few well-maintained super-packages.
20:48:53 <rwe> That seems like a pretty worrisome outcome, if that model is accurate, and the expected utility of "gain wide adoption, because then you get more eyeballs, resources, tooling, and choice" is high, which I know isn't everyone's priority.
20:49:00 <maerwald> I don't see a fundamental tooling problem. Badly maintained packages is always a problem. When the ecosystem grows in professional adoption, people will care about it, pick stuff up, fix stuff, maintain stuff.
20:49:49 <maerwald> making it easy to use ancient packages is not that interesting
20:49:50 <rwe> I think that it's not an immediately fatal problem. You're right that badly maintained packages are always a problem in every ecosystem. I'm referring more to compounding effects of friction.
20:50:15 <rwe> I mean…it's not that interesting, but it can be pretty useful.
20:50:40 <maerwald> It can have negative effect even
20:50:48 <maerwald> because stuff somehow works, why update it properly
20:51:08 <rwe> Frankly, that's what I like about strong type systems. Because you're right. If it works, why update it properly.
20:51:42 <maerwald> Because types don't express runtime behavior
20:52:05 <maerwald> if they did, we wouldn't have versions at all
20:56:31 <rwe> Well, I kind of agree with that. Maybe from a different direction. I feel Haskell's type system is interesting but insufficient, overall. If types aren't expressing the runtime properties you care about, then types aren't really doing their jobs
20:57:08 <maerwald> You cannot (and should not) express everything in types
20:57:14 <rwe> But also — if something has buggy runtime behaviour, then that's a bug, you're right; it should be fixed. That's totally independent of being able to use old packages, though
20:57:39 <rwe> You should not express *everything* in types. You should express the properties that matter with types.
20:57:55 <maerwald> No, it's also about testing your package (library even) against the new stack of underlying dependencies with a test suite. Your types will not tell you behavior is correct.
20:58:55 <geekosaur> note that, having mentioned JS earlier, it's common to bundle the operations in the type (OO) which ameliorates this
21:06:28 <rwe> maerwald: Types are the interface boundaries. In every language, including Haskell, that's the purpose they serve: "This symbol foo, you can do this with it and when you do this you get that". So differences in runtime properties seem to me that they *should* be encoded in the types.
21:06:53 <rwe> (I realize this is deviating *way* away from the whole "nested modules discussion, though they do seem related now)
21:07:33 <rwe> I'm pretty convinced about the value of dependent types; I think any language that can't distinguish the properties of the functions "(* -1)" and "(+ 2)" is pretty limited in what it can tell you about your APIs
21:10:03 <rwe> geekosaur: Haskell kind of does this too with type classes and modules, no? I'd consider that to be isomorphic. Except that JavaScript does mutable objects, which interferes with soundness very fast :-/
21:10:53 <geekosaur> typeclasses sort of, but note what I said earlier; you can end up with weird errors because the instance it has is for the wrong version of the type, even if they're isomorphic or even representationally identical.
21:11:39 <maerwald> rwe: why? canoncializePath :: FilePath -> FilePath
21:11:47 <maerwald> now you change the type just because you fixed a bug?
21:12:01 <maerwald> Maybe someone already relies on the presence of that bug, you don't know
21:12:11 <rwe> geekosaur: Yeah, that's what I thought would be the most glaring problem, stuff like: `derive instance "base-4.9.0.0@Data.Monad" "base-4.12.0.0"@Data.Monad`
21:13:08 <rwe> maerwald: Yes, if you have a function that, say, takes in a vector of N objects; and you return a vector of N objects, and then you say "aw crap, I meant to remove the first element"…then that has a different type.
21:13:10 <maerwald> Types are not for expressing the entire behavior of a function
21:13:37 <maerwald> You wouldn't be allowed to write a function body at all if that was the case
21:13:39 <rwe> And if someone relied on the presence of that bug, then they would need to update their code to work with your new library, wouldn't they? How is that not normal?
21:14:26 <rwe> That's…not true. Types are not the same as implementations.
21:14:54 <maerwald> Exactly
21:15:18 <maerwald> Now prove to me that two implementations (algorithms) behave the same way... familiar problem?
21:15:23 <rwe> Yes!
21:15:24 <rwe> It is!
21:15:59 <rwe> That's what proof assistants are! Dependent types!
21:16:25 <MarcelineVQ> "<rwe> I'm pretty convinced about the value of dependent types;" Yes and dependent types make implementing api's safer because you have the ability to prove your gurantees, but your api boundry is not likely to be using those types because it makes the use of them unweild and users are exposed to the internals. the boundry will be an abstract type like you're used to seeing elsewhere, which means it won't have as strong a type at 
21:16:26 <MarcelineVQ> the boundry as you're probably wanting. grain of salt on that though, my dependent experience has been limited
21:16:43 <maerwald> rwe: Haskell is neither a proof assistant, nor does it have dependent types.
21:17:11 <maerwald> And deciding when two algorithms are the same is a tremendously difficult problem
21:17:27 <maerwald> Don't trust types.
21:23:29 <rwe> maerwald: Take a look at Agda. Within the context of Haskell, I agree with you and re-state that its type system is not sufficient. But if it were, it would be less of a problem. Because if you have a library exposing a function that "takes any integer and returns an integer", then the types of *your* use of that can't be made more specific by relying on unstated assumptions
21:24:06 <rwe> So if you say "my function takes a string and returns a positive number", then for that to be well-typed, you couldn't rely on an assumption that the library's exported function was positive. Because integers are a bigger set than positive numbers
21:26:22 <maerwald> rwe: Yes and guess why Agda and Idris have none to zero commercial users =)
21:26:39 <maerwald> You're trying to solve the wrong problem imo
21:30:44 <rwe> The same could have been said of Haskell not _too_ long ago. I point to Agda not because it's doing everything right or is widely adopted, but because I think it has some right ideas
21:31:14 <rwe> Eh. Maybe. People seem to like to solve the same problems over and over again. Why have computers verify stuff when we can get paid to do it manually?
21:33:49 <rwe> Thank you maerwald and geekosaur for the very nice discussion, by the way :) It's late in my TZ so I need to disconnect, but I appreciate you humoring me on these topics
21:34:55 <geekosaur> agda is going for precision, and losing usability in the process. there is some work on "dependent haskell" which is trying to chart a middle course, but it's not a thing as yet
21:35:57 <rwe> I agree. I hope things improve on all those fronts
21:37:53 <maerwald> I hope not
21:38:04 <maerwald> It will make haskell even less popular, imo
21:38:25 <geekosaur> well, it's not supposed to be required
21:38:35 <geekosaur> my understanding is that it's sort of "gradual dependent typing"
21:39:18 <geekosaur> of course this ends up like MarcelineVQ's comment about dependent types at api boundaries
21:52:17 <cocreature> Phyx-: iirc for 8.6.4 the bindists still had various issues (yes I know that’s not the same as GHC being broken but it’s still something users might hit)
21:54:45 <ski> jusss : any progress ?
22:56:06 <dminuoso> [CT] Does internalization of some feature F in a canonical category C always require C to be equipped with some doctrine?
22:57:02 <dminuoso> I was wondering whether basic ideas like finite products aren't internalization of the cartesion product from Set, for which you do not appear to require any doctrine.
23:05:49 * ski doesn't know about feature,canonical,doctrine
23:07:18 <dminuoso> ski: https://ncatlab.org/nlab/show/internalization
23:07:40 <dminuoso> ski: It all started with me looking at nlab to understand exponential objects more thoroughly. Then I saw something about internal hom, which lead me to internalizatoin.
23:07:48 <dminuoso> Wiki behavior on nlab is quite dangerous.
23:37:28 <bahamas> hello. I'm using this package to run Haskell on Spark: https://github.com/tweag/sparkle. I have this line, where I want to json decode text to a `Session` type, but I get this error: https://bpaste.net/show/bd1919b0cc2e. anyone know what I need to do?
23:39:19 <jgt> bahamas: it's asking you to write the instance
23:39:46 <jgt> so you would need something like `instance Static (Maybe Session) where`
23:40:03 <jgt> followed by the required methods of the Static typeclass
23:40:55 <jgt> maybe the Static instance for Session (as opposed to (Maybe Session)) is already defined, so it's possible all you need to do here is unwrap that Maybe type
23:48:00 <bahamas> jgt: hm, ok. I found the class here https://hackage.haskell.org/package/distributed-closure-0.4.1.1/docs/Control-Distributed-Closure.html#t:Static. but it's telling me I need an argument of kind Constraint
23:48:37 <Axman6> it may not be that Static class
23:49:09 <Axman6> ah looks like it is
23:49:24 <Axman6> you may find this useful https://skillsmatter.com/skillscasts/10632-static-pointers-closures-and-polymorphism
23:54:24 <bahamas> I think the constraint in this case is the "jvm-0.4.2:Language.Java.Reflect" part. but that's not exported by the package
23:54:46 <Axman6> by the jvm package?
23:58:18 <Axman6> Looks like Language.Java is exposed but its docs will likely fail to build on hackage - try building the docs locally to see more of the Static class
23:58:25 <Axman6> (or look at the source)
