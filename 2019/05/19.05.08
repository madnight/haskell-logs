00:00:15 <zincy> It was to do with the Either checking right
00:00:27 <jle`> it has to do with >>= for ReaderT
00:00:41 <jle`> which in turn delegates to >>= for Either
00:00:51 <jle`> which is strict on the LHS's left-or-rightness
00:01:34 <jle`> not on the actual value inside necessarily; it just has to evaluate enough to know if it's Left or Right. but this requires traversing the entire Exp tree to deduce
00:03:12 <jle`> Right x >>= f = f x
00:03:18 <jle`> Left e >>= _ = Left e
00:04:51 <jle`> r >>= f = ReaderT $ \x -> runReaderT r x >>= \y -> runReaderT (f y) x     -- ReaderT's >>= uses the >>= of the inner monad
00:17:30 <zincy> So in a monad transformer the bind of the inner monad is used
00:17:50 <zincy> and then the result is essentially `return`ed
00:22:06 <jle`> ReaderT is like that, at least.  and also most of the common monad transformers
00:22:22 <jle`> ReaderT doesn't add any extra control flow, but MaybeT and ExceptT do a bit more logic "over" the bind of the base monad
00:22:43 <jle`> one notable exception is ContT, which doesn't ever use the bind of the inner monad
00:24:03 <zincy> ContT is a bit special
00:25:02 <zincy> So ExceptT and MaybeT add the logic in of short circuiting right on top of the inne monad
00:25:04 <zincy> inner
00:26:42 <jle`> mt >>= f = MaybeT $ runMaybeT mt >>= \case Nothing -> pure Nothing; Just x -> runMaybeT (f x)
00:27:33 <jle`> so first it does bind with >>=, then it figures out whether or not to go on to the next action based on the result
00:30:38 <zincy> Do you lift a computation returning a Maybe x to get mt where x has to be the inner monad
00:30:59 <zincy> lift 
00:31:04 <zincy> oops
00:31:39 <zincy> lift is for lifting the inner monad into the outer monad so is analogous to return in a normal monad
00:31:47 <dminuoso> zincy: ListT (the generally correct version) is very special too.
00:32:04 <zincy> :t lift
00:32:05 <lambdabot> (Monad m, MonadTrans t) => m a -> t m a
00:32:53 <zincy> How does the List monad work
00:33:20 <zincy> It might be the only common monad I haven't used with >>=
00:33:28 <dminuoso> zincy: Have you ever used list comprehensions?
00:33:39 <zincy> Yes
00:33:43 <dminuoso> zincy: That.
00:33:51 <zincy> oh so I have used them
00:34:17 <zincy> I guess it does an operation on each element and then builds up a nested cons
00:34:40 <dminuoso> zincy: [x * 2 | ...] is equivalent to `do { ...; pure (x * 2) }`
00:35:20 <dminuoso> And each `... <- ...` corresponds to an equivalent `... <- ...` line in do-notation. iow you can replace all your list-comprehensions with do-notations very mechanically.
00:36:45 <zincy> > [ x*x | x <- [1..10], mod x 2 == 0 ]
00:36:47 <lambdabot>  [4,16,36,64,100]
00:36:55 <jle`> zincy: in the case of MaybeT, lift x = MaybeT (Just <$> x).  it's defined so that >>= for MaybeT essentially adds no extra logic
00:36:57 <zincy> How does the predicate map to Do notation
00:36:59 <dminuoso> zincy: guard
00:37:12 <dminuoso> zincy: so its *slightly* stronger than monad since it requires MonadPlus too
00:37:28 <jle`> since the result of runMaybeT returns a Just, we can see from the definition of >>= for Maybe that the case with Just will happen every time
00:37:56 <zincy> jle`: So no extra logic apart from wrapping values in Just?
00:38:08 <jle`> no extra logic in the context of >>= for MaybeT
00:38:19 <jle`> since it makes the case statement redundant
00:38:48 <jle`> lift is structured so that the >>= for the monad transformer basically just behaves like >>= for the underling monad
00:39:08 <dminuoso> jle`: So given: t : Σ (x : A). B(x), how does one consume a value with the type of a dependent sum? Im thinking you'd need something along the lines of: f: Π (x : A). A (x) -> C
00:39:25 <dminuoso> Oops. f: Π (x : A). D (x) -> C
00:39:26 <dminuoso> Of course.
00:39:33 <jle`> if you look at the definition of >>= for MaybeT above, just imagine that the Just x case gets run every time, so it's basically like hte case statement doesn't exist
00:40:10 <jle`> dminuoso: B(x), maybe
00:40:31 <dminuoso> jle`: Mmm. Oh right that makes sense (I was thinking it could be more general than that)
00:40:34 <jle`> or just a dependent pattern match will do
00:41:31 <zincy> jle`: yeah MaybeT only hides the machinery of the case analysis on the maybe type
00:42:27 <jle`> it might be fun to actually 'derive' lift, based on the law that >>= for the transformer becomes essentially >>= for the underlying monad 
00:42:38 <zincy> Is this sigma notation stuff possible to implement in Haskell or only Agda, Coq etc
00:42:53 <dminuoso> zincy: In limited form you can encode it in Haskell.
00:43:26 <jle`> the law is `lift m >>= \x -> lift (f m)` is equivalent to `lift (x >>= f)`
00:43:37 <jle`> * lift (m >>= f)
00:44:03 <jle`> so if you look at the definition of lift for MaybeT:
00:44:09 <jle`> mt >>= f = MaybeT $ runMaybeT mt >>= \case Nothing -> pure Nothing; Just x -> runMaybeT (f x)
00:44:16 <jle`> *bind for MaybeT
00:45:03 <jle`> you can say "the only difference is that you pattern match on the result, and if it's Just, things proceed as normal. so, if lift x = MaybeT (Just <$> x), we force the Just case, so things proceed as normal, as if we weren't even in MaybeT"
00:45:11 <dminuoso> jle`: Isn't GADT pattern matching a kind of dependent pattern match?
00:45:30 <jle`> dminuoso: yes, i would say that it is a dependent pattern match as realized in haskell
00:45:39 <zincy> jle`: :)
00:45:57 <zincy> Do people here find GADTS useful?
00:46:06 <dminuoso> zincy: Yes.
00:46:13 <zincy> Disclaimer I dont know what they are
00:46:15 <dminuoso> zincy: GADTs are a very natural and intuitive conclusion of ADTs.
00:46:16 <jle`> they are useful for certain applications
00:46:17 <kuribas> zincy: yes
00:46:22 <zincy> I just know they are. :)
00:46:23 <jle`> GADT syntax is useful in general, though, i believe
00:46:34 <kuribas> they generalise the types of constructors
00:46:47 <dminuoso> zincy: If you program for a while, you will on your own probably arrive in this channel, asking "Why cant I do ... with ADTs.." and the answer will be GADT. :)
00:46:47 <jle`> i don't think GADTs are a good general purpose useful tool, since probably most haskell projects wouldn't gain too much from using them
00:46:59 <zincy> kuribas: Which kinds of constructors?
00:47:07 <kuribas> zincy: data constructors
00:47:21 <jle`> i don't really know if GADTs are as prevalently useful as dminuoso claims. but they have their applications
00:47:34 <jle`> zincy: actually the situation you're writing right now with Exp is a very common 'hello world' kind of use case for GADTs
00:47:42 <zincy> So GADT's let you group types?
00:47:42 <kuribas> zincy: they allow you to hide information from the constructor, add information, or restrict the types of the constructor.
00:47:46 <zincy> sorry not types
00:47:50 <dminuoso> jle`: Not useful in the sense you will have broad applications, but I consider it likely you will encounter a problem at some point where GADTs are a good fit.
00:47:56 <zincy> groups of data constructors which span multiple types
00:48:21 <kuribas> zincy: hiding information = existential quantification
00:48:22 <jle`> zincy: not quite; it's more like it lets you have a little more power over what constructors you already have
00:48:43 <jle`> if i say data Maybe a = Nothing | Just a, i don't really have much to say about what Nothing and Just can do
00:48:54 <jle`> all i can say is that it makes Nothing :: Maybe a, and Just :: a -> Maybe a
00:49:15 <jle`> GADT gives you a little more features you can use with constructors
00:49:37 <zincy> interesting
00:49:55 <jle`> in the end the constructors are 'grouped' the same way as normal ADT's, but it's just you can give your individual constructors a bit more 'power', so to speak
00:50:42 <jle`> but also GADTs are never actually "required", i believe
00:50:45 <zincy> Generally speaking do you guys have any ideas for learning advanced concepts which might be alien to me by implementing them on top of this https://github.com/therewillbecode/functional-interpreter/blob/master/src/Interpreter.hs
00:50:55 <zincy> Say GADT's, typefamilies etc
00:50:57 <jle`> everything you can do with GADTs, you can do do with normal data types...just a lot more verbose
00:51:04 <zincy> ah right
00:51:18 <jle`> zincy: that type you have is a common example of a basic project that GADTs can help
00:51:26 <zincy> cool
00:51:33 <jle`> it's actually the exact example in the haskell wikibook for GADTs, heh
00:51:34 <jle`> https://en.wikibooks.org/wiki/Haskell/GADT
00:51:56 <zincy> nice!
00:52:06 <jle`> but yeah, almost all things you'll use GADTs for, you can do pretty easily with just normal data types
00:52:20 <zincy> hehe "GADTs are mainly used to implement domain specific languages"
00:52:43 <zincy> Does a lambda calculus like langauge count as a DSL
00:52:54 <zincy> Seems a bit too general to be domain specific
00:52:59 <jle`> i guess i shouldn't say 'almost all things', there is that grey area where GADTs might be preferable over multiple data declarations, but whether or not it's worth it is arguable
00:53:23 <jle`> zincy: what you are doing is pretty much what the article walks you through, heh
00:53:50 <jle`> although implementing a fully type safe lambda calculus using GADTs can get a bit involved
00:54:12 <jle`> implementing a partially type safe lambda calculus (expressions are type safe but variables can sometimes have the wrong type) is pretty straightforward
00:54:34 <jle`> actually hm the example they have has no lambda.
00:56:03 <zincy> Is implementing a typeOf function and using it at compile time sufficient to declare your language is statically typed
00:58:47 <ricky_clarkson> I don't think so. Otherwise you could implement a JavaScript compiler and say JS is statically typed, everything is of the static type 'dynamic'. Your typeOf function gives a constant output.
00:59:50 <kuribas> jle`: GADTs are nice for dependend typing
01:00:01 <dminuoso> zincy: The notion of "statically typed" really depends on what you mean by the term.
01:02:37 <zincy> I meant if you use the typeOf function to throw errors when there is a type mismatch at compile time
01:02:58 <zincy> ricky_clarkson: Typescript adds static typing to JS by doing that no?
01:05:50 <jusss> how to avoid assignment and keep or save a value?
01:06:13 <jusss> not just passing by
01:07:00 <dminuoso> jusss: what do you mean?
01:07:18 <dminuoso> Haskell does not have the intrinsic notion of assignment. It's closer to naming an expression.
01:08:07 <Maxdamantus> zincy: what would this "typeOf function" return for a term whose type depends on a type parameter?
01:11:23 <jusss> dminuoso: like in other languages, we can do a=1, and a=a+1, this is a assignment, and this is not good,right?
01:11:36 <dminuoso> jusss: I prefer not to judge it.
01:11:46 <jusss> dminuoso: but sometimes we do need a variable to store someting
01:12:21 <dminuoso> jusss: So using where/let you can name expressions.
01:13:25 <jusss> dminuoso: do you know python?
01:13:27 <dminuoso> Yes.
01:13:35 <Solonarv> > let xs :: [a]; xs = [] in typeOf xs
01:13:37 <lambdabot>  error:
01:13:37 <lambdabot>      • No instance for (Typeable a0) arising from a use of ‘typeOf’
01:13:37 <lambdabot>      • In the expression: typeOf xs
01:13:41 <Solonarv> Maxdamantus: ^
01:14:09 <Solonarv> i.e. it doesn't work; there needs to be a Typeable instance for typeOf's argument
01:14:31 <jusss> dminuoso: you're not in #python, I have a little python assignment problem,
01:15:32 <Maxdamantus> Solonarv: well, that `typeOf` function is semantically dynamic.
01:15:39 <Solonarv> Maxdamantus: no, it is not
01:15:54 <Maxdamantus> Solonarv: it's applied upon invocation of the function.
01:16:03 <Solonarv> incorrect
01:17:04 <dminuoso> jusss: Haskell requires you to rethink how problems are solved. Many languages like Python want you to solve every problem with these mutable memory references you call variables. Haskell promotes a different line of thinking.
01:17:20 <jusss> like there's variable called isSomethingRunning to check is something running, and several function change its value, it's a Bool value
01:17:23 <Maxdamantus> > let f x = typeOf x in 5
01:17:25 <lambdabot>  5
01:17:36 <Maxdamantus> What's the invocation of `typeOf`?
01:17:43 <dminuoso> jusss: So the first step to encode it, is with recursion.
01:18:28 <dminuoso> jusss: A recursive function with one or more parameters. You can then change the parameters in each recursion step giving the same behavior of "mutable variables"
01:18:32 <Solonarv> Maxdamantus: the type of 'f' here is either Integer -> TypeRep or (forall a. Typeable a -> TypeRep)
01:18:38 <dminuoso> Other techniques exist too, but start with that.
01:18:41 <jusss> the thing is that several functions change its value, make other functions not work, like a global variable in threading 
01:18:59 <jusss> dminuoso: but python doesn't have TCO
01:19:08 <jusss> dminuoso: so recursion will crush
01:19:15 <Maxdamantus> Solonarv: it should be the latter. The function is never even denoted as being called.
01:19:29 <jusss> I don't know do haskell have TCO?
01:19:30 <Solonarv> Maxdamantus: oh, of course
01:19:35 <dminuoso> jusss: Essentially, yes.
01:19:37 <Maxdamantus> Solonarv: but even if it were denoted, `typeOf` is still not necessarily called.
01:19:43 <Solonarv> I somehow misread your snippet and didn't notice that f is completely unused
01:19:46 <dminuoso> jusss: However, its much different because our execution model is vastly different.
01:19:51 <Solonarv> in which case it is indeed never called
01:19:54 <dminuoso> jusss: Functions are not realized as calls that are entered and exited.
01:21:04 <dminuoso> jusss: In general tail-recursion is good in Haskell, its not a big deal.
01:21:09 <Maxdamantus> also, since `Typeable` can have instances that are produced through polymorphic recursion, there's no way for `typeOf` to be guaranteed "static".
01:21:36 <Maxdamantus> Semantically, you get a `TypeRep` at runtime, not at compile time.
01:21:44 <jusss> dminuoso: how to solve that problem cause by threads changing one global vairbale?
01:21:54 <Solonarv> yes, which is implemented by dictionary passing
01:22:16 <Maxdamantus> any type errors to do with `TypeRep`/`Typable` should only be subject to the regular typing rules in Haskell.
01:22:25 <dminuoso> jusss: So thats a complex topic really. We have various tools at our disposal.
01:23:26 <jusss> dminuoso: is there a common way?
01:23:51 <dminuoso> jusss: Its very situational really. Perhaps the architecture can be redesigned to not rely on shared global state
01:23:58 <jusss> dminuoso: I heard that stuff call STM Act-Model Async what ever
01:24:24 <dminuoso> jusss: Right, STM is a great toolbox that we use.
01:24:24 <Solonarv> jusss: yes, usually if we want to mutate shared state from multipe threads we create an MVar, TVar, or similar and pass that to the various threads that need to modify it
01:24:40 <dminuoso> Or, alternatively to what Solonarv said, it can be beneficial to rely on message passing styles rather.
01:24:50 <dminuoso> Shared global state can be extremely difficult to reason about
01:25:02 <dminuoso> And depending on the performance characteristics it can scale very poorly
01:25:34 <Solonarv> true
01:25:42 <Solonarv> but if you want it, we do have it in Haskell
01:26:01 <dminuoso> We also do have raw mutable memory references (like python variables)
01:26:08 <Solonarv> and of course all the nicer concurrency abstractions are ultimately built on mutable shared state
01:26:19 <dminuoso> But they dont exist to solve all your problems, but rather as a primitive for special edge cases.
01:26:55 <jusss> what's the easiest?
01:27:08 <dminuoso> jusss: Depends on the situation really.
01:27:38 <Solonarv> they're still easier to reason about than plain old global variables, because they can't be modified from just anywhere - only from functions that you actually pass them into, and only if those functions are IO/STM/etc
01:27:56 <kuribas> what's nice is that with lazyness you can have near instant updates to shared mutable state, so the lock is there only for a fraction of time.
01:28:15 <Unhammer> Can stack use a globally installed hoogle for all my repos, or does it need to be installed per resolver?
01:28:36 <dminuoso> jusss: I suggest you start praciting the basic functional principles, like encoding state via parameters in functions.
01:28:38 <Solonarv> on the one hand, yes; on the other hand, that can easily lead to work not happening in the thread you thought it was
01:28:42 <dminuoso> And get a hang for it, it's a very very common theme in Haskell.
01:28:54 <dminuoso> Much more common than mutable memory references.
01:29:02 <Solonarv> indeed
01:29:09 <jusss> dminuoso: for example? 
01:29:19 <dminuoso> jusss: Say quicksort.
01:29:40 <Nevoic> Pretty random vim question, does anyone know if there's anyway to prevent the buffer from moving up when the command line grows (i.e to show text result from a command)? I have a command that shows up to 10 lines at the bottom, and it ends up pushing my buffer up 10 lines to where I can't actually see the code I'm inspecting, which is kind of annoy
01:29:41 <Nevoic> ing.
01:29:57 <Solonarv> I do use mutable references not infrequenty, but I almost always wrap a layer over it instead of mutating stuff directly (or use someone else's layer)
01:30:51 <dminuoso> Solonarv: Oh they have plenty of uses, but if a beginner starts using them, all the code will be in IO using IORefs, writing essentially C-style code in Haskell. :-P
01:30:54 <jusss> dminuoso: but that depends recursion
01:31:00 <dminuoso> jusss: Yes, doesn't it.
01:31:07 <dminuoso> jusss: Recursion is not bad. :-)
01:31:18 <dminuoso> Its how you encode loops in Haskell too.
01:31:23 <jusss> dminuoso: and not anyone language support TCO
01:31:23 <dminuoso> Well. One way at least.
01:31:30 <Solonarv> it won't blow the call stack, that's not how Haskell works
01:31:43 <dminuoso> jusss: Sure, but you are learning Haskell, no?
01:31:53 <jusss> dminuoso: I know that, I did that in scheme a lot of time
01:32:01 <Solonarv> jusss: well, not every language has TCO, but Haskell does (or rather, something equivalent given Haskell's evaluation model)
01:32:19 <tdammers> scheme has a completely different execution model than Haskell though, which is why it needs TCO to be able to do efficient recursion
01:32:37 <tdammers> depending how you look at it, Haskell either has TCO, or doesn't need it
01:32:54 <Solonarv> "recursion is bad in other languages because it can make the stack explode" doesn't mean it's bad in Haskell
01:33:15 <dminuoso> I prefer the "doesn't need it" model because it doesn't trick you into thinking Haskells execution model is similar to many other languages.
01:33:25 <Solonarv> indeed you can write functions which mimick while, for and all these imperative looping construct; and they're implemented using... recursion!
01:34:02 <dminuoso> And then you discover recursion schemes and do it under the sheets! :-p
01:34:28 <tdammers> also, recursion that does the same thing as a typical imperative loop tends to expose the same time and space complexity in Haskell as the imperative loop would in a strict language
01:35:09 <dminuoso> jusss: The essence is basically: If you have a loop, try and encode it with recursion. If you have a kind of "state" that needs to change, add a parameter to your recursive function.
01:35:11 <tdammers> to see this in action, all you need to do is recursively iterate over an infinite list while watching the program's memory consumption in, say, htop
01:35:32 <Solonarv> and sometimes (especially when it's strict tail recursion) the recursive Haskell code will even produce native code that looks suspiciously like what you'd get from an imperative loop in a different language
01:35:50 <dminuoso> It's not the "ideal for all purposes" solution, but it's a good technique to have later, and it trains rethinking in haskell terms.
01:37:23 <jusss> dminuoso: except recursion, is there other way?
01:37:40 <Solonarv> > foldl' (+) 0 [1..10^7] -- this list would use a bit under 2 GB if fully evaluated, try it in ghci and see that it uses way less
01:37:43 <lambdabot>  50000005000000
01:37:46 <dminuoso> jusss: If I say yes, would you still use recursion? :-)
01:37:59 <jusss> I do love recursion, but some lanugaes don't have TCO, and I use them at work
01:38:07 <Solonarv> jusss: yes, use some functiont that does the recursion for you
01:38:14 <Solonarv> :>
01:38:19 <dminuoso> jusss: What's the deal with other languages?
01:38:25 <jusss> dminuoso: dminuoso a simple example?
01:38:37 <jusss> dminuoso: js and python both don't
01:38:39 <dminuoso> jusss: So?
01:38:50 <dminuoso> jusss: Are you trying to figure out writing code that works exactly the same in all three languages?
01:39:14 <jusss> dminuoso: yeah, a common way
01:39:18 <dminuoso> Haskell is simply different, trying to write code the same way you would in JS/Py throws away all the benefits you'd get from Haskell and adds no benefit.
01:39:23 <jusss> work on all languages
01:39:47 <Solonarv> I guess if you use a function to handle the recursion/looping for you the code ends up looking somewhat similar
01:40:08 <dminuoso> Well, the similarity only becomes obvious once you have reached a certain level of proficiency though.
01:40:42 <dminuoso> jusss: https://gist.github.com/dminuoso/ebf43f159afc5719473e091a6d0665e0
01:40:55 <dminuoso> jusss: This is an excerpt from a crypto routine where I encode a loop inside `go` using recursion.
01:40:55 <jusss> Solonarv: you mean Trampolining?
01:41:09 <dminuoso> The three parameters are my three "mutable variables".
01:41:26 <dminuoso> Writing this in imperative style would make it unreadable and error prone.
01:41:34 <Solonarv> 'map (\x -> x*2+1) [1..10]' vs. 'map(lambda x: x*2+1, range(1, 11))' vs. '[1,2,3,4,5,6,7,8,9,10].map(x => x*2+1)'
01:41:46 <Solonarv> in this simple example the difference are almost purely syntactic
01:41:54 <Solonarv> (in order: haskell, python, JS)
01:42:02 <jusss> trampoline-function-recursive-TCO
01:42:08 <Solonarv> but the exact runtime behavior of these varies
01:42:54 <dminuoso> jusss: It's like: I want a single tool that works on all screws, I dont care one is a philips head, one is a torx and one is a flathead. Dont you have a single screwdriver that works on all?
01:43:19 <dminuoso> The elegant solution is to pick the screwdriver (= technique) that fits your screw (= language).
01:43:36 <dminuoso> The inelegant solution is to pick a flathead and forcibly use it to unscrew all screws regardless of the head.
01:44:01 <kuribas> dminuoso: you can also drill a groove in your screw and use a flathead :-)
01:44:19 <kuribas> adapt the problem to the tool
01:45:00 <zincy> so typeOf is a runtime function silly me
01:45:35 <dminuoso> jusss: Haskell has very special features like a very expressive type system, lazy evaluation and algebraic data types that add so much value to programming that it's refreshing.
01:45:42 <zincy> At what part of the compiler toolchain is typechecking done
01:45:58 <Solonarv> zincy: quite early, actually - even before desugaring
01:46:02 <dminuoso> jusss: The common denominator of those languages is simple "imperative sequencing of commands and mutable memory references" with no language features.
01:46:40 <zincy> Solonarv: So literally after the parsing stage you walk through the AST and essentially run something analogous to typeOf
01:46:41 <dminuoso> zincy: https://www.aosabook.org/images/ghc/hscpipe2.png
01:46:58 <dminuoso> zincy: Typechecking could also be done after desugaring.
01:47:26 <Solonarv> zincy: no, the typechecking algorithm doesn't work by just trying to answer "what type is this" in a bottom-up manner
01:47:43 <zincy> Oh of course
01:47:56 <Solonarv> instead GHC walks over the AST and generates a bunch of constraints which look like "this type should match that type"
01:48:01 <dminuoso> zincy: typeOf is a vastly different beast. it has nothing to do with type checking.
01:48:07 <zincy> typechecking depends on whether you are using implicit or explicit types
01:48:13 <dminuoso> zincy: its rather that typeOf is recovering what the type checker has already found out.
01:48:14 <Solonarv> then once it has a big bag of constraints it solves them all together
01:48:22 <zincy> ah
01:48:34 <dminuoso> zincy: that is, imagine the type checker hanging a tag on each expression denoting what type it is (and each sub expression). typeOf reads out that tag.
01:48:55 <dminuoso> the typeOf happens at runtime, but the typechecking was done much earlier in compilation.
01:48:56 <zincy> So how does that differ in a language with dynamic types
01:49:01 <zincy> gotcha
01:49:45 <Solonarv> in a language with dynamic types, you don't typecheck :>
01:49:56 <dminuoso> zincy: Its rather runtime tags
01:50:07 <dminuoso> zincy: kind of like a giant sum type.
01:50:14 <Solonarv> in most (?) dynamically typed languages each value points back to its type definition somehow
01:50:47 <zincy> So when the expression is evaluated it is assigned a type
01:50:47 <dminuoso> zincy: So imagine you have: data Object = OArray Object | OString String | OInteger Integer
01:51:02 <dminuoso> zincy: So the type of each thing is Object, but the constituent part is a runtime flag.
01:51:09 <jusss> dminuoso: it taks a long time to learn haskell, and only a few people use it at work
01:51:33 <dminuoso> jusss: The value of learning it can be high though.
01:51:37 <dminuoso> jusss: Even if you dont end up using it.
01:51:48 <jusss> and the most people use like python java at work
01:52:10 <dminuoso> jusss: Im going to argue that learning Haskell and getting comfortable with it will make you a better java or python programmer.
01:52:17 <jusss> dminuoso: yeah, I want to learn it 
01:52:23 <maerwald> dminuoso: python maybe, java no
01:52:43 * Solonarv . o O ( profunctor optics in java )
01:52:50 <dminuoso> zincy: So the "type" word is a bit dangerous.
01:52:52 <Rembane> Solonarv: Is it a good idea? :D
01:53:00 <Solonarv> Rembane: I have no idea tbh
01:53:10 <maerwald> if you start worrying about state and effects, you will be too scared to create any new class...
01:53:14 <Taneb> Solonarv: wasn't there profunctor optics in the portion of the Minecraft source code they released/
01:53:18 <maerwald> and your java productivity drops :P
01:53:20 <Solonarv> I haven't really looked at the library, but it seems like it would be really clunky to use
01:53:27 <Solonarv> Taneb: yes, that is what I was referring to
01:53:52 <dminuoso> zincy: So Pierce defines the term type as follows: A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute.
01:54:09 <dminuoso> zincy: Here, the important part is that its a syntactic method.
01:54:14 <jusss> dminuoso: maerwald and what about c#
01:54:21 <jusss> I heard it has type too
01:54:35 <jusss> and no one use it nowadays
01:54:37 <maerwald> haven't really learned or used it, but I know some haskellers like it
01:54:37 <tdammers> maerwald: or you could just gain the insight that mutable state is something to be aware of, and while you have to use it more often that you should in java, it's still good to be aware of it in the first place
01:54:39 <zincy> What is a syntactic method? Using the syntax to infer?
01:54:46 <dminuoso> zincy: So my point is not as much "python does not have a type system", but rather when people talk about "python has dynamic types", they still have valuable opinions even though they picked a poor term.
01:55:00 <dminuoso> zincy: Right! For example a type annotation.
01:55:04 <Solonarv> "no one uses C# nowadays"? wow, where'd you hear that nonsense?
01:55:19 <maerwald> C# is very well supported and maintained
01:55:30 <maerwald> haskell cannot compare with that level
01:55:38 <Solonarv> zincy: or something like 'I know that f :: A -> B and x :: A, so therefore f x :: B'
01:56:29 <jusss> maerwald: and its type system?
01:56:45 <zincy> inferring a values type /= type inference?
01:57:11 <tdammers> technically speaking, type inference infers the type of an expression, not the type of a value
01:57:21 <dminuoso> zincy: Its not values that have types, but expressions.
01:57:23 <Solonarv> IIRC the type system of C# is vaguely similar to Java's but with a bit less idiocy
01:57:34 <tdammers> at least if you subscribe to the notion that term-level values only exist at runtime
01:57:35 <dminuoso> zincy: If you read the definition again:
01:57:36 <Solonarv> I haven't used it though, so I'm not entirely sure
01:57:45 <dminuoso> zincy: ... "by classifying phrases according to the kinds of values they compute."
01:57:50 <dminuoso> zincy: "phrases" are classified. not values.
01:58:07 <dminuoso> where phrase should be understood as "an expression/statement" in the language.
01:58:12 <dminuoso> or some "fragment" of code perhaps.
01:58:31 <tdammers> .oO( the "expression / statement" duality makes absolutely no sense )
01:58:34 <zincy> So static type systems assign types to expressions (phrases) whereas values always have types
01:59:08 <dminuoso> tdammers: duality?
01:59:32 <dminuoso> zincy: the notion of values is absent in a type checker.
01:59:47 <zincy> ah ok
01:59:53 <tdammers> dminuoso: the idea of "expressions" and "statements" being fundamentally different beasts
02:00:18 <dminuoso> tdammers: it was not meant as "fundamentally different beasts". I was trying to name different terms to show what `phrases` is trying to generalize.
02:00:29 <dminuoso> Sorry if that was confusing.
02:00:54 <tdammers> dminuoso: yes, I know. IMO one might as well just say "expressions" though
02:00:58 <dminuoso> tdammers: Fair enough.
02:01:13 <tdammers> especially when discussing Haskell, where "statements" are really just expressions of a particular type
02:01:24 <tdammers> (or a class of types)
02:02:26 <zincy> The main takeaway seems to be type systems classify phrases not values
02:02:47 <tdammers> yes
02:02:47 <zincy> The difference being values are evaluated phrases?
02:03:00 <zincy> This is compile time (before evaluation?0
02:03:01 <tdammers> kind of
02:03:17 <dminuoso> zincy: There is a relationship to the values though.
02:03:17 <tdammers> but the most important thing here is that values live at runtime, whereas types (and expressions) live at compile time
02:03:33 <dminuoso> zincy: A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute.
02:03:39 <tdammers> you'll see people say that "values inhabit types", and you can (crudely) think of a type as a set of values
02:03:42 <dminuoso> So the classification is related to the kind of values they compute.
02:03:55 <dminuoso> Though one could generalize and toss it away to broaden the notion of type system.
02:04:18 <zincy> kinds of values = types?
02:04:26 <tdammers> so if a type is a set of values, then a type checker's job is to prove that the values that a certain expression can evaluate to are in the set that the expression's type represents
02:04:32 <dminuoso> Right, and types are classified under "kinds"
02:04:35 <dminuoso> in Haskell anyway
02:04:51 <dminuoso> So this notion of a type system exists on multiple levels
02:04:59 <zincy> and types can be promoted to kinds
02:05:06 <zincy> and values to types
02:05:12 <dminuoso> zincy: not promoted to kinds.
02:05:17 <dminuoso> the kind system is the type system of types.
02:05:38 <dminuoso> So within the type system you have another type system in Haskell.
02:05:38 <zincy> Im thinking of datakinds
02:05:49 <zincy> kind of data is types
02:07:20 <zincy> tdammers: how does the "prove" bit happen
02:07:32 <dminuoso> zincy: By employing an automated theorem prover.
02:07:53 <zincy> So does C's type checker have an automated theorem prover?
02:08:03 <dminuoso> It *is* one, in some sense.
02:08:17 <dminuoso> Though C is a particularly bad example for many reasons.
02:08:21 <dminuoso> Java would be a better pick.
02:08:33 <zincy> Aren't all type checkers automated theoreom provers?
02:08:47 <dminuoso> Yes in some sense.
02:09:19 <zincy> Although you could formally verify a type checker
02:10:12 <dminuoso> You probably should, in fact.
02:10:39 <zincy> So is it fair to say that statically typed languages do typechecking on expressions before evaluating them?
02:11:01 <dminuoso> zincy: The rawest type checker widely in use is the flow type checker in the JavaScript community.
02:11:23 <zincy> In what sense is it raw?
02:12:05 <dminuoso> The type annotations are in comments, the type checker reads those syntactic portions, runs its type checking algorithm and tells you "looks good" or "does not look good"
02:12:10 <dminuoso> You can still run the program if you want.
02:12:25 <dminuoso> The type checker is not glued into a program compilation pipeline.
02:12:34 <dminuoso> It's just a completely isolated type checker.
02:14:23 <tdammers> the main consequence of that is that you cannot have type-based polymorphism, that is, the compiler cannot choose different behaviors based on the type of something
02:14:23 <anatole> Hi ! I am new to Haskell, and trying to get a nice testing workflow going on my computer. I'm used to do that with emacs, and as such I'm trying to configure haskell mode. But it seems to require global installs (hasktags, stylish-haskell)... I don't know what you would suggest : should I still try to make global installs, if so, how ? Or should I get used to create projects, even if right now, my main objective is only to get a nice
02:14:23 <anatole> way to learn (i.e. one text editor and GHCi next to it) before even knowing how the language exactly works ?
02:15:20 <dminuoso> tdammers: And another consequence is that you cant use type information for optimization purposes either.
02:15:41 <zincy> flow has type-based polymorphism no?
02:15:58 <dminuoso> zincy: flow has no program output. 
02:16:05 <zincy> I am thinking of type variables which it has I think
02:16:13 <dminuoso> zincy: flow essentially just tells you "type checks" or "does not typecheck"
02:16:16 <dminuoso> nothing more.
02:16:18 <zincy> ah
02:18:03 <zincy> anatole: You could always just use VSCode with the Haskell plugin for a quick way to start
02:19:30 <anatole> zincy: I'm actually trying to use as few proprietary softwares as possible...
02:19:55 <Solonarv> well, you'll be happy to hear that VSCode is actually open source :P
02:19:58 <maerwald> https://github.com/microsoft/vscode 
02:20:12 <maerwald> I guess everyone thinks "proprietary" when they hear microsoft :)
02:22:33 <anatole> From what I've heard, it is a dual license right ?
02:23:22 <Solonarv> https://github.com/microsoft/vscode/blob/master/LICENSE.txt - MIT licensed
02:24:06 <maerwald> don't listen to people :P
02:24:32 <Solonarv> there is also https://github.com/VSCodium/vscodium which is a VSCode build without the MS telemetry and branding, but otherwise identical AFAICT
02:24:54 <zincy> Otherwise you lose the telemetry by building from source apparantly
02:25:09 <Unhammer> <Unhammer> Can stack use a globally installed hoogle for all my repos, or does it need to be installed per resolver?
02:25:12 <Solonarv> ah - the "not-FLOSS" license is for the binary downloads offered by MS
02:25:12 <Unhammer> … seems it can, if I just `( cd && stack install hoogle )` and ensure ~/.local/bin is in PATH :)
02:25:19 <Unhammer>  
02:26:26 <dminuoso> Okay so dependent typing seems extremely intuitive,.
02:26:32 <dminuoso> I thought it was complicated... :<
02:27:18 <[exa]> dminuoso: it is complicated, but only for the typechecker :]
02:28:39 <anatole`> I decided to try out vscodium, thanks for the advice !
02:30:38 <dminuoso> [exa]: My main difficulty was thinking of it as kind of "functions", but realizing it's rather universal/existential quantification made things easy for me.
02:30:46 <dminuoso> So it seems I just needed to find the right mental model.
02:43:55 <freeside> question. I have a list of string infixes that i want to find in a string: ["/",":",".."] `areInfixesOf` "/some/file/path". if i were working against a list of filepaths, I could isInfixOf <$> infixlist <*> pathlist. But is there some idiomatic way to just search against a single filepath rather than a list of filepaths? hoogle returns "liftOp" for a type search for (a -> b -> c) -> [a] -> b -> [c]
02:45:05 <freeside> I plan to Data.List.or the [c] which is [Bool] to see if any of the infixes matched
02:46:22 <Solonarv> > map (\i -> i `isInfixOf` "/some/file/path") ["/",":",".."]
02:46:24 <lambdabot>  [True,False,False]
02:46:41 <freeside> is there some idiomatic way to do it without the lambda?
02:47:08 <freeside> some sort of punctuation inside < >
02:47:11 <Solonarv> yes, using an operator section:
02:47:12 <Solonarv> > any (`isInfixOf` "/some/file/path") ["/",":",".."]
02:47:14 <lambdabot>  True
02:47:31 <freeside> ah, thank you
02:47:32 <Solonarv> note: any f xs = or (map f xs)
02:49:38 <freeside> what if i want to move things around so that the "/some/file/path" would sit at the rightmost end of the function definition? i believe i am groping toward something like point-free style
02:49:49 <[Leary]> > or $ isInfixOf <$> ["/",":",".."] <*> pure "/some/file/path"
02:49:51 <lambdabot>  True
02:50:21 <Solonarv> @pl any (`isInfixOf` "/some/file/path") ["/",":",".."]
02:50:22 <lambdabot> any (`isInfixOf` "/some/file/path") ["/", ":", ".."]
02:50:31 <Solonarv> oh, right
02:51:01 <Solonarv> @pl \needles hay -> any (`isInfixOf` hay) needles
02:51:02 <lambdabot> flip (any . flip isInfixOf)
02:51:17 <freeside> so the pure squishes my single argument into an invisible list so we can use <*>
02:51:17 <Solonarv> :D
02:51:33 <Solonarv> not an "invisible list", just a one-element list
02:51:49 <Solonarv> pure "path" here is the same as ["path"]
02:52:21 <freeside> gotcha
02:52:40 <kuribas> freeside: pointless isn't idiomatic
02:53:05 <freeside> i was poking around and found (??) in Lens
02:53:21 <Solonarv> :t (??)
02:53:22 <lambdabot> Functor f => f (a -> b) -> a -> f b
02:53:25 <kuribas> freeside: and never use the function (reader) monad, unless you want to obfuscate
02:53:30 <kuribas> deliberately
02:59:46 <aveltras> is there any reason to use the rec keyword over the mdo with the RecursiveDo extension ?
03:00:58 <Solonarv> aveltras: yes; making it more explicit exactly which bindings are mutually recursive
03:02:40 <aveltras> Solonarv: ok thx
03:16:45 <freeside> what's the difference between these two formulations? inside a main do:
03:16:52 <freeside>   when (True) $ putStrLn "blah"
03:16:52 <freeside>   when (True) $ do putStrLn "blah"
03:18:45 <opqdonut> nothing
03:18:59 <opqdonut> "do x" is equivalent to "x"
03:19:20 <freeside> but i can't say do $ do $ do
03:19:44 <opqdonut> no
03:19:53 <opqdonut> do is special syntax
03:20:35 <opqdonut> see the box on https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-470003.14
03:20:43 <freeside> any sufficiently advanced technology is indistinguishable from magic
03:20:44 <opqdonut> for what the do-syntax translates to
03:20:56 <opqdonut> it has an explicit rule for `do e == e`
04:05:11 <habbah> I am trying to perform the example query in the postgresql-simple README and I am receiving errors which I don't understand. Is someone available open to helping me out? https://gist.github.com/mcbahson/e5e3212a918a5ace87b3858bee9ce095
04:07:42 <phadej> habbah: add :: IO [Only Int]
04:08:00 <phadej> ghci doesn't know which type to decode the payload to
04:12:00 <habbah> Thank you so much! I was adding type annoations, but I didn't know what it should be. I'm guessing and hoping this becomes intuitive over time
04:13:21 <phadej> the ghci usage is not optimal, as there are too little "context" to infer the types
04:13:48 <phadej> in a complete program, you'd do something with he result which would disambiguate ethem
04:19:03 <dminuoso> :t (??)
04:19:05 <lambdabot> Functor f => f (a -> b) -> a -> f b
04:19:16 <dminuoso> So after staring at this for a few minutes, this seems like black magic.
04:19:45 <dminuoso> Until you realize its not.
04:20:33 <Taneb> > [(*2), (*3), (+2)] ?? 10
04:20:35 <lambdabot>  [20,30,12]
04:20:58 <Taneb> It only has one possible suitably well defined implementation, I think
04:23:19 <dminuoso> Taneb: Ah I was looking at the code examples in the haddock documentation, and it looked like black magic.
04:30:17 <tty1_> So i think i realized why the idea of kinds were confusing me... Mostly because they are treated a little like functions (in the sense that you can have partial application) but are not in any way actually a function. .. so "* -> *" doesnt mean it takes one thing and returns another... It really just means it is missing a parameter in order to be concrete (an actual type rather than a half-completed representation of a ty
04:30:17 <tty1_> pe)... does that sound about right?
04:30:39 <dminuoso> tty1_: They are actually a kind of function.
04:30:50 <dminuoso> tty1_: So imagine `Maybe` as taking a type and giving you a new type back.
04:31:02 <tty1_> dminuoso: ahh i was wondering if they might be some how.. but i cant picture any way of using it as such
04:31:05 <lyxia> tty1_: what's the difference between "missing a parameter" and "function"
04:31:13 <dminuoso> The new type simply has no name.
04:31:17 <tty1_> like how can i pass something into Maybe dynamically (not Just, but Maybe itself)
04:31:29 <dminuoso> tty1_: Dynamically in what sense?
04:32:55 <tty1_> dminuoso: hmm thats fair `Maybe Integer` resolves to some no name type and so does `Maybe`.. i can dig that.. but then is thee some way to programatically/dynamically pass in the argument to Maybe... I know this wont work buyt something like {a = Integer; (Nothing :: (Maybe a)) }
04:33:56 <dminuoso> tty1_: Sort of.
04:34:08 <dminuoso> tty1_: Take this for example:
04:34:10 <tty1_> dminuoso: can you show me an example that does something like i just tried to show?
04:34:22 <dminuoso> % fabricate = Proxy a -> Maybe a; fabricate = Nothing
04:34:23 <yahb> dminuoso: ; <interactive>:31:21: error: parse error on input `->'
04:34:28 <dminuoso> % fabricate :: Proxy a -> Maybe a; fabricate = Nothing
04:34:28 <yahb> dminuoso: ; <interactive>:32:46: error:; * Couldn't match expected type `Proxy a -> Maybe a' with actual type `Maybe a0'; * In the expression: Nothing; In an equation for `fabricate': fabricate = Nothing; * Relevant bindings include fabricate :: Proxy a -> Maybe a (bound at <interactive>:32:34)
04:34:37 <tty1_> dminuoso: right now in my head the closest thing i can think of to a kind isnt a function at all but the definition of a generic in Java (and similar concepts in other languages)
04:34:41 <dminuoso> % fabricate :: Proxy a -> Maybe a; fabricate _ = Nothing
04:34:41 <yahb> dminuoso: 
04:34:47 <dminuoso> % fabricate (Proxy :: Int)
04:34:47 <yahb> dminuoso: ; <interactive>:34:12: error:; * Couldn't match expected type `Int' with actual type `Proxy t0'; * In the first argument of `fabricate', namely `(Proxy :: Int)'; In the expression: fabricate (Proxy :: Int); In an equation for `it': it = fabricate (Proxy :: Int); <interactive>:34:12: error:; * Couldn't match expected type `Proxy a' with actual type `Int'; * In the first argumen
04:34:50 <dminuoso> % fabricate (Proxy :: Proxy Int)
04:34:51 <yahb> dminuoso: Nothing
04:34:54 <dminuoso> % :t fabricate (Proxy :: Proxy Int)
04:34:54 <yahb> dminuoso: Maybe Int
04:35:14 <dminuoso> tty1_: Kinds are to types as types are to values.
04:35:23 <dminuoso> tty1_: So if types classify values, then kinds classify types.
04:35:56 <dminuoso> tty1_: So `Maybe` for example is a type level construct, you could call it a type if you want, but it has no values.
04:36:06 <dminuoso> `Maybe Int` is also a type level construct, a type, but it has values.
04:36:10 <tty1_> dminuoso: yes I understand that aspect now (thanks though)... But that is also true of generic definitions in java. Not exactly the same i know but similar
04:36:33 <tty1_> dminuoso: wait whats the difference between Int and Integer?
04:36:51 <dminuoso> tty1_: Int is bounded, Integer is not.
04:37:02 <dminuoso> tty1_: They are very different from another.
04:37:16 <tty1_> ohhh So Integer is like BigInteger in java I guess and Int is like int
04:37:25 <tty1_> I know not exactly the same, but similar
04:37:45 <dminuoso> tty1_: The implementation is different, but conceptually it's the same.
04:38:03 <tty1_> right
04:38:14 <dminuoso> tty1_: So why is it that Maybe has no values?
04:38:51 <dminuoso> tty1_: It's because `Maybe` is not a "concrete" type, it's a kind of function that is not fully applied yet. So the kind system lets you describe this way of "is this a function.. how many arguments does it take, and what kind of arguments does it need"
04:38:54 <dminuoso> % :k Maybe
04:38:54 <yahb> dminuoso: Maybe :: * -> *
04:39:05 <dminuoso> This means, Maybe takes one type argument of kind `*`
04:39:09 <tty1_> dminuoso: not sure what you mean by "has no values".. in my head kinds dont have values, they have types, and the types have values.. Maybe is the kind, Just is the type, and `Just 1` is the value
04:39:21 <dminuoso> tty1_: the type itself.
04:39:30 <dminuoso> tty1_: The kind system lets you discover which types can have values, and which types cant.
04:39:56 <dminuoso> tty1_: A type of kind * is inhabitated, which means it can have values. `Int :: *`, so values of type Int exist.
04:40:02 <dminuoso> `Char :: *`, so values of type Char exist.
04:40:11 <dminuoso> `Maybe :: * -> *`, so values of type Maybe do not exist.
04:40:22 <dminuoso> Moreover the kind system tells you what arguments are acceptable
04:40:36 <dminuoso> (Maybe Maybe) is not allowed, because Maybe demands something of kind * as an argument.
04:41:21 <tty1_> dminuoso: that makes sense.. though if i understand correctly it tells you how many different types it will have but not how many values.. for example `data Foo a = (a,a)` That has two different values both of the same type but just `Foo a` only tells you half that picture.. meanwhile `data Bar a b = (a,b)` tells you there are two different types, and it has two different values in it.
04:41:38 <dminuoso> tty1_: The kind system lets you infer *different* information.
04:41:54 <tty1_> dminuoso: right since Maybe takes a * and returns a * it cant take a Maybe because Maybe is not `*` it is `* -> *`
04:41:58 <dminuoso> Right!
04:42:02 <tty1_> dminuoso: thats fair :)
04:42:05 <dminuoso> % :k StateT
04:42:06 <yahb> dminuoso: StateT :: * -> (* -> *) -> * -> *
04:42:19 <dminuoso> tty1_: % ^- tell me a correctly and fully applied type using StateT
04:42:22 <dminuoso> (without knowing what that is)
04:42:55 <tty1_> while it still feels like an awfully confgusing syntax its probably just because im not used to it at this point. It does, at least, make sense i think.. at least i hope im making sense now
04:43:13 <tty1_> dminuoso: hmm 
04:43:22 <tty1_> dminuoso: that one is hard give me a second...
04:43:58 <tty1_> So I think this would be valid `StateT Integer (Maybe) Integer Integer`
04:44:06 <dminuoso> tty1_: Count the arguments.
04:44:10 <dminuoso> Do you think its correct?
04:44:28 <tty1_> dminuoso: oops one too many arguments, i forgot the last one is the return
04:44:35 <tty1_> dminuoso: so drop the last integer and its right
04:44:41 <dminuoso> tty1_: Then its correct. The parens are not needed by the way.
04:44:52 <dminuoso> tty1_: Another example of where the kind system is used:
04:44:55 <dminuoso> % :i Functor
04:44:57 <yahb> dminuoso: class Functor (f :: * -> *) where; fmap :: (a -> b) -> f a -> f b; (<$) :: a -> f b -> f a; {-# MINIMAL fmap #-}; -- Defined in `GHC.Base'; instance [safe] Functor m => Functor (WriterT w m) -- Defined in `Control.Monad.Trans.Writer.Lazy'; instance [safe] Functor m => Functor (ReaderT r m) -- Defined in `Control.Monad.Trans.Reader'; instance [safe] Functor m => Functor (RWST r w s m) -- Defined 
04:45:14 <dminuoso> This tells you that to write an instance Functor for some type, that type *must* have kind `* -> *`
04:45:24 <dminuoso> Would it kind-check to write `instance Functor Integer` ?
04:45:27 <tty1_> dminuoso: If i loose the parentehsis wouldnt it be equivelant to `StateT Integer (Maybe Integer)` instead and then be incorrect though? Shouldnt it need the parenthesis?
04:45:37 <dminuoso> tty1_: Nope, type application is left-associative.
04:45:47 <tty1_> dminuoso: ahhh ok
04:46:16 <tty1_> dminuoso: while i cant tell you exactly what that Maybe means or is doing in that answer, i do understand why it is the answer to your question at least
04:46:43 <Solonarv> and if it was right associative, then StateT Integer (Maybe) Integer would be the same as StateT (Integer ((Maybe) Integer)) -- you can see why we made it left associative, that makes no sense!
04:46:44 <dminuoso> tty1_: What that means is not relevant. I just picked it because its what I always pick since it has a `(* -> *)` tucked away in there. :-)
04:46:58 <dminuoso> Its meant to test whether you understand the kind concept.
04:47:10 <tty1_> yea i figured
04:47:16 <dminuoso> % :k Either
04:47:16 <yahb> dminuoso: Either :: * -> * -> *
04:47:16 <tty1_> well thanks all this is making much more sense
04:47:24 <dminuoso> tty1_: How would you saturate the Either type constructor correctly?
04:48:20 <tty1_> dminuoso: I guess if i want to get fancy it could be something like. `Either Int Int` or an actual instance like this `Left 1 :: Either Int Int` 
04:48:34 <dminuoso> Right. Know that the type parameters are allowed to differ too.
04:48:38 <dminuoso> So `Either Int Char` is fine.
04:48:49 <dminuoso> class Functor (f :: * -> *) where fmap :: (a -> b) -> f a -> f b
04:48:56 <dminuoso> This is, in principle, what the Functor class looks like.
04:48:56 <tty1_> dminuoso: right, if they werent allowed to differ it would have been defined with a single type parameter not two of them
04:49:24 <dminuoso> tty1_: This means, that all the instances must be of kind * -> *
04:49:32 <dminuoso> Maybe is an acceptable type for an instance Functor.
04:49:37 <dminuoso> Int is not, since it has the wrong kind.
04:49:45 <tty1_> dminuoso: for me thinking of kinds as a sort of generic actually helps a lot right now because many of the patterns are similar
04:49:45 <dminuoso> Either is also not acceptable, since it has the wrong kind.
04:50:01 <tty1_> dminuoso: makes sense yea, thank you
04:50:05 <dminuoso> tty1_: kinds are very different from generics.
04:50:12 <dminuoso> tty1_: kinds are a type system for the type system.
04:50:15 <dminuoso> thats the best way to describe it.
04:50:59 <tty1_> dminuoso: well i say sort of for a reason, but the stuff inside the <> for generics is sort of the same, its a type system for the the type system... the stuff in the <> are like kinds and the class which defines the <> itself is the type
04:51:16 <tty1_> dminuoso: i know the analogy only goes so far though 
04:51:27 <dminuoso> tty1_: What you are looking at are just type parameters.
04:51:35 <dminuoso> tty1_: Its a syntax fragment for no good reason.
04:52:04 <dminuoso> tty1_: When java writes `public class Box<T> { ... }` this *roughly* translates to `data Box t = ...` perhaps
04:52:13 <dminuoso> Its not about kinds there.
04:52:16 <Solonarv> the thing is that most languages only let you talk about parameters of kind *
04:52:41 <Solonarv> there's no Java equivalent to StateT, for example, because it has a parameter of kind * -> *
04:52:46 <dminuoso> tty1_: You could say that Java allows you to have parametized types.
04:52:56 <dminuoso> Which is great to have.
04:53:08 <tty1_> fairt
04:53:16 <dminuoso> `Box<Foo>` would be written `Box Foo` in Haskell
04:53:44 <dminuoso> tty1_: Just to give you some more perspective, there exists other special kinds too.
04:55:01 <dminuoso> You really dont need to worry about them, but perhaps you have called about unboxed types and boxed types. The way to differentiate between them is with the kind system. * is the kind of boxed types
04:55:03 <piyush-kurur> I have a package with multiple components (backpack style) and an executable section. The executable depends on the lib component ofcourse. Because of this cabal v2-build --dep fails (cannot satisfy the executables demand on the lib). Is there any other way to do this.
04:55:53 <dminuoso> Int# for example is an unboxed type, so `Int# :: #`. That has some interesting consequences, `Maybe Int#` does not kind-check because Maybe demands a type of kind *, not one of kind #
04:56:00 <tty1_> dminuoso: i have not been exposed to what boxed types mean in the haskell world though I am familiar with it in other languages.. though I may know the idea just not by that name
04:56:21 <tty1_> dminuoso: ohhh wow no thats completely new to me
04:56:26 <dminuoso> tty1_: unboxed is a raw more primitive representation
04:56:35 <tty1_> didnt even know # could be a kind or what the hell Int# is.. this is the first im seeing it
04:56:51 <Solonarv> (note: what dminuoso is saying is not entirely accurate anymore)
04:57:09 <dminuoso> Indeed. I intentionally tell you the old news, because the current state of affairs is very complicated.
04:57:10 <tty1_> dminuoso: i think i need to see examples of how one might use these unboxed types, they do seem interesting and worth learning about even if id never use it (just to better understand the limits and usefulness of kinds)
04:57:12 <Solonarv> # is not in fact a kind anymore, and I'm not sure if was ever actually a kind instead of a weird hack
04:57:16 <dminuoso> But its still close enough to the truth that it doesnt matter.
04:57:18 <lyxia> Kinds are a generalization of the arities of Java generics.
04:57:30 <Solonarv> but we can keep to the lie for now, just be aware that it isn't quite true
04:58:05 <tty1_> lyxia: yea thats sort of how i see it, vaguely similar to generics with similar patterns but also different in its own ways.. eventually ill see what all those differences are
04:58:13 <tty1_> fair
04:58:33 <tty1_> though id still like to see how these unboxed types could be used in a real life example, even if it is complicated and may confuse me
04:58:44 <tty1_> I often find i learn best by diving in over my head :)
04:58:44 <dminuoso> tty1_: the actual usage is no less complicated than any other haskell code, really.
04:58:59 <dminuoso> tty1_: Its just that it mostly relates to internal and low level libraries.
04:59:06 <tty1_> dminuoso: saying that to a noob probably means something very different than it does in your head, lol :)
04:59:18 <lyxia> Like Option<T> has one parameter, Map<K,V> has two. In Haskell we say Maybe has kind (* -> *), Map has kind (* -> * -> *).
04:59:41 <tty1_> lyxia: yup thats exactly the realization i had earlier that made kinds easier for me to grok
04:59:53 <dminuoso> tty1_: The implications are somewhat complicated, but from a usage point its exactly the same.
05:00:32 <lyxia> But "number of parameters" is no longer sufficient as a representation when your types can be parameterized by other parameterized types, i.e., you have higher-kinded types.
05:00:40 <tty1_> dminuoso: ahh that makes sense, so if i write some haskell code that talks to a C library I might get an Int# out of it rather than a regular Int.
05:00:54 <dminuoso> tty1_: for example, yes.
05:01:27 <tty1_> lyxia: i would have to think about it, but you can nest generic definitions to create supprisingly dizzing generic type parameters. so there may still be an analogy there to be hard.. but id need to think about it
05:01:58 <tty1_> dminuoso: and if i wanted to stick that Int# into a Maybe I would have to do some dance to box it first probably?
05:03:44 <ggole> The argument of Maybe has kind *, and Int# is not of kind *, so you indeed can't have a Maybe Int#. 
05:04:13 <zincy> What is Int#?
05:04:19 <zincy> And how does it differ from Int
05:04:21 <dminuoso> tty1_: Correct.
05:04:31 <dminuoso> tty1_: well. Sticking "Int# into a Maybe" doesnt make much sense actually.
05:04:40 <dminuoso> tty1_: But I think I know what you mean.
05:05:15 <Solonarv> zincy: it's a "raw" machine integer
05:05:28 <Solonarv> Int is a wrapper around it, defined like so: data Int = I# Int#
05:05:32 <zincy> Mutable?
05:05:33 <dminuoso> tty1_: In fact, values of Int are constructed using this: https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Exts.html#v:I-35-
05:05:37 <Solonarv> no, not mutable
05:05:50 <tty1_> yea its a primitive basically, which usually in haskell it seems we never deal with primitives except in special cases.
05:05:50 <dminuoso> tty1_: So every Int is actually a value of type Int# wrapped around an Int data constructor.
05:06:03 <Solonarv> dminuoso: s/around/in/
05:06:07 <dminuoso> *in yes!
05:06:24 <zincy> ok
05:06:39 <zincy> So what is the purpose of a raw machine integer?
05:06:53 <zincy> As in why would it need to be exposed in Haskell?
05:07:15 <Solonarv> well, obviously the generated code needs to work with machine integers at some point if you don't want it to be horribly slow
05:07:26 <tty1_> hmmm
05:07:45 <zincy> And Word is a machine word?
05:07:52 <Solonarv> exposing "primitive" types means you can write operations directly on them in case compiler optimizations don't eliminate the wrappers
05:07:58 <dminuoso> zincy: You can at least rule it out by the kind system.
05:08:04 <Solonarv> Word# is a machine word, Word is a wrapper around it
05:08:05 <dminuoso> zincy: If it has type *, its definitely not a machine- thing.
05:08:09 <tty1_> if i wanted to do bitwise math on an Int would i have to work with the underlying Int# to do it?
05:08:14 <dminuoso> zincy: But the converse does not hold true.
05:08:30 <Solonarv> tty1_: no, you would use functions from Data.Bits most likely
05:08:37 <tty1_> ahh
05:08:51 <Solonarv> @hoogle .|.
05:08:51 <lambdabot> Data.Bits (.|.) :: Bits a => a -> a -> a
05:08:51 <lambdabot> Graphics.Rendering.Chart.Grid (.|.) :: Grid a -> Grid a -> Grid a
05:08:51 <lambdabot> Data.Array.Accelerate.Data.Bits (.|.) :: Bits a => Exp a -> Exp a -> Exp a
05:08:55 <tty1_> Solonarv: but those functions are probably for convience and they themselves would access the raw Int# then?
05:09:01 <Solonarv> in the end, yes
05:09:18 <tty1_> makes sense
05:09:51 <tty1_> so sounds like the only time you need to touch a raw type like Int# is when haskell is incomplete for your purposes (such as not having a library to access to some low level C code or something)
05:09:51 <zincy> GADTs just alter the constraints of type variables for particular data constructors right?
05:09:59 <tty1_> good to know
05:10:02 <Solonarv> zincy: oh, exposing the machine types also means the compiler optimizations don't need to be quite as magical
05:10:16 <tty1_> I will try to play with them at some point even though they dont seem like something id need to touch too often
05:10:22 <zincy> So is the compiler the main user of machine types?
05:10:25 <Solonarv> tty1_: actually Haskell's FFI knows how to wrap/unwrap a number of types, including Int
05:10:49 <Solonarv> zincy: no, not at all - GHC doesn't use unlifted types all that much AFAIK
05:11:05 <zincy> I dont understand why you would use them
05:11:20 <zincy> I think you said performance?
05:11:24 <tty1_> Solonarv: this may be of use to me at some point as I would love to be able to get ruby and haskell playing together at some point.. and Id rather not use eta with JRuby or anything so indirect
05:11:34 <Solonarv> tty1_: also they're inconvenient to work with - you can't put them in a list, or Maybe, or... basically, most of the usual data structures don't work on it
05:12:30 <tty1_> Solonarv: well id imagine if you just want to use it within the haskell universe in that way you'd just wrap it (box it) and then use it.. unless its just intermediary somehow in which case you might manipulate it directly then wrap it or something.
05:12:49 <Solonarv> well yeah, you'd box it... that's what Int is
05:12:59 <Solonarv> and most of the time you don't need to "crack open" the box
05:13:33 <Solonarv> if you're doing arithmetic GHC is pretty good at not unwrapping and rewrapping all the time
05:14:00 <Solonarv> zincy: yeah, performance is the main one
05:14:16 <zincy> Solonarv: Why is the performance better?
05:14:28 <tsahyt> boxing means indirection
05:14:35 <Solonarv> because the "wrapper" is essentially a pointer
05:14:43 <Solonarv> (assuming the value is fully evaluated)
05:14:44 <tsahyt> but GHC is good at doing this stuff for you
05:15:10 <Solonarv> so the boxed Int takes up 8 bytes for the pointer + 8 bits somewhere on the heap for the actual value
05:15:17 <Solonarv> Int# is just the value itself
05:15:26 <Solonarv> (I'm assuming a 64bit system)
05:16:38 <zincy> Makes sense 
05:16:39 <zincy> thanks
05:16:51 <tsahyt> it's probably also worth pointing out that there are data structures that do store unboxed values, e.g. unboxed vectors. they are equipped with functions that when you want to get something out of it for whatever reason, you'll still get a boxed one so it's not inconvenient to deal with.
05:17:11 <zincy> What is boxed vs unboxed?
05:17:39 <Solonarv> "boxing" refers exactly to this extra indirection
05:18:10 <Solonarv> so if you're working with a boxed value, you have a pointer to the actual data (or to a thunk)
05:18:22 <Solonarv> if you're working with an unboxed value you have the actual "raw" thing
05:18:28 <zincy> Ok so akin to ptr vs ptr*
05:18:43 <Solonarv> pretty much
05:19:14 <zincy> There is a type for pointers in base
05:19:44 <tsahyt> in regular Haskell code you should never need to pass around a Ptr to anything. it exists primarily for the FFI
05:20:14 <Solonarv> "or to a thunk" makes things a bit more complicated, and additionally GHC sometimes sneaks some data into the 2 or 3 lowest bits of the pointer
05:29:35 <aveltras> how would one lift the fetch function from the transformer below ?
05:29:37 <aveltras> class (Monad m) => HasDataSource m where
05:29:37 <aveltras>   fetch :: Req a -> m a
05:29:37 <aveltras>   default fetch :: (HasDataSource m', m ~ t m', MonadTrans t) => Req a -> m a
05:29:37 <aveltras>   fetch = ???
05:32:20 <Solonarv> lift . fetch
05:32:35 <Solonarv> or if you prefer: fetch req = lift (fetch req)
05:33:20 <Solonarv> note that the fetch on the right side has type Req a -> m' a and comes from the HasDataSource m' instance
05:34:52 <ezyang> piyush-kurur: is Backpack actually involved? 
05:35:12 <aveltras> Solonarv: it worked, thx !
05:36:32 <Solonarv> aveltras: that's the general pattern for this kind of default-for-a-monad-transformer
05:36:32 <Solonarv> foo x1 x2 ... xn = lift (foo x1 x2 ... xn)
05:37:52 <aveltras> Solonarv: was trying to transcribe https://github.com/obsidiansystems/obelisk/blob/develop/lib/frontend/src/Obelisk/Frontend/Cookie.hs for another purpose but im still not proficient :)
05:42:44 <kuribas> what's your database library of choice?
05:43:41 <dminuoso> kuribas: *-simple
05:44:19 <kuribas> dminuoso: funny how safety minded haskellers prefer the string manipulation over typed solutions
05:44:47 <dminuoso> kuribas: You can hide the string manipulation behind simple functions too.
05:45:35 <dminuoso> kuribas: I have not seen any database abstraction library worth the time in any langauge.
05:46:14 <dminuoso> Raw SQL is a precise domain specific language. It's *sql* that lacks a kind of type system that is modular enough to integrate with other type systems.
05:46:28 <dminuoso> So I blame SQL, not the abstraction libraries ontop of it.
05:47:32 <dminuoso> Writing tests solves most, if not all, of the troubles involving types mismatching code.
05:48:24 <kuribas> I agree, but string manipulation is tedious and error prone
05:48:42 <kuribas> I'd like a light combination library on top of the string manipulation
05:48:48 <dminuoso> kuribas: I agree. I just dont know of any better alternative that doesn't ruin the usable interface of SQL by shoehorning it into Haskells type system.
05:49:16 <kuribas> dminuoso: I'll let you know if I come up with something :)
05:49:22 <dminuoso> Absolutely.
05:49:44 <dminuoso> kuribas: You should look at equeleto and opaleye by the way. Perhaps you might enjoy them.
05:49:57 <kuribas> I am thinking of a haskell version of honeysql (clojure)
05:50:01 <tty1_> In the paper im reading it just referred to Haskell as being statically typed. Is that true? until now it looked dynamically typed to me
05:50:03 <DigitalKiwi> funny how mysql users are surprised most haskellers use postgresql :)
05:50:12 <kuribas> tty1_: it's true!
05:50:17 <tty1_> oh wow
05:50:26 <dminuoso> tty1_: Dont conflate type inference with the idea of dynamic typing.
05:50:31 <kuribas> tty1_: but it has optionally dynamic types
05:50:34 <tty1_> fair
05:50:55 <kuribas> tty1_: I'd even say the static type system is more advanced that the one in mainstream languages.
05:51:04 <tty1_> i guess it just does so much type inference it feels like its dynamic
05:51:14 <dminuoso> tty1_: Indeed!
05:51:18 <kuribas> true
05:51:29 <dminuoso> tty1_: Once you have good type inference, much of the apparent pain that Java gives you disappears.
05:51:38 <dminuoso> And then the benefits start to outweight the downsides.
05:51:47 <kuribas> and polymorphism allows you to write things you cannot in Java
05:52:08 <dminuoso> tty1_: our type inference is so good, that it not only gives (almost) always the type, but it gives you the most general type.
05:52:28 <tty1_> yea sadly java can be pretty painful when it comes to typing, particularly when you get into generic hell. I learned generics like a pro as a result but man was it mind bending at times... Im new to haskell so its mind bending a bit right now but ill wait till i get the basics before i judge it
05:52:39 <dminuoso> tty1_: The core algorithm is called Hindley Milner type inference which quite a few other languages use as well, such as some from the ML family
05:52:49 <Solonarv> and also Rust!
05:53:05 <tty1_> havent played with those languages yet
05:53:15 <tty1_> though i do want to try Rust at some point
05:53:17 <[Leary]> @djinn ((a -> (b -> m r) -> m r) -> (a -> m r) -> m r) -> (a -> m r) -> m r
05:53:17 <lambdabot> f a b = a (\ c _ -> b c) b
05:53:20 <Solonarv> every time I use java generics I gnash my teeth because type erasure is so pants-on-head
05:53:25 <zincy> Can GADTs be used as a shortcut for typechecking in a simple typed lambda calculus?
05:53:42 <dminuoso> tty1_: Rust is a really great langauge from what Ive seen and heard.
05:53:46 <[Leary]> Spent a while trying to write a callCC I could understand ... turns out I should have just given up and asked lambdabot. <.<
05:53:55 <Solonarv> zincy: you can define your AST as a GADT so you can only construct well-types ASTs, yes
05:54:06 <tty1_> Solonarv: fair. Java is the language i have most expiernce in. And it isnt a bad language really, but its not the language i have the most fun with. It just pays me the most money to know it
05:54:22 <zincy> Solonarv: Would that give me type inference for my expressions?
05:54:25 <dminuoso> tty1_: Its not the language itself that is bad, but the type system that is incredibly inflexible.
05:54:36 <Solonarv> zincy: mmmmmmaybe?
05:54:45 <dminuoso> tty1_: In some ways, getting used to Haskell opens your eyes how limiting some languages can be.
05:54:49 <tsahyt> dminuoso: but isn't the type system part of the language in some way?
05:55:04 <dminuoso> tsahyt: Mmm. I guess.
05:55:15 <gonz_> tty1_: In the US the language that would've netted you the highest pay was Erlang.
05:55:21 <tty1_> In java I write a lot of machine learning low level stuff. I had to create a Graph Theory library using generics. Because the generics wound up being recursive it all broke down real fast.
05:55:24 <gonz_> + "a few years ago"
05:55:28 <zincy> Yes as Wittgenstein said the limits of your world is language
05:55:35 <gonz_> Java has historically not been particularly well paid
05:55:51 <zincy> How do you describe the benefits of type safety to a javascript programmer
05:55:51 <Solonarv> (mumbling) somethingsomething sapir whorf
05:55:54 <gonz_> You may have just found a local maximum, but don't confuse a big market with high salaries
05:56:18 <dminuoso> tty1_: Another main thing that annoys me about Java is that it lacks many very principle concepts, and you need to shoehorn them into class patterns to make it work.
05:56:24 <gonz_> Java has many reasons to not garner high pays; you can replace almost any Java programmer in no time at all
05:56:34 <Solonarv> zincy: you can try the "prevents a large class of bugs" angle, or the "trick the compiler into writing code for you"  angle
05:56:41 <dminuoso> tty1_: For example the "factory pattern" is an artifact of lacking top-level functions.
05:56:47 <tty1_> gonz_: i dunno man, im pretty much at the top of the pay scale for a programmer. But that isnt entierly due to java, its a combination of java plus my algorithmic skills 
05:56:51 <dminuoso> tty1_: And in part about lacking partial application.
05:57:00 <zincy> Solonarv: Then they tell you fancy abstractions get in the way of getting shit done
05:57:11 <Solonarv> or sneak them towards it via typescript (-> purescript) -> haskell
05:57:20 <dminuoso> tty1_: While the GoF would have you believe that such patterns are good style, they are rather a necessary evil to encode basic ideas because the language doesn't have them as first-class features.
05:57:21 <tty1_> dminuoso: makes sense
05:57:40 <dminuoso> tty1_: this applies to many of so-called "patterns"
05:57:41 <Solonarv> zincy: tell them "ah yes that is why we are writing assembly" :P
05:57:52 <tty1_> dminuoso: well in a way java rigidity makes it harder to write but easier to read.. at least thats my current opinion
05:57:55 <dminuoso> tty1_: the visitor pattern for example is a workaround for languages lacking pattern matching.
05:58:01 <zincy> Solonarv: That is exactly what I thought of saying
05:58:12 <zincy> Solonarv: Those philosophical clashes are tough
05:58:17 <Solonarv> for sure
05:58:37 <zincy> Solonarv: Sometimes I feel like I am not cut out for web development
05:58:38 <dminuoso> tty1_: Im not convinced of that.
05:59:10 <zincy> I wonder if there is a career path for people like me which like theory and correctness
05:59:12 <dminuoso> tty1_: When code is hard to write, its equally hard to express the meaning of code. You cant recover it from a quick glance, you have to recreate the mental designspace in which the code was written.
05:59:13 <tty1_> dminuoso: i may change my mind when I finish learning haskell, we shall see
05:59:30 <dminuoso> tty1_: Its when code becomes short and expressive that it gets easy to write and read.
05:59:45 <Solonarv> zincy: academia :P
05:59:53 <TMA> zincy: there is, even outside academia
05:59:58 <tty1_> dminuoso: well its not that i find java code hard to write. Most of the time it is vcery easy to write. It is just verbose and thus annoying because most of the effort i put in is "monkey coding".. but that same verbosity makes it easier to read in my mind
06:00:01 <Solonarv> others too I'm sure, but they don't come to mind right now
06:00:13 <zincy> TMA: Such as :)
06:00:25 <dminuoso> tty1_: Let me give you a hopefully convincing example:
06:00:39 <zincy> Solonarv: Did you do any degree? I have a degree in Politics :P
06:00:40 <TMA> zincy: but the downside is that it consists mainly of "suffer because of the industry practice is not amenable to one's interests"
06:00:53 <c_wraith> dminuoso, the visitor pattern also feels remarkably similar to a catamorphism. the visitor object is sort of an f-algebra
06:00:53 <zincy> TMA: Yes
06:01:07 <tty1_> dminuoso: sure
06:01:22 <Solonarv> zincy: I'm studying for a bachelor's in physics
06:01:38 <zincy> Solonarv: So you are self-taught?
06:01:56 <Solonarv> for CS? mostly, yes
06:02:05 <zincy> Solonarv: Impressive
06:02:15 <zincy> Solonarv: Where are you studying?
06:02:32 <Solonarv> Freiburg, Germany
06:02:45 <dminuoso> tty1_: Try to look at the following code for about 10 seconds, and tell me if you have any idea of what it does: https://gist.github.com/dminuoso/2c3f743a1d52bdc3a8bd440200be16b8
06:02:55 <zincy> Maybe I should just bite the bullet and do a masters in CS. thinking a Scandinavian uni as no fees :) 
06:03:00 <tty1_> dminuoso: sure
06:03:36 <zincy> Bug bear - people who find an imperative style more readable
06:04:00 <zincy> It is more readable sure on a micro level but not on the macro level
06:04:07 <Solonarv> yeah, no fees here either :>
06:04:15 <zincy> In Germany?
06:04:16 <tty1_> dminuoso: ok spent 10 seconds, looks like a merge sort but i didnt step through it in full
06:04:18 <Solonarv> yup
06:04:36 <dminuoso> tty1_: same story again: https://gist.github.com/dminuoso/2a03e3eae5627861f114160db736b86c
06:04:40 <zincy> Maybe I will just collect masters degrees for the rest of my life
06:05:30 <tty1_> dminuoso: to me that is more confusing but i also recognize being a haskell noob that is more to blame than haskell itself. To look at it is not immediately obvious it is a merge sort. But with more expiernce in haskell it might be
06:05:54 <dminuoso> tty1_: qsort (h:t) = qsort (filter (<= h) t) ++ [h] ++ qsort (filter (> h) t)
06:05:59 <dminuoso> tty1_: Intrinsically shows you how it even works.
06:06:06 <tty1_> dminuoso: i did however write my own merge sort in haskell, its a bit more verbose than the example you gave but i fgeel it is more readable than the c example you showed
06:06:07 <Solonarv> that's a quicksort, not a mergesort
06:06:09 <dminuoso> You dont need to recover the information because its staring you in the face.
06:06:28 <phadej> that's quicksort
06:06:29 <tty1_> ahh, looked like it was splitting it in half then recursively feeding both halfs back to itself
06:06:36 <phadej> ah, solonarv where quicker 
06:06:46 <tty1_> so the C one isnt merge sort or is the haskell one qwuicksort and the c one merge sort
06:06:53 <dminuoso> tty1_: both are quicksort.
06:06:59 <dminuoso> tty1_: With C I couldnt tell either from just staring.
06:07:04 <tty1_> ohh .. let me spend more than 10 seconds looking at it then :)
06:07:11 <phadej> if you are strict, the C-one is *in-place* quick-sort
06:07:14 <dminuoso> Id have to understand the instructions and mentally connect the blocks. With the haskell variant it's blatantly obvious.
06:07:21 <tty1_> it did look weird since i didnt see any merging happening
06:07:30 <dminuoso> phadej: Yeah that's fair.
06:08:01 <tty1_> dminuoso: for me merge sort example i think would have shown your point better (but just because i implement that algorithm more often).. want to see my haskell code for merge sort next to some java code?
06:08:04 <Solonarv> you can write in-place quicksort in Haskell too of course, but you first need to conjure up a mutable array from somewhere
06:08:54 <phadej> Solonarv: it won't look much different than that C-example;actually worse :)
06:09:17 <dminuoso> phadej: Because of all the unsafe prefixes you'd introduce? :p
06:09:18 <tty1_> Here is a gist I personally wrote that shows merge sort implemented in java vs haskell vs javascript : https://gist.github.com/freemo/8628562
06:09:25 <phadej> See, e.g. http://hackage.haskell.org/package/vector-algorithms-0.8.0.1/docs/Data-Vector-Algorithms-Intro.html
06:09:31 <Solonarv> dminuoso: no, there's nothing unsafe involved
06:09:44 <dminuoso> Solonarv: unsafe array accesses? 
06:10:16 <Solonarv> dminuoso: oh, omitting the bounds check. sure, forgot about tht
06:10:21 <tty1_> dminuoso: in my head at least with the example i just posted I'd say the haskell varient is the easiest to read of all of them
06:10:31 <dminuoso> tty1_: the unfair point was raised by phadej though.
06:10:42 <dminuoso> tty1_: they are not equivalent on the basis that the haskell one is not in place in both examples.
06:11:01 <tty1_> dminuoso: fair
06:11:30 <zincy> dminuoso: I have heard people saying you should almost never write raw sql queries, is this true?
06:11:47 <dminuoso> zincy: I dont know why they would say that.
06:11:47 <tty1_> dminuoso: in my own example i show non-in-place versions and inplace versions for comparison
06:11:52 <dminuoso> tty1_: https://gist.github.com/dminuoso/2d514aa968f40fa0900443be7ea5025f
06:12:08 <dminuoso> tty1_: this is a haskell in-place quicksort and the "elegant/compact" variant.
06:12:12 <tty1_> im not even sure how in-place is possible with haskell since everything is immutable
06:12:32 <dminuoso> tty1_: Haskell has the full toolset to do *all* the dirty things.
06:12:39 <dminuoso> You can play with pointers, memory, mutable variables..
06:13:01 <c_wraith> arbitrarily break type safety...
06:13:07 <tty1_> ohhh so not everything is immutable in haskell.. its just that things are sort of immutable by default?
06:13:09 <zincy> Does anyone here every read Core output so they can optimise perf?
06:13:12 <zincy> ever
06:13:26 <dminuoso> tty1_: Kind of. Its rather that the dirty tricks are constrained by certain types.
06:13:30 <Solonarv> zincy: occasionally I have a look at it
06:13:40 <Solonarv> mostly to see if optimizations worked properly
06:14:09 <zincy> Solonarv: How long have you been self teaching
06:14:16 <dminuoso> tty1_: All these tricks are opt-in rather.
06:14:24 <tty1_> hmmm
06:14:35 <tty1_> gonna have to learn that before i start seriously implementing my algorithms then
06:14:45 <Solonarv> zincy: I started learning Haskell 4 or 5 years ago, CS in general a few years before that (not sure exactly)
06:14:52 <dminuoso> tty1_: For example you can have mutable memory refences just fine. You just need IO and then its: `x <- newIORef 1` - and every time you want to modify it, you'd use `modifyIORef` for example.
06:15:15 <Solonarv> or readIORef, writeIORef which do as their name suggests
06:15:34 <dminuoso> tty1_: Granted, it requires a bit extra typing - but you can do it just as fine.
06:15:53 <dminuoso> tty1_: Except now you must do this inside IO, it cant leak into non-IO parts anymore. Side effects become visible.
06:15:55 <tty1_> dminuoso: i just recently "got" IO at a basic level. that will probably be a new challenge to understand.. but ill get to it very soon. I still need to start playing with monads first
06:16:03 <dminuoso> tty1_: you dont.
06:16:07 <dminuoso> tty1_: Just use IO and forget that m word.
06:16:38 <zincy> Solonarv: Cool! 
06:16:46 <tty1_> dminuoso: by understand monads I just mean to make instances of Monad or to consume them. Not monads as a concept... it seems straight forward enough by the definition of a monad
06:17:14 <dminuoso> tty1_: Well, so you want to understand specific monad instances?
06:17:22 <dminuoso> That's great and all you need. :)
06:17:33 <tty1_> dminuoso: i just want to understand when some idea in my head should be implemented as a monad or not
06:20:04 <jgt> I'm using monads all day and I have no intuition for when I should be writing my own
06:20:58 <dminuoso> tty1_: So the rule could be rather simple: Dont think about implementing it as monad. Implement it like it feels right.
06:20:59 <jgt> or maybe I just never come up against scenarios where I have to implement my own monad instances in my work
06:21:06 <jgt> or maybe I'm just bad at programming
06:21:37 <amx> is it generally worth it to use something like safe-money instead of storing currency values in an Int or even a Float?
06:22:07 <dminuoso> And if you happen to write two functions matching a particular shape, then you've already done it.
06:22:18 <dminuoso> Dont make something an instance of monad for the purpose of making it a monad, you wont gain anything.
06:22:18 <jgt> amx: who's money is at stake if your program miscalculates transactions?
06:22:58 <tty1_> dminuoso: well i tend to write libraries. So I need to making something a monad potentially because others may want to consume it as such. Even if i myself dont have an immediate need for it
06:23:07 <dminuoso> tty1_: No you dont.
06:23:13 <dminuoso> tty1_: Monads are not something to "consume"
06:23:15 <amx> jgt: my customer's and it will probably be detected before it vanishes, but then I have to fix it
06:23:27 <Solonarv> alright, definitely use a proper library then
06:23:30 <dminuoso> tty1_: Are you familiar with Java interfaces?
06:23:38 <tty1_> dminuoso: I am
06:24:22 <dminuoso> tty1_: So lets say I have some interface Foo. Do you need to write an implementation of Foo for your own data type in order to use that data type?
06:24:28 <dminuoso> Or can you use your own data type without my interface just fine?
06:24:42 <jgt> amx: personally, I'm using safe-money because I'd rather just do it properly (small mental/ergonomical expenditure), rather than risk shooting myself in the foot (large mental expenditure) and/or potentially having to fix the problem later (large ergonomical expenditure)
06:25:02 <tty1_> dminuoso: Not always.. sometimes
06:25:04 <jgt> amx: so in my view, it's just better economic sense to do it right from the outset
06:25:06 <dminuoso> tty1_: Generally you dont.
06:25:33 <dminuoso> tty1_: Monad is not necessary for anything. 
06:26:09 <dminuoso> tty1_: Its just an observation that sometimes your data type has two functions with a particular type signature. It's just a common theme. When that happens, then the deed is done already.
06:26:20 <tty1_> dminuoso: well it really depends, i do a lot of each. Sometimes i write interfaces and then implementations of them so consumers can consume my classes according to a shared interface... Sometimes its the reverse, i give them an interface and they implement classes from it because that way my library can consume their classes in a common way. It really works both ways, at least in java. I presume the same is true here
06:26:20 <dminuoso> Nothing more.
06:26:31 <amx> jgt: I agree, thanks
06:26:56 <jgt> tty1_: don't understand the utility of simple functions. Prefer these to typeclasses.
06:27:04 <jgt> underestimate*
06:27:18 <jgt> I swear I'm not illiterate but sometimes my fingers are
06:27:27 <tty1_> hmm perhaps haskell is just a bit different in that regard then
06:27:34 <tty1_> jgt: haha your good
06:27:54 <dminuoso> tty1_: Monad is neither important nor necessary.t
06:28:01 <tty1_> jgt: i do the same, type out something elegant in my head and it looks like i mashed the keyboard with my head.. my fingers do their own thing after 30 years of typing at hyper speed
06:28:04 <dminuoso> tty1_: We could throw out the typeclass without replacement, and everything would still be fine.
06:29:10 <ThomasLocke> jgt, I have the exact same experience as you in regards to monads. I acknowledge them and use them. Never had any need to write any Monad instances. Granted, I've only been using Haskell at work for a couple of years, but still. :)
06:30:18 <jgt> I'm on a mission to prove that even luddites like myself can be productive in Haskell
06:30:25 <ThomasLocke> The amount of homegrown typeclasses can be counted on one hand also. Simple functions for the win!
06:30:47 <ThomasLocke> Simplicity rules my world, because I'm quite dumb
06:31:54 <Solonarv> most of the Monad instances I've written manually were for learning purposes, yeah
06:32:02 <jgt> I'm also quite dumb. That's why I use Haskell :P
06:32:20 <Solonarv> I do write ' deriving (Functor, Applicative, Monad)' fairly often when defining my own "monad stack"
06:32:29 <ThomasLocke> jgt, Hahaha... Same reason I use it. It helps me in so many ways.
06:32:40 <jgt> I once started a Haskell conference talk by saying that, including "I don't even have a high school maths grade — I was drunk in my exam"
06:32:51 <jgt> and then recently my mother told me she watched it
06:32:54 <jgt> I was mortified
06:33:16 <ThomasLocke> :D
06:34:55 <zincy> jgt: :)
06:40:15 <ThomasLocke> Is there a "good" way to turn ["","1","2","","3","4","","","","5","6","",""] into [["1","2"],["3","4"],["5","6"]]?
06:40:26 <ThomasLocke> I've got a solution, but it feels pretty convoluted
06:40:34 <ThomasLocke> Here's my ugly solution: https://gist.github.com/ThomasLocke/753c305197f6b547ef4138dfb909513c
06:40:39 <infinisil> > groupBy null ["","1","2","","3","4","","","","5","6","",""]
06:40:41 <lambdabot>  error:
06:40:41 <lambdabot>      • Couldn't match type ‘Bool’ with ‘[Char] -> Bool’
06:40:41 <lambdabot>        Expected type: [Char] -> [Char] -> Bool
06:41:06 <Axman6> > groupBy (comparing null) ["","1","2","","3","4","","","","5","6","",""]
06:41:08 <lambdabot>  error:
06:41:08 <lambdabot>      • Couldn't match type ‘Ordering’ with ‘Bool’
06:41:08 <lambdabot>        Expected type: [Char] -> [Char] -> Bool
06:41:35 <Axman6> > groupBy ((==) <$> null <*> null) ["","1","2","","3","4","","","","5","6","",""]
06:41:37 <lambdabot>  error:
06:41:37 <lambdabot>      • Couldn't match type ‘Bool’ with ‘[Char] -> Bool’
06:41:37 <lambdabot>        Expected type: [Char] -> [Char] -> Bool
06:41:42 <ThomasLocke> I have mucked about with groupBy a bit, but I haven't found a way to make it work
06:41:49 <Axman6> :t groupBy
06:41:50 <lambdabot> (a -> a -> Bool) -> [a] -> [[a]]
06:42:00 <Axman6> :t ((==) <$> null <*> null)
06:42:01 <lambdabot> Foldable t => t a -> Bool
06:42:05 <dminuoso> Is there a notion of lenses that work through monadic effects? Or perhaps one that works with MonadIO?
06:42:37 <Axman6> > groupBy (\a b -> null a ==  null b) ["","1","2","","3","4","","","","5","6","",""]
06:42:39 <lambdabot>  [[""],["1","2"],[""],["3","4"],["","",""],["5","6"],["",""]]
06:42:58 <Axman6> >filter (all null) $  groupBy (\a b -> null a ==  null b) ["","1","2","","3","4","","","","5","6","",""]
06:43:02 <Axman6> > filter (all null) $  groupBy (\a b -> null a ==  null b) ["","1","2","","3","4","","","","5","6","",""]
06:43:02 <jgt> ThomasLocke: I'd probably do chunksOf 2 $ filter (not . null) ["","1","2","","3","4","","","","5","6","",""]
06:43:04 <lambdabot>  [[""],[""],["","",""],["",""]]
06:43:17 <Axman6> > filter (not . all null) $  groupBy (\a b -> null a ==  null b) ["","1","2","","3","4","","","","5","6","",""]
06:43:19 <lambdabot>  [["1","2"],["3","4"],["5","6"]]
06:43:24 <dminuoso> ThomasLocke: What problem are you trying to solve?
06:43:30 <infinisil> > :t liftA2 (==) null null
06:43:31 <jgt> chunksOf is in the split package
06:43:31 <Axman6> works but feels fragile
06:43:32 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
06:43:39 <infinisil> % :t liftA2 (==) null null
06:43:39 <yahb> infinisil: Foldable t => t a -> Bool
06:44:12 <infinisil> > groupBy (liftA2 (==) null null) ["","1","2","","3","4","","","","5","6","",""]
06:44:14 <lambdabot>  error:
06:44:14 <lambdabot>      • Couldn't match type ‘Bool’ with ‘[Char] -> Bool’
06:44:14 <lambdabot>        Expected type: [Char] -> [Char] -> Bool
06:44:19 <infinisil> Sorry I should stop
06:44:21 <infinisil> Lol
06:45:14 <ThomasLocke> dminuoso, Getting rid of the empty elements and grouping elements together whenever they are separated by on or more empty element. If that makes sense
06:45:41 <dminuoso> ThomasLocke: Can you tell us more context?
06:45:46 <dminuoso> ThomasLocke: This might be an XY problem perhaps.
06:48:48 <ThomasLocke> dminuoso, Each group will represents lines coming from a FreeSWITCH event socket. I'm getting the data as JSON, not directly from FreeSWITCH. I've no idea how many empty lines there might be, all I know is that they separate the events from each other.
06:50:10 <ThomasLocke> Sometimes I might get a json with 100 lines, other times it can be 10000 lines. Empty lines can and may be found everywhere.
06:52:30 <jgt> "other times it can be 10000 lines" don't forget to stream
06:53:17 <ThomasLocke> jgt, I'm not in any way performance/memory constrained, and 10000 is perhaps stretching it a bit.  :D
06:53:56 <c_wraith> 10000 blank lines is also not very much memory
06:56:04 <ThomasLocke> The longest line I've seen so far is  a few hundred characters, so it's not huge amounts of data coming at me.
06:57:58 <dminuoso> Axman6: Fragile in what sense?
07:05:59 <zincy> Is there a better way of doing the add and mull operations without pattern matching since with GADTs now those cases should never match? https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab
07:06:03 <zincy> Solonarv ^
07:07:26 <ThomasLocke> Axman6, I kinda like your solution, and I can't really see how it is fragile?
07:08:05 <Axman6> I guess it's not
07:08:11 <Axman6> a better one is:
07:08:25 <Axman6> > filter (not . null . head) $  groupBy (\a b -> null a ==  null b) ["","1","2","","3","4","","","","5","6","",""]
07:08:28 <lambdabot>  [["1","2"],["3","4"],["5","6"]]
07:08:59 <Axman6> the all isn't necessary, and head is safe because groupBy always produces non-empty lists
07:09:39 <c_wraith> and you gave groupBy a real equivalence relation so that it doesn't do weird things
07:12:28 <ThomasLocke> Axman6, This is so much better than my crap. Thanks man.  :D
07:15:35 <Axman6> infinisil got the ball rolling
07:18:03 <ski> @let equating :: Eq b => (a -> b) -> (a -> a -> Bool); equating p = (==) `on` p  -- or, `equating p x y = p x == p y'
07:18:04 <lambdabot>  Defined.
07:18:06 <ski> @type comparing
07:18:08 <lambdabot> Ord a => (b -> a) -> b -> b -> Ordering
07:18:09 <ski> @src comparing
07:18:09 <lambdabot> comparing p x y = compare (p x) (p y)
07:18:50 <ski> > (filter (not . null . head) . groupBy (equating null)) ["","1","2","","3","4","","","","5","6","",""]
07:18:52 <lambdabot>  [["1","2"],["3","4"],["5","6"]]
07:19:34 <dminuoso> Ah the `not . null . head` is certainly better than `not . all null`
07:19:40 <ski> > (unwords . sortBy (comparing length <> compare) . words) "The quick brown fox jumps over the lazy dog"
07:19:42 <lambdabot>  "The dog fox the lazy over brown jumps quick"
07:46:28 <kuribas> > (not . all . null) []
07:46:30 <lambdabot>  error:
07:46:30 <lambdabot>      • Couldn't match type ‘[a0] -> Bool’ with ‘Bool’
07:46:30 <lambdabot>        Expected type: [a1] -> Bool
07:46:46 <kuribas> > (not . all null) []
07:46:48 <lambdabot>  False
07:47:01 <kuribas> > (not . null . head) []
07:47:04 <lambdabot>  *Exception: Prelude.head: empty list
07:47:11 <kuribas> dminuoso: ^^
07:47:36 <kuribas> > (any . not null) []
07:47:38 <lambdabot>  error:
07:47:38 <lambdabot>      • Couldn't match expected type ‘[a1] -> a -> Bool’
07:47:38 <lambdabot>                    with actual type ‘Bool’
07:47:53 <kuribas> > any (not null) []
07:47:55 <lambdabot>  error:
07:47:56 <lambdabot>      • Couldn't match expected type ‘a1 -> Bool’ with actual type ‘Bool’
07:47:56 <lambdabot>      • Possible cause: ‘not’ is applied to too many arguments
07:49:22 <dminuoso> kuribas: If you look at the code, it's safe.
07:50:12 <kuribas> ok
08:11:01 <jkachmar_> kinda open-ended question, but do any of y'all have advice on handling parse errors when working with lens-aeson?
08:11:40 <phadej> don't use lens-aeson
08:11:41 <phadej> :)
08:11:45 <phadej> if you need parse-errors
08:11:49 <jkachmar_> womp
08:11:56 <jkachmar_> but it's so nice :(
08:12:03 <phadej> it's good for some adhoc transformations, but for actual parsing it's actually isn't
08:12:22 <phadej> not an improvement over `aeson`s Parser
08:12:50 <jkachmar_> mostly I'm drilling down through some grossly nested JSON and it's been very helpful
08:13:09 <phadej> you can combine that with aesons Parser machinery
08:13:39 <adamCS> phadej: Yes!  Drill down to a "Value" and then work on that more...delicately.
08:13:54 <jkachmar_> Yeah, I'm doing a bit of that now.
08:14:16 <jkachmar_> I suppose the answer is really just "Only use `lens-aeson` for the stuff that you can handle reporting back with a single `fail "You goofed"` for all of it
08:15:03 <phadej> yes :)
08:15:56 <Cale> dminuoso: Hey, are you around?
08:33:09 <jgt> is there a GHC flag that will warn me against incomplete pattern matches of this form? http://ix.io/1IpO
08:33:23 <jgt> (just gotten bitten by this)
08:33:41 <phadej> the [E.Value a] <- ?
08:33:47 <jgt> exactly
08:33:51 <phadej> it's a feature
08:34:28 <jgt> runtime errors aren't much of a fun feature
08:34:34 <phadej> incomplete pattern match in `do` block desugar to `fail`
08:34:40 <phadej> and `fail` for IO is runtime error
08:35:48 <jgt> does that mean there isn't a way to protect against this then?
08:35:55 <jgt> (other than knowing not to do that)
08:36:00 <jkachmar> jgt: I believe if you turn on `MonadFailDesugaring` it will require an explicit constraint of `MonadFail` in order to enable this
08:36:15 <phadej> jkachmar: but IO has it, so no win
08:36:16 <Solonarv> jkachmar: that's on by default in ghc 8.6 and always on in 8.8
08:36:31 <Solonarv> jgt: there is a warning for it actually
08:37:26 <jgt> nice. That language extension did the trick. Thanks!
08:37:57 <jkachmar> Like phadej said though, you need to be careful of which context you're operating in
08:38:10 <Uniaika> phadej: that's quite interesting! Is there someplace where this behaviour is documented? Or is it bound to each data structure's Monad implementation?
08:38:21 <jgt> it's Haskell; I don't want to be careful
08:38:33 <jgt> I want to be reckless
08:38:33 <jkachmar> You don't get to not be careful when working with computers, unfortunately
08:38:59 <phadej> Uniaika: https://wiki.haskell.org/MonadFail_Proposal
08:39:11 <jgt> GHC permits a relative degree of carelessness
08:39:22 <hyperisco> units can be scaled, so  3*(9m) = 27m  but they can also be divided, so  27m/9m = 3  where do we find this operation? short of a Euclidean ring, because I do not wish multiplication
08:39:37 <jgt> or inebriation
08:40:00 <phadej> hyperisco: you do want multiplication in units
08:40:12 <hyperisco> I really don't because then it is not linear
08:40:34 <phadej> 3 km * 1 N = 3 kJ (IIRC)
08:40:42 <Solonarv> that's a group (written multiplicatively)
08:40:45 <hyperisco> yeah, I don't want that
08:41:57 <phadej> hyperisco: you still have multiplication, there's an abstract 1-unit 1 * m = m
08:42:18 <hyperisco> phadej, that is different
08:42:50 <phadej> vector space is 3 * 9m = 27 m; not sure if you are after that one
08:43:09 <phadej> where "SI unit" is a basis vector
08:43:21 <hyperisco> with a module one can scale units, because a particular unit is a module, so I can solve  3*(9m) = x  but what if I want to solve  k*(9m) = 27m  ? That is also sensible but not part of a vector space
08:43:31 <hyperisco> (or part of a module)
08:43:41 <Uniaika> phadej: <3
08:44:21 <Solonarv> phadej: that's not a vector space if you allow units of different dimensions
08:44:36 <phadej> but in vector spaces with different "units" as basis (i.e. multiple dimensions) that yeah, vector space isn't either
08:44:38 <Solonarv> in a vector space you can add any two vectors, but adding '1m + 3s' makes no sense
08:44:40 <phadej> I don't know
08:44:50 <phadej> Solonarv: if it's one dimensional it works
08:45:19 <Solonarv> yes, so you have a separate (one-dimensional) vector space for every dimension
08:45:24 <Solonarv> of which there are infinitely many
08:46:51 <hyperisco> the product of vector spaces is a vector space, and so the product of all units is a vector space…
08:46:54 <Solonarv> "dimension" itself is a ℚ-vector space with basis vectors like (usually) {Time, Length, Mass}
08:47:08 <hyperisco> 1m + 1s  doesn't make sense but  (1m, 0s) + (0m, 1s)  does :P
08:47:12 <phadej> but for physical units i'd use abelian group
08:47:31 <phadej> not allowing to multiply meters by seconds doesn't make sense to me
08:47:38 <Solonarv> this dimension-space is an abelian group!
08:47:45 <nshepperd_> Different units are also a module, but multiplicative
08:48:20 <Solonarv> it's a ℚ-vector space instead of a mere ℤ-module because we do occasionally need fractional powers of units/dimensions
08:49:09 <hyperisco> phadej, it doesn't make sense in this context because a value like  3m  is a vector, and what is vector multiplication?
08:49:36 <Solonarv> vector multiplication isn't usually a thing
08:50:00 <Solonarv> you can multiply a vector with a scalar (in this case: a unitless number), but not with another vector
08:50:52 <phadej> you can: https://en.wikipedia.org/wiki/Geometric_algebra#The_geometric_product
08:51:23 <phadej> and if basis vectors form abelian group; ab = ba, "normal stuff" falls down
08:51:27 <phadej> so 2m * 3s = 6ms
08:52:05 <Cale> Cases in which fractional powers of units can be interpreted as meaningful are exceptionally rare
08:52:11 <Solonarv> oh, *that* is what you meant
08:52:25 <hyperisco> typical mathy statement to say  ab = 1/2(ab + ba) …  what is this recursive?
08:52:31 <Solonarv> Cale: yeah, I recall that there exists one but I can't even remember what it is
08:53:31 <phadej> but what I said is nonsense
08:53:59 <phadej> i think that _units_ form an abelian group, and then numbers are tagged by that group
08:54:11 <zincy> What would the next steps towards type checking look like here in my interpreter? https://github.com/therewillbecode/functional-interpreter/blob/master/src/Interpreter.hs 
08:54:59 <phadej> your Exp is well-typed by construction, isn't it?
08:55:16 <zincy> Yep
08:55:28 <zincy> Not sure about the lambda exps though
08:55:35 <Solonarv> no, not quite well-typed by construction
08:55:45 <phadej> I see, yeah, FunCall isn't
08:55:52 <phadej> Exp (a -> b) -> Exp a -> Exp b would be
08:55:52 <Solonarv> Let also
08:56:04 <Solonarv> and Lambda
08:56:05 <phadej> and Variable having proper context
08:56:11 <hyperisco> at any rate, what I'm actually looking for is an extension of vector spaces which allows one to determine by what do you scale u to get v assuming they are colinear? though really vector spaces may not be the appropriate perspective
08:56:12 <phadej> it's half-way there
08:56:27 <zincy> Yeah those two aren't well typed because I am not constraining the type variable there right?
08:57:27 <Solonarv> hyperisco: if you have an inner product space you can check whether <u,v> == |u| * |v| to see if they're colinear, and then do |u|/|v| to figure out the scaling factor
08:57:53 <hyperisco> er, colinear is a property of points… I mean parallel
08:57:59 <Solonarv> (and you can define |u| = sqrt <u,u>)
08:58:14 <Solonarv> fortunately I correctly guessed what you meant anyway :P
08:59:26 <Solonarv> hyperisco: so, the extension you're looking for is "inner product space"
08:59:44 <hyperisco> thankfully I already have those codified… so lets see here…
08:59:47 <Cale> Solonarv: If you're willing to include rational exponents, might as well include real ones. It basically comes up with measuring certain fractal and probabilistic processes.
09:00:01 <Solonarv> Cale: oh, I didn't know that - sure!
09:00:31 <Solonarv> anyway, gotta go
09:00:37 <Cale> Solonarv: For example, there are processes where you have a quantity that jumps around such that the probability density of a hop of length l is proportional to 1/l^(1+b) for some b
09:00:39 * Solonarv should really set up a bouncer
09:01:23 <Cale> and then if you want to calculate the probability of finding the particle at a given place after a certain number of steps, you end up with quantities that have fractional units
09:01:28 <zincy> So how would I ensure that lambda expressions are well typed?
09:01:40 <Cale> (with b in their exponent)
09:02:26 <Cale> zincy: Need to write a typechecker?
09:02:34 <zincy> yeah
09:02:36 <hyperisco> Solonarv, but how do I then do |u|/|v|? I don't have a magnitude operation… I have positive-definite quadratic form on Euclidean spaces…
09:02:58 <zincy> Cale: Just not sure how far GADT's will take me before I need to start implementing ML type inference
09:03:20 <Cale> zincy: Ah, well, GADTs let you steal Haskell's type system and subvert it for your own uses.
09:04:01 <zincy> Cale: Yeah GADT's seem powerful
09:05:31 <hyperisco> I mean, I can do that, I just need something stronger than an inner space
09:08:02 <tabaqui> how can I builds projects with stack in parallel?
09:08:38 <tabaqui> like I "packages: ["a", "b", "c"]" and want to use all my cores to build them
09:08:47 <nshepperd> Cale: wouldn't you divide l by some universal constant to make it unitless there?
09:09:05 <tabaqui> and some of them can be built parallel too (on cabal project level)
09:11:27 <tabaqui> err, looks like "jobs" key is responsible for that
09:11:35 <tabaqui> and by default stack tries to load all cores
09:11:42 * phaul is happy as the Coroutine stuff now works. it passes the checks on submission.
09:12:23 <tabaqui> oh, it works by default on stack level
09:13:47 <tabaqui> ghc-options: {"*": "-j"} enables it on cabal level, but it cause to overloading if is enabled with "jobs" at the same time
09:21:49 <Taneb> Why is there no instance IsList (ZipList a)?
09:26:16 <lyxia> It's waiting for you to write it.
09:28:20 <infinisil> Taneb: have you tried implementing it?
09:28:40 <infinisil> Oh wait, ziplist
09:30:07 <Taneb> infinisil: it's pretty trivial to implement
09:30:49 <Taneb> There was a mailing list proposal in 2015 but it didn't seem to go anywhere...
09:31:38 <infinisil> Yeah weird
09:34:56 <infinisil> (I initially thought of Swift's Zip2Sequence, which is the result of a zip, which couldn't implement ToList)
10:03:38 <tabaqui> ZipList has no Monad instance too
10:03:50 <tabaqui> I don't really sure, that there exists sane implementation
10:03:59 <tabaqui> but I don't see any contras
10:08:20 <Taneb> tabaqui: there's no possible Monad instance for ZipList compatible with its Applicative instance
10:09:22 <tabaqui> Taneb: because of "<*> = ap" law?
10:09:37 <Taneb> tabaqui: yeah
10:10:41 <Taneb> I managed to prove that in a job interview a couple of years ago but I've got no idea how
10:11:24 <Taneb> I think it was the "x >>= pure === x" law?
10:12:01 <tabaqui> I don't think so
10:12:14 <tabaqui> In Haskell Monad is not the math monad
10:12:28 <tabaqui> because it requires Applicative instance, while math's doesn't
10:12:44 <Taneb> I believe that's a coincidence that Hask has
10:12:48 <tabaqui> so it is about something related to Applicative
10:12:59 <Taneb> That every Monad on Hask gives rise to an Applicative
10:13:09 <Taneb> tabaqui: and pure is definitely something to do with Applicative
10:13:22 <Taneb> > pure 'a' :: ZipList Char
10:13:23 <tabaqui> iirc, it is something about ghc optimizations
10:13:24 <lambdabot>  ZipList {getZipList = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...
10:13:57 <tabaqui> wow
10:14:01 <zincy> Taneb: What was the company?
10:14:07 <Taneb> zincy: Myrtle
10:15:00 <zincy> Taneb: Where do you work now?
10:15:21 <Taneb> Also Myrtle ;) (I got the job)
10:15:46 <zincy> Taneb: Do you offer remote working?
10:16:32 <Taneb> Sadly not
10:16:50 <zincy> Ah ok
10:17:11 <zincy> Do you ever take on people with a year of Haskell under their belt?
10:17:31 <Taneb> Yes, if they've got other functional programming or hardware or machine learning experience
10:17:56 <zincy> That is all I have.
10:18:17 <zincy> Just curious would a technical degree benefit my application?
10:19:03 <zincy> Because it seems like there a two kinds of programming jobs: 1. Relies on CS knowledge 2. Doesn't. 
10:19:07 <zincy> *are
10:19:15 <Taneb> It's not going to hurt it
10:19:30 <zincy> For type 1 jobs is a technical degree going to be needed?
10:20:09 <Taneb> Strictly no, but I bet some recruitment people will through your CV away
10:20:13 <Taneb> Without a degree
10:21:13 <zincy> So is the Myrtle premise to gain more efficiency for ML through novel hardware?
10:21:30 <Taneb> That's exactly it
10:21:35 <dmwit> ?src ap
10:21:36 <lambdabot> ap = liftM2 id
10:21:46 <zincy> Cool
10:22:08 <zincy> Taneb: How do compilers come into play?
10:22:46 <zincy> Just looking at the job description "• Knowledge or experience of writing compilers "
10:22:50 <Taneb> A lot of what we've done is make compilers from neural networks to circuits
10:24:35 <Taneb> And compilers in the sense of "translating one code-like structure into another, possibly completely different code like structure, with identical behaviour" is very up our alley
10:28:15 <zincy> What is this Hask I keep hearing about
10:28:31 <zincy> Is it a category named after Haskell Curry
10:28:37 <Taneb> zincy: indirectly, yes.
10:28:45 <Taneb> It's the category of Haskell types and functions
10:28:54 <dmwit> ?let notBind (ZipList xs) f = ZipList . concat $ zipWith (\n -> take 1 . drop n . getZipList . f) [0..] xs
10:28:56 <lambdabot>  Defined.
10:29:13 <dmwit> ?let notAp l r = notBind l (\f -> notBind r (pure . f))
10:29:14 <lambdabot>  Defined.
10:29:22 <dmwit> > notAp (ZipList [not, id] [True, False])
10:29:24 <lambdabot>  error:
10:29:24 <lambdabot>      • Couldn't match expected type ‘[Bool] -> ZipList (a1 -> a2)’
10:29:25 <lambdabot>                    with actual type ‘ZipList (Bool -> Bool)’
10:29:25 <dumptruckman_> Anyone have any suggestions for haskell courses?
10:29:33 <dmwit> > notAp (ZipList [not, id]) (ZipList [True, False])
10:29:35 <lambdabot>  ZipList {getZipList = [False,False]}
10:29:50 <dmwit> No problem.
10:29:56 <dmwit> ;-)
10:31:24 <dmwit> (Yes, it violates at least one Monad law.)
10:32:10 <zincy> dumptruckman_: Monadic Party
10:32:14 <dmwit> ?where tutorials
10:32:14 <lambdabot> http://haskell.org/haskellwiki/Tutorials
10:32:33 <tabaqui> I've started from "join" implementation :)
10:32:37 <tabaqui> but not finished yet
10:33:05 <dmwit> I think join makes it pretty clear what goes wrong.
10:33:36 <zincy> Is it necessary when designing a typed DSL to keep track of the types of variables in scope?
10:33:50 <tabaqui> well, it satisfies Functor laws now, but I didn't tested with Applicative ops
10:33:50 <dmwit> You want the diagonal. But the diagonal could have holes in it. So what should you do then?
10:33:52 <dumptruckman_> if only my company's L3 funds would cover travel costs :(
10:34:03 <tabaqui> right, I want diagonal
10:34:08 <tabaqui> hmm, dunno
10:34:21 <dmwit> zincy: Almost certainly yes.
10:34:47 <zincy> What is the simple way of doing this?
10:34:48 <dmwit> dumptruckman_: Check the wiki page I linked above.
10:34:49 <tabaqui> alright, but I'm sure it will not work with infinite columns
10:35:05 <zincy> https://stackoverflow.com/a/38601492/3946931
10:35:09 <zincy> ^ That is the hard way
10:35:43 <portnov> hi all
10:35:58 <zincy> hi
10:35:59 <dmwit> zincy: Do it at runtime instead. As I said in my comment there.
10:36:28 <zincy> dmwit: What if you want static type checking?
10:36:45 <dmwit> That's fine. You just can't reuse GHC's type-checker, that's all.
10:36:51 <portnov> Q: could you recommend a thread-safe mutable hash-map library? for multiple reader and writer threads
10:37:02 <dmwit> You do it at the runtime of the program you're writing in Haskell, not at the runtime of the program you've written in the DSL.
10:37:25 <d34df00d_azoth> Hi!
10:37:35 <d34df00d_azoth> Looks like I have a few questions about deriving instances today.
10:37:52 <portnov> I see "hashtables", but do not see any words about thread-safety in it's documentation; and I see "stm-containers", but i'm not sure if I really need STM
10:38:21 <Solonarv> stm-containers would be my recommendation
10:38:22 <dmwit> STM is great. There's very few reasons to avoid it. The attitude "do I need STM" is weird and backwards.
10:38:36 <d34df00d_azoth> Let's say I have a type like this: data Debtor = Debtor { companies :: S.HashSet T.Text, aggPhones :: IS.IntSet, totalDebt :: Sum Int } deriving (Eq, Show, Generic)
10:38:51 <d34df00d_azoth> How do I derive Semigroup instance for it? I know there is generic-deriving, ubt it does not really work for me in this case.
10:38:54 <portnov> okay...
10:38:56 <dmwit> Forwards is "Is STM a good solution for my problem?".
10:39:03 <d34df00d_azoth> Namely, I get
10:39:07 <d34df00d_azoth> No instance for (GSemigroup (S.HashSet T.Text)) arising from a use of ‘gsappenddefault’
10:39:16 <portnov> dmwit: ok, and how do I answer that question? :)
10:39:20 <zincy> dmwit: Ah ok, so the runtime of your haskell program is the compile time of your DSL?
10:39:33 <Solonarv> zincy: precisely!
10:39:35 <dmwit> zincy: Can be. Depends on what Haskell program you write, of course!
10:39:55 <d34df00d_azoth> (where S is Data.HashSet and IS is Data.IntSet)
10:40:11 <Solonarv> portnov: in this case you want thread-safe shared mutable data structures, so STM seems like it might be helpful
10:40:22 <dmwit> portnov: No idea. If the only library you've found that matches your needs uses STM, then it seems like your options are use STM or write your own. Which seems better to you? (I know which seems better to me.)
10:40:26 <Solonarv> in particular I have heard good things about the performance of stm-containers
10:40:54 <portnov> ok, thanks
10:41:01 <dmwit> d34df00d_azoth: But Semigroup /= GSemigroup!
10:41:55 <tabaqui> d34df00d_azoth: do you really need of Generics?
10:41:57 <dmwit> d34df00d_azoth: Ah, I understand now. Ignore my previous comment.
10:42:13 <d34df00d_azoth> tabaqui: how would I do without them?
10:42:29 <portnov> d34df00d_azoth: i guess you need to do {-# LANGUAGE StandaloneDeriving #-} and then "instance GSemigroup (S.HashSet a)"
10:42:29 <zincy> Can you have STM implementations in impure languages?
10:42:33 <d34df00d_azoth> dmwit: yeah, if I understand correctly, that's how it's intended to be used.
10:42:55 <dmwit> d34df00d_azoth: I mean, I'm not sure I would bother going to much trouble. The hand-written instance is v. short anyway. `instance Semigroup Debtor where Debtor cs ps d <> Debtor cs' ps' d' = Debtor (cs <> cs') (ps <> ps') (d <> d'); instance Monoid Debtor where mempty = Debtor mempty mempty mempty`.
10:43:11 <tabaqui> d34df00d_azoth: all your record fields already have Semigroup instances
10:43:35 <tabaqui> so you can just derive without any additional movements
10:43:40 <dmwit> zincy: There exist such. They rely on the programmer to avoid doing impure things.
10:43:52 <d34df00d_azoth> dmwit: yeah, it'd be really short, but it'd be nice to have the compiler do it for me (especially given that I'm gonna show this code as an alternative solution to some problem :)).
10:43:53 <dmwit> zincy: No promises what happens if the programmer screws up on this promise.
10:44:07 <d34df00d_azoth> tabaqui: you mean, writing the implementation by hand?
10:44:39 <zincy> So purity is crucial for STM so you can rollback transactions?
10:45:06 * dmwit nods agreeably in zincy's direction
10:46:03 <tabaqui> d34df00d_azoth: oh, I see
10:48:36 <infinisil> zincy: In stm API's in other programming languages, you have to trust the user to only use functions like `x = STMCreate`, `STMSet(x, 10)`, etc. in the transaction
10:48:39 <dmwit> d34df00d_azoth: https://gist.github.com/dmwit/8391b0e4f0a92a128ae729c466e26a46 works for me
10:48:40 <d34df00d_azoth> Hmm, why isn't there an instance Semigroup a => GSemigroup a
10:48:49 <infinisil> Anything else they do will mess it up, and the programming language can't guard against that
10:49:16 <d34df00d_azoth> dmwit: it seems to work unless you have something like IntSet in your type.
10:49:34 <tabaqui> dmwit: DeriveAnyClass creates stubs, doesn't it?
10:49:37 <d34df00d_azoth> Which is a perfect semigroup, but generic-deriving does not know how to use it.
10:49:44 <zincy> So Haskell gives a type error if you try and do IO inside STM transactions and that prevents the impure actions?
10:49:59 <dmwit> tabaqui: Yes. That is precisely what is needed for GMonoid and GSemigroup: stubs.
10:50:21 <zincy> What happens if you have a monad stack with IO and STM in it
10:50:32 <infinisil> zincy: You don't :)
10:50:41 <infinisil> Because then you can't get STM's guarantees anymore
10:50:51 <tabaqui> dmwit: it works indeed
10:50:59 <zincy> So Haskell doesn't prevent it then does it?
10:51:07 <zincy> It is is simply discouraged
10:51:11 <infinisil> It doesn't prevent what?
10:51:29 <infinisil> Ah no you can't have IO in STM, that's a no-go in haskell and gives you type errors
10:51:39 <tabaqui> I don't understand how GSemigroup works here, but it works
10:51:44 <zincy> Oh so you get a type error
10:51:48 <infinisil> Yeah
10:51:59 <infinisil> (well there's ways to get around it, but using bad functions)
10:52:16 <tabaqui> like, stubs should raise exception, but they don't
10:52:21 <Solonarv> with scary names that start with unsafe*
10:52:21 <zincy> So in a monad stack you are only ever in one monad at once?
10:52:26 <MarcelineVQ> though you can have STM return IO actions you then run
10:52:35 <infinisil> zincy: It wouldn't be a monad *stack* if you only used 1 monad
10:52:43 <MarcelineVQ> s/return/result in
10:52:44 <dmwit> d34df00d_azoth: Oh, this is a bug in generic-deriving.
10:53:09 <dmwit> d34df00d_azoth: You should file a feature request to use Semigroup constraints on the contained types rather than GSemigroup ones.
10:53:16 <dmwit> d34df00d_azoth: (Similarly for Monoid/GMonoid.)
10:53:25 <zincy> Each computation is in one monad at once and lifted to the outer monad tho
10:53:29 <dmwit> d34df00d_azoth: It shouldn't be too hard to fix it up yourself if you want.
10:53:55 <d34df00d_azoth> dmwit: oh I see, I was thinking in a different direction.
10:53:58 <d34df00d_azoth> This one makes more sense.
10:54:14 <d34df00d_azoth> Yeah, I guess I'll throw up a PR.
10:54:20 <d34df00d_azoth> Thanks!
10:54:43 <dmwit> tabaqui: All the GSemigroup methods have defaults if the thing is also an instance of Generic (which Foo is).
10:55:01 <infinisil> zincy: Ah yeah
10:55:20 <dmwit> zincy: Monad stacks are usually composed of transformers layered on a base monad.
10:55:30 <dmwit> zincy: There is no transformer version of IO, ST, or STM.
10:55:36 <tabaqui> dmwit: okaay, didn't know it, thanks
10:55:38 <dmwit> (There may be other immiscible ones, as well.)
10:55:47 <zincy> data  Variable = Variable {  value :: Value, type :: Type }
10:55:49 <zincy> dmwit: Is this what you mean with the typed scoping 
10:56:13 <zincy> And then Type is just a sum type of data constructors representing DSL types
10:56:25 <tabaqui> dmwit: except of monad-control and friends
10:56:34 <dmwit> Um. I'd probably have it be `name :: VariableName, type :: Type`, but... yes-ish?
10:56:50 <dmwit> tabaqui: eh?
10:57:18 <Solonarv> tabaqui: no, those aren't transformer verisons of IO/ST/STM
10:57:41 <Solonarv> instead they let you get to the IO/ST/STM at the bottom of your stack
10:57:58 <tabaqui> Solonarv: why not? It allows you to lift states of underlying monad
10:58:09 <tabaqui> if combined with mtl classes
10:58:36 <Solonarv> yes, but that doesn't mean that there are transformer versions of IO/ST/STM
10:58:46 <Solonarv> there are *transformed* versions of them
10:58:51 <Solonarv> but that's a very different thing!
10:59:10 <tabaqui> I consider them like somewhat dirty transformers
10:59:26 <dmwit> Then your consideration is confused.
10:59:36 <Solonarv> they're not monad transformers in any way
10:59:42 <dmwit> Or let's attack this in another way.
10:59:48 <dmwit> You ask, "What if I have IO and STM in the same stack?".
11:00:05 <dmwit> My question is: before answering, please show me a stack which has that property.
11:00:37 <tabaqui> well, you cannot mix them
11:00:47 <pinkunicorn> bgamari: please tell me does some information about deleting GHC fork?
11:01:19 <zincy> You can't lift a monad into IO
11:01:29 <dmwit> Oh, I am attacking the wrong person!
11:01:37 <zincy> :D
11:01:39 <d34df00d_azoth> Ok, next question then. So I'm trying to parse a JSON with a flaky scheme (example objects are https://bpaste.net/show/9852a4ab9618 ), and, being lazy, I'm trying to do that by throwing up types representing the possible variants in the input json.
11:01:55 <d34df00d_azoth> What I have right now is
11:02:12 <d34df00d_azoth> https://bpaste.net/show/eade87a961a1
11:02:19 <zincy> But you can lift IO into a monad that has an instance of MonadTrans
11:02:31 <d34df00d_azoth> Can I do better? Can I reuse (,) or Either somehow instead of AnyTag?
11:02:36 <Solonarv> beep beep, ill-kinded sentence detected
11:03:08 <d34df00d_azoth> So this is more of Aeson question than Haskell question.
11:03:25 <zincy> Solonarv: Where :)
11:03:35 <fen> > :t \f g -> (f .) . g
11:03:37 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
11:03:44 <Solonarv> "a monad that has an instance of MonadTrans"
11:03:50 <fen> % :t \f g -> (f .) . g
11:03:50 <yahb> fen: (b -> c) -> (a1 -> a2 -> b) -> a1 -> a2 -> c
11:03:56 <fen> can we do that at type level?
11:04:13 <tty1_> how would i go about making a reference to another "object" in haskell (as opposed to just a copy)? If it would help i can give the real world problem im trying to solve.
11:04:26 <zincy> Solonarv: Has an instance?
11:04:27 <Solonarv> a monad is something of kind Type -> Type, but MonadTrans :: ((Type -> Type) -> Type -> Type) -> Constraint
11:04:39 <Solonarv> hence: ill-kinded
11:04:49 <zincy> So a monad /= monad transformer
11:04:58 <boj> tty1_: you may want to lay out the problem you are solving
11:05:01 <zincy> different kinds right?
11:05:03 <zincy> so no
11:05:05 <Solonarv> yes
11:05:18 <tty1_> boj: sure i can do that
11:05:22 <zincy> Thanks that is why I speak out loud to see if I pass the scanner
11:05:23 <Solonarv> roughly, a monad transformer is something that gives you a monad for any monad you give it
11:05:46 <Solonarv> so if T is a monad transformer that means T M is a monad whenever M is a monad
11:05:52 <fen> zincy: a monad transformer partially applied to Identity gives a kind of canonical version, might be the original Monad the transformer was created from
11:06:13 <zincy> Ah ok so until the type constructor for T is fully applied we have a monad transformer
11:06:22 <zincy> What is it called if it is partially applied?
11:06:23 <Solonarv> well, not fully applied
11:06:34 <zincy> Not applied at all right
11:06:54 <zincy> fen: Interesting property
11:06:57 <Solonarv> no - 'ReaderT Int' is partially applied, but it's a monad transformer alright
11:06:59 <tty1_> basically i want to write some sort of a data object that would represent a graph (as in graph theory).. Namely, it would be a data structure that would contain a Set of arbitrary objects (nodes they can be anything), as well as a list of associations (you can think of them as a list of 2-tuples where each of the elements of the tuple is a reference to one of the nodes)
11:07:27 <tty1_> So i want my list of associations to refer to the nodes in the hash set, rather than simply being copies of the nodes
11:07:31 <zincy> Is ReaderT Int IO Int a monad transformer?
11:07:39 <Solonarv> no, it's just a value
11:07:43 <freeside> i have a fresh question! if i had two arrays xs::[Int] and ys::[Int], and i wanted every combination of xs and ys, I would do a list comprehension: [ (x,y) | x <- xs, y <- ys ]. now, instead of just two arrays xs and ys, i have n arrays, where n could be 2 or 3 or 4 or more. how would i develop an n-dimensional space of all possible combinations?
11:07:52 <Solonarv> er, a type of values
11:08:14 <freeside> the n arrays are, of course, in some sort of [[Int]]
11:08:22 <tabaqui> freeside: (,,,) <$> xs <*> ys <*> zs <*> vs...
11:08:27 <bgamari> pinkunicorn, oh dear, sorry about that
11:08:35 <freeside> but i don't know the length of [[Int]]
11:09:02 <Solonarv> informally we might call it a monad transformer because it happens to be the application of a monad transformer to a bunch of arguments
11:09:14 <zincy> So monads can't have an instance of MonadTrans (wrong kind) 
11:09:14 <fen> tty1_ why does your lookup table graph not have copies?
11:09:25 <bgamari> pinkunicorn, just a moment, I was distracted before I had a chance to finish yesterday
11:09:29 <Solonarv> zincy: precisely
11:09:42 <dmj`> zincy: monad transformers are of the kind (* -> *) -> (* -> *)
11:09:44 <tty1_> fen: i dont have any table yet.. im just thinking about how i would implement such a thing in a sane way as a data structure in haskell
11:09:48 <Solonarv> additionally, even if I generously interpret your original statement it's not true
11:09:51 <zincy> But monad transformers are types  which are of ^ that kind
11:09:55 <bgamari> pinkunicorn, can you remind me of the project URL?
11:09:56 <tabaqui> freeside: so how can you convert it in a fixed-length tuple?
11:09:58 <fen> tty1_ why are you asking about copies?
11:10:06 <zincy> Is it a necessary condition to be an instance of MonadTrans too
11:10:26 <Solonarv> newtype RIO env = RIO { runRIO :: env -> IO a } -- this is not a monad transformer, but it can easily have a MonadIO instance
11:10:41 <freeside> if i don't know the cardinality of the space ahead of time, then maybe i can't have the outputs be in a tuple; maybe they can be in an array?
11:10:55 <Solonarv> they can be in a list, yes
11:11:05 <Solonarv> the function you're looking for is 'sequence'
11:11:12 <freeside> the function i'm looking for is 'sequence'.
11:11:16 <tty1_> fen: because the same node needs to be references in more than one spot in the data structure?
11:11:27 <tabaqui> freeside: http://okmij.org/ftp/Haskell/polyvariadic.html#polyvar-fn
11:11:30 <Solonarv> > sequence [[1,2,3], [10,20,30]]
11:11:32 <lambdabot>  [[1,10],[1,20],[1,30],[2,10],[2,20],[2,30],[3,10],[3,20],[3,30]]
11:11:32 <tabaqui> check this out
11:11:38 <boj> tty1_: rather than nested copies distributed through the data structure, maybe references that point back to the object stored in another structure?
11:11:39 <freeside> hot
11:11:45 <Solonarv> don't need to mess around with polyvariadic functions
11:11:51 <fen> tty1_ you mean you dont want to strictly evaluate them and have some reuse of the original value?
11:12:00 <pinkunicorn> bgamari: thank you! Here my fork: https://gitlab.haskell.org/Pluralia/ghc (I don't want to delete it anymore)
11:12:02 <tabaqui> or use Traversable :)
11:12:38 <tty1_> maybe ill try to write something first so i can show why i dont think it would work.. an example would be better to get help here since i cant demonstrate the problem i envision yet (assuming its even a problem)
11:12:50 <boj> tty1_: good plan :)
11:13:00 <tty1_> :) thanks though for the help, ill check back
11:13:53 <fen> something about using the hashes instead of the values?
11:14:41 <tty1_> i was just thinking how in haskell everything is a immutable copy.. but i may have been overthinking now that I think about it
11:14:58 <fen> cant you have the value as the lookup applied to the hash, and then eg map into the hash to change it, or whatever you want to do
11:15:27 <fen> to give it the type of a value, but to be able to modify the position of the value without examining its contents?
11:15:45 <Solonarv> tty1_: "in haskell everything is an immutable copy" is false
11:16:02 <bgamari> pinkunicorn, would you mind if I deleted the fork and create a new one?
11:16:05 <Solonarv> the fact that values are immutable means the compiler is free to not copy them
11:16:15 <tty1_> Solonarv: Well I should have say "by default".. i think there are ways to get mutable things I just dont know what that is yet...
11:16:27 <tabaqui> ST
11:16:27 <Solonarv> yes, that too
11:16:49 <fen> so what is (f .) . g at type level?
11:16:52 <tty1_> Solonarv: ohh right well yea they arent copies more like pointers internally im sure. I wasnt suggesting it is inefficient.
11:16:53 <Solonarv> % import GHC.Exts (reallyUnsafePtrEquality#)
11:16:53 <yahb> Solonarv: 
11:17:11 <tabaqui> but it is not cool if you don't need shared memory or arrays with O(1) index complexity
11:17:14 <tty1_> I meant copy at a high level, not at the low-level
11:17:39 <boj> i followed what you meant tty1_ 
11:17:57 <boj> not about efficiency, but sharing
11:18:00 <Solonarv> % ptrEq !x !y = x `pseq` y `pseq` (isTrue# (reallyUnsafePtrEquality# x y))
11:18:00 <yahb> Solonarv: 
11:18:01 <zachk> tty1_, there are IOref, MVar, and TVar's 
11:18:10 <fen> like if you have a type family returning type * -> * -> * but you want to modify the values it will be provided with using some computation from within that type family
11:18:26 <tty1_> Solonarv: in the case of my problem would be if i have two seperate nodes called 1, and they each had their own seperate associations I'd have to make sure i delete the correct one. Which i could do by just adding some sort of a uuid to distinguish what is contained inside of a node. But i suspect there is a better way
11:19:01 <Solonarv> tty1_: well, you can't "mutate the wrong copy" if you can't mutate in the first place
11:19:07 <fen> or is that some kind of terrible hack around the limitations of partially applied type families that would be impossible for some reason?
11:19:29 <pinkunicorn> bgamari, will all changes be lost?
11:19:30 <tty1_> Solonarv: true, i guess in this case mutate means to create a copy that is similar but with the applied change.
11:19:45 <boj> tty1_: if two 1 nodes have different associations then they aren't the same anyways :)
11:19:49 <tty1_> anyway ill try to hack together an attempt at this i guess.. using uuid or something
11:20:03 <bgamari> pinkunicorn, yes
11:20:28 <fen> oh wait, maybe (f .) . g isnt the right thing to begin with
11:20:31 <Solonarv> fen: if you're interested in partially applied type families, read this paper: https://www.microsoft.com/en-us/research/uploads/prod/2019/03/ho-haskell-5c8bb4918a4de.pdf
11:20:44 <tty1_> boj: right they arent the same, but they would be seen as the same if i dont give a way to distinguish them.. which is the problem.; in other languages i might just use a pointer for that.. different pointers that each point to different integers. Obviously pointers arent an option in haskell
11:20:47 <bgamari> I don't believe it's possible to unqueue the repository for deletion
11:20:48 <bgamari> so if there are any changes you want to preserve you should be sure to pull them to a local repository
11:20:51 <fen> how do you map over either input value of a function taking 2 arguments?
11:20:57 <fen> is that a bifunctor instance or something?
11:21:00 <tty1_> hope that explains better why im getting tripped up
11:21:09 <pinkunicorn> bgamari, if there isn't another way, I agree
11:21:59 <boj> tty1_: your point of view definitely makes sense coming from another language. finding the right data structure in haskell can be an interesting problem to solve
11:22:15 <fen> Solonarv: oh, they are making ~> part of GHC?
11:22:35 <Solonarv> fen: yes
11:23:38 <fen> might be worth trying to build their preliminary GHC to see if it helps with all these difficulties, code without that feature is very annoying 
11:23:45 <Solonarv> although they write ->> for the unmatchable arrow - which is fair, because ~> is already used in library code
11:23:55 <bgamari> pinkunicorn, alright
11:24:16 <Solonarv> fen: yes, the paper observes that the new extension makes the type-level code of generic-lens about 80% smaller
11:24:27 <fen> wow
11:24:37 <fen> you know where we can get at this repo/
11:24:38 <fen> ?
11:25:03 <dmwit> d34df00d_azoth: Do you need to reproduce the original JSON?
11:25:49 <dmwit> If not, I think I would do this a bit differently.
11:25:52 <fen> % :set -XUnsaturatedTypeFamilies
11:25:52 <yahb> fen: Some flags have not been recognized: -XUnsaturatedTypeFamilies
11:25:58 <fen> :-(
11:29:43 <fen> ok well might just have to persevere with symbols for now
11:29:47 <Solonarv> fen: https://gitlab.haskell.org/kcsongor/ghc/tree/unsaturated_type_families -- there's the fork
11:29:53 <tty1_> boj: I think i will just give nodes uuids to solve the problem i would solve with a pointer in another languages
11:30:01 <Solonarv> just took some poking around on gitlab.haskell.org
11:30:15 <tty1_> boj: but ill try to keep the uuid hidden outside the module
11:30:44 <d34df00d_azoth> dmwit: nope, I don't really.
11:30:53 <d34df00d_azoth> I just need to aggregate it in some way.
11:32:08 <fen> gitlab is giving some 502 error...
11:32:22 <bgamari> fen, sorry about that
11:32:47 <bgamari> fen, I restarted it
11:32:47 <bgamari> it will be back up momentarily
11:33:20 <Solonarv> hah, such perfect timing
11:37:18 <bgamari> pinkunicorn, alright
11:37:18 <bgamari> pinkunicorn, It took a while but things should be sorted now
11:37:18 <fen> any idea when its going to be released as part of the haskell platform?
11:37:34 <Solonarv> what, unsaturated type families?
11:37:38 <fen> yeah
11:37:58 <dmwit> d34df00d_azoth: I'd do something like this, I think: https://gist.github.com/dmwit/7ef3dd25c4ee05f55352247f671beb10
11:37:59 <Solonarv> that was supposed to be in 8.8 but I'm not sure what the deadlines look like
11:38:18 <Solonarv> so 8.8 or maybe 8.10
11:38:19 <dmwit> d34df00d_azoth: Untested, and so certainly wrong and probably not even type-correct. But hopefully contains enough of the idea that a human can understand the advice I'm giving.
11:38:25 <fen> worried that building the fork would mess up the current ghc version installed with the haskell platform
11:38:52 <pinkunicorn> bgamari, thank you very much!
11:39:00 <dmwit> d34df00d_azoth: Specifically: don't make a new type just to create a FromJSON instance. Use sensible types, and write the parser you want. If you make that parser available with the name parseJSON later, great, but it's really optional.
11:39:24 <bgamari> pinkunicorn, no worries; sorry it took so long!
11:39:28 <Solonarv> fen: building GHC shouldn't mess up any system-level GHC instance
11:39:33 <fen> its a fairly major undertaking
11:39:39 <Solonarv> but don't ask me how to build GHC; I've never done it
11:39:51 <dmwit> d34df00d_azoth: You're going to drive yourself crazy working with the nested AnyTag things in your version.
11:39:55 <fen> and maybe running a development version would mean people wouldnt be able to help with code errors
11:40:28 <fen> at least there are the likes of jle` around with a working knowledge of symbols
11:40:43 <dmwit> d34df00d_azoth: (If the phone numbers turn out not to be readable integers every time, no big deal, just use String instead of Int and show the Int side instead of reading the String side. My point is to use a sensible type for each field, not some type you chose specifically to cater to aeson's API.)
11:42:04 <fen> yeah, might just try and get the code working with the current tools, even if they do lead to bloated code
11:42:17 <dmwit> d34df00d_azoth: *Especially* if you discover later that there are more variants. You don't want your type to change every time you need to fix a bug in your parser.
11:42:42 <fen> easier to translate something that works into a new syntax rather than trying to wrangle both at the same time
11:45:47 <fen> ah, so unsaturated type familes and type level labdas *are* different things... 
11:47:41 <Solonarv> you can define S and K combinators, which are enough to encode lambdas
11:47:55 <Solonarv> note: K is const, and S is <*>
11:49:04 <fen> wait, how is this extension going to change anything? what difference does it make if the defunctionalisation machenery is built in?
11:51:14 <fen> there would still be all the hassle of having to convert between -> and ->> ?
11:51:47 <fen> like mapping TyCon over lists and stuff
11:54:04 <fen> or is there some class that contains both arrows or something?
11:54:19 <d34df00d_azoth> dmwit: thanks for your input!
11:54:46 <d34df00d_azoth> I indeed considered as a sort of raw internal type that just reflects what could be out there in the json. Perhaps, yes, writing a parser would be nicer.
12:08:56 <LovellyEmma> i have sexy body,big Ass,Nice boobs, Clean WET pussy.See my all picture then knock me. I am sexy girl looking for crazy sex and love sucking dick. Watch me Live FREE: http://um.lk/V-Cams ♥
12:10:04 <iqubic> There are some things one shouldn't try doing in Haskell.
12:10:41 <iqubic> Like attempting to write an interpreter for a procedural language with mutable variables.
12:11:08 <iqubic> Because I need sequenced actions, and I need mutability. Both of which are a pain in Haskell.
12:14:37 <[exa]> iqubic: why though? both of those things are handled cleanly by State
12:14:45 <iqubic> They can?
12:15:11 <iqubic> I thought I'd need to use MVars for sure.
12:16:07 <[exa]> is something wrong about, say, 'State (Map String VarContentsType)' ?
12:16:24 <[exa]> MVars are kindof brutal for such a simple purpose
12:16:25 <iqubic> No. Nothing at all.
12:17:09 <iqubic> Does haskell have support for message passing systems?
12:17:21 <[exa]> you might hit performance considerations though, picking the variable from Map everytime costs something; but then we have vectors, or even mvectors over STM
12:18:39 <iqubic> What *ARE* MVars used for?
12:18:45 <[exa]> iqubic: certainly, but I never used any related package so can't tell for sure
12:18:51 <ProofTechnique> iqubic: https://github.com/sheyll/extensible-effects-concurrent#readme, for instance
12:19:37 <ProofTechnique> Also, https://wiki.haskell.org/Haskell_for_multicores#Message_passing_channels
12:19:37 <[exa]> iqubic: https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent-MVar.html <- three usecases right there
12:20:11 <[exa]> iqubic: it has some tiny wrapper around which handles atomicity and correct sharing between threads
12:20:36 <iqubic> Actually, what I need actually is a mutable 2-d data structure.
12:20:42 <Solonarv> fen: sorry, stepped out for a bit
12:20:49 <Solonarv> did you read the paper yet?
12:20:58 <ProofTechnique> Also also, http://hackage.haskell.org/package/stm-2.5.0.0/docs/Control-Concurrent-STM-TChan.html
12:21:51 <Solonarv> [exa]: actually, modifying one entry in a Vector is much less efficient than doing the same in a Map
12:22:01 <Solonarv> because you have to copy the entire vector each time
12:22:03 <[exa]> iqubic: if you just want something mutable in IO, I'd probably go with IORef. But for normal purposes, go with State
12:22:23 <[exa]> Solonarv: yeah, I followed with mvector because of that
12:22:28 <Solonarv> yup
12:23:41 <iqubic> Well, I'm going to doing plenty of reads and writes to this 2-d structure.
12:23:42 <[exa]> Solonarv: I'd be scared about cache consistency with Map though, especially with small amount of actual data.
12:23:53 <[exa]> Solonarv: needs benchmarking. :]
12:24:25 <[exa]> iqubic: btw what kind of interpreter is that?
12:24:58 <iqubic> Alright... I'm not sure why I called this an interpreter. It really isn't an interpreter.
12:25:04 <Solonarv> Map tends to be shockingly fast, tbh
12:25:18 * [exa] digs in Map source
12:25:52 <iqubic> But this is going to be a 2-d data structure. Not sure how a 2-d map would work.
12:26:12 <Solonarv> Map (Int, Int) Value
12:26:23 <Solonarv> the (Int, Int) tuple is the coordinates
12:26:27 <Solonarv> enjoy! :P
12:26:53 <iqubic> I guess I can do that.
12:26:59 <hyperisco> okay… this is neat… a partial order of  (a, b) ≤ (c, d)  if a ≤ c and ≤ d  gives you a meet and join semilattice which normalises two points to the point of smallest components and point of largest components
12:27:27 <hyperisco> so for defining a rectangle somewhere in space you can normalise the corners
12:27:38 <Solonarv> yeeeah :D
12:27:40 <hyperisco> given any two corners of the rectangle
12:28:21 <iqubic> But let's say I want write a function that takes a (Int, Int) and returns the values at all of the neighbors? How hard would that be to do with a map?
12:28:31 <hyperisco> I was originally using Ord and realised, wait, that doesn't make sense… what makes sense for multidimensional ordering? Well, in this context, a lattice does!
12:28:58 <iqubic> Also, I want to make sure that my function correctly handles the edges.
12:29:35 <Solonarv> iqubic: actually there is a package for working with grids
12:29:35 <Solonarv> https://hackage.haskell.org/package/grid
12:29:55 <iqubic> neighbors :: Map (Int, Int) a -> (Int, Int) -> [((Int, Int), a)] is the sort of thing that I'd like to write.
12:30:10 <[exa]> hyperisco: btw is there a typeclass for lattices?
12:30:21 <hyperisco> Uh, I defined my own, *shrug*
12:30:31 <iqubic> Using a list as output because edges and corners have less than 4 orthoganol neighbors.
12:31:04 <hyperisco> and am actually still working on the details because there is an Applicative Monad problem with Ord… i.e. where is PartialOrd
12:31:26 <hyperisco> on top of which, I have not totally made sense of a 3-way comparison in terms of partial orderings
12:31:45 <[exa]> oh wow, and it's a good one
12:31:46 <Solonarv> actually you can write something like
12:32:32 <[exa]> hyperisco: in lattices it's 4-way, greater/less/same/can't say
12:33:04 <hyperisco> yeah, but I don't know how to make complete sense of  Maybe Ordering
12:33:24 <phadej> @package lattices
12:33:25 <lambdabot> http://hackage.haskell.org/package/lattices
12:33:37 <Solonarv> neighbors grid (x,y) = [ (r, v) | x' <- [x-1,x+1], y' <- [y-1,y+1], let r = (x',y'), Just v <- Map.lookup grid r]
12:33:42 <Solonarv> iqubic: ^
12:34:12 <Solonarv> er, wait, that's not quite right
12:34:15 <[exa]> Solonarv: that does diagonal neighbors
12:34:18 <hyperisco> that incarnation uses Bool
12:34:24 <Solonarv> yes I just noticed :P
12:34:52 <[exa]> Solonarv: best to use plain offsets in such cases, like [(0,1), (0,-1), (1,0), (-1,0)]
12:35:16 <Solonarv> hyperisco: the 'Maybe Ordering' you get from comparing x and y tells you the values of x ≤ y and also of y ≤ x
12:37:10 <[exa]> anyway, what would be the shortest way for generating that sequence without pulling in complex?
12:37:12 <hyperisco> Solonarv, the issue is more like… so classes should have laws, right, and for example Eq is an equivalence relation
12:37:12 <Solonarv> Nothing means neither x ≤ y nor y ≤ x
12:37:13 <Solonarv> Just LT means x ≤ y but not y ≤ x
12:37:13 <Solonarv> Just EQ means x ≤ y and y ≤ x
12:37:13 <Solonarv> Just GT means not x ≤ y but y ≤ x
12:37:33 <Solonarv> oh yes you can still have laws for a partial ordering
12:38:05 <hyperisco> Solonarv, a PartialOrd should also be Eq, so we need  `eq a b = True ⇒ (partialCompare a b = Just EQ)`
12:38:25 <Solonarv> yes, that can be a law of the PartialOrd class
12:38:33 <hyperisco> when it comes to transitivity, I am still muddled
12:38:33 <phadej> it is: http://hackage.haskell.org/package/lattices-2/docs/Algebra-PartialOrd.html#t:PartialOrd
12:39:12 <[exa]> hyperisco: AFAIK in usual literature the implication goes the other way
12:39:20 <Solonarv> well, that class is defined in terms of ≤ rather than a 'partialCompare' 
12:39:33 <hyperisco> [exa], should be a two-way implication really
12:39:34 <[exa]> hyperisco: (but feel free to disregard that, it's impractical for programming)
12:39:35 <Solonarv> also that is supposed to be a two-sided implication
12:39:40 <phadej> if one could justify why the 4-way -> Maybe Ordering def would be good (i.e. a) useful in some scenario; b) interesting partial orderigns where defining partialCompare is simple
12:39:50 <hyperisco> [exa], since either instance can be defined in terms of the other
12:40:04 <Solonarv> yeah, I'm not saying that Maybe Ordering is better
12:40:10 <Solonarv> just that they're equivalent
12:40:16 <[exa]> hyperisco: can you define partial ordering instance from eq?
12:40:18 <nshepperd_> The four cases also correspond to whether meet x y is equal to x, y, both, or neither
12:40:38 <hyperisco> [exa], I can use the eq instance as part of the implementation, yes
12:40:40 <nshepperd_> So you can probably derive the laws from the join/meet laws
12:40:49 <Solonarv> nshepperd_: ah, there it is
12:41:06 <Solonarv> [exa]: Eq alone isn't enough to define a (non-trivial) partial ordering
12:41:26 <Solonarv> the trivial one is the one where x ≤ y exactly when x = y
12:41:29 <hyperisco> `(eq a b = True) <=> (partialCompare a b = Just EQ)`  so everyone is happy
12:41:49 <hyperisco> compose key doesn't like double implication for some reason…
12:42:09 <[exa]> collides with leq/geq
12:42:31 <[exa]> (and arrows)
12:42:32 <Solonarv> <equals> <left> <right> works for me
12:42:37 <Solonarv> ⇔
12:42:45 <hyperisco> I don't exactly know how transitivity should translate for  partialCompare
12:43:31 <hyperisco> originally I said  partialCompare a b <> partialCompare b c = partialCompare a c  but this can't be right
12:44:04 <Solonarv> (partialCompare a b = partialCompare b c = Just p) => partialCompare a c = Just p
12:44:25 <phadej> ...complicated
12:44:40 <phadej> I still don't get, what's the point (except if curious exercise)
12:44:44 <hyperisco> another option is to ditch Comparing
12:45:01 <hyperisco> well because why isn't Ord defined by a Bool predicate?
12:45:33 <hyperisco> I think it is because practically speaking if you've computed if two objects are ordered one way you've also figured out whether they're ordered the other, or are equal
12:45:45 <phadej> hyperisco: it's enough to define <= in Ord
12:45:48 <fen> ok - here is a paste showing the problem; https://pastebin.com/raw/N8aTvUvz
12:46:05 <hyperisco> yes of course but there's a reason compare is in the class
12:46:27 <Solonarv> yes I think that hits the nail on the head - Ordering allows us to avoid duplicating work
12:46:36 <Solonarv> (often, anyway)
12:46:45 <phadej> 22:39  phadej if one could justify why the 4-way -> Maybe Ordering def would be good (i.e. a) useful in some scenario; b) interesting partial orderigns where defining partialCompare is simple
12:46:54 <hyperisco> maybe  partialCompare  can be better explained in terms of  ≤  if we merely make that part of the class too
12:47:21 <Solonarv> yes, ideally I think PartialOrd should have both just like Ord
12:47:44 <phadej> try to write `partialCompare` for https://hackage.haskell.org/package/lattices-2/docs/Algebra-Lattice-N5.html
12:47:44 <hyperisco> and then even given this resolution, now we have an Applicative Monad problem
12:48:01 <hyperisco> the entire ecosystem written on Ord has to be duplicated to work on PartialOrd, where applicable
12:48:09 <[exa]> phadej: :D
12:49:32 <fen> square grids are different to other shapes
12:49:39 <fen> because they form trees
12:49:44 <fen> ie Free []
12:49:48 <Solonarv> phadej: easy
12:49:48 <Solonarv> partialCompare x y = case (x `leq` y, y `leq` x) of ...
12:49:51 <fen> others need cyclic refs
12:50:08 <phadej> Solonarv: ` b) interesting partial orderigns where defining partialCompare is simple`
12:50:18 <fen> any ideas on the above paste?
12:50:21 <Solonarv> hey, I never said I had an answer to b)
12:50:27 <Solonarv> just to a)
12:50:29 <Solonarv> :P
12:50:38 <[exa]> Solonarv: what's the result of N5b `leq` N5c ?
12:50:44 <hyperisco> I think you're looking for a partial ordering which specifically isn't a total ordering
12:50:53 <Solonarv> [exa]: False
12:50:59 <phadej> hyperisco: I do
12:51:02 <hyperisco> I gave such an example earlier to normalise the corners of a rectangle
12:51:26 <hyperisco> it is a partial ordering built on two total orderings
12:51:41 <Solonarv> well, there defining <= is easier
12:51:43 <fen> eg if you go down left up right on a square grid you get back where you started, but this isnt the case for eg triangle grids
12:51:50 <hyperisco> so assuming the total orderings have a useful compare, so does the partial order
12:51:58 <fen> the orthogonal 1d directions form a Euclidean space
12:52:12 <fen> this is ruined if you start trying to use triangles or hexagons
12:52:14 <Solonarv> phadej asked about a non-total partial odering where partialCompare is easier to define than <=
12:52:24 <phadej> or at least as easy
12:52:42 <fen> riemenian geometry being locally euclidean 
12:53:03 <phadej> http://hackage.haskell.org/package/lattices-2/docs/src/Algebra.PartialOrd.html#line-146 <- look for NB: *not* a lexical ordering
12:53:06 <phadej> that is quite simple
12:53:09 <hyperisco> that's a different concern
12:53:23 <hyperisco> easy to program is not the same as efficient to compute, even if the two sometimes coincide
12:53:46 <fen> dont know what happens if you start adding singularities or moving to hyperbolic or parabolic spaces for example
12:53:50 <phadej> hyperisco: show the code
12:53:54 <hyperisco> why?
12:54:02 <phadej> how you would define partialCompare for (a,b)
12:54:09 <phadej> hyperisco: to prove your point
12:54:25 <hyperisco> well… not that interested in proving it lol
12:54:36 <fen> i think the normal appraoch is like to consider to punctured disk that is, to remove the place where a node would have more than 4 edges
12:54:38 <hyperisco> more of a take it or leave it offering
12:55:09 <phadej> you don't succeed to convince me partialCompare is useful as a class member
12:55:18 <hyperisco> *shrug* okay
12:55:57 <hyperisco> Are you Oleg Grenrus?
12:55:59 <fen> basically - trying to find a way to write this without using a lambda; https://pastebin.com/raw/N8aTvUvz
12:56:46 <phadej> hyperisco: I am
12:56:52 <fen> (nothing to do with grids)
12:57:01 <hyperisco> well in that case I'll show you
12:57:24 <fen> is it possible?
13:02:07 <hyperisco> \(a, b) (c, d) -> let ab = compare a b; cd = compare c d in if ab == cd then Just ab else Nothing
13:02:25 <hyperisco> maybe someone can golf that a little better, but that's the idea
13:03:51 <fen> hmm, could use defunctionalised dot... yeah then to extend that to appying a function to the first input of a 2 input thing
13:03:54 <hyperisco> actually I don't think that works in my use case
13:07:49 <hyperisco> the table is more complicated than that… GT GT ⇒ GT, LT LT ⇒ LT, LT EQ ⇒ LT, EQ LT ⇒ LT, GT EQ ⇒ GT, EQ GT ⇒ GT, EQ EQ ⇒ EQ, otherwise Nothing
13:08:41 <hyperisco> so lets see… if we just toss out  GT LT  and  LT GT  and then use  <>  then that lines up
13:10:50 <hyperisco> definitely not easier to program, because the ≤ definition is merely  (a, b) <= (c, d) = a <= b && b <= d
13:12:28 <fen> seems to work; https://pastebin.com/raw/WTUNaDWK
13:13:53 <phadej> hyperisco_: that uses compare, but there's only partialCompare to be used for (PartialOrd a, PartialOrd b) => PartialOrd (a,b) instance
13:14:49 <iqubic> How does this grid library work? https://hackage.haskell.org/package/grid
13:17:49 <jle`> iqubic: what aspect of the library are you unsure of?
13:18:02 <jle`> most of it is just direct translations from the mathematical formulas
13:18:08 <iqubic> Oh, I see.
13:18:17 <hyperisco_> phadej, yes, but as I said, this is a partial order defined on two total orders
13:18:19 <iqubic> I should really just take a look at the API right now.
13:18:55 <phadej> hyperisco_: ok, that one I'm not interested in for lattices package
13:18:58 <phadej> even then 
13:19:08 <phadej> > :t uncurry min
13:19:10 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
13:19:13 <phadej> :t uncurry min
13:19:14 <lambdabot> Ord c => (c, c) -> c
13:19:19 <iqubic> Mainly what I want to know is... How do I create a grid, and what operations can I perform on that grid?
13:19:35 <phadej> or something is simpler
13:19:54 <jle`> iqubic: hm, you don't really "create" grids, the library is more about doing math on grids
13:20:07 <jle`> so things like, finding the distance between two points on a given grid
13:20:10 <phadej> sorry, but I'm not convinced
13:20:33 <hyperisco_> that's okay… I am not using the lattices package
13:20:57 <jle`> phadej: although you do "create" grids, i guess, in the sense that you construct an explanation of what mathematical grid you are working on 
13:21:02 <jle`> sorry, iqubic ^
13:22:04 <jle`> iqubic: for example, indicies :: Grid g => g -> [Index g] gives the list of all indices on a given description of a grid
13:22:28 <jle`> the Index g is a type family that is different for every grid type; for hex grids it's (Int, Int)
13:22:54 <jle`> iqubic: the operations that you can perform on a grid are in the Grid typeclass, which provides a uniform interface for all the grid descriptions
13:23:37 <jle`> it's roughly similar to the API of the statistics library
13:23:52 <jle`> which provides a similar interface for its statistical distributions
13:24:07 <jle`> basically just functions to query mathematical properties of different distributions
13:25:46 <nitrix> I have a grid question as well after (flood fill / bi-connected components).
13:28:26 <fen> the use of unstructured grids in mimetric finite difference schemes could be worth considering 
13:28:41 <nitrix> Given a 2D grid, whose cells are solid or empty, I'm able to initially mark the contiguous cells belonging to the same shave via a flood fill algorithm. I would like to devise a system to maintain this knowledge as the cells are being mutated (a shape being broken down into two shapes), etc.
13:29:16 <fen> you have very difficult proofs for stability depending on the local deformation of a grid, ie being continuously deformable to a square domain. 
13:29:53 <fen> then there are issues at the boundaries between structured and unstructured, or curvilinear and euclidean segments
13:30:04 <fen> again with difficult stability proofs
13:30:14 <nitrix> I'm told this would be O(|E| + |V|) on each change, but I think I found an optimization that I need help to verify :)
13:31:25 <phadej> nitrix: 2d grids have more exploitable structure than graphs in general
13:31:28 <fen> do the segments divide? 
13:31:43 <fen> like, is a connected component split by the deformation?
13:32:13 <nitrix> phadej: If you're curious to hear what I came up with; it seems to me like this would apply to graphs too.
13:32:35 <robbym> Hello, I tried my hand at a simple ternary search tree implementation. Would anyone be willing to comment on my implementation/style? Or suggest simplification? https://repl.it/@robbym/CrimsonOverdueBash (relatively new to Haskell)
13:32:49 <zincy> How hard is it to write a parser for an AST represented as a GADT?
13:33:07 <zincy> Compared to a normal ADT AST representtion
13:33:20 <fen> nitrix: like persistent homology for higher dimetional simplicies? 
13:34:52 <phadej> zincy: my feeling is that you'd need an normal ADT which you'd "elaborate" to your GADT
13:35:42 <phadej> you cannot write Parser (Expr a) <- you don't know which a there is; so you'd use http://hackage.haskell.org/package/dependent-sum-0.5/docs/Data-Some.html; i.e. Parser (Some Expr) -- at which point it's almost the same as Parser ADTExpr
13:36:14 <nitrix> fen: phadej In my case, my idea came from observing a rubber-band-like structure. If you cut it once (one strand), the rubber-band loop becomes a rope. But if you cut two strands at once, you sliced the thing in half and now you have two ropes.
13:36:34 <zincy> Is using a GADT in such a case generally useful? Also if you are going to implement a typechecker for your DSL does using GADTs force you into doing everything at the type level?
13:36:46 <nitrix> fen: phadej Then I realised that my shapes in my grid behaved the same way if that "rubber-band" idea was applied to the inner and outer perimeters of the shape.
13:37:09 <phadej> zincy: yes, as *then* you have more restricted format
13:37:15 <iqubic> So, If I'm reading this correctly, then a "Grid g" can be thought of as a mapping from (Int, Int) to g.
13:37:17 <iqubic> https://hackage.haskell.org/package/grid-7.8.12/docs/Math-Geometry-Grid.html#t:Grid
13:37:20 <iqubic> Is that right?
13:37:39 <phadej> zincy: I'm just saying that UntypedText -> ADT -> GADT might be easier then directly UntypedText -> GADT
13:38:02 <nitrix> Actually, ignore me, I'll put it into drawings and move to ##algorithms because now I'm interested again :)
13:38:19 <zincy> phadej: Sorry is that answering the first or second question?
13:38:20 <phadej> because "type-checking" (ADT -> GADT in that case) doesn't always go in text-linear order
13:39:46 <jle`> robbym: looks good to me :)
13:40:11 <iqubic> So what exactly is a "Grid g" according to the grid library?
13:40:21 <jle`> robbym: i might move the guards on lines 7-12 down to a lower indentation level, so it doesn't overflow horizontally
13:40:31 <jle`> iqubic: Grid is a typeclass, like Show or Eq
13:40:42 <iqubic> I see.
13:40:48 <jle`> iqubic: its instances are mathematical definitions of grids
13:40:57 <jle`> and the grid typeclass has methods for interrogating those definitions for certain properties
13:40:57 <zincy> phadej: yeah someone said to me the recommend not going the GADT route as I would have to implement all the type checking at the type level
13:41:34 <phadej> zincy: i'm not sure you understood it right
13:41:40 <jle`> if this is a learning exercise, then it really just depends on what you want to learn
13:41:42 <phadej> but yes, GADT route is bumpy
13:42:04 <zincy> phadej: sorry understand what?
13:42:08 <jle`> iqubic: for example, one instance of grid is UnboundedHexGrid, which specifies an unbounded hex grid
13:42:12 <iqubic> jle`: Is there a way to make something like "Map (Int, Int) a" using the Grid library?
13:42:30 <phadej> zincy: "type checking" doesn't make sense if you have GADT formulation of syntax
13:42:33 <phadej> as it always type-correct
13:42:34 <jle`> iqubic: ah yeah, it's not a grid in the sense of an array
13:42:36 <phadej> there's nothing to check
13:42:40 <jle`> iqubic: it's more about properties of mathematical grids
13:42:45 <iqubic> I see.
13:42:51 <iqubic> So that's not what I want than.
13:42:53 <jle`> iqubic: but it might be useful for making a Map (Int, Int)
13:43:00 <jle`> since you can do things like, get all coordinate pairs for a given grid
13:43:11 <iqubic> Right. I guess.
13:43:19 <jle`> or things like, find all neighbors of a given pair
13:43:36 <zincy> Yeah I realise that the AST would be correct by construction if it was implemented with a GADT
13:43:36 <phadej> iqubic: but goint from untyped format (e.g. SyntaxExpr) to typed GADT (e.g. Expr Ty) *is* type-checking
13:43:43 <jle`> iqubic: the name 'grid' is not grid in a cartesian sense, but grid in a general sense, like hex grids, octagonal grids, etc.
13:44:11 <robbym> jle`, Thanks, will do!
13:44:14 <phadej> zincy: ^
13:44:26 <jle`> robbym: from a logical perspective i'm not too sure, since i'm not too familiar with ternary trees
13:44:53 <jle`> robbym: also, putStrLn (show x) is just print x
13:44:55 <zincy> phadej: Exactly which is why I found this recommendation from someone else so confusing
13:45:25 <phadej> zincy: but it really depends on how complex is your "type system" if GADT way is viable or not
13:45:30 <phadej> for language like GHC HAskell it isn't
13:45:38 <phadej> for something like C, it is
13:45:48 <jle`> robbym: actually, one small thing, instead of using guards on ==, < and >, you can instead case match on `compare`
13:45:51 <jle`> > compare 1 9
13:45:53 <lambdabot>  LT
13:45:55 <zincy> Typed lambda calculus - just have functions , bools and Ints
13:46:11 <jle`> robbym: 'compare' returns either LT, EQ, or GT
13:46:19 <phadej> zincy: yes, that's ~easy to do GADTs style
13:46:29 <phadej> where easy is relative; not absolute
13:46:41 <jle`> robbym: the advantage is that you don't have to duplicate work (check for ==, then check for <, etc.), and also you can be a bit more confident that you cover all possibilities
13:46:46 <zincy> phadej: How close is this?
13:46:47 <zincy> https://github.com/therewillbecode/functional-interpreter/blob/master/src/Interpreter.hs
13:47:23 <zincy> I was told GADT style would require a lot of pain for this route which doesn't seem right to me
13:47:25 <phadej> zincy: you showed that already, and we discussed that your treatment of binders (function type, variable etc) is not well-typed
13:47:33 <phadej> so it's close, but at the same time quite far
13:48:05 <zincy> Yeah so just the variables, lambda and funCall right?
13:48:06 <jle`> there's an intermediate GADT style which would give some benefits of GADTs, but still be non-typesafe at some other points
13:48:21 <jle`> in the end if this is a learning project then you get to pick what it is you want to learn
13:48:27 <iqubic> jle`: What I could do is "fromList $ map (\x -> (x, defaultVal)) (indices g)" with g :: Grid a and defaultVal :: b
13:48:48 <jle`> iqubic: yes, that's one way you can use the library to help :)
13:48:50 <zincy> jle`: Yeah I guess right :)
13:48:59 <jle`> iqubic: but also it's only really helpful if you are using non-cartesian grids
13:49:00 <zincy> it is a learning project
13:49:07 <jle`> iqubic: if you are using cartesian grids then you can just use Data.Ix
13:49:10 <phadej> but I had GADT like syntax only in Agda
13:49:11 <phadej> https://gist.github.com/phadej/82084de18b314701fa7e
13:49:23 <phadej> that's is translatable to Haskell, but it will be way less pretty
13:49:30 <jle`> and Data.Ix is in base already
13:49:30 <iqubic> jle`: I need a two dimensional square array.
13:49:39 <jle`> yeah, that's exactly what Data.Ix gives you
13:49:51 <iqubic> How does one use Data.Ix?
13:50:02 <jle`> > range ((0,0), (3,3))
13:50:04 <lambdabot>  [(0,0),(0,1),(0,2),(0,3),(1,0),(1,1),(1,2),(1,3),(2,0),(2,1),(2,2),(2,3),(3,...
13:50:26 <phadej> lambdabot: almost!
13:50:39 <jle`> @botsnack
13:50:39 <lambdabot> :)
13:50:43 <jle`> thanks for trying
13:50:49 <zincy> phadej: Cool! Agda looks intense
13:50:53 <iqubic> If I do go that route, then I'll need to implement neighbors myself.
13:51:19 <jle`> iqubic: that is true, yes. but implementing neighbors on a 2d grid is not something i would typically pull in an entire external library for
13:51:20 <phadej> for intense, there's Syntax Fomega: https://gist.github.com/phadej/780c1f5706b6cee805bd
13:51:30 <iqubic> Why is that lambdabot output not quite right?
13:51:33 <jle`> since it's relatively simple
13:51:38 <phadej> (I guess, not sure which System F variant it si)
13:51:43 <jle`> iqubic: it's "almost" because it almost prints out the whole list
13:51:51 <jle`> but quits like three characters short, heh
13:51:55 <zincy> phadej: What on Earth is that and how do I get into it
13:51:58 <iqubic> Lol.
13:52:12 <jle`> zincy: check out Tapl :)
13:52:18 <phadej> that's one route, yes
13:52:27 <ski> @where TaPL
13:52:27 <lambdabot> "Types and Programming Languages" by Benjamin C. Pierce in 2002-02-01 at <https://www.cis.upenn.edu/~bcpierce/tapl/>
13:52:31 <zincy> What is Tapl
13:52:36 <zincy> oh ok
13:53:32 <jle`> fwiw i spent about a month trying to implement someothing like a type-safe kind-safe sort-safe system f omega in haskell and eventually gave up
13:53:42 <phadej> (for the record the examples in second agda file were found by Agda, I just formatted them)
13:54:00 <jle`> it had to do with limitations on polykinded type families in haskell i think ..
13:54:09 <jle`> that was an experience
13:54:47 <phadej> jle`: that's why i pick Agda, not Haskell
13:55:13 <jle`> my application required haskell :'(
13:55:21 <zincy> phadej: Do is that a complete implementation of systemF in Agda
13:55:24 <zincy> so
13:55:47 <phadej> it defines expression type, and few examples; nothing else
13:56:36 <phadej> System F cannot be evaluated in Agda, as SystemF is not a subsystem of Agda's type system (STLC is, there things are easier)
13:57:44 <zincy> phadej: What would you recommend for the next steps for my Gist to make it completely typesafe , I am a bit stuck
13:57:57 <zincy> phadej: Hence the repetitive questions today :)
13:58:41 <jle`> one thing you can do is typecheck it
13:58:48 <jle`> hindley milner style
13:59:01 <jle`> to verify that it is correct, before running it :)
13:59:04 <phadej> thhttps://www.seas.upenn.edu/~cis194/spring15/lectures/11-stlc.html
14:00:52 <zincy> Great thanks guys
14:01:00 <jle`> zincy: your exp won't be *structurally* typesafe, but you could verify it is typesafe before presenting it to someone
14:01:14 <Solonarv> I think you typo'd that link, phadej
14:01:21 <jle`> kind of like how you can have "untrusted" strings in a web application, that you sanitize before giving it to your application
14:01:23 <Solonarv> fixed: https://www.seas.upenn.edu/~cis194/spring15/lectures/11-stlc.html
14:01:50 <jle`> you can parse a text file into an "untrusted" AST, and then typecheck it in the process of verifying it before presenting it as validated
14:02:05 <zincy> So is the hindley milner inference usually completely separate from the use of GADTS
14:02:15 <jle`> yeah
14:02:18 <zincy> or are they combined sometimes when implementing type checking
14:02:24 <zincy> ah right so it is one or the other
14:02:37 <jle`> hm, i wouildn't say so
14:02:46 <jle`> one quirk of this system is that both your "safe" and "unsafe" AST's are the same type
14:03:01 <jle`> so using hindley milner to verify your AST returns...another AST, just safe because you promise it is
14:03:12 <jle`> using a GADT system, you could translate an unsafe ADT into a safe GADT using hindley milner
14:03:44 <jle`> the diference is that the reuslting type is a 'different' type where it is structurally impossible to construct a badly typed AST
14:04:16 <jle`> so i guess the algorithm of typechecking ends up being the same, the difference is that the target domain is more restricted and reflects the safety
14:04:19 <jle`> instead of just "i promise it's safe"
14:04:34 <zincy> makes sense thanks
14:04:59 <jle`> btw, parsing into an unsafe type and typechecking it to validate it is how the dhall library works
14:05:06 <zincy> So not mutually exclusive GADTs just add constraints which form a tight contract
14:05:20 <jle`> the underlying dhall AST is untyped, but before doing things, it runs the typechecker on it
14:05:47 <fen> wouldnt that require things like exhastiveness checking and other things a proof assistant would help with?
14:05:50 <jle`> dhall actually implements some form of system f_omega i believe
14:06:11 <jle`> but within an untyped ast
14:06:20 <zincy> So that is the typical approach right in most languages? You just essentially run type of on each expression and ensure that it is legal?
14:06:21 <fen> like, you would need to prove your translation preserved type safety 
14:07:05 <phadej> https://github.com/dhall-lang/dhall-lang/tree/master/standard#summary
14:07:07 <phadej> Dhall's type system is a variation on CCω, implemented using a pure type system (see the "Function check" section for more details). 
14:07:13 <phadej> https://hal.inria.fr/hal-01445835
14:07:30 <ski> phadej : do you prefer the 2015 spring version over the 2013 spring one ?
14:07:43 <phadej> ski: one which came in google search first
14:07:49 <ski> okay
14:08:01 <ski> i've seen people in here say they prefer the 2013 one
14:08:08 <ski> and it's the one that
14:08:13 <ski> @where CIS194
14:08:14 <lambdabot> https://www.seas.upenn.edu/~cis194/spring13/lectures.html
14:08:17 <ski> gives you
14:08:30 * ski hasn't compared different instances/versions
14:08:38 <phadej> ski: they are very different
14:08:48 <ski> phadej : okay. good to know
14:08:49 <phadej> see https://www.seas.upenn.edu/~cis194/spring13/lectures.html vs. https://www.seas.upenn.edu/~cis194/spring15/lectures.html
14:09:06 <jle`> imagine the people who signed up to take the class in 2015 expecting the 2013 version only to get a completely different version
14:09:21 <fen> that hal link is a super intense abstract
14:10:09 <jle`> zincy: not sure what you mean by 'most' languages, but that's true in most LC implementations i've seen
14:10:16 <zincy> ouch that Penn class ramps up in difficulty doesnt it
14:10:16 <fen> whats all this stuff about coinductive universes something something type equality?
14:10:53 <jle`> zincy: i would recommend trying it out just to learn how to implement HM typechecking
14:11:05 <jle`> it provides a lot of useful insight to how haskell type inference works
14:11:06 <zincy> the course?
14:11:16 <zincy> cool will do!
14:11:18 <jle`> trying to implement hindley milner on your Exp type, i mean
14:11:38 <jle`> there's a reason it's often a midterm project for beginner haskell courses
14:11:45 <fen> there are some things you can do which make massively complicated changes to the proofs about the soundness of a language and you have to understand all these aspects to be able to run the proof assistant over them, or can the ramifications of these complex features be derived by the checker?
14:11:45 <phadej> HM is type *inference* algorithm
14:11:48 <phadej> tnot *checking*
14:11:53 <phadej> there's is a huge difference
14:12:05 <jle`> ah yes, that's an important distinction
14:12:22 <ski> zincy : if you're interested in HM, then perhaps also the following paper could be interesting
14:12:28 <ski> @where polymorphic-type-inference
14:12:29 <lambdabot> "Polymorphic Type Inference" by Michael I. Schwartzbach in 1995-03 at <https://cs.au.dk/~mis/typeinf.p(s|df)>,<http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.1493>
14:12:59 <fen> ski: dud link
14:12:59 <jle`> but yeah, a lot of beginner confusion on how haskell type inference works would be resolved if they put in time to implement HM themselves
14:13:01 <zincy> ski: Thanks!
14:13:22 <jle`> it clears up a lot of ambiguities that might not be obvious if you're starting out
14:13:26 <phadej> except, HM is difficult
14:13:40 <zincy> I am glad it is instructive to implement HM
14:13:54 <phadej> http://dev.stephendiehl.com/fun/006_hindley_milner.html
14:14:07 <zincy> I don't think one would be worse at understanding type errors after
14:14:17 <ski> zincy : that paper spells out some things which are commonly taken for granted, in type system papers
14:14:17 <monochrom> I may make my students implement unification in an assignment. And then I will be able to explain type inference. :)
14:14:25 <fen> i wonder what the difference is if you "get the feel" of how the typechecker works with experience, vs, having a more systematic/algoritmic understanding
14:14:38 <jle`> yeah, it helps you understand things like why ghc complains about 'infinite types'
14:15:03 <zincy> monochrom: Where do you teach?
14:15:13 <monochrom> U of Toronto Scarborough
14:15:14 <phadej> I was "lucky", I was forced to implement mini-prolog in C in Uni
14:15:21 <phadej> after that, everything feels easy
14:15:31 <ski> phadej : lucky you :)
14:15:32 <monochrom> Hell in fact: http://www.cs.utoronto.ca/~trebla/CSCC24-2019-Summer/
14:15:33 <zincy> That scary type notation
14:15:57 <fen> doesnt it result in a community which find it difficult to spek to the layperson?
14:16:01 <phadej> (yet implementing type-inference in Prolog is quite simple)
14:16:04 * ski had to propose implementing a mini-Prolog (with a novel extension) as a project, for a course (advanced functional programming)
14:16:38 <monochrom> implementing type inference : prolog :: implementing lazy evaluation : haskell  :)
14:16:59 <fen> the typechecker has difficulty explaining itself, maybe humans can imporove on this
14:17:06 <zincy> monochrom: What are those items ordered by?
14:17:25 <monochrom> It's a notation for analogies.
14:17:50 <monochrom> borrowed from the notation for ratios.  4 : 5 :: 20 : 25
14:17:50 <jle`> finger : hand :: toe : foot
14:18:07 <monochrom> I thought everyone knew.
14:18:10 <jle`> finger * foot = toe * hand
14:18:20 <monochrom> Like, because I learned it from someone else on IRC.
14:18:55 <fen> i cant explain it, but maybe if you implemented the type system yourself you would understand...
14:19:04 <jle`> finger = (toe * foot) / hand
14:19:36 <jle`> oops, that should be finger = (toe * hand) / foot
14:19:58 <fen> i think if people have a brutal learning experience that actually makes them less good at being able to communicate easily 
14:20:37 <monochrom> fen: What are you talking about?
14:20:53 <fen> perhaps having a slightly inferior understanding is of great benefit in being a useful teacher  
14:21:20 <fen> otherwise you might imagine the only way to even slightly understand something is with a huge amount of work
14:21:55 <fen> monochrom: the inacessability of high level programming literature 
14:22:15 <monochrom> Is this a right channel for that?
14:22:31 <fen> anybody that can understand it has some kind of computer-brain which makes them unintelligible 
14:22:48 <fen> monochrom: maybe you can better exaplin; https://hal.inria.fr/hal-01445835
14:22:58 <foo__> @djinn a->b->a
14:22:59 <lambdabot> f a _ = a
14:23:13 <ski> `A : B :: C : D' means "`A' is to `B', as `C' is to `D'". or roughly, the "ratio"/"proportion" of `A' to `B', is equal to the "ratio"/"proportion" of `C' to `D'
14:23:20 <monochrom> That doesn't answer my question. Since you're evading my question...
14:23:22 --- mode: ChanServ set +o monochrom
14:23:23 <ski> zincy ^
14:23:26 <foo__> @djinn (a->b)->c->(a->b->c)
14:23:26 <lambdabot> f _ a _ _ = a
14:23:37 --- mode: monochrom set +q *!*@gateway/web/freenode/ip.85.95.114.253
14:23:42 --- mode: monochrom set -o monochrom
14:24:02 <zincy> Ski: Cool notation
14:25:58 <ski> zincy : there's ⌜∷⌝ for "proportion" (and ⌜∶⌝, not a plain colon), in unicode. (and apparently also a ⌜∺⌝ for "geometric proportion". also cf. ⌜∝⌝ for "(is) proportional to")
14:30:52 <ski> zincy : for maps, there's scale indications like `1:10,000' ("one centimetre to one hundred metres"). and in odds, you can say "two to three", which you might write `2 : 3'. and regarding ingredients in a recipe (or say molecules in a chemical reaction), you can have `2 : 2 : 5 : 3', expressing relative proportions of several ingredients/molecules (according to some ordering)
14:31:41 <zincy> :)
14:36:54 <zincy> ski: That advanced functional programming course wasn't at Gothenberg was it?
15:13:50 <alx741> hello everyone. I'm in need of matching some Text values like I would a String (x:y:xs) where x is the first letter, y the second, and xs the rest of the string. Is this possible with Text? or should i unpack it, and then pack it back again when i'm done with that computation?
15:16:35 <aplainzetakind> alx741: There's the uncons function: https://hackage.haskell.org/package/text-0.11.2.0/docs/Data-Text.html#v:uncons
15:18:52 <lavalike> alx741: you can use functions in patterns with the ViewPatterns extension
15:37:16 <alx741> ah! I could use the combination of those things, thank you both!
15:41:33 <aplainzetakind> For a typing tutor, I had a function that waited for a character from stdin, another one which, using the first, read an expected string, and a third one which repeatedly called the previous one for random strings.
15:42:24 <aplainzetakind> I wanted to break this when ESC was pressed, So I wrapped things in ExceptT, and threw an exception from the character reader and rethrew it up.
15:42:33 <aplainzetakind> It worked fine.
15:43:41 <aplainzetakind> Then I wanted to separate the UI, so I replaced putChar etc. with reading and writing to Chan Char's in these functions, and put the stdin stdout stuff on the other end.
15:44:29 <aplainzetakind> Now when I press escape, I need to press two more whatever keys before it exits, and I can't figure out why this is happening.
15:45:24 <aplainzetakind> Also even though I think I'm calling hSetEcho True while handling ESC, after quitting I'm left in a non-echoing terminal that needs to be reset.
15:46:26 <geekosaur> I think this is related to the hs runtime quietly diddling extra terminal settings behind your back. if it behaves differently in ghci vs. compiled (or ghci vs. runghc), this may be it
15:46:51 <aplainzetakind> I think there's no difference, let me check.
15:47:04 <aplainzetakind> (cabal new-run is equivalent to runghc right?)
15:47:13 <geekosaur> also, if youre using a higher level thing that recognizes function keys, ESC is the first key in most function key sequences so the higher level thing might need to read more to realize it's just ESC here
15:47:53 <aplainzetakind> ^
15:48:02 <aplainzetakind> That sounds very likely.
15:49:15 <jgt> > length . take 5000000 . cycle $ [1]
15:49:17 <lambdabot>  5000000
15:49:29 <jgt> does Haskell count the length?
15:49:37 <aplainzetakind> If I try getChar >>= putChar in ghci and press something like Home, I get three characters the first being \ESC.
15:49:41 <jgt> or does it just know the result since I use that number in take?
15:49:45 <geekosaur> aplainzetakind, yep
15:49:46 <MarcelineVQ> it counts
15:50:19 <geekosaur> jgt, it has to count, length has no way to know that take limited it, nor does it know that take got that full amount from cycle
15:50:20 <aplainzetakind> So why didn't this happen before I put the Chan's inbetween?
15:50:43 <jgt> MarcelineVQ: Ok, thanks. I'm trying to understand why Haskell can count a 5 million list in 0.10s (unoptimised, GHCi), and yet PostgreSQL takes like 5s to count 5 million rows
15:51:09 <aplainzetakind> jgt: It doesn't look at the terms of the list.
15:51:29 <aplainzetakind> Just traverses the structure.
15:51:32 <geekosaur> aplainzetakind, I don't know because I don't know details of what you're using. some things use short timeouts to distinguish function keys from standalone keys and you might have thrown timing off just enough to confuse it (although that ought to fail in the other direction)
15:52:48 <jgt> aplainzetakind: sure, but why can't Postgres do the same?
15:53:07 <geekosaur> jgt, there's likely a lot more involved on the postgresql end, including that you are sending a query to a different process and it's responding, whereas ghci is doing it all in place (although -fexternal-interpreter changes that... but the protocol is much simpler and probably uses a faster IPC mechanism)
15:53:41 <aplainzetakind> geekosaur: Does "what I'm using" refer to my system or the Haskell side of things?
15:53:57 <geekosaur> and postgresql may be doing a table scan, which means accessing disk quite a lot
15:54:13 <geekosaur> aplainzetakind, which packages and functions and precisely how you've glued them together
15:54:43 <geekosaur> it's not difficult to come up with explanations for what you see, but which ones apply to your situation is harder
15:54:44 <jgt> geekosaur: oh, so is it because Haskell just holds it all in memory?
15:54:55 <geekosaur> jgt, largely that vs. eading disk, yes
15:55:23 <geekosaur> plus postgresql being a database engine is doing a lot of locking and lock checking behind your back in case some other process is also modifying the table
15:55:36 <geekosaur> which ghci doesn't have to worry about
15:56:12 <aplainzetakind> Do you think converting `Chan Char`s to `Chan String`s would be a hopeful attempt?
15:57:10 <geekosaur> aplainzetakind, that's one of those questions that can only be answered if I know details of what your'e using and how you hooked it together
15:57:30 <aplainzetakind> Would you take a look at the repo?
15:57:42 <geekosaur> I can look, yes
15:58:28 <aplainzetakind> Thanks: https://gitlab.com/aplainzetakind/typingtutor/tree/UIdecouple
15:59:20 <aplainzetakind> TypingTutor.hs is the backend, CLI.hs is the CLI, and exe/Main.hs is hooking them together.
16:03:33 <geekosaur> ok, so one problem I see immediately is that you can't interrupt the readChan, so you need to read at least one more character before realizing that the ESC isn't part of a multi-key sequence (e.g. function key)
16:04:36 <geekosaur> if you;re even doing that, hm. diffInMs, but you're not using it that way.
16:04:37 <aplainzetakind> If I give expectManyString the ThreadId an kill it there would it fix it?
16:06:44 <geekosaur> mrrr, you do hSetBuffering in two different threads, which will complicate the RTS cleaning up afterward
16:07:23 <geekosaur> because on a terminal, they will not only be affecting haskell buffers but also terminal state (it's quietly adjusting termios) and there will be races
16:07:34 <aplainzetakind> One is stdin one is stdout though?
16:07:44 <aplainzetakind> Ah, races.
16:08:09 <geekosaur> again, they're operating on the same operating system tty device, which has one set of termios settings. not one set per thread or per process
16:08:40 <aplainzetakind> Can I call closeCLI after those threads are killed?
16:08:50 <aplainzetakind> And put all the cleanup there?
16:09:35 <geekosaur> also hSetEcho on stdout isn't very sensible, since echo is part of input handling
16:09:56 <geekosaur> I would have an openCLI that does the setup, then fork the threads, then closeCLI after the threads are gone
16:10:05 <aplainzetakind> Whoa, I moved the call to closeCLI two lines down and it seems fixed.
16:10:44 <aplainzetakind> Strange, the only thing it did was set echo back on.
16:10:55 <aplainzetakind> But the whole ESC situation is also fixed.
16:11:06 <aplainzetakind> As well as echo.
16:12:30 <geekosaur> I'd kinda be interested in seeing what stty says about the terminal state, but that gets tricky. you may have gotten it into an unexpected state via a race condition. some systems will for example overlap vmin with the control characters, so you can end up in a state where it is using control-D as minimum number of characters to read instead of as a control character
16:12:38 <geekosaur> except I didn't think linux did that overlap
16:13:08 <geekosaur> which is why I'd be interested in seeing stty during. something is certainly becoming confused and I'd suspect it's conflicting tty driver configuration
16:13:34 <geekosaur> this is aprt of why I don't like how the RTS overloads hSetBuffering to do termios stuff, it invites these race conditions
16:13:47 <geekosaur> and leads to this kind of weird behavior
16:14:12 <geekosaur> stack ran into it at one point too, with respect to running tests and the tty was in an odd mode while the tests were running
16:14:57 <aplainzetakind> OK, these are beyond my grasp of the OS and the inner workings of the terminals, so I'm not really following.
16:15:20 <aplainzetakind> I will write an openCLI, which gets the buffering states.
16:15:47 <aplainzetakind> And leave them as I found them with the close after killing the threads.
16:15:58 <geekosaur> RTS is quietly doing things that affect terminalc onfiguration, which affects both stdin and stdout at the same time even though you specify only one or the other
16:16:30 <geekosaur> this interacts badly with multiple threads, since nothing expects the not-thread-specific part or locks against it, so you get unexpetced race conditions
16:16:47 <aplainzetakind> But that doesn't happen if I do things sequentially before forking and doing them in separate threads right?
16:17:07 <geekosaur> it's complicated and weird, and why I don't like how the RTS does that even if it means people can pretend hSetBuffering is enough to set up the terminal instead of using termios directly to do so
16:17:41 <geekosaur> that only works in the non-threaded and non-forking case. you hit the thread version of what goes wrong. stack hit the fork / process version
16:45:29 <Marge99> i have sexy body,big Ass,Nice boobs, Clean WET pussy. Trade nude selfies with me: http://um.lk/user-Marge99
17:05:59 <Axman6> Oh my, whatever will Homer think!
17:14:19 <jgt> Marge is barking up the wrong tree here. Programmers prefer DRY.
17:26:44 <jackdk> hedgehog question: I am trying to build a Command whose result i want to store in a map. I currently have the execute step returning a (key, value) pair, so the Update callback is giving me a Var (key, value) v.
17:27:20 <jackdk> I _think_ I want the model to hold a Map (Var key v) (Var value v), but I'm not sure how to split the tuple, or whether I'm doing something quite wrong.
18:05:47 <d34df00d_azoth> Hi!
18:08:43 <d34df00d_azoth> I have a function aggregate :: [T1] -> [T2] (which does just one pass on the input) and a list [Maybe T1], where each element represents a result of parsing some data that might fail. How do I combine the two in a lazy fashion? Sure, I could `sequence` the list to get Maybe [T1] and fmap `aggregate` over that, but that would force parsing all of the input data at once, which I don't want to do.
18:10:54 <hpc> d34df00d_azoth: evaluation is always "if this is evaluated, that is evaluated"
18:11:16 <hpc> in this case it sounds like you have "if T2 values are fully evaluated, their T1 values are fully evaluated"
18:11:17 <lyxia> d34df00d_azoth: what do you want to do if any element fails to parse
18:11:58 <hpc> oh, T1 isn't the input
18:12:50 <hpc> perhaps think about it as
18:12:52 <d34df00d_azoth> `aggregate` is expressed in terms of a foldr, so technically I could replace that with foldM, but looks like it hurts modularity.
18:13:01 <hpc> f :: Parser [T1]
18:13:09 <hpc> g :: T1 -> Parser T2
18:13:16 <lyxia> should aggregate still somehow succeed if any element fails to parse
18:13:36 <hpc> write f so it's a streaming parser
18:13:37 <d34df00d_azoth> lyxia: nope, but I'm ok with throwing away some work if something fails to parse.
18:13:47 <hpc> uh, g's type is wrong it'd just be T1 -> T2
18:14:01 <hpc> and then you have a streaming Parser T2
18:14:47 <hpc> to consume lazily, consume from the parser piece by piece
18:15:01 <hpc> er, Parser [T2]
18:15:09 <lyxia> right, you should look into making aggregate stream, because the current signature says that you have to get a list of elements that were properly parsed upfront.
18:15:51 <d34df00d_azoth> Alright, let's put it another way.
18:16:09 <d34df00d_azoth> I have a list of ByteStrings, each one being a JSON object.
18:16:16 <d34df00d_azoth> Or, a representation of a JSON object.
18:16:48 <Axman6> what behaviour do you want if something fails?
18:16:48 <d34df00d_azoth> So I do something like `A.decode' <$> strs` for A = Data.Aeson and get back my list of parse results.
18:17:03 <Axman6> so you want everything to fail? or do you want to ignore failures? 
18:17:11 <d34df00d_azoth> Axman6: I'd like everything to fail.
18:17:23 <Axman6> sounds like you want sequence then
18:17:35 <d34df00d_azoth> Axman6: but sequence parses everything before it gets to my aggregation function.
18:17:44 <d34df00d_azoth> s/parses/forces parsing/
18:17:45 <Axman6> sequence will do no further work after one of the elements in the list is Nothing
18:17:54 <hpc> perhaps what you want is for a parse error to return all the valid values it gets before that point
18:18:04 <hpc> in which case it's not a simple list of results
18:18:10 <Axman6> > sequence [Just 1, Nothing, undefined]
18:18:12 <lambdabot>  Nothing
18:18:16 <d34df00d_azoth> Nah, that would perhaps overcomplicate things.
18:18:30 <lyxia> aggregate :: Monad m => [m T1] -> m [T2]
18:18:40 <d34df00d_azoth> Axman6: in most of the cases all of the parses succeed.
18:18:40 <hpc> ah, then you're stuck with evaluating everything up to knowing if the last value parses
18:18:44 <hpc> before you can get the first value
18:19:07 <d34df00d_azoth> Axman6: but I'll build up a huge number of parsed values out of my (lazy) bytestring before I get to aggregate them.
18:19:14 <d34df00d_azoth> Which is O(n) on the input, while it could be O(1).
18:20:01 <Axman6> then I don't think you can use aggregate directly
18:20:13 <Axman6> you need to interleve the logic with the parsingf
18:20:20 <d34df00d_azoth> hpc: so, since my aggregate function is a fold, can I just write that as a foldM getting the right streaming semantics?
18:20:29 <d34df00d_azoth> Axman6: meh, that's not as modular as I was hoping :(
18:20:56 <d34df00d_azoth> But now I wonder if it can be modular even in theory.
18:21:46 <lyxia> are conduits not modular
18:22:01 <d34df00d_azoth> Hmm, yep. But conduit is perhaps an overkill.
18:22:19 <d34df00d_azoth> Whatever, I'll just change aggregate to be [m T1] -> m [T2]
18:22:25 <d34df00d_azoth> Looks like it also communicates the intended usage nicely.
18:22:32 <d34df00d_azoth> Or I'm just rationalizing it :)
18:23:18 <hpc> heh
18:23:50 <hpc> perhaps see if that's good enough, then check out conduits if you need more
18:24:32 <aplainzetakind> Is it not possible to datakinded phantom types as a parameter in multi parameter type classes?
18:24:42 <aplainzetakind> *to have
18:25:31 <Axman6> You may need to add explicit kind annotations to the class definition
18:26:16 <d34df00d_azoth> hpc: somebody just threw up a task that they say Rust is awesome for, so I'm just curious about expressing that in Haskell efficiently and elegantly.
18:26:40 <d34df00d_azoth> I'm already beating by the line count 3x while having kinda the same performance, so shall be good enough.
18:27:03 <dmwit> % :set -XDataKinds -XMultiParamTypeClasses -XPolyKinds
18:27:04 <yahb> dmwit: 
18:27:10 <dmwit> % data Foo = Foo
18:27:10 <yahb> dmwit: 
18:27:18 <dmwit> % class Bar a (b :: Foo)
18:27:18 <yahb> dmwit: 
18:27:23 <dmwit> aplainzetakind: Perfectly possible.
18:28:35 <dmwit> % class Baz a b where baz :: f b -> f Foo
18:28:35 <yahb> dmwit: ; <interactive>:54:21: error:; * Could not deduce (Baz a0 b); from the context: Baz a b; bound by the type signature for:; baz :: forall k (a :: k) b (f :: * -> *). Baz a b => f b -> f Foo; at <interactive>:54:21-39; The type variable `a0' is ambiguous; * In the ambiguity check for `baz'; To defer the ambiguity check to use sites, enable AllowAmb
18:28:40 <aplainzetakind> Axman6: that worked, though I'm being asked to enable one extension after another.
18:28:58 <Axman6> welcome to type level programming
18:28:59 <dmwit> % class Baz a b where baz :: f a b -> f a Foo
18:29:00 <yahb> dmwit: 
18:29:04 <dmwit> % :k Baz
18:29:05 <yahb> dmwit: Baz :: k -> * -> Constraint
18:29:23 <dmwit> Okay, I admit that surprises me a bit.
18:29:51 <Axman6> I geuss a can be polykinded
18:29:59 <dmwit> Yes, but why has it inferred b to be *?
18:30:05 <dmwit> What kind does it think f has??
18:30:29 <dmwit> oh!
18:30:34 <Axman6> because you've f :: k -> * -> * by making b ~ Foo
18:30:37 <dmwit> % class Baz a b where baz :: f a b -> f a 'Foo
18:30:38 <yahb> dmwit: 
18:30:40 <Axman6> (I think)
18:30:41 <dmwit> % :k Baz
18:30:41 <yahb> dmwit: Baz :: k -> Foo -> Constraint
18:30:44 <dmwit> There we go.
18:30:49 <Axman6> that's more like it
18:31:07 <aplainzetakind> What does FlexibleInstances do exactly?
18:31:25 <Axman6> makes instances do pilates
18:31:47 <dmwit> The Report says all instances must be of the form `C (T a b c ...)` where `C` is a class, `T` is a type constructor, and `a`, `b`, `c`, etc. are variables.
18:32:06 <dmwit> FlexibleInstances relaxes the constraint that `a`, `b`, `c`, etc. must be variables.
18:33:24 <aplainzetakind> Ah OK.
18:35:02 <bzm3r> hi all. i'm trying to read through this paper: http://strictlypositive.org/Idiom.pdf, but i am struggling with the first paragraph of section 2 (titled "The Idiom Class")
18:35:18 <aplainzetakind> I got fixated on the "must be distinct" part of the error and couldn't understand what was wrong.
18:36:06 <bzm3r> the authors write: In each example, there is a type constructor i which embeds the usual notion of value, but supports its own peculiar way of giving meaning to the usual applicative language—its idiom.
18:36:26 <bzm3r> what does it mean for a "type constructor to embed the usual notion of value"?
18:36:48 <dmwit> "the usual notion of value" means it supports containing arbitrary Haskell values
18:37:12 <dmwit> By contrast think of IntSet, which can only contain Ints, and therefore not arbitrary Haskell values
18:37:36 <bzm3r> i see
18:37:40 <bzm3r> and what does "usual applicative language" refer to?
18:38:13 <dmwit> ι and (*)
18:38:45 <geekosaur> everything in the first section, which is about using `ap` to do applications of some variety
18:38:51 <dmwit> Or "return" and "ap" if you prefer those names.
18:38:59 <bzm3r> ah i see
18:40:51 <geekosaur> so: section 1 shows that we can derive a notion of applicative functors from Monad, but that it doesn't actually require Monad as such. section 2 develops this notion of "applicative functor", which it calls "idiom"
18:41:33 <bzm3r> right
18:42:54 <bzm3r> What does the notation "m a" mean though? does it mean "m applied to a"?
18:43:12 <dmwit> yes
18:44:00 <bzm3r> in this case, how is ι the K combinator? after all, K x y  gives you x
18:44:17 <bzm3r> or actually, i shouldn't use spaces
18:44:22 <bzm3r> Kxy gives you x
18:44:26 <dmwit> Why do you believe that ι x y does not give you x?
18:44:35 <dmwit> > pure x y
18:44:37 <lambdabot>  x
18:45:09 <bzm3r> i think its type is confusing me: ι :: x -> ι x
18:45:32 <dmwit> But that isn't its type!
18:45:44 <Axman6> :t \pure -> pure True 1 `asAppledTo` pure
18:45:45 <lambdabot> error:
18:45:45 <lambdabot>     • Variable not in scope:
18:45:45 <lambdabot>         asAppledTo :: t1 -> (Bool -> t -> t1) -> t2
18:45:46 <bzm3r> sorry, not type, signature
18:45:50 <dmwit> Its type is ι :: Idiom i => x -> i x
18:45:53 <Axman6> :t \pure -> pure True 1 `asAppliedTo` pure
18:45:54 <lambdabot> error:
18:45:54 <lambdabot>     • Occurs check: cannot construct the infinite type:
18:45:54 <lambdabot>         a ~ Bool -> t -> a -> b
18:46:05 <Axman6> :t (\pure -> pure True 1) `asAppliedTo` pure
18:46:06 <lambdabot> Num t => (Bool -> t -> Bool) -> Bool
18:46:47 <dmwit> bzm3r: N.B. the type mentions i, not ι
18:46:56 <dmwit> bzm3r: Which is the type variable bound by the class declaration.
18:47:14 <dmwit> bzm3r: (This ain't dependent types, where we can just throw computations into a type willy-nilly!)
18:47:37 <bzm3r> (i have no clue about dependent types, sorry, but i did catch my mistake regarding ι and i)
18:48:20 <bzm3r> so i is a generic type, and class Idiom i means "type i is of the class Idiom if it has ι and * as defined)
18:49:03 <dmwit> Well... roughly, yes.
18:49:05 <bzm3r> let me write that more clearly, `class Idiom i` means "type `i` is of the class `Idiom` if it has `ι` and `*` defined with the following signatures
18:49:35 <bzm3r> where ι has signature ι :: x -> i x, but what does it mean to apply type i to x?
18:49:38 <dmwit> Yep!
18:49:41 <dmwit> It does, yes.
18:49:50 <dmwit> Oh, sorry, missed the "what" in that question.
18:50:00 <dmwit> bzm3r: Are you comfortable with the type `Maybe Int`?
18:50:14 <bzm3r> nope, but i can look it up and let you know once i am?
18:50:23 <dmwit> That's okay. Let's find one you are familiar with.
18:50:28 <dmwit> Are you comfortable with `[Int]`?
18:50:35 <bzm3r> an array of integers?
18:50:39 <dmwit> Close enough.
18:50:52 <dmwit> Would you be comfortable if I defined a type alias, `type List a = [a]`?
18:51:03 <bzm3r> yes, that makes sense to me
18:51:08 <dmwit> So then I could write `List Int` and it would mean the same thing as `[Int]`.
18:51:17 <bzm3r> yes
18:51:26 <dmwit> This is an example of an application. I've applied `List` to `Int`.
18:52:06 <dmwit> Here I've applied a concrete type, but just like we can have things polymorphic over concrete types like `Int` and `String`, we can also have a form of polymorphism that ranges over things like `List` and `Set`.
18:52:34 <dmwit> So we can have a variable which may be filled in with any parameterized type.
18:53:01 <dmwit> `i x` is the application of a not-yet-determined parameterized type (named `i`) to a not-yet-determined contained type (named `x`).
18:53:08 <bzm3r> i see, so "`ι :: x -> i x`" would mean "`ι` takes an input of type `x` and returns something which is a "package" of type `i` containing `x`"
18:53:18 <dmwit> Right!
18:54:30 <bzm3r> alright, so going back to the example of a combinator K, if its given an input xy, it returns x --- what is i in this case, such that it packages `xy` as `x`?
18:54:51 <dmwit> It doesn't package xy, it only packages x.
18:55:06 <bzm3r> right, sorry, let me be more precise:
18:55:09 <dmwit> The i is `(->) r` for some type `r`.
18:55:54 <bzm3r> "what is `i` in this case, such that it takes `ι xy` gives you back `i x`" -- is that correct?
18:56:05 <bzm3r> nope, its not correct
18:56:09 <bzm3r> `i` doesn't take anything
18:56:11 <bzm3r> let me try again
18:56:20 <dmwit> Okay. =)
18:56:28 <Axman6> Just as we can have List Int and Maybe Int, we can also have r -> Int, or ((->) r) Int if you write (->) in prefix form. what this says is, functions which can accept r, and return Int
18:56:54 <bzm3r> "what is `i` in this case, such that it has a definition for `ι ` where `ι xy`returns `i x`?"
18:57:12 <dmwit> Got it!
18:57:21 <Axman6> so i = ((->) r) -- (people often find (r ->) a little easier to think about but we're not actually allowed to write it)
18:57:22 <dmwit> `i` is a partially-applied function type.
18:57:27 <bzm3r> now, you suggest that `i` is `(->) r`
18:57:38 <bzm3r> let me interpret `(->) r`
18:57:50 <dmwit> In particular, we have `ι :: x -> (r -> x)`.
18:58:01 <dmwit> Compare `ι :: x -> i x`.
18:59:50 <bzm3r> `(->) r` is the same as `r -> <phantom>`, usually `a -> b` is the signature of  a function which takes type `a` and returns type `b`, so in our particular case, we have a function which takes type `r` and returns a `<phantom>`
19:00:08 <dmwit> I'm turning into a pumpkin. But there should be plenty of other folks here who can answer questions about this paper, so keep asking away.
19:00:22 <geekosaur> I wouldn't say phantom. It's partially "applying" (->)
19:00:34 <bzm3r> dmwit thanks so much for your time and explanations; they really helped!
19:01:02 <geekosaur> because the missing type will come from the class
19:01:28 <bzm3r> geekosaur ahhhh, that's what i was wondering: even for partial application, you need to know what type to give "next"
19:01:58 <geekosaur> ultimately, yes
19:02:17 <bzm3r> no wait, i thought a light bulb flipped on, but i realized i do not know how to interpret "missing type will come from the class"
19:02:50 <geekosaur> do you understand Functor?
19:03:15 <bzm3r> geekosaur no, but i can look it up and come back to you once i think i do? (functor as in category theory, right?)
19:03:58 <geekosaur> it's doing the same thing. we don't say "instance Functor (Maybe a) where", we say "instance Functor Maybe where". fmap specifies it and requires it to be polymorphic, because it's derived from the first parameter being (a -> b) where both a and b are specified by the caller of fmap, not by fmap or the Functor instance
19:04:27 <geekosaur> fmap :: Functor f => (a -> b) -> f a -> f b
19:05:06 <bzm3r> okay, so fmap is like `*`, but i am trying to figure `ι` for now
19:05:26 <geekosaur> so the type f has to handle both a and b, and can't know what either type is; it must accept any type. This is expressed by that type not being part of the class Functor, so it's impossible to write a Functor instance that can inspect that type
19:05:39 <bzm3r> ah, okay, let me process this
19:07:47 <bzm3r> geekosaur ok, i think i can write up something which puts what you've communicated in terms that are "at my level": 
19:08:01 <geekosaur> "i" is the type in the typeclass. "ι :: x -> i x" here we supply the "missing" type
19:08:20 <geekosaur> so if i is ((->) r), then (i x) is ((->) r x)
19:08:29 <geekosaur> and now its type is complete
19:08:33 <bzm3r> ahhhhhhhhhhhhh
19:09:19 <bzm3r> geekosaur oh my god, thank you
19:12:16 <bzm3r> and the implementation of `ι` to make it like the combinator K would be `ι x y = x`, when `i` is `(->) r`
19:13:30 <bzm3r> geekosaur ^
19:15:12 <geekosaur> yeh
19:15:19 <geekosaur> if I'm reading that right
19:19:12 <scott> is there a way i could define some functions that will be automatically available in all my ghci sessions? this is basically for desktop calculator-style usage
19:20:25 <geekosaur> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#the-ghci-files ?
19:25:31 <bzm3r> if `* :: i (s -> t) -> i s -> i t`, and `i` is `(->) r`, then `* :: (->) r (s -> t) -> (-> r) s -> (-> r) t` which is the same as `*:: r -> (s -> t) -> r -> s -> r -> t`; if `*` is the S combinator (Sxyz = xzyz), then `* x y z` (where `x` has type `r`, `y` has type `s`, and `z` has type `t`) becomes tricky to interpret, because `*` should have sign
19:25:32 <bzm3r> ature `r -> (s -> t)`, not `r -> s -> t`?
19:26:22 <geekosaur> you're missing some parens there
19:27:04 <bzm3r> the step `* :: (->) r (s -> t) -> (-> r) s -> (-> r) t` to `*:: r -> (s -> t) -> r -> s -> r -> t` is incorrect, right?
19:27:13 <geekosaur> "* :: (((->) r) (s -> t)) -> ((->) r) s) -> ((->) r) t)
19:27:40 <bzm3r> right
19:28:25 <geekosaur> so that -> r -> s -> r -> t is actially -> (r -> s) -> (r -> t) which is not quite the same thing
19:28:52 <bzm3r> yep
19:29:28 <geekosaur> actually the final set is redundant, but (r -> s) still needs them
19:29:40 <bzm3r> makes sense
19:30:04 <jusss> what is a endofunctor?
19:30:30 <scott> geekosaur: thanks, looks like i can just write normal haskell inside a `:{`/`:}` block in ~/.ghci
19:30:32 <geekosaur> a functor whose domain and range are the same type
19:30:56 <geekosaur> er.
19:31:26 <geekosaur> actually, if this is a continuation of yesterday's confusion, you may be talking about CT endofunctors and they have to be in the same category
19:32:22 <geekosaur> lots of terminology means different things in different contexts, sadly. All Haskell Functor-s are endofunctors in this sense, since they necessarily apply to Haskell types, which form a category
19:33:23 <jusss> now I have five terms I don't understand, they're Group, Semigroup, Monoid, Endofunctor, Monad
19:34:25 <geekosaur> semigroup: a type and an operation which combines two values with that type to produce another value with that type
19:34:54 <jusss> and monoid?
19:34:59 <geekosaur> monoid: a semigroup with an identity value, such that you can get the same value out that you put in by applying the operation to it and the identity value
19:35:15 <jusss> then monad?
19:36:45 <geekosaur> a type which has an operation to lift any arbitrary value into the type, and an operation to apply / "execute" some kind of action on a value of that type
19:37:02 <geekosaur> endofunctor we don't use much in Haskell, because all Functors are endofunctors.
19:37:42 <jusss> geekosaur: semigroup is an operation combines two values and produce another value, they all are the same type?
19:37:42 <geekosaur> and there's no useful way to have a non-endofunctor, since Haskell can only talk about Haskell types
19:37:57 <jusss> geekosaur: or use type to produce value?
19:38:10 <geekosaur> all of the same type
19:38:35 <geekosaur> (+) and (*) are semigroup operators on numbers. (++) is a semigroup operator on lists
19:38:58 <geekosaur> all three also happen to be monoid operators, each with its own identity: 0, 1, "" respectively
19:39:07 <jusss> geekosaur: and (+1) is not a semigroup, right?
19:39:57 <geekosaur> it doesn't combine two arbitrary values, so it's not. but you're getting a little fuzzy here.
19:40:28 <geekosaur> strictly we have a semigroup (Integer, (+)) and a monoid (Integer, (+), 0)
19:40:51 <geekosaur> and similar semigroups and monoids for other numeric types
19:41:25 <geekosaur> however note that we don't actally define those, because of a limitation of Haskell: you can only have one instance of a typeclass instance per type
19:41:54 <geekosaur> so we can't directly say both (+) and (*) are monoids in Haskell
19:42:45 <geekosaur> we use newtypes instead: Sum has the (Integer, (+)) Semigroup instance and Product has the (Integer, (*)) Semigroup instance, and likewise Monoid instances with their identity elements
19:45:38 <geekosaur> sometimes we can point to one semigroup / monoid which is more important than the others, so while we use those newtypes for Integer, lists have only the semigroup and monoid for (++).
19:45:52 <bzm3r> so the signature of `*` makes sense from an S combinator point of view, and i am trying to write an implementation for `*`.  recall the signature `* :: (r -> (s -> t)) -> (r -> s) -> (r -> t)` and note that Sxyz = xyzy; already, we are at an impasse, non? "S" doesn't really have a signature that makes sense?
19:45:57 <jusss> geekosaur: if an operation apply on two values and produce one value, and they're all of the same type, this operation is an semigroup?  and if an operation with an identity value apply on another value and return the same input value, and they're all of the same type, this operation is an monoid?
19:46:25 <bzm3r> monoid = semigroup + identity element
19:46:49 <geekosaur> jusss, a monoid is a semigroup *plus* an identity
19:46:52 <geekosaur> whoops
19:47:02 <jusss> (+) and (*) are semigroup, and (+ 0 ) and (* 1 ) are monoid?
19:47:09 <geekosaur> no
19:47:10 <bzm3r> yes
19:47:12 <bzm3r> oh
19:47:12 <bzm3r> sorry
19:47:14 <bzm3r> my mistake
19:47:18 <bzm3r> i'll let geekosaur answer
19:47:20 <geekosaur> well, depending on what you mean by that notation
19:47:45 <geekosaur> a semigroup is a type and an operation. a monoid is a semigroup with an additional identity element
19:48:11 <geekosaur> so (Integer, (+)) is a semigroup and (Integer, (+), 0) is the corresponding monoid
19:48:15 <jusss> geekosaur: (+ 0 ) is \x -> x + 0
19:48:32 <geekosaur> then no, that's not what that means
19:48:32 <metreo> I'm getting a nasty warning when I try to downgrade `base` and it doesn't seem possible. Is this the case
19:48:49 <geekosaur> metreo, base is wired into the compiler, you "downgrade" it by installing an older version of ghc
19:49:16 <metreo> Thanks
19:49:40 <bzm3r> geekosaur is it okay to re-paste a question i asked earlier, but scrolled up?
19:49:51 <jusss> geekosaur: that semigroup part is right?
19:49:55 <geekosaur> it might be more correct to say the monoid is ((Integer, (+)), 0) to show that it's based on the semigrou
19:50:17 <geekosaur> bzm3r, I saw the question but got sidetracked.
19:50:40 <bzm3r> (no problem, that's what i thought, not sure if it would be more convenient for me to paste it again)
19:51:14 <geekosaur> I think the difference between lambda calculus notation and Haskell type notation is confusing you
19:51:58 <jusss> geekosaur: a monoid is an operation with a value A , then give it a value B , and it produces the same value B, right?
19:52:02 <bzm3r> yeah, i think i see what you mean: "S is a substitution operator. It takes three arguments and then returns the first argument applied to the third, which is then applied to the result of the second argument applied to the third."
19:52:13 <geekosaur> and similarly values. xyzy would in Haskell be x y (z y)
19:52:20 <geekosaur> jusss, it's still a semigroup
19:52:42 <geekosaur> you have to be able to do the semigroup thing. the difference is that there is a special value you can use to make it a no-op: an identity
19:53:07 <jusss> geekosaur: no-op is short for?
19:53:16 <geekosaur> no-operation (does nothing)
19:53:41 <geekosaur> so we have (+) as a semigroup operator, but we can make it do nothing by using 0 as one of its arguments
19:54:05 <geekosaur> thus does not mean (+0) is a monoid, it means (+) is a monoid where 0 can be used to make it do nothing
19:54:12 <geekosaur> monoid operation
19:54:40 <jusss> geekosaur: when one value is 0, (+) is a monoid operator, right?
19:54:45 <geekosaur> "a monoid is a semigroup that lets us get back out what we put in"
19:54:54 <jusss> geekosaur: and (+） is a semigroup
19:55:32 <bzm3r> geekosaur may i try explaining it to jusss in "my way"?
19:55:34 <geekosaur> (+) is still a monoid even if we don't happen to apply it to the identity
19:55:36 <bzm3r> i think i see what is confusing him
19:55:39 <geekosaur> sure
19:55:54 <geekosaur> the fact that there is an identity is what matters, not that we specifically used it
19:56:33 <geekosaur> (String,(\x y -> x ++ "," ++ y)) is a semigroup, but not a monoid because there's no way to stop it from adding that ","
19:57:19 <geekosaur> (String, (++)) is a semigroup, and is a monoid with identity "" because if we pass "" as one of the parameters we get the other parameter back
19:57:35 <bzm3r> jusss imagine you have a type `a`, and an operator `*`, such that `* :: a -> a -> a` and if `x` and `y` are of type `a`, then `* x (* y z) = * x y z`; then `* ` is a semigroup
19:57:50 <bzm3r> sorry, `(*, a)` is a semigroup
19:58:28 <bzm3r> now imagine that we had a type `b` and an operator `^`, such that `(^, b)` is a semigroup
19:58:45 <jusss> wait a sec, this (*,a) for mean?
19:59:01 <jusss> this form (String, (++)) mean?
19:59:14 <bzm3r> um, maybe i should just write (`a`, `*`)
19:59:42 <bzm3r> like, i am just saying, `*: a -> a -> a` is a semigroup (no need to list the type, because the type is specified in the signature)
19:59:55 <geekosaur> they're using a different notation from the one I was; I stuck closer to Haskell
20:00:08 <bzm3r> yeah, that's probably it
20:00:15 <geekosaur> but it's not the same notation used in mathematics
20:00:25 <bzm3r> right, ok, nvm
20:00:31 <bzm3r> i don't know how to write it in the haskell way
20:00:37 <jusss> what this notation ('a','*') mean?
20:00:56 <metreo> How "fixable/updatable" is a dependency for an older version of `base` likely to be? 
20:01:44 <geekosaur> in mathy notation, * is often used to mean some unspecified operator and a is a variable representing some type. 
20:03:14 <jusss> "" ++ "a"   get "a"
20:03:34 <jusss> ++ is a monoid?
20:03:53 <bzm3r> jusss (ignore everything i said)
20:03:57 <bzm3r> (will help you more)
20:04:35 <geekosaur> jusss, yes (++) is a monoid on strings because it is a semigroup on lists and you can use "" to make it do nothing
20:05:34 <jusss> bzm3r: sorry about your notation I don't understand
20:06:04 <bzm3r> its totally okay! my bad for introducing more notation which only made things confusing
20:06:09 <[Leary]> A semigroup is an algebraic structure formed by a set or type S, and a binary operation * on elements of S satisfying certain properties (namely that for all x, y any z we have x * (y * z) = (x * y) * z). (S, *) and (*, S) are just ways to specify both the set/type and operation at the same time, since the operations and sets/types are not uniquely determined by one another.
20:07:09 <jusss> geekosaur: and now what about monad?
20:08:27 <jusss> "a" ++ "b" get "ab"   (++)is a semigroup,    "" ++ "a" get "a" , (++) is a monoid
20:09:53 <jusss> "A monad is just a monoid in the category of endofunctors"
20:10:20 <[Leary]> You can forget you ever read/heard that line, it won't help you.
20:10:46 <Axman6> I wouldn't say (++) is a semigroupo, I would say [] is a semigroup with (++) being the binary associative operation
20:11:24 <Axman6> (well, [a] is a semigroup I guess)
20:13:49 <geekosaur> jusss, that line is a statement in category theory. it's not helpful or even meaningful in Haskell
20:14:11 <geekosaur> it's not talking about Haskell's Monoid, in particular, and all Haskell Functors are necessarily endofunctors
20:14:23 <jusss> geekosaur: ok, forget that, what's the relationship with monad, monoid
20:14:36 <geekosaur> and this 9is what I was trying to tell you yesterday when I recognized your questions wre coming from that
20:14:41 <geekosaur> haskell does not relate them
20:14:50 <geekosaur> the relationship is at a level haskell can't talk about
20:15:18 <jusss> er...
20:15:33 <geekosaur> it;s a category theory joke, not a statement about haskell
20:15:50 <jusss> geekosaur: and what is a Monad in haskell?
20:16:23 <c_wraith> One specific way of expressing the CT idea in code
20:16:26 <geekosaur> [09 02:36:22] <geekosaur> a type which has an operation to lift any arbitrary value into the type, and an operation to apply / "execute" some kind of action on a value of that type
20:18:16 <geekosaur> (note how much this does *not* look like that "monoid in the category" statement. this should tell you smething)
20:18:50 <Axman6> metreo: usually it's not a big problem
20:18:52 <c_wraith> If you squint hard enough, return+join looks like a monoid
20:19:19 <metreo> Axman6: Is there documentation on the process involved? Or just Google it?
20:20:41 <jusss> geekosaur: "a type which has an operation to lift  any arbitrary value into the type" this operation, what it's?
20:20:55 <geekosaur> the release notes for every new ghc release point to an updates page that usually provides tips on what needs to be changed
20:21:03 <Axman6> metreo: have you run into something breaking by changing the version?
20:21:06 <c_wraith> jusss: return
20:21:08 <metreo> Ok I'll refer to the release notes! 
20:21:15 <geekosaur> return, or pure
20:21:34 <jusss> c_wraith: geekosaur and unit?
20:21:37 <metreo> Axman6: I simply have a package requesting base <4.10
20:21:45 <geekosaur> a more mathematical name for it, that haskell doesn't use
20:22:01 <metreo> The package is quipper
20:22:14 <Axman6> @hackage quipper
20:22:14 <lambdabot> http://hackage.haskell.org/package/quipper
20:22:21 <metreo> Yes, thanks!
20:22:31 <metreo> I didn't know about that @
20:22:56 <jusss> geekosaur: c_wraith so monad has nothing to do with monoid and semigroup?
20:23:04 <jusss> in haskell
20:23:04 <Axman6> I'm sure that if you just force a newer base, it will just work perfectly fine... ine some universe =)
20:23:04 <geekosaur> not in Haskell
20:23:07 <c_wraith> not in code
20:23:51 <Axman6> metreo: would also be worth sending a PR if you can make it work with newer bases
20:24:36 <Axman6> Of course Monads in Haskell are Monoids, we have (>>) and fail "oops" :p
20:24:56 <metreo> Yes I will do so. Just was interested if the idea of attempting such an update as a user is sane. 
20:25:10 <geekosaur> metreo, https://gitlab.haskell.org/ghc/ghc/wikis/commentary/libraries/version-history might be useful
20:25:17 <metreo> Thank you.
20:26:03 <geekosaur> it's generally sane. it can't always be automated, and occasionally you also run into e.g. that version has a bug and nobody checked to see if a later version fixed it
20:26:17 <jusss> I'm confused, (+) is a semigroup, because those two input values and one output value are the same type,  ((+),0) is a monoid, because the input one value and one output value are same, and those three values are same type, now (+) connect to monad?
20:26:28 <geekosaur> they don't connect
20:26:37 <geekosaur> Monad is a different kind of thing, literally
20:26:43 <jusss> the unit/return/pure, that  (a-> m a), 
20:27:07 <jusss> but all the books that tell monoid first before monad
20:27:15 <geekosaur> becuase it's a simpler concept
20:27:16 <c_wraith> jusss: Monads are one *very specific kind of monoid that has nothing to do with Haskell's Monoid class*. 
20:27:18 <metreo> geekosaur: Ok in that case I'll venture forward and look to have a PR in when I'm done. Thanks again all you lovely people.
20:27:19 <jusss> and trying to do some connect
20:27:21 <geekosaur> npt because they're dependent
20:27:40 <Axman6> jusss: that's likely to get you use to thinking about things abstractly
20:27:45 <Axman6> used*
20:28:26 <c_wraith> jusss: the CT concepts are far more general than the classes named after them.
20:28:27 <jusss> c_wraith: wait a sec, you mean monoid in haskell is not with monoid in math?
20:28:55 <c_wraith> jusss: Haskell's Monoid class is one *very narrow* form of CT monoid
20:28:57 <jusss> c_wraith: CT is short for?
20:29:05 <geekosaur> monoid in haskell is a simpler version of monoid in math
20:29:06 <jusss> Category theory?
20:29:09 <c_wraith> yes
20:29:22 <geekosaur> monad in haskell is a simpler thing than monad in math / category theory
20:29:34 <geekosaur> programming languages have trouble being as general as math usually is
20:30:17 <geekosaur> in particular, math doesn't consider Integer and Double to be different "types", they're overlapping sets. but in Haskell they do not overlap
20:30:19 <jusss> geekosaur: then I think why haskell don't give it another name
20:30:53 <geekosaur> beause then everything has to have a new name different from the conventional one because it's not 100% identical to the conventional one
20:31:13 <geekosaur> it;s not a monoid it's a notquitemathmonoid, it's not a number it's a notquitemathnumber, it's not...
20:31:23 <jusss> geekosaur: I wonder the type in haskell or computer science, is the same stuff in Curry Haskell's theory?
20:32:58 <geekosaur> you mean the curry-howard isomorphism? it's talking about types in general. haskell's types, ocaml
20:33:02 <geekosaur> s types, C's types ...
20:33:22 <geekosaur> do all those languages now have to rename"type" because they're not all as general as that?
20:34:08 <geekosaur> (you can't win this one. come up with a way to be that general and some mathematician will find a way to generalize what you created)
20:34:41 <geekosaur> that's sort of where category theory came from
20:35:06 <jusss> ok
20:35:33 <jusss> I think maybe we can forget that math, let's focus on haskell
20:37:04 <geekosaur> the mth will only give you a headache, yes
20:37:44 <geekosaur> there are things to learn there, but a deep dive into number theory is not the way to learn about Haskell's Semigroup and Monoid and a deep dive into category theory is not the way to learn about Haskell's Monad
20:37:56 <jusss> the monad, I was confused, the return, is something with semigroup
20:38:04 <geekosaur> you can look into them later to understand why the Haksell ones work the way they do
20:38:15 <geekosaur> if you ever care; there's little reason to, usually
20:38:42 <jusss> and it seems return have nothing to do with semigroup
20:39:20 <geekosaur> right, they're not related. I didn't need something liek "return" to use a number with (+), it already works. I need to use return to lift a value into a monad
20:39:53 <geekosaur> something like Integer can be a Semigroup or Monoid.
20:40:18 <geekosaur> something like "list of..." or "Maybe ..." or "IO ..." can be a Monad
20:40:40 <jusss> geekosaur: wait a sec, the operation is a Semigroup or Monoid, or the value is a Semigroup or Monoid?
20:41:04 <jusss> "<geekosaur> something like Integer can be a Semigroup or Monoid." for you word, Integer is a value not a operation I think
20:41:23 <geekosaur> as I said earlier, the actual Semigroup is a combination of a type and an operation. only in Haskell we say it's just the type, which is why we need a hack to have Semigroup and Monoid instances for (+) and (*)
20:41:42 <jusss> or you say the operation with a type is a semigroup or monoid
20:41:44 <geekosaur> so in terms of Haskell we say the type is a Semigroup
20:42:22 <geekosaur> because Haskell can't speak in terms of a combination of a type and an operator; we can have only one instance of Semigroup or Monoid or ... for a type
20:43:37 <geekosaur> in math it goes the other way, we speak of the operation because math doesn't have types in that sense, it has sets
20:43:43 <jusss> geekosaur: ((+),0) is a semigroup in math, and Integer is a semigroup in haskell?
20:43:43 <geekosaur> (as we usually formulate it)
20:43:58 <geekosaur> neither of those is true
20:44:38 <jusss> geekosaur: (+) is a semigroup in math?
20:44:51 <geekosaur> in math, (Integer, (+)) is a Semigroup. in Haskell, we can't say which of (+) or (*) is the "more improtant" semigroup, so Integer has neither
20:45:42 <geekosaur> we have instead a newtype wrapper Sum which has the Semigroup and Monoid instances for (+), and a newtype wrapper Product which has the Semigroup and Monoid instances for (*)
20:46:56 <geekosaur> (both of those are somewhat inaccurate also, but closer)
20:47:33 <geekosaur> (but to be more specific about either gets confusing quickly. math has a more general notion of "number" than you think)
20:49:00 <jusss> ok, I wonder this return lift value into something, and that something how we can define?
20:49:08 <jusss> monad
20:49:40 <jusss> return 3 will get 3
20:50:04 <jusss> not Just 3 or [3]
20:50:11 <geekosaur> you cannot.
20:50:17 <geekosaur> tjhe closest you get is Identity 3
20:51:23 <jusss> (>>=) :: Monad m => m a -> (a -> m b) -> m b
20:51:33 <geekosaur> yes. the "m" is always there
20:51:44 <jusss> this (a->m b) is return function, right?
20:51:51 <geekosaur> no
20:51:55 <geekosaur> it's an action.
20:52:00 <geekosaur> return :: a -> m a
20:52:56 <jusss> still confused,
20:53:10 <[Leary]> You could give it return, it just wouldn't do anything.
20:53:26 <[Leary]> > [0,1] >>= return
20:53:29 <lambdabot>  [0,1]
20:53:55 <[Leary]> > [0,1] >>= \x -> [x, -x]
20:53:57 <lambdabot>  [0,0,1,-1]
20:54:13 <geekosaur> note that return is a -> m a, not a -> m b. it's a simple example of *an* action
20:54:20 <geekosaur> but as an action it doesn't do anything
20:54:20 <jusss> >>= need one argument or two?
20:54:24 <geekosaur> two
20:54:59 <jusss> >>= [0,1] a-function?
20:55:25 <geekosaur> you saw [Leary]
20:55:27 <geekosaur> ;s examples?
20:55:45 <jusss> (>>=) [0] \x->x
20:56:13 <[Leary]> `[0,1] >>= f` won't type check unless `(>>=) [0,1]` is a function.
20:57:19 <jusss> wait a sec, (>>= return) is the second argument in >> [0,1] ?
20:57:34 <jusss> >> [0,1] (>>= return) ?
20:59:17 <jusss> oh, there's no = in >>[0,1], it's not a functionn
21:00:17 <jusss> I thought [Leary] use the prefix notation
21:01:05 <jusss> (>>=) [0] return
21:02:01 <jusss> that m in return which comes from (m a) ?
21:02:36 <geekosaur> the m in this example is []
21:02:49 <geekosaur> you can write the type [Int] as ([] Int)
21:03:07 <geekosaur> :t [0] :: [] Int
21:03:08 <lambdabot> [Int]
21:10:58 <jusss> and what this >>= is used for?
21:11:11 <jusss> if the middle part function is return
21:11:24 <geekosaur> it *can be* return. it does not have to be
21:11:34 <jusss> for other function like?
21:11:37 <geekosaur> you dont often see it used explicitly because of do notation.
21:12:05 <jusss> if we do curry on >>=
21:12:18 <geekosaur> the function is an action of some kind. return is a do-nothing action (sort of like an identity, but "one level up" from the identity of monoids)
21:12:28 <jusss> and >>= :: m a -> ( (a->m b) -> m b)
21:12:54 <jusss> (>>=) [0] will get ?
21:12:57 <geekosaur> putStrLn is another action, a -> m b where a is String, m is IO, and b is ()
21:13:36 <geekosaur> http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html
21:13:54 <jusss> why (>>=) [0] will get error? why not a curried form?
21:14:06 <geekosaur> :t (>>=) [0]
21:14:07 <lambdabot> Num a => (a -> [b]) -> [b]
21:14:55 <geekosaur> tbh I'm not quite sure what [Leary] meant by that comment, you presented a prefix partial application that looked valid to me
21:14:57 <jusss> the action and the notation , what's the related
21:15:34 <geekosaur> nless they meant you had left off the function/action
21:15:52 <geekosaur> and I'm not quite sure what you're asking
21:16:00 <jusss> return :: a -> m a, and  a -> m b in >>=
21:16:09 <jusss> and return can be used in >>=
21:16:54 <geekosaur> the notion of "action" depends on the type. in IO, an action is generally some I/O operation. for the list monad, it means applying it to every element of the list to produce a new list, which gives you a "nondeterminacy" (all possible results, hypothetically "in parallel")
21:17:27 <geekosaur> but if you read the page I linked earlier, there are lots of different concepts of "action"
21:17:39 <jusss> ok
22:56:25 <jusss> why use :: not use : notation in type signature?
22:56:43 <geekosaur> because : is taken for list construction
22:57:30 <geekosaur> (this gets discussed a lot; the ML family of languages swapped them.)
22:58:17 <dminuoso> jusss: It was an arbitrary choice, honestly.
22:58:34 <jusss> ...
22:58:57 <geekosaur> if you think people do logical things for logical reasons, you don't work with the people I do :)
22:59:55 <geekosaur> but really, choices have to be made somewhere and there are only so many single characters that can be taken for such things. unless you go into unicode, but back when Haskell was first conceived nobody really used unicode
23:00:23 <dminuoso> And realistically it's a non-issue. Unless you refuse to accept it on religious belief, you get used to it very quickly.
23:00:29 <geekosaur> and you still had to use utf7 if you wanted it to survive passage through random programs
23:01:11 <dminuoso> Once you start gaining in experience in many languages you will discover all these discrepancies. Either you start accepting languages being different, or you start getting rather emotional when they are not all like your favourite language.
23:02:00 <geekosaur> all languages suck. the trick is using the language that sucks least for what you're trying to do. :)
23:02:03 <MarcelineVQ> Why can't they all take the good sugar from ocaml and the good syntax from haskell :>
23:07:13 <Axman6> Is there any way to convince GHC this should be allowed? instance HasCallStack => IsString Text1 where. It complains about "Illegal implicit parameter ‘?callStack::GHC.Stack.Types.CallStack’" which normally I would happily agree with, but call stacks are supposed to be magic
23:10:46 <[exa]> Axman6: what type do you need to "have the call stack" ?
23:11:24 <geekosaur> this is the problem indeed. callstacks don't stick to types, they stick to functions
23:12:05 <Axman6> We throw an error from our fromString call if the string is empty so we can find where the string literal is
23:12:40 <geekosaur> I suspect this wants InstanceSigs instead?
23:13:33 <Axman6> hmm, surprisingly it is!
23:14:25 <Axman6> Looks like that works (at least it compiles)
23:14:45 <Solonarv> does it throw errors with the appropriate information?
23:16:55 <Axman6> sadly no
23:17:36 <Axman6> how annoying
23:18:28 <geekosaur> suppose that's not too surprising, tbh; it probably needs to be in the class definition. but not in the instance head or the class head, in the method definition in the class
23:18:42 <geekosaur> which isn't an option, of course :(
23:18:50 <Axman6> :'(
23:19:10 <dminuoso> geekosaur: The instance signature can deviate from the class method signature? o_o
23:19:28 <Axman6> fromString :: HasCallStack => String -> Text1 is apparently perfectly legal
23:19:40 <Axman6> but doesn't do what I'm hoping for
23:19:43 <geekosaur> sure. not a whole lot different from DefaultSignatures
23:20:34 <geekosaur> the problem is how class methods work, the default case would be that it goes through a wrapper that looks up the right instance and calls it… but the wrapper doesn't have a CallStack
23:21:00 <geekosaur> conceivably optimization affects this, if it can rewrite such that it's calling the instance method directly
23:21:15 <Solonarv> I suspect you can only add constraints that can be solved from the instance's context
23:21:43 <Solonarv> HasCallStack is treated specially by GHC (that's the whole point of it), so it can be solved there
23:23:02 <dminuoso> What would the impact be if you patched GHC to (perhaps conditionally on a flag) add the HasCallStack to isString in the class definition?
23:24:17 <geekosaur> actually I wonder if it does actually need special support for code generation with respect to method invocations
23:26:01 <MarcelineVQ> Axman6: would cheating help? +RTS -xc
23:26:21 <Axman6> ha, not really, but worth keeping in mind
23:53:36 <bahamas> is the error here a cabal error or a gradle error? https://bpaste.net/show/22527e20e9b4
23:54:38 <Solonarv> bahamas: looks like gradle errored and that caused cabal to fail as well
23:54:45 <[exa]> bahamas: seems like gradle but you might want to see the referenced logs
23:56:04 <bahamas> in the logs for sparkle, that's all I get
23:56:43 <bahamas> btw, where is the config that tells cabal to call gradle? this is the project I'm trying to build https://github.com/tweag/sparkle
23:58:03 <[exa]> not even in .stack-work/logs/sparkle-0.7.4.log
23:58:13 <[exa]> ?
23:58:59 <bahamas> [exa]: that file only contains the part that starts with > Task :compileJava FAILED
23:59:31 <geekosaur> bahamas, it's in Setup.hs
