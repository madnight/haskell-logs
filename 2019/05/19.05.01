00:03:52 <jle`> trcc: no problem, happy i could help :)
00:04:21 <trcc> Well I am just happy that fusion is a thing. I believe it improves the "readability" in some cases
00:05:32 <trcc> do you by any chance know if this is a thing in scala as well?
00:22:00 <Phyx-> koz_: what's your exact command? and is GHC on your path?
00:24:08 <koz_> Phyx-: cabal new-build
00:24:11 <koz_> Just that.
00:39:41 <Phyx-> koz_: and ghc is on your path?
00:40:08 <merijn> What was/is the problem? (I missed the question)
01:06:46 <FUL64> ciao a tutti
02:00:17 * hackage eventloop 0.8.2.8 - A different take on an IO system. Based on Amanda's IO loop, this eventloop takes a function that maps input events to output events. It can easily be extended by modules that represent IO devices or join multiple modules together.  https://hackage.haskell.org/package/eventloop-0.8.2.8 (LeonSchoorl)
03:15:47 * hackage massiv 0.3.2.0 - Massiv (Массив) is an Array Library.  https://hackage.haskell.org/package/massiv-0.3.2.0 (lehins)
03:24:08 <hpyCdr> how can I enable overloadedstrings during a stack repl session?
03:24:17 * hackage vault-tool 0.1.0.1 - Client library for HashiCorp's Vault tool (via HTTP API)  https://hackage.haskell.org/package/vault-tool-0.1.0.1 (BitConnor)
03:24:33 <jgt> hpyCdr: IIRC, you can use the same stuff you would do in GHCi
03:25:08 <jgt> so you can probably do :set -XOverloadedStrings
03:25:17 * hackage vault-tool-server 0.1.0.1 - Utility library for spawning a HashiCorp Vault process  https://hackage.haskell.org/package/vault-tool-server-0.1.0.1 (BitConnor)
03:25:48 <Athas> Does anyone know of a nice data-parallel way of computing histograms?
03:26:03 <hpyCdr> jgt, worked, thanks
03:26:08 <jgt> np
04:00:00 <merijn> Athas: Do you know bucket sizes in advance?
04:00:29 <Athas> merijn: not statically.
04:00:59 <merijn> Athas: then I don't know
04:02:11 <Athas> It *is* difficult!
04:02:35 <merijn> Athas: How many data points?
04:03:45 <Athas> merijn: any number.  I'm looking for a general strategy that scales to any number of bins and any number of inputs, with any bin distribution.
04:04:08 <Athas> (It's OK if it doesn't work well for very pathological input.)
04:18:10 <Squarism> if one want to stay up to date with important changes in haskell universe, where does one go. Mainly from a commersial perspective rather than language research oriented.  
04:18:18 <Squarism> ?
04:23:01 <cocreature> Squarism: https://haskellweekly.news/ is a pretty decent summary
04:23:18 <Squarism> thanks, ill check it out
04:23:41 <merijn> Squarism: Commercial how?
04:24:29 <merijn> haskell-cafe and the Haskell reddit are also pretty good sources, although the latter tends to occasionally attract migrating troll herds
04:25:41 <Squarism> well, I guess typical enterprise stuff like like database, web, build tools, testing etc. 
04:27:10 <Squarism> less profunctor folds of special types of trees, so to speak. =D
04:29:31 <merijn> I think Haskell weekly + reddit + haskell-cafe should cover most of both topics :p
04:30:36 <cocreature> even just weekly is a decent summary of the other sources and can help avoid some of the trolling
04:31:21 <merijn> cocreature: I just use /r/haskell without reading comments :p
04:31:31 <merijn> Well, not entirely true, I sometimes skim some comments
04:31:33 <cocreature> yeah that works as well :)
05:52:17 * hackage th-env 0.1.0.0 - Template Haskell splice that expands to an environment variable  https://hackage.haskell.org/package/th-env-0.1.0.0 (DmitryDzhus)
05:54:47 * hackage repline 0.2.1.0 - Haskeline wrapper for GHCi-like REPL interfaces.  https://hackage.haskell.org/package/repline-0.2.1.0 (sdiehl)
05:56:17 * hackage chronos 1.0.5 - A performant time library  https://hackage.haskell.org/package/chronos-1.0.5 (chessai)
06:26:47 * hackage shake 0.17.9 - Build system library, like Make, but more accurate dependencies.  https://hackage.haskell.org/package/shake-0.17.9 (NeilMitchell)
06:39:18 <dexterfoo> is anyone using dhall with webpack?
07:33:56 <saml> how is functional
07:39:17 * hackage monad-metrics 0.2.1.3 - A convenient wrapper around EKG metrics  https://hackage.haskell.org/package/monad-metrics-0.2.1.3 (parsonsmatt)
08:18:26 <zincy> When should the state monad be used vs just passing the state through as an argument each time you need it?
08:29:57 <dmwit> Two binds.
08:30:40 <dmwit> I mean, after you hand-write your second bind, switch to State(T).
08:31:20 <blackW0rm> hi all
08:40:01 <zincy> What do you mean by bind?
08:40:40 <zincy> dmwit: Do you mean threading the variable through the function?
08:40:45 <Taneb> Usage of >>= or handwritten equivalent
08:42:47 * hackage persistent-typed-db 0.1.0.0 - Type safe access to multiple database schemata.  https://hackage.haskell.org/package/persistent-typed-db-0.1.0.0 (parsonsmatt)
08:50:47 * hackage forma 1.1.2 - Parse and validate forms in JSON format  https://hackage.haskell.org/package/forma-1.1.2 (mrkkrp)
09:01:17 * hackage gitlib-test 3.1.2 - Test library for confirming gitlib backend compliance  https://hackage.haskell.org/package/gitlib-test-3.1.2 (JohnWiegley)
09:02:11 <dmwit> zincy: It is common when threading the variable manually to have a chain like `let (s', v) = f s; (s'', v') = g s'; (s''', v'') = h s'' in (s''', v''')`. The second and third of these are "bind"s.
09:02:40 <fendor> do we have a format preserving yaml library?
09:03:16 <dmwit> If you have to do just one of those, okay, no big deal, it's still lighter than adding a runState+State. Two of these makes me queasy. By the third one I'm using the monad.
09:05:10 <MarcelineVQ> fendor: check out https://hackage.haskell.org/package/waargonaut
09:09:53 <fendor> MarcelineVQ, thanks, I will try it!
09:30:55 <michalrus> Can I run all tests in a tasty subtree serially, without having to name each of them in `after`?
09:31:09 <michalrus> like… `serially :: TestTree -> TestTree`?
09:31:13 <michalrus> Seems so useful :p
09:31:39 <merijn> michalrus: Why do you want to run them serially?
09:31:53 <michalrus> They’re not very pure
09:32:12 <merijn> That seems...unwise
09:32:31 <merijn> If there is setup required you should incorporate that in the tests
09:32:55 <michalrus> I know, I know, but they’re testing some API, simulating a few users, and I don’t want those users to interact with each other… But they will, when run in parallel.
09:33:26 <michalrus> I should maybe run a separate server in each test. But that’s for later.
09:33:32 <cocreature> michalrus: you can set your whole test suite to be single-threaded
09:33:53 <cocreature> I’m not sure there is something at the level of an individual test tree
09:34:09 <michalrus> But that would make it take ages. :P I just want single threaded per a small sub-TestTree
09:34:14 <michalrus> Hmmmmmm.
09:34:39 <michalrus> What if I `unsafePerformIO newEmptyMVar`… and used that as a semaphore
09:34:42 <michalrus> Or even TSem. xP
09:34:44 <michalrus> In each test.
09:34:46 <michalrus> OK, I’ll do that
09:35:15 <roconnor> What is the consequences of setting 'exposed: False' for a library defined with Cabal?
09:35:47 <Solonarv> it means packages which depend on your package won't see that library
09:36:08 <merijn> roconnor: "Almost all new libraries use hierarchical module names that do not clash, so it is very uncommon to have to use this field. However it may be necessary to set exposed: False for some old libraries that use a flat module namespace or where it is known that the exposed modules would clash with other common modules."
09:36:17 <merijn> https://cabal.readthedocs.io/en/latest/developing-packages.html#pkg-field-library-exposed
09:36:49 <roconnor> yes but what if I know that the exposed modules will clahs with other common modules.
09:36:54 <Solonarv> note that there is a GHC extension which makes even overlapping module names unproblematic by allowing you to specify which package to import a module from
09:37:10 <Solonarv> uhhh... don't do that I guess? :P
09:37:16 <merijn> roconnor: Then I would rename those modules...
09:38:45 <roconnor> okay.  I'll think about it.  I guess I shouldn't use flags to configure variants of packages.
09:39:10 <merijn> roconnor: Yes, they're not intended for that
09:39:18 <merijn> roconnor: What are you trying to do?
09:40:22 <merijn> (actually, dinner time, bbl)
09:40:28 <roconnor> later
09:41:57 <marxS> hi, I'm running this code and I'm not sure why I'm getting the error : https://paste.ofcode.org/ndE7uyeCxBdtuuLQCJx93Q
09:42:10 <marxS> why is it matching (Imp f g) with Con Formula Formula instead of just Formula
09:42:28 <marxS> because I have data Formula = Atom | Con Formula Formula , so surely it could match with this case to match the type signature of mtp?
09:44:32 <jgt> I'd like to stream database records with Persistent/Conduit when a Yesod app starts up. I almost have something working, but GHC says I don't have a MonadResource IO instance. Here's the relevant code: http://ix.io/1HL0
09:44:37 <jgt> am I even taking the right approach?
09:46:08 <Solonarv> jgt: I think you just want to run some part of your code in a ResourceT
09:46:32 <Solonarv> if everything is nice and polymorphic I think you can just do that by inserting a 'runResourceT' somewhere
09:49:45 <jgt> Solonarv: Ah, yeah. That works. Need to change the type signature too; just removed it for now to get past the type-checker
09:49:48 <jgt> thanks!
09:58:08 <gunther_> Hello, I've been using parsec_parser = Control.Applicative.liftA2 Bar (many ...) (read <$> ..) to fill data Bar = Bar { a .. , b ..}, however, now I need to initialize a datatype of 14 fields. hoogle says liftA14 doesn't exist. Could you please help me out as to how to follow the same pattern and accomplish that? Thanks!
09:59:29 <geekosaur> liftAn f x0 x1 ... is the same as f <$> x0 <*> x1 <*> ...
10:00:18 <gunther_> I see, thanks!
10:00:48 * hackage interpolator 0.1.2 - Runtime interpolation of environment variables in records using profunctors  https://hackage.haskell.org/package/interpolator-0.1.2 (asariley)
10:03:33 <zincy> Say you have a monad stack such as      StateT Memory (Except Err) Variable   
10:03:41 <zincy> Should you wrap it in a newtype or leave as is?
10:04:42 <geekosaur> newtype only if you need modified or partial instances, otherwise consider type to abbreviate it / centralize the definition (easier to change if needed later, including potential replacement with newtype if you do turn out to need instance control)
10:05:49 <zincy> Thanks!
10:06:43 <geekosaur> marxS, because Imp is a constructor of the type Con, not of Formula
10:07:04 <fen> https://pastebin.com/raw/3ek1impA
10:07:10 <fen> !!!! ^^^ 
10:07:47 <marxS> geekosaur but Con Formula Formula is of type Formula?
10:08:19 <geekosaur> I thnk you're confusing yourself because you use Con as a type, and then as a data constructor for a different type
10:09:00 <geekosaur> Imp is a data constructor for the type Con. this is not, as far as Haskell is concerned, related to your later reuse of Con as a data constructor for the type Formula
10:09:34 <marxS> geekosaur ah okay I see, thanks
10:10:31 <geekosaur> maybe you wanted the later one to be data Formula = Atom | Expr (Con Formula Formula), or similar?
10:13:33 <fen> probably could have made a more simple implementation of Length for '[], but anyway it shows 2 ways to write a "sum list"
10:13:47 <fen> like a sum datatype but using a list
10:14:44 <roconnor> oh Cabal has private libraries now.
10:17:06 <Solonarv> it's had them for a little while, yea
10:21:35 <dmwit> marxS: (Same applies to `Atom`. You probably want `data Formula = Var Atom | ...`, by analogy to geekosaur's previous comment about `Con`.)
10:21:52 <geekosaur> yeh
10:22:17 * hackage semirings 0.4 - two monoids as one, in holy haskimony  https://hackage.haskell.org/package/semirings-0.4 (chessai)
10:22:37 <dmwit> marxS: I'd also propose deleting the parameters and fields to `Con`, as in `data Con = And | Or | Imp; data Formula = Var Char | BinOp Con Formula Formula`.
10:23:34 <zincy> Should you wrap a tuple of (String, Int) representing variable names and values in a new type called Variable
10:23:39 <zincy> ?
10:24:10 <dmwit> Yes wrap it in a new type. No, don't call it Variable.
10:24:10 <geekosaur> that depends on how you want to balance type safety against annoyance.
10:24:18 <dmwit> Binding would be a better name, possibly.
10:24:34 <dmwit> Also, don't wrap a tuple. Use a real data type with two fields.
10:24:56 <dmwit> So: `data Binding = Binding String Int` would be okay, or `data Binding = Binding { variable :: String, value :: Int }`, too.
10:25:44 <dmwit> See also https://stackoverflow.com/q/19072930/791604
10:26:34 <dmwit> Use the votes to decide between the two answers, not the green check mark. ;-)
10:27:03 <dmwit> (Full disclosure in case it's not completely obvious: I am plugging my own answer here.)
10:32:12 <zincy> dmwit: Thanks!
10:35:23 <zincy> dmwit: Yeah the tuple came from the fact I was using a Map of bindings to represent memory
10:39:17 * hackage retry 0.8.0.1 - Retry combinators for monadic actions that may fail  https://hackage.haskell.org/package/retry-0.8.0.1 (MichaelXavier)
10:40:32 <fen> still not sure if Nat is best as Int with a positivity constraint or using a unary representaiton
10:40:48 <fen> depends if its to be used for replicate or not
10:42:30 <fen> anyway, now with these implementations of a "Selection", a type level list of tags corresponding to state constructors can be scanned over with nesting function and turned into a selection, so that a nested state can have the option of failing to return at various levels
10:46:20 <fen> well, Inits of the tag list should be scanned over with Compose (the type list annotated version of Free in the paste) and a function to turn them into the base functor of the state with the `s' removed  (basically the tags correspond to Maybe a / Either a a for Stack / Linear resp.)
10:51:17 * hackage megaparsec 7.0.5 - Monadic parser combinators  https://hackage.haskell.org/package/megaparsec-7.0.5 (mrkkrp)
10:52:17 * hackage megaparsec-tests 7.0.5 - Test utilities and the test suite of Megaparsec  https://hackage.haskell.org/package/megaparsec-tests-7.0.5 (mrkkrp)
11:07:21 <fen> does haskell interface with kotlin?
11:08:17 <Solonarv> I'm not aware of anything special existing for that
11:08:40 <Solonarv> but they're both JVM languages (if you use Eta) so in principle they could
11:08:44 <zincy> fen: What would be represented as Nat?
11:09:07 <fen> in what?
11:09:11 <Solonarv> or you could use the regular Haskell FFI + JNI to interface between them
11:09:27 <fen> is that ok for teamwork?
11:09:57 <Solonarv> seems to me like you'll need to put in a bunch of work to make the languages talk to each other
11:10:07 <fen> like, in an android company wouldnt the other devs want to read actual kotlin code?
11:10:23 <fen> as opposed to haskell with a common backend
11:10:43 <Solonarv> I'm sure they would prefer to read languages they know
11:11:37 <Uniaika> fen: as a personal advice, I would highly encourage you to make your applications with Kotlin, if you're doing Android stuff
11:11:51 <fen> right, so instead of FFI / compiling to jar, wouldnt it be better to compile to and from the actual readable syntax of the language
11:11:53 <fen> ?
11:12:08 <Solonarv> sure, that would be better
11:12:17 <Solonarv> but that's not really possible
11:12:21 <fen> Uniaika: why the plug? 
11:13:00 <fen> Solonarv: right, even algoritmically refactoring code from some language to itself is difficult enough
11:13:23 <fen> but then, if a kind of abstract way of doing that was made, then it could work for any language and between them
11:13:57 <fen> haskell has always seemed the best place to do this from since we have such easy higher order functions
11:14:08 <Solonarv> yes, you can write a Haskell (or whatever) compiler that outputs Kotlin (or whatever)
11:14:09 <fen> ie refactoring can be more systematic 
11:14:32 <Solonarv> it's not even some huge complicated thing, just a bunch of work but no great innovations needed
11:14:37 <Solonarv> but the output won't exactly be readable
11:14:42 <fen> Solonarv: thats the point
11:14:55 <fen> its about the refactoring, not the translation
11:15:50 <Solonarv> you want to "refactor" haskell into kotlin? or you want to compile Haskell to Kotlin, then apply some hypothetical magical refactoring tool to make the output readable?
11:15:53 <zincy> fen: Oh I thought you were talking to me sorry
11:16:37 <fen> but because haskell can kind of reduce machine generated code output by a translator, to a really neat form using common hofs, then it can kind of serve as a middle point of a refactoring tool from a foreign language to itself
11:16:39 <zincy> Is there a way of setting a custom get function for the statement monad. Say your state is a map and you want a function which calls get and then lookup
11:17:14 <hpyCdr> when using `stack install foo` how can I define which lts to use?
11:17:24 <Solonarv> zincy: you can just write a function which does that
11:17:33 <Solonarv> no need to override anyhing
11:17:44 <Solonarv> hpyCdr: --resolver lts-13.6
11:17:47 <zincy> I thought there was maybe a clever way of doing it
11:17:50 <zincy> perhaps not then
11:17:50 <Solonarv> (or whatever else you want, of course)
11:18:17 * hackage hslua-module-system 0.2.0 - Lua module wrapper around Haskell's System module.  https://hackage.haskell.org/package/hslua-module-system-0.2.0 (tarleb)
11:18:25 <Solonarv> it doesn't get much simpler than: getAt k = Map.lookup k <$> get
11:18:28 <fen> Solonarv: yeah, the refactoring is easiest in haskell, so the translator would just have to produce unreadable haskell, then the refactoring tool (from haskell to haskell) would be able to make it readable in haskell. then the translator from haskell would just have the easy task of taking this cannonical form into a direct translation of those hofs in the foreign language
11:18:35 <hpyCdr> Solonarv, thanks
11:18:45 <Solonarv> fen: this is far from an easy task
11:19:18 <zincy> Solonarv: Would `gets` not fit the bill it takes a so called projection function
11:19:18 <Solonarv> consider: if "translate to Haskell and back" were such a nice way to do refactoring, why does literally no one anywhere have a tool that does this?
11:19:20 <fen> yeah no doubt, but the point is that it is a really massive thing, and that haskell could serve as the best way to do it
11:19:27 <Solonarv> zincy: oh, of course - I forgot about that
11:20:01 <fen> Solonarv: the question why doesnt it exist yet says nothing about if its the best way
11:20:19 <Solonarv> fen: no, not really - you lose a lot of readability from having to awkwardly encode Kotlin language features in Haskell, and Haskell features in Kotlin on the trip back
11:20:41 <fen> hofs just are not as much of a thing in any other language, functional programming is the way to go for a language translator
11:20:46 <Solonarv> I don't think I've even seen a pair of Haskell <-> Kotlin converters that round-trip cleanly
11:20:57 <Solonarv> which is surely a prerequisite if you want to use that to refactor
11:21:15 <fen> what special language features would complicate this?
11:21:48 <fen> isnt it just a case of writing common hofs in Kotlin and then refactoring haskell code into these hofs?
11:22:20 <Solonarv> not familiar enough with kotlin to give you a concrete example
11:22:33 <Solonarv> but this applies to most pairs of languages, not just Haskell and Kotlin
11:22:43 <boj> fen: perhaps writing a proof of concept would help drive the conversation
11:22:43 <cocreature> just translating between lazy and strict semantics is going to produce very messy and unidiomatic code (in both directions)
11:22:56 <fen> it might only need a subset of Kotlin to do this, which might seem like not making use of "the best kotlin idiom"...
11:23:15 <fen> boj!
11:23:29 <fen> heres one i made earlier! 
11:23:31 * Solonarv has to go
11:23:45 <fen> biggest project ever
11:24:17 <fen> probably would generate more real value than most companies! oh yeah, i just have this lying around
11:25:21 <boj> i am not suggesting you build a complete product, i am impying that arguing in #haskell about it is even less productive
11:32:15 <zincy> If you are representing a Map of variable bindings as state in StateT, what should the result type be? 
11:32:24 <zincy> I am a bit confused as I am writing an interpreter
11:32:38 <zincy> I am not sure if my state is just the variable bindings or the interpreter itself
11:33:11 <gentauro> is there a way to add `default-language: Haskell2010` to a .yaml file? (stack.yaml or package.yaml)?
11:33:12 <zincy> I.e should the result of looking up a variable binding and adding an int to the variable value be modelled in the state result type
11:37:50 <hyperisco> zincy, what should the result type of what be?
11:38:45 <cocreature> gentauro: hpack automatically adds default-language: Haskell2010 to the generated cabal file so you don’t need to specify it
11:39:01 <zincy> So my type is  StateT Memory (Except Err) (VarBinding)
11:39:31 <zincy> I believe in the StateT the VarBinding is the type of the result of state computations
11:40:03 <gentauro> cocreature: I just listened to Michael Snoymans webinar, and he said that ideally you should aim for Haskell98. I just couldn't find Haskell2010 on my projects to change it ...
11:40:37 <hyperisco> zincy, sure
11:40:38 <cocreature> that seems like a really weird statement
11:41:26 <zen_monk> st
11:41:33 <zen_monk> oops
11:41:40 <cocreature> are you sure he didn’t just use Haskell98 as a way of describing “fairly simple Haskell”? the differences to 2010 are quite small 
11:41:55 <geekosaur> even that's somewhat weird given e.g. yesod
11:42:23 <cocreature> it’s been a while since he created yesod. people change their opinions :)
11:43:13 <gentauro> maybe I misunderstood his statment -> https://www.snoyman.com/reveal/haskell-success-program#/8
11:43:15 <glguy> gentauro: That sounds like a recommendation to avoid turning on too many extensions and getting fancy. You shouldn't actually set the default language to 98
11:43:15 <hyperisco> zincy, I am not sure what you are asking. If you're asking what your Monad type should be, the result type is left variable
11:43:29 <gentauro> glguy: it might be that :-)
11:43:41 <glguy> It's either that or it's wrong.
11:43:44 <gentauro> but how do you control you team not going "loco" on extensions if you can limit it?
11:44:09 <glguy> That's a social problem, not a technical one. You walk over to your team mates and chat with them
11:44:11 <hyperisco> zincy, if you're trying to choose a result type, it matters what the computation is. If you're adding two Ints then the result is an Int.
11:44:20 <__monty__> Bless a certain set of extensions?
11:44:31 <gentauro> glguy: aren't most projects in Haskell done by remote teams :-)
11:44:42 <glguy> gentauro: Not that I was aware of
11:44:51 <glguy> but I don't have a complete view
11:44:55 <zincy> hyperisco:  Ah yes that is a good point. You can have different results based on the computation
11:44:57 <gentauro> fair point
11:45:05 <cocreature> you can limit extensions with hlint if you want to
11:45:39 <jakov> Hello ! I am working with the persistent library by Michael snoyman, and i am trying to lift an action into the persistent monad. What is the syntax ? When directly using the liftIO, if complains that it cannot match ..Transformer.ReaderT with IO() ... 
11:45:42 <cocreature> but getting a somewhat consistent style in a codebase is not a problem that you can solve just with tooling
11:45:45 <hyperisco> zincy, a way to think of Monads… go about your work as normal, but now you have additional side effects you can use. In the case of State, you can get and set a state variable.
11:45:49 <zincy> For production code is it frowned upon to turn on things like DataKinds and other fanciness
11:45:49 <gentauro> I can see that *cabal* has the `default-language` property
11:46:31 <gentauro> but my *cabal* files are generated automatically from my stack *yaml* files ...
11:46:34 <zincy> hyperisco: :)
11:46:45 <cocreature> no they are generated from your hpack package.yaml files
11:47:07 <cocreature> but there is really nothing to change here. "default-language: Haskell2010" is perfectly fine
11:47:40 <hyperisco> zincy, look at a type like  f (a -> b) -> f a -> f b  and see how that is familiar to  (a -> b) -> a -> b
11:47:43 <gentauro> cocreature: roger that :-)
11:48:24 <hyperisco> zincy, so you're going about your work as per usual, but you're carrying this extra  f  along, and it gives you extra effects
11:49:31 <zen_monk> i have freenode and weechat at the top left, how do i remove the weechat word from there ?
11:50:50 <zen_monk> whats the command to remove this word ?
11:51:10 <zincy> hyperisco: ah right. So the main benefit of the state monad is just to abstract away the machinery of getting , modifying and setting state? I feel the real benefits come from composing said getters and setters
11:51:31 <zen_monk> #weechat channel is locked so i cant ask questions there
11:51:48 <hyperisco> zincy, yes that's right
11:53:22 <hyperisco> now that I look at it, I think <*> should have been <$>
11:53:52 <zincy> I guess using state to model global variables a lot is a code smell
11:54:04 <hyperisco> I am guessing somehow the plan of  <*>  for  f a -> f b -> f (a, b)  got changed
11:54:21 <Solonarv> State(T) doesn't give you *global* mutable variables though
11:55:19 <zincy> Yeah
11:55:26 <zincy> But you can model them
11:55:26 <hyperisco> it invites some familiar issues of understanding what state the program is in, though that's not necessarily avoidable
11:55:52 <zincy> Wrap your whole app in State
11:56:31 <jakov> Hi! In the case condition of a maybe monad, i know that i have a 
11:56:31 <jakov> maybeperson <- Just personname
11:56:36 <hyperisco> StateT doesn't add anything to what is possible, it just simplifies a piece of it
11:56:47 <jakov> how do i  'unpack maybeperson' to get personname ?
11:57:09 <zincy> fromMaybe?
11:57:15 <hyperisco> jakov, in your example,  maybeperson  is bound to  personname
11:57:40 <fendor> MarcelineVQ, I now looked at the library, and it looks like it does not natively support YAML parsing.
12:00:53 <cocreature> zincy: “wrap your whole app in State” no longer works once you have multiple threads
12:01:08 <zincy> jakov: fromMaybe takes a default value which will be used if your wraped maybeType turns out to be Nothing. Otherwise it will unwrap the value in Just
12:01:38 <zincy> cocreature: Interesting why is that
12:02:40 <Solonarv> State(T) is just weird function composition in a trenchcoat
12:02:44 <hyperisco> it cannot share state across threads
12:03:05 <Solonarv> if you fork off a thread how are state changes from there ever going to come back to your main thread? (answer: they aren't)
12:03:15 <cocreature> zincy: if two threads are supposed to modify the same variable concurrently you can’t really express that with parameter passing
12:03:29 <zincy> Makes sense!
12:03:50 <zincy> So best option is to use a TVar State right?
12:04:10 <Solonarv> TVar/MVar/IORef/something similr
12:04:21 <hyperisco> IORef is getting desperate :P
12:04:47 <zincy> Is IORef a reference to mutable memory?
12:05:05 <Solonarv> pretty much
12:05:13 <zincy> TVar/MVar/IORef ... what is the grouping called?
12:05:21 <zincy> Concurrency primitives?
12:05:26 <fendor> for a package.yaml, is it valid if executable and library source dirs overlap?
12:05:37 <Solonarv> nah, IORef isn't a concurrency primitive but forkIO is a concurrency primitive
12:05:42 <geekosaur> IORef isn't really a concurrency primitive, it's just a mutable variable
12:06:29 <Solonarv> fendor: should be; hpack's package.yaml is just a thin yaml wrapper over cabal's package description format
12:06:47 * hackage hjugement-protocol 0.0.0.20190501 - A cryptographic protocol for the Majority Judgment.  https://hackage.haskell.org/package/hjugement-protocol-0.0.0.20190501 (julm)
12:06:49 <cocreature> fendor: iirc ghc can get unhappy about that since it then might pick up the source files when you compile your executable instead of the compiled module from the library
12:07:06 <Solonarv> if I want to refer to that group-of-things I usually say "some kind of mutable reference"
12:07:10 <cocreature> but yeah there is no difference between hpack and cabal here 
12:07:46 <fendor> cocreature, I think there is, since cabal specifies every module, it is absolutely clear which component a module is part of
12:08:13 <hyperisco> all the trouble is getting threads to coordinate, and IORef alone only practically coordinates one writer and multiple readers
12:08:39 <cocreature> fendor: fair point, if you rely on the automatic globbing in hpack you might run into other problems in addition to the one I mentioned
12:09:20 <cocreature> hyperisco: there is atomicModifyIORef to coordinate multiple writers
12:09:28 <Solonarv> whereas MVar/TVar have a sort of built-in locking, so coordinating threads is much more possible
12:09:31 <cocreature> but yeah it doesn’t get you very far beyond that
12:09:50 <Solonarv> cocreature: a big limitation of atomicModifyIORef is that you can't do any IO to decide about the new value
12:09:59 <Solonarv> % :t atomicModifyIORef -- no IO
12:09:59 <yahb> Solonarv: IORef a -> (a -> (a, b)) -> IO b
12:10:08 <cocreature> right
12:10:56 <fendor> hm, lets if there is an issue regarding that.
12:11:05 <hyperisco> cocreature, I am not familiar with concurrency in Haskell. That has to do some locking though. Not sure how that is accomplished.
12:14:18 <hpyCdr> with attoparsec I'd like to parse doubles/floats BUT make it fail on integer values
12:14:25 <cocreature> fendor: given that as I mentioned even GHC/cabal might break later on, I would just avoid it even if hpack doesn’t fall over
12:14:35 <hpyCdr> e.g. using double on "3" returns 3.0
12:14:37 <cocreature> hyperisco: I think it’s a cas
12:14:39 <hpyCdr> but should fail
12:14:46 <hpyCdr> any idea how to achieve that?
12:15:01 <infinisil> hpyCdr: Um, a parser can't return and fail at the same time
12:15:10 <infinisil> At least the standard ones
12:15:16 <fendor> cocreature, you mean, in a project I should avoid it? totally agree, but it is not for a project am trying to add programmatically a package to a package.yaml
12:15:41 <hpyCdr> nah, I mean the "double" parser consumes "3"
12:15:48 <hpyCdr> but the parser I want, should fail on it
12:15:50 <infinisil> Ohh I see
12:16:33 <infinisil> hpyCdr: Parse it as an integer first, if it succeeds, fail, if it fails, use double
12:17:11 <hyperisco> cocreature, with what compare? pointer?
12:17:48 <Solonarv> infinisil: note that you need backtracking for this
12:17:54 <infinisil> Yeah
12:18:13 <cocreature> hyperisco: I don’t remember the details, PrimOps.cmm probably has them if you’re feeling adventerous :)
12:18:15 <infinisil> Solonarv: Not sure if it's possible without backtracking
12:18:25 <hpyCdr> infinisil, but won't the decimal parser just consume the "3" of "3.0" and leave behind ".0" . I mean it would succeed even on floats
12:18:40 <hyperisco> it boils down to MutVar# and all that is internal, so I dunno
12:18:41 <hpyCdr> I could force space afterwards, tho
12:18:46 <infinisil> hpyCdr: That's why you need backtracking, which is probably <|>
12:19:02 <infinisil> Or something with try I mean
12:19:02 <Solonarv> <|> doesn't have to backtrack
12:19:12 <infinisil> Yeah sorry, I meant try
12:19:19 <infinisil> At least that's what it's called in megaparsec :P
12:19:52 <infinisil> hpyCdr: https://hackage.haskell.org/package/attoparsec-0.13.2.2/docs/Data-Attoparsec-Combinator.html#v:try
12:19:56 <infinisil> Yeah also called try in attoparsec
12:20:08 <cocreature> hyperisco: it does seem to call "cmpxchgW" at some point in "stg_atomicModifyMutVar2zh" but I’m too tired to figure out what exactly is getting swapped :)
12:21:25 <hyperisco> honestly haven't heard of CAS and sounds a bit strange to me
12:22:09 <hpyCdr> infinisil, I'll give it a try, thanks
12:22:43 <cocreature> cas is fairly common since it’s one of the few ways of doing atomic operations at the lowest level so it’s often used at the building block for nicer abstractions
12:22:50 <hyperisco> if there is something to do other than just try again, if the compare mismatches, then I get it
12:26:14 <hyperisco> just trying to grok how this is actually different than a lock, if one is just going to retry until it succeeds
12:27:13 <cocreature> it isn’t different
12:27:19 <cocreature> that’s basically a spinlock
12:27:23 <geekosaur> it *is* a lock. it's a lock at the level of the CPYU
12:28:44 <cocreature> your CPU most likely does not have an “acquire lock” and “release lock” operation that you can use. But it probably has a “CAS” operation that you can use
12:29:22 <hyperisco> I see, okay, so it is an implementation of a lock
12:30:31 <camsn0w> anyone on?
12:30:52 <hyperisco> conceptually… I thought of a lock that only one actor gets to have at a time, so the lock has to pass around
12:30:54 <Solonarv> camsn0w: yes, plenty of people
12:30:57 <Tuplanolla> Most definitely off at this time of the day.
12:31:24 <geekosaur> hyperisco, at a higher level, yes. at the lowest level, you need something like this to enable building the higher level
12:31:25 <hyperisco> whereas conceptually this is more like… everyone has the lock, but anyone can spontaneously invalidate everyone else's lock, as long as their lock is valid
12:32:47 <hyperisco> it is like… everyone has the password to an account, but anyone can change the password by entering the correct password
12:33:26 <geekosaur> at the level of the CPU, there is no concept of different actors
12:33:37 <geekosaur> (aside from CPUs themselves as actors)
12:34:04 <geekosaur> the CPU has no idea why the instruction is being executed, or on "whose" behalf.
12:34:08 <hyperisco> mm, actors are, lets say, instructions :)
12:34:59 <geekosaur> (this lack of identity at CPU level is also why those recent speculative execution etc. attacks)
12:35:14 <hyperisco> maybe cores makes more sense
12:35:58 <geekosaur> cores, yes, but there's still the idea of multiple threads that could take turns running on a given core. but the CPU doesn't know about that
12:37:06 <hyperisco> I don't think threads are relevant from the CPU perspective
12:38:21 <geekosaur> meanwhile, to get to the higher level from this one: if everything modifying a designated memory location uses the cmpxchg "protocol" to do so, then the location can itself be used as a lock or semaphore. you get spinlocking during the one CPU instruction in order to make that modification safe, then higher level abstraction can use the designated location to indicate that a lock is held.
12:38:34 <hyperisco> a core executes serially, so it can't step on itself
12:39:31 <hyperisco> but two cores execute concurrently, so it matters that the cores cannot step on each other, hence an atomic instruction
12:39:38 <geekosaur> sadly not entirely true, consider speculative execution and branch prediction. (admittedly "step on itself" is a bug, but such bugs do occur)
12:40:02 <geekosaur> yes, if you have only one CPU, higher level locking is much easier
12:40:17 <geekosaur> multi-CPU requires something liek this at the lowest level to make the higher levels safe
12:40:44 <geekosaur> but it does require everything to obey the protocol; something directly modifying the memory location without using the CAS "protocol" can break it
12:40:57 <shapr> anyone here using pandoc to turn emacs org-mode into a blog?
12:41:49 <geekosaur> this is why these low level locks get abstracted behind futexes, or MVars, etc.
12:42:35 <hyperisco> you know, CPU designers have one hell of a job
12:42:44 <geekosaur> yep
12:43:38 <hyperisco> I haven't thought closely about the concurrency issues wrt out-of-order execution
12:43:54 <hyperisco> so you have some memory load in flight, and you keep computing away to fill in the dead time
12:44:27 <hyperisco> and all the while you have to maintain certain concurrency constraints
12:44:43 <geekosaur> and getting them wrong gets you spectre etc.
12:44:53 <hyperisco> between main memory, L3, L2, L1, registers…
12:45:01 <geekosaur> this shit ain't easy at all
12:46:18 <zincy> All threading relies on locks at some level right?
12:46:47 * hackage tagsoup 0.14.8 - Parsing and extracting information from (possibly malformed) HTML/XML documents  https://hackage.haskell.org/package/tagsoup-0.14.8 (NeilMitchell)
12:46:56 <geekosaur> if you want the result to be predictable
12:47:10 <hyperisco> first one says task A and B are independent, so lets so them at the same time
12:47:13 <c_wraith> if you're counting hardware locks used by things like atomic compare-and-swap, then sure.
12:47:53 <hyperisco> then one says tasks C and D are mostly independent, but some things have to happen before others
12:48:01 <geekosaur> although things like map-reduce rely on threads instead having dedicated mutable areas for results, and they don't need to lock against each other because each one has exclusive ownership of their mutable regions
12:48:15 <devalot> I'm building some Beam queries that I'd like to give type signatures to.  I thought maybe I could do this with a type alias: `type Query s t = Q Postgres Schema s (t (QExpr s Postgres))`  However, when I use it as a type sig GHC complains that `s' is rigid.  What's the best way to make this work?
12:48:16 <hyperisco> now you're trying to add some dependencies back in
12:48:50 <hyperisco> in serial programming, statement n+1 gets to depend on statements 0 through n, inherently
12:48:57 <Tuplanolla> Did you forget to quantify over the type variables with `ScopedTypeVariables`, devalot?
12:49:41 <devalot> Tuplanolla: Sure did. Would I forall them in the type alias or the type signature?
12:50:05 <zincy> Can you use kleisli composition in place of multiple monadic actions
12:50:24 <Tuplanolla> Only in the top-level type signature, devalot.
12:50:25 <hyperisco> a common situation is that you want to modify a cell, but it can only make sense if you know the state of that cell as it is written
12:50:34 <Solonarv> zincy: sure
12:50:40 <Solonarv> sometimes it's more elegant, even
12:50:46 <devalot> Tuplanolla: okay.  I'll give that a try.  Thanks.
12:51:01 <hyperisco> so you need both your read and write to happen without anyone else's writes between
12:51:52 <zincy> Solonarv: Here it goes >=> for the first time
12:52:18 <zincy> I am still at the stage of overcomplicating everything by writing as clever code as possible
12:52:19 <Solonarv> simple silly example: printFile = putStr <=< readFile
12:52:32 <zincy> It is called being an intermediate
12:52:47 <hyperisco> and all concurrency primitives, or w/e you call them, are about adding constraints to otherwise a completely arbitrary ordering of happenings
12:53:47 <hyperisco> serial programming is, in that light, just a highly constrained version of concurrent programming :P
12:54:01 <zincy> hyperisco: interesting
12:54:16 <zincy> So is it fair to say concurrency is purely an ordering problem
12:55:18 <hyperisco> fundamentally, I guess yes
12:57:25 <geekosaur> yes, and some of the smarts in modern cpus is dependency inspection to determine which instructions can be safely executed in a different order (effectively in parallel, which means a CPU is scheduling its own internal regions as well: if the ALU isn't needed for one instruction but is for another, those two instructions can potentially execute at the same time)
12:58:36 <geekosaur> provided they don't use the same registers or memory (a core can only address one memory location at a time, there being only one set of address lines for its use usually) etc.
12:59:52 <zincy> Is parallelism ordering for the purpose of better performance
13:00:08 <hyperisco> now how much has AMD's lag behind Intel CPUs been due to concurrency capabilities
13:01:08 <hyperisco> though that seems to be changing recently
13:01:14 <davean> geekosaur: what? a lot of CPUs have more than one fetch unit, and theres scatter/gather units. Theres several memory controlers on many CPUs.
13:01:59 <zincy> Can I use >==> to run two monadic actions of type String -> StateT Memory (Except Err) Int
13:02:10 <zincy> and bind the results to variables named a and b
13:02:13 <davean> hyperisco: still no HTM on AMD
13:02:26 <davean> and, IMO, POWER's HTM is still the best
13:02:39 <geekosaur> mm, maybe they do now. I have noot paid close attention, and ofc ourse cache also figures into it, but theres still going to be a small limit on concurrent memory accesses. and on the other end, concurrent access to a given page of memory (dual or multiport memory being much more expensive and usually slower)
13:02:58 <davean> geekosaur: CPUs have had 2 L1 per cycle as long as I can remember
13:03:30 <davean> I'll see if agner can tell me when that started
13:03:46 <Solonarv> zincy: (>=>) is point-free, much like (.)
13:03:58 <geekosaur> there's also how many address leads the packaging has
13:04:12 <hyperisco> zincy, if there is no dependency between two things to do, whether those happen one after the other or simultaneously is irrelevant semantically, just different in how much wall time it takes :)
13:05:00 <hyperisco> so yeah, state of the art is to painfully explain that nondependency, and then parallel execution can happen
13:05:17 <dmwit> :t liftA2 (liftA2 (,)) :: Monad m => (i -> StateT s m o) -> (i -> StateT s m o) -> i -> StateT s m (o, o')
13:05:18 <lambdabot> error:
13:05:18 <lambdabot>     • Couldn't match type ‘o1’ with ‘o'1’
13:05:18 <lambdabot>       ‘o1’ is a rigid type variable bound by
13:05:30 <dmwit> :t liftA2 (liftA2 (,)) :: Monad m => (i -> StateT s m o) -> (i -> StateT s m o) -> i -> StateT s m (o, o)
13:05:32 <lambdabot> Monad m => (i -> StateT s m o) -> (i -> StateT s m o) -> i -> StateT s m (o, o)
13:05:32 <geekosaur> the memory cycle for example may run 2x as fast, but at any given instant only one address can be represented at hardware connection level unless there are multiple memory controllers on chip each with its own address and data leads. which there may well be at this point, but still a relatively low number thereof
13:05:34 <dmwit> zincy: ^
13:05:49 <dmwit> zincy: ...but don't do that. =P
13:06:47 * hackage bindings-hdf5 0.1.2 - Project bindings-* raw interface to HDF5 library  https://hackage.haskell.org/package/bindings-hdf5-0.1.2 (JohnWiegley)
13:07:00 <davean> geekosaur: I think you mena channel
13:07:10 <zincy> dmwit: clever
13:07:13 <geekosaur> probably
13:07:29 <hyperisco> maybe someone can explain to me why memory clocks keep going up even though memory latency isn't going down
13:07:34 <davean> geekosaur: First off, any server CPU basicly has multiple controllers, but also channels index address seperately, and I can't think of a memory controller without at least 2
13:07:44 <hyperisco> like, the cas timings keep going up, which I understand as a measure of latency in clock cycles
13:07:54 <davean> hyperisco: because the signals still have to cross the distance, and the memory has to access the location
13:08:01 <merijn> hyperisco: cas as in compare-and-swap?
13:08:07 <davean> hyperisco: theres a litteral speed of light issue in there
13:08:15 <davean> merijn: no
13:08:24 <davean> merijn: Its the access latency of memory
13:08:52 <hyperisco> davean, okay, I am just a little confused still, because increasing the clock speed doesn't change the speed of light
13:08:54 <geekosaur> that's what I thought. column access strobe
13:08:54 <merijn> hyperisco: Anyway, cache coherency is a major contributor when it comes to bottlenecks in the memory system
13:09:08 <davean> hyperisco: Right, exactly, it doesn't increase the speed of light
13:09:10 <davean> thtas the POINT
13:09:14 <davean> thats why latency is increasing
13:09:21 <hyperisco> davean, one may be able to send and receive more data per unit time, but if you have to wait a fixed time to get the data in the first place, does that matter?
13:09:28 <geekosaur> basically, reference to the physical / wire level activity needed to solicit / recognize an address
13:09:30 <davean> hyperisco: yes, very much
13:09:48 <hyperisco> I know why the latency is increasing
13:09:50 <davean> hyperisco: latency isn't throughput
13:10:01 <hyperisco> what I am asking is, what advantage is increasing the clock?
13:10:08 <davean> You don't have to wait for the last thing to complete to start the next thing
13:10:13 <davean> hyperisco: more memory bandwidth
13:10:16 <davean> you can more more data
13:10:24 <davean> you can access mroe things per time also
13:10:29 <hyperisco> granted, so how much can actually be buffered?
13:10:46 <davean> buffering doesn't have to factor into it
13:10:59 <geekosaur> also "column": memory isn;t a single monolithic thing, you can access different pages (for some granularity of "page", which isn't the same as a CPU page) simultaneously
13:11:05 <hyperisco> I don't get how not, but I have 1/10th of the info here
13:11:28 <davean> hyperisco: there isn't a buffer, its on the wire traveling to you or from you
13:11:42 <hyperisco> lets just say the memory can only execute one fetch at a time, then you're waiting the whole latency of that fetch regardless of how fast you can send the fetch command and receive the data
13:11:47 <davean> plus theres page switch and such
13:11:56 <davean> incorrect
13:12:01 <davean> You are wrong exactly there
13:12:07 <hyperisco> alright, then I fundamentally do not understand something
13:12:11 <davean> you keep ignoring the speed of light
13:12:28 <davean> Just because its done doesn't mean you've heard about it yet
13:12:30 <merijn> Since were basically off-topic anyway...GHC's configure script is finding the wrong compiler, how do I figure out which compiler it actually found?
13:12:44 <davean> That data is on the wire traveling to you
13:12:50 <davean> it takes time to know about what the memory did
13:13:03 <davean> but also, the memory can do multiple things
13:13:06 <geekosaur> merijn, ideally it's in config.log.
13:13:18 <hyperisco> the total time is  send command time + read memory time + receive data time  no?
13:13:40 <geekosaur> plus bus settle time (electronics aren't instant on/off) etc.
13:13:47 <geekosaur> which starts to matter at modern CPU speeds
13:13:52 <davean> the total time is send command + time the command takes to travel there + time to perform the command + time to send the command + time for the command to travel back
13:13:59 <geekosaur> and that
13:14:03 <merijn> geekosaur: I just see "checking version of gcc" followed by "error: Need at least gcc version 4.4"
13:14:05 <davean> geekosaur: well thats inside the signals
13:14:13 <davean> geekosaur: I tihnk you're talking eye diagrams?
13:14:19 <merijn> geekosaur: Now, I know I have a stupid old gcc on this machine, but it's not THAT stupid old
13:14:24 <hyperisco> okay, you just broke it down a little further than I did
13:14:32 <davean> No, not really
13:14:33 <geekosaur> merijn, config.log contains more information than is printed on the console.
13:14:40 <hyperisco> increasing the clock speed decreases what? all three?
13:14:40 <davean> You ignored the speed of light
13:14:45 <merijn> geekosaur: No, those lines are from config.log
13:14:56 <hyperisco> I am not ignoring the speed of light…
13:15:00 <monochrom> @quote monochrom einstein
13:15:00 <lambdabot> monochrom says: einstein's theory implies that haskell cannot be faster than c
13:15:03 <davean> Increasing the clock speed decreses the sends, and possible the performs
13:15:10 <geekosaur> hm. they should instrument that lookup then. you might have to patch the code that does that :/
13:15:11 <davean> it does NOT change the time things tkae to get places
13:15:22 * geekosaur doesn't think he has a ghc checkout on here
13:15:24 <merijn> geekosaur: In fact, config.log lists several newer gcc versions and their paths
13:15:25 <davean> hyperisco: you litterly left out the part where the speed of light comes in in your version
13:15:38 <merijn> geekosaur: (this is the bindist configure script)
13:15:39 <davean> hyperisco: the CPU is done and the memory hasn't heard the start of it yet
13:15:47 <hyperisco> I don't think we're going to get anywhere on this
13:15:56 <hyperisco> because we cannot agree to really basic terms here
13:16:01 <davean> what term?
13:16:02 <geekosaur> oh, tha one is more bare bones, yes. but I'd have expected it to use the same configure macro for that part
13:16:12 <davean> hyperisco: lets take this off channel
13:16:14 <hyperisco> I think just about every one :P
13:18:35 <hyperisco> no I guarantee we're going nowhere in this discussion :P I'll just have to study the issue in more detail before I can make any sense
13:18:46 <merijn> Ugh, what is this thing doing? It finds 4 different gccs that are all sufficiently new, plus 2 clang versions and it magically cooks up a non-existent outdated gcc...
13:19:15 <monochrom> It is doing a nix thing? >:)
13:20:34 <merijn> oh god...
13:20:58 <merijn> So, wild ass premature guess: For some retarded reason it has decided clang == gcc
13:21:12 <roconnor> merijn: I was trying to do something very much like http://blog.ezyang.com/2017/01/try-backpack-cabal-packages/ describes:  Using Haskell modules to implement ML-functor like things.  I understand now that I should use this backpack support thing.
13:21:15 <Tuplanolla> Does it call `cc` and expect `gcc`, merijn?
13:21:36 <merijn> Tuplanolla: My first guess, but cc is actually gcc 4.8.5
13:22:14 <Tuplanolla> How about `$CC`?
13:22:27 <merijn> Tuplanolla: Ding, ding. I just found the offender
13:22:45 <int-e> pray tell
13:22:47 <merijn> It first finds gcc, concludes were using gcc, then tests the version by...running $CC which is clang
13:23:15 <int-e> That is a stroke of genius :)
13:23:22 <Tuplanolla> Why am I not surprised?
13:23:52 <merijn> If I had a dollar everytime I managed to break GHC configure script I'd have...5 or 6 dollars >.>
13:25:26 <Boarders> Does anyone know in tasty how I set a quickcheck option?
13:25:40 <Boarders> I gather I am meant to use different ingredients but can't quickly figure out how you do it
13:26:41 <phadej> Boarders: which option
13:27:02 <Boarders> e.g.  QuickCheckTests 200
13:27:17 <merijn> Tuplanolla: Whoo! The bug is a whopping 5 lines below the comment explaining my last configure script patch... >.>
13:27:34 <phadej> Boarders: you mean in code, default amount?
13:27:50 <Boarders> yeah, or is it better to just pass as a command line option?
13:29:18 <phadej> Boarders: adjustOption
13:29:25 <phadej> Boarders: http://hackage.haskell.org/package/tasty-1.2.1/docs/Test-Tasty.html#g:3
13:29:52 <Boarders> phadej: excellent, thank you!
13:29:56 <phadej> Boarders: no worries
13:30:58 <toblorone> dumb question: I haven't used haskell in years but I'm struggling to think of reasons why it doesn't support overloading function names similar to how c++ does? It should be able to resolve the correct function to call given the provided arguments, correct?
13:31:18 <Cale> toblorone: It supports something better: type classes
13:31:43 <Cale> toblorone: The nice thing about type classes is that by *using* polymorphic things, you can get polymorphic results
13:31:56 <Cale> deferring the decision about which type to use further
13:32:05 <toblorone> well typeclasses don't allow me to have the same function name support differnt number of arguments, right?
13:32:11 <Cale> whereas in C++, you have to make the decision at the call site
13:32:25 <Cale> They do let you do that, but we don't tend to make use of that very much
13:32:57 <toblorone> they do? How? Could i achieve something like: foo :: Int -> Int and foo :: Int -> String -> Int?
13:33:15 <phadej> you can, but in general you don't want in Haskell
13:33:18 <Cale> In a few different ways... the most obvious is just
13:33:23 <Cale> class Foo a where
13:33:25 <Cale>   foo :: a
13:33:33 <Cale> instance Foo (Int -> Int) where ...
13:33:37 <toblorone> ah ok
13:33:40 <Cale> instance Foo (Int -> String -> Int) where ...
13:33:58 <Cale> But see also what gets done in Text.Printf
13:34:13 <phadej> but again, I wouldn't say that's good Haskell code (and Text.Printf is quite an extreme example)
13:34:29 <Cale> Yeah, that's not particularly well-structured
13:34:41 <toblorone> so why not simply allow for simply having multiple definitions of a function as long as their types are distinct?
13:34:54 <phadej> toblorone: that doesn't go well with type-inference
13:35:05 <Cale> Usually you want a proper *abstraction* if you're going to use the same name to refer to different things at different types
13:35:25 <Cale> Otherwise, why not just use different names? It would be less confusing.
13:36:14 <phadej> toblorone: distinct types are fine, but key difference is that in Haskell all fucntions take one argument. Int -> Bool -> String is a function taking Int as an argument and returning Bool -> String value (also a function)
13:36:17 <dexterfoo> Cale: Sometime around the year 2003 or 2004 I wrote a Haskell program and pasted it here. It was a 3D raytracer. You modified the code and rendered some beautiful images with spheres that reflect each other infinitely. Do you happen to still have the code? It was the first Haskell program I ever wrote
13:36:25 <phadej> so overloading on "number of arguments" doesn't make sense
13:36:35 <royal_screwup21> % [y | x <- [1..10], y  <- add x 1  ]
13:36:35 <yahb> royal_screwup21: ; <interactive>:3:26: error:; * Variable not in scope: add :: Integer -> Integer -> [a]; * Perhaps you meant one of these: `and' (imported from Prelude), `odd' (imported from Prelude)
13:36:37 <phadej> you can do it, but things will fight back
13:37:00 <royal_screwup21> I have defined add x y = x+y. I'm trying to run [y | x <- [1..10], y  <- add x 1  ]
13:37:08 <royal_screwup21> but I get an error: • Non type-variable argument in the constraint: Enum [t]      (Use FlexibleContexts to permit this)    • When checking the inferred type        it :: forall t. (Enum [t], Num [t]) => [t]
13:37:17 <toblorone> phadej: sure, not the number of arguments, but the types can make it distinct. I understand that with partial application it can potentially become ambiguous
13:37:20 <Cale> dexterfoo: I... if I do, it would be on some hard drive on a shelf somewhere, but probably not, sadly
13:37:21 <royal_screwup21> I'm not sure why this is happening and how enums come into play here...
13:37:32 <Cale> dexterfoo: However, I can tell you exactly what the scene was, in English
13:38:01 <dexterfoo> Cale: so you remember what I'm talking about? :o
13:38:05 <Cale> dexterfoo: It was 4 spheres arranged at the vertices of a tetrahedron (I probably used half the vertices of a cube)
13:38:11 <phadej> toblorone: yes, then you could abstract as `class Foo a where foo :: Int -> a`, instance Foo Int where foo :: Int -> Int; instance ... => Foo (a -> b) where foo :: Int -> a -> b
13:38:17 <Cale> I have a favourite raytracer scene :D
13:38:42 <Cale> dexterfoo: Their radii should be such that they are tangent to one another
13:38:57 <monochrom> merijn: No, you would have 5 or 6 environment variables (because each uses a $ to dereference!)
13:39:08 <Cale> and then you can place lights at each of three of the faces of the tetrahedron, and have the camera look in to the 4th face
13:39:16 <dexterfoo> Cale: Ok. I'm more interested in finding the Haskell code that I wrote rather than the layout of the scene.. but thanks :)
13:40:37 <Cale> dexterfoo: I was just thinking about a program I wrote back around that time as well, and wondering if I had the code for it anywhere
13:41:26 <Cale> It was a program where you could input the English name of a chord or scale, and it would list chords that were related by way of adding or removing any given number of notes.
13:41:41 <Cale> (in all possible inversions)
13:42:03 <Cale> I should remake it into a web application :)
13:43:18 <dexterfoo> hehe sounds cool. well if you ever do find my old raytracer code then i am always in this channel (mostly idling)
13:44:05 <toblorone> phadej: hmmm so why doesn't this work? https://repl.it/repls/VagueBlandAbility
13:44:40 <phadej> toblorone: because what the GHC tells you as an error message: those instances overlap
13:44:42 <geekosaur> royal_screwup21, because you used <- which in a list comprehension means `add x 1` produces a list
13:44:56 <phadej> toblorone: it's different than in C++ template resolution
13:45:15 <phadej> toblorone: the sooner you don't try to write as in C++ the easier it will become ;)
13:45:41 <geekosaur> which then echoes back to the [1..10], via numeric literals having type Num a => a, and at least theoretically could represent a list which then would need an Enum instance
13:46:23 <geekosaur> (because [1..10] expands to (enumFromTo 1 10)
13:47:40 <toblorone> phadej: i'm sorry, but I don't understand... how are they overlapping? What did you mean in your earlier message then? 
13:47:40 <toblorone> `class Foo a where foo :: Int -> a`, instance Foo Int where foo :: Int -> Int; instance ...
13:50:11 <phadej> oh, they don't actually overlap.
13:50:29 <geekosaur> should include the full error message
13:50:32 <phadej> but they are ambiguous
13:50:37 <geekosaur> hm, maybe it does, I didn't get it to load fully
13:50:37 <phadej> geekosaur: press run on top
13:50:47 <geekosaur> adblockers overdo things sometimes
13:51:12 <phadej> you can make that example compile with FunctionalDependencies, but it's tricky
13:52:44 <phadej> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#functional-dependencies -> google for Type Classes with Functional Dependencies
13:53:04 <geekosaur> ok, once I added the right things to the page load "run" worked
13:53:34 <phadej> that paper describes the plus example you try to do too
13:54:36 <phadej> and has a line "Without dependency information, we quickly run into problem with ambiguity"
13:55:22 <geekosaur> btw most of those errors go away with ExtendedDefaultRules, it can't resolve Num otherwise through Foo
13:55:48 <phadej> geekosaur: even I add (4 :: Int), it's still ambiguous
13:55:51 <geekosaur> but then it infers an Integer because of defaulting
13:56:08 <phadej> there can be instance (String -> Int -> SomeThingElse)
13:56:24 <phadej> so the "result type" isn't determined: ambiguous
13:56:29 <monochrom> My perspective is (as usual, monochkam razor) not how to force this code to be accepted, but why this foo class exist at all.
13:56:47 <phadej> so you would need to write (foo "bar" (4 :: Int) :: Int)
13:56:55 <geekosaur> and then print is also inferring () for its Show instance the same way
13:57:06 <toblorone> monochrom: well I was curious why c++ type overloading wasn't possible in haskell and someone suggested that i could be done like this
13:57:09 <monochrom> For example WTH does it even try to model?  Any coherent laws other than "I like to overload a cool function name"?
13:57:23 <geekosaur> toblorone, I think it would be possible, but not at the same time as typeclasses
13:57:46 <phadej> toblorone: search and read the paper I linked, it's better explanation than you'll get from "random" folks on IRC :)
13:57:54 <monochrom> I have never heard of "type overloading". Not even in Haskell or Agda.
13:58:06 <toblorone> monochrom: i should've said "c++ style"
13:58:09 <geekosaur> or various other aspects of types (e.g. complicates parametric polymorphism). haskell made this tradeoff instead of that one
13:58:14 <toblorone> phadej: ok i'll check it out
13:58:51 <monochrom> What is "type overloading"? Does it mean suddenly "int" refers to different types in different contexts?
13:59:12 <toblorone> no. type overloading isn't a thing. I meant to say "c++ style overloading"
14:00:07 <toblorone> eg: you can define int foo (int, char*, bool) and int foo (char*,char*, char*)
14:00:21 <phadej> I think this problem won't benefit from meta-level discussion, let's wait until toblorone reads the paper; it has short overview of type classes in haskell, and describes how something like Foo (= Add) can be made work in Haskell
14:00:35 <monochrom> Then I don't know in what sense it is not possible in Haskell. I thought classes like Eq, Ord, Num (just need Haskell 2010, no extension needed) already are good examples?
14:01:09 <Tuplanolla> If you're looking for "type-directed name resolution", we don't have that, toblorone.
14:01:35 <toblorone> Tuplanolla: that's a good name for it
14:01:46 <Tuplanolla> If you're looking for "ad-hoc polymorphism", we do have that via type classes.
14:02:20 <Solonarv> actually we do have type-directed name resolution, but *only* for record field selectors
14:02:32 <Solonarv> (with the appropriate GHC extension(s) enabled)
14:02:44 <phadej> Solonarv: not in Haskell98, so this really doesn't help
14:03:00 <Solonarv> true
14:03:17 <phadej> (think hard before starting a comment with "actually" and "well" when talking to beginners; I often do that mistake myself, and always regret)
14:04:26 <toblorone> monochrom: those aren't the same as c++ though? the "methods" of each are parameterized with a single type variable and have a fixed number of arguments
14:04:57 <toblorone> phadej: that's probably good advice ha
14:06:33 <monochrom> OK.
14:08:24 <Tuplanolla> I should also point out that "operator overloading" and "template instantiation" as they are in C++ are both different from "type classes" and "type class resolution" as they are in Haskell.
14:08:36 <Tuplanolla> The parallels are merely analogies.
14:10:22 <Tuplanolla> Actually "instance resolution" would've been a better term for the last concept.
14:11:16 <phadej> template instantiation and instance resolution are unfortunately quite close conceptually, but rules are different indeed
14:11:48 <fen> how do we describe what can be done best with various idioms?
14:12:07 <boj> with words
14:12:13 <monochrom> "The best that can be done with various idioms."
14:12:23 <fen> is the "style" that arises something computer science considers?
14:13:00 <monochrom> Yes, in particular machine learning is very interested in it.
14:13:31 <fen> thats more of a black box approach though
14:13:49 <fen> normally in systems theory we consider specific aspects
14:14:11 <monochrom> That doesn't contradict either "machine learning considers it" or "machine learning is part of computer science".
14:14:40 <fen> but it doesnt therefor satisfy "describe" 
14:15:33 <fen> its the interacting components that are not represented that capture all the information
14:16:33 <fen> unless machine learning fills in a graphical template. they do that with gene modelling, you find the least complex (irreducible) structure
14:17:01 <fen> which actually might be a pretty interesting way to consider languages
14:17:19 <fen> but basically, that template would have to be existing and developed using human reason
14:17:22 <fen> i think...
14:18:10 <fen> well, certainly it can help show if a certain template is sufficient. but anyway the question remains about how it is done traditionally  
14:19:30 <fen> an earlier comment on this was "lazy vs strict" having pretty far reaching implications on the way we write code and what the most common functions we use are etc 
14:19:40 <fen> doesnt this have a standard? 
14:20:41 <fen> monochrom: can you reference that? what literature has resulted from this interest ?
14:20:49 <monochrom> No.
14:21:03 <fen> so its just interesting, but no headway has been made
14:21:08 <fen> i find that hard to believe!
14:21:21 <fen> oh, or you just dont have any references to hand.. 
14:21:27 <fen> so what makes you think this?
14:23:08 <fen> its difficult with not having any computer science training its impossible to guess at what kind of interest exists in academia 
14:23:24 <fen> well, nothing serious anyway
14:23:54 <fen> have heard people mention particular styles pertaining to C etc
14:24:09 <fen> but these dont make any sense unless you speak C
14:24:25 <fen> just thought there might be an actual way to call these things
14:24:37 <monochrom> Computer science is huge. Even those who have a degree know only like 1%.
14:25:00 <fen> like - how it does polymorphism, somethings as first order values etc
14:27:50 <fen> vaguely remember people finding java class hierarchies useful
14:28:04 <fen> like, the "way it does them" has some nice properties
14:28:10 <fen> what do you call that?
14:29:13 <fen> monochrom: right, and people that can evaluate the differences between various languages in a reasonable way are rare
14:29:27 <fen> are they just "language features" like we have in haskell?
14:29:48 <fen> like "cant pass functions as arguments" is a kind of thing
14:30:12 <fen> and then, what ends up happening with various capabilities of different languages
14:31:05 <fen> are each language feature totally different or do they have different named groups - cant think of an example
14:31:55 <hiptobecubic_> concepts generally do have names, if that's what you're asking
14:32:06 <fen> thats certainly not what im asking!
14:32:11 <fen> im asking what its called!
14:32:55 <hiptobecubic_> What is "it" in that question
14:33:04 <fen> like, lazyness is totally different to polymorphism, but some set of features could be to do with representing hierachies or something
14:33:27 <fen> and then some languages might use different subsets of features to achieve similar or different things
14:33:58 <fen> but all those features would be under the same heading
14:34:06 <fen> "hierarchy somethings" or something
14:34:16 <hiptobecubic_> I think you're finding it difficult to attach a name to this concept because you're not asking a concrete question
14:34:36 <fen> like, an actual example would be helpful, but i dont know the computer science so its difficult
14:35:07 <monochrom> It is still an open problem what "language feature" means.
14:35:24 <fen> yeah, thats one part, and then the other is about the name of its collections
14:35:27 <boj> whatever you are aimning at, it is way too abstract
14:35:32 <hiptobecubic_> Like, different kinds of engineers can all use some subset of math to achieve similar or different things. What of it? Math is a general tool. There's no name for it other than "math" or the name of the subfield of "math" that you're referring to directly.
14:35:41 <monochrom> Or rather, an open problem of quantifying/formalizing it.
14:36:17 <fen> yeah but you would be able to refer to things as subbranches of algebra, like homotopy type theory 
14:36:39 <monochrom> Not quite an open problem if you just ask around "what does lazy evaluation mean" and find that people have very good consensus despite having no quantification or formalization.
14:36:51 <monochrom> The same is true of "what is a car?"
14:37:57 <fen> like, we understand what is an idiom - machine generated code is often not how a human would write it because they have a particular way of thinking which shapes their derivation appraoches and resulting code. maybe there are several equivalent ways, even that cant be simplified. 
14:39:08 <fen> but this termanology to describe "how the code people end up writing is shaped by the language features" should have some describable component concepts, where we can find specific examples 
14:39:40 <monochrom> Oh that's just Sapir-Worf.  (I would add -Orwell.)
14:40:05 <Rembane> That has been debunked for spoken languages, does it still hold true for formal languages?
14:40:10 <monochrom> Oh nevermind they just pointed out that it happens. You're asking how/why.
14:40:34 <fen> the idea is to make groups of things
14:40:41 <monochrom> No I have zero evidence of it for formal languages.  I just like to whip it out and tease people!
14:40:42 <fen> and nest these as deeptly as possible
14:41:04 <fen> we have "language features" as a kind of atomic unit, and now seek an example of several which solve the same thing
14:41:09 <monochrom> Actually I probably could have much evidence if I bothered to gather data.
14:41:33 <Rembane> monochrom: It's a good thing to whip out.
14:41:50 <monochrom> Actually I probably could just dump my students' assignment code as evidence. >:)
14:41:51 <fen> "these are all different ways of approaching the *insert example here* problem"
14:42:18 <Rembane> monochrom: If you ever do that, ping me! 
14:42:36 <fen> monochrom: do they speak more than one language already to be able to draw these comparisons!? 
14:44:01 <monochrom> I have students who define, for example, "data X = X Int Bool".  Then they go on to define "getInt (X i _) = i", "getBool (X _ b) = b".  Then they go on to use getInt and getBool exclusively instead of pattern matching at the spot where they're needed.
14:44:23 <Rembane> :D
14:44:30 <monochrom> So my theory is they were trained by Java and Python and all they can think now is "getter methods".
14:45:18 <fen> right, so thats an artefact of them not having pattern matching in java?
14:45:30 <Solonarv> (this seems related to the idea of a "grammatical accent" for natural languages)
14:45:50 <monochrom> Truth be told, after I shared this with colleagues and really expert people, they have a broader and simpler theory.  "You learned hammers well, so now you only know to use hammers on everything"
14:46:21 <Solonarv> also true
14:46:32 <fen> right, it shapes a way of thinking
14:46:33 <Rembane> Trying hammers first is a good idea imo
14:46:38 <RedNifre> What can cause Segmentation Faults?
14:47:19 <geekosaur> bad FFI, usually
14:47:20 <fen> so you would say various tools can be used for the same purpose?
14:47:40 <fen> RedNifre: coerce? 
14:47:52 <fen> unsafeCoerce* 
14:48:19 <monochrom> Related experiment done by other pedagogic people:  You pick out kids who have recently and only learned addition.  Then you pose them this problem: "A ship is shipping 20 pigs and 30 goats.  How old is the ship's captain?"
14:48:44 <restrictedchoice> hire the kid who punches you?
14:48:48 <monochrom> Most such kids actually think up an excuse to do 20+30 and answer "captain is 50 years ago".
14:48:53 <Rembane> :D
14:49:09 <Solonarv> monochrom: interesting, got a link?
14:49:16 <monochrom> I lost the link.
14:49:17 <fen> oh right yeah, specifically pertaining to computer science, to draw on your depth of experience in this field and answer the question with actual useful example, sure
14:49:58 <RedNifre> Okay, so only unusual stuff causes SegFaults?
14:50:46 <RedNifre> (Actually, I got a SegFault in Idris and just assume that Idris segfaults in the same situations as Haskell does, but I guess that's not really the case then)
14:51:04 <monochrom> Bugs cause segfaults.  To be sure, it is hard to be sure whose bug it is.
14:51:37 <fen> rather than spin a yarn "oh for years, the ... language struggled with the notion of ... and presented numerous various proposals, none of which quite manage to solve it, so eventually that language was abandoned all together. this has since become known as the ... problem and is a fundamental aspect to be handled by any worthy language"
14:51:46 <Solonarv> might also be a bug in the compiler (leading to incorrect codegen)/ standard library (which usually rests on primitives/FFI somehow)
14:52:16 <monochrom> IMO the right question is "how much would you pay someone to hunt down this bug?"
14:52:34 <fen> how much would you pay the bug to just stfu!
14:52:57 <monochrom> stfu = seg the fault up? >:)
14:53:02 <Solonarv> but how can you pay the bug without having found it? :P
14:53:32 <fen> maybe it would emerge on the offer of big bucks and then you could use the hammer 
14:54:19 <fen> maybe you could design a language with no seg faults!?
14:55:07 <monochrom> Idris was designed with no segfaults. Yet we are observing one. What gives?
14:55:30 <RedNifre> meh, time for some good old printf debugging (Idris is eager, so this might work better than in Haskell)
14:55:44 <monochrom> Yeah!
14:56:55 <fen> no idioms today
14:57:01 <RedNifre> I strongly suspect that it's caused by my non total Show implementations inside of a mutual block or something...
15:07:41 <RedNifre> Okay, non total Show instances cause the segfault. This would be less problematic in Haskell because the laziness would at least print my data up to the point where a "Show a" can't be shown... in an eager language, the program crashes so early that you don't get any output at all.
15:11:02 <monochrom> That would still be "Idris implementer laziness". :)  The implementation could have done simply run-time checks and branch to a consciously written error handler, rather than segfault.
15:59:03 <fen> % data BCConstructor = LinearC (* -> *) | StackC  (* -> *) | StreamC ((* -> *)) | Nested [BCConstructor] 
15:59:03 <yahb> fen: 
15:59:55 <fen> :t StreamC Identity
15:59:56 <lambdabot> error:
15:59:56 <lambdabot>     Data constructor not in scope: StreamC :: (a0 -> Identity a0) -> t
16:00:05 <fen> % :t StreamC Identity
16:00:05 <yahb> fen: ; <interactive>:1:9: error:; * Couldn't match type `Identity *' with `*'; Expected type: * -> *; Actual type: * -> Identity *; * In the first argument of `StreamC', namely `Identity'; In the expression: StreamC Identity
16:00:10 <fen> % :k StreamC Identity
16:00:10 <yahb> fen: StreamC Identity :: BCConstructor
16:01:43 <fen> r
17:00:03 <roconnor> Hmm,  Haddock doesn't include docs of reexpoted-modules?
17:11:02 <roconnor> Found the issue @ https://github.com/haskell/haddock/issues/563
17:25:14 <shapr> dcoutts: could I get the password for my hackage account reset? I bet you're busy with sixty other things ...
17:34:48 <shapr> @seen dcoutts
17:34:48 <lambdabot> DCOU+75
17:34:55 <shapr> lambdabot: you are not helping.
17:43:17 * hackage hpython 0.3 - Python language tools  https://hackage.haskell.org/package/hpython-0.3 (qfpl)
17:46:53 <shapr> oh interesting, is that based on bj pope's berp?
17:47:08 <shapr> guess not
18:39:11 <suzu> lol is that leetspeak
18:58:51 <geekosaur> "@seen" edit-corrects to "@leet", yes
19:10:41 * geekosaur doesn't know why there aren't dummy commands on @seen and @info, being the two most common things that edit-correct unexpectedly
19:10:59 <fizbin> Anyone here really know stack?
19:11:41 <fizbin> I'm trying to convert a Makefile from using cabal to using stack for the haskell bits, and stack seems to make it impossible to know where the binaries will get written.
19:12:30 <geekosaur> iirc you can dig it out of "stack path"
19:13:28 <fizbin> With cabal, I could just have my makefile do a `cabal build` and then pick the binaries out of a known location (dist/build/BINARYNAME/BINARYNAME)
19:13:36 <MarcelineVQ> --local-install-root perhaps
19:14:30 <fizbin> @geekosaur Not that I can see. You can find the location it'll install stuff into when you do "cabal install", but I really don't want this Makefile to cause stuff to happen to the home directory of someone who runs it.
19:14:30 <lambdabot> Unknown command, try @list
19:14:55 <fizbin> MarcelineVQ: I'll try that...
19:15:07 <MarcelineVQ> e.g. $(stack path --local-install-root)/bin
19:16:52 <fizbin> MarcelineVQ: Oh, that won't work. I really don't want stack to install stuff in a subdirectory of the home directory and then have the Makefile copy stuff out again.
19:17:22 <MarcelineVQ> Not sure what you're actually wanting now :> Do you want to specify where the bins get placed?
19:18:31 <fizbin> MarcelineVQ: I either want to be able to say "place the binaries here, in this spot underneath the build tree", or I want to run something that will tell me where they wound up after "stack build" built them.
19:18:55 <fizbin> I don't want this build to mess with something outside the build tree.
19:19:14 <fizbin> I mean, the stack cache stuff is okay.
19:20:24 <MarcelineVQ> you can place them where you like with stack --local-bin-path thepath thecommand, you can ask where the things wind up with stack path --local-install-root or stack path --dist-dir
19:20:25 <fizbin> Oh, look at this. "stack install --local-bin-path ..."
19:21:43 <MarcelineVQ> stack path isn't some global cache it's per project, when you ask the paths from the project you're building it gives you that project's paths
19:32:41 <dmwit> You might try `stack exec which my-executable`.
19:32:59 <dmwit> Not really a stack expert, but the docs suggest it should modify the PATH of the subcommand appropriately for that to work.
19:33:59 <CelestialLake> Well, stack has an ill tendency of hiding stuff from user (.stack-work or whatever it was)
19:42:33 <fizbin> Is there any way in stack to get the equivalent of `cabal test --test-option=--jxml=dist/test/$test-suite.xml` ? That is, pass an argument to all the tests that includes a templated spot for the test name?
20:36:25 <fen> need; '[a] -> (a -> (* -> *)) -> '[* -> *], but Fmap takes (a ~> b), and defunctionalising gives (a ~> (* ~> *)) resulting in '[* ~> *]
20:43:12 <fen> Fmap again with (* ~> *) ~> (* -> *) ?
20:46:21 <jle`> do you mean [a], and not '[a]
20:46:39 <fen> yeah
20:47:12 <jle`> fen: if you have a (a -> (* -> *), you can use TyCon1
20:47:14 <domenkozar[m]> I've been avoiding Lens, could someone help me how to position getters/setters in here:      uri & (URI.uiPasswordL . URI.authorityUserInfoL . URI.authorityL) .~ password
20:47:24 <jle`> TyCon1 :: (a -> b) -> (a ~> b)
20:47:43 <jle`> oh, mayb ei misread your question
20:47:53 <jle`> domenkozar[m]: what are you trying to get/set?
20:48:15 <domenkozar[m]> given an uri, get into a deep level and set password
20:48:17 <jle`> fen: can you explain your question again? you're trying to do some flip fmap?
20:48:33 <jle`> domenkozar[m]: is 'password' the password you want to set?
20:48:39 <domenkozar[m]> yes
20:48:44 <jle`> that looks right to me
20:48:53 <fen> % data TyCon1 (tc :: a -> b) (tf :: TyFun a b)
20:48:53 <yahb> fen: ; <interactive>:7:35: error: Not in scope: type constructor or class `TyFun'
20:49:03 <jle`> the parentheses aren't necessary but if you're starting out then it helps with readability maybe
20:51:12 <domenkozar[m]> ah need to flip around
20:51:18 <domenkozar[m]> now just need to handle Maybes
20:52:30 <fen> % :kind TyCon1
20:52:30 <yahb> fen: TyCon1 :: (a -> b) -> TyFun a b -> *
20:52:48 <fen> type a ~> b = TyFun a b -> *
20:52:50 <fen> aha
20:53:09 <fen> maybe that will work
20:53:10 <fen> thanks
20:53:52 <fen> oh, it would need to be defunctionalised itself...
20:54:06 <fen> ok, should be fine
20:55:59 <fen> looking forwards to seeing how DependantHaskell will manage to solve these kinds of things...
20:57:41 <fen> writing `Fmap TyCon1Sym0 (Fmap f)' instead of `Fmap (TyCon1Sym0 $$.! f)' is unidiomatic but saves some complexity from the defunctionalised dot
21:00:21 <fen> oh wait
21:00:32 <fen> no, thats the wrong thing all together 
21:01:11 <fen> jle` : TyCon1 :: (a -> b) -> (a ~> b), but the type needed is (a ~> b) -> (a -> b)
21:01:26 <fen> it needs to be an un-TyCon1
21:02:19 <jle`> ah yeah, we have (@@) :: (a ~> b) -> a -> b
21:02:25 <jle`> application :)
21:02:57 <fen> and a defunctionalised version? 
21:03:35 <fen> yeah, was trying Fmap (f @@) at one point
21:03:49 <jle`> why not Fmap f?
21:05:05 <fen> because it gives [* ~> *], but it should be [* -> *] for another function (Nest :: [* -> *] -> * -> *, like Free but with a different `f' at each level)
21:05:49 <fen> its fmapping over a list of Tags which are passed around instead of things of kind * -> * 
21:06:41 <fen> the function being fmapped resolves the tag, but its fully defunctionalised version returns a partially defunctionalised thing
21:06:47 <fen> when fmapped
21:08:26 <fen> yikes! when writing ApplySym0 how are we supposed to give an Apply instance!? is that a problem?
21:10:31 <fen> % type family Apply (f :: k1 ~> k2) (x :: k1) = (k :: k2) 
21:10:31 <yahb> fen: 
21:12:33 <fen> % data ApplySym1 :: (f :: k1 ~> k2) -> (x :: k1) ~> (k :: k2) 
21:12:33 <yahb> fen: ; <interactive>:18:19: error:; * Expecting one more argument to `(f :: k1 ~> k2)'; Expected a type, but `(f :: k1 ~> k2)' has kind `k1 ~> k2'; * In the kind `(f :: k1 ~> k2) -> (x :: k1) ~> (k :: k2)'
21:12:38 <fen> its not working!
21:14:03 <fen> oh...
21:14:06 <fen> % data ApplySym1 :: (k1 ~> k2) -> k1 ~> k2 
21:14:06 <yahb> fen: 
21:14:15 <fen> % type instance Apply (ApplySym1 a) b = Apply a b
21:14:15 <yahb> fen: 
21:14:17 <fen> yay!
21:14:22 <fen> ok everything seems fine
21:22:43 <fen> hmmm, but now its just ApplySym0 (a ~> b) ~> (a ~> b)
21:22:52 <fen> hmmm, but now its just ApplySym0 :: (a ~> b) ~> (a ~> b)
21:23:00 <fen> thats no good at all
21:23:02 <fen> damn
21:24:19 <fen> seems like you *cant* defunctionalise Apply
21:27:33 <fen> maybe there is a way to defunctionalise the original F :: (Tag -> * -> *) into FSymSomthing :: (Tag ~> (* -> *)) instead of FSym0 :: (Tag ~> * ~> *) 
21:27:45 <fen> jle` ^ ?
21:29:06 <fen> like the opposite way round from Sym1
21:29:33 <fen> which would be (Tag -> (* ~> *))
21:42:47 * hackage aeson-diff 1.1.0.7 - Extract and apply patches to JSON documents.  https://hackage.haskell.org/package/aeson-diff-1.1.0.7 (ThomasSutton)
21:48:54 <fen> not sure really about this at all
21:49:47 <fen> like, writing data Something (tf :: a ~>b) (tc :: a -> b)
21:50:02 <fen> is like the opposite of how you write a defunctionalisation symbol
21:50:30 <fen> which is basically wrapping something of type (a -> b) and telling GHC it actually has type (a ~> b)
21:50:38 <fen> this does not seem like it would work backwards
21:51:08 <fen> basically, your wrapping (a ~> b) and telling GHC it actually has type (a -> b) ...
21:51:15 <fen> thats going to break right?
21:51:36 <fen> like when you try and apply a value to it
21:51:41 <fen> a type*
21:52:48 <fen> it kind of does actually have type (a -> b), but only within the TyFun data constructor
21:52:53 <fen> not sure how to unwrap that
21:53:51 <fen> like, if you want to apply a value to something of kind (a ~> b) you use @@ to unwrap it
21:54:06 <fen> but GHC isnt going to know to do that when it sees something of kind (a -> b)
21:59:42 <fen> and there is no way to partially apply the defunctionalisation...
21:59:57 <fen> like you cant write;
22:00:10 <fen> data A_Sym01 :: Tag ~> (* -> *)
22:00:32 <fen> type instance Apply A_Sym01 x = A x
22:00:46 <fen> for type family A :: * -> * -> *
22:00:56 <fen> because thats leaving it partially applied
22:01:10 <fen> so basically you *have* to result in a [* ~> *]
22:01:20 <fen> there is no way round it!
22:02:04 <fen> so then there is no way of using a function `[* -> *] -> b' on it
22:02:28 <fen> somehow we have to convert that into a function `[* ~> *] -> b'
22:02:40 <fen> whats that some kind of hellish natural transformation?
22:02:53 <fen> :-(
22:23:17 * hackage constraints-deriving 1.0.1.1 - Manipulating constraints and deriving class instances programmatically.  https://hackage.haskell.org/package/constraints-deriving-1.0.1.1 (achirkin)
