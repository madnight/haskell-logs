00:40:33 <infinisil> ARE YOU SERIOUS
00:40:48 <infinisil> I debugged this stupid problem for like 2 hours now
00:40:49 <infinisil> or more
00:41:07 <infinisil> You know what solved it, a frigging `cabal clean`
00:41:23 <infinisil> NOT COOL
00:43:15 <Cale> hmm, what was the problem?
00:45:20 <infinisil> Apparently when you patch a dependency with Nix and reload the environment, cabal doesn't actually realize that, and uses the caches of the previous version
00:46:13 <Cale> ahh, sometimes cabal configure is enough as well
00:46:31 <Cale> If it's the sort of thing I'm thinking of, anyway
00:51:34 <infinisil> Yeah probably
00:53:39 <ryant[m]> F
02:01:22 <zincy> What is the use case of free monads?
02:27:19 <zincy> Solonarv: I am a bit confused about how primFunc works in your gist? https://gist.github.com/Solonarv/8525a61340edaad47908081381be6ff1
02:28:13 <Solonarv> zincy: what part of it is confusing you?
02:29:47 <zincy> The use of pure outside of a monadic context confuses me
02:30:05 <Solonarv> ah, but there is a monadic context here
02:30:27 <Solonarv> the type of Closure's field is 'Val p v -> EvalM (Val P v)'
02:33:03 <zincy> So `f` is the Closure's data constructor argument (not sure what the name for that is)
02:33:24 <zincy> And f  is a function which returns in the EvalM monad
02:34:08 <Solonarv> no, the argument of Closure is the whole \case PrimVal p -> ...; Closure _ -> ...' block
02:36:03 <zincy> Ah I see
02:36:41 <zincy> So is the purpose of primFunc to enable the lifting of arbitrary unary functions into the Val data type
02:37:18 <Solonarv> precisely
02:37:51 <zincy> And the arith map is like the languages standard lib?
02:37:57 <Solonarv> yup!
02:38:08 <Solonarv> well, one example of such
02:38:26 <zincy> So is this how you would write a std lib for such a language
02:38:37 <zincy> because directly writing the std lib in AST form is annoying
02:38:53 <Solonarv> I mean, it's not possible
02:38:53 <zincy> Can I just use primFunc2 (.)
02:39:11 <zincy> To enable the lang to support composition
02:39:17 <Solonarv> the std lib is a set of bindings that are in scope for every program, how could you write that as a program?
02:39:37 <Solonarv> no, primFunc / primFunc2 are for lifting "primitive" functions into the language
02:40:17 <zincy> Look for the token representing say + and then just swap bits out on the ast
02:40:56 <zincy> Look for the token representing say + and then just swap bits out on the ast 
02:42:46 <zincy> Solonarv: Is your gist using strict evaluation
02:42:57 <Solonarv> yes it is
02:43:16 <Unhammer> Does stack download a list of package names somewhere that I can grep?
02:43:29 <Unhammer> to query locally what's in lts-12.10 or whatever
02:44:03 <Solonarv> Unhammer: yes, should be somewhere in ~/.stack - I don't know where exactly, but you should be able to find it by exploring
02:44:09 <zincy> Solonarv: How would you write a lazy version of primFunc that takes (Exp -> Exp -> Value) ?
02:44:28 <Solonarv> zincy: the strictness isn't in primFunc, it's built into eval
02:44:36 <Solonarv> specifically the App rule
02:45:16 <Solonarv> 'body =<< eval e' performs 'eval e' before passing its result to 'body'
02:48:05 <Solonarv> I added a "compose" function to the gist
02:48:06 <zincy> Thanks
02:48:35 <Unhammer> hm, there's .stack/indices/Hackage/*index* but those are huge, while the .idx files are some binary format
02:48:48 <Solonarv> zincy: whoops, reload it - small fix
02:49:17 <Solonarv> Unhammer: those indexes hold all-packages-in-existence
02:50:14 <Solonarv> you're looking for some lts-X.Y.yaml files I think
02:50:37 <Solonarv> note that you won't find every snapshot in existence there, only those that have been downloaded at some point
02:51:06 <Solonarv> zincy: so, since eval uses strict evaluation, there's no straightforward way to do laziness in this language
02:53:56 <zincy> I am trying to slowly incorporate the ideas from your gist into mine
02:54:03 <zincy> neg = primFunc $ NumVal . negate  
02:54:26 <zincy> Solonarv: ^ How do I get around the fact that primitive values are tagged with data constructors
02:54:47 <Solonarv> you don't, in this design
02:55:00 <Solonarv> that's the cost of abstracting out the type of primitive values
02:55:44 <Solonarv> could do some stuff with classy prisms which would probably be reasonably pleasant, but I couldn't be bothered to do that
02:56:19 <Solonarv> note also that it'll be something like: neg = primFunc $ NumVal . negate . unNumVal
02:57:28 <zincy> That works
02:57:32 <zincy> Why do you need classy prtisms
02:57:59 <Solonarv> hm, don't *need* them strictly speaking
02:58:40 <Solonarv> I guess you could do something like: primFunc :: (p -> Maybe a) -> (a -> p) -> Val p v
02:59:15 <Solonarv> where the first argument says how to take the value out of the primitive
02:59:33 <zincy> So I guess classyPrisms would abstract out this pattern : neg = primFunc $ NumVal . negate . unNumVal 
03:00:05 <Solonarv> e.g. if you had data Prim = PrimInt Int | PrimStr String
03:00:05 <Solonarv> you would have neg = primFunc (\case PrimInt i -> Just i; _ -> Nothing) (PrimInt . negate)
03:02:16 <zincy> Or an Either which could express a typeError?
03:02:42 <Solonarv> yeah, or that
03:14:49 <zincy> Solonarv: Getting there ... https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab
03:18:55 <Solonarv> indeed!
03:19:23 <Solonarv> the biggest difference I see is that the function in your NumVal takes an Exp, whereas mine takes a Value
03:19:30 <zincy> Now just primFunc2
03:19:59 <zincy> Yeah if I went straight to Value I would end up copy and pasting and not learning :P)
03:21:44 <Solonarv> your approach would in theory allow for a lazy evaluation, but you don't actually make use of that
03:22:23 <zincy> Yeah to make use of that would I just try to avoid passing Values about as much as possible
03:22:39 <zincy> Are there degrees of lazy evaluation?
03:22:53 <Solonarv> I'm not sure
03:23:04 <Solonarv> actually, definitely yes
03:23:26 <Solonarv> but your language is just strict in the usual way (no evaluating-as-far-as-possible under a lambda)
03:24:14 <Solonarv> (which we could call "super-strict")
03:25:00 <zincy> eval (Let varName varExp exp) = do
03:25:00 <zincy>   val <- eval varExp
03:25:00 <zincy>   bindVar varName val (eval exp)
03:25:17 <Solonarv> yup, that's the part which makes everything strict
03:25:37 <Solonarv> it's quite a bit simpler to write a strict language, so I'd recommend sticking to that
03:25:44 <zincy> Yes haha
03:26:27 <zincy> So would the language grammar essentially be the Exp type
03:26:40 <zincy> Plus Value
03:28:24 <zincy> Is if-then-else basically a binary function?
03:28:42 <zincy> Sorry trinary
03:28:59 <zincy> condExp ifExp elseExp
03:29:10 <zincy> You would need a Boolean type then
03:29:21 <Solonarv> The language grammar is just the Exp type, Value isn't involved
03:29:57 <Solonarv> And yes, if-then-else is a ternary function
03:30:37 <zincy> ah right so grammar is the structural rules
03:31:05 <zincy> Is there a ternary function in haskell for IfthenElse
03:31:41 <JappleAck> zincy: kinda (?)
03:32:01 <zincy> :t (?)
03:32:02 <lambdabot> error: Variable not in scope: ?
03:32:26 <JappleAck> it's definition: (?) :: Bool -> a -> a -> a; (?) c x y = if c then x else y; {-# INLINE (?) #-}; infixl 1 ?
03:33:02 <JappleAck> it's not in base package or something, you just able to define it yourself
03:33:14 <JappleAck> also https://wiki.haskell.org/Ternary_operator
03:33:27 <JappleAck> but i believe i've seen package with all the ways to do "if" stuff
03:34:56 <JappleAck> just don't remember how to find it :(
03:34:59 <zincy> Solonarv: Is there a function which can return primFunc functions of a given arity?
03:36:08 <Solonarv> There might be a way
03:36:36 <JappleAck> ah, found it https://wiki.haskell.org/Case happy to see i left a comment with that link in my own code)
03:37:42 <JappleAck> zincy: but you may like MultiWayIf extension instead of ternary operator (depends on what you're doing)
03:53:31 <zocijux[m]> hi
03:56:34 <zincy> Solonarv: Any ideas ? https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab
03:56:40 <zincy> hi
03:59:07 <Solonarv> zincy: can't look right now, I'll ping you later
03:59:15 <zincy> Sure :)
04:19:13 <tty1> I'm trying to understand functions as Applicatives and having a hell of a time getting an intuitive understanding. Can someone help me. Here is a stackoverflow question I created where I go into more detail about how I'm trying to reason about this: https://stackoverflow.com/questions/55991151/understanding-functions-as-applicatives-in-haskell
04:19:50 <zincy> :t (<*>)
04:19:51 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
04:20:01 <tty1> Thanks in advance by the way, any help is really appreciated.
04:21:01 <tty1> zincy: I managed to understand applicatives (I think) in the context of other things like Maybe or Lists, at least I have applied those ideas there successfully. Its only on functions specifically where I'm confused. The link i gave might help you understand my confustion (I hope)
04:23:09 <JappleAck> tty1: imagine you have a sum function, like this one: sum = (+), you apply it to two arguments: sum 10 20
04:23:09 <JappleAck> and if you have those values wrapped to some container, like inside Maybe, you could do kinda the same like this: sum <$> Just 10 <*> Just 20, <$> is allusion to $ operator, and <*> is a separator for wrapped values
04:24:22 <zincy> Are you trying to understand how (->) is an applicative?
04:24:23 <JappleAck> tty1: but in this case your `sum` function is pure, i mean not wrapped, you also may have that function wrapped, see: Just sum <*> Just 10 <*> Just 20 -- and you get Just 30
04:25:27 <tty1> JappleAck: thanks, yea that part I understand, I've been applying it to most common Applicatives successfully. My issue is very specific to understanding Functions being applied to other functions.. like this is where I get lost (\a b c -> a*2+b*3+c*5) <*> (+) ... What does that do?
04:25:43 <JappleAck> tty1: <*> separates wrapped values/functions (you could think about a value as a function with no arguments) and <$> separates *not* wrapped function
04:25:52 <tty1> or even simpler why does (\a b c -> a*2+b*3+c*5) <*> (+3) behave the way it does
04:26:30 <Social-Reject> good morning all, how do I run this one test :: ([Int] -> [Int]) -> ([Int] -> [Int]) -> [Int] ------------> test f x = x (f [1,2,3])
04:27:12 <tty1> JappleAck: the second it becomes counter intuitive is when botht he right and hand side of the <*> both have functions that take multiple arguments
04:27:33 <tty1> *both the right and left hand side
04:31:10 <JappleAck> tty1: i personally haven't met such example too, i believe it comes from Applicative ((->) a) instance
04:31:13 <zincy> I think it is key to remember that all functions are curried
04:32:22 <tty1> yea I'm pretty sure it has to do with currying and function composition. Thanks anyway an answer just came in on SO that may help me, I'm reading and pondering it now...
04:33:37 <JappleAck> here is how that instance defined for <*> operator: (<*>) f g x = f x (g x)
04:35:59 <JappleAck> it seems it's just a composition with different arity of a function (the dot combines function with only one argument)
04:36:17 <zincy> fmap of functions is composition
04:39:17 <zincy> Is pure int the context of (->) essentially const?
04:39:27 <JappleAck> > ((\a b c -> "A " <> a <> " B " <> b <> " C " <> c) <*> (<> "baz")) "foo" "bar"
04:39:29 <lambdabot>  "A foo B foobaz C bar"
04:40:13 <JappleAck> > ((\a b c -> mconcat ["A ", a, " B ", b, " C ", c]) <*> (<> "baz")) "foo" "bar"
04:40:15 <lambdabot>  "A foo B foobaz C bar"
04:40:51 <Solonarv> zincy: yes, pure is const
04:42:16 <JappleAck> tty1: the `b' here is a duplicate of first argument but applied with function from second argument of <*>
04:44:57 <JappleAck> > ((\a b c d -> mconcat ["A ", a, " B ", b, " C ", c, " D ", d]) <*> (<> "baz") <*> (<> "bzz")) "foo" "bar"
04:44:59 <lambdabot>  "A foo B foobaz C foobzz D bar"
04:46:39 <JappleAck> tty1: and if you don't need original "foo" value, you use <$>:
04:46:41 <JappleAck> > ((\a b c -> mconcat ["A ", a, " B ", b, " C ", c]) <$> (<> "baz") <*> (<> "bzz")) "foo" "bar"
04:46:44 <lambdabot>  "A foobaz B foobzz C bar"
04:46:45 <tty1> hmmm
04:47:09 <tty1> yes I think this is starting to make sense now....
04:47:27 <tty1> Still absorbing it all but I think im on the right track now, thanks
04:53:38 <JappleAck> > ((\a b -> mconcat ["A ", a, " B ", b]) <$> (<> "baz") <*> (<> "bzz")) "foo"
04:53:40 <lambdabot>  "A foobaz B foobzz"
04:54:29 * JappleAck thinks he's on few steps before reinventing parallel computation
04:54:40 <JappleAck> like kleisli arrows or something
05:17:02 <talqu> hi, i have two source files App.hs, which is called from Main.hs. ghcid -r gives me this warning https://pastebin.com/GNkKTPg6. Why does it say I have include App module to other-modules in cabal file? How should I get rid of this warning?
05:40:00 <pavonia> talqu: other modules are modules that are not exposed to the package user but are still needed to compile the package
06:03:49 <svipal> I wish there was a way to make multiple files part of one module
06:05:08 <pilmi> q
06:23:16 <tty1> Why does (\a b-> b) <*> (+) result in a function that takes two arguments while (\a b-> a) <*> (+) results in a function that takes one argument?
06:25:43 <JappleAck> tty1: because the whole expression takes one argument, where `b' is original that argument and `a' is that argument applied with function from second argument of <*>
06:26:16 <tty1> hmmm
06:26:37 <JappleAck> > ((\a b -> b) <*> (+)) 1 2
06:26:39 <lambdabot>  3
06:27:33 <tty1> JappleAck: so is haskell just smart enough to know that one of the arguments isnt used by the function so it drops it? I'm not sure I understood your explanation even though it was probably correct
06:27:38 <Athas> So, what's the #haskell consensus on linear types in GHC?
06:28:14 <JappleAck> wait, i guess i mixed up `a' and `b'
06:28:37 <JappleAck> `a' is original value
06:30:09 <JappleAck> tty1: you remember previous examples, <*> gives you original value and second value applied with function from second argument of `<*>'
06:30:27 <tty1> right if I understand it corre3ct if i used math notation mixed with haskell it would be something like f(a,b) <*> (+) is the same as defining a new function that is g(x,y) = f(x, x+y) .. thing is, Id still expect the new function to always take two values.. but perhaps haskell is smart enough to drop an argument because it isnt being used
06:30:51 <tty1> JappleAck: yup
06:31:17 <JappleAck> > (\a b -> a <> "|" <> b) <*> (<> "bar") $ "foo"
06:31:19 <lambdabot>  "foo|foobar"
06:31:41 <tty1> JappleAck: im still learning the language, the <> operator is one I havent worked with yet
06:31:52 <JappleAck> `a' is `"foo"' and `b' is `(<> "bar") "foo"'
06:32:09 <JappleAck> tty1: you can replace it with (++) here
06:32:22 <JappleAck> > (\a b -> a ++ "|" ++ b) <*> (++ "bar") $ "foo" 
06:32:22 <tty1> ok
06:32:24 <lambdabot>  "foo|foobar"
06:32:32 <turion> I want to "script" a GHCi session. I have a few commands that I'd like to pass to GHCi and I want, ideally in a text file, how it would look like if I had entered each line manually. I know I can have a .ghci file, but that simply executes the commands and doesn't show how they would be "entered".
06:33:03 <turion> If I put "print 3" in .ghci and then start ghci, it does this:
06:33:03 <turion> $ ghci
06:33:03 <turion> GHCi, version 8.6.4: http://www.haskell.org/ghc/  :? for help
06:33:03 <turion> 3
06:33:03 <turion> Loaded GHCi configuration from /home/turion/haskell/.ghci
06:33:04 <turion> Prelude>
06:33:21 <turion> I want it to do:
06:33:21 <turion> > print 3
06:33:21 <turion> 3
06:33:23 <lambdabot>  <IO ()>
06:35:04 <JappleAck> tty1: so, let's consider `f <*> (+)', by applying `f <*> (+) $ 1` `f' here gets two arguments, first is original `1' value, and second is `(+) 1' so it's `(+1)'
06:35:24 <JappleAck> first argument is original value, second is partially applied (+) function
06:35:33 <JappleAck> that takes another one argument
06:36:44 <JappleAck> `f <*> (+)` in general takes at least one argument, but if you return partially applied function as a result from `f' which takes one arguments at the end you have function that takes two arguments
06:38:04 <JappleAck> all functions are curried, so function that takes 2 arguments just mean: function that takes one argument that return another function that takes another one argument and then returns a value
06:38:40 <tty1> jamm: haskell is still a mind fuck to me so im taking time trying to process what your saying and writing it out on paper and workign through it. but thanks.. just will take me a minute to absorb all this
06:38:49 <JappleAck> and that value also could be an another function (there's no difference between values and functions, values are just functions that takes *no* arguments)
06:39:58 <JappleAck> tty1: it's just currying, you're understand currying, right? so `foo a b = a + b` is equivalent to `foo = \a -> \b -> a + b`
06:40:48 <tty1> JappleAck: I understand currying but dont have the deeper intuition for it. I still view currying as just a partial application of a functions parameters
06:41:43 <JappleAck> tty1: the key to understand is to get that functions are values too
06:41:46 <tty1> JappleAck: but that example you just gave I think helps in understanding currying a little better (I knew it was some sort of function composition)
06:42:00 <JappleAck> > map (+1) [1..10]
06:42:02 <lambdabot>  [2,3,4,5,6,7,8,9,10,11]
06:42:07 <JappleAck> > map (+) [1..10]
06:42:10 <lambdabot>  [<Integer -> Integer>,<Integer -> Integer>,<Integer -> Integer>,<Integer -> ...
06:42:42 <JappleAck> > map (\f -> f 5) $ map (+) [1..0]
06:42:44 <lambdabot>  []
06:43:06 <JappleAck> hmm...
06:43:09 <JappleAck> ah
06:43:17 <JappleAck> typo
06:43:18 <JappleAck> > map (\f -> f 5) $ map (+) [1..10]
06:43:20 <lambdabot>  [6,7,8,9,10,11,12,13,14,15]
06:43:20 <tty1> yea im fairly comfortable passing around functions in general. But keep in mind haskell is my first functional language so intuitively i just think as functions as a sort of pointer to the function when used as values (which probably isnt the best way to think of them in haskell)
06:45:00 <tty1> alot of my challenges are just changing my mindset with haskell
06:45:06 <JappleAck> tty1: when you're trying to understand haskell, don't think about code from machine's perspective, but think about it abstractly, haskell is very abstract of what machine is actually doing, no need to mess with "pointers" stuff in your model of understanding
06:45:28 <JappleAck> sooner of later you'll get it
06:46:20 <tty1> JappleAck: well I already wrote some working Markov chain code.. it probably isnt the best haskell code, but it works. So I'm starting to get the hang of some of the more basic ideas at least.
06:46:58 <tty1> JappleAck: here is the code I wrote if your curious as to what level I'm at so far: https://anaconda.org/freemo/markov-chain/notebook
06:47:37 <turion> Can I somehow use GHCi from _within_ Haskell source code? Something like runInGHCi :: String -> IO String?
06:47:49 <tty1> JappleAck: I havent even gotten to the part where they explain to me what a Monad is in the book yet :)
06:50:12 <[exa]> turion: you mean 'eval' ? :]
06:50:32 <[exa]> turion: anyway, ghci repl should be somehow available as a library; look at ghci source
06:51:52 <JappleAck> tty1: monad-shmonad is just a mathematical model, you don't have to know category theory to get how to deal with them, you certainly musn't mystificate them too
06:53:18 <JappleAck> tty1: first - you need to understand what the typeclasses are in haskell, and they're just a way to write functions which are work with different set of types (as opposite to functions which are working with single type)
06:53:51 <turion> [exa]: I mean a little less than eval. There is the plugins package that achieves that kind of thing by using Typeable. That's great, but I really just want the side effects. When I type 3 in ghci then I don't care to bring this value into scope and try to type it. I just want the side effect of printing 3.
06:53:53 <JappleAck> tty1: and a Monad or any other type-class such as Functor, Applicative and stuff is just an interface to work with some kind of functions/values
06:53:56 <tty1> JappleAck: yea I've used class and instance to define typeclasses in a few examples so far. 
06:54:36 <JappleAck> tty1: Monad is just an interface for composition of functions which return some wrapper as a result
06:55:01 <tty1> Yea in fact the way I was able to understand the earlier problem with functions as Applicators was to stop thinking about an Applicative as a general idea and just look at how it was defined for functions. Then it made a lot of sense since it wasnt some "special new thing"
06:55:44 <turion> [exa]: I guess I could look at the source, but that takes quite some time, for a comparably simple goal
06:56:17 <JappleAck> > Just 10 >>= \y -> Just (y + 10)
06:56:19 <lambdabot>  Just 20
06:57:05 <tty1> >>= is another new operator for me i didnt get to yet int he book
06:57:13 <turion> I need this for the following: I'm writing an article and I want to show the results of an interactive GHCi session. While the implementation of the library changes, I want to be able to update the results of the GHCi session by just running a script
06:57:30 <[exa]> turion: IO handling in ghci requires quite a large hack afaik
06:57:53 <turion> Hmm, sounds like too much effort then maybe :/ but thanks for the hint
06:58:00 <JappleAck> tty1: main function of a Monad is (>>=), it gets wrapped value, unwraps it and passes to second argument (of >>=), passes unwrapped value, and second function of (>>=) which gets unwrapped value is supposed to return another wrapped value.
06:58:13 <turion> I'm surprised this doesn't exist somewhere, maybe with Haskeline or so
06:58:23 <[exa]> turion: so you have some kind of markup which includes haskell source that gets auto-evaluated for the article?
06:58:28 <JappleAck> tty1: don't think about operators as "operators", they're just infix functions)
06:58:28 <[exa]> (into the article text)
06:58:53 <JappleAck> > return 5 :: Maybe Int
06:58:55 <lambdabot>  Just 5
06:59:02 <tty1> JappleAck: sounds a bit similar to an Applicative and Functor already... im still focusing on my earlier problem though trying to solidify it in my head, so your getting a bit ahead of my mental queue too :)
07:00:04 <JappleAck> tty1: good observation, because any Monad must be an Applicative too, and any Applicative must be a Functor)
07:01:00 <[exa]> tty1: suggest printing types of fmap, (<*>) and (flip (>>=)) and aligning them on 3 separate lines; IMHO it provides nice insight into the differences
07:01:01 <turion> [exa]: I  run some executables with stack and pipe their output in a text file. Then I include the text file in the article source.
07:01:51 <JappleAck> tty1: just keep in mind that any IO side-effects magic doesn't happen because it is a Monad, it's not happening even inside your haskell code, all the side-effects happens in GHC runtime while interpreting your IO monads composition
07:02:07 <[exa]> turion: just a wild guess-- isn't that the same thing that lambdabot does?
07:02:16 <JappleAck> well, just IO, because it's not only a Monad, it's a Functor and Applicative too)
07:02:21 <[exa]> turion: lambdabot source is certainly shorter than of ghci :]
07:02:42 <turion> [exa]: Hmmmmm yes... I could write an IRC bot that spams lambdabot every time I recompile my article :D
07:03:10 <turion> That's an exellent hi
07:03:12 <turion> hint
07:03:14 <turion> Except:
07:03:19 <turion> > print 23
07:03:21 <lambdabot>  <IO ()>
07:03:40 <turion> Aww come on lambdabot, that wasn't dangerous IO! Don't be so afraid of effects!
07:04:03 <tty1> JappleAck: That last statement sounds important to understand IO, but not sure i fully understand it yet
07:04:04 <JappleAck> tty1: all the mystification about Monad is happening because people associate side-effects in "real world" with Monads, but the real source of side-effects is in GHC runtime, Monad is just an interface for composition
07:04:56 <[exa]> turion: I meant tearing the source code from lambdabot source
07:05:01 <JappleAck> tty1: think about IO as about Maybe, but keeping in mind that if you put that IO as `main' function definition of your program GHC runtime will interpret that IOs as a guide what to do
07:05:05 <turion> Yes, I'm on it, that's a great idea
07:06:31 <JappleAck> tty1: and the Monad interface allows you easily compose one IO with another, like this `getLine >>= \x -> print x'
07:06:47 <[exa]> turion: aww it uses mueval
07:06:55 <tty1> JappleAck: yea i get that part, and how i have to isolatte IO and pull stuff out of it and all that.. But the way you worded it seemed to say something special. too many words i dont understand is all. I'll get there
07:07:08 <turion> [exa]: It seems like lambdabot actually pastes the line into a file and calls an external process to compile and evaluate
07:07:18 <[exa]> turion: btw can't you just 'fake' the IO for the affected functions with, say, writer?
07:07:22 <JappleAck> tty1: i just composed `getLine' IO with `print' one, nothing happening inside this code, until GHC runtime will get it as a `main' function definition
07:07:37 <turion> Ah yes exactly :)
07:07:39 <turion> https://hackage.haskell.org/package/mueval
07:07:48 <[exa]> turion: anyway unixy approach is a good approach :D
07:08:22 <tty1> JappleAck: oh right, the IO doesnt get executed until you pull the contents out of it (something that happens automatically if its in main and will cascade through the do blocks)
07:08:26 <tty1> or at least thats how i see it
07:08:58 <JappleAck> tty1: you just said you haven't time understanding Monads yet and don't know what (>>=) operator is, and i'm just telling you there's nothing very special or magical in Monads, it's actually very simple
07:09:33 <tty1> JappleAck:  ahh yea :) makes sense
07:09:38 <tty1> I appreciate the explanation
07:10:10 <JappleAck> tty1: just to warn you of mystification you may dive into and many do while trying to understand monads
07:10:30 <JappleAck> as many do*
07:12:33 <matsurago> IMHO the correct way to understand monads is to understand Functor first
07:12:56 <JappleAck> as myself too actually) i too was thinking that there's some magic inside IO i don't understand yet, but the truth is that magic is outside IO, in GHC runtime
07:13:55 <[exa]> JappleAck: do you mean the magical emptiness of RealWorld? :]
07:14:14 <JappleAck> sort of)
07:15:04 <turion> tty1: First, learn sufficient examples for monads before you try to learn monads in depth abstractly. Learn Maybe, List, Either, State, Reader, Writer. Second, for starters you just need to know: Functors can encode side effects, Applicatives can encode _composable_ side effects, Monads can encode _composable_ side effects where the results of earlier effects influence the execution of later effects.
07:15:05 <JappleAck> writing your own type and interpreter for side-effects helps with that too very much
07:16:20 <turion> Yep, I don't understand why we don't encode IO like in https://hackage.haskell.org/package/pure-io-0.2.0/docs/PureIO.html
07:17:41 <turion> Ah well, I guess I'm just going to run the GHCi commands manually every time...
07:17:59 <[exa]> turion: theoretically, you can clone PureIO values without any problems and do forkIO without actually forking
07:18:15 <[exa]> turion: which is kindof dangerous before having linearity
07:18:24 <[exa]> also, performance
07:20:46 <tty1> turion: if those things are monads then many of them I've been using fairly successfully.. some are new to me.
07:21:52 <turion> [exa] what do you mean by forkIO without actually forking? poor mans conc?
07:22:13 <turion> tty1: Great, which ones do you already know?
07:22:43 <turion> Or rather, which ones don't you know yet?
07:23:32 <tty1> turion: I've worked in detail with Maybe, List, and Either so far. I'm basically on the section about Applicatives in "learn you a haskell". But they were good enough to include many examples leading up to the deep dives.
07:24:06 <tty1> turion: the book covered IO as well
07:25:17 <turion> tty1: Then implement the Fibonnacci function in the State monad
07:25:45 <tty1> turion: dont know what the "State monad" is yet.
07:25:52 <[exa]> turion: you can basically take the whole pureio's IO with 'inputStdin' and copy it (thus duplicating the input, and possibly running 2 different programs on that), and there's nothing to prevent you from doing that... which is okay if you are only talking about files' contents, but starts to become problematic with real user input, networking, etc
07:28:07 <[exa]> turion: while theoretically right, that thing is an engineering disaster, like unsafePerformIO anywhere.
07:28:47 <turion> [exa]: Hmmm ok, apparently I didn't study it enough :/
07:28:52 <turion> tty1: http://hackage.haskell.org/package/transformers-0.5.6.2/docs/Control-Monad-Trans-State-Strict.html#g:3
07:29:34 <tty1> turion: Ill take a look once I've mastered this whole functions as an Applicative thing. I'm starting to get it down but still struggling with some edge cases. Want to finish this up first.
07:29:58 <[exa]> turion: the point is that ghc's realworld has some very practical compiler-provided guarantees that common library code can't match yet
07:30:07 <turion> Goal: implement the Fibonnacci function just using put, get, >>=, replicateM_ and evalState
07:30:19 <turion> tty1: No worries, didn't want to load too much onto you :)
07:30:45 <tty1> turion: I love hearing exercises within my reach. It will be the next thing I try. So thanks.
07:31:11 <turion> [exa]: Yeah, fair enough, but doesn't that mean that GHC's IO is somehow too much baked into the compiler?
07:31:53 <[exa]> to the RTS, yes. Which is quite expectable, as with any other practical language.
07:33:02 <tty1> ok I think i got all the edge cases down on this function as an applicative thing.. at least, i can work through them on paper now...
07:33:43 <[exa]> tty1: btw did you arrange the types? map/fmap/<*>/flip >>= ?
07:33:47 <tty1> JappleAck: you were right thinking of functions as values themselves helped
07:34:28 <tty1> [exa]: im not sure what your asking. I know those first three types (>>= im new to).. but not sure what you mean by "arrange the types"?
07:34:43 <[exa]> oh don't worry I'll write a pastebing
07:35:19 <tty1> ok
07:36:02 <[exa]> https://pastebin.com/bcCBaYzZ
07:37:02 <turion> [exa]: But the RTS is a bit like a virtual machine, so it ought to be implemented cleanly and separately, I thought?
07:37:09 <tty1> [exa]: im familiar with the type signatures for the first three that you listed, the last one is new to me. Still not sure what you mean by "arrange" though or what your asking
07:37:39 <turion> tty1: Just compare them and see how they differ ;)
07:38:05 <Solonarv> [exa]: btw, (flip (>>=)) is also known as =<<
07:38:09 <[exa]> tty1: just writing it on separate lines aligned like this. It nicely visually displays all major differences
07:38:24 <[exa]> Solonarv: I tried to stay supersimple
07:38:37 <Solonarv> fmap :: (a -> b) -> f a -> f b
07:38:37 <Solonarv> (<*>) :: f (a -> b) -> f a -> f b
07:38:40 <Solonarv> gah
07:38:43 <tty1> turion: well the first three make sense to me each one appears to be an "extension" of the last (Applicative is a specific type of Functor, etc). The last one is foreign to me though but I assume a Monad is an extention of an Applicative now...
07:38:53 <turion> For example, >>= allows you to plug a pure value in. <*> doesn't, it only allows you to combine values already in the Applicative
07:39:02 <tty1> [exa]: ahh i see, yes its good to see them next to eachother indeed.
07:39:04 <turion> tty1: You're right there
07:39:15 <[exa]> turion: anyway, it can be thought as a VM, but you usually need to very precisely know what VM you're generating code for, right
07:40:00 <Solonarv> fmap  ::   (a ->   b) -> f a -> f b
07:40:00 <Solonarv> (<*>) :: f (a ->   b) -> f a -> f b
07:40:00 <Solonarv> (=<<) ::   (a -> f b) -> f a -> f b
07:40:00 <Solonarv> here you go, nice and lined up (if your IRC client uses a monospace font, anyway)
07:40:16 <tty1> Monads are actually why i started learning haskell. My friend is drunk on functional programming languages and knowing I'm a math major he insisted I learn one to the point of understanding monads.. So im almost there :)
07:40:49 <turion> [exa]: True. But wouldn't you ideally declare first what kind of effects you have, very abstractly? And then you have your optimizing compiler that creates efficient VM code
07:41:11 <tty1> HE is a clojure guy though, but I decided on haskell because i liked the look of it better and it felt more like pure procedural which i like.
07:41:30 <tty1> Solonarv: showed great here thanks :)
07:41:51 <Solonarv> hopefully that helps see how they all do a similar thing 
07:42:01 <turion> I mean, I don't expect that you can write down IO as, say a free monad over a very simple algebraic type. I'd expect it to be very long and riddled with all sorts of RTS quirks. But just saying "Here's this totally misterious RealWorld thing" is less than I would expect
07:42:07 <tty1> I've been programming for more than 2 decades so procedural coding, being so new, and with so many habbits established, makes me dizzy... but thats why I want to learn it :)
07:42:21 <[exa]> turion: but the haskell VM doesn't know about the side effects
07:42:37 <Solonarv> turion: sure, you could do that; and in fact Hugs (another Haskell implementation) defines IO that way, IIRC
07:42:52 <turion> [exa]: Hmmm then I don't understand it that well, it seems
07:42:59 <[exa]> hugs has real IO ops in VM? wow
07:43:12 <Solonarv> no, hugs uses the "free monad" approach for its IO
07:43:18 <[exa]> oh wow
07:43:26 <Solonarv> at least I've heard it does
07:43:26 <[exa]> okay, good to know
07:43:44 <tty1> by the way before i head back to my book to read up on Monads let me just say, despite the difficulty wrapping my head around this new paradigm I'm having a lot of fun. There is a beauty to haskell I'm enjoying.
07:43:50 <turion> Solonarv: Oh, that's great! Is hugs actually still somehow active? Can it do roughly what GHC can in terms of IO? I mean I don't expect that great concurrency
07:44:00 <[exa]> tty1: anyway this is my second favorite example which kindof composes everything together: https://pastebin.com/gAN4J1Jt
07:44:12 <Solonarv> frankly I have no idea, it seems to not be maintained/used as much as it used to be
07:45:16 <turion> I only know hugs from old articles that sometimes comment "This works on hugs but not on GHC", or the other way around
07:45:25 <[exa]> ghc is too great now, other compilers have mostly educational use
07:45:38 <Solonarv> basically, yeah
07:46:01 <tty1> [exa]: yea ive seen similar examples like that int he book already. Those were fairly easy for me to understand (though im not entierly clear about some IO specifics still). The only point things get me a bit dizzy is once I start treating functions as applicative. Most other types are straight forward enough.
07:46:02 <Solonarv> GHC has so many features beyond the standard it's hard to match it, and those features are actually used widely
07:46:48 <[exa]> turion: anyway, the thing disappears somewhere around compilation to STG -- passing of RealWorld is replaced by strict evaluation of functions; actual IO operations are present as low-level calls directly in the haskell source. Not sure where exactly they are implemented though, but my best guess is that most of them are in library and call some RTS primitives
07:47:06 <tty1> I wish ghc support was a little nicer on OSX though... I cant use the latest resolver, luckily I dont know enough for it to matter much :)
07:47:10 <[exa]> or maybe it's after STG now that I'm looking at it
07:47:40 <tty1> I spent a day trying to get it to work on OSX before finally just using the one resolver that didnt need compiling
07:47:46 <Solonarv> STG is the last stage that still looks sort of like a lambda calculus
07:47:55 <tty1> anyway, i should head back to my haskell book, thanks for all the help im sure you guys will see me again soon 
07:48:20 <__monty__> tty1: If you want the newest packages you could always just drop stack. Cabal new-* works fine on osx.
07:48:34 <[exa]> tty1: it takes a bit of practice to get intuition on that; really suggest writing a parser in Parsec
07:48:38 <turion> [exa]: I see... well I should dive into GHC at some point
07:48:57 <[exa]> aaaand that is one deep dive.
07:49:10 <tty1> [exa]: im not familiar with whatever "Parsec" is, aside from an astronomical unit of measure
07:49:16 <turion> Solonarv: Yeah, anything real world would use GHC
07:49:24 <Solonarv> tty1: it's a parser combinator library
07:49:46 <Solonarv> it spawned a whole zoo of similar libraries with names like megaparsec, attoparsec, and so one
07:50:10 <tty1> Solonarv: ahh
07:50:22 <Solonarv> parsec itself is a bit dated, I'd actually recommend megaparsec instead - but the documentation / learning materials might not exist to the same extent, I'm not sure
07:50:43 <[exa]> tty1: I liked this tutorial btw http://jakewheat.github.io/intro_to_parsing/
07:51:09 <tty1> Solonarv: i doubt it has any use for me at the moment. I dont have much need to write a parser in haskell just yet... not unless I decide to start moving over some of my libraries from other languages tohaskell, in which case I would have some parsers to rewrite
07:51:51 <[exa]> tty1: btw have you used bison/flex or boost::spirit?
07:56:45 <tty1> [exa]: I havent written any haskell programs yet, just working through an intro book. I just wrote that markov chain thing really quickly as I was learning just for shits and giggles. 99% of haskell that I did was inside a juypter sheet
07:58:11 <[exa]> tty1: oh so :] anyway you might want to see monadic parsing later, it's certainly one of the greatest things haskell has for beginners
08:00:24 <tty1> [exa]: ill keep it in mind once I learn about monads
08:00:34 <tty1> [exa]: which im about to do right now
08:36:15 <fweht> i know that there are functional programming languages where you have to prove totality of every function, i just wonder, are there also any concepts where you have to prove that all functions under the given type must be equal (by extensionality)?
08:42:56 <roconnor_> as in all functions of a given type are extensionally equal to each other?
08:43:56 <turion> fweht: The opposite, you'd want this statement to be automatically true, right?
08:56:12 <fweht> roconnor_: yes!
08:56:48 <fweht> turion: i never thought about that, is it possible?
09:34:59 <bzm3r> hi all, i am reading through the following paper (https://www.cs.ox.ac.uk/ralf.hinze/Lifting.pdf), but am only somewhat familiar with haskell notation --- would this be an okay place to ask questions? (i am more interested in the mathematics than the programming)
09:35:58 <__monty__> bzm3r: Sure, depends on the volume obviously.
09:36:53 <bzm3r> __monty__: ah, there might be quite a few -_-
09:37:32 <MarcelineVQ> I wonder why they choose to say container types insted of structures again
09:38:09 <bzm3r> MarcelineVQ: this is in reference to?
09:39:08 <__monty__> bzm3r: Just go ahead, if it's too much someone'll complain : )
09:39:25 <MarcelineVQ> the second introduction sentence of the paper you linked :>
09:40:15 <bzm3r> MarcelineVQ: i have no clue, but i'll put down a note beside it to say "aka structures"
09:40:28 <bzm3r> i've got a haskell book open in front of me, will look up structures
09:40:42 <__monty__> Haskell doesn't have structs though.
09:41:08 <MarcelineVQ> I just wonder if there's an important difference in the authors mind, there's not one in mine but I don't know a lot
09:43:02 <MarcelineVQ> __monty__: structs like in C? that's not the subject :X
09:43:47 <__monty__> Not sure what you're referring to with "structures" then. I was just pointing out to bzm3r that that's not a haskell concept.
09:44:27 <MarcelineVQ> That's first sentence in the intro section of the paper
09:45:54 <__monty__> Yeah, container types is the box interpretation of functors and the like?
09:49:08 <MarcelineVQ> bzm3r: there's a strongly related paper here if you've not seen http://strictlypositive.org/Idiom.pdf
09:49:25 <MarcelineVQ> I don't know the maths side super well but feel free to ask questions, my own question wasn't a prompt for you but just an idle wondering
09:49:53 <bzm3r> MarcelineVQ: your questions have been helpful in helping me immerse myself in the terminology :)
09:50:02 <bzm3r> i hadn't seen that paper! i'll go through it
09:50:39 <MarcelineVQ> It's also heavy on the haskell but the latet half is more of the math iirc
09:50:51 <bzm3r> currently, i'm trying to figure out where i (a -> b) -> i (a -> b) notation would come from
09:51:06 <MarcelineVQ> oh, not really half ehe
09:53:08 <MarcelineVQ> do you mean i (a -> b) -> (ia -> i b) ? ( ) in types signatures is right associative so that can be read as i (a -> b) -> i a -> i b if that's helpful at all
09:58:49 <bzm3r> MarcelineVQ right, that's what i was referring to
09:58:59 <bzm3r> but what does it mean to just have i a
09:59:12 <bzm3r> (i.e. no arrow between the two symbols)?
09:59:37 <MarcelineVQ> It's some type i applied to some type a. In some concrete case like i = Maybe and a = Int, that's Maybe Int
10:00:05 <MarcelineVQ> And I just used my some quote for the day
10:00:11 <MarcelineVQ> quota :>
10:00:39 <bzm3r> if i've got a haskell text open, what would be the keywords too look it up? "type application?
10:00:50 <__monty__> type constructor
10:00:53 <bzm3r> ty
10:01:00 <__monty__> As opposed to data constructor.
10:07:50 <bzm3r> __monty__ hmm, but type construction just refers to the general notation specifying the "type" of data? in that sense, i understand (a, b) -> a, or a -> (a, b), or a -> a -> a
10:07:59 <bzm3r> but i do not understand a (b -> c)
10:08:25 <bzm3r> is that like "a is a function, which will be applied to another function, of the type b -> c"
10:10:03 <geekosaur> a would be a type function, not a value function. something like [] or Maybe
10:10:26 <bzm3r> type function, ok, let me look that term up
10:10:54 <MarcelineVQ> mmm type function probably won't be a helpful search term in this case
10:11:00 <geekosaur> one value shaped like (a (b -> c)) would be: Just ord
10:11:09 <cocreature> “type constructor” might be a better name
10:11:23 <dmwit> bzm3r: Would you understand if I wrote `a -> b` as `(->) a b`?
10:11:38 <bzm3r> yup
10:11:38 <dmwit> Like, I really mean the same thing by both of those, I'm just using a slightly different spelling of the same concept.
10:11:50 <bzm3r> prefix vs. infix, sure
10:11:57 <dmwit> bzm3r: Okay. And like, instead of `a -> a -> a`, I'm going to write `(->) a ((->) a a)`. Still good?
10:12:09 <bzm3r> still good
10:12:13 <dmwit> Cool.
10:12:51 <dmwit> Okay, so now let's treat `(->) a` as a block.
10:13:02 <dmwit> It's a sort of partially-applied version of `(->)`.
10:13:05 <bzm3r> right
10:13:08 <dmwit> So we can still apply it to something else.
10:13:24 <bzm3r> and we can give it a name, let's say "x"
10:13:25 <dmwit> We could even, if Haskell supported it, do something like `let f = (->) a in f b`.
10:13:32 <dmwit> As a really weird way of writing `a -> b`.
10:14:01 <dmwit> Or, if we wanted, we could `let f = (->) a in f ((->) b c)` for `a -> b -> c`.
10:14:54 <bzm3r> right
10:14:57 <dmwit> And there's other types we could put in the `let`, too, that would still make sense.
10:15:05 <dmwit> Like `let f = Maybe in f ((->) b c)`.
10:15:06 <dmwit> Or others.
10:15:25 <bzm3r> thank you very much, that makes sense
10:15:31 <dmwit> So in Haskell proper, we can't actually write `let`. But we *can* have type variables that range over things like `(->) a` and `Maybe` and the like.
10:15:34 <dmwit> And that's what's going on here.
10:15:49 <bzm3r> got it
10:27:46 <ggole> Hmm, can you use ~ for that?
10:28:14 <bzm3r> so, why does this not compile? (just trying to create an Idiom class) https://repl.it/repls/GummySturdyPrinter
10:28:32 <bzm3r> it says that diamond isn't in scope?
10:29:02 <bzm3r> wait sorry, it should be: https://repl.it/repls/GummySturdyPrinter
10:29:06 <bzm3r> (but that still doesn't compile)
10:29:58 <geekosaur> for starters, diamond is prefix, not infix. if you want to use it as infix, it has to be phrased: infixl 6 `diamond`
10:30:52 <bzm3r> why is diamond prefix for starters? i defined it to be infixl, no?
10:31:27 <geekosaur> basic syntax. symbols are infix, words are prefix
10:31:37 <geekosaur> you can't change this with declarations, it's baked in
10:31:46 <bzm3r> i see
10:31:57 <ggole> > id :: f ~ (->) Int => f Int
10:31:59 <lambdabot>  <Int -> Int>
10:32:42 <ggole> Ugly, but it does seem to give (nonrecursive) let
10:32:43 <geekosaur> but `` around a prefix word lets you use it as infix, and () around an infix symbol lets you use it as prefix
10:33:45 <bzm3r> is it actually possible to use a diamond symbol in haskell, like ♦
10:34:18 <geekosaur> > let x ♦ y = x + y in 1 ♦ 2
10:34:20 <lambdabot>  3
10:34:36 <bzm3r> very cool
10:35:26 <geekosaur> there are some limitations: since it relies on unicode properties, characters that don't have symbol (or letter) properties don't work well (hence nothing in a private use area is usable)
10:35:54 <bzm3r> i see isee
10:36:02 <bzm3r> so why does *this* not compile? https://repl.it/repls/GummySturdyPrinter
10:36:06 <geekosaur> also, haskell uses initial letter case to distinguish constructors from bindings. but symbols don't have case, so initial : marks a constructor
10:36:29 <geekosaur> you only changed the one
10:36:39 <bzm3r> i'm an idiot
10:36:41 <geekosaur> it has no idea that the ♦ in the infixl refers to the diamond
10:37:06 <bzm3r> even after that change though: main.hs:8:3: error: parse error on input ‘♦’
10:37:08 <geekosaur> and if you change the second one you'll need parens around it
10:37:10 <bzm3r> https://repl.it/repls/GummySturdyPrinter
10:37:27 <bzm3r> ahhh
10:38:06 <bzm3r> oh boy, so the notation in https://www.cs.ox.ac.uk/ralf.hinze/Lifting.pdf is really not proper haskell...
10:38:39 <bzm3r> oh no, wait it is
10:38:43 <bzm3r> i'm the one who is not paying attention
10:38:45 <bzm3r> phew
10:39:04 <c_wraith> it needs the UnicodeSyntax extension to use unicode arrows
10:39:14 <c_wraith> I really dislike papers that do that.
10:39:35 <c_wraith> Sticking with ascii doesn't diminish the quality of your research!
10:39:41 <bzm3r> agreed
10:40:03 <bzm3r> i think its because mathematicians are generally scared to use ascii words for variables/operators, etc.
10:40:57 <bzm3r> and their intended audience is mathematicians?
10:41:15 <__monty__> I think it's more because variable width makes ASCII symbols look terrible.
10:41:31 <__monty__> Maybe they're not even using listings.
10:41:33 <bzm3r> oh that too
10:41:44 <c_wraith> Then use fixed width, too.  SPJ does it.  Everyone cane.
10:41:56 <c_wraith> *can.  Also, SPJ is the only person who makes comic sans look good.
10:42:29 <__monty__> I agree you should either go full lhs and include all the extension pragmas or do proper code listings with a fixed width font and ascii.
10:44:12 <bzm3r> hmm, now i am getting compiler errors, when i include the second definition of black star: https://repl.it/repls/GummySturdyPrinter
10:45:51 <c_wraith> those errors are mostly "you said this thing would exist, but never defined it)
10:46:01 <c_wraith> Wow, my punctuation is awful today.
10:46:04 <bzm3r> but didn't i? 
10:46:14 <bzm3r> don't i have `(★) :: i a -> i b -> i (a, b)`
10:46:14 <geekosaur> no, you provided type signatures
10:46:25 <bzm3r> i see
10:46:26 <geekosaur> in a class definition, you don't need the implementations because instances provide those
10:46:35 <geekosaur> at top level, you need the implementation
10:46:45 <bzm3r> right
10:47:08 <bzm3r> ok, let me search for the appropriate implementation then
10:47:48 <bzm3r> Hutton 1992: "Higher-order functions for parsing"
10:48:26 <c_wraith> :t \x y -> pure (,) <*> x <*> y
10:48:27 <lambdabot> Applicative f => f a1 -> f a2 -> f (a1, a2)
10:48:35 <c_wraith> there's a hint for you. :)
10:49:42 <bzm3r> how much of the initial :t \x y ... should i ignore as input to the bot?
10:50:12 <c_wraith> It's not input to the bot.  I just didn't feel like naming a function
10:50:54 <c_wraith> Hmm, your types for map, unit, and (★) will all need fixes, too.  Don't worry about that, yet, just don't be surprised when the compiler complains.
10:51:18 <bzm3r> sounds good, will keep in mind
10:51:30 <bzm3r> (currently just reading up on applicatives)
11:00:25 <bzm3r> c_wraith: can i ask for clarification in what you typed: `:t \x y -> pure (,) <*> x <*> y`
11:00:41 <bzm3r> still not sure i am able to parse it
11:01:31 <c_wraith> It's a lambda - a function defined without a name
11:01:59 <bzm3r> that part i am okay with, it takes two inputs, x y
11:02:09 <c_wraith> yes
11:02:14 <bzm3r> the part that is getting to me, is <*>
11:02:23 <c_wraith> :t (<*>)
11:02:24 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
11:02:45 <bzm3r> :t pure
11:02:47 <lambdabot> Applicative f => a -> f a
11:03:05 <c_wraith> Applicative is the standard library equivalent of Idiom in that paper
11:03:10 <c_wraith> pure is the same thing
11:03:21 <c_wraith> (<*>) is the equivalent of the diamond operator in that paper
11:04:48 <c_wraith> that expression is parsed as (((pure (,)) <*> x) <*> y), if that's also a stumbling block
11:05:13 <bzm3r> no, i think the main stumbling block is the introduction of standard library stuff
11:05:27 <bzm3r> i.e. i am just translating back to the symbols i introduced
11:05:43 <bzm3r> (fyi, yesterday is the first time i started looking at haskell, and i really don't want to program in it, just want to understand this paper)
11:05:57 <bzm3r> (so i don't know any of the standard library stuff, etc.)
11:06:09 <bzm3r> (managing scope carefully because of time limitations)
11:07:03 <merijn> bzm3r: I recently saw a bunch of stuff on "reading haskell for advanced (as in, non-haskell) programmers/engineers" lemme see if I can find it
11:07:36 <bzm3r> merijn: thanks, that sounds helpful!
11:07:43 <merijn> bzm3r: http://www.joachim-breitner.de/blog/750-Teaching_to_read_Haskell
11:08:23 <merijn> bzm3r: The explicit goal was "how to teach people how to *read* haskell, rather than how to program it" (in this case for security auditing, but similar things apply to reading papers, I suppose!)
11:08:39 <bzm3r> nice: http://haskell-for-readers.nomeata.de/
11:09:36 <james4> \quit
11:59:31 <hopsing> I'm trying to understand a haskell function and got stuck: http://hackage.haskell.org/package/chalmers-lava2000-1.6.1/docs/src/Lava-Vhdl.html#writeVhdl : Can someone tell me what (var "inp") resolves to in function wirteVhdl ?
12:00:37 <hopsing> Lava module http://hackage.haskell.org/package/chalmers-lava2000-1.6.1
12:01:30 <hopsing> Where can I ask for help with this kind of questions?
12:01:35 <hopsing> Any tip?
12:02:04 <dmj`> hopsing: I'd darcs get that repo
12:02:32 <dmj`> nix-shell -p haskellPackages.darcs --run 'darcs get http://projects.haskell.org/chalmers-lava2000/' && ag 'var ::' chalmers*
12:02:42 <dmj`> and grep it
12:04:06 <dmj`> project builds for me on 8.6.4
12:04:28 <hopsing> djm: It not a simple function. There is some metaprogramming involved. ag will point you to class Constructive : http://hackage.haskell.org/package/chalmers-lava2000-1.6.1/docs/src/Lava-Generic.html#line-253
12:04:49 <dmj`> yea, seems like var :: String -> a is a typeclass method
12:05:16 <hopsing> It seems like `var` is becoming a constructor of some sort. But I cannot ficure out how this is done....
12:10:10 <dmj`> hopsing: it's either an Int, Bool, (), or a Signal of these things, or up to a 7 tuple of combinations of these things
12:10:51 <dmj`> Oh whoops, it's not an Int or Bool, that's only for ConstructiveSig
12:11:03 <dmj`> nor Signal
12:13:46 <dmj`> hopsing: it can only become one of these, http://hackage.haskell.org/package/chalmers-lava2000-1.6.1/docs/Lava-Generic.html#t:Constructive
12:14:21 <dmj`> tuples of unit, or Signal
12:14:58 <hopsing> djm`: if the input arg circ to writeVhdl is a untyped function "halfAdd (a, b) = (sum, arry)", then I can see that at some point instance (a,b)'s  'var s      = (var (s ++ "_1"), var (s ++ "_2"))' is called.
12:15:33 <hopsing> I dont understand how this function is selected.
12:15:55 <hopsing> I dont call 'var' in (a,b) ...
12:16:12 <hopsing> There seem to be some type system magic going on.
12:18:33 <dmj`> ghc seems to infer that type as "halfAdd :: (Signal Bool, Signal Bool) -> (Signal Bool, Signal Bool)" for me
12:18:37 <dmj`> which will be the most generic
12:19:42 <hopsing> How is this inference done?
12:21:57 <dmj`> in this case, if I follow the function down, halfAdd -> sum -> xor2 -> xorl ->  liftl -> Signal
12:22:19 <dmj`> It seems halfAdd is always specialized to Signal
12:24:09 <dmj`> hopsing: inside of typeclass instances, its common to call to call other typeclass methods or the same method (of the same typeclass) that will use other instances to populate an object. `var` is called in this way in the tuple Constructive instances
12:27:19 <dmj`> something like this: instance Example a => Example b => Example (a,b) where ex (a,b) = (ex a, ex b)
12:27:20 <hopsing> dmj`: it is different that anything I have read so far adount typeclasses. I still cannot connect the dots...
12:28:01 <dmj`> hopsing: the recursion is implicit in the typeclass instance hierarchy 
12:32:56 <hopsing> dmj`: The 'var' function of (a,b) is selected because of the circ signature. Then the signature of a and b select the next 'var'. Because halfAdd specializes to Signal 'Constructive (Signal a)' 's var is taken.  
12:33:48 <dmj`> hopsing: here's a contrived example showing how typeclass instances can resolved recursively to construct an object, https://gist.github.com/36a394ff36e382b8f9da53ec1687acb2
12:34:21 <dmj`> var is doing something with that extra string though
12:34:38 * dmj` looks at circ signature
12:37:10 <hopsing> dmj`: Impressive. I have to digest it.
12:38:59 <dmj`> hopsing: this is also the core technique that is used in GHC.Generics as well, to traverse the meta data of a Haskell record that has derived Generic
12:39:26 <zincy> Is there any way of seeing the derivation of typeclasses?
12:39:27 <hopsing> dmj`: You use some TypeApplications @(Int,Int). How is this implicitly done in vhdlWrite?
12:39:54 <zincy> By that I mean the resulting instance code
12:40:00 <dmj`> zincy: traceShow always worked for me :) 
12:40:23 <dmj`> hopsing: trying that out right now, stay tuned
12:41:41 <dmj`> Lava has their own Generic class which conflicts with GHC.Generics
12:41:43 <zincy> dmj`; thanks
12:42:02 <zincy> How do you traceShow on source code?
12:42:24 <zincy> As in what do you traceShow to see the instance code?
12:42:32 <dmj`> zincy: this is also core to how servant works as well. servant and GHC.Generics are actually the same thing in spirit
12:43:16 <dmj`> zincy: so an extremely powerful technique is to use a closed type family which lets you explicitly recurse over a type like this
12:43:41 <geekosaur> zincy, do you want -ddump-deriv?
12:43:44 <dmj`> I've done this before to accumulate up all the field names in a record into a [Symbol], from here you can make a typeclass that converts [Symbol] -> [String]
12:44:34 <dmj`> class ReifySymbols (xs :: [Symbol]) where reifySymbols :: Proxy xs -> [String]
12:45:16 <dmj`> instance (ReifySymbols xs, KnownSymbol x) => ReifySymbols (x ': xs) where
12:45:16 <dmj`>   reifySymbols = symbolVal (Proxy @ x) : reifySymbols (Proxy @ xs)
12:45:28 <dmj`> requires some type level pattern matching
12:45:47 <dmj`> zincy: but the order in which the strings are presented should be the order in which the instances were chosen by GHC
12:46:06 <dmj`> and don't forget the base case
12:46:20 <dmj`> instance ReifySymbols '[] where reifySymbols Proxy = []
12:46:48 <dmj`> otherwise GHC will be lost in the abyss of instance resolution
12:47:04 <hopsing> too complicated...
12:48:11 <dmj`> it's mild dependently typed programming
12:49:12 <hopsing> dmj`: i thought I had a glimpse but about to loose it again: Is it possible that you describe how the @(Int,Int) of your example is implicit in vhdWrite's calling of var ?
12:49:51 <hopsing> I still missing that dot. Maybe it is obviouse...
12:54:12 <dmj`> hopsing: here are some different specializations of writeVhdl https://gist.github.com/dmjio/4f991bf50d254aa7f22a519b0d6eef32
12:54:58 <dmj`> hopsing: type applications will apply the types in the order they are declared matching them with the type variables introduced by the forall (the forall being implicit in this case in writeVhdl)
12:56:37 <dmj`> there's an implicit forall a b . before the typeclass constraints are defined in writeVhdl that type applications uses
13:01:01 <hopsing> dmj`: The typedefinition itself is like a program that is first executed? (I'm a haskell beginner...) 
13:01:05 <zincy> Thanks, just saw the responses now
13:02:23 <zincy> Is the use of type families ok in production code?
13:03:12 <phadej> it depends
13:03:25 <phadej> but in general, yes
13:04:00 <merijn> zincy: Define ok
13:04:33 <hopsing> djm`: Is there s some reading you can recomment that I can get more insights in that direction?
13:04:48 <dmj`> zincy: yea, I use them heavily in prod. code w/ Generics for working with databases
13:05:15 <dmj`> correct by construction m'boi
13:05:35 <zincy> dmj`: So it doesn't lead to code which is harder to maintain?
13:05:49 <dmj`> hopsing: anything by kosmikus is the best literature out there on generics, hands donw
13:05:50 <dmj`> down
13:05:51 <zincy> Am i right in saying typefamilies need to be used with data kinds to be useful?
13:06:18 <merijn> zincy: Whether it's harder to maintain or not depends on how you use them
13:06:37 <dmj`> hopsing: https://www.andres-loeh.de/ExploringGH.pdf 
13:06:41 <zincy> merijn: That kinda answers it, there are an infinite number of ways of defining ok
13:07:03 <dmj`> zincy: not necessarily, but there's a 99% change you'll be turning on data kinds
13:07:07 <dmj`> chance*
13:07:42 <zincy> So data kinds promotes the data constructors to type constructors
13:07:52 <dmj`> zincy: and also enables type level nats / symbols
13:07:57 <dmj`> which Generics depends on
13:08:09 <zincy> what are symbols in this context?
13:08:17 <dmj`> type level strings
13:08:33 <dmj`> http://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-TypeLits.html
13:09:18 <zincy> Does data kinds turn types into kinds?
13:09:40 <dmj`> zincy: yes
13:09:43 <zincy> Then you have more expressive kinds to group types?
13:10:04 <zincy> So types of types are kinds
13:10:15 <dmj`> and types of kinds are sorts
13:10:25 <zincy> So we need kinds to group our types
13:10:26 <Solonarv> dmj`: no, they're also types
13:10:35 * dmj` falls out of chair
13:10:44 <Solonarv> kinds, types, and sorts are all collapsed into the same layer in GHC
13:10:56 <dmj`> that's with TypeInType
13:11:06 <dmj`> which isn't enabled by default afaik 
13:11:07 <Solonarv> that's always on in reality
13:11:21 <Solonarv> all the extension controls is whether you're allowed to write code using that
13:11:28 <dmj`> maybe I live in a different reality then
13:11:31 <Solonarv> % :set -XNoTypeInType
13:11:31 <yahb> Solonarv: 
13:11:36 <Solonarv> % :k Type
13:11:36 <yahb> Solonarv: Type :: *
13:11:43 <Solonarv> % :k *
13:11:43 <yahb> Solonarv: * :: *
13:11:50 <merijn> Bringing up type in type isn't really helpful for anyone just getting started
13:12:03 <merijn> Honestly, I don't think bringing up type in type is helpful for anyone in general :p
13:12:09 <merijn> Confusing nonsense...
13:12:15 <Solonarv> perhaps, but then again neither is bringing up (incorrect!) information about sorts, IMO
13:12:22 <[exa]> guys be kind to sorts
13:12:24 <geekosaur> dmj1, TypeInType became default in one of the later 8.x's
13:12:58 <dmj`> geekosaur: interesting, I just assumed that if I called :k Int and didn't see "Type" it wasn't enabled
13:13:21 <geekosaur> StarIsType is a distinct setting, and is also default as of 8.6 iirc?
13:13:37 <zincy> merijn: Are you referring to hopsing?
13:13:39 <dmj`> not on 8.6.3 :/
13:13:49 <zincy> Yeah I think we forgot to answer his question
13:13:51 <zincy> or hers
13:13:55 <geekosaur> er, inverted. StarIsType is the old behavior, default is now NoStarIsType
13:13:58 <Solonarv> the GHC manual says this about TypeInType: "In the past this extension used to enable advanced type-level programming techniques."
13:14:03 <talqu> can i map/loop over all record fields somehow?
13:14:24 <dmj`> talqu: using a closed type family over the meta data GHC Generics provides you, yes you can
13:14:26 <[exa]> talqu: if they are of the same type, there might be lenses that do that
13:14:28 <Solonarv> geekosaur: StarIsType is still the default for now
13:14:32 <zincy> hopsing: haskell from first principles or learn you a haskell are good resources
13:14:47 <geekosaur> oh, guess they put it off
13:15:02 <Solonarv> the switch was only added in 8.6.1
13:15:07 <dmj`> Solonarv: thanks for correcting me, I know I should really stop leading people astray out here
13:15:10 <Solonarv> things don't move that fast
13:15:43 <hopsing> zincy: Thanks, Im reading the learn your haskell book right now.
13:16:09 <dmj`> hopsing: the typeclassopedia is the best resource(s)
13:16:14 <dmj`> @google typeclassopedia
13:16:15 <lambdabot> https://wiki.haskell.org/Typeclassopedia
13:16:22 <dmj`> what all the OGs learned on
13:17:02 <zincy> hopsing: Try and write little programs as soon as possible
13:17:56 <dmj`> hopsing: don't get bogged down by the type level stuff either, it's not sound anyways, despite the rhetoric around here
13:17:56 <hopsing> zincy: I'm trying it right now. Have setup the emacs enviroment and interpreter inside emacs.
13:18:33 <zincy> hopsing: Cool! I got started by asking lots of questions here. 
13:18:56 <hopsing> dmj`: It sound really interesting. I can imagine it is very powerful.But must say I dont understand much still..
13:20:15 <zincy> What are free monads for?
13:20:36 <zincy> I am thinking they may be fun to try out on my little interpreter
13:20:55 <dmj`> hopsing: most people don't but act like they do, so you're in good company
13:21:25 <dmj`> zincy: free monads allow you to divorce the definition of your computation from its evaluation
13:22:14 <dmj`> zincy: this is the best answer for that https://stackoverflow.com/a/13388966/453261 by johnw 
13:22:34 <zincy> Thanks
13:24:27 <dmj`> free monads allocate a ton though, so caveat emptor
13:27:37 <talqu> i can't write an input in lucid https://pastebin.com/6Prb00nL. What am i doing wrong?
13:30:40 <talqu> sorry, i figured it out. need to pass none-sense empty array as a second param 
13:33:24 <zincy> Is it ok to have a value type embedded in the langauge grammar to fix the issue on line 94 : https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab
13:33:32 <zincy> Sorry 91
13:34:12 <zincy> I mean changing (Let String Exp Exp) to (Let String Value Exp) feels like a horrible hack
13:34:45 <zincy> ^ Solonarv
13:35:05 <Solonarv> zincy: yeah, I wouldn't make that change to Let
13:35:22 <zincy> Thanks 
13:36:06 <[exa]> zincy: do you really want lambda in FunVal ?
13:36:15 <[exa]> (regarding line 91)
13:36:21 <Solonarv> also, I don't actually see an error on line 94, it looks fine to me
13:36:55 <Solonarv> [exa]: yes, FunVal represents a closure - which can be easily represented by a Haskell function
13:37:08 <zincy> Solonarv: Line 91 sorry
13:37:16 <zincy>       • Couldn't match expected type ‘Exp’ with actual type ‘Value’
13:37:24 <Solonarv> aaah, I see
13:37:25 <[exa]> oh I looked at wrong definition
13:37:41 <Solonarv> well, do you have to use Let in there?
13:37:53 <zincy> Bit confusing as the lambda arg is named exp but it IS a Value
13:38:11 <Solonarv> well, you haven't changed defineLambda's type signature to reflect that
13:38:12 <zincy> The typerror in full is at the bottom of the gist
13:38:23 <Solonarv> oh no you have, nbm
13:38:34 <[exa]> zincy: you might want to put 'ReaderT Scope (Except LangErr)' in a type alias btw, it's gonna look better
13:39:36 <zincy> exa: Would it be better to wrap it in a newtype?
13:39:48 <zincy> as in Solonarv's excellent example: https://gist.github.com/Solonarv/8525a61340edaad47908081381be6ff1
13:40:12 <Solonarv> doesn't matter much tbh
13:40:39 <[exa]> zincy: certainly shorter.
13:40:46 <Solonarv> I'd prefer a newtype but an alias is fine for something small like this
13:41:02 <[exa]> zincy: about defineLambda, shouldn't there be some kind of env-modifying function from Reader?
13:41:22 <Solonarv> eval's Let case does precisely that
13:41:24 <zincy> Solonarv: Is there any benefit to writing custom instances for monad and functor etc instead of deriving?
13:41:31 <Solonarv> but there's no need for this jumping back and forth
13:41:43 <Solonarv> zincy: learning, I suppose
13:41:44 <[exa]> oh yes it's there transitively
13:42:28 <[exa]> but Let can "only" do full expressions, not simple Values
13:42:38 <zincy> What would be a good next step for learning after implementing your example Solonarv
13:42:43 <zincy> Compiler?
13:42:51 <zincy> Type inference?
13:42:54 <Solonarv> I mean, depends on your goal
13:43:30 <Solonarv> you could add types, or output some sort of generated code
13:43:46 <zincy> My goal right now is mainly learning about computer architecture
13:44:00 <zincy> And type level programming in Haskell
13:44:15 <[exa]> zincy: anyway, why not just: eval (Let paramName (eval exp) body) ?
13:44:47 <zincy> So I guess writing a type checker and then compile the result to some architecture I want to learn about
13:44:53 <zincy> could be good
13:45:44 <zincy> exa: Which line?
13:45:56 <Solonarv> yeah, and you can pretty much do them in whichever order
13:45:59 <[exa]> still at 91 (sorry if I'm late now :] )
13:46:25 <Solonarv> [exa]: 'exp' is misnamed, its type is Value
13:46:58 <zincy> sorry :/
13:47:01 <Solonarv> and eval :: Exp -> m Value, not the other way 'round
13:47:57 <zincy> Solonarv: Is the way you wrote your std lib in your Gist basically the only real way of doing so in any language
13:48:18 <zincy> As in it has to be done at the AST level in the compiler or interpreter
13:48:30 <Solonarv> well, depending on the language you can write some of the standard library int the language itself
13:49:05 <Solonarv> but usually (always? I'm not aware of any exceptions) it has to at least be built on top of some primitives that are wired into the compiler/interpreter/runtime
13:49:39 <Solonarv> also, slight nitpick: 'arith' knows nothing about my Expr AST
13:50:02 <Solonarv> it knows about Val, but that has nothing to do with the AST!
13:50:55 <zincy> It is counter intuitive that the primitives are in your custom langugage but you get the full power of the lang you use to implement your compiler/interperter to define the operations on the primitives
13:51:45 <Solonarv> the primitives are *not* written in the extended lambda calculus I defined there
13:51:52 <Solonarv> they don't even know it exists!
13:53:44 <zincy> hmm https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab
13:54:07 <zincy> Solonarv: The primitives are written in Haskell right?
13:54:08 <Solonarv> I could make this really clear by splitting the code into multiple modules and showing that the module defining 'arith' doesn't depend on the module defining the Expr AST
13:54:17 <Solonarv> indeed, they are written in Haskell
13:55:09 <Solonarv> zincy: I ask again: why does defineLambda have to use Let?
13:55:09 <zincy> So the Val type isn't the custom language it is Haskell representing the custom language
13:55:45 <Solonarv> not even the entire language, just a value that might be computed by it
13:55:56 <zincy> Solonarv: i couldnt think of any other way of binding a lambda definition in scope
13:56:22 <Solonarv> why not use this wonderful bindVar function?
13:56:40 <zincy> So the language primitives are defined in the grammar not in the Haskell types
13:56:50 <zincy> Good idea!
13:57:41 <Solonarv> I mean, I can hand you the solution:
13:57:41 <Solonarv> \val -> bindVar paramName val (eval body)
13:57:50 <Solonarv> this is pretty much what I wrote in my interpreter
13:59:32 <zincy> I am sorta confused by the evaluation of the body there
13:59:47 <zincy> Oh wait maybe not
14:00:03 <zincy> the eval body gives us a Function value
14:00:24 <Solonarv> no, it doesn't
14:00:30 <Solonarv> well it might but it doesn't have to
14:00:53 <zincy> oh right
14:01:59 <Solonarv> in words, we can read this as:
14:01:59 <Solonarv> evaluating 'Lam v body' gives us a closure that, when applied to a value 'val', evaluates 'body' with 'v' bound to 'val'
14:03:04 <zincy> So body is the innerscope after the binding of the lambda
14:03:17 <zincy> like a continuation
14:03:55 <Solonarv> yes, that's about right
14:05:04 <zincy> Ah I was confusing it with the actual lambda body
14:05:28 <zincy> I dont know what a closure is
14:05:48 <zincy> in this lambda calculus style language perhaps the rest of the code is your body?
14:06:25 <zincy> as in /a -> /b -> c-> bodyExp
14:08:20 <Solonarv> here I'm using the term "closure" to mean "value that happens to be a function", basically
14:08:53 <nisstyre> that's not what a closure is
14:09:03 <Solonarv> I'm aware of that
14:09:08 <nisstyre> ok cool :p
14:09:19 <Solonarv> if you have a better explanation, feel free to chime in; I'm too tired to synthesize one
14:09:44 <nisstyre> a function as a value along with an environment mapping the function's free variables to values
14:10:20 <Solonarv> sure, that works
14:10:21 <nisstyre> surprisingly some languages have "closures" that aren't that
14:10:36 <nisstyre> *cough* PHP *cough*
14:11:02 <Solonarv> hm, actually that uncovers a potential bug in this implementation (and mine)
14:11:45 <nisstyre> there's also more than one way to actually implement it
14:13:24 <nisstyre> http://matt.might.net/articles/closure-conversion/
14:15:03 <monochrom> Closure has the "close" root because if you have "\x -> x+y" then it is still open i.e. "wth is y there?".  A compiler/interpreter has to find out what's y from the context and store it alongside with your "\x -> x+y".  The two together is called a "closure" because now all open questions are answered.
14:15:35 <Solonarv> fixed the mistake - https://gist.github.com/Solonarv/8525a61340edaad47908081381be6ff1#file-lcinterpreter-hs-L44
14:16:30 <nisstyre> monochrom: and it has to figure out if it should share y with any other closures or if it can copy y
14:16:41 <monochrom> More generally you don't have to have a function there.  For example for the purpose of lazy evaluation, you will be storing arbitrary expressions like "x + y + let z=1 in z+2" so now it has the same problem and admits the same solution, you store the expression plus what's x and what's y, this is still called a closure.
14:16:43 <nisstyre> but that's more like a general design decision
14:16:54 <nisstyre> and if y is immutable it doesn't even matter to the end user
14:17:16 <monochrom> Yeah C++'s lambda involves that consideration.
14:17:44 <Solonarv> Rust too (they're actually called closures there)
14:17:53 <zincy> Solonarv: So the bug was that scope wasn;t being inherited?
14:17:56 <nisstyre> and if y is always fresh every time the closure is created it wouldn't even matter
14:18:04 <nisstyre> but you could obviously have two closures with the same "y"
14:18:15 <Solonarv> zincy: the bug was that the scope where the lambda is defined was being completely ignored, yes
14:18:43 <monochrom> Oh are you making the classical dynamic scoping mistake? >:)
14:19:16 <Solonarv> I was, yes
14:19:32 <Solonarv> the perils of a shallow embedding!
14:19:59 <monochrom> Shallow embedding is fine but there are always a few gotchas no matter what you do.
14:20:22 <Solonarv> yes, the shallow embedding is convenient in other ways; I'm not saying it's a bad idea
14:20:36 <monochrom> Dynamic scoping was invented as a mistake from experts. This stuff is actually non-obvious.
14:20:39 <Solonarv> just that perhaps I wouldn't have made this particular mistake had I opted for a different approach
14:20:57 <nisstyre> at some point you start to get a headache from all the mutual recursion going on
14:21:17 <nisstyre> writing interpreters is hard
14:23:27 <zincy> Would the interpeter me and Solonarv have written count as hard?
14:23:36 <zincy> https://gist.github.com/therewillbecode/e0ff5dae4b59405f6adfcad4a0b490ab Yay it compiles
14:23:54 <nisstyre> zincy: I guess it depends on what your goal is
14:24:08 <zincy> Well what has been done already?
14:24:22 <zincy> Seems like fairly basic stuff right soo far
14:24:26 <nisstyre> yeah
14:24:52 <zincy> I guess there is a big difference when you go beyond toy interpreters
14:25:11 <nisstyre> once you start wanting things like type checking and desugaring it gets a bit more complex
14:25:12 <zincy> Did I write a lambda calculus interpreter?
14:25:24 <zincy> Yeah type checking is something I want
14:25:26 <nisstyre> zincy: maybe a version of LC
14:26:13 <nisstyre> zincy: also CPS-ing it
14:26:18 <nisstyre> that's something some compilers do
14:26:24 <nisstyre> or SSA form
14:26:43 <zincy> Type checking and then targeting x86 would be fun
14:26:59 <zincy> Is it still functional if you do that?
14:26:59 <nisstyre> you might want to check out Compiling with Continuations by Andrew Appel
14:27:04 <nisstyre> yeah, why not?
14:27:29 <zincy> Thanks
14:27:46 <nisstyre> if you target LLVM it will be easier though
14:27:55 <nisstyre> you won't have to write your own code generator for assembly
14:28:35 <nisstyre> you can always swap it out later if you want to rewrite that part
14:29:01 <Solonarv> you could cheat even more by outputting C or something
14:29:22 <nisstyre> you will have to write some C anyway for the RTS
14:29:23 <zincy> If you targeted X86 would you need to write a garbage collector?
14:29:28 <nisstyre> or C++, but ugh
14:29:40 <nisstyre> zincy: yes if you want it to be GC'd
14:29:46 <nisstyre> that's what the RTS is for
14:29:53 <zincy> Oh you would write the GC in C and link it in right
14:29:53 <nisstyre> (RTS = runtime system)
14:29:57 <nisstyre> yeah
14:29:57 <zincy> to the binary
14:30:05 <zincy> Unless you are a masochist
14:30:27 <nisstyre> I guess you could write an RTS in Rust too
14:31:06 <zincy> That would be another interesting experience
14:31:17 <zincy> Off to bed night everyone
14:32:07 <nisstyre> gnight
14:59:54 <talqu> could someone please have a look at this question https://pastebin.com/irZUDdDT?
15:02:06 <geekosaur> normally I would expect Html to be a type alias for HtmlT Identity
15:02:20 <geekosaur> not a distinct type
15:03:17 <dmj`> type Html = HtmlT Identity
15:06:58 <talqu> pff, didn't see that definitions, thanks
15:13:25 <talqu> should i then be able to concat the outputs of a function returning Html () and a function returning HtmlT m ()
15:18:27 <royal_screwup21> if I have f::Map String Int and I do f! -- does this convert it to a function of type (String -> Int)?
15:19:45 <lyxia> The operator section (f !) does.
15:22:14 <Cale> royal_screwup21: You typically should use lookup or findWithDefault though.
15:23:16 <Cale> royal_screwup21: (!) uses error to deal with the case that the element isn't in the Map, which means you basically have to be certain that it's there before you use it.
16:07:36 <nisstyre> why doesn't Haskell have checked exceptions anyway?
16:19:07 <JappleAck> nisstyre: MonadError isn't enough? https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Error.html#t:MonadError
16:19:10 <davean> who said it didn't? ;)
16:25:10 <geekosaur> afaikit's never going to change that most exceptions have no business being exceptions
16:28:28 <Cale> nisstyre: The question is: how would checked exceptions differ from any of the other methods we use to keep track of potential failures in the type system?
16:32:11 <jackdk_> I feel like we have better tools for mapping and binding through computations that might fail than I ever did with checked exceptions. Admittedly, the last time I used checked exceptions was in some archaic Java.
16:57:37 <davean> I rather did enjoy using http://hackage.haskell.org/package/control-monad-exception for a while in some special situations, but mostly because I could tie it into montioring stuff and auto-file tickets
17:07:58 <aplainzetakind> I have a simple typing drill function which takes a string and monitors key presses to see if they match. It returns when ESC is pressed. I want to give it to `forever` with random strings, but naturally when I press ESC I'd like to break out of the whole thing and not just break a single run. What would be a good way to have this behaviour without having a similar but looping version of the 
17:08:04 <aplainzetakind> entire thing?
17:13:47 <lyxia> throw an exception?
17:16:41 <aplainzetakind> lyxia: Like fail?
17:22:19 <lyxia> I would rather use a custom exception or the MaybeT/ExceptT transformer.
17:51:49 <Cale> aplainzetakind: It's possible to use ContT for that purpose if you really want, but I'd probably favour just not using forever, and instead use explicit recursion that only happens if you're not breaking out.
17:52:50 <jackdk_> aplainzetakind: there might be something that works for you in monad-loops too, but I generally do what Cale suggested
17:54:37 <Cale> callCC $ \done -> forever $ do ... done v ...
17:54:40 <Cale> something like that
17:55:09 <Cale> (but yeah, just explicit recursion is less tricky to deal with)
18:05:11 <aplainzetakind> I feel explicit recursion would make things a bit monolithic and ugly. callCC looks like it would fit the bill.
18:07:54 <MarcelineVQ> why monolithic?
18:08:18 <MarcelineVQ> sounds like a code structure question rather than a code method question, what have you got currently?
18:23:25 <nisstyre> jackdk_: ponylang.io has them as part of the type system, but I think the difference between what it does and what Haskell does is that it's essentially baked into the stdlib. So instead of letting you just do `xs !! 1`, it forces you to add a "?" to your return type which is the exception operator basically.
18:23:58 <nisstyre> if Haskell *forced* you to use things like Maybe/Either/MonadError/etc then that would be what I'd call "checked exceptions"
18:24:32 <aplainzetakind> MarcelineVQ: Something like this: http://dpaste.com/3Q5ET1H
18:27:50 <aplainzetakind> Since I handle the key presses inside this, I don't see how I could make the decision to not keep looping from outside.
18:30:54 <MarcelineVQ> aplainzetakind: Have DrillRes report if esc was pressed?
18:31:17 <iqubic> I'm bored. What should I program in Haskell right now?
18:31:27 <MarcelineVQ> An audible alarm clock
18:32:44 <aplainzetakind> MarcelineVQ: Wouldn't that be hackish? DrillReses are just data to be written to a database.
18:33:14 <iqubic> MarcelineVQ: Why would that be a good thing to create?
18:33:39 <MarcelineVQ> iqubic: Who cares :>
18:34:02 <iqubic> I do.
18:34:12 <iqubic> It's my project, isn't it?
18:34:20 <MarcelineVQ> iqubic: Then I'll leave it to you to figure out a reason
18:34:22 <iqubic> I want it to be something fun and interesting.
18:35:46 <nisstyre> iqubic: improve this library so I can use it https://github.com/zenhack/haskell-capnp
18:35:48 <MarcelineVQ> aplainzetakind: If DrillRes has that specific a job then you can use something else, even a tuple of Bool and DrillRes, my point is that you can return a value indicating whether to keep looping
18:37:07 <iqubic> nisstyre: What's wrong with the library as it stands right now?
18:38:52 <nisstyre> iqubic: the github page says it's still missing a bunch of features
18:39:11 <iqubic> What features do you wish the library had?
18:39:40 <nisstyre> > The implementation is not robust against resource exhaustion attacks; for now users are strongly discouraged from using it to do RPC with untrusted peers
18:39:42 <lambdabot>  <hint>:1:69: error: parse error on input ‘;’
18:39:47 <nisstyre> that's kind of a deal breaker for me
18:40:33 <aplainzetakind> MarcelineVQ: I understand, but it somehow feels inelegant.
18:42:18 <clever> nisstyre: ive heard that its not even safe to parse json from untrusted peers, because aeson internally stores key/value pairs in a hashmap, and if you pick keys with hash collisions, it ruins the performance of the hashmap
18:43:09 <geekosaur> nisstyre, re checked exceptions, I would argue that things that should be exceptions are things that can't really be checked, and things like (!!) or openFile throwing exceptions instead of using Either ErrorIndication Handle are bugs in the library.
18:43:24 <geekosaur> but at this point I doubt it will change because too many things depend on how it currently works
18:44:54 <nisstyre> geekosaur: well yeah if they used Either, then that would essentially be checked exceptions, because if you tried to use it with something expecting Handle it would fail to unify
18:45:01 <nisstyre> so yeah I think I agree with you
18:45:58 <geekosaur> and then there's things like lazy I/O where an exception is really the only option, because random things that look pure suddenly can be doing I/O behind your back
19:05:57 <Axman6> is it currently possible to create threads within ResourceT using the monad stack that ResourceT is part of? so if I have newtype Foo a = ResourceT (BarT IO), I'd like to be able to do something like lifted-async's mapConcurrently within Foo
19:06:29 <Axman6> I feel the whole unliftIO change made much of the snoymanverse less useful without providing decent alternatives to the old functionality
19:06:32 <geekosaur> what do you expect to happen with, e.g. an embedded State?
19:07:31 <Axman6> I understand there are monads it doesn't make sense for, but I don't think we're using any of them
19:51:37 <rkuo>  a newbie question: why I can enter "a = [1,2,3]" in ghci, but not in tryhaskell.org, got error msg "<hint>:1:3: parse error on input ‘=’"
19:52:36 <Cale> rkuo: tryhaskell.org is looking for expressions rather than declarations. Somewhat recently in GHC history, GHCi gained the ability to accept declarations as well as expressions
19:59:39 <rkuo> Cale: thank you! I guess I need to find what is the difference between expressions and declarations. I will use GHCi for my learning for now.
20:00:18 <Axman6> you can use let a = [1,2,3] in tryhaskell IIRC
20:02:16 <Cale> rkuo: Expressions are the syntactic class of things which get evaluated to produce values, declarations are how you make new definitions -- defining new datatypes, functions, constants, etc.
20:15:43 <rkuo> Cale: thank you, I found a page https://wiki.haskell.org/Declaration_vs._expression_style, reading it. One more question: Can I just use Declaration style for all my Haskell coding?
20:17:58 <Cale> oh, that's sort of a follow-on thing
20:18:34 <Cale> You pretty much could? Realistically, you'll end up doing a combination of the two? That wiki page makes a strange distinction.
20:21:59 <rkuo> Cale: thank you, :-) I will log out and back to my online class homework now.
20:22:23 <Cale> Feel free to stick around and ask any questions you might have
21:53:15 <clever> data NextDlg s a1 = forall a2. (Show a2) => UpdateCurrentState s | PushNew (Dialog a2) | CloseCurrent a1
21:53:19 <clever> Not in scope: type variable ‘a2’
21:53:29 <clever> i must be missing something obvious, but i cant really see it
21:58:21 <[Leary]> clever: I think that parses as `(forall a2. (Show a2) => UpdateCurrentState s) | PushNew (Dialog a2) | CloseCurrent a1`
21:58:41 <jackdk_> data NextDlg s a1 = UpdateCurrentState s | forall a2. (Show a2) => PushNew (Dialog a2) | CloseCurrent a1 -- perhaps?
21:58:56 <clever> that does shift the error elsewhere
21:59:50 <clever> now its back to the messy: Couldn't match type ‘a’ with ‘a3’
22:00:48 <clever> and `Record update for insufficiently polymorphic field`
22:02:03 <clever> https://gist.github.com/cleverca22/9e2241a8a43c2945632ff50996f83b36
22:05:52 <clever> i think the problem, is `asDialogStack :: [ Dialog a ]`, i'm trying to store a list of Dialogs, with different a's
22:06:29 <clever> but it doesnt have to be a regular list type, i could make my own singly linked list, without that restriction...
22:07:59 <[Leary]> It looks like that `a` type parameter isn't being used anyway; you introduce a new `a` and shadow it?
22:08:17 <clever> ah, the forall is doing that?
22:08:39 <clever> yeah, changing it to `forall s.` reduces the number of errors
22:08:54 <clever> but i think removing the list will still be an improvement, so i'll continue with that refactor
22:10:20 <clever> that also greatly simplifies NextDlg, rather then having special types to manipulate the list, i just return the current one every time
22:16:52 <jle`> clever: not sure what you're trying to do exactly
22:17:29 <clever> trying to create a framework where a dialog can push more dialogs onto a stack, and the top most one renders, and can then return a value to its previous dialog and pop itself off the stack
22:18:12 <jle`> this sounds like a pretty textbook case of the Existential Typeclass antipattern maybe?
22:18:39 <jle`> hiding an existential variable with Show is no different than just having a Strign
22:19:00 <c_wraith> ...  technically, no different than having a ShowS.  :P
22:19:01 <clever> Show is just a placeholder, i'm not 100% sure what the types should be yet
22:19:14 <jle`> clever: right, but the point remains for any typeclass
22:19:53 <jle`> are you familiar with the antipattern/why it's discouraged?
22:20:05 <clever> not really
22:20:05 <jle`> this is sort of a "don't do it unless you know why you shouldn't" sort of thing
22:20:50 <jle`> here is one of the main articles on it https://lukepalmer.wordpress.com/2010/01/24/haskell-antipattern-existential-typeclass/
22:21:41 <jle`> clever: do you know what is meant by existential type? it's what you're making here, but you might be doing it inadvertantly
22:21:53 <clever> not really
22:22:06 <clever> part of why i was hiding the type was to allow mixing types within the list
22:22:13 <clever> but i'm removing the list now, so that can maybe go
22:22:36 <jle`> ah, okay. the mechanics of existential types can be a bit surprising
22:22:46 <jle`> at first
22:23:06 <clever> i think i was using them to put both `Dialog Foo` and `Dialog Bar` into the same list
22:23:24 <jle`> the idea is that your functions that *use* a data type with an existentials have to be well-typed, and that constraint makes using existential types sort of tricky
22:23:33 <jle`> clever: why not [Either (Dialog Foo) (Dialog Bar)] ?
22:23:38 <clever> but now i'm just going to make `Dialog Foo` have a function within it, that returns `Dialog Bar`, and use that to pop things off the list
22:23:59 <jle`> ah yeah. if you have *specific* types in mind, that avoids most of the issues
22:24:07 <jle`> specifically Foo, or specificalyl Bar
22:24:07 <clever> jle`: the problem is that i'm trying to make a dialog tree, where any dialog can call into any other dialog, and then return back into it
22:24:10 <jle`> instead of trying to be polymorphic
22:24:29 <clever> which is trivial when doing blocking codeflow
22:24:37 <clever> but making it event driven, in a typed language, gets hairy
22:25:18 <jle`> often, existential types arise from trying to "port" an OOP design/mindset into haskell
22:26:03 <jle`> existential types sometimes are accidentally used when trying to simulate things like java interfaces or subclasses
22:26:35 <jle`> in the end the final solution is still "trivial", but only if you abandon that sort of approach
22:26:47 <jle`> usually, at least :)
22:27:24 <jle`> clever: here's one problem, let's imagine a data type that hides an existential type that is Showable
22:27:31 <jle`> data SomeShow = forall a. Show a => SomeShow a
22:27:51 <clever> Record update for insufficiently polymorphic field: dState :: s
22:27:54 <jle`> you might reach for this if you want a list of showable things of different types ... so like [SomeShow]
22:28:11 <jle`> so you can have a list of Int, Bool, Double, etc., as long as they're Showable
22:28:25 <jle`> but, what happens when you want to *use* the list?
22:28:37 <jle`> what happens when you want to *use* a value of type SomeShow?
22:28:49 <clever> in my case, the Dialog contains functions that accept those values
22:29:12 <clever> the idea was to have a function that sits un-applied, and a state to apply to it, and then the function returns the new state
22:29:25 <jle`> because the variable isn't inside the type, the variable can't be used anywhere in the *result*
22:29:37 <clever> but, i could just as easily redo it, to hold a partially applied function, that has been partially applied to the state
22:29:39 <jle`> you have to handle it in a polymorphic way, and the inner type variable can't show up in the result
22:29:41 <clever> so the state is never visible
22:30:00 <jle`> and so you have to handle a value (SomeShow x), polymorphically, for all 'a', only knowing that it is 'Show'
22:30:06 <jle`> and so really the only thing you can do to 'x' is 'show' it
22:30:11 <clever> basically:
22:30:14 <jle`> so, [SomeShow] is identical to just [String]
22:30:40 <clever> data Foo = forall s . Foo { state :: s, func :: s -> s }
22:30:51 <clever> and then calling func on state, produces a new state that can go back into the Foo
22:31:02 <jle`> clever: right, but that Foo is completely unusable
22:31:05 <jle`> do you see why?
22:31:26 <jle`> it's essentially equivalent to ()
22:31:31 <clever> and at some point, it would return something not-s, rewritten as: func :: s -> Either NotS s
22:32:03 <jle`> do you see why [SomeShow] is equivalent to [String]?
22:32:09 <clever> so you keep calling func on the state, which can be held inside the Foo until later
22:32:31 <clever> and the Show is just for debug, so i can print that state from things that dont know what s truely is
22:32:33 <jle`> in the end, all of your existential games really are just simulating a non-existential type
22:32:46 <jle`> i'm not talking about SHow here, i'm asking if you understand the reason why [SomeShow] is equivalent to [Show]
22:32:57 <jle`> understanding this reason will help you understand what is going on in your situation
22:33:00 <jle`> it is an analogy :)
22:33:13 <clever> yeah, for a simple thing like SomeShow, its identical, and i could just call `show` before filling the list
22:33:14 <jle`> sorry, i mean [SomeShow] is equivalent to [String]
22:33:29 <clever> but what about a more complex type like
22:33:31 <clever> data Foo = forall s . Foo { state :: s, func :: s -> Either NotS s }
22:33:41 <jle`> right, and after the value goes into a SomeShow, the only way "out" is to show it
22:33:58 <jle`> clever: ah okay, so there isn't a typeclass involved here
22:34:15 <clever> yeah
22:34:30 <clever> the only point of Show was for "outside" things to pretty-print it for debug/tracing
22:35:06 <clever> `func` also accepts something else, that will control how it mutates `s`
22:35:13 <jle`> clever: so actually your type is some form of automata; you can run the func and update the state
22:35:14 <clever> data Foo = forall s . Foo { state :: s, func :: s -> Event -> Either NotS s }
22:35:20 <jle`> record updates don't work, because they are ill-typed
22:35:20 <clever> yep
22:35:31 <jle`> ah, adding the Event as an input makes it useful now :)
22:35:42 <clever> yeah, i over-simplified the example
22:35:44 <jle`> because before, your Foo = forall s. Foo { state s :: s, func :: s -> Either NotS s } is equivalent to 'NotS'
22:35:57 <jle`> because the only thing you can do is run the function until you get a Left
22:36:10 <clever> let me grab a chunk of code i saw recently...
22:36:15 <jle`> so like how SomeShow ~ String, your original Foo ~ NotS
22:36:34 <jle`> your Foo without the Event input is equivalent to NotS, and writing the isomorphism can be fun :)
22:36:43 <clever> halting problem
22:36:47 <clever> it could never return Left
22:36:53 <jle`> it can possibly return Left
22:37:17 <jle`> here: `myFoo = Foo 0 $ \x -> if x > 10 then Left blahblah else Right (x + 1)
22:37:39 <Solonarv> I think clever means that it's also possible for it to never actually return Left
22:38:07 <Solonarv> but that simply means you get back bottom, which is already possible
22:38:12 <clever> https://github.com/snoyberg/http-client/blob/master/http-client/Network/HTTP/Client/Core.hs#L61-L64
22:38:29 <clever> here is some strange code i recently discovered, that i think is doing similiar things to what ghc isnt letting me do
22:38:42 <clever> its using a record field update, to turn a Response BodyReader, into a Response ByteString
22:39:13 <jle`> clever: in that case it's maybe because responseBody is the only field that uses BodyReader/ByteString
22:39:39 <jle`> remember that record updates are just syntactic sugar for normal functions, so they can't be used to do anything magical you can't do with normal functions
22:40:03 <jle`> in your case you can't use record update to update state, because state isn't the onyl field that uses 's'
22:40:04 <clever> https://github.com/snoyberg/http-client/blob/master/http-client/Network/HTTP/Client/Types.hs#L601-L632
22:40:12 <clever> yep
22:40:18 <clever> responseBody is the only thing of type `body`
22:40:28 <jle`> both 'state' and 'func' use 's', so you can't update one without updating the other
22:41:01 <clever> even if state is the same type as before, and reading both state and func, and re-constructing the entire record works
22:41:08 <jle`> only thing you can do here is just make a new value and put both state and func :)
22:41:26 <jle`> yeah. you have to re-construct the entire thing
22:41:29 <clever> yep, i was doing that in some code i just deleted
22:41:39 <clever> the style without the list doesnt need that as much
22:41:45 <jle`> the reason why is that your value 'myFoo :: Foo', the 's' is not in the type
22:41:57 <jle`> so record update can't know that myFoo contains 's' in it
22:42:05 <jle`> of whatever s your new state is
22:52:31 <clever> Occurs check: cannot construct the infinite type: d2 ~ Dialog () Dialog1State d2
22:52:42 <clever> Expected type: EventM Name (NextDlg d2)
22:52:47 <clever>   Actual type: EventM Name (NextDlg (Dialog () Dialog1State d2))
22:56:55 <clever> jle`: i'm wondering if some of this might be simpler if i use a class rather then a polymorphic data record?
22:57:29 <clever> instead of a record that holds state and update methods, i could just have a state, with an instance of the update method...
22:57:30 <jle`> using a typeclass can make things less verbose sometimes, but it always makes things more complicated
22:57:36 <jle`> because typeclasses are global magic
22:58:25 <jle`> it's good to at least draft out your ideas with explicit passing before seeing if typeclass magic can replace it
22:58:29 <clever> i think the problem, is that i'm managing a data record with several functions, and a type, all polymorphic, but all tied to the type
22:58:39 <clever> so if i had a typeclass on that type, that just supplied those functions directly...
22:59:03 <clever> the functions themselves dont need to change over time, which is why i was using record updates
22:59:08 <jle`> a typeclass on a type is identical to a record of functions on that type
22:59:26 <jle`> the only difference is that now you can't pass around that record anymore, you have to rely on compiler magic
22:59:58 <clever> i would expect record updates to become simpler, within the functions, because they dont have to be aware of the other functions in the record
23:00:34 <jle`> is what you are trying to do already working with normal value creation w/o using record updates?
23:01:31 <clever> jle`: thats what i was doing around line 87 of https://gist.github.com/cleverca22/9e2241a8a43c2945632ff50996f83b36
23:01:35 <clever> i believe
23:01:46 <jle`> ah. so what you have already works, you just want to use record updates instead of normal functions
23:01:49 <clever> just reconstruct the entire record every time, with a new state
23:17:21 <clever> jle`: down to a single type error!, Record update for insufficiently polymorphic field
23:18:14 <clever> ah, the dlg is the wrong type
23:18:38 <clever> i'm pattern matching on dlg like its a list, but it isnt, and ghc then says something completely different
23:35:52 <clever> class DialogRedo s where
23:35:58 <clever>   handleRedoEvent :: DialogRedo s2 => AppState s -> s -> BrickEvent Name CustomEvent -> EventM Name (NextDlgRedo s2)
23:36:16 <clever> jle`: now i'm stuck, becayse the event handler needs to return a new thing, that simply has to be in the typeclass
23:36:40 <clever> and its basically failing with expected s2, got Dialog1State (which has an instance of DialogRedo)
23:37:46 <jle`> there's nothing you can do with a typeclass that you can't do without one :)  at least other than letting two functions have the same names. the only other difference is implicit argument passing
23:38:38 <jle`> clever: note that your handleRedoEvent is polymorphic on s2, meaning that s2 can't depend on s
23:38:38 <clever> any idea whats wrong with the error i just gave?
23:38:55 <jle`> the caller of handleRedoEvent can decide any s2 they want, without any relationship to s
23:39:11 <clever> that is intended, it can return either something of the same type, or an unrelated thing that is also an instance of DialogRedo
23:39:13 <jle`> which error?
23:39:17 <clever> based on what the BrickEvent is
23:39:24 <jle`> clever: it can't do that
23:39:36 <jle`> it can't return a different instance based on what BrickEvent is
23:39:39 <clever> jle`: https://gist.github.com/cleverca22/f636bc1c2eb90cbfea3d379cb22c81eb
23:39:57 <jle`> notice it's universally quantified, meaning that the choice of s2 is up to the *caller* of handleRedoEvent
23:40:00 <jle`> not the implementor
23:40:23 <jle`> the error you are giving is similar to writing a function `myFunc :: String -> a`
23:40:34 <jle`> and implementing `myFunc _ = True`
23:41:01 <jle`> the *caller* of myFunc is free to choose the type variable 'a'
23:41:07 <jle`> so the implementor of myFunc can't pick Bool
23:41:15 <jle`> it has to return something completely polymorphically
23:41:37 <clever> ah :S
23:42:37 <clever> that seems tricky to solve
23:42:38 <jle`> using a typeclass doesn't give you any extra power; the only difference is implicit passing
23:43:11 <jle`> so if you can't implement your thing with explicit passing, adding a typeclass won't make any difference
23:44:02 <jle`> clever: back to the idea of [SomeShow] and [String], what properties of a DialogRedo do you actually ever observe?
23:44:13 <jle`> usually the answer is monomorphic, or at least dependent on visible non-existential types
23:44:53 <clever> i want to have a dialog type, which can render its state (return a list of Widgets, a pure function)
23:45:06 <jle`> clever: is that all a dialog type can do?
23:45:11 <clever> it can also mutate the state (IO, takes an event, and returns a new state)
23:45:34 <clever> and, it can also create new dialogs, which have a different state type, and a different implementation of the previous 2 methods
23:45:47 <clever> and when a dialog returns, it passes something to the parent dialog
23:46:02 <clever> so i could spawn a "file selection" dialog, that will return a FilePath
23:46:13 <clever> and then i mutate the parent dialogs state, and do someting with the FilePath
23:46:37 <jle`> so a dialog is an impure thing that must be updated within IO? 
23:46:47 <clever> yeah
23:47:21 <clever> and my current plan, is that the update method returns a new dialog, of either the same or different type (unpredictable type)
23:47:32 <clever> and the previous dialog, is held within a field on the new dialog
23:47:46 <jle`> why does the update need to happen within IO ?
23:47:54 <clever> so at some point in the future, i can "pop" the stack, and return the previous dialog
23:48:30 <clever> https://hackage.haskell.org/package/brick-0.47/docs/Brick-Types.html#t:EventM
23:48:43 <clever> jle`: everything happens inside EventM, which is a ReaderT over IO
23:49:07 <jle`> what sort of state updates are you thinking of that require IO
23:49:11 <clever> and most of the state changes involve taking an event, performing IO based on that event, and returning a new state
23:49:19 <clever> and then using that new state when the next event comes back in
23:49:43 <jle`> okay, so try planning out the type of the API of your dialog
23:50:09 <jle`> renderWidgets :: Dialog -> [Widget X()] ?
23:50:25 <jle`> updateDialog :: Event -> Dialog -> (IO (), Dialog)   ?
23:50:42 <jle`> does the new state ever depend on IO action's results, or are the IO actions just things that are emitted??
23:51:00 <clever> the new state depends on what the IO has discovered
23:51:31 <jle`> so updateDialog :: Dialog -> IO Dialog, then
23:51:41 <clever> yep
23:51:48 <jle`> and what wouild the type of the spawning be
23:51:59 <jle`> spawn :: Dialog -> [Dialog] ?
23:53:19 <clever> a dialog opening a new dialog, would be like creating a "file chooser" dialog, and passing it a `FilePath -> IO Dialog` function
23:53:35 <jle`> okay, so what does that look like as a type
23:53:38 <clever> and when the "file chooser" is done doing things, it calls that on the chosen file, to revert back to the previous dialog
23:53:41 <jle`> spawn :: Dialog -> IO Dialog ?
23:53:55 <clever> openFileChooser :: (FilePath -> IO Dialog) -> Dialog
23:54:03 <clever> or maybe
23:54:06 <clever> openFileChooser :: (FilePath -> IO Dialog) -> IO Dialog
23:54:22 <jle`> so openFileChooser ... doesn't take any Dialog as inpu
23:54:33 <clever> just a function, that returns a dialog
23:54:50 <jle`> right, it's not associated with any Dialog value, it's just a global function, basically
23:55:00 <jle`> okay, so let's look at our API
23:55:10 <jle`> renderWidgets :: Dialog -> [Widget X]
23:55:15 <clever> and then internally, the file chooser either returns its own Dialog (mutating the state), or calls the f to return the parents Dialog
23:55:21 <jle`> updateDialog :: Dialog -> Event -> (IO (), Dialog)
23:55:31 <clever> IO Dialog ^
23:55:35 <jle`> ah yeah, sorry
23:55:42 <jle`> and openFileChooser, which isn't associated with any Dialog value
23:55:45 <jle`> to me, this looks like:
23:56:06 <jle`> data Dialog = Dialog { renderWidgets :: [Widget X]; updateDialog :: Event -> IO Dialog }
23:56:18 <jle`> do you see how i constructed that? i basically directly read off the functions of the API
23:56:47 <jle`> now renderWidgets :: Dialog -> [Widget X], just from record syntax's automatic functions it generates for us
23:56:55 <jle`> and updateDialog :: Dialog -> Event -> IO Dialog
23:56:57 <clever> what i'm seeing, is that you just partially applied the handlers on the states, and put the partially applied functions into a record
23:57:09 <clever> so the Dialog doesnt have any reference to the state
23:57:10 <jle`> that's one way to look at it
23:57:15 <jle`> but the other way is that the Dialog *is* the state
23:57:21 <jle`> a list is a state
23:57:26 <jle`> an `Event -> IO Dialog` is a state
23:57:54 <jle`> and updateDialog is a function that trivially extracts a portion of the state (namy, the Event -> IO Dialog portion)
23:58:24 <jle`> remember that functions are values, so functions are just as valid states as ints or bools
23:58:29 * clever rewrites it once more to test
23:59:03 <clever> i was more wanting to use record updates to swap out a state, and reuse the functions, but i can also just partially apply the functions to the state, and store the partially applied funcs
23:59:39 <jle`> this is essentially what you are doing, except your state now has an explicit type that is shared amongst all Dialog's
23:59:59 <jle`> your state is not 's', it's ([Widget X], Event -> IO Dialog)
