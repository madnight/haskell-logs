00:04:58 <dansho> anyone else think it's kind of silly that 0.042 prints as 4.2e-2 ?
00:06:03 <Axman6> 420e-5{-blaze it-}
00:07:25 <Axman6> > 420e-5
00:07:29 <lambdabot>  4.2e-3
00:07:35 <mmaruseacph2> > 0.042
00:07:38 <lambdabot>  4.2e-2
00:07:57 <dansho> 4.2e2
00:08:04 <dansho> > 4.2e2
00:08:07 <lambdabot>  420.0
00:13:33 <Miroboru> Q: I have a function foo :: a -> b -> c. I want to apply it to a list of [a], but with a fixed b, return a list [c]... What is the best approach?
00:14:03 <Axman6> map
00:15:19 <Miroboru> If I map foo [a], that will give me a list of curried functions, no? And then I apply those functions to a single b?
00:15:35 <Axman6> indeed
00:15:46 <Miroboru> kk, Ill try that - thanks
00:15:53 <Axman6> but you can pass it something which isn't foo
00:16:05 <Axman6> map (\a -> ...) as
00:37:10 <jackdk> Miroboru: you could also `map (\a -> f a b) as`, `map (flip f b) as`, or `f <$> as <*> pure b`
01:28:04 <dminuoso> Mmm, why am I gettng this diagnostics from my deriving via clause? https://gist.github.com/dminuoso/5dacfb71e664e592ce016985267e8efd
01:29:05 <Axman6> Prbabaly because The type family application ‘LdFTy Text’ is no smaller than the instance head ‘LdFTy Alias’, I'd say =)
01:29:53 <dminuoso> Axman6: class ToLdapAttr a where type LdFTy a :: * -> *; toAttr :: a -> LdFTy a ByteString
01:30:21 <dminuoso> Axman6: Im not quite sure what deriving via generates to trigger this diagnostic.
01:37:30 <dminuoso> Ah well I shuffled things around to using closed type families and fundeps, no UndecidableInstances needed now. :)
02:31:15 <fasal> hallloww
02:31:55 <fasal> \O/ D: O:3 ;( 
02:32:50 * ski stares blankly
02:36:02 <Jinna> Should `putStrLn` be called  a) an Action, or IO-Action?  Or is it fine to say that `putStrLn` is an ordinary function, which b) _computes_ an IO-Action?
02:36:42 <ski> the latter
02:37:33 <ski> one might also say "a parameterized (`IO'-)action"
02:37:48 <Jinna> Makes sense, thx.
02:37:56 <ski> or perhaps, an `IO'-operation
02:38:36 <ski> (`getLine' would also be one)
02:48:32 <dminuoso> % :t putStrLn -- Jinna 
02:48:33 <yahb> dminuoso: String -> IO ()
02:48:58 <dminuoso> Jinna: putStrLn is a function, and it produces an IO action. getLine on the other hand is itself an IO action and not a function.
02:49:47 <JappleAck> isn't it a function which takes no arguments?
02:50:03 <dminuoso> JappleAck: No, it is not a function. There is no (->) in its type signature.
02:50:23 <dminuoso> JappleAck: The conflation between function and "action" is a source of many confusions amongst newcomers.
02:51:02 <jgt> I like the way you very neatly phrased that — it is not a function because there is no arrow
02:51:30 <jgt> it helps newcomers understand when things are phrased in such black and white terms
02:51:47 <jgt> like in JavaScript: no, this function is not pure because you used the keyword `this`
02:53:26 <JappleAck> ..or changed a variable outside of function scope, called some other function which changed something, whatever
02:53:27 <tdammers> alternatively, keep coming back to the fact that all Haskell functions are unary
02:54:12 <tdammers> JappleAck: well yes - there are all sorts of ways for JS procedures to be impure, but anything that involves `this` is definitely impure.
02:54:36 <tdammers> in fact, it is arguably impossible for a JS procedure to be pure
02:54:44 <dminuoso> JappleAck: Mind my asking, did you mean to imply that values could be thought of as functions from ()? Or was it to convey that its a coroutine that is halted, ready for continuation?
02:56:37 <JappleAck> dminuoso: i guess kinda both, it could be interpreted like that and also implementation more or less corresponds to that
02:56:54 <dminuoso> JappleAck: So for the first part, http://conal.net/blog/posts/everything-is-a-function-in-haskell is a post worth reading.
02:57:17 <JappleAck> well, in PureScript an Effect monad in js code is a function which takes no arguments
02:57:29 <dminuoso> JappleAck: For the second part, that's an implementation detail. In Haskell we don't reall have the notion of "call a function by pushing something on the stack, executing its things, and then returning"
02:57:46 <dminuoso> JappleAck: That's a way in some languages to capture an action as a first class value.
02:57:53 <dminuoso> It's a trick to mimic what we have built into the language.
02:58:26 <dminuoso> JappleAck: One good way to think of `IO T` is to think of it as a "list of assembly instructions"
02:59:26 <dminuoso> A list of assembly instruction that, if executed, would produce a final result of type T.
03:00:21 <dminuoso> JappleAck: A function otoh is not a list of instructions, it's a mapping between values. So `putStrLn` is a mapping between strings and lists of instructions. Every string is mapped to a particular list of instructions.
03:01:51 <ski> @where everything-is-a-function
03:01:51 <lambdabot> http://conal.net/blog/posts/everything-is-a-function-in-haskell
03:01:54 <ski> hm, okay
03:02:52 <ski> JappleAck : no, a monad is not a value. one could perhaps call such a function a monadic *action*, or an `Effect'-*action*'
03:02:52 <dminuoso> ski: It's one of my favourite articles. :)
03:03:29 <dminuoso> JappleAck: The main problem is the confusion of the word "function" in various languages.
03:04:19 <dminuoso> JappleAck: In Haskell when we say "function" we mean it in the mathematical sense where the function maps values from the domain to some values in the codomain. The "how" is irrelevant, the "which values map to what things" is.
03:04:36 <dminuoso> JappleAck: The term was sadly abused by some programmers/languages to mean something completely different.
03:04:50 * ski would prefer to say "a recipe / list of instructions, for how to communicate (do input and output) with the surrounding system (OS), in order to obtain/compute a result of type `T'"
03:04:53 <dminuoso> JappleAck: In JavaScript the term "routine/procedure" would be more appropriate.
03:05:47 <dminuoso> JappleAck: And what JavaScript captures with routine/procedure (they call it "function"), we capture with `IO T`. What we capture with "functions" you cannot cleanly represent in JavaScript.
03:05:58 <ski> Scheme tends to call them "procedures", fwiw
03:06:28 <ski> well, they also express parameterized expressions via "functions", so ..
03:06:41 <ski> (ECMAScript, i.e.)
03:06:53 <dminuoso> ski: via routines. :-P
03:07:02 <dminuoso> Just like in Haskell you could do everything in IO.
03:07:18 <ski> just pointing out that they also express `->', not only `IO', with them
03:07:29 <ski> (which is part of the problem, of course :)
03:07:38 <dminuoso> So if we did a 1:1 translation of JavaScript in to Haskell, then addition of numbers would become: `(+) :: IO Double -> IO Double -> IO Double`
03:07:52 <ski> hmm ?
03:08:06 <dminuoso> ski: `1 + f(10)`
03:08:07 <ski> i don't think so, because it uses by-value parameter passing
03:08:38 <dminuoso> ski: Where `f` is some coroutine that could launch missiles and return a double.
03:08:53 <ski> if you had said that their `+' translates to combining two `IO Double's into a single one, then i'd agree
03:09:16 <dminuoso> ski: That's what I was trying to imply. :)
03:09:50 <ski> (but thinking of `+' as a function is distinct from thinking about how one can build larger expressions out of smaller ones, by connecting them with `+')
03:11:05 <Rembane> Construction and elimination.
03:11:42 <dminuoso> JappleAck: And then, because mathematically inclined programmers were annoyed that the word "function" got abused, they tried to find a new word for what function originally meant. So now you have "pure functions" (which are functions in their true sense), and "impure functions" (which are not functions at all, but routines/procedures)
03:12:40 <ski> `plus(1,f(10))' corresponds to `bindM2 plus (return 1) (f =<< return 10)' (`bindM2' defined in the obvious way), where `plus :: Double -> Double -> IO Double' here
03:13:36 <ski> (if it has used by-name, then it'd correspond to `plus (return 1) (f (return 10))', where indeed `plus :: IO Double -> IO Double -> IO Double')
03:16:31 <ski> i suppose, just like there's by-value vs. by-name CPS transformations, there's by-value vs. by-name "Monadic Style" transformations
03:18:53 <ski> (the latter transforming from a language with side-effects, to a language which expresses effects monadically (possibly in a first-order way, with language constructs for bind). i believe Wadler talked about the latter in some paper ?)
03:49:34 <Jinna> Interesting discussion.
04:52:17 <dminuoso> JappleAck: Now it should be said, that there is an interesting notion to "function from () to a value" that relates to Haskell.
04:52:40 <dminuoso> Oh wow ops. Was just eating lunch and accidentally pressed enter with that stuff in the line editor still.
04:53:22 <ski> hello, dminuoso's lunch
04:53:25 <hpc> i do that all the time with ^K/^J in irssi
05:00:59 <ochkep> There is now a way for foreigners to donate to MoveOn PAC without being detected and to help defeat Donald Trump in 2020. We have set up accounts that will take your donation and peg it to the name of someone who hasn't donated the maximum yet.  Best of all, this is 100% legal!  Help preserve human rights and global governance; donate to MoveOn.  “When a community starts to listen to each other, pull together, and work towards 
05:00:59 <ochkep> a common goal, then anything is possible.”
05:00:59 <ochkep> — Chuck, MoveOn Mobilizer 
05:00:59 <ochkep> Donation information
05:00:59 <ochkep> URI: bitcoin:bc1qyv7kug65090hq8yhzp76q2kvujt69p9pdxrjd7?amount=0.03000000&label=MoveOn&message=MoveOn%202020
05:01:00 <ochkep> Address: bc1qyv7kug65090hq8yhzp76q2kvujt69p9pdxrjd7
05:01:19 --- mode: ChanServ set +q *!*@fixed-187-188-177-153.totalplay.net
05:03:49 <__monty__> Doesn't look like a scam at all...
05:30:08 <dminuoso> hpc: Interesting, why do you use ^K/^J? Is that an emacs thing?
05:40:25 <Jinna> Is there an existing streaming lib (pipes, concurrent-machines, conduit, folds, etc) that works on top of postgresql-simple?
05:54:31 <dminuoso> Jinna: There appears to be https://hackage.haskell.org/package/streaming-postgresql-simple on hackage
05:55:31 <dminuoso> Jinna: You could of course use stm-conduit yourself 
06:52:18 <Jinna> dminuoso: thanks for the tip about the streaming lib. What do you mean by stm-conduit? What connection does this have to pg-simple?
06:52:32 <dminuoso> Jinna: none, but you can build your own streaming.
06:53:36 <Jinna> dminuoso: how would that work? In pgsimple I can use the `fold` function. But I think it has to run in one go. It will not act as a sink and block until some other thread tries to pull things out of it.
07:23:42 <dminuoso> Jinna: You'd just stream into a TMChan
07:24:26 <phadej> dminuoso: you are over-enginering whatever Jinna asks about
07:25:17 <phadej> they wanted to do few folds with only single traverse of result set using https://hackage.haskell.org/package/postgresql-simple-0.6.2/docs/Database-PostgreSQL-Simple-Cursor.html#v:foldForward (as far as I understan)
07:25:25 <phadej> you don't need STM for that
07:25:29 <phadej> KISS please.
07:26:04 <phadej> sadly I have no time to explain how to use e.g. foldl package to do that nicely
07:26:43 <phadej> (or actually this one: https://hackage.haskell.org/package/postgresql-simple-0.6.2/docs/Database-PostgreSQL-Simple.html#v:fold, but same technique would apply)
07:35:32 --- mode: ChanServ set -q *!*@fixed-187-188-177-153.totalplay.net
07:58:37 <dminuoso> This is so strange... `• Non type-variable argument in the constraint: MonadReader Env m(Use FlexibleContexts to permit this)` but the extension is enabled via language pragma.
07:59:13 <merijn> dminuoso: You sure you don't have FlexibleInstances?
07:59:36 <dminuoso> merijn: Yes.
07:59:43 <merijn> ghci?
07:59:47 <AndreasK> I wonder why Array allows arbitrary lower bounds instead of just enforcing zero (or one I guess) based indexing.
07:59:56 <dminuoso> merijn: Ah mmm, its ghcid.
08:00:01 <merijn> AndreasK: Well, why would it?
08:00:07 <dminuoso> merijn: Nope, same issue with cabal new-build
08:00:46 <AndreasK> merijn: Seems to me it provides little benefit but comes with a performance cost.
08:00:55 <dminuoso> merijn: https://gist.github.com/dminuoso/77718083bf7ace276d3e48f060a13b8e
08:01:02 <merijn> AndreasK: Array has a whole bunch of overhead anyway
08:01:56 <merijn> dminuoso: Spoiler alert: Check the colour of your pragma on github ;)
08:02:07 <dminuoso> merijn: Ohhh man.
08:02:18 <dminuoso> How does GHC even accept this? :<
08:02:28 <dminuoso> 20 minutes of my life for this.
08:02:34 <dminuoso> Thanks. :)
08:02:42 <AndreasK> dminuoso: With the proper flags it should warn about unknown pragmas
08:03:16 <dminuoso> AndreasK: Well its not that the pragma was mispelled, it was the "LANGUAGE" that was miswritten. Does the warning include this?
08:05:08 <AndreasK> dminuoso: Yes, LANGUAGE is the pragma in this case
08:05:30 <AndreasK> https://www.irccloud.com/pastebin/bj33w8CC/
08:27:32 <solonarv> dminuoso: I write LANGAUGE embarrassingly often
08:27:42 <solonarv> although so far I have always noticed before compiling
08:28:15 <dminuoso> solonarv: That's reassuring. :)
08:31:47 <solonarv> if I were smarter/lazier I would have configured things so just typing lan<tab> writes LANGUAGE
08:54:09 <dmwit> solonarv: If you vim, https://gist.github.com/dmwit/88c2c9806191075b32b491864efaafc9
08:54:56 <dmwit> H# HL to insert {-# LANGUAGE <cursor here> #-}
08:55:31 <dmwit> In normal mode, \l will insert language pragmas and leave your cursor wherever it is in the file; e.g. \lck for ConstraintKinds, \leq for ExistentialQuantification, etc.
08:55:39 <solonarv> cool!
08:56:12 <dmwit> The rule is "just the upper case letters of the extension name, unless that's ambiguous, in which case add one lower case letter after the last upper case one".
09:30:28 <tabaqui> I have some monad -> data dependency, like "class MonadFoo m ch | m -> ch where pull :: ch a -> m a" or "class MonadFoo m where type Channel ch; pull :: ch a -> m a". And I want to defined new type, that can hold any appropriate "ch" inside. Like "data SomeChannel where SC :: ch Int -> SomeChannel", so I could easily unbox it and use in function "foo :: MonadFoo m => SomeChannel -> m Int; foo (SC ch) = pull
09:30:31 <tabaqui> ch"
09:30:39 <tabaqui> But I cannot compile data declaration
09:30:52 <tabaqui> I don't know type families well, actually
09:31:01 <tabaqui> Can I even do such things in Haskell?
09:31:53 <tabaqui> "data SomeChannel = (MonadFoo m ch) => SC ch" doesn't work obviously
09:32:44 <tabaqui> s/SC ch/SC (ch Int)/
09:51:55 <tabaqui> yeah, well, I can make it works, by adding m as nominal type into SomeChannel definition. Like "data SomeChannel m = SC (Channel m Int)"
09:52:18 <tabaqui> but I would like to make it monomorphic
09:56:38 <solonarv> you can define your typeclass like so: class MonadFoo m where Channel m :: Type -> Type; pull :: Channel m a -> m a
09:56:43 <tabaqui> oh, it's logically impossible
09:56:59 <tabaqui> yeah, I did
09:57:18 <tabaqui> but I just realized that I cannot pass the same SomeChannel into different MonadFoo instances
09:57:52 <solonarv> then you can write: data SomeChannel where MkSomeChannel :: MonadFoo m => Channel m Int -> SomeChannel
09:58:23 <solonarv> yes, if you have a 'SomeChannel' value that means whoever created the value already decided what 'm' should be in there
09:58:48 <tabaqui> nope, one cannot use this trick with MkSomeChannel
09:59:12 <tabaqui> solonarv: and not just decided, but also wiped from type signature
10:01:28 <solonarv> yes
10:01:55 <solonarv> it really sounds like you just want a plain old parameterized data type, I don't know what you're trying to accomplish with this existential stuff
10:03:00 <tabaqui> Some MonadMock for tests, that behave like TQueue in release IO code and like some pure storage in (State TestState) test code
10:08:31 <merijn> I agre with solonarv, a parameteric data type is the way to go
10:08:56 <merijn> existentials inevitably end up sucking and making you wrtie tons of boilerplate
10:48:02 <alx741> what would be the equivalent of counduit/pipes in other languages? say python, java, etc...
10:49:13 <wildtrees> iterators or coroutines? 
10:49:56 <voyons_osti> i'm trying to write a type like `data Thing = Empty | One Thing | Two Thing Thing | Three Thing Thing Thing` ... 
10:50:02 <voyons_osti> is there a way to do this? 
10:50:18 <tabaqui> in Python: generators(for ...: yield), iterators(__iter__ and __next__ keywords)
10:51:27 <tabaqui> voyons_osti: if you mean infinite production, than you cannot do this. In case of finite but big production, you can use TemplateHaskell to generate datatype
10:52:04 <voyons_osti> tabaqui, aw, okay thanks
10:54:07 <alx741> will take a look, thanks
10:56:02 <solonarv> voyons_osti: actually, if you want infinite you can use a vector (well, "infinite" - it's limited by memory, of course)
10:57:25 <solonarv> then your type is just 'Fix Vector' (Fix is from e.g. recursion-schemes)
11:02:32 <voyons_osti> solonarv, from https://hackage.haskell.org/package/vector ? 
11:05:14 <solonarv> yup
11:05:33 <solonarv> although I confess I'm not entirely sure what you want to *do* with that type
11:05:59 <voyons_osti> i'm experimenting with this problem: https://leetcode.com/problems/generate-parentheses/
11:07:30 <shafox> For emacs, do i need both haskell-mode and intero or just one of these not both ? 
11:11:37 <voyons_osti> solonarv, `newtype Fix f = In { out :: f (Fix f) }` ? 
11:11:52 <solonarv> yes, that's the one
11:12:03 <voyons_osti> thanks
11:17:37 <jgt> is it possible to write this function? coerceAsText :: (Coercible a b) => a -> Text
11:18:04 <jgt> or phrased another way, is it possible to specialise `coerce` to produce a Text?
11:22:07 <solonarv> you can't write 'foo :: Coercible a b => a -> Text', no - 'b' has nothing to do with 'Text'
11:22:10 <solonarv> I mean
11:22:17 <solonarv> you can of course just return the same constant Text every time
11:22:32 <jgt> ah, but that would be definitely the wrong thing
11:22:57 <solonarv> yes :P
11:23:13 <solonarv> but you can just write 'foo :: Coercible a Text => a -> Text; foo = coerce'
11:23:16 <jgt> I know I can always do `coerce foo :: Text` inline, but the double colon doesn't play nicely with shakespearean templates
11:23:33 <jgt> oh really?
11:23:42 <jgt> cool!
11:23:42 <solonarv> of course! why would that not work?
11:23:54 <jgt> …because I'm a charlatan?
11:24:21 <jgt> I'm only in this IRC channel because I used to hang out with a guy called Monad at school
11:33:23 <jgt> solonarv: worked just fine with FlexibleContexts
11:33:27 <jgt> thanks for that
12:02:38 <tst3> Is the following possible: I've a local project, built/installed using "cabal new-install"
12:03:00 <tst3> Now, on a different directory on this very same machine, I want to be able to load it into ghci
12:03:23 <tst3> it's a library, to be clear
12:10:05 <Geekingfrog> Given an ADT: data Foo = Bar String | Baz Int, and a list of Foo, how can I do `findBar :: [Foo] -> Maybe String`. I have `find`, but then I'm forced to extract the string from the Bar and ghc complains about the non-exhaustivity. Is there a "standard" function for that?
12:11:18 <tabaqui> % :t find
12:11:18 <yahb> tabaqui: Foldable t => (a -> Bool) -> t a -> Maybe a
12:11:48 <ziman> you can just return Nothing in the (unreachable) Baz case ;)
12:11:50 <tabaqui> findBar = find (\case { Bar{} -> True; Baz{} -> False})
12:11:58 <Geekingfrog> I would get a Bar there, but I want the thing inside the Bar.
12:12:06 <Geekingfrog> yeah, I could do that ziman
12:12:19 <tabaqui> % find (\case { Left{} -> True; Right{} -> False}) [Left "asd", Right 1, Left "123"]
12:12:20 <yahb> tabaqui: Just (Left "asd")
12:12:26 <tabaqui> % find (\case { Left{} -> True; Right{} -> False}) [Right 5, Right 1, Left "123"]
12:12:26 <yahb> tabaqui: Just (Left "123")
12:12:30 <tabaqui> % find (\case { Left{} -> True; Right{} -> False}) [Right 5, Right 1]
12:12:30 <yahb> tabaqui: Nothing
12:12:45 <tabaqui> oh, ok
12:13:06 <ziman> but otherwise you might consider a list comprehension (listToMaybe [s | Bar s <- xs]) or a custom function
12:13:47 <tabaqui> yeah, comprehension is the best solution here, as I think
12:14:17 <Geekingfrog> uhm, let me try a prism from generic-lens and see how heavy it is.
12:26:08 <tabaqui> oh yeah, I found an example of code, where data cannot be replaced with newtype
12:26:09 <tabaqui> damn
12:26:37 <tabaqui> I mean the definition itself can be compiled, but it will cause errors in dependent module
12:31:02 <dmwit> tst3: That is definitely possible, so hang around for somebody who's more expert than me.
12:31:24 <dmwit> tst3: If you don't mind making a project in that other directory, then it's even quite easy: just list the path in your cabal.project file.
12:31:34 <dmwit> But I think it's possible even without doing that.
12:32:54 <dmwit> tst3: Perhaps take a peek at https://github.com/hvr/cabal-env
12:34:16 <dmwit> % data Foo = Bar String | Baz Int
12:34:16 <yahb> dmwit: 
12:34:31 <dmwit> % :t foldMap (\x -> case x of Bar s -> Just s; _ -> Nothing)
12:34:31 <yahb> dmwit: Foldable t => t Foo -> Maybe String
12:34:56 <dmwit> % :t foldMap (\case Bar s -> Just s; _ -> Nothing)
12:34:56 <yahb> dmwit: Foldable t => t Foo -> Maybe String
12:35:31 <dmwit> Oh, actually, that's... probably not what you want. =P
12:35:58 <dmwit> There's First. But the list comprehension one is probably better anyway.
12:42:50 <tst3> Is it possible to tell ghci which package db to use?
12:43:03 <tst3> ghci -package-db=new-location doesn't seem to work
12:43:35 <wildtrees> tst3, you might want stack or nix for something like that 
12:46:54 <merijn> wildtrees: Stack doesn't help, as that requires an explicit project, just like v2-repl does
12:46:55 <monochrom> -package-db works. Perhaps new-location wasn't set up properly.
12:47:04 <monochrom> http://www.vex.net/~trebla/haskell/sicp.xhtml#sandbox
12:47:28 <merijn> tst3: If you're inside a cabal.project directory ghci should automatically use the right one, alternatively you can use this cabal environment stuff dmwit linked
12:50:16 <jedai> -package-db takes a file as parameter, not a path
12:50:26 <jedai> (not a folder path)
12:50:41 <monochrom> It can be a folder.
12:51:02 <monochrom> http://www.vex.net/~trebla/haskell/sicp.xhtml#sandbox
12:52:18 <jedai> monochrom: Right, sorry the usage of <file> confused me. https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/packages.html#package-databases
13:04:51 <garvis> Good evening everyone, I'm stuck with a problem, and I'm not sure I'm facing up to it properly. Hope someone can help
13:05:55 <Rembane> garvis: Tell us the problem and we'll soon find out.
13:06:08 <garvis> I'd like to define a class to define a partial order among some data types, I'm defining "class TypeOrd a where"
13:06:46 <garvis> and then I'd like to let define as a minimal complete definition an operator "<" that lets the user to define the order among data types
13:07:00 <garvis> but I'm stuck in defining the transitivity property
13:08:07 <garvis> I mean, if I define the operator (<) such that "B < I" and "I < F", I expect to have positive answer if I ask "B < F"
13:08:38 <garvis> I don't know, maybe I'm thinking a bit too much in logic programming style
13:08:43 <dmwit> Such typeclass laws are generally not checked by the compiler.
13:08:57 <dmwit> (Or enforced/ensured by the compiler.)
13:09:06 <dmwit> It is on each individual instance writer to make sure they hold.
13:09:47 <garvis> so I should define the instance such specifying also "B < F" in my previous example?
13:10:07 <dmwit> e.g. for Semigroup it is expected and documented that `x <> (y <> z) = (x <> y) <> z`; but one can write an instance where this doesn't hold and the compiler won't notice or prevent it.
13:10:14 <dmwit> garvis: For example, yes.
13:10:43 <garvis> ok I see
13:10:47 <dmwit> You may of course use whatever decision procedure you like; if you want to program up a function which takes in a list of pairs and finds its transitive closure, and use that to implement (<), you are by all means invited to do so.
13:10:51 <jgt> is there a reason why many of the latest Yesod-and-related-packages docs are all broken on Hackage?
13:11:45 <jgt> this doesn't have any docs, though the previous version does: http://hackage.haskell.org/package/classy-prelude-yesod-1.5.0
13:12:07 <jgt> and then you follow the link to stackage and check the docs there, and you get NoSuchKey: https://www.stackage.org/haddock/nightly-2019-07-07/classy-prelude-yesod-1.5.0/ClassyPrelude-Yesod.html
13:12:16 <garvis> dmwit: oh ok great, probably that's a best fit with what I had in mind
13:13:15 <dmwit> jgt: Curious. The build log says that the docs failed, but has no errors in the actual log text.
13:13:39 <dmwit> jgt: Perhaps the doc builder just died for unrelated reasons in the middle or something.
13:13:56 <dmwit> jgt: If you poke the maintainers, I think they can click a button to request a second attempt at building the documentation.
13:14:15 <jgt> dmwit: this seems to be the case for several packages, and it's been this way for a while
13:14:21 <jgt> at least a few weeks
13:14:26 <garvis> dmwit: now everything is more clear, many thanks!!
13:31:21 <butterthebuddha> newline :: (MonadParsec e s m, Token s ~ Char) => m (Token s)
13:31:30 <butterthebuddha> What does the ~ in the type signature mean?
13:31:40 <ski> type equality
13:32:07 <ski> `Token s' is presumably a type family, or an associated type, which is indexed by the parameter `s'
13:32:28 <Io> what is haskell especially good for
13:32:41 <phadej> _everything_
13:33:07 <ski> @quote world's.best
13:33:07 <lambdabot> _pizza_ says: i think Haskell is undoubtedly the world's best programming language for discovering the first few dozen numbers in the Fibonacci sequence over IRC
13:33:07 <Io> does it have a niche?
13:33:19 <ski> hehe
13:33:23 <Io> haha
13:33:33 <ski> @quote is.the.world's.best
13:33:33 <lambdabot> SPJ says: Haskell is the world's best imperative language.
13:33:40 <ski> that was the one i was looking for :)
13:34:03 <Booooorja> Why is that better that python functional style?
13:34:09 <ski> Haskell is good when it's important that your program does what you wanted it to do
13:35:09 <ski> Booooorja : Python doesn't support FP idioms that well (by design, GvR won't allow it)
13:35:45 <jedai> Io: Haskell has been used in several fields: * compiler/ formal language processing * high assurance programming for diverse applications (including generating embedded programs) * web servers * finance ....
13:35:59 <ski> Io : Haskell shines especially well when it helps to make Problem Domain Specific Languages, i'd say
13:37:01 <Io> hmm so what would recommend as a beginner project for learning haskell
13:37:27 <ski> depends on what kind of stuff you're interested in
13:37:41 <ski> perhaps an IRC bot ?
13:38:01 <jedai> lo: You can do anything with it of course but if I had to spot a weak point, that would be complex GUI programming (there are libraries, so you can do it but they're definitively not idiomatic Haskell and the better alternatives are somewhat immature or partially applicable to a big GUI application)
13:38:18 <ski> if you like math, you could perhaps try solving Project Euler problems with it
13:38:54 <Io> I love math.
13:39:03 <Guest20829> It's a mystery why the Haskell GUI scene is like that when Elm and other FRP languages are the best ways to build GUI's
13:39:28 <dmwit> Io: A regex -> DFA compiler is always a fun exercise to learn a language.
13:40:01 <dmwit> Io: Or write a roguelike!
13:40:07 <boj> Guest20829: that is a very web-centric comment, of which reflex-dom/miso seem to do a suitable job
13:40:07 <jedai> building "Web" interface in Haskell is pretty good though
13:40:09 <Io> what is a roguelike
13:40:33 <dmwit> A game that is "like rogue" (one of the earliest games in this particular genre).
13:40:39 * ski idly glances in the general direction of conal land
13:41:00 <conal> regex -> DFA is also a great application of denotational design.
13:41:06 <dmwit> You can see lots of examples online, but if you haven't played a few already, implementing one probably won't hold much appeal for you.
13:41:26 <Io> sounds like a lot of fun actually
13:41:35 <dmwit> Yay!
13:41:49 <dmwit> "Sounds like fun" is an important metric by which to judge intro projects.
13:42:08 <ski> "having fun" is important for learning
13:42:18 <Io> top 3 i would say
13:42:37 <Booooorja> I wanna go into haskell, but I'm afraid I would not give me everything what I need
13:43:54 * ski . o O ( "What nobody tells you about documentation" by Daniele Procida at <https://www.divio.com/blog/documentation/> )
13:44:27 <ski> Booooorja : you should aim towards multiple languages, anyway. the more different, the better
13:45:00 <isovector1> I'm planning on traveling around the world and would love to meetup with as many people here as is possible. If you're interested, please fill out my form! https://isovector.github.io/erdos/
13:45:21 <ski> (and learning never stops, there's always more things to learn. don't think you're ever finished learning)
13:46:00 <Io> it's just that with so many things popping up it is hard to make up one's mind about what to learn next
13:46:11 <Io> for instance i came up with haskell when picking a wm
13:46:21 <Io> saw xmonad although looked kind of intimidating
13:46:26 <Io> went for i3
13:46:38 <Io> Im trying to learn rust atm too
13:46:58 <Io> it is easy to get overwhelmed, you kind of want to learn relevant technologies
13:47:49 <[exa]> 'relevant to what' is probably the question you want to answer first
13:49:42 <Io> just starting cs, idk where this is going to take me... 
13:49:54 <Jonathan93> Anyone here?
13:50:31 <dmwit> Nope, nobody.
13:50:36 <dmwit> This is a bots-only channel.
13:50:51 <Jonathan93> lol
13:51:58 <dmwit> ski: Thanks for the documentation article.
13:52:03 <jedai> 1257 bots
13:52:05 <ski> Io : try it for a bit, and see how you like it ?
13:52:31 <Jonathan93> I have been pulling my hair out this morning trying with a TCP server.  I am working with the `Network` library.  I need to `accept` but without blocking.  Basically I want any accept that immediately returns with a `Maybe NewSocket`.
13:52:40 <ski> dmwit : yw :)
13:52:51 <dmwit> Jonathan93: I challenge your claim that you need to `accept` without blocking.
13:52:55 <Jonathan93> It figured it should be a super simple common need.
13:53:00 <dmwit> Can you say carefully why you believe that to be true?
13:53:34 <Jonathan93> Okay, I guess I do not **need**...
13:53:56 <dmwit> Great! So, problem solved...? ;-)
13:54:34 <Jonathan93> The only way it seems to get connections while still having code executing is with threads, correct?
13:54:45 <Jonathan93> Or, the only way with `Network` library.
13:54:45 <dmwit> Yes. Please use threads. Use lots of threads, we love threads.
13:54:54 <Jonathan93> Really?
13:55:03 <jedai> Jonathan93: threads are really good in Haskell
13:55:08 <leifm> Oh yeah threads
13:55:11 <dmwit> (Perhaps you are coming from another language, where "threads are expensive" is a folklore fact. This is not true of Haskell threads.)
13:55:27 <Jonathan93> I guess I am fairly new to Haskell.
13:55:31 <jedai> Jonathan93: they're "green threads" that are very cheap and efficient
13:55:47 <Jonathan93> And with purity and Haskells green threads it is efficient.
13:56:00 <hyperisco_> Application thread vs OS thread
13:56:52 <jedai> Jonathan93: plus we have very good support for several type of parallelism and concurrency, Haskell is one of the best in the field (some languages like Erlang may be "better" in their specific idioms though)
13:57:26 <dmwit> Jonathan93: See also https://stackoverflow.com/a/11744780/791604
13:58:06 <Jonathan93> I love that answer dmwit.
13:58:10 <Jonathan93> lol
13:58:29 <dmwit> <3
13:59:03 <Jonathan93> So if you could help me a little with some logic of it then I would appreciate it!
13:59:09 <conal> dmwit: I just saw your message about AD from a few days ago. I'm glad you enjoyed that talk. I like the affine-approximation angle. The needed laws about affine approximations (for sequential composition, parallel composition, and affine functions) would seem to hold. And one can extend to truncated or full Taylor series.
13:59:13 <dmwit> Jonathan93: Hit us up!
13:59:24 <Jonathan93> Your awesome...
13:59:39 <dmwit> conal: The only wrinkle is that representations are nice because they're much easier to inspect.
14:00:01 <dmwit> conal: So perhaps for efficiency you want the pair version anyway. I hadn't managed to work through the details of how it would affect the efficiency of AD.
14:00:23 <dmwit> conal: e.g. maybe the sharing is harder to observe in affine-world or something.
14:00:42 <Jonathan93> I am working on a funny game. 
14:01:13 <conal> dmwit: both linear and affine can be represented via functions or "data", can't they? i don't expect sharing preservation to be any harder.
14:01:25 * dmwit nods agreeably
14:01:38 <conal> key is to formulate independently of any particular representation of linear or affine maps.
14:02:03 <conal> formulate the instances of category, cartesian, etc.
14:03:18 <dmwit> In any case it's definitely going to take me more cycles to absorb your paper. It looks awesome, though, thanks for revealing this bit of beauty!
14:03:34 <conal> dmwit: :)
14:04:34 <hyperisco_> Where is the recording?
14:05:11 <conal> hyperisco_: https://github.com/conal/talk-2018-essence-of-ad/blob/master/readme.md, and follow links
14:05:42 <hyperisco_> thanks!@
14:06:39 <conal> dmwit: there's a lovely way to derive correct (and efficient I think) arithmetic on univariate and multivariate polynomials and power series in http://conal.net/papers/convolution/. Could be useful for a power series category that embodies all orders of derivatives.
14:07:59 <dmwit> Neat, I'll add it to my list!
14:08:34 <Jonathan93> I have an update loop that updates the Ship of the game which each client has a part of controlling.  The clients issues different commands (over the network) to the Ship and the resulting state of the ship gets calculated in the loop and the changes need to be sent to each client.  Do I have some sort of a queue of messages that needs sent to each
14:08:34 <Jonathan93>  client that each thread reads from?
14:09:09 <dmwit> Uh-oh, Cofree.
14:09:14 <dmwit> I might not make it through this paper. =P
14:09:16 <conal> i had wanted to understand whether "derivatives" of regular expressions (for elegant and efficient recognition) is indeed a special case of the generalized AD algorithm in my paper & talk. i don't think it is, but i learned some interesting things on the way.
14:09:55 <conal> dmwit: Cofree is the natural trie (memoization) for functions on lists, which i hadn't realized.
14:10:07 <dmwit> Jonathan93: Sure, use a Chan. You can duplicate the channel for multicast using dupChan.
14:10:34 <conal> list tries were the original tries from Thue in 1912, long before they were generalized to arbitrary algebraic data types.
14:11:08 <dmwit> err
14:11:19 <dmwit> Is that Cofree [] that you're talking about, or something else?
14:11:56 <dmwit> Perhaps: `Cofree (TMap k) v` is tries for memoizing `[k] -> v` or so?
14:11:57 <conal> DFAs come from memoizing functions from "strings" to Bool, ie language recognizers. Then generalize from Bool to any semiring.
14:13:02 <conal> dmwit: Cofree f where f represents functions from list elements (e.g., characters).
14:13:21 <conal> dmwit: so, yes, for instance TMap k
14:13:22 <Jonathan93> So I write the messages to the "channel" which client thread loops through to send the messages?
14:13:29 <dmwit> conal: Got it. Sensible enough.
14:13:46 <dmwit> conal: I guess there's still some question about getting the knot tied up right, but I suppose the paper covers such details.
14:14:42 <infinisil> Jonathan93: Well, if you can send a single message, you can send multiple messages just by looping over them
14:14:44 <dmwit> Jonathan93: Right. One central thread is in charge of keeping track of the Ground Truth about the Ship. It writes update events to a Chan. There's one thread per client connection, and they each get a copy of the Chan to read those events from.
14:14:56 <infinisil> Ah, I guess I'm missing context
14:15:43 <conal> dmwit: indeed. one can use the vocabulary of *closed* ("star") semirings or express grammars recursively.
14:16:10 <voyons_osti> hi, i'm trying to write a general version of this function , but i'm having trouble even getting the types right
14:16:11 <voyons_osti> https://gist.github.com/dan-so/7125272c38b2a35a84172ef8907bd66a
14:16:15 <voyons_osti> is there a way to do this? 
14:16:22 <dmwit> Hm. Is star the only place where a knot needs to get tied?
14:16:24 <conal> dmwit: the technique applies beyond regular languages. some non-regular examples are in the paper.
14:16:41 <Jonathan93> dmwit: Hum, okay that make logical sense.  Although why does that make more sense than just putting the message on the send queue of the socket?
14:16:59 <infinisil> voyons_osti: You can't write this generalized in standard Haskell
14:17:01 <dmwit> One thing I've been thinking about recently is generating "random" strings from a language of infinite strings, generated from a grammar in the usual way.
14:17:02 <conal> dmwit: for regular languages yes, but for non-regular no.
14:17:05 <dmwit> Perhaps this paper can help with that.
14:17:16 <infinisil> voyons_osti: You'd need TemplateHaskell for that
14:17:30 <conal> dmwit: yes, i think so. i think you'd choose a related semiring.
14:17:35 <dmwit> Jonathan93: I'd assume that sending on a socket can block. So you don't want the central thread doing that.
14:17:44 <voyons_osti> infinisil, aw, okay thank you 
14:18:03 <conal> dmwit: a single program can be polymorphic over semiring, and you get multiple interpretations.
14:18:13 <Jonathan93> dmwit: I guess as you so, these green threads don't really add any overhead...
14:18:13 <dmwit> Jonathan93: (Sending on a Chan doesn't block. Although if you don't empty your Chans out regularly you might find yourself using a bit more memory than you expected... =P)
14:18:17 <hyperisco_> dmwit, what is the thought wrt infinite languages?
14:18:26 <conal> dmwit: preferably related by homomorphisms. 
14:18:41 <conal> (semiring homomorphisms, as in the paper)
14:18:58 <Jonathan93> dmwit: Right (:  I guess I can see the elegance of that.
14:19:06 <voyons_osti> infinisil, is it possible if the type is [[Int]]?
14:19:16 <infinisil> voyons_osti: Indeed
14:19:34 <conal> and relaxing from lists to other monoids give rise to things like temporal and spatial convolution and probabilistic programming.
14:19:35 <Jonathan93> dmwit: Thanks for your help!
14:20:23 <dmwit> hyperisco_: Mmmm. Well... music often has a quite recursive-looking structure. e.g. a symphony might have three parts, in keys related by a fifth. And then within each piece, there will be subsections where there's a sort of "home chord", related by a fifth to the key of the piece. And then there will be phrases in the subsection related by a fifth...
14:20:51 <voyons_osti> infinisil, using a list comprehension? i don't see how
14:20:52 <dmwit> (There are other relationships than a fifth. But you can describe a surprising number of pieces with a pretty small grammar.)
14:21:23 <infinisil> voyons_osti: Nah the implementation will look different
14:21:35 <dmwit> hyperisco_: Now imagine I want to just start generating structured music. So I generate a phrase. But then I want to continue that phrase, with a larger structure that comes from the grammar, too. And then embed that in a larger structure, and so on, as long as the listener cares to listen.
14:22:39 <infinisil> voyons_osti: Well actually, you could use list comprehension when you write generate_list_n in terms of generate_list_(n-1)
14:23:07 <infinisil> Maybe
14:23:18 <voyons_osti> i need arbitrarily large numbers though :v( 
14:23:34 <infinisil> Which is a problem because?
14:24:15 <infinisil> You can write a generalized `generate :: Int -> [[Int]]` is what I'm saying
14:24:16 <voyons_osti> doesn't that way require functions generate_list_n 
14:25:04 <infinisil> Yeah sorry that was a bit confusing, I meant to say write `generate n` in terms of `generate (n - 1)`
14:25:05 <hyperisco_> dmwit, I see
14:25:51 <hyperisco_> dmwit, well I thin I can tell you how to enumerate a language in order of word length
14:25:55 <hpc> dminuoso: bit late, but it's a terminal thing - ^K is delete after cursor and ^J is enter
14:26:03 <dmwit> hyperisco_: Anyway I haven't sat down with a pencil and paper to think carefully about it, but my gut says there's going to be oddities. Like, how do you pick a very first chord sequence in a way that is "uniform" over all sensible starting sequences? What does "uniform" even mean when we're talking about an uncountably big set? Is it sensible to have a grammar where some symbols are both terminal and 
14:26:09 <dmwit> nonterminal? What exactly is going on there?
14:26:54 <hyperisco_> Then it is a matter of using randomisation to filter what should follow… yeah I can see this happening
14:27:07 <hyperisco_> Musical though? I doubt it :P
14:28:10 <hyperisco_> I am not sure how you construct a grammar that can only produce musical things
14:28:13 <dmwit> I dunno. I was pleased with my preliminary (non-recursive) results.
14:28:32 <hyperisco_> If your grammar can just produce any note, then you're going to get random notes
14:29:08 <dmwit> I expect the grammar will produce chord progressions. There's a known and smallish set of rules about what chord progressions sound pretty good.
14:29:23 <hyperisco_> if you're going to filter what comes next from what came prior then I don't know if the problem actually has to do with grammars
14:29:33 <wildtrees> hyperisco_, have you looked at harmtrace , iirc, on hackage? it uses grammars for music I believe, but it only compiles with the 7.10.x series at the latest
14:29:39 <hyperisco_> but is moreso a problem of given this piece of music what is a piece of music that could follow?
14:30:10 <dmwit> I have some code up on github somewhere that takes an arbitrary melody and finds a good-sounding chord progression to go underneath it, using HMMs to model what chords sound good after what other chords.
14:30:14 <dmwit> Let me see if I can find it...
14:30:33 <dmwit> Ruby, though. =P
14:32:14 <wildtrees> HMMs?
14:32:43 <dmwit> https://github.com/dmwit/twitch-music/blob/master/experiment.rb#L247-L251
14:32:52 <hyperisco_> Yes you could have a grammar for chord progressions. Given this chord what chords could follow? Then you can choose from that list.
14:33:20 <hyperisco_> However… there will be no cohesion over the whole
14:33:25 <hyperisco_> just from one chord to the next
14:34:12 <dmwit> Yep. I want the grammar stuff to provide the cohesion.
14:34:34 <dmwit> e.g. if the only rule was I -> I V I, this would ensure that you always "come back home"
14:34:39 <wildtrees> hyperisco_, this? http://hackage.haskell.org/package/HarmTrace 
14:34:51 <dmwit> Of course, you could only generate one progression. =)
14:36:25 <hyperisco_> I think you could have luck with CSGs
14:38:13 <hyperisco_> because lets see with CFGs… so if you have  I -> I x y I  then  x  needs to start with something that is good after I, and y needs to end with something that is good before I, and x must end with something that is good before whatever y starts with
14:39:02 <dmwit> Ah, nah.
14:39:12 <hyperisco_> one variable alright… so with  I -> I x I  then x must start with something good after I and end with something good before I
14:39:13 <dmwit> Just treat x as an I and generate a structure there. Then transpose.
14:39:45 <dmwit> So two steps of I -> I V I would be I -> I V I -> I V I V V/V V I V I
14:40:03 <hyperisco_> oh you're doing rewrite rules
14:40:13 <dmwit> I -> I V I -> I V I    V V/V V   I V I -- if the spacing helps
14:40:57 <hyperisco_> maybe this is doable in CFG with a lot of rules
14:41:18 <dmwit> I think it shouldn't really need that many.
14:41:45 <dmwit> Remember we get to walk the parse tree, not just the string produced by the parse tree, when generating the actual music.
14:42:09 <dmwit> So all major chords get the same productions, all minor chords get the same productions.
14:42:22 <dmwit> Diminished chords... don't think about diminished chords, okay? =P
14:43:13 <wroathe> On the GHC 8.6.5 release branch I'm getting "error: Server does not allow request for unadvertised object def8c55d0c47c1c40de985d83f052f3659b40cfd" when trying to update the transformers submodule. Is this just a mistake in the repo or am I doing something wrong?
14:43:32 <wroathe> git submodule update --init --recursive
14:43:50 <hyperisco_> there are how many chords, lets say n
14:44:30 <dmwit> Let's say 14.
14:44:33 <hyperisco_> so I think you can get away with around n^2 rules
14:44:43 <dmwit> I plan to get away with just two rules.
14:44:47 <dmwit> err
14:44:55 <dmwit> Two nonterminals, I guess.
14:45:02 <dmwit> "major" and "minor"
14:45:19 <dmwit> Use my HMM for the productions.
14:46:19 <hyperisco_> for every start chord "A" and end chord "B", you can have production rules  AB_0 ::= ...  AB_j ::= ...  for each pair that sounds good after A and before B
14:47:07 <hyperisco_> AB_0 ::= "C" CD "D";  AB_1 ::= "E" EF "F"   for example
14:47:27 <hyperisco_> and then  CD  is a nonterminal for progressions that start with C and end with D, and so on
14:48:40 <hyperisco_> though you also need some way to tie the ends together, so figure out that
14:50:03 <hyperisco_> Then of course to get a progression that comes home you just start with AA or something
14:50:21 <hyperisco_> 14*14 is only 196 so get cracking :P
14:50:50 <hyperisco_> well actually that is just the number of pairs… for each pair there are up to n productions for pairs that sound good with them
14:50:53 <hyperisco_> so… 14*14*14
14:51:25 <wroathe> Ah, I think I figured it out. While the GHC repo on git.haskell.org is being kept up to date with gitlab.haskell.org it seems that the transformers package is not
14:51:36 <wroathe> Yup. That was it.
14:52:00 <wroathe> And the .gitmodules file has relative URLs
14:52:39 <dmwit> hyperisco_: I think you and I have very different plans and goals in mind.
14:52:47 <hyperisco_> or is it 14^4
14:53:07 <hyperisco_> I'm just generating all chord progressions that have a deemed musical quality
14:54:46 <dmwit> Like I said: I believe I have a very nice-sounding set of productions already in place. It didn't require 14^4 work. It required 2*7^2 work.
14:57:13 <hyperisco_> I was just guaranteeing the progressions began and ended with a desired chord
14:57:28 <hyperisco_> using a CFG
14:58:28 <dmwit> Do you suppose it's possible that enumerating the productions is just one possible representation of a CFG, and there might be more compact representations of particularly regular sets of productions?
14:58:53 <dmwit> (Not "regular" as in regex. Just "showing patterns".)
14:59:16 <hyperisco_> there should be a more compact representation, but that doesn't change how many productions there actually are
15:00:01 <dmwit> (In fact, the grammar I have in mind is itself infinite!)
15:01:11 <hyperisco_> maybe you're using the wrong language class then
15:01:28 <dmwit> You started all this CFG talk, not me. =)
15:01:48 <hyperisco_> doesn't matter what it is
15:01:58 <hyperisco_> if it isn't closed then it doesn't seem right
15:02:10 <dmwit> What does "closed" mean?
15:02:29 <hyperisco_> finite
15:03:52 <hyperisco_> reason being that an infinite grammar can just trivially enumerate all the words
15:04:03 <dmwit> I don't think that follows.
15:04:24 <hyperisco_> what doesn't?
15:04:37 <dmwit> I don't think "the grammar is infinite" implies "the language contains all words".
15:04:44 <hyperisco_> it doesn't
15:04:53 <hyperisco_> the grammar is infinite means there is an equivalent grammar that just enumerates all the words
15:05:04 <hyperisco_> in a trivial way, so there is a production per word
15:05:12 * dmwit nods agreeably
15:05:21 <dmwit> Is that a problem for some reason?
15:05:30 <hyperisco_> yes
15:05:41 <dmwit> I'm listening.
15:05:58 <hyperisco_> because to do some analysis you're going to want to know what all the productions are
15:06:09 <hyperisco_> and to figure that out you're going to look at your finite representation of them
15:06:14 <dmwit> I can know that despite the existence of some other grammar that represents the same language.
15:06:47 <hyperisco_> if grammars were infinite then everything is regular
15:07:51 <dmwit> So what?
15:08:36 <hyperisco_> well then there's not much point talking about grammars if we're not figuring out what the actual (finite) grammar is
15:08:44 <dmwit> Why not?
15:08:51 <hyperisco_> because it isn't a grammar
15:09:15 <dmwit> Sounds circular to me.
15:10:41 <hyperisco_> well whatever, it is your problem, not mine. best of luck, I'm out for tonight
15:25:18 <butterthebuddha> Is there a do-notation type thing for Alternative?
15:27:40 <Nevoic> Hey, I'm seeing massively different performance characteristics between Python/Haskell. It seems Python generators out perform Haskell's lazy lists incredibly, even when I use those generators in Python to create lists.
15:27:57 <Nevoic> I'm getting 5x the time complexity in Haskell and 50x the space complexity (10GB vs. 200 MB)
15:28:24 <Nevoic> I've crashed my computer twice with the Haskell XD
15:29:00 <Nevoic> Does Haskell have any way of reconciling this difference?
15:29:01 <Rembane> Nevoic: Do you have an example? 
15:29:08 <Rembane> Nevoic: ...of code
15:29:15 <Nevoic> Yup! one second.
15:30:56 <Nevoic> https://cdn.discordapp.com/attachments/496210024498987009/597917335285661712/unknown.png there's the difference in memory space (the first jump is Haskell, the second is Python)
15:30:59 <Nevoic> code is inc.
15:31:24 <Nevoic> https://cdn.discordapp.com/attachments/496210024498987009/597917558833938451/unknown.png
15:32:20 <c_wraith> images aren't useful code.
15:32:33 <Rembane> Nevoic: I think laziness bites you. But please pastebin some code. 
15:32:45 <Rembane> Nevoic: My monitor is way too small for me to easily read your code.
15:33:15 <Nevoic> https://bpaste.net/show/tm62
15:33:17 <Nevoic> Haskell
15:33:30 <Nevoic> Python https://bpaste.net/show/oRuZ
15:33:42 <Nevoic> I accidentally posted it in the Python IRC lol
15:33:57 <Rembane> I'm sure they will enjoy it. 
15:34:30 <Nevoic> I don't see how laziness plays into this. Both lists are strictly evaluated because I get the last element of both.
15:34:40 <c_wraith> but notable points: 1. runhaskell is an interpreter designed only to start as fast as possible. compile for actual performance. 2. print isn't ideal. it actually grabs a lock for every single character of output.
15:35:04 <Nevoic> print is only printing 2 characters, is that actually making a noticeable difference in performance?
15:35:16 <c_wraith> ah, didn't realize that. no, then.
15:35:27 <Nevoic> the original images showed the output XD
15:36:17 <c_wraith> but yeah.. if you're doing performance testing, compile. otherwise you're running a worst-case interpreter.
15:36:30 <Nevoic> Compiling the Haskell and running that is noticeably faster.
15:36:34 <Nevoic> Good call.
15:36:49 <Rembane> ghc -O2 is good stuff too
15:37:35 <Nevoic> Oh wow that's even faster.
15:37:40 <Nevoic> Is there an O3? ;)
15:37:57 <c_wraith> nope! maxes out at 2. :)
15:38:07 <Nevoic> What's the O stand for?
15:38:17 <Rembane> Optimize! 
15:38:22 <Nevoic> really? lol
15:38:26 <c_wraith> though there is -fllvm which makes *some* code faster.
15:38:42 <c_wraith> I don't think it'll matter much there.
15:38:55 <Nevoic> Yeah didn't seem to make a noticeable difference.
15:39:11 <Nevoic> Is there anyway to compile and run the code without generating literally 3 extra files lol
15:39:21 <Nevoic> I like to make comparison folders and usually I try to keep it to one file per lang.
15:39:53 <Nevoic> and if not, maybe just redirect the compiled crap to an `out` dir or something?
15:40:19 <c_wraith> you can certainly do the latter.
15:41:00 <Nevoic> I could just write a short bash script called `runHaskellGood` and have it compile, run, and delete the files lol
15:41:05 <c_wraith> see https://downloads.haskell.org/~ghc/6.0/docs/html/users_guide/options-output.html
15:41:16 <c_wraith> um. wow, Google, indexing the old docs.
15:42:43 <c_wraith> more modern docs: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/separate_compilation.html#output-files
16:23:43 <dmj`> does anyone have an objective-c parser that actually works
16:43:04 <Nevoic> I'm extra confused now. So I'm compiling/running all my code, and found this really odd circumstance.
16:43:21 <Nevoic> Running this code: https://bpaste.net/show/xNqm everything is incredibly fast.
16:43:31 <Nevoic> wait
16:43:33 <Nevoic> that's the wrong file
16:43:58 <Nevoic> https://bpaste.net/show/7qxC this is the fast one. the results are at the bottom.
16:44:04 <Nevoic> https://bpaste.net/show/xVTk this is the slow one.
16:44:11 <Nevoic> the only line I changed was line 8.
16:44:33 <Nevoic> And changing that line made the *other* function slower.
16:44:40 <Nevoic> I don't understand how that's even possible.
16:46:01 <Axman6> did you compile both with optimisations turned on?
16:46:12 <Nevoic> Yup, I'm running both of them in the exact same way.
16:46:24 <Nevoic> ghc -O2 Timeit.hs
16:46:34 <Nevoic> then I run ./Timeit
16:46:44 <Axman6> it's possible GC is affecting you. if you want to time things, use criterion
16:47:22 <Nevoic> I didn't know GC could hinder performance this much.
16:47:28 <Nevoic> It goes from 0.02 seconds to 4.3 seconds.
16:47:41 <Nevoic> That's like over a 200x slowdown.
16:48:46 <boj> Nevoic: to be fair, it is a list with a single element in it vs. 44222111 elems
16:49:17 <boj> never mind, i was staring at the wrong line
16:50:12 <Nevoic> The Python version does also experience a massive slowdown, and it is also GC'd, so I could see that as the reason.
16:50:12 <Nevoic> However, the GC only brings the original 3 second runtime to 6 seconds (on the first one), and the second one is 3 seconds.
16:50:20 <Nevoic> So it's a 2x slowdown instead of a 200x slowdown.
16:50:37 <Nevoic> But it's also 4 seconds vs 3 seconds, it's just the Haskell version was so much faster to begin with.
16:50:45 <Nevoic> So maybe Haskell's GC is a tad bit slower than Python's?
16:51:29 <Nevoic> I thought GC time would be somewhat relative to the runtime of the program, but maybe that's me not really thinking through what would make GC take a long time.
16:54:33 <lyxia> Nevoic: Add {-# INLINE timeIt #-} and the slow one becomes fast.
16:54:50 <dmwit> Nevoic: I don't believe you have correctly recorded the source-code-to-output mapping.
16:55:18 <Nevoic> dmwit: ouch
16:55:23 <dmwit> Nevoic: In particular, in your `slowComp = [4]` code, the output of `timeIt slowComp` claims to be `88444222`, when it should clearly be `4`.
16:56:27 <Nevoic> I think you're right.
16:57:25 <Nevoic> I changed the times without changing the values.
16:57:43 <Nevoic> I was manually copying them from my terminal
16:58:14 <Nevoic> however, I think the runtimes were actually right. I just got something very similar to the numbers that were posted in the pastebins.
16:58:19 <Nevoic> If you get something different that'd be interesting though.
16:59:08 <Nevoic> lyxia: =O that sped things up quite a lot
16:59:29 <lyxia> I'm not sure that's an interesting benchmark beyond learning that GHC optimizes things weirdly if you don't know what you're doing.
16:59:45 <Nevoic> what does `INLINE` do?
17:00:01 <Nevoic> That brought it down from 4.3 seconds to 0.013 seconds.
17:00:07 <lyxia> It tells GHC to iline timeIt instead of making a function call.
17:00:08 <Nevoic> and the second one from .21 to .013
17:00:25 <Nevoic> So it's not a GC slowdown then?
17:00:28 <dmwit> Ah. I suspect CSE is pulling out [0..max].
17:00:58 <lyxia> no it's not the GC, the generated code was just bad.
17:01:16 <boj> 'fast' is just lazy, right? it's not actually computing all of the values?
17:01:30 <Nevoic> I think it has to compute all the values because I do `last f`
17:01:33 <Nevoic> that was my intention, at least.
17:01:39 <dmwit> boj: In fast, it is computing all the values, but only because all the values are shared.
17:01:52 <boj> ah, ok
17:02:02 <dmwit> boj: But the others are indeed not computing all the values.
17:02:15 <dmwit> Nevoic: -fno-cse does indeed help quite a lot.
17:02:17 <Nevoic> `slowMap` and `slowComp` aren't computing all the values?
17:02:24 <dmwit> nah
17:02:31 <Nevoic> how do they get the last value then?
17:03:02 <dmwit> Nevoic: Try `slowMap = (let loop = loop in loop) : map (\x -> x+x) [0..max]` and you'll see it can't possibly be evaluating the first element of `slowComp`.
17:03:24 <dmwit> err. ...the first element of slowMap.
17:03:36 <dmwit> They just... get it. (?)
17:03:45 <Nevoic> I have no idea what that code does.
17:03:48 <dmwit> Why would getting the last value force you to compute the first value?
17:04:01 <dmwit> Nevoic: It inserts an infinite loop as the first element of the list.
17:04:19 <cheater> given a, b, and <~>, what is the best way to create the list [a, a<~>b, a<~>b<~>b, ... ]?
17:04:24 <dmwit> > let loop = loop in loop :: Int
17:04:28 <lambdabot>  *Exception: <<loop>>
17:04:29 <Nevoic> Ah I see.
17:04:30 <cheater> <~> is actually + for some data type.
17:04:35 <dmwit> Oh, yeah, this isn't a good enough loop.
17:04:41 <dmwit> > let loop n = loop (n+1) in loop :: Int
17:04:45 <lambdabot>  error:
17:04:45 <lambdabot>      • Couldn't match expected type ‘Int’
17:04:45 <lambdabot>                    with actual type ‘Integer -> t0’
17:04:47 <dmwit> > let loop n = loop (n+1) in loop 0 :: Int
17:04:53 <lambdabot>  mueval-core: Time limit exceeded
17:04:59 <dmwit> cheater: iterate (<~>b) a
17:05:04 <cheater> oh, yes
17:05:07 <Nevoic> That's clever.
17:05:11 <cheater> that's the function i needed. thanks.
17:05:25 <cheater> thank you dmwit
17:05:44 <Nevoic> are list comprehensions strictly evaluated in Haskell?
17:05:53 <dmwit> No.
17:06:06 <dmwit> > last [x | x <- [undefined, "no"]]
17:06:09 <lambdabot>  "no"
17:06:22 <Nevoic> > first [x | x <- [undefined, "no"]]
17:06:27 <lambdabot>  error:
17:06:27 <lambdabot>      • Couldn't match type ‘[]’ with ‘a b’
17:06:27 <lambdabot>        Expected type: a b [Char]
17:06:28 <dmwit> (head)
17:06:38 <Nevoic> head [x | x <- [undefined, "no"]]
17:06:48 <Nevoic> > head [x | x <- [undefined, "no"]]
17:06:51 <lambdabot>  "*Exception: Prelude.undefined
17:08:13 <dmwit> Nevoic: undefined is the standard name for `let loop = loop in loop`. ;-)
17:08:26 <Axman6> but it executed much faster
17:08:29 <Axman6> executes*
17:08:30 <dmwit> yeah =)
17:08:49 <dmwit> Well... probably only a tiny bit faster, actually.
17:08:50 <Nevoic> `let loop = loop in loop` looks the same as `f = f` to me
17:08:56 <dmwit> It is.
17:09:10 <dmwit> > let f = f in f :: Int
17:09:14 <lambdabot>  *Exception: <<loop>>
17:09:26 <Nevoic> how is an infinite recursive loop the same as `undefined`? I thought `undefined` was the bottom type in Haskell.
17:09:39 <dmwit> No, it's the bottom *expression*.
17:09:45 <dmwit> And infinite loops are also the bottom expression.
17:09:53 <hpc> an infinite loop is an expression of any type that you can pass around
17:09:59 <hpc> but when evaluated, does not produce a value
17:10:23 <Nevoic> Ah, that makes sense.
17:10:42 <Nevoic> So the only way to remove undefined/ all bottom expressions (i.e anything of the bottom type) is to enforce totality (agda style)?
17:10:59 <dmwit> (The semantics does not distinguish between infinite loops, undefined, or exceptions. The implementation does, as a convenient cheat.)
17:12:06 <Axman6> or just don't evaluate them
17:12:07 <dmwit> Um. The question is a bit tautological.
17:12:12 <Axman6> don't do it!
17:12:35 <Nevoic> is the definition of totality not having a bottom type? I haven't looked into the theory of it that much.
17:12:49 <dmwit> Again: bottom computation, not bottom type.
17:12:57 <dmwit> And basically yes.
17:13:08 <Nevoic> isn't a bottom computation of the bottom type?
17:13:21 <dmwit> If there is a bottom type, then yes. It is of every type.
17:13:26 <Nevoic> or in other words, removing "the" or "all" bottom type would invalidate all bottom expressions?
17:13:36 <dmwit> But e.g. Haskell doesn't have an ordering on its types. So there is no bottom type.
17:13:43 <Nevoic> ordering?
17:14:12 <dmwit> Yes. "Bottom" means "less than all others" for some ordering.
17:14:48 <Nevoic> my only understanding of bottom/top is "top" is a supertype of all types (Any/Object etc.) and bottom is a subtype of all types (Nothing/Null/Exception etc.)
17:15:06 <dmwit> Subtyping is one choice of ordering.
17:15:25 <dmwit> Where if A is a subtype of B it is less. Then being less than all others means being a subtype of all others.
17:15:39 <Nevoic> "less" as in it has less potential values?
17:15:44 <Nevoic> i.e `Nat` being less than `Int`?
17:16:01 <dmwit> No. In that particular example, "less" means "subtype of".
17:16:21 <dmwit> Saying what order you mean amounts to defining carefully what you mean when you say "less".
17:16:44 <Nevoic> But isn't that true? That any given subtype cannot have more allowable values than its parent type?
17:16:47 <dmwit> (And proving that "less" follows some rules about behaving sanely -- e.g. transitivity and reflexivity.)
17:16:59 <Nevoic> If Int :> Object, then there are more `Object`s than `Int`s.
17:17:24 <dmwit> Perhaps. But you can have a type with less allowable values than another without it being a subtype of the other.
17:17:24 <Nevoic> greater than or equal to, maybe more properly put.
17:17:28 <dmwit> So they do not mean the same thing.
17:17:38 <dmwit> i.e. Bool is not a subtype of Int, usually.
17:17:48 <Nevoic> it is in Python. *shoot me*
17:18:00 <Nevoic> ruins my day tbh
17:18:33 <Nevoic> But I get your point.
17:18:56 <Nevoic> I don't get what's being ordered though, then.
17:19:14 <Nevoic> why is a subtype `less` than a parent type? Was it an arbitrary linguistic decision?
17:19:14 <dmwit> If you are super interested, you could have a read through https://en.wikibooks.org/wiki/Haskell/Denotational_semantics
17:19:23 <dmwit> Yes, arbitrary.
17:19:41 <dmwit> Like most of natural language.
17:20:12 <Nevoic> Yeah that's fair, I just usually assume more reason behind programming/mathematical nomenclature.
17:20:18 <Nevoic> Maybe wrongly so.
17:20:49 <hpc> the reasoning here is that there exist many things that satisfy the properties an ordering should have
17:20:59 <hpc> for example, maybe you order the alphabet in the usual way
17:21:05 <hpc> or maybe you order the vowels first
17:21:16 <hpc> either ordering behaves consistently
17:21:34 <hpc> you can see it at the value as well in the type of say
17:21:36 <hpc> :t sortBy
17:21:37 <lambdabot> (a -> a -> Ordering) -> [a] -> [a]
17:22:02 <hpc> (ignore that they chose Ordering as the name for LT | EQ | GT)
17:22:11 <hpc> *at the value level
17:22:59 <hpc> an ordering based on subtyping relationship happens to satisfy the properties of a partial ordering
17:23:06 <hpc> which is where not all elements can be properly compared
17:23:19 <hpc> for instance Bool < Object, and Int < Object
17:23:38 <hpc> but Bool < Int isn't a valid comparison, neither has a subtyping relationship with the other and they aren't equal
17:24:06 <infinisil> Well unless you define it of course!
17:25:26 <hpc> (partial ordering is a good term to google btw)
17:26:14 <boj> hpc's comment lead me to http://alternative-alphabetical-arrangements.blogspot.com
17:26:38 <hpc> awesome
17:26:46 <hpc> i like the homotopy ordering
17:34:56 <turab> dmwit: So I kinda followed the first implementation of effect-stack. The new changes introduced a lot of things I haven't even seen before (everything in Internal is new to me). Is it possible to get a list of features/concepts I can study to understand it?
17:35:12 <dmwit> hpc: It's a fun idea, but strange. Why did they choose the order 1-hole, 2-hole, 0-hole?
17:35:37 <dmwit> turab: All the old should still work.
17:35:43 <dmwit> I do plan on writing some documentation, so stay tuned.
17:36:15 <dmwit> But in short: `MonadStateDepth 3 m s` lets you say that the fourth StateT down in the stack m has state s.
17:36:36 <dmwit> And `depthState @3 foo` lets you run `foo` with access to the fourth state down in the stack.
17:36:43 <turab> dmwit: They do but I would like to understand this stuff too :)
17:36:47 <dmwit> (Indexing starts at 0 of course!)
17:37:05 <dmwit> As a user of the library you should not need to understand anything in Internal.
17:37:17 <dmwit> There is indeed some strange magic there.
17:38:03 <dmwit> Anyway, the whole thing happened because I noticed it was really annoying to write `(StateStack m, StateStack (PopState m), StateStack (PopState (PopState m)), MonadState s (PopState (PopState (PopState m))))` just to access the state in the third layer or whatever.
17:38:16 <dmwit> So I wrote a bit of type-level computation to generate those from a type-level natural number.
17:39:48 <turab> Damn. This reminds me of a topic that came up in one of my classes. We have functions like liftM, liftM2 ... would it possible to use this type-level nat to somehow make a liftMn?
17:42:42 <halogenandtoast> So I spoke with someone today who mentioned that when you have a lot of routes, the type servant generates gets a bit unruly, if you plan on having a hundred or so endpoints, does using Yesod end up making more sense at that point due to its maturity and ecosystem?
17:43:02 <halogenandtoast> Specifically referring to an API application, not using any of the shakespearian packages
17:43:40 <dmwit> turab: It would be possible, yep.
17:44:57 <jackdk> I don't think that size is a dealbreaker. you can break your API type across modules. if you find you are problems, only then put effort into the rework
17:45:27 <turab> :0 Alright I gotta learn this stuff
17:47:48 <jackdk> generally, what i do is have an API module for each "section", and then a module that collects all the sections into  a single api that you then pass to serve or w/e
17:48:22 <halogenandtoast> jackdk: that's an interesting point
18:05:35 <zacts_pi> is there a commonly used IDE for editing Haskell code?
18:06:24 <infinisil> I think intero and spacemacs for emacs is pretty popular
18:06:53 <zacts_pi> ok, thanks
18:08:19 <Axman6> VS Code with haskell-ide-engine is also pretty widely used
18:08:46 <zacts_pi> cool
18:09:32 <infinisil> Axman6: I'm actually a user of haskell-ide-engine myself, but I'm not sure if it's really widely used
18:09:37 <infinisil> Would love to be corrected on that though
18:09:54 <infinisil> It is pretty new still
18:10:28 <infinisil> Well, newish, in the grand scheme of Haskell IDEs
18:10:29 <Axman6> I wouldn't cvall it that new, I've been using it for somewhere between 1-2 years
18:11:56 <infinisil> I have a feeling a lot of Haskellers just use ghcid because it's a very solid experience, without having to fiddle around
18:13:00 <Axman6> I mostly use stack test --fast --file-watch, it seems to doa better job of running all our tests
18:14:42 <zacts_pi> should I be using stack?
18:14:52 <zacts_pi> I'm on NixOS btw
18:15:48 <Axman6> If you're willing to go through the pain of using Nix then you might as well use that
18:16:57 <zacts_pi> I mean is stack required for all users of a particular project?
18:17:05 <zacts_pi> or is it a personal preference?
18:18:10 <Axman6> cabal is redquirted for all users of a haskell progect, stack, nix, or both can be used on top of that (and using either or both isn't a terrible way to ensure your code is usable by the most other users)
18:18:17 <Axman6> required*
18:18:35 <zacts_pi> ok
18:18:50 <zacts_pi> I have cabal and ghci on my NixOS computer, but I don't have stack
18:19:04 <zacts_pi> can I get by with this until I learn more?
18:19:16 <zacts_pi> note: I'm just getting started with Haskell
18:19:26 <Axman6> sure
18:19:29 <zacts_pi> cool
18:19:37 <Axman6> assuming you also have ghc =)
18:19:41 <zacts_pi> I have ghc
18:19:58 <zacts_pi> both ghc and ghci
18:22:14 <Axman6> If you're just learning, you should mostly just focus on HAskell, and not worry too much about packages, so GHC and GHCi are allyou really need
18:22:21 <zacts_pi> ok
18:22:28 <zacts_pi> I'm just learning for now
18:22:45 <Axman6> eventually you'll start needing packages, and you can then use cabal new (I think) to create a new project where yoy can add the packages you need to the cabal file
20:13:24 <cheater> what's the best way to sleep a thread until a specific UTCTime? i'm fine with it being on the order of 1 second
20:14:30 <MarcelineVQ> possibly threadDelay a second or half at a time and check the time
20:15:45 <MarcelineVQ> or maybe have the thread wait on an mvar or channel that is filled at that time
20:19:23 <MarcelineVQ> I kinda like the mvar option the more I think about it
20:19:36 <cheater> what fills it at that time
20:19:39 <monochrom> I have a program that uses threadDelay and wakes up every 30 seconds to take a look at a priority queue for UTCTime-scheduled jobs.
20:19:54 <cheater> i shall do that
20:20:01 <cheater> but 1 second not 30 seconds
20:20:36 <monochrom> However, right now I'm coming up with the idea of zeno paradox.  Sleep for 0.5*(scheduled time - current time).  Repeat.
20:20:39 <MarcelineVQ> Whatever you like, probably option 1, but the thread at least doesn't care about time anymore with the mvar option. the thread becomes a self-contained unit of work
20:21:18 <cheater> yes monochrom i too thought of that
20:21:39 <cheater> but then i thought scheduling too many paradoxa at the same time would be of no benefit to the logic brain
20:21:52 <MarcelineVQ> Well, probably a bad way to think about it, since mvar is a link which makes it not-self contained :<
20:23:01 <monochrom> It's OK. There can be no complete de-coupling. You just need loose-enough coupling.
20:25:38 <cheater> we could shoot the computer past the event horizon of a singularity. then it would be fully decoupled.
20:26:11 <MarcelineVQ> shoot is kind of funny because that's how I was thinking of the mvar thread, a chambered bullet waiting to fire
20:26:14 <cheater> at least in case the computer can't manipulate the second clock of a wrist watch using gravity
20:26:40 <cheater> i think building computers out of guns shooting at other guns would be a very american thing to attempt
20:27:03 <cheater> i think i did that once in The Incredible Machine
20:27:11 <MarcelineVQ> That game is wizard
20:27:16 <cheater> good night
20:33:51 <monochrom> Hey people do build shooting guns in Game of Life to simulate Turing machines.
20:34:06 <MarcelineVQ> monochrom: first I've seen this zero stuff. got to say these are pretty weak paradoxes, fun though, and interesting in their relevance still today, like this paradox of place one which makes me think of set/type hierachry. And the arrow paradox is something I've spent time on my own thinking of, by no particular name
20:34:11 <MarcelineVQ> *zeno
20:36:15 <MarcelineVQ> er, link to my reference https://en.wikipedia.org/wiki/Zeno's_paradoxes
20:40:47 <monochrom> I think Einstein solved the Paradox of Place. >:)
20:43:43 <MarcelineVQ> What was the solution, or is that just a joke about frame of references? :>
20:45:43 <monochrom> Things and places (space, even space-time) interact with each other. You get a differential equation. It looks like full of ad infinitum if you discretize it (all differential equations do), but it still has solutions.
20:45:57 <dmwit> "If everything that exists has a place, place too will have a place." First of all: what makes this a paradox? Second of all: this seems to assume that "place exists", which seems unwarranted.
20:46:35 <monochrom> Ah but Zeno wants to argue that places don't exist.
20:47:10 <Axman6> Only if we know how fast they're going
20:47:28 <jle`> monochrom: i know they do it for wolfram-style CA
20:47:33 <jle`> (1 dimensional CA)
20:47:45 <jle`> i'm sure they have done it for GoL too
20:47:48 <dmwit> I am okay with "place is not a thing that exists". Or maybe: we must first establish what is meant by "exists".
20:50:05 <heatsink> Isn't "everything that exists" a redundant phrase?  "Everything" doesn't normally include things that don't exist.
20:51:26 <MarcelineVQ> idk about that, a six demon bag is a thing, but it doesn't exist
20:53:20 <dmwit> Is "six-demon" an indication of its size, like "ten-gallon"?
20:53:22 <MarcelineVQ> And you might include a six demon bag in your list of things if the context called for it, so it can fall under everything.
20:56:06 <MarcelineVQ> dmwit: There may be no way to know
20:56:27 <heatsink> But then you would be supposing that it exists
20:57:11 <MarcelineVQ> That's back to dmwit's point about defining exists I think
20:57:52 <MarcelineVQ> Does everything featured in the film big trouble in little china exist? The film exists as we commonly understand the word.
20:59:09 <heatsink> I thought that it was more about the semantics of the word "exist"
20:59:38 <heatsink> We say that numbers exist.  But unless you're a platonist, you don't think they describe physical objects
20:59:44 <MarcelineVQ> The semantics we choose to use sure
21:03:33 <heatsink> Regarding the film, ceci n'est pas une pipe.  The image is not the thing.
21:04:33 <monochrom> What about the movie called The Thing? >:)
21:05:16 <heatsink> Well, that is actually a cosmic horror that exists outside space and time, so we can't apply our mortal logic to it
21:05:38 <monochrom> Yikes
21:07:03 <MarcelineVQ> that's not a particularly accurate description of the thing as far as I know it ehe
21:07:16 <MarcelineVQ> maybe latter media retconned it, idk
21:08:30 <MarcelineVQ> heatsink: or does it exist outside of space and time in the Who Goes There? book?
21:17:07 <heatsink> I haven't read the Who Goes There? book
21:17:39 <heatsink> But I super liked Peter Watt's The Thing fanfiction
21:20:43 <MarcelineVQ> ah neat, I saw a review a little bit ago that said the creature was from another time but checked the story and they just meant it had been there for 20m years, literally out of human time. we should move to #haskell-offtopic if you want to talk more about it. I've not read the story either but appearantly it's only 40 pages in pdf form so I'm gonna
21:30:56 <fragamus> hey I was surprised when my non-exhaustive function implementation compiled. My parameter is an ADT with many constructors
21:31:50 <fragamus> I thought it had to be exhaustive
21:31:50 <MarcelineVQ> If non-exhaustive patterns isn't set to Werror it's not an error
21:32:00 <fragamus> ahhh
21:33:29 <MarcelineVQ> It's not an error by default because people like more flexibility on determining themseles whether something is exhaustive, and ghc can give you false positives on exhaustivness, especially with guards.
21:34:57 <MarcelineVQ> I'm pretty rarely smarter than the compiler when it comes to assembling programs, so I think not being an error is dumb, or at the very least a basic always-on warning
21:35:44 <MarcelineVQ> *basic on-by-default warning
21:38:35 <MarcelineVQ> Whatever that opinion is worth :> -Werror=incomplete-patterns -Werror=incomplete-uni-patterns
21:46:23 <hvim> Hello. If I have a function 'f' that is 'a -> m b -> m c' but I have 'a' wrapped in 'm' how do I unwrapp it so that I can pass it to f?
21:46:48 <heatsink> Use do-notation or >>=
21:47:00 <heatsink> For example, do { x <- a; f x y }
21:47:51 <heatsink> Here, "a" has a type like "m a".  Its result is extracted into "x", and then passed to f
21:48:05 <heatsink> That's all presuming that m is a monad
21:57:10 <hvim> Thanks, looks like it works now.
22:48:43 <jackdk> I find it easier to think in terms of >>= being a combination of join and fmap, because otherwise I start asking myself how to extract the 'a' from the 'm a', which is not possible from the outside
23:35:10 <butterthebuddha> I'm trying to work on this challenge https://adventofcode.com/2015/day/8
23:35:54 <butterthebuddha> How can I read the input file as a raw string
23:38:26 <Axman6> readFile?
23:38:48 <yushyin> what do you mean by raw?
23:42:55 <butterthebuddha> Nvm, I misinterpreted the readFile output
23:48:55 <maerwald> it's RAW
