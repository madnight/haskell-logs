00:03:37 <jle`> i don't mean that as any criticism on lens
00:04:05 <jle`> but just that it made a library i was writing have a dependency footprint closer to what i was aiming for :)
00:04:10 <jle`> (two, actually)
00:14:26 <iqubic> I think the right way to include lenses is to just have some functions with the type signature of the optics you want and just not rely on the official lens package.
00:14:52 <iqubic> Because Lens and Prism and Travesal are just type synonyms at the end of the day.
00:17:22 <dminuoso> iqubic: It depends on whether you intend to *use* lenses or just expose optics.
00:17:59 <iqubic> True. True.
00:19:26 <dminuoso> iqubic: And even for the last part it may be convenient to use the TH helper utilities. microlens can get you pretty far already but it does't have all the TH tools.
00:19:51 <iqubic> I suppose that's true.
00:20:04 <iqubic> How big is the full lens package anyway?
00:22:27 <dminuoso> What kind of metric are you interested in?
00:28:44 * hackage hw-ip 2.3.1.1 - Library for manipulating IP addresses and CIDR blocks  https://hackage.haskell.org/package/hw-ip-2.3.1.1 (haskellworks)
00:30:22 <cocreature> microlens is great, people use it to reduce their dependency footprint before checking if they already depend on lens transitively and using microlens might actually increase their dependency footprint.
00:31:15 * hackage hprox 0.1.0.1 - a lightweight HTTP proxy server, and more  https://hackage.haskell.org/package/hprox-0.1.0.1 (BinJin)
00:55:42 <Brouwer> So, who is now attending Haskell track on exercism?
00:56:38 <jgt> not I
00:57:36 <Brouwer> I can't quite understand how long it takes to mentor to check out soultion
00:59:35 <Brouwer> If there are no conversations why this chat existing?
00:59:40 <jgt> I did about a third of the last Advent of Code, all in Haskell
00:59:55 <jgt> Brouwer: people do chat here, but not always at this time of day
01:00:13 <jgt> and also, not everyone finds it useful to respond with "not I"
01:00:32 <jgt> so probably other people are seeing this, but not chiming in
01:01:07 <merijn> It's 10 o clock after a long weekend, so all of Europe is busy having coffee with colleagues and the US is asleep
01:01:43 <Brouwer> O, sorry for being a jerk pretty used to telegram-chat activity
01:01:57 <tdammers> same though
01:02:14 <tdammers> a telegram group with 600 members geographically distributed across the globe is going to behave much the same
01:02:18 <jgt> I should be in my basement, assessing the damage from the ridiculous storm last night
01:04:30 <Brouwer> Awaiting the storm in my basement so far, but in Moscow there is fatal heat
01:05:27 <nshepperd> fatal heat? that sounds... dangerous
01:05:32 <jgt> sounds fatal!
01:06:10 <tdammers> the problem with anything fatal is that it tends to be deadly
01:06:40 <jgt> welcome to #dadjokes
01:06:59 <nshepperd> fatal errors aren't all they're cracked up to be though
01:07:11 <Brouwer> It is as deadly as 2.8 Schwarzenegger communists 
01:08:54 <jgt> that doesn't sound as bad as the most dangerous insect
01:09:01 <jgt> the hepatitis bee
01:09:13 <jgt> or the most dangerous place to go swimming
01:09:18 <jgt> the hepatitis sea
01:09:26 <jgt> (those jokes work better spoken)
01:10:52 <Brouwer> debugging this jokes
01:11:59 <Brouwer> compiling
01:12:04 <Brouwer> :)
01:13:25 <Brouwer> So, the question
01:14:15 <Brouwer> There is an exercise to write Integer -> Bool function defining the leap year
01:14:37 <Brouwer> module LeapYear (isLeapYear) where  isLeapYear :: Integer -> Bool isInt :: Integer -> Bool isLeapYear year   | even (year / 4) == True = True   | (rem) year 100 == 0 = False   | (rem) year 400 == 0 = True   | otherwise False 
01:15:06 <Brouwer> I done this but compiler arguing for parse error
01:15:11 <merijn> Brouwer: " == True" is redundant
01:15:25 <Brouwer> ow
01:15:34 <merijn> Brouwer: Also, you have no = between otherwise and False
01:15:50 <merijn> And the parentheses around rem are redundant :)
01:16:41 <Brouwer> thank you, wise man
01:17:30 <jgt> Brouwer: this would be easier to read if you used some pastebin
01:17:56 <Brouwer> what is it
01:19:21 <tdammers> a website where you can paste text into a textarea, and it'll store it and give you a fresh URL pointing to it
01:19:40 <tdammers> so you write the code in the textarea, and then just paste the URL here, instead of pasting the whole code into IRC
01:19:50 <tdammers> easier to read, easier to type, and less noisy
01:20:19 <Brouwer> Oh, I'll take note of that
01:47:25 <maerwald> is there an anacron implementation in haskell?
01:52:23 <simon> you mean any cron daemon, or specifically anacron?
01:53:25 <maerwald> anacron
01:53:59 <maerwald> I don't care whether it's a daemon or just some library doing similar functionality
01:55:52 <simon> there's a pretty neat 'cron' package that only handles the data format of cron daemons. and a somewhat outdated 'hcron' that schedules IO actions, but doesn't use 'cron' for it.
01:56:20 <simon> seems like an under-supplied area.
01:58:22 <jgt> I use the cron library, and it works great
01:59:26 <phadej> having written few cron-like "libraries" myself for private use, it's surprisingly tricky to come with general enough approach
01:59:45 * hackage docusign-client 0.0.3 - Client bindings for the DocuSign API  https://hackage.haskell.org/package/docusign-client-0.0.3 (maerwald)
01:59:55 <phadej> in private setting you can make choices like "what logging lib will we use", etc.
02:00:24 <maerwald> jgt: that's not anacron though
02:00:32 <simon> interesting. so 'cron' does a pretty neat job of isolating just the syntax.
02:00:33 <maerwald> you reboot your app/platform and your jobs are gone
02:03:43 <jgt> I don't know what anacron is
02:03:55 <jgt> but in my case, when the application starts up, it sets up all those jobs
02:04:11 <maerwald> https://en.wikipedia.org/wiki/Anacron
02:04:33 <jgt> here's what I do on application startup http://ix.io/1Lta
02:05:34 <jgt> oh, I see. Well, my website is meant to be online all the time, so I don't need anacron
02:05:37 <jgt> (I think)
02:15:07 <simon> jgt, https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Monad.html#v:void ? :)
02:15:30 <simon> jgt, also, pretty cool use of cron.
02:17:44 * hackage simple-vec3 0.5 - Three-dimensional vectors of doubles with basic operations  https://hackage.haskell.org/package/simple-vec3-0.5 (DmitryDzhus)
02:21:03 <simon> maerwald, it seems from jgt's snippet that `execSchedule` in the 'cron' package is actually capable of acting as a cron daemon, not just parsing the cron format. if you create a wrapper around `addJob :: IO () -> Text -> m ()` so that it executes UNIX commands in some way.
02:21:46 <jgt> simon: yeah, I definitely could have used void. I started writing that project a couple of years ago though, so I knew a lot less then
02:22:05 <jgt> simon: it's from one of my businesses, NewBusinessMonitor if you're curious
02:23:22 <simon> jgt, cool.
02:42:44 * hackage bglib 0.1.0.0 - Implementation of the BGAPI serial protocol  https://hackage.haskell.org/package/bglib-0.1.0.0 (tamasFabian)
04:12:35 <yorick> my haskell process uses 14 cores for... gc? even if I set +RTS -n4
04:13:44 <merijn> yorick: HOw are you determining that is using 14 cores?
04:14:03 <yorick> merijn: htop shows 1400%
04:14:10 <merijn> Also, note that there is an API for changing the thread count from the code, ignoring the RTS -n4 parameter
04:14:23 <yorick> yes, I also use that to set it to 4
04:14:43 <merijn> And your sure nothing else is overriding it?
04:14:49 <yorick> yes, I check it sometimes
04:14:51 <merijn> s/you/you're
04:14:56 <merijn> That's...odd
04:15:15 <yorick> does it need -qn4?
04:15:23 <merijn> You probably wanna disable parallel GC anyway, because performance is often bad
04:15:37 <merijn> But that doesn't really explain why there's 14 threads GCing at the same time
04:15:47 <merijn> otoh, I dunno how accurate htop is
04:15:50 <yorick> I found https://www.reddit.com/r/haskell/comments/85vwlq/our_lovely_ghc_parallel_gc_on_96_core_arm/
04:16:08 <yorick> merijn: well, it does show per-core cpu utilization at 100% too
04:16:54 <yorick> https://pub.yori.cc/screen/20190611131620.png
04:17:20 <merijn> yorick: You can simply disable parallel GC, though? :)
04:17:36 <merijn> I know that it *cripples* the performance of some of my programs
04:18:00 <yorick> -qg1?
04:18:14 <merijn> -qg with no arguments
04:18:31 <yorick> I'll try that
04:19:10 <yorick> this improved memory performance but still uses >4 cores
04:19:25 <merijn> yorick: Do you do a lot of FFI?
04:19:51 <merijn> Note that the -n RTS option only affects the capability count, not number of threads
04:19:52 <yorick> yes, but all bound to a single system thread
04:20:19 <merijn> yorick: All safe foreign calls run in their own thread to prevent blocking Haskell code
04:20:59 <yorick> I don't think these are safe calls (haskell-opencv)
04:21:14 <merijn> -n controls the number of capabilities (i.e. how many threads are simultaneously executing Haskell code) the program may use more threads than the -n parameter (although those generally should be mostly idle)
04:22:01 <merijn> yorick: Are you sure those 14 cores are occupied by your Haskell code? Also, if you run with "+RTS -sstderr" what do you see?
04:22:13 <merijn> yorick: Oh, wait
04:22:31 <merijn> yorick: Very obvious but forgotten question: Are you sure opencv isn't using/spawning more thread internally?
04:22:31 <yorick> no, I don't know what these cores are doing
04:22:44 <yorick> yes, I've seen the code
04:22:49 <yorick> -sstderr has no effect
04:23:17 <merijn> yorick: -sstderr shouldn't have an effect, it should print GC and compute statistics when you program terminates :)
04:23:30 <yorick> worst case I'll limit it with cgroups, I suppose
04:23:46 <merijn> yorick: tbh, this sounds a lot like opencv internally using threads
04:23:57 <yorick> ctrl-c now no longer terminates my program
04:24:12 <yorick> (second ctrl-c kills it without printing anything)
04:25:21 <yorick> merijn: opencv has a bug where it uses additional memory for every thread where you call it (and never cleans it up). the author responded to the bug report with "you shouldn't go and make threads all the time"
04:26:09 <merijn> Ah, quality engineering >.>
04:26:26 <merijn> Have you tried looking in gdb/lldb what those threads are all doign?
04:28:13 <yorick> oh, -sstderr stats are in: https://gist.github.com/yorickvP/c0d33a9843df9c21dc10f2965a2d9e39
04:29:25 <merijn> yorick: Right, so definitely not GC anymore :)
04:29:37 <merijn> 99.6% is pretty freaking impressive
04:29:45 <merijn> *99.6% productivity
04:31:14 <merijn> ok, so it lists 16 peak workers, so presumably that's indeed threads spawned by Haskell. Which leads me back to safe FFI calls
04:31:39 <merijn> yorick: Do you have 16 forkIO threads by any chance?
04:34:14 * hackage dprox 0.1.2 - a lightweight DNS proxy server  https://hackage.haskell.org/package/dprox-0.1.2 (BinJin)
04:36:14 <yorick> merijn: there's two forkIO's, no thread pool that I can see
04:36:26 <yorick> and they don't seem to be performing a lot of computation
04:36:59 <yorick> I'll attach gdb to one of the threads
04:37:53 <yorick> ...tensorflow thread pool
04:43:29 <yorick> merijn: sorry for bothering you, thanks for the help!
04:44:24 <merijn> Mystery solved! :)
04:45:08 <merijn> yorick: On the bright side, you got a super low-effort way to improve performance with -qg ;)
05:23:14 * hackage hw-packed-vector 0.0.0.2 - Packed Vector  https://hackage.haskell.org/package/hw-packed-vector-0.0.0.2 (haskellworks)
05:33:15 <Ok> Can someone explain me about monads please..
05:35:48 <hpc> Ok: have you looked at Functor and Applicative yet?
05:36:10 <lyxia> Ok: https://en.wikibooks.org/wiki/Haskell/Understanding_monads
05:37:50 <dminuoso> Ok: What kind of background do you have, and why do you aim to learn about monads?
05:49:24 <infinisil> Is it just me or is GHC HEAD (or 8.8.1) really that much faster than 8.6.*?
05:49:34 <infinisil> I notice everything compiling rather quickly
05:52:06 <jgt> Ok: everyone is jumping at the opportunity to help you here; is there no follow-up?
05:52:39 <jgt> infinisil: I would like my projects to compile a bit faster; I'm on 8.4.3
05:52:58 <jgt> would be nice if there were a way to see where GHC is spending most of its time during compilation
05:53:44 * hackage containers 0.6.1.1 - Assorted concrete container types  https://hackage.haskell.org/package/containers-0.6.1.1 (dfeuer)
05:55:11 <cocreature> is there any way to use guards in the definition of a pattern synonym?
05:56:31 <merijn> cocreature: I thought so? But don't ask me what it was :p
05:58:01 <cocreature> merijn: so far I’ve only produced syntax errors
05:58:10 <cocreature> I can avoid it, it just looks horrific :)
06:08:48 <lyxia> cocreature: For anything fancier than patterns of constructors, there's ViewPatterns
06:10:41 <cocreature> lyxia: right but "(==foobar) -> True" looks somewhat ugly, I’d prefer a "| x == foobar = …", especially if there is more than one of these cases
06:18:39 <lyxia> I meant that you can use ViewPatterns in PatternSynonyms (I don't know whether I was clear, I might have been).
06:19:18 <cocreature> yeah it was
07:31:04 <saml> n! + (n-1)! + (n-2)! + ...  what's big o of this?
07:32:17 <gobby> I'm trying to serve my elm .js file via yesod using `sendFile`. However this renders the .js file as text in my browser. Anybody know how to serve the file properly with Yesod? Or would it be recommended to move to a simpler library?
07:36:58 <hyperisco> Well multiplication is linear, right? So… uh… O(n^3)
07:37:52 <stilgart> saml> O(n!)
07:38:15 <merijn> hyperisco: Wasn't there a recent proof that multiplication is n log n ? :p
07:38:27 <hyperisco> it was that or linear, I can't remember now
07:39:03 <olligobber> yeah, multiplication has been shown to be O(nlogn)
07:39:07 <stilgart> merijn: n-digits integer multiplication is O(n.log(n)) indeed
07:39:23 <hyperisco> oh, n-digits, well that's much different
07:39:27 <olligobber> https://mathstodon.xyz/@erou/101787744661719386
07:40:34 <olligobber> I think n! + (n-1)! + ... is not O(n!) though
07:42:18 <hyperisco> so the multiplication cost for n a number, not number of digits, is log(n)*log(log(n))) which is log(n)*log^2(n)
07:42:46 <olligobber> yes
07:42:55 <hyperisco> then there are n multiplications in n!
07:42:59 <hyperisco> and we have n n!'s
07:43:10 <hyperisco> so there are n^2 of these
07:43:19 <hyperisco> n^2*log(n)*log^2(n)
07:43:20 <stilgart> well, in pratice you have an extra log(log(n)) (for the n-digits cost)
07:43:21 <olligobber> there are two different questions here, one is how long does it take to computer that sum, and the other is how big is the total sum
07:43:48 <hyperisco> there are n summations, so that goes away does it not
07:43:48 <olligobber> and actually, the notation log^2(n) is used for log(n)*log(n) not log(log(n))
07:44:06 <hyperisco> it is? well that's silly
07:44:22 <hyperisco> okay, log(log(n)) then
07:44:48 <hyperisco> not sure why one would write it log^2(n) rather than log(n)^2 but w/e
07:44:58 <stilgart> not so, in (structured) linear algebra, we have several algorithms in O(n . (log(n))^alpha )
07:45:11 <monochrom> because they also write sin^2 for \x -> (sin x)^2
07:45:39 <hyperisco> shows how good I am at math
07:46:04 <monochrom> sometimes there is f^(2) for f.f but no one has ever used f^2 for it.
07:46:06 <saml> let's think
07:46:18 <saml> n*(n-1)*(n-2)...
07:46:21 <saml> that's n!
07:46:29 <monochrom> the exception is d^2/dx^2 for (d/dx).(d/dx)
07:46:44 <hyperisco> was there some problem with my thinking? other than notation…
07:47:08 <saml> n! + n!/n + n!/(n(n-1)) + n!/(n(n-1)(n-1)) + ...
07:47:13 <saml> so common stuff is n!
07:47:29 <saml> n!*(1 + 1/n + 1/(n(n-1)) + ...)
07:47:54 <hyperisco> are we trying to find the complexity as written or are we trying to optimise it
07:48:06 <saml> i think it'll be n!
07:48:11 <stilgart> saml: my idea is that [ (n-3)! + (n-4)! + .... + 2! + 1!] / n! is less than O(1/n)
07:48:34 <saml> i'm trying to find complexity as written
07:49:12 <stilgart> the issue here is that you have an non-constant number of terms to add
07:49:34 <hyperisco> okay, so there are n additions, that is bupkis… then there is just the question of how many multiplies there are, and what a multiply costs
07:49:50 <hyperisco> so we figured what a multiply costs, and then we figured how many multiplies there are
07:49:54 <hyperisco> is there something else to figure?
07:51:10 <stilgart> hyperisco: did you understand the question as "what does it cost to compute n! + ... " ?
07:51:44 <hyperisco> no I understood it as "what is the big o of this"
07:52:01 <monochrom> :)
07:52:44 <stilgart> then, I would say that n! + (n-1)! + ... = n! ( 1 + 1/n + 1/n(n-1) + ...) = n! (1 + O(1/n)) = O(n!)
07:53:00 <saml> > let fact n = if n <= 1 then 1 else n * fact (n-1)  in fact 10
07:53:01 <lambdabot>  3628800
07:54:12 <hyperisco> I do not understand the step between  1 + 1/n + 1/n(n-1) ...  and  O(1/n)
07:54:15 <saml> > foldr (*) 1 [10, 9, .., 1]
07:54:16 <lambdabot>  <hint>:1:21: error: parse error on input ‘..’
07:54:37 <stilgart> hyperisco: 1/n is O(1/n), 1/n(n-1) is O(1/n)
07:55:17 <infinisil> stilgart: Is that (1/n) * (n-1) or 1/(n * (n-1))
07:55:20 <hyperisco> I don't get what is happening
07:55:40 <stilgart> and 1/n(n-1)(n-2) + 1/n(n-1)(n-2)(n-3) + .... is 1/n(n-1) ( 1/(n-2) + 1/(n-2)(n-3) + ...)
07:55:55 <stilgart> and the last () is less than n/(n-2)
07:55:57 <hyperisco> okay, so you've rewritten it, so now we have a bunch of multiplies in a denominator. I don't get how that changes the problem.
07:56:11 <stilgart> it is 1/((n*(n-1))
07:57:35 <stilgart> my idea is that there is only n terms, and that they are (almost) all O(1/n²)
07:57:44 <stilgart> so there sum is O(1/n)
07:58:13 <hyperisco> I don't understand O(1/n)
07:58:22 <hyperisco> maybe my understanding of big-o is too weak
07:58:42 <saml> > let fact n = foldr (*) 1 [n, n-1 .. 1]; o n = foldr (*) 1 $ map fact [n, n-1 .. 1] in [o 10, fact 10]
07:58:43 <stilgart> f = O(1/n) means |f(n)| <= C . 1/n
07:58:44 <lambdabot>  [6658606584104736522240000000,3628800]
07:58:46 <hyperisco> but here, as n gets bigger, the cost is less
07:58:48 <stilgart> where C is a constant
07:58:50 <hyperisco> and that doesn't make any sense
07:58:53 <saml> it's much bigger than factorial
07:59:06 <saml> i think it's O(n!^2)  or O(2^n!)
07:59:10 <tabaqui> > fail "hi" :: Maybe Int
07:59:12 <lambdabot>  Nothing
07:59:19 <tabaqui> > fail "hi" :: Either String Int
07:59:21 <lambdabot>  *Exception: hi
07:59:40 <tabaqui> I don't think that it is fine
07:59:49 <tabaqui> % :i fail
07:59:50 <yahb> tabaqui: class Applicative m => Monad (m :: * -> *) where; ...; fail :: String -> m a; -- Defined in `GHC.Base'
08:00:17 <merijn> tabaqui: This is already being remedied
08:00:21 <hyperisco> the cost of computing  n*n  is not  O(n*n), it is the cost of a multiplication
08:00:27 <merijn> tabaqui: You want -XMonadFailDesugaring
08:00:32 <hyperisco> so I don't know how you go from the cost of  1/n  is  O(1/n)
08:00:41 <hyperisco> the cost is the cost of a division
08:00:48 <joomy> would it be fair to say Data and Typeable today are the modern version of the Scrap Your Boilerplate work? is there a paper about the modern state of Data and Typeable?
08:01:17 <tabaqui> merijn: I thought that proposal was to move fail into MonadFail class
08:01:22 <merijn> tabaqui: Right
08:01:43 <merijn> tabaqui: But that's incompatible with Haskell2010, so you need an extension
08:02:14 <merijn> tabaqui: With MonadFailDesugaring failable patterns in do notation infer as "MonadFail" instead of just "Monad"
08:02:21 <merijn> % :seti -XMonadFailDesugaring
08:02:21 <yahb> merijn: 
08:02:42 <merijn> % :t fail
08:02:42 <yahb> merijn: Monad m => String -> m a
08:02:56 <merijn> % :t Control.Monad.fail
08:02:56 <yahb> merijn: Monad m => String -> m a
08:03:04 <merijn> % :t Control.Monad.Fail.fail -- 3rd time's the charm
08:03:05 <yahb> merijn: Control.Monad.Fail.MonadFail m => String -> m a
08:03:29 <monochrom> That doesn't bode well :)
08:03:32 <merijn> tabaqui: With -XMonadFailDesugaring the use of fail in the desugaring of "do" uses Control.Monad.Fail.fail
08:03:47 <monochrom> Oh! You need "do"...
08:04:26 <merijn> % :t do { Right s <- Left True; return s }
08:04:26 <yahb> merijn: ; <interactive>:1:6: error:; * No instance for (Control.Monad.Fail.MonadFail (Either Bool)); arising from a do statement; with the failable pattern `Right s'; * In a stmt of a 'do' block: Right s <- Left True; In the expression:; do Right s <- Left True; return s
08:05:06 <monochrom> Oh! Probably you also need to avoid saying "fail" but instead use a refutable pattern...
08:07:03 <Rayler> Hello Haskell people how are ya
08:08:05 <hyperisco> Expressed as an interval in the extended reals, I can only assume somewhere from negative to plus infinity.
08:10:15 <tabaqui1> You didn't name the axis
08:10:41 <hyperisco> The axis of how-you-doin'
08:11:45 <merijn> monochrom: Right, it affects the do desugaring. You can still explicitly use fail, but then you have to make sure to use the right one
08:12:03 <monochrom> "I fail at fail."
08:13:18 <hyperisco> When your exception handler throws it raises the infamous exception exception, causing your computer to lose all hope on continuing.
08:20:11 <jkachmar> phadej: I think I remember seeing a lot of Haxl + Servant stuff in one of your projects a little while back, can you comment on what you ended up using it for, and whether or not it felt like a good investment at the time?
08:20:38 <phadej> jkachmar: haxl and servant where not tied to each other in any way
08:20:51 <phadej> haxl was used to implement servant handlers
08:23:15 <jkachmar> Right, did you find that to be a good use of Haxl and did you use any of the cache replaying stuff for tests or was it mostly just to take advantage of Haxl's reordering of queries?
08:23:40 <solonarv> joomy: actually, Data is somewhat old news (and the actual SYB implementations are built on top of it)
08:24:53 <solonarv> a somewhat newer thing is ghc's Generic machinery, which makes the structure of a datatype available at the type level
08:25:21 <solonarv> and you can use type-level computation and typeclass machinery to build generic operations on top of that
08:25:27 <solonarv> for example:
08:25:32 <solonarv> % :kind! Rep Either
08:25:32 <yahb> solonarv: ; <interactive>:1:1: error: Not in scope: type constructor or class `Rep'
08:25:42 <solonarv> % import GHC.Generics
08:25:42 <yahb> solonarv: 
08:25:44 <solonarv> % :kind! Rep Either
08:25:44 <yahb> solonarv: ; <interactive>:1:5: error:; * Expecting two more arguments to `Either'; Expected a type, but `Either' has kind `* -> * -> *'; * In the first argument of `Rep', namely `Either'; In the type `Rep Either'
08:25:51 <lavalike> solonarv: this is not the sum-of-product stuff is it
08:26:04 <solonarv> % :kind! Rep (Either Int Bool)
08:26:04 <joomy> solonarv: I know about GHC.Generics but the kind of computation I want to do is too complex for type level.
08:26:04 <yahb> solonarv: Rep (Either Int Bool) :: * -> *; = D1 ('MetaData "Either" "Data.Either" "base" 'False) (C1 ('MetaCons "Left" 'PrefixI 'False) (S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 Int)) :+: C1 ('MetaCons "Right" 'PrefixI 'False) (S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 Bool)))
08:26:40 <solonarv> joomy: well, usually you can't do all the work at the type level
08:26:46 <jle`> GHC.Generics doesn't do your computation at the type level. what it does is provide a uniform 'generic' representation of an ADT so you can pattern match on all of them uniformly
08:27:02 <solonarv> since at the type level you only know the structure of the data type, you don't have actual values of it to work with
08:27:08 <jle`> so you can match on say, the first constructor, or the first field, of any ADT
08:27:15 <lavalike> I was thinking it's a type level reflection/reification deal too but I had never seen Rep before
08:27:25 <lavalike> *value level
08:27:39 <solonarv> Rep is from GHC's machinery
08:27:39 <jle`> Rep just matches each ADT to its generic constructor/field pattern
08:27:55 <joomy> solonarv: going back to Data, do you know where I should look at to learn more about its origins? I've been looking at the SYB papers to no avail
08:28:08 <solonarv> in practice the representation is indeed a sum-of-products representation (because that is how Haskell's ADTs are defined too)
08:28:19 <solonarv> joomy: sorry, I don't know a lot about Data
08:28:29 <jle`> you could implement Rep yourself :) it's basically a mechanical transformation of an ADT to Either's and Tuples
08:28:37 <joomy> solonarv: I see, thank you
08:28:43 <solonarv> yup - a balanced binary tree, specifically
08:28:46 <lavalike> where is the doc for this?
08:29:04 <solonarv> there are also some unary nodes interspersed which hold meta-information like the names of constructors and record fields
08:29:12 <solonarv> lavalike: in the haddocks for GHC.Generics, mostly
08:29:27 <lavalike> yeah can't find mentions in the ghc user guide
08:29:32 <solonarv> @hackage base/docs/GHC-Generics.html
08:29:32 <lambdabot> http://hackage.haskell.org/package/base/docs/GHC-Generics.html
08:35:50 <stilgart> hyperisco: my apologies, i had to answer a call
08:37:13 <stilgart> big-O notation is more general than its usage in algorithmic
08:38:28 <stilgart> as I saif, f = O(g) means than |f(n)| <= C . f(n) for some onstant C and for all values of n near some value (usually 0 or +inf)
08:39:53 <stilgart> is this sense, n! + (n-1)! + ... = O(n!) when n goes to +inf
08:40:18 <solonarv> yeah, that seems correct to me
08:40:44 <solonarv> that's even a tight bound, but I forget the symbol for that (it's not O)
08:40:45 <monochrom> "when n goes to +inf" is redundant
08:41:05 <monochrom> Theta. Θ
08:41:17 <stilgart> oops,  |f(n)| <= C . *g* (n)
08:42:10 <stilgart> i agree with Θ(n!) which is even more precise
08:45:34 <monochrom> Please use Θ as much as possible!
08:45:37 <hyperisco> I'd have to get my course notes from uni out to look up these definitions
08:45:51 <dmwit> Can we all please agree that the correct notation to use should be f ∈ O(g) ?
08:46:08 <monochrom> CLRS begs to differ.
08:46:21 <int-e> monochrom: n! + (n-1)! + ... = m!(1 + o(1)). :-P
08:46:26 <monochrom> Then again, just saying. I am against = too.
08:46:27 <int-e> s/m/n
08:46:38 <dmwit> CLRS is stupid and wrong (on this particular point).
08:46:39 <stilgart> dmwit: \in (i suppose it was the symbol) is better but rarely used :(
08:46:41 <hyperisco> but vaguely I remember big-O is an upper bound on worst case cost, and not necessarily least, and yes it throws out some details
08:47:01 <hyperisco> I think just the detail of a constant factor
08:47:30 <infinisil> saml: stilgart: hyperisco: Complexity of calculating n! + (n-1)! + ... + 1! + 0! can be as low as O( (n * log(n)) ^ 2 )
08:47:51 <monochrom> Generally, people rarely use the better choices.
08:47:52 <hyperisco> but I guess you're doing something other than big-O, so now I don't know anything about it
08:48:14 <stilgart> but the question (as i understand it) is just "how big is n! + (n-1)! + ... ?"
08:48:26 <monochrom> This is also why I would pitch Haskell as a premium language.  Fewer people use it, precisely because it's better.
08:48:32 <hyperisco> oh, well that is *way* different than what I originally understood, stilgart
08:49:05 <infinisil> saml: stilgart: hyperisco: I described the full proof here: https://gist.github.com/Infinisil/738d1c8615e44fbc534b789a00f6ef82
08:49:09 <stilgart> and my answer is that it is as big as 
08:49:11 <stilgart> n!
08:49:29 <infinisil> included is also that n! + (n-1)! + ... has n * log(n) digits
08:49:31 <hyperisco> maybe part of my confusion is that because this was being asked in #haskell I figured we were talking about the cost to compute, not magnitude of the number
08:49:34 <infinisil> Max
08:50:33 <hyperisco> infinisil, that is also what I calculated
08:50:52 <hyperisco> using the napkin rigor I was taught in school
08:51:43 <infinisil> But compute complexity is more interesting tbh, O (n * log(n)) ^ 2) is a nice result :)
08:51:54 <infinisil> Assuming I didn't make a mistake
08:51:59 <dmwit> The Wikipedia page on Stirling's approximation (which includes both upper and lower bounds) might also be fun reading at this point.
08:52:07 <hyperisco> actually I had another log(n), not sure how you got rid of that, but close enough for me
08:52:50 <infinisil> hyperisco: You mean something like `O( (n * log(n)) * log(n * log(n)) ) <= O( n * log(n) ^ 2 )` ?
08:54:24 <hyperisco> infinisil, I got  O(n^2*log(n)*log(log(n)))
08:54:58 <infinisil> Ah, yeah I just did log(log(n)) <= log(n)
08:55:06 <hyperisco> Hm,  log(n)*log(log(n))  is smaller than  log^2(n)  right?
08:55:34 <infinisil> Yeah
08:56:23 <hyperisco> I guess this problem isn't competitive enough to care about loosening the bounds for beauty
08:57:15 <stilgart> O( (n.log(n))^2 ) for the computation cost of n! + (n-1)! + ... is quite a nice bound
08:57:23 <stilgart> (and no Theta this time ;) )
08:57:53 <saml> Can I just say it's O(n^n) ?
08:58:03 <hyperisco> They haven't proven that multiplication can't be linear, so there's hope it can be even simpler
08:58:41 <infinisil> saml: (n*log(n))^2 is a lot better than n^n
08:58:54 <saml> O((n log(n)) ^ 2)  is there  a name for this?
08:59:11 <hyperisco> "kinda slow"
08:59:18 <nimba> Hi. I'm dealing with a test suite written using Hspec; it uses forM_ to go over largish lists of inputs and outputs and runs `shouldBe` on those; problem is that this short-cuts evaluation of the remaining test cases upon the first failure. 
08:59:27 <nimba> Easy way to get them to run all?
08:59:44 <stilgart> saml: "time of FFT" squared ?
09:00:09 <infinisil> Ohh actually I bet we just solved saml's homework xD
09:00:21 <hyperisco> "your sort comparator requires sorting"
09:00:23 <saml> i wish it was a homework
09:00:37 <infinisil> What's this for?
09:00:38 <saml> then i can get A+
09:00:54 <stilgart> are you trying to simplify some strange complexity?
09:00:54 <saml> someone asked me thinking i was smart
09:01:14 <saml> I have no idea about the context
09:01:24 <saml> i just said it's O(n^n) :P
09:01:58 <dmwit> hyperisco: https://arxiv.org/abs/1902.10935
09:02:06 <stilgart> saml: it is good enough
09:02:09 <dmwit> (Not a contradiction, but maybe interesting to you anyway.)
09:02:38 <infinisil> stilgart: Well (n^n) is really bad.. Worse than exponential, and exponential is already really bad
09:02:54 <infinisil> (n*log(n))^2 <= n^4
09:03:09 <infinisil> So n^4 would be a simple answer that's not too far off
09:03:47 <stilgart> infinisil: n! is just as bad if you ask me
09:03:56 <hyperisco> I press one wrong key combo...
09:04:03 <hyperisco> why not n^3
09:04:18 <infinisil> Hmm, is (log(n))^2 <= n?
09:04:24 <stilgart> sure
09:04:51 <infinisil> I can see it from thinking about it, but I don't have a proof
09:04:51 <stilgart> (log(n))^1000 is still less than n at some point
09:05:17 <hyperisco> remember for big-O the bounding function just has to be always bigger after some point
09:05:45 <hyperisco> which is a reason why it is useless for talking about small input sizes on real computers
09:06:22 <infinisil> Hm, how do you prove that though?
09:06:23 <stilgart> infinisil: the easiest path is to show that exp(x) >= x^m / m! for any m (as long as x >= 0)
09:07:04 <stilgart> this can be achieved by induction, and then you take x = log(y) and m = 2
09:07:38 <stilgart> and you have (log(y))^2 \in O(n)
09:07:42 <stilgart> O(y)
09:09:59 <infinisil> Neat
09:19:10 <hyperisco> infinisil, log gives the number of digits, so log(n)^y has y times the number of digits as the number that represents the number of digits n has. So  log(n)/log(log(n))  is the largest y such that  log(n)^y <= n  and you can ask Wolfram to solve for n :P
09:19:26 <hyperisco> is that some redneck math or what?
09:21:10 <stilgart> hyperisco: context taken into account, I assumed that the question was O(log(n)^2) <= O(n) 
09:22:02 <hyperisco> yeah, so you can find the point that n overtakes log(n)^2
09:22:12 <stilgart> I admit that I should have added "(log(n))^1000 is still less (in order of magnitude) than n"
09:48:44 * hackage hedgehog-classes 0.2.1 - Hedgehog will eat your typeclass bugs  https://hackage.haskell.org/package/hedgehog-classes-0.2.1 (chessai)
09:49:51 <Boarders> if I do cabal new-install [blah] and then want to run that program from the command line how can I find out what I need to add to my PATH to do it?
09:51:14 * hackage config-schema 1.0.0.0 - Schema definitions for the config-value package  https://hackage.haskell.org/package/config-schema-1.0.0.0 (EricMertens)
09:52:26 <fendor> Boarders, without cabal? or with cabal? You can use cabal new-install to install it to ~/.cabal/bin
09:52:33 <fendor> to install the executable
09:53:03 <solonarv> yeah, that is the default location
09:53:44 <solonarv> so unless you've changed it (which you can do by editing ~/.cabal/config) that is what you need to add to your $PATH
09:53:51 <Boarders_> thank you!
09:54:14 <solonarv> if you used ghcup to install ghc/cabal, you can simply source ~/.ghcup/env in your bashrc
09:58:46 <dmwit> You know what would be neat?
09:58:52 <dmwit> A way to declare a new open data kind.
09:59:09 <hyperisco> I was going to say "folding my laundry" but you didn't provide adequate quip time.
09:59:24 <dmwit> hyperisco: Score one for the good guys.
09:59:57 <sm> it's important to remember adequate quip time
10:02:08 <dmwit> e.g. think about `newtype Temp a = Temp Double; class ToKelvin a where toKelvin :: Temp a -> Temp K`. Currently if we want to allow users to define new temperature scales, we have to choose `K :: *` (and so `Temp :: * -> *`), even though we might reasonably want to be able to rule out idiocy like `Temp ()` or `Temp Bool`.
10:03:04 <dmwit> It would be nice to say like `open kind TemperatureScale; data K :: TemperatureScale` or something like that.
10:04:10 <dmwit> Then we could rule out idiocy by putting explicit annotations on `Temp` and `ToKelvin` to say they only accept types of kind `TemperatureScale`.
10:05:17 <solonarv> does a data family work?
10:05:36 <dmwit> I wondered about that too, but couldn't think of a way.
10:05:39 <solonarv> (i.e. can data families/their constructors be promoted ?)
10:05:49 <dmwit> Because the promoted things have different kinds, see?
10:06:22 <solonarv> you could do something like: data family TemperatureScale (name :: Symbol)
10:06:47 <solonarv> and: data instance TemperatureScale "Kelvin" = K
10:08:45 <solonarv> and then anything that needs a TemperatureScale argument could simply be polymorphic in the 'name' parameter, and it would accept all instances
10:09:01 <dmwit> I guess that basically works? Indeed, we don't even need to restrict `name :: Symbol`. It can be whatever.
10:09:17 <dmwit> (Gotta have PolyKinds on anyway to be able to write the kind annotations for `Temp` and `ToKelvin`, so no harm there.)
10:10:31 <dmwit> Thanks, I like that trick!
10:10:56 <solonarv> glad I could help!
10:11:26 <dmwit> Hah. Tried `data instance TemperatureScale 'X = X` just for kicks, but the GHC devs already thought of that. =D
10:11:40 <Boarders_> does anyone here use glirc?
10:11:54 <dmwit> Some definitely do, yep. There's also a channel specifically for it.
10:13:00 <dmwit> Hm. Not specifically for it. But coopted to be specifically for it. ;-)
10:13:02 <dmwit> #haskell-irc
10:13:23 <Boarders_> thanks
10:33:05 <Rayler> Best way to leanr haskell?
10:33:11 <halogenandtoast> Do it
10:33:16 <dmwit> ?where tutorials
10:33:16 <lambdabot> http://haskell.org/haskellwiki/Tutorials
10:33:18 <monochrom> Depends on your brain.
10:33:30 <monochrom> And does it have to be "best"?
10:35:24 <isovector1> jle`: yt?
10:37:31 <isovector1> hoping someone can help with the data-reify package
10:37:51 <bahamas> does ghc offer an API to manipulate its AST?
10:38:14 <solonarv> it does
10:38:25 <bahamas> solonarv: where can I find it?
10:38:40 <solonarv> you can hook into the compiler (at various phases) using a compiler plugin
10:38:43 <bahamas> I'm looking at the ghc lib on hackage, but I haven't seen anything related to that
10:39:33 <zachk> doesn't template haskell allow manipulation of the AST, and some generic packages allow manipulations of ADT's 
10:39:47 <bahamas> solonarv: I'm more interested in using that functionality in my app. I know that haskell-src-exts exists, but I remember reading that it had some issues
10:40:35 <solonarv> in order: template-haskell only lets you manipulate the front-end (~ source haskell) AST, and it is not identical to GHC's internal AST
10:41:02 <solonarv> the main issue of haskell-src-exts is that it basically reimplements GHC's parser, which make sit hard to keep up with changes
10:41:44 <solonarv> what is it you actually want to do with the AST? GHC is usable as a library; for example you can pass it some code, have it type-check and desugar it, and inspect the resulting Core
10:43:22 <dminuoso> solonarv: You should change your nickname to have a capital `S` again. :)
10:43:47 <bahamas> solonarv: I want to parse haskell source and keep it in memory. then I want to create an alternative editing interface. that will communicate with the back-end that holds the AST in memory
10:43:57 <monochrom> Why!  Even yours and mine are lowercase...
10:45:10 <solonarv> bahamas: okay, that certainly seems doable. perhaps look at haskell-ide-engine to see examples of how to do that? IIRC it uses the GHC API
10:46:03 <solonarv> and it is certainly at a similar point in design space: it parses & analyzes haskell source code to offer augmented editing
10:46:25 <bahamas> solonarv: ok. I'll have a look
10:46:56 <bahamas> solonarv: indeed, I know about haskell-ide-engine. my attempt is more radical, but at least I can learn from them where the two projects overlap
11:36:16 <ekleog> How should I indent a let statement to have the compiler be happy?
11:36:43 <ekleog> I'm doing http://ekleog.xelpaste.net/HiTCVB and it's saying the "nix-build" is ill-indented
11:37:41 <monochrom> Where is your "in"?
11:37:45 <monochrom> Is this Haskell?
11:37:50 <alanz> ekleog, line 3 needs to be just past the nixbuild on line 2, for a start
11:38:01 <alanz> 3 to 7, that is
11:39:32 <solonarv> the indentation of the first token after the 'let' keyword determines the indentation of the whole block
11:39:37 <ekleog> monochrom: I've been copying from other code without `in`, though it was in monads -- I guess that's what tricked me?
11:39:39 <solonarv> also, you need an 'in'
11:39:41 <solonarv> yup!
11:39:53 <solonarv> in a 'do' block you can have a 'let' without 'in'
11:40:12 <monochrom> Yes. Also, it's clearer to say "it was in/using do-notation".
11:40:49 <monochrom> In fact in a couple of years there will be enough number of do-blocks that desugars to using Applicative rather than Monad.
11:40:53 <solonarv> (which you technically *can* use without moands being involved)
11:41:12 <solonarv> monochrom: also RebindableSyntax (rare) and single-statement do blocks
11:41:15 <ekleog> alanz solonarv: oh, so I need to add parenthesis around the list to get it to parse as a block that's going to get into nixBuildCmd as a value?
11:41:30 <solonarv> no, parentheses are not the problem
11:41:50 <halogenandtoast> Is there a good resource for looking at using lenses with records, just want to adopt some best practices.
11:41:55 <ekleog> ooooh got it
11:41:58 <ekleog> it's not enough indented
11:42:00 <solonarv> the stuff between 'let' and 'in' has to be indented at least as much as the first thing after 'let'
11:42:20 <ekleog> I was thinking it was looking similar to another let below in the code but that's why. Thank you! :D
11:42:31 <solonarv> also, I'm pretty sure your 'do' block below does not need parentheses
11:42:51 <alanz> ekleog, I hit the reply to snippet thing
11:43:04 <alanz> with an indentation that might help
11:43:19 <ekleog> alanz: gotcha, thanks :)
11:43:41 <ekleog> solonarv: AFAIU it's getting passed as an argument to `catchany_sh`, so it needs either parentheses or a $
11:44:30 <solonarv> oh, right
11:44:42 <solonarv> well, not on ghc 8.6 if you enable BlockArguments ;)
11:46:23 <monochrom> I debated myself whether to use BlockArguments in code for students when I wrote "withFile WriteMode $ \h -> ..."
11:47:32 <Rembane> monochrom: Who won? 
11:47:49 <monochrom> "fewer extensions" won
11:48:12 <Rembane> That's a classic. 
11:48:15 <monochrom> But I won.
11:48:23 <monochrom> LEM strikes again! >:)
11:48:51 <hyperisco> isn't that the idempotency of disjunction?
11:49:07 <monochrom> No I didn't use that.
11:49:28 <monochrom> I used: Either use BlockArguments or don't.
11:49:35 <__monty__> Who's lem?
11:49:36 <Rembane> LEM ftw! 
11:49:46 <Rembane> Lem has a tendency to always win.
11:49:53 <hyperisco> Oh, I used monochrom won or monochrom won.
11:50:10 <hyperisco> (is true)
11:50:12 <__monty__> Ah, got it.
11:50:49 <monochrom> Law of Either Monochrom. >:)
11:51:01 <jle`> monochrom: block arguments is nice, but last time i tried it none of my tooling had caught up yet
11:51:12 <monochrom> Yeah!
11:51:16 <jle`> it'd be nice for teaching purposes if you could have some sort of custom configuration to load, extension-wise
11:51:28 <monochrom> When is the next stable release of emacs haskell-mode!
11:51:30 <jle`> it's really weird trying to assure students that -XTupleSections is ok
11:51:41 <hyperisco> see, I might ask what BlockArguments is, but in light of our prior conversation I am afraid to
11:52:04 <jle`> it's a purely syntactical extension that i've been jealous of purescript for having forever
11:52:10 <hyperisco> ah, okay, I figured as much… what I've been doing in PureScript for over a year :P
11:52:15 <monochrom> It's OK hyperisco!  It allows me to write "withFile WriteMode \h -> ..."
11:52:18 <jle`> also it means $ no longer needs to be special-cased magic'd
11:52:55 <jle`> well, it still needs to if you use it
11:52:58 <monochrom> Yeah "runST $ do ..." is super annoying.  Now you can have "runST do make me a sandwich"
11:53:01 <jle`> but it means youi don't need $ to do runST magic anymore
11:53:45 <hyperisco> I can say from experience that it influences how you order function parameters. Now I prefer a function parameter to be trailing rather than leading!
11:53:45 <__monty__> jle`: Implicit extensions would be far worse than the status quo imo.
11:53:53 <monochrom> But in the interest of not breaking old code, I think special-$ is here to stay, alongside with return.
11:54:07 <sarahzrf> is there any sane way to enter strings at ghci
11:54:09 <hyperisco> flip traverse, flip fmap, flip it all!
11:54:14 * hackage line-drawing 0.1.0.0 - raster line drawing  https://hackage.haskell.org/package/line-drawing-0.1.0.0 (fffaaa)
11:54:16 <sarahzrf> which may contain quotes and stuff
11:54:24 <jle`> __monty__: maybe just as a training wheels maybe
11:54:29 <sarahzrf> sorry thats not really my question let me go back
11:54:29 <jle`> sarahzrf: you can do getLine, i suppose?
11:54:40 <jle`> myString <- getLine
11:54:45 <monochrom> I learned that evalCont and evalContT are flip runCont and flip runContT. :)
11:54:47 <jle`> and ghci will enter getLine mode
11:54:51 <sarahzrf> yeah, what i really meant to ask was, is there any way to getLine from ghci with sane editing behavior :V
11:55:03 <sarahzrf> e.g., at the very least the ability to backspace
11:55:31 <jle`> hm, i wonder if you can do something with haskeline
11:55:40 <monochrom> No, sane editing behavious is explicitly using a line-editor library like haskeline or readline.
11:56:19 <monochrom> Even bash is explicitly using readline. Not a kernel-supplied cooked mode line buffering. (Compare with sh.)
11:56:51 <monochrom> getLine is merely stdin.
11:57:04 <jle`> yeah, haskeline seems to work well for me
11:57:06 <sarahzrf> yes, but it's unbuffered stdlin
11:57:07 <sarahzrf> *stdin
11:57:13 <jle`> myString <- H.runInputT H.defaultSettings H.getInputLine ""
11:57:30 <sarahzrf> :\
11:57:53 <jle`> let fancyGetLine = H.runInputT H.defaultSettings H.getInputLine ""
11:57:57 <jle`> myString <- fancyGetLine
11:58:08 <jle`> er that shouild be (H.getInputLine "")
12:02:57 <__monty__> sarahzrf: Why not just enter a string literal if it's ghci anyway?
12:06:50 <sarahzrf> __monty__: well, sometimes i wanna enter something that has a bunch of characters in it that id have to escape, or sometimes i wanna test out running an IO procedure that invokes getlines
12:21:48 <__monty__> sarahzrf: How about composing in editor-of-choice before pasting to getLine.
12:22:11 <sarahzrf> thats what i generally resort to if i get fed up :(
12:23:39 <monochrom> haha
12:24:00 <monochrom> Actually sometimes I use my IRC input space for this!
12:24:39 <monochrom> "HexChat. monochrom's editor of choice."
12:25:37 <hyperisco> I've used the HexChat message box as a clipboard swap space because it just happened to be readily available
12:25:57 <hyperisco> though I can say the same of any application that works with the clipboard
12:26:14 <hyperisco> (what can go wrong?)
12:26:21 <hc> =)
12:26:23 <monochrom> Just don't press enter.
12:26:38 <hc> ever used it for a password and accidentally pressed enter?
12:26:56 <monochrom> Don't worry, passwords become *******
12:27:11 <hc> oh really? that's cool! let me test that
12:27:17 <hc> sdf3Cj178ByXOloS85Wh
12:27:38 * hyperisco suddenly becomes aware that hc is not hpc
12:27:41 <hc> hmm, my client still shows the real password, so the replacement probably only happens for everyone else
12:28:47 <jle`> that is also my conclusion based on the fact that i see stars on my screen
12:28:56 <hc> ah good :=)
12:28:57 <hc> how does the client know it's a password, btw? i mean, it could theoretically be a higher order haskell function
12:29:41 <c_wraith> it feels weird to walk into a 20 year old joke.
12:30:02 * hyperisco puts on his robe and wizard hat
12:34:00 <monochrom> Usually Haskell function names are random like sdf3Cj178ByXOloS85Wh.  Whereas passwords are usually meaningful like mySecret.  So the client estimates the entropy, high entropy => likely Haskell code, low entropy => likely password.
12:34:41 <hyperisco> lmao
12:34:42 <monochrom> Aw, I blew my joke, should have stuck to "meaningless" instead of "random".
12:35:10 <hc> :-)
12:35:25 <[exa]> monochrom: don't worry, everyone knows randomness can't be achieved
12:35:58 <[exa]> monochrom: if I used better IRC client, it would s/random/meaningless/ automatically given the context.
12:36:13 <monochrom> :)
12:38:34 <monochrom> Revisionist history: edwardk wrote lens because he needed a source of passwords.
12:39:30 <monochrom> On that note, I need a cute example of record type for a C lecture.
12:39:31 <hyperisco> "Your password must include at least 2 profunctors"
12:39:38 <monochrom> :D
12:40:10 <monochrom> Maybe (x,y) coordinate isn't that bad.
12:40:50 <hyperisco> Isn't  struct Person { char[25] name; int age; }  obligatory?
12:41:12 <dmwit> struct HList { void *element; struct HList *next; };
12:41:20 <monochrom> heh hlist
12:41:22 <[exa]> monochrom: "polymorphic" prefix list_head with T[0] last member for offsetof-style content pointing
12:42:18 <[exa]> also, union of float with sign/mantissa/exponent bitfields is lovely
12:45:18 <hyperisco> oh boy… so in JavaScript I added some rigor wrt the differentiation of bitfields and numbers… part of that is teasing the bytes out of a double precision float, except I cannot do that with bitwise operations because bitwise operations automatically truncate to a 32-bit integer.
12:46:02 <hyperisco> So, I had to do it with arithmetic in such a way that it put the bits in the right spot so I could get them out with bitwise operations. There's a fun exercise!
12:46:22 <hyperisco> Also, constructing a double precision float from bytes…
12:47:54 <[exa]> in fact, javascript seems to be a great venue for that kind of stuff.
12:48:29 <hyperisco> Kids think teachers come up with these silly restrictions out of the blue. Ho ho!
12:50:07 <c_wraith> the latest versions of browsers give you a real 64-bit integral primitive in Javascript.
12:50:11 <hyperisco> There's actually a more sane option of using typed arrays, but I think one of the directions benched faster doing the arithmetic instead… would have to dig up the code again.
12:51:34 <hyperisco> Some day maybe we'll collectively stop conflating numbers and bitfields…
12:52:08 <hyperisco> Even saying "32-bit integer" is danger close to that.
12:52:24 <[exa]> can't see that happening with any actual CPUs around
12:53:28 <hyperisco> More of a language thing… there's nothing wrong with relating a bitfield to a number through 2's complement, or an IEEE float, but that usually isn't done.
12:54:13 <hyperisco> Rather in one moment something is like a number and in the next it is like a bitfield, and the sanity of what is taking place can be lost.
12:55:25 <hyperisco> If we want to talk integers why not talk about modular arithmetic… that maps dandy to hardware.
12:56:27 <[exa]> Hm anyway, how does gloss handle resource allocation for rendering bitmap-ish stuff? Say, I have 10k small bitmaps loaded in memory, and relatively often switch the exact ones I'm displaying (totally less than 100 are displayed at any time point). Is that going to hit some texture memory/count limit, or is it going to behave just right?
12:57:38 <dmwit> I don't know gloss, but even so I'd be shocked if it did any management of that stuff on your behalf.
12:57:48 <dmwit> I'd be willing to place a pretty steep bet you have to do it all yourself.
12:59:12 <[exa]> hyperisco: hm you're right about the language thing, CPU only sees 32bit blobs; instructions give the actual "type"
12:59:25 <hyperisco> yes!
12:59:27 <[exa]> dmwit: ok thanks :D
12:59:30 <dmwit> http://hackage.haskell.org/package/gloss-1.13.0.1/docs/Graphics-Gloss-Data-Bitmap.html seems to more or less agree with me
13:00:26 <dmwit> That said 10k 10x10 bitmaps is like 10MB. So who cares.
13:01:24 <hyperisco> The assumption of 2's complement is pervasive and implicit. I am often not in favour of implicits for the usual reasons.
13:02:02 <hyperisco> Heck, there is the matter of endianness, for one thing.
13:02:27 <hyperisco> bitfields are not concerned about endianness, whereas number encodings are
13:04:08 <[exa]> oh noes, BitmapData contains Ptr Word8 and a mysterious field called bitmapCacheMe
13:08:35 <lambdabot> Is this thing on?
13:08:43 <orion> I'm using Persistent/Esqueleto with the sqlite backend. I am getting this error intermittently: SQLite3 returned ErrorMisuse while attempting to perform bind text. It happens when I hammer the application with many concurrent web requests. As a result I suspect that this is a race condition. Has anyone else experienced this?
13:12:14 * hackage imm 1.6.1.0 - Execute arbitrary callbacks for each element of RSS/Atom feeds  https://hackage.haskell.org/package/imm-1.6.1.0 (koral)
13:12:15 <[exa]> orion: https://sqlite.org/rescode.html
13:12:41 <[exa]> orion: you're probably destroying the prepared statement before you get it, or perhaps ignoring earlier errors
13:13:37 <orion> "Misuse detection is probabilistic." Interesting.
13:13:46 <[exa]> not sure how well esqueleto handles concurrency though
13:14:29 <[exa]> how much concurrent request hammering do you need to see the error?
13:14:42 <kostas> orion: do you use the Data.Pool for concurrency?
13:15:59 <sm[m]> infinisil: did you find out if ghc 8.8 is faster ?
13:16:06 <zachk> is sqlite even thread safe? 
13:16:35 <infinisil> sm[m]: It was just a feeling when using it, I can neither confirm it's faster nor would I know a reason
13:17:33 <[exa]> zachk: it can be turned off when compiling, but generally it's safe
13:17:34 <kostas> zachk: it is supposed to be if you compile it in ThreadSafe mode. But it is still tricky.
13:17:34 <orion> kostas: No. I am using servant like so: withSqliteConn connInfo $ \backend -> liftIO $ run 5000 $ app
13:19:48 <kostas> Do you use any locks or just query using the backend?
13:20:35 <dminuoso> kostas: What kind of locks do you think you would need?
13:20:35 <orion> I do not use any locks.
13:21:06 <dminuoso> kostas: sqlite features serializable transactions with ACID properties... :)
13:21:30 <dminuoso> Transactions beat manual locking.
13:24:58 <kostas> dminuoso: But these are transactions from the same connection. This shouldn't happen.
13:26:11 <kostas> A single persistent `backend` backs up a single SQlite connection.
13:31:55 <sm[m]> infinisil: I want to believe, I'm sure it's real!
13:34:43 <mikeplus64> anyone played around with sequences based on foldr or indexing? 
13:35:32 <edwardk> monochrom: nah, i just wanted a custom prelude that everyone would use
13:35:33 <mikeplus64> https://gitlab.com/transportengineering/vector-odd/blob/master/src/Data/Vector/Odd/Index.hs for indexing and in the same dir there is Slice.hs using folds on specific ranges ...
13:35:56 <edwardk> it was an exercise in branding
13:37:02 <mikeplus64> it seems useful ... maybe ...? except that in both cases inlining is pretty handily defeated
13:45:01 <dminuoso> So in category theory people keep flinging around this word "functoriality" - is there a coherent meaning for this term?
13:47:30 <monochrom> I think it just means "this thing is a functor".
13:49:16 <MarcelineVQ> seems like it https://ncatlab.org/nlab/show/functor#idea
13:50:09 <dminuoso> MarcelineVQ: Ohh, strangely it didn't occur to me to consult nlab (I've been digging a bit in google, but didn't find it).
13:50:27 <dminuoso> MarcelineVQ: So that seems to rather state that functoriality is about the morphism/composition preservation portion of the functor.
13:50:54 <dminuoso> So it's functoriality that seperates a functor from a function (if we assume small categories of course)
13:58:02 <jle`> dminuoso: that's kind of a tautology, isn't it?
13:58:14 <jle`> something is a functor iff it has functoriality
13:58:32 <dminuoso> jle`: Then I truly do not understand why people fling around a redundant term for this.
13:58:48 <dminuoso> Unless functoriality is trying to capture some philosophical meaning.
13:58:52 <jle`> it's probably just a conjugation of fucntor that makes sense gramatically
13:58:55 <jle`> in that context
13:58:59 <dminuoso> Oh.
13:59:05 <jle`> like, functor as an adjective
13:59:07 <solonarv> jle`++
13:59:19 <solonarv> well no, functor-as-an-adjective is "functorial"
13:59:44 <dminuoso> so functoriality would be "functor-as-an-adjective-turned-into-a-noun-again"
13:59:48 <solonarv> "functoriality" is the correspnding property: something "has functoriality" if it "is functorial"
14:04:29 <monochrom> adult (noun), adult (adjective), adulthood (noun) referring to whether you are an adult.
14:05:11 <monochrom> functoriality, naturality, childhood, adulthood.
14:05:33 <monochrom> Yes some people use them pompously. But there are good uses too.
14:12:06 <jle`> adulthood = a dull thud
14:13:22 <Fare> Hi. I'm trying to use language-javascript-0.6.0.12 but it fails to compile with: happy: language-javascript-0.6.0.12/src/Language/JavaScript/Parser/Grammar7.y: hGetContents: invalid argument (invalid byte sequence)
14:15:06 <Fare> that's not a very informative message from happy-1.19.10
14:15:15 <Fare> how do I debug this kind of things?
14:19:46 <sm[m]> Fare: that kind of message usually means you're processing non-ascii and the system locale isn't set to a locale that can handle it
14:19:59 <sm[m]> usual fix: export LANG=en_US.utf-8 or whatever
14:21:06 <sm[m]> would anyone remember how to enable call stacks for code run from GHCI prompt ?
14:21:53 <zeta_0> has anyone here used yesod with emacs?
14:22:54 <sm[m]> add -fexternal-interpreter -prof, it looks like
14:22:57 <alx741> zeta_0: is there something peculiar about it?
14:23:16 <sm[m]> zeta_0: yes
14:24:12 <sm[m]> nice! traceStack works
14:26:14 * hackage sdl2 2.5.0.0 - Both high- and low-level bindings to the SDL library (version 2.0.6+).  https://hackage.haskell.org/package/sdl2-2.5.0.0 (OliverCharles)
14:28:51 <sobad> should i use polysemy in a project if i am a relative newcomer to haskell?
14:29:00 <sobad> or just do IO things 
14:29:21 <jle`> probably not
14:29:54 <sobad> so just doing everything in IO is okay?
14:30:02 <jle`> the only time i'd use a managed effects system is probably for a large-scale project
14:30:06 <sobad> i heard people frown upon this 
14:30:11 <jle`> sobad: it depends on what you mean by 'everything'
14:30:18 <jle`> but you might be mistaking the problem that polysemy solves
14:30:30 <jle`> there is nothing wrong with using IO when you want to do IO
14:30:31 <sobad> i mean toplevel effects like DB access and filesystem/forkIO things
14:31:06 <jle`> db access, some libraries offer their own DB action/monad you can use, but you can just work with that and eventually run it in IO
14:31:13 <jle`> for the most part there isn't anything wrong with using IO to do IO
14:31:20 <jle`> i'm not sure why people would frown upon that
14:31:33 <Welkin> I do all my database access in plain IO
14:31:48 <sobad> something about testability but i don't write tests for effects ..
14:31:55 <sobad> maybe i should
14:32:01 <monochrom> I frown upon using big hammers and over-generalizations on what you don't need them for.
14:32:24 <monochrom> Now go tell the other people what I frown upon.
14:32:49 <monochrom> If someone tells you they frown upon using IO directly, go tell them I frown upon frowning upon using IO directly!
14:33:02 <sobad> okay sir/madam
14:33:02 <zeta_0> sm[m]: well, how did you do it? i am trying to setup yesod with the emacs package: `web-mode.el`
14:33:49 <sobad> i am also scared about async excepltions
14:34:08 <jle`> luckily IO can handle that, too :)
14:34:28 <jle`> in fact it is rather "OG", as the kids say these days
14:34:31 <sobad> yeah just using bracket for that for now
14:34:31 <zeta_0> alx741: i am not sure how to integrate the yesod engine with emacs? http://web-mode.org/
14:35:15 <jle`> the only time i would ever suggest a newcomer to learn polysemy is if they started working at a company with a 20 person team and the project used polysemy
14:35:50 <jle`> polysemy is even bleeding edge as far as abstract/modular effects systems go
14:36:10 <jle`> if it was a 19 person team i would tell them to wait
14:36:24 <jle`> 20 is the hard cut-off for me
14:36:29 <monochrom> heh
14:36:50 <sm[m]> zeta_0: what are you trying specifically, and what's going wrong ?
14:37:22 <jle`> sobad: everything you want to do in haskell , to build an application, you can usually do with just IO
14:37:34 <jle`> and it's not a bad tool for it either
14:37:49 <jle`> note that that's not the same as "doing everything in IO" -- you don't want to do things like pure addition of integers in IO, for example
14:38:03 <sobad> i was seeing lots of hype on mtl and effects so i was worried
14:38:18 <jle`> but the main benefit of those higher-level abstractions usually are for things like maintainability, refactorability, ease in testing, etc. 
14:38:46 <sobad> so for small personal projects i shouldn't bother with this iiuc?
14:38:51 <solonarv> yup
14:38:55 <jle`> they don't actually enable any functionality that was otherwise not possible without IO
14:38:55 <glguy> Trying to use mtl as an effect system tends to generate some really bad results as it forces people to compromise their code to make things fit
14:39:13 <jle`> s/without/with just
14:39:24 <solonarv> and Haskell is already very easy to refactor, so if you decide to use an effect system alter on you can always switch
14:39:33 <edwardk> withEngine :: MonadUnliftIO m => (GivenSetupInfo => ((GivenFrameInfo => m a) -> m ()) -> m ()) -> m () -- whee
14:39:50 <jle`> especially if you're a newcomer, it's good to get comfortable working with IO as well, as a lot of the lessons generalize to those sorts of more abstract effects systems
14:40:30 <solonarv> on top of that, in the end if you want to write files or communicate over the network or draw graphics or whatever there will still be IO involved somewhere
14:40:39 <edwardk> glguy: s/mtl as //
14:40:46 <zeta_0> sm[m]: when i scroll down to the: `Engine families` section i don't see yesod? http://web-mode.org/
14:41:18 <glguy> edwardk: I'm on board, that was just more of a battle than I had time for :)
14:41:33 <edwardk> glguy: heh, trying a funny experiment in "effects" in my current engine code actually
14:41:48 <zeta_0> sm[m]: did you have to do anything for `web-mode.el` to recognize yesod?
14:41:53 <edwardk> i have a ton of things i want to plumb everywhere like i would usually application state in a big mutable ball of mud style application
14:42:08 <edwardk> access to the freetype library, harfbuzz, sdl's window, input events, options, etc.
14:42:12 <zeta_0> sm[m]: how exactly did you setup yesod in emacs?
14:42:25 <edwardk> using implicit parameters to push them around only to where they need to go 
14:42:34 <edwardk> that is what that GivenFoo stuff is
14:42:40 <solonarv> edwardk: did you have anything to do with the 'sdl2' update a few minutes ago? just wondering
14:42:48 <edwardk> solonarv: probably
14:43:06 <edwardk> solonarv: talking to ocharles now, and i pushed a release of fixed and of StateVar that affectit
14:43:14 <glguy> Because then you get the constraint solver to figure out what pieces need to go where instead of having to write selectors everywhere?
14:43:25 <edwardk> fixed was a bug in 15.16 precision rounding
14:43:40 <edwardk> and StateVar was an extra instance which i stupidly pushed as a major release because i'm a bad maintainer
14:43:49 <edwardk> glguy: yeah
14:43:54 <sm[m]> zeta_0: for editing hamlet templates, eg, I probably used the default html mode. I've never used web-mode. There's a hamlet-mode you could install from melpa.
14:44:19 <edwardk> glguy: was experimenting with using it to make a parser that has almost no fields being passed around the other day
14:44:22 <sm[m]> if you're talking about something else, you should say what you mean :)
14:44:27 <edwardk> they get passed using reflection
14:46:29 <edwardk> e.g. https://github.com/ekmett/codex/blob/59c669f2f756d2f458052c1a91d8956a30cc4f46/parsnip/old/Sum.hs#L222
14:46:54 <edwardk> if you don't look at your position down in some sub parse-tree i don't bother to pass the information needed to be able to calculate it
14:47:11 <zeta_0> sm[m]: thanks, if i have any problems with web-mode.el i will give hamlet a try
14:47:13 <edwardk> it just has the current pointer into a null terminated string for state and an unboxed sum of success of failure as state
14:47:22 <edwardk> er of success or failure
14:48:35 <edwardk> i had a version of it that just had the pointer and didn't have the null termination property, but that required satisfy, etc. to take the implicit argument
14:48:52 <edwardk> er not implicit, this one uses reflection
14:50:11 <edwardk> https://github.com/ekmett/codex/blob/master/engine/src/Engine.hs#L47 shows a more complex example of me setting up a harness for user code
14:50:42 <edwardk> now i can use that harness with something like:
14:50:43 <edwardk> https://github.com/ekmett/codex/blob/master/engine/example.hs
14:51:27 <sm[m]> zeta_0: ok, good luck
14:51:39 <edwardk> in the setup/teardown areas i can make gl resources, use the file watching tools, etc. inside the call to drive i have access to the events and input buttons as well.
14:52:28 <edwardk> very much a "framework" rather than a library, but hey
14:53:42 <ocharles> solonarv: anything up?
15:03:34 <solonarv> ocharles: huh? not particularly
15:03:38 <solonarv> I just noticed the timing
15:04:10 <ocharles> Ah :)
15:05:03 <Fare> sm, I tried defining utf8 or latin1 environments, to no avail, and said file has no non-ascii content (but for all I know may be importing from another file that does). stack exec env seems to pass-through my locale variables.
15:10:45 * hackage servant-swagger-ui 0.3.4.3.22.2 - Servant swagger ui  https://hackage.haskell.org/package/servant-swagger-ui-0.3.4.3.22.2 (phadej)
15:13:15 * edwardk is currently forcing himself to switch to BlockArguments style
15:14:11 <sm[m]> Fare: what did you set LANG to ?
15:14:56 <sm[m]> and does locale -a show it, with exact spelling ?
15:35:45 * hackage nonempty-containers 0.3.0.0 - Non-empty variants of containers data types, with full API  https://hackage.haskell.org/package/nonempty-containers-0.3.0.0 (jle)
15:58:39 <ShYGirl99> Hello. I am new and I decided to try making a Live in a Cam site. Hope you will like my idea. The idea of being watched makes me really horny. Enter now: http://tny.im/6bnuJ
16:02:02 * dmwit . o O ( new to what? )
16:02:41 <subttle> lmao
16:03:40 <Berengal> How do I create a good Arbitrary instance for a tree?
16:03:56 <dmwit> You use that one package that's based on Boltzmann sampling or whatever.
16:04:26 <subttle> Berengal: yeah I think byorgey did a nice write up on that
16:04:48 <subttle> https://byorgey.wordpress.com/2013/04/25/random-binary-trees-with-a-size-limited-critical-boltzmann-sampler-2/
16:04:49 <dmwit> http://hackage.haskell.org/package/boltzmann-samplers I think?
16:05:10 <dmwit> But it's tough to keep up. I think there was one based on Generic that's now considered outdated; and the one I linked suggests another package.
16:05:16 <dmwit> So I don't know what the current status is.
16:06:30 <Berengal> Nice, thanks
16:13:08 <monochrom> w00t boltzmann sampler
16:45:03 <lyxia> Berengal: both are alive (as in if you have any bug or question or request I will patch the bug and answer)
16:45:18 <lyxia> "both" being boltzmann-samplers and generic-random
16:45:41 <lyxia> you probably want generic-random
16:51:51 <lyxia> the story is that generic-random started with boltzmann samplers, and then I figured that the complexity is really not worth it in practically all cases so I rewrote it and moved boltzmann samplers out.
16:54:12 <lyxia> The theory of it is so cool though.
17:37:39 <lordcirth_> Having some trouble understanding how Prisms compose with Lenses. I have a record "p :: Part" which contains "_engineInfo :: Maybe EngineInfo". "EngineInfo" contains "_thrust :: Int". I can do "e = preview _Just (p^.engineInfo)". What is the correct way to compose so I can cleanly get a "Maybe Int"?
17:39:35 <lordcirth_> Or am I doing everything wrong? :P
17:45:39 <mightybyte> Anyone know how to spawn a new process and then read its stdout in a blocking fashion?  hWaitForInput doesn't seeem to work.  It's terminating with an EOF exception.
17:50:46 <Welkin> with getLine not be enough?
17:50:49 <Welkin> will
17:51:02 <Welkin> or, getChar, or others
17:53:31 <mightybyte> Welkin: I also tried hGetLine.  That also terminates with an EOF exception.
17:53:57 <lordcirth_> mightybyte, are you sure the process isn't sending EOF / closing the pipe?
17:55:05 <mightybyte> lordcirth_: Pretty sure...I guess?  I'm just doing withCreateProcess and running git.
17:56:44 <mightybyte> I'm pretty sure git isn't closing the pipe because if I catch the EOF exception and continue polling, it eventually gets all of the output.
17:57:53 <Axman6> can you share the code?
17:59:21 <Welkin> you ned to sign an NDA first
17:59:22 <mightybyte> Axman6: https://gitlab.com/mightybyte/zeus/blob/master/backend/src/Backend/Build.hs#L339
17:59:32 <mightybyte> Not for this.  :)
17:59:47 <mightybyte> That collectOutput function is called by runCmd just above it.
18:00:14 <Welkin> zoose
18:01:58 <Axman6> what does hWaitForInput with -1 do?
18:02:07 <mightybyte> Same thing
18:02:39 <Axman6> ?
18:02:46 <mightybyte> Dies with an EOF exception
18:03:15 <mightybyte> Catching the exception turns it into a hot spinning loop.
18:10:53 <solonarv> lordcirth_: regarding your lens question: you can simply compose lenses and prisms directly (the result will be a traversal)
18:11:28 <lordcirth_> solonarv, That's what I thought; but I can't seem to figure out the correct order / syntax
18:11:43 <solonarv> then you can use: preview (engineInfo . _Just) p -- or: p ^? engineInfo._Just
18:13:07 <lordcirth_> solonarv, ok, and then to get 'thrust' as a Maybe Int?
18:13:09 <solonarv> the gotcha is that the order is reversed compared to composing "normal" record accesors
18:13:34 <lordcirth_> (engineInfo . _Just . thrust) ?
18:13:38 <solonarv> yup!
18:14:07 <lordcirth_> perfect, thanks!
18:17:29 <lordcirth_> solonarv, ok, so now I have a list of Maybe Int; what is the idiomatic way to sum them, as if Nothing was 0?
18:19:14 <infinisil> :t traverse (undefined :: [Maybe Int])
18:19:15 <lambdabot> error:
18:19:15 <lambdabot>     • Couldn't match expected type ‘a -> f b’
18:19:15 <lambdabot>                   with actual type ‘[Maybe Int]’
18:19:22 <infinisil> :t sequence (undefined :: [Maybe Int])
18:19:23 <lambdabot> Maybe [Int]
18:19:54 <infinisil> :t sum <$> sequence (undefined :: [Maybe Int])
18:19:55 <lambdabot> Maybe Int
18:20:02 <infinisil> lordcirth_: ^
18:21:06 <lordcirth_> That's equivalent to 'fmap (sum) sequence  (undefined :: [Maybe Int])' right?
18:21:53 <c_wraith> :t sum . catMaybes
18:21:54 <lambdabot> Num c => [Maybe c] -> c
18:22:25 <c_wraith> keep things simple. :)
18:23:18 <lordcirth_> c_wraith, oh, that's handy!
18:23:47 <lordcirth_> And sum [] is already safely 0 
18:23:59 <c_wraith> yep. works out nicely.
18:25:06 <lordcirth_> That's perfect, thanks!
18:33:59 <Axman6> @hoogle _Sum
18:34:00 <lambdabot> Numeric.Natural.Lens _Sum :: Iso' Natural (Either Natural Natural)
18:34:00 <lambdabot> Data.Number.MPFR.FFIhelper mpfr_sum :: Ptr MPFR -> Ptr (Ptr MPFR) -> CULong -> CRoundMode -> IO CInt
18:34:00 <lambdabot> Numeric.GSL.Statistics tot_sumsq :: Vector Double -> Double
19:06:28 <jle`> lordcirth_: you can do (foldMap . foldMap) Sum, i suppose. if you have many layers of nesting
19:06:48 <jle`> :t getSum . (foldMap . foldMap) Sum
19:06:49 <lambdabot> (Foldable t2, Foldable t1, Num c) => t1 (t2 c) -> c
19:07:08 <jle`> > (getSum . (foldMap . foldMap) Sum) [Just 1, Just 2, Nothing, Just 3]
19:07:09 <lambdabot>  6
19:07:31 <jle`> but for specifically [] and Maybe i'd use catMaybes and sum, yeah :)
19:09:03 <lordcirth_> jle`, I will keep that in mind, but I don't have that many layers just yet. Thanks
19:09:48 <jle`> yeah, this way you can sum through aribtrary amounts of layers by just adding more foldMaps
19:09:57 <jle`> (foldMap . foldMap . foldMap) Sum will add through three layers, for instance
19:10:07 <lordcirth_> That's pretty cool, yeah
19:12:46 <jle`> actually you can get rid of the newtype overhead with some lensisms, too
19:12:56 <jle`> the wrapping/unwrapping of sum is what sumOf does
19:13:12 <jle`> > sumOf (folding . folding) [Just 1, Just 2, Nothing, Just 3]
19:13:14 <lambdabot>  error:
19:13:14 <lambdabot>      • Couldn't match type ‘(a -> f1 a) -> f0 (a -> f1 a)’
19:13:14 <lambdabot>                       with ‘Const (Endo (Endo a)) (f1 a -> f0 (f1 a))’
19:13:35 <jle`> > sumOf (folded . folded) [Just 1, Just 2, Nothing, Just 3]
19:13:37 <lambdabot>  6
19:30:33 <isovector1> jle`: some updates on yesterday! your instance works! but it loses sharing between the elements for some reason
19:31:33 <isovector1> i think the right solution might be to stop cargo culting, write a gadt for my type that does multiples and singles, and then use data-reify as it was meant to be used
19:46:58 <infinisil> Does GHC optimize Nothing to be a null pointer?
19:47:26 <infinisil> I think this should be possible in theory, but would require some special casing for the Maybe type
19:48:01 <infinisil> Or just any type that has the form `data M a = N | J a` actually
19:51:17 <infinisil> Ah I found something here: https://gitlab.haskell.org/ghc/ghc/wikis/unpacked-sum-types#exploiting-nullary-constructors
19:52:08 <int-e> infinisil: No it does not. However pointer tagging and the fact that unary constructors are not allocated on the heap gets you much of the same effect: In many cases, the runtime can tell that a value is Nothing without dereferencing the pointer.
19:52:31 <int-e> (And creating a Nothing value does not cause any allocation.)
19:53:28 <infinisil> Neat
19:53:36 <int-e> That link has a *strict* type, that's different...
19:55:01 <Cale> Have to be careful, or you end up with the same problem that aeson's encoding for Maybe has, which is that Just Nothing and Nothing encode to the same thing.
19:55:36 <int-e> Yeah but the code in that link maintains an explicit tag, so that should be fine.
19:55:44 <Cale> yeah
20:00:36 <infinisil> Cale: I remember that problem from Swift too (or many other languages too probably), where nil has the ambiguous type Option<a> and Option<Option<a>>, etc.
20:01:50 <Cale> Well, *that's* okay
20:02:35 <infinisil> Which makes inserting nil's into dictionaries problematic, because when the dict holds values of type Option<a>, and you assign dict[key] = nil, this can either mean "remove this key" or "set the key to the value nil"
20:03:06 <infinisil> In haskell the former would be Nothing, the latter would be Just Nothing
20:03:17 <Cale> ah, yeah, there needs to be a distinction between Nothing and Just Nothing
20:03:24 <Cale> It's okay for Nothing to be polymorphic though
20:03:27 <Cale> :t Nothing
20:03:29 <lambdabot> Maybe a
20:03:30 <infinisil> Oh right
20:03:36 <Cale> :t Nothing :: Maybe (Maybe Integer)
20:03:37 <lambdabot> Maybe (Maybe Integer)
20:04:32 <infinisil> Yeah, I guess I meant to say that a value a has the type a and Option<a> and Option<Option<a>>, ... 
20:06:23 <dmwit> oh, yuck
20:06:30 <dmwit> You don't need an explicit Just?
20:06:35 <dmwit> How do you... disambiguate?
20:27:14 * hackage aeson-typescript 0.2.0.0 - Generate TypeScript definition files from your ADTs  https://hackage.haskell.org/package/aeson-typescript-0.2.0.0 (thomasjm)
22:12:39 <orzo_> Hello
22:13:23 <orzo_> I have a situation where a spec says something is an integer, but i am required to accept a float.  So floor/ciel/round/truncate ... which is best if I don't really care?
22:13:29 <orzo_> which is fastest?
22:32:57 <jle`> well, they all do different things
22:33:03 <jle`> so which one you pick will depend on which behavior you want
22:33:23 <jle`> ( orzo_ )
22:33:37 <jle`> being faster is no good if your answer is wrong :)
22:33:57 <jle`> the "fastest option" is probably (const 0)
22:52:44 * hackage pandoc 2.7.3 - Conversion between markup formats  https://hackage.haskell.org/package/pandoc-2.7.3 (JohnMacFarlane)
23:10:39 <iqubic> But that's most likely not what you want.
23:12:11 <iqubic> I mean, it might be, but I doubt it.
23:19:22 <iqubic> :t (const 0)
23:19:24 <lambdabot> Num a => b -> a
23:19:30 <maerwald> I would guess truncate is the fastest?
23:19:35 <iqubic> IDK man.
23:19:39 <nshepperd> i use 'round' when i need to convert floats which are known to be integers into integer types
23:19:46 <iqubic> But it depends on what you want.
23:20:02 <maerwald> he said it doesn't matter
23:20:07 <iqubic> nshepperd: Just use and (Either Float Int) and that will work just fine.
23:20:09 <maerwald> so probably -ffast-math
23:20:12 <nshepperd> 'truncate' does slightly less work but will cause pain and suffering if you somehow acquire 0.999999999
23:20:51 <iqubic> > truncate 0.9999999999999
23:20:54 <lambdabot>  0
23:20:57 <iqubic> Ouch.
23:25:03 <MarcelineVQ> iqubic: similar story for ceiling, a person should probably care instead of not care if they can accept a floating number and want to treat it as an integer
23:50:36 <koz_> jle`: Is 'undefined' even faster? :P
23:56:01 <Nevoic> What's the point of `map`? It simply serves a less general purpose than `fmap`.
23:56:25 <Nevoic> IIRC in the `pure` vs `return` debate, one is legacy. Is that the case with `map` vs `fmap` as well?
23:56:26 <koz_> Nevoic: Hysterical raisins I believe.
23:56:51 <MarcelineVQ> or put another way a more specific purpose. which is useful if you want to convey that you're working with lists or teaching someone
23:57:28 <MarcelineVQ> similar reason to why you might say [1] instead of pure 1
23:57:34 <Nevoic> Honestly it was just a point of confusion for me while I was beginning Haskell. I came from other languages that used `map` in the more general sense.
23:58:05 <Nevoic> I.E `map` exists on `List` and `Option` types in a lot of OO languages.
23:58:13 <koz_> :t foldMap pure
23:58:14 <lambdabot> (Applicative f, Monoid (f a), Foldable t) => t a -> f a
23:59:01 <Nevoic> MarcelineVQ: that's an interesting comparison, but that's not exactly true right?
23:59:52 <Nevoic> General functions can take general values or specific values, where general values can only be passed to general functions.
23:59:55 <Nevoic> If I'm not mistaken there.
