00:17:31 <petersen> cabal-install doesn't try an older cryptonite
00:31:27 <gentauro> petersen: `stack build`?
00:31:29 <gentauro> ...
00:31:35 <petersen> gentauro: yep
00:32:40 <gentauro> the only problem I've seen to have with `stack` is on `nixos`. I mean, it's because they don't "port" all the compilers and packages so I'm guessing that LTS + NixOS is kind of a joke?
00:32:53 <gentauro> (I would highle recommend not using that OS for build servers)
00:44:20 * hackage minilight 0.4.0 - A SDL2-based graphics library, batteries-included.  https://hackage.haskell.org/package/minilight-0.4.0 (myuon)
00:55:20 * hackage reason-export 0.1.2.0 - Generate Reason types from Haskell  https://hackage.haskell.org/package/reason-export-0.1.2.0 (AndreiBarbu)
00:58:50 * hackage servant-reason 0.1.2.0 - Derive Reason types to interact with a Haskell backend  https://hackage.haskell.org/package/servant-reason-0.1.2.0 (AndreiBarbu)
01:13:34 <HK416> Hello, Can anyone recommend a newish graphics card that works on qubes OS out of the box?
01:14:52 <jgt> HK416: This is the #haskell channel.
01:16:44 <HK416> oops, my bad. I shall ask on #qubes but if anyone here has any info of this I would be glad to have it.
01:24:32 <gentauro> HK416: I moved from Qubes OS to NixOS :)
01:24:35 <gentauro> (if that helps)
01:26:49 <EmilKarlson> the dynamic typing of nix does not help
01:34:27 <jgt> EmilKarlson: know of any better alternative?
01:34:46 <jgt> (to nix, not dynamic typing)
01:35:46 <EmilKarlson> not really
01:36:12 <EmilKarlson> create your own haskell edsl!
01:36:26 <jgt> like I don't already have enough work to do :P 
02:10:30 <runningriot9[m]> Hi guys anybody use intero nvim ?
02:12:18 <jgt> standard vim, no intero
02:15:20 <[exa]> +1 vim
02:16:14 <[exa]> runningriot9[m]: corrolary: most missing features are better implemented by a reasonable keyboard shortcut for switching to hoogle and/or tiling window manager
02:19:52 <runningriot9[m]> How can I use standard vim to communicate with ghci?
02:20:11 <jgt> runningriot9[m]: I use a vim-dispatch and tmux send-keys
02:20:23 <jgt> s/a //
02:20:44 <jgt> and a custom .ghci file for each project
02:21:18 <jgt> .ghci for project I'm looking at now: http://ix.io/1KCI
02:22:11 <jgt> runningriot9[m]: some bindings https://github.com/jezen/dotfiles/blob/master/.vimrc#L259-L262
02:22:37 <runningriot9[m]> <jgt ".ghci for project I'm looking at"> Cool thx
02:26:54 <runningriot9[m]> Do I need to have hlint and stylish Haskell too ?
02:27:24 <solonarv> if you want those commands to work, yes
02:27:38 <jgt> ^^
02:27:44 <runningriot9[m]> Lol
02:27:55 <ski> need, for what purpose ?
02:28:27 <jgt> I use those two tools often, so I have bindings for them. Otherwise, they're not necessary
02:32:53 <[exa]> I somehow consider :%hin a great binding
02:33:34 <[exa]> anyway, is there any man difference between stylish-haskell and hindent?
02:33:37 <[exa]> *main
02:34:41 <phadej> a lot, stylish-haskell mainly reformats imports
02:34:44 <phadej> and is configurable
02:34:55 <phadej> hindent is one-true-style and full source formatter
02:35:44 <[exa]> oic, so running both is probably a reasonable choice
02:37:56 <jgt> stylish-haskell also aligns :: in record definitions
02:38:22 <jgt> it doesn't do much, which suits me. I generally am not in favour of auto-formatting
03:05:10 <runningriot9[m]> @jgt I was sucessfull in dispatching send keys with tmux
03:05:11 <lambdabot>  Parse failed: TemplateHaskell language extension is not enabled. Please add ...
03:05:45 <runningriot9[m]> However I don't see the GhC booting up In another tmux window
03:07:04 <runningriot9[m]> Do I need the .ghci file for this purpose? I have just configured .vimrc so far
03:11:33 <ski> runningriot9[m] : fyi, it's not IRC custom to prefix people's nicknames with sigils like `@'. if you want to reference or address someone, simply mention their nickname. e.g. at the start of the message line, followed by a comma or colon, and then the message
03:12:50 <ski> runningriot9[m] : i think most IRC clients will highlight/alert if you mention their nickname, first thing in a message. but not as many, i think, will highlight/alert, if you don't have it as first thing. (also, i think most (?) highlights/alerts on private message)
03:13:16 <ski> also, `@' on IRC already mean something else (that the person in question is a channel operator)
03:13:41 <ski> (and, as you saw, lambdabot will think that you're trying to give it a command, if you start a message by `@')
03:14:30 * ski doesn't know about this VIm & TMux setup, though ..
03:14:32 <runningriot9[m]> Ah I didn't know that
03:14:58 <runningriot9[m]> No problem ski
03:15:04 <runningriot9[m]> ski
03:15:05 <ski> (IRC predates Twitter (did the `@'-convention you used originate on Twitter, or somewhere else ?))
03:15:21 <ski> .. perhaps you need to start the interactor in a TMux window, manually ?
03:15:25 * ski is just guessing, here
03:15:43 <runningriot9[m]> I will test that
03:15:50 <ski> jgt ^
03:17:13 <[exa]> ...irc channels are just hashtags
03:18:07 * ski chortles
03:21:51 <[exa]> (fortunately for twitter, IRC messages can only have 1 hashtag)
03:26:08 <ais> When i enter `stack ghci` and load some module, is it possible to import another module that's just a file somewhere in my file system?
03:27:41 <__monty__> [exa]: That doesn't sound right.
03:30:12 <__monty__> ais: Usually you'd refer to the module by name, e.g., Data.Functor.Module would be at ./Data/Functor/Module.hs or Data.Functor.Module.hs
03:32:02 <__monty__> ais: You can try :m +Module.hs but I don't think that takes paths either, only module identifiers.
03:32:19 <[exa]> __monty__: why not, it creates a void in the featurespace, in which twitter lives. :]
03:32:32 <ais> Well i have two modules in one folder. I Start ghci by loading one of the modules and then want to import the other. However ghci says it can't find it.
03:33:27 <__monty__> [exa]: #because #I #can #tag #every #word #with #a #hash?
03:33:41 <Rembane> Tungur hashur.
03:33:59 <__monty__> ais: What's the filename and what's the module name?
03:35:00 <ais> it's GetSamples.hs and GetSamples
03:37:46 <[exa]> __monty__: but it doesn't get forwarded to all these channels (quite luckily)
03:37:50 <[exa]> nvm :]
03:53:07 <__monty__> ais: And `import GetSamples` doesn't work?
03:54:29 <ais> it does not
03:56:28 <__monty__> ais: What directory do you start ghci from?
03:57:34 <ais> when i do `:! pwd` it show the same directory that both of the modules are in 
03:59:17 <__monty__> I'm stumped. Could you try a non-stack ghci?
04:00:50 <ais> i don't have one
04:02:16 <__monty__> ais: Could you pastebin the output of `ls`, `head -2 GetSamples.hs` and the ghci error?
04:02:57 <ais> `ls` from where?
04:03:30 <jgt> ski runningriot9[m] sorry, I was away doing normal-life stuff
04:04:09 <jgt> basically I have a tmux window with two panes; vim on the right and GHCi on the left
04:04:44 <jgt> I work from vim, and use some nnoremaps with vim-dispatch to send commands to GHCi on the left through tmux send-keys
04:05:07 <jgt> it's not terribly sophisticated
04:05:13 <jgt> but it's not terrible either
04:05:45 <ais> __monty__ https://paste.ubuntu.com/p/ywHFzQQDff/
04:11:14 <__monty__> ais: Ok, so I can actually reproduce it. `import GetSamples` from a file works fine though. And once that's done ghci knows about the module and can import it. So I think you need to declare your modules in your cabal file and then ghci will be able to pick up on them?
04:15:40 <ais> I think i will somehow manage without that. What i wanted to find out, is if i can quickly import a couple of hastly written modules when prototyping. Having to set them up in some configuration kind of defeats the purpose, i think. 
04:16:08 <runningriot9[m]> Jgt what's the nnoremaps for example if I want to evaluate each line to ghc from vim
04:17:35 <runningriot9[m]> The nnoremap that you have in your dot file like <leader> gr sends serve to tmux but it just throws an error
04:27:50 * hackage elminator 0.2.4.0 - Generate ELM types/encoders/decoders from Haskell types.  https://hackage.haskell.org/package/elminator-0.2.4.0 (sras)
04:57:50 * hackage tls 1.5.0 - TLS/SSL protocol native implementation (Server and Client)  https://hackage.haskell.org/package/tls-1.5.0 (VincentHanquez)
04:59:16 <ais> How do overloadedstrings work? I am able to do `patternString :: Pattern String; patternString = "hh"`, however if i change the "hh" literal to (read somestringvar :: Pattern String) it does not work.
04:59:38 <ski> it only works for string literals
04:59:54 <ski> it doesn't magically convert `String's to other things
05:00:39 <ski> if you write `"hh"', then that gets converted into `fromString "hh"', where that `"hh"' is a `String' (and doesn't get converted into a new call with `fromString')
05:00:51 <ski> so .. you could just manually call `fromString', in your case
05:01:09 <ski> or, do whatever your implementation of `fromString' does, i suppose
05:01:50 <ais> the Pattern String thing is not from my code
05:02:10 <ais> and i can't figure out how it's build 
05:02:27 <ski> anyway, this is similar to how integer and decimal literals are treated. they are also polymorphic. `23' will become `fromInteger 23', and `23.45' will become `fromRational 23.45'
05:02:36 <ski> you can still call `fromString', manually
05:03:08 <ski>   fromString (read somestringvar)
05:03:57 <ski> (also, you probably should be using `reads' or `readMaybe', rather than a plain `read', which will abort in case of parse failure)
05:06:46 <ais> when i do the `fromString (read somestringvar)`, it says `Variable not in scope: fromString :: t0 -> Pattern String`
05:07:08 <ski> @index fromString
05:07:08 <lambdabot> Data.String, GHC.Exts, Distribution.ModuleName
05:08:39 <ais> ok, after importing it, i get: `*** Exception: Prelude.read: no parse`
05:09:02 <ski> hmm, actually
05:09:22 <ais> maybe the import overode something?
05:09:31 <ski> using `read' like that will try to parse your `String', as a Haskell `String'
05:09:36 <ski> probably not what you want to do ?
05:09:59 <ski> try just `fromString somestringvar', maybe ?
05:10:08 <ski> why did you write `read' there in the first place ?
05:10:34 <ski> > read "abc" :: String
05:10:37 <lambdabot>  "*Exception: Prelude.read: no parse
05:10:41 <ski> > read "\"abc\"" :: String
05:10:43 <lambdabot>  "abc"
05:11:12 * ski didn't reflect much on what the `read' was supposed to do there
05:11:15 <ais> ok, that seems to work 
05:11:20 <ais> thanks
05:11:42 <ski> np
05:36:20 * hackage ribosome-root 0.3.0.0 - api extensions for nvim-hs  https://hackage.haskell.org/package/ribosome-root-0.3.0.0 (tek)
05:43:13 <runningriot9[m]> I think i have two version of ghci , when I run in terminal ghci I get version 8.6.5 and when I open intero vim I get 8.6.4 without any modules installed from hackage
05:43:27 <runningriot9[m]> Is it possible to remove the ghci 8.6.4 ?
05:50:50 * hackage ribosome-test 0.3.0.0 - test helpers for ribosome  https://hackage.haskell.org/package/ribosome-test-0.3.0.0 (tek)
05:51:50 * hackage ribosome 0.3.0.0 - api extensions for nvim-hs  https://hackage.haskell.org/package/ribosome-0.3.0.0 (tek)
05:52:50 * hackage ribosome-test 0.3.0.1, ribosome 0.3.0.1 (tek): https://qbin.io/unions-maine-izgu
06:13:16 <mbwgh> In the expression "course-of-value iteration/recursion", where exactly does the term "course-of-value" come from? I'm not a native speaker, and I can't seem to find similar expressions, so I don't think it's common. What does a native speaker "associate" with it?
06:13:40 <mbwgh> (It comes up in the context of recursion schemes)
06:17:22 <ski> hm, i suppose given a function ‚åúf : ‚Ñï ‚ü∂ A‚åù, you get a "course" of "values" ‚åúf(0)‚åù,‚åúf(1)‚åù,‚åúf(2)‚åù,‚åúf(3)‚åù,&c. ?
06:18:15 <ski> ‚åúf(n)‚åù for each ‚åún‚åù possibly being defined in terms of the values of ‚åúf(m)‚åù, for all ‚åúm‚åù being less than ‚åún‚åù
06:18:20 <ski> e.g.
06:19:06 <ski>   f(n) = smallestPrimeFactor(1 + ‚àè m | m < n. f(m))
06:19:32 <ski> defines an infinite sequence of distinct primes (thereby proving that there's infinitely many prime numbers)
06:20:59 <ski> btw, it's also sometimes called "complete/strong iteration/recursion", i suppose "complete" because it allows you to use "all previously computed values", and "strong" because it seems stronger, for a similar reason ?
06:21:33 <mbwgh> Could strong be related to strong functors?
06:21:42 <ski> not that i know
06:22:24 <ski> if you're talking about lists, or trees, rather than natural numbers, then i suppose instead of talking about all lesser numbers, you'd talk about all proper sublists/subtrees ?
06:23:28 <ski> sometimes you see a recursion/induction on trees, where the IH assumes not the property for direct subtrees, or all proper subtrees, but rather assumes the property for all trees of strictly lesser depth .. or size
06:23:33 <mbwgh> And how do I parse f(n)? The smallest prime factor of (1 + (?))? I see a product, a "divides", and a less than such that f(m)? Sorry for being stupid
06:24:29 <ski>   f n = smallestPrimeFactor (1 + product [f m | m <- [0 .. n-1]])  -- in Haskell terms
06:24:54 <mbwgh> Yes, the intuition seems to be correct. A course-of-value algebra is used with a histomorphism, which is basically a catamorphism that at each stage has access to the (list|tree|..) of already computed values
06:25:59 <ski> @let smallestPrimeFactor 0 = 2; smallestPrimeFactor n = head [d | d <- [2 .. n],n `div` d == 0]
06:26:01 <lambdabot>  Defined.
06:27:02 <int-e> > smallestPrimeFactor 1
06:27:05 <lambdabot>  *Exception: Prelude.head: empty list
06:27:10 <int-e> > smallestPrimeFactor (-3)
06:27:13 <lambdabot>  *Exception: Prelude.head: empty list
06:28:03 <ski> err
06:28:10 <ski> should be `mod', silly me :)
06:28:16 <ski> @define
06:28:16 <lambdabot>  Define what?
06:28:23 <ski> @slap lambdabot
06:28:24 * lambdabot pushes lambdabot from his chair
06:28:27 <ski> @undefine
06:28:28 <lambdabot> Undefined.
06:28:29 <solonarv> hah, nice error message!
06:28:41 <ski> @let smallestPrimeFactor 0 = 2; smallestPrimeFactor n = head [d | d <- [2 .. n],n `mod` d == 0]
06:28:42 <lambdabot>  Defined.
06:28:56 <lavalike> I guess you *can* push yourself off a chair
06:29:26 <ski> > let f n = smallestPrimeFactor (1 + product [f m | m <- [0 .. n-1]]) in f `map` [0 .. 6]
06:29:29 <lambdabot>  [2,3,7,43,13,53,5]
06:29:51 <ski> int-e : yes, the behaviour for `1' (and negatives) was intended
06:30:07 <ski> mbwgh ^
06:30:29 <int-e> I just found it funny that you bothered with 0 as a special case
06:30:44 <ski> zero is a natural number !
06:31:22 <solonarv> lavalike: oh that's easy, just push against something solid
06:31:30 <solonarv> newton's third law will take care of it
06:31:42 <lavalike> I don't want newton to push me, push yourself!
06:32:19 <ski> mbwgh : care to remind me/us about the type of that operation ?
06:32:44 <mbwgh> ski: Which operation do you mean?
06:34:19 * ski . o O ( <http://web.student.chalmers.se/%7Emd9slj/gfx/Pushme-Pullyu.png> )
06:34:32 <ski> mbwgh : "A course-of-value algebra is used with a histomorphism, which is basically a catamorphism that at each stage has access to the (list|tree|..) of already computed values"
06:35:13 <ski> @oeis 2 3 5 7 43 13 53 5
06:35:14 <lambdabot>  Sequence not found.
06:35:17 <ski> hmpf !
06:35:17 <mbwgh> type CVAlgebra f a = f (CoFree f a) -> a; histo :: Functor f => CVAlgebra f a -> Fix f -> a
06:35:42 <mbwgh> Basically, I am working my way through this blog post: https://blog.sumtypeofway.com/recursion-schemes-part-iv-time-is-of-the-essence/#fn7
06:36:11 <lavalike> @oeis 1 2 3 4 5 6 31
06:36:13 <lambdabot>  https://oeis.org/A037403 Numbers n such that every base 7 digit of n is a ba...
06:36:13 <lambdabot>  [1,2,3,4,5,6,31,99,106,107,195,198,248,257,284,297,321,498,514,749,750,751,7...
06:36:33 <mbwgh> The authorative source is recursion-schemes: http://hackage.haskell.org/package/recursion-schemes-5.1.3/docs/Data-Functor-Foldable.html#v:histo
06:38:28 <ski> mbwgh : oic
06:39:59 <ski> oh .. i mistyped without realizing :)
06:40:00 <ski> @oeis 2 3 7 43 13 53 5
06:40:02 <lambdabot>  https://oeis.org/A000945 Euclid-Mullin sequence: a(1) = 2, a(n+1) is smalles...
06:40:02 <lambdabot>  [2,3,7,43,13,53,5,6221671,38709183810571,139,2801,11,17,5471,52662739,23003,...
06:40:05 <ski> there we go
06:40:15 <int-e> > take 7 $ fix (map (smallestPrimeFactor . succ) . scanl (*) 1)
06:40:18 <lambdabot>  [2,3,7,43,13,53,5]
06:40:20 <ski> Euclid-Mullin sequence: a(1) = 2, a(n+1) is smallest prime factor of 1 + Product_{k=1..n} a(k).
06:40:31 <lavalike> he fix-d it
06:40:59 <mbwgh> So with the prototypical NatF = Zero | Succ f; type Nat = Fix NatF , you have fib :: Nat -> Integer; fib = \case {Zero -> 0; Succ (_ <: Zero) -> 1; Succ (fib1 <: Succ (fob2 <: _)) -> fib1 + fib2} modulo typos and fixities
06:41:38 <mbwgh> I mean fib = histo $ \case ...
06:41:51 <solonarv> ski: there's no 5 at the start of the euclid-mullin sequence
06:41:58 <solonarv> @oeis 2 3 7 43 13
06:41:59 <lambdabot>  https://oeis.org/A000945 Euclid-Mullin sequence: a(1) = 2, a(n+1) is smalles...
06:42:00 <lambdabot>  [2,3,7,43,13,53,5,6221671,38709183810571,139,2801,11,17,5471,52662739,23003,...
06:43:04 <solonarv> oh wait, you already said that...
06:43:13 * solonarv needs to (re)learn to read
06:46:05 <mbwgh> But who needs histomorphisms for fib. Always with the fib examples
06:47:09 <ski> solonarv : i know, my fingers apparently typed it by muscle memory, anyway !
06:47:38 <ski> mbwgh, fact
06:48:03 * ski fibs away
06:48:51 <ski> hm .. anyway, that description of Euclid-Mullin is .. inelegant
06:49:03 <lavalike> ‚åúski(n-1)‚åù + ‚åúski(n-2)‚åù
06:49:06 <ski> the whole point of strong induction is that you don't need a (separate) base case !
06:49:07 <mbwgh> I've never seen anyone mention that you can boil fib down to O(1)
06:49:23 <ski> you can ?
06:49:36 <mbwgh> Yeah, though the constant factors are probably not favorable
06:50:00 <solonarv> really? the best I can think of is O(log2 n) using the matrix-powers method
06:50:14 <mbwgh> You can notice that you can implement fib via successive matrix*vector products, exactly
06:50:19 <mbwgh> But the matrix is symmetric
06:50:23 <mbwgh> So you can diagonalize it
06:50:24 <ski> do you mean the `(phi^n - psi^n) / (phi - psi)', where `phi' and `psi' are the two solutions for `x' of `x^2 - x - 1 = 0' ?
06:50:33 <mbwgh> You will have the golden ratio on the diagonals I think
06:50:37 <mbwgh> That makes powers O(1)
06:50:37 <solonarv> ((1 1) (0 1)) doesn't look symmetric to me
06:51:02 <solonarv> (writing the two rows below each other)
06:51:20 <ski> it's symmetric on the diagonal ..
06:51:26 * ski glances sideways
06:51:37 <solonarv> @slap ski
06:51:38 * lambdabot decomposes ski into several parts using the Banach-Tarski theorem and reassembles them to get two copies of ski!
06:51:53 <int-e> mbwgh: okay, please show me that constant time arbitrary precision exponentiation that you're using...
06:52:02 <ski> no, not two copies of ski, one is quite enough !
06:52:15 <mbwgh> The haskell wiki uses [[0, 1], [1, 1]]
06:52:54 <mbwgh> int-e: That might be an issue yes. And you would get memory issues before such an algorithm would be necessary I guess
06:52:59 <int-e> yeah [1,1;0,1]^n = [1,n;0,1] won't help :)
06:53:16 <ski> mayhap they have access to something like a <https://en.wikipedia.org/wiki/Blum-Shub-Smale_machine> ?
06:53:24 * ski . o O ( I√§ i√§ ! )
06:53:49 <int-e> mbwgh: the matrix exponentiation will perform better because you can still use fast exponentiation but all the intermediate results are integers...
06:54:20 <int-e> solonarv: and it's actually O(n).
06:54:36 <int-e> solonarv: err
06:54:55 <solonarv> can't you compute M^n in O(log2 n) by squaring repeatedly?
06:55:13 <int-e> solonarv: sorry, O(m(n)), where n is the fast multiplication bound. Where's that at currently?
06:55:14 <solonarv> so you end up with O(log2 n) matrix multiplications
06:55:27 <int-e> solonarv: the intermediate results shrink exponentially...
06:55:56 <mbwgh> But yeah, given arbitrary precision, my O(1) claim is bullshit. Should still hold if you would be forced to you Double because of the diagonalization
06:55:56 <solonarv> oh! I was assuming constant-time multiplication on the underlying integer type
06:56:28 <mbwgh> (I didn't say that it would be useful)
06:57:37 <int-e> Well, modulo any fixed m it's essentially constant time anyway... since the sequence is periodic. But you have to reduce the input modulo the period, so that makes it O(log(n)) again. Annoying.
06:57:51 <ski> what's a number system where you count in ‚åú‚àë n : ‚Ñï. b‚Åø‚åù called ? (‚åúb‚åù being a positive integer)
06:58:42 <solonarv> ski: what does that notation mean?
06:58:53 <ski> like you count, `0',`1',`1 + 1',`1 + 2',`1 + 2 + 1',`1 + 2 + 2',`1 + 2 + 3',`1 + 2 + 4',`1 + 2 + 4 + 1',&c. (in the case `b = 2')
06:59:25 <Axman6> looks like one of those ski's wqas skifree
06:59:43 * Axman6 jackdk finally got his skifree joke
06:59:54 <ski> instead of counting `0',`1',`2',`1 + 2',`4',`1 + 4',`2 + 4',`1 + 2 + 4',`8',`1 + 8',&c. (still `b = 2'), which is positional number system, base two
07:01:06 <Axman6> who's gonna compute factorial using Double's, what is this, javascript?
07:01:08 <Axman6> madness
07:01:17 <Axman6> literal insanity
07:01:45 <mbwgh> Doesn't javascript just have "numbers"? Way simpler if you ask me
07:02:02 * solonarv mumble mumble Œì function
07:02:14 <solonarv> mbwgh: indeed, and those "numbers" are doubles
07:02:53 <ski> the positional thing would be something like ‚åú‚ãÉ‚Üë n : ‚Ñï. b‚Åø‚åù, being a directed union
07:02:56 <Axman6> IIRC they're defined to be IEEE-754 doubles, which is totally batshit, but far from javascript's biggest problem
07:03:17 <solonarv> yeah, IEEE 754 doubles are equally batshit in all programming languages!
07:03:58 <ski> (are there systems with pre- IEEE 754 floating point still in use ?)
07:04:20 <solonarv> of course there are
07:04:31 <solonarv> but common use? that's more dubious
07:04:41 <Axman6> probably all at the US tax office and DoD
07:04:55 <solonarv> unless you count banking/finance applications which should never use IEEE 754 floats
07:05:06 <ski> hm, does IEEE 754 specify BCD floats ?
07:06:09 <mbwgh> Why do things that do not compare equal to themselves exist? Honest question
07:06:58 * ski . o O ( SQL )
07:07:01 <Axman6> ski: sounds vaguely familliar, I wouldn't be surprised if it does
07:07:17 <mbwgh> I was thinking NaN, but I think NULL is the same, yes
07:07:18 <Axman6> mbwgh: like NaN? or like functions?
07:07:23 <nshepperd_> Bash uses decimals. Probably
07:07:32 <ski> functions ?
07:07:47 <Axman6> > succ == succ
07:07:49 <lambdabot>  error:
07:07:49 <lambdabot>      ‚Ä¢ Ambiguous type variable ‚Äòa0‚Äô arising from a use of ‚Äòsucc‚Äô
07:07:49 <lambdabot>        prevents the constraint ‚Äò(Enum a0)‚Äô from being solved.
07:08:01 <ski> > not == not
07:08:03 <lambdabot>  error:
07:08:03 <lambdabot>      ‚Ä¢ No instance for (Eq (Bool -> Bool)) arising from a use of ‚Äò==‚Äô
07:08:03 <lambdabot>          (maybe you haven't applied a function to enough arguments?)
07:08:27 <mbwgh> even if function equality were define, you would run into issues like intensional vs extensional equality, like in dependendly-typed languages. This makes things yet more complicated
07:08:57 <nshepperd_> > undefined == undefined
07:09:00 <lambdabot>  *Exception: Prelude.undefined
07:09:52 <ski> @let instance (Bounded a,Enum a,Eq b) => Eq (a -> b) where f == g = all (uncurry (==)) (map (f &&& g) [minBound .. maxBound])
07:09:53 <lambdabot>  Defined.
07:09:56 <ski> > not == not
07:09:59 <lambdabot>  True
07:10:03 <ski> > not == id
07:10:05 <lambdabot>  False
07:10:52 <mbwgh> Anyhow, when is NaN /= NaN a useful property?
07:10:54 <ski> you could use `instance (Compact a,Eq b) => Eq (a -> b)' instead, i think
07:10:55 <solonarv> functions don't compare unequal to themselves, that comparison just fails to terminate (if you allow attempting it on functions with infinite domain)
07:10:56 <nshepperd_> NaN is basically bottom
07:11:47 <ski> mbwgh : they're attempting to represent an effect. namely a failing (aborting) computation. like `Applicative' and `Monad' instances of `Maybe'
07:11:47 <ziman> > fst . not == snd
07:11:50 <lambdabot>  error:
07:11:50 <lambdabot>      ‚Ä¢ Couldn't match type ‚ÄòBool‚Äô with ‚Äò((), b0)‚Äô
07:11:50 <lambdabot>        Expected type: Bool -> ((), b0)
07:11:50 <mbwgh> Yet there typically is an isNaN function
07:11:52 <Axman6> ski: how would compact be used?
07:12:03 <solonarv> mbwgh: no, it's not - the idea was that you could easily check whether x is NaN by doing x == x
07:12:30 <ski> Axman6 : `forAll :: Compact a => (a -> Sierpinski) -> Sierpinski'
07:12:42 <nshepperd_> Except it falls apart a bit because bools don't have NaN so NaN == NaN is false instead of NaN
07:13:01 <nshepperd_> mbwgh: you can catch undefined in haskell too
07:13:25 <ski> > liftA2 (==) (Just "foo") (Just "foo")
07:13:27 <Axman6> I was getting confused with Data.Compact (and GHC.Compact) - what's the Compact class?
07:13:27 <lambdabot>  Just True
07:13:28 <ski> > liftA2 (==) (Just "foo") (Just "bar")
07:13:28 <ggole> The float comparisons are an attempt to map the three-element set Less, Unordered, Greater into a two element set.
07:13:30 <lambdabot>  Just False
07:13:31 <ski> > liftA2 (==) (Just "foo") Nothing
07:13:33 <lambdabot>  Nothing
07:13:45 <solonarv> mbwgh: that is why I find this justification profoundly silly
07:13:52 <ski> @where impossible
07:13:52 <lambdabot> <http://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/>,<http://math.andrej.com/2008/11/21/a-haskell-monad-for-infinite-search-in-finite-time/>
07:13:53 <solonarv> nevertheless that is the actual historical reason
07:13:55 <ski> @where topology
07:13:55 <lambdabot> "topology in Haskell" <http://www.haskell.org/pipermail/haskell/2004-June/014134.html> and "Synthetic topology of data types and classical spaces" <http://www.cs.bham.ac.uk/~mhe/papers/entcs87.(pdf|
07:13:55 <lambdabot> dvi|ps)> by MartÌn EscardÛ
07:14:01 <ski> Axman6 ^ like in those
07:14:07 <ggole> Amusingly, such comparisons are (usually) cleaner at the machine code level
07:14:55 <mbwgh> So, good intentions aside, isNaN /= isNaN because of histerical raisins?
07:15:13 <ski> solonarv : "functions don't compare unequal to themselves, that comparison just fails to terminate (if you allow attempting it on functions with infinite domain)" -- actually, you can compare for equality in some uncountable types. see the Escard√≥ posts above
07:15:23 <mbwgh> Or have you ever used this property intentionally?
07:15:38 <Axman6> perhaps you should go and read IEEE-754
07:15:46 <ski> @where floating-point
07:15:47 <lambdabot> "What Every Programmer Should Know About Floating-Point Arithmetic" at <http://floating-point-gui.de/> and "What Every Computer Scientist Should Know About Floating-Point Arithmetic" by David
07:15:47 <lambdabot> Goldberg in 1991 at <http://docs.sun.com/source/806-3568/ncg_goldberg.html> and <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.102.244>
07:16:26 <ski> > (0 == -0,isNegativeZero `map` [0,-0])
07:16:28 <lambdabot>  (True,[False,True])
07:16:33 <Axman6> ski: looks fun - I'll have to take a look sometime
07:16:55 <mbwgh> oh boy
07:17:10 <ggole> Negative zero is also fun, because x = y but f x <> f y
07:17:20 <int-e> > (1/0, 1/-0)
07:17:23 <lambdabot>  error:
07:17:23 <lambdabot>      ‚Ä¢ Variable not in scope: (/-) :: Integer -> Integer -> b
07:17:23 <lambdabot>      ‚Ä¢ Perhaps you meant one of these:
07:17:27 <int-e> > (1/0, 1/ -0)
07:17:29 <lambdabot>  error:
07:17:29 <lambdabot>      Precedence parsing error
07:17:30 <lambdabot>          cannot mix ‚Äò/‚Äô [infixl 7] and prefix `-' [infixl 6] in the same infi...
07:17:33 <ggole> signum, etc
07:17:35 <int-e> :(-(
07:17:36 <mbwgh> > (1/0, 1/(-0))
07:17:39 <ski> we don't believe in extensionality anyway
07:17:39 <lambdabot>  (Infinity,-Infinity)
07:18:03 <mbwgh> (werks with -XNegativeLiterals)
07:18:09 <int-e> > (0 :: Double) == -0
07:18:12 <lambdabot>  True
07:18:49 <Axman6> mbwgh: you should also watch https://www.youtube.com/watch?v=5TFDG-y-EHs
07:19:32 <ski> int-e, oh, good point
07:20:23 <solonarv> ski: oh yes, s/infinite/some more cromulent adjective/
07:20:35 <mbwgh> Axman6: Thanks!
07:20:51 * hackage toolshed 0.18.0.1 - Ill-defined library.  https://hackage.haskell.org/package/toolshed-0.18.0.1 (AlistairWard)
07:21:07 <nshepperd_> Uncompact
07:21:31 <Axman6> If anyone wants a good laugh, they should also watch that
07:21:51 * hackage squeeze 1.0.4.17, fishfood 0.0.1.9 (AlistairWard): https://qbin.io/wang-deaf-173o
07:24:04 <Axman6> "... NaN is like the GNU Public License of numbers ..."
07:24:51 * hackage regexdot 0.12.2.1 - A polymorphic, POSIX, extended regex-engine.  https://hackage.haskell.org/package/regexdot-0.12.2.1 (AlistairWard)
07:28:20 * hackage regexchar 0.9.0.17 - A POSIX, extended regex-engine.  https://hackage.haskell.org/package/regexchar-0.9.0.17 (AlistairWard)
07:33:20 * hackage factory 0.3.2.1 - Rational arithmetic in an irrational world.  https://hackage.haskell.org/package/factory-0.3.2.1 (AlistairWard)
07:37:20 * hackage bishbosh 0.0.0.4 - Plays chess.  https://hackage.haskell.org/package/bishbosh-0.0.0.4 (AlistairWard)
07:42:30 <mbwgh> Axman6: Thanks, I hate it! (cool video)
08:10:28 <flebron> Hi folks. What's the common solution to "I have a bunch of functions (Floating a) -> a -> a -> a, I'd like to sometimes invoke them with a Float, sometimes with a Double.
08:10:46 <flebron> "? The type [Floating a => a -> a -> a] would be my choice, but that's not allowed :)
08:11:07 <flebron> Should I wrap them in a GADT + existential type?
08:11:14 <solonarv> that's one option
08:11:47 <solonarv> if they only need to work specifically on Float and Double, you could also specialize them to Double and then convert from/to Float when you need to work with those
08:12:37 <solonarv> also, minor nitpick: not an existential, just a higher-rank type
08:12:53 <ski> flebron : sounds like you want `[forall a. Floating a => a -> a -> a]', or `forall a. Floating a => [a -> a -> a]' ?
08:12:56 <flebron> That would be maaaany functions tho. I currently have something like [(FPow, (**)), (FPlus, (+)), (FMul, (*)), ...]
08:13:16 <ski> flebron : doesn't sound like existentials is what you're after, here
08:13:20 <flebron> ski: The first one makes GHC whine about not (yet) supporting impredicative polymorphism
08:13:26 <solonarv> % newtype FloatingCombiner = FloatincCombiner { combineFloatings :: forall a. Floating a => a -> a -> a }
08:13:27 <yahb> solonarv: 
08:13:30 <ski> flebron : yes, i know
08:13:36 <solonarv> ^ that's the sort of type you would want here
08:13:55 <ski> flebron : so, possibly you can use the second, or what solonarv suggested ?
08:13:58 <flebron> Ah, I didn't realize newtypes could have class constraints, thought I'd need a GADT for that
08:14:29 <flebron> That seems to work, I'll give it a try. Thanks!
08:14:32 <solonarv> you would need a GADT if you wanted an existential
08:14:33 <ski> no, that's not a data constructor having a class constraint
08:14:37 <solonarv> but this is not an existential
08:14:48 <ski> that's `PolymorphicComponents', a rank-2 data constructor
08:15:07 <flebron> So [forall a. Floating a => a -> a -> a] would whine, but [FloatingCombiner] is OK>
08:15:10 <flebron> ?
08:15:12 <ski> yes
08:15:19 <solonarv> ski: you might want to refrain from explaining things by referring to GHC extensions that don't exist anymore :>
08:15:22 <flebron> Is there some deep reason why?
08:15:34 <ski> solonarv : i was just about to say something about that ;)
08:15:40 <solonarv> flebron: I'm not sure if it counts as "deep"
08:15:57 <solonarv> but essentially allowing the former would require a different type inference algorithm
08:16:31 <ski> flebron : just like `[exists a. Widget *> Map String a]' can be represented by `[SomeWidgetMap]' given `data SomeWidgetMap = forall a. Widget a => WrapWidgetMap (Map String a)'
08:17:17 <solonarv> note that here the forall is *before* the data constructor, which is how we write existentials in Haskell because of historical reasons
08:17:52 <flebron> ski: What does "*>" mean there?
08:18:08 <solonarv> made-up syntax for existentials
08:18:27 <solonarv> ...or rather, for a pair of constraint-and-value
08:19:21 <solonarv> you can think of 'Ctx => Type' as a plain old function 'Dict Ctx -> Type', where 'Dict Ctx' is a record type that contains all the typeclass methods corresponding to 'Ctx'
08:19:40 <solonarv> then 'Ctx *> Type' is like a pair '(Dict Ctx, Type)'
08:20:24 <ski> except that the dictionary handling and passing is hidden for you, in the dictionary translation implementation of class constraints
08:20:37 <flebron> Right, Ithink of that as vtable ptrs flying around
08:20:44 * ski nods
08:20:50 <ski> more or less
08:21:22 <ski> (except that a dictionary for `Widget a' isn't associated (passed around) with values of type `a')
08:22:30 * ski . o O ( "Interface-passing style" by Fare (Far√© Rideau, of TUNES) in 2010-02-17 at <https://fare.livejournal.com/155094.html> )
09:15:03 <p53> hello, I'm trying to understand how monads work. and come across the problem of reading a number from the console as a double and passing it to a function to output the result afterwards. everything without do-notation
09:15:05 <p53> 	putStrLn "h in mm:" >>
09:15:05 <p53> 	return (read "2334.34" :: Double) >>= 
09:15:06 <p53> 	(\b -> print ((\x -> round (x * (2 ** 0.5))) b))
09:18:34 <int-e> :t readLn
09:18:35 <lambdabot> Read a => IO a
09:18:36 <int-e> :t read
09:18:37 <lambdabot> Read a => String -> a
09:19:58 <int-e> For starters, readLn will do the trick (in essence it gets one line of input, and calls "read" on the resulting string)
09:20:37 <ski> @type getLine
09:20:39 <lambdabot> IO String
09:20:46 <ski> will get you one line of input
09:20:58 <int-e> @src readLn
09:20:59 <lambdabot> readLn = do l <- getLine; r <- readIO l; return r
09:21:16 <ski> @type readIO
09:21:17 <lambdabot> Read a => String -> IO a
09:21:24 <ski> @type read
09:21:25 <lambdabot> Read a => String -> a
09:21:49 <ski> the difference is that `readIO' will throw an I/O exception, in case of parse failure
09:22:03 <ski> (and so `readLn' also will)
09:22:32 * ski looks at p53
09:24:16 <p53> mh, ok thx ; So readLn automatically recognizes the data type based on the following usage
09:24:18 <int-e> (\b -> print ((\x -> round (x * (2 ** 0.5))) b)) can be written as just  \b -> print (round (b * sqrt 2))  (sqrt 2 instead of 2 ** 0.5 is a cosmetic preference)
09:25:07 <c_wraith> p53: Haskell has full inference of return types based on context.  It works far better than what you get out of something like scala, for instance
09:25:20 * hackage twitter-types 0.8.0 - Twitter JSON parser and types  https://hackage.haskell.org/package/twitter-types-0.8.0 (TakahiroHimura)
09:26:50 * hackage twitter-types-lens 0.8.0 - Twitter JSON types (lens powered)  https://hackage.haskell.org/package/twitter-types-lens-0.8.0 (TakahiroHimura)
09:26:54 <int-e> > abs ((sqrt 2)^2 - 2) `compare` abs ((2 ** 0.5)^2 - 2)
09:26:57 <lambdabot>  EQ
09:27:40 <int-e> Oh, nice. I expected a (small) difference.
09:30:45 <erisco> I am looking for any materials on incremental computation that pertain to recursive types.
09:31:59 <ski> hm. as in adaptive computation ?
09:32:04 <erisco> Sure.
09:32:37 <ski> i assume you've seen the Acar,Blelloch,Harper paper ? and the Carlsson one ?
09:33:12 <p53> ok, so you can pass an object of type "IO x" to an ordinary function, whose paraemetr is only of type "x"; then "IO x" and "x" are not different?
09:33:13 <ski> i suppose derivatives of lambda terms are also related, somehow
09:33:22 <ski> p53 : they are different
09:33:52 <ski> they're as different as a cake, and a recipt of a cake
09:34:07 <ski> s/recipt/recipe/
09:34:10 <ski> you normally wouldn't try to eat a recipe
09:34:23 <erisco> ski, I don't know. I read something on incremental lambda calculus but I don't recall it ever talking about recursive types.
09:34:27 <ski> @quote is.not.the.cake
09:34:27 <lambdabot> ski says: <ski> `getLine :: IO String' is a recipe for how to interact with the world to acquire a `String'  <ski> the recipe is not the cake
09:34:33 <ski> @where adaptive
09:34:33 <lambdabot> "Adaptive Functional Programming" by Umut Acar,Blelloch,Harper in 2002 (POPL) at <http://www.umut-acar.org/publications/popl2002.pdf> and in 2006 (TOPLAS) at <http://www.umut-acar.org/publications/
09:34:33 <lambdabot> toplas2006.pdf>
09:34:37 <ski> @where incremental
09:34:37 <lambdabot> "Monads for Incremental Computing" (Functional Pearl) by Magnus Carlsson in 2002 (ICFP) at <http://www.carlssonia.org/ogi/papers/icfp-2002.pdf>,<http://www.carlssonia.org/ogi/Adaptive/>,in Hackage
09:34:37 <lambdabot> at <http://hackage.haskell.org/package/Adaptive>
09:34:49 <ski> i suppose you could check those out, if you haven't yet
09:35:07 <ski> (there's quite possibly more recent papers, which i haven't seen)
09:36:51 <erisco> Generally stuff that talks about change propagation isn't talking about what I'm talking about. I am taking a look though.
09:36:53 <glguy> Anyone seen the scientific package unable to finish building on Travis-CI before? https://travis-ci.org/ekmett/ersatz/jobs/540139110#L532
09:36:55 <ski> (then there's also the basic "incremental vs. bulky distinction", as in `foldr' vs. `foldl' (being tail-recursive). but i assume you know about that)
09:37:08 <glguy> This is the second build in a row that has stalled on this packag
09:37:09 <ski> erisco : then ?
09:37:39 <erisco> ski, there seems to be a schism in what people are referring to as incremental/adaptive/whatever
09:38:01 <ski> okay ?
09:38:17 <erisco> one says once you know how the input changes, here's how you efficiently update the output
09:38:32 <erisco> the other says how we talk about input changes in the first place
09:39:01 <p53> ok, then this "recipe X" is automatically converted into object X, so to speak, or how can we visualize it?
09:39:11 <erisco> or lets say one tends to be some sort of mutable graph of thunks, or something, and the other tends to be about derivatives
09:39:14 <ski> p53 : not automatically
09:40:34 <p53> ok, via this graceful operator ">> =" XD
09:40:35 <ski> p53 : `act >>= continue' will construct a new action that, when/if executed (later) will start by executing the action `act', (and, if all goes well) getting back a result `val', which is passed to `continue', so `coninue val' is the action which is then executed, and its eventual result is the result of executing the whole compound action
09:40:40 <ski> yes
09:41:50 <ski> the only way to execute an I/O action, is by making it part of a larger I/O action, which is eventually executed. or by making it the `main' action of the program
09:42:10 <erisco> or in other words, I want to know how to talk about the differences between two lists, and from there we can figure out some efficient adaptive computation
09:42:13 <ski> in the interactor, you can also start off execution of I/O actions, by typing them at the prompt
09:42:31 * ski nods to erisco
09:45:48 <erisco> the only approach I have seen which really makes sense involves a zoo of f-algebras, where each algebra is also a complicated exhibit
09:46:40 <erisco> but the result in my opinion is really unsatisfying
09:47:52 <ski> perhaps with language-level support for it, it would be nicer ?
09:48:27 <erisco> the language is orthogonal to the issue, but I am going too OT to discuss that
09:48:55 <erisco> (upon reflection, I think "OT" is a poor abbreviation‚Ä¶ is it on topic or off topic?)
09:49:23 <p53> So in order to keep functions "pure", all inputs are only converted in between, but have to be printed out somehow at the end again, must not stand around in the room. It always bothers me C. There are so many inputs and outputs buzzing around in the room, and you do not really know what the function actually does on the basis of the signature.
09:49:35 * ski . o O ( Original Thetan )
09:50:12 <erisco> But okay, let me give an example
09:50:57 <erisco> Say we have a list  [1,2,4,5]  and a list  [1,2,3,4,5]  then how do we describe the difference of these?
09:51:03 <ski> p53 : yes, the point is to be explicit about effects, in the interface (the type), and also in the expressions (you can't write `1 + readLn'). that way, they're not *side*-effects anymore, but effects which are explicitly catered for
09:51:41 <ski> p53 : so, merely by checking whether the return type involves `IO', you can tell whether an operation is allowed to do I/O, or not
09:52:16 <ski> erisco : good example. perhaps a monoid-based description of lists would make more sense, here ?
09:52:18 <erisco> Cutting to the chase, what we really want is a difference that can be efficiently applied to an adaptive computation. This means the difference should describe as small of a change as possible, without the difference itself becoming complicated to comprehend.
09:53:24 <erisco> Naively we could say the difference is the tail [4,5] vs [3,4,5], but that is a larger change than splicing 3 between [1,2 and ,4,5]
09:54:22 <erisco> I spent a few weeks tackling this problem last summer and it became clear to me that this sort of splicing is what is ultimately desirable, but I never figured out how to do it.
09:55:24 <erisco> What I do know is that a list zipper is related to the derivative of a list, and derivatives are related to this problem, and the way a list zipper looks seems relevant to this problem
09:55:32 <ski>   ‚åú[1,2] ‚ß∫ ‚åûreplace [] [3]‚åü ‚ß∫ [4,5]‚åù
09:55:55 <erisco> But what I am after is the general solution for any ADT.
09:56:13 <erisco> (Including recursive)
09:56:31 * ski nods
09:57:19 <erisco> The language problem comes in once we figure out what sort of code generation is or is not needed. I can imagine how some definitions would be necessary but also be auto-derivable from a data type definition.
09:57:19 <ski> how about `[[0,1,2,3],[4,5,6],[7,8],[9]]' vs. `[[0,4,7,9],[1,5,8],[2,6],[3]]' ?
09:57:44 <ski> or, even just `[0,1,2,3,4,5]' vs. `[0,1,3,2,4,5]'
09:58:15 <erisco> Yes, well this is where the zoo comes from.
09:58:23 <c_wraith> erisco: this also seems closely related to the problem of edit distance, generalized to a set of editing operations on arbitrary ADTs
09:58:59 <erisco> What seems to happen is the efficiencies of whatever effects we're ultimately using put back pressure on how we design the diffs.
10:00:14 <erisco> That's the really unsatisfying part, because whatever you come up can be made inefficient by trying to drive certain effects instead of others.
10:01:58 <erisco> Splicing is particularly important in so far as it can abate DOM editing woes, and generalised to any ADT it can presumably find other uses.
10:02:42 <erisco> But yes, merely swapping two things in a list‚Ä¶ one option is to splice the element out, then splice it back in where you want it
10:03:10 <erisco> but if there is an underlying move effect you want to use, rather than a delete then insert, it could be tricky to recover that as a move operation
10:03:32 <erisco> so then you have to add a move operation to your diff, and the zoo gets another animal
10:03:41 * ski is reminded of Darcs
10:05:09 <erisco> I am a bit inspired by xpath in that it lets you navigate a recursive structure
10:06:10 <erisco> In my mind, the essence of a splice is to punch out a contiguous hole in a structure, giving you several pieces, and then the splice defines how to put these pieces back together, possibly involving new pieces
10:06:39 <erisco> So, you can punch out one element in a list, but you could also punch out two consecutive elements in a list
10:07:00 <erisco> You could punch out the left-most branch in a binary tree
10:08:28 <erisco> So you can think of this as addressing the general problem of localised editing in a structure
10:08:34 <ski> can you elaborate on the last example ?
10:09:17 <erisco> http://2.bp.blogspot.com/-3eyinMSgNi4/Vio9pd_tdYI/AAAAAAAAD-8/zT2D0lgWa8s/s1600/binary%2BSearch%2BTree%2Bin%2BJava.png punch out 7, 5, 3, 1
10:09:41 <erisco> Now you have three pieces left over (or more, depending on how we define things)
10:10:25 <erisco> I could also punch out 12, 9, 15
10:10:51 <erisco> Which gives me 5 pieces
10:11:06 <erisco> Note that some pieces will have holes in them whereas other pieces are complete by themselves
10:11:28 <erisco> This is like when we splice a list, where the head has a hole but the tail is by itself complete
10:11:49 <ski> ok, so you punch out those nodes in the tree
10:12:26 <ski> hmm .. interesting. like lenses, but "the other way around"
10:13:50 * hackage plots 0.1.1.1 - Diagrams based plotting library.  https://hackage.haskell.org/package/plots-0.1.1.1 (cchalmers)
10:14:29 <erisco> Though this is my intuition of the idea, it doesn't necessarily lead to anything beautiful
10:14:51 <erisco> Maybe I should just look more at how XSLT does things
10:21:24 <erisco> The idea I get with xpath is that I can address every location of the structure either absolutely (from the top) or relatively (from somewhere else). Once I have a way to identify every part, I can then define operations on these parts.
10:22:52 <erisco> Computationally, going from the top every time is not ideal, but that is what a relative path can solve. You could, say, define some operations with paths to 9, 15, 8, 10, 13, 17, and then scope all these with a path to the 12 node.
10:23:03 <erisco> The computationally you just have to get to 12 once.
10:25:16 <erisco> Also, benefit is that it is really easy to figure out what the path definition has to be.
10:28:51 * hackage pipes 4.3.10 - Compositional pipelines  https://hackage.haskell.org/package/pipes-4.3.10 (GabrielGonzalez)
10:30:49 <ski> i suppose relative paths should be expressed wrt zippers
10:31:10 <ski> elasticity of demand gives paths
10:32:13 <erisco> I am going to play with it to see what I can do with paths.
10:33:59 <erisco> Also worth noting‚Ä¶ computing the difference between two values is not necessarily the interesting case. In practice, from what I am seeing for myself, you're typically going to be constructing the diffs directly.
10:34:40 <erisco> You're not going to compute x:A and then y:A and then compute the difference between these‚Ä¶ you're going to compute x, then construct a Œîx, then patch x with Œîx to get y
10:34:53 * ski nods
10:35:05 <ski> or `map' the patching over a list of `x's
10:35:06 <erisco> Only in select circumstances would you do the former‚Ä¶ particularly if you're dealing with something external that isn't going to send you diffs.
10:36:39 <erisco> Computing the difference between two values is a much different problem because we've lost all the semantics of the edit. Move vs delete and insert is an easy example.
10:37:37 <erisco> Trying to recover a move could cost far more than what is gained.
10:38:56 <cole> what priority queue would you recommend for ease of usage? there seem to be a lot of them
10:43:35 <cocreature> cole: I‚Äôve used psqueues in the past and I‚Äôve been quite happy with it
10:44:21 <cole> cocreature: thanks, will give that a try
10:53:57 <habbah> Is there a haskell vim or emacs plugin which allows me to see a list of all the functions in a file?
10:55:10 <maerwald> habbah: https://github.com/majutsushi/tagbar/wiki#haskell
11:13:57 <bifunc2> when doing data Boom = Boom { great :: Bool }  should i write "isGreat" instead of "great" for booleans? What's the common practice?
11:14:55 <[exa]> bifunc2: why not data Boom = OrdinaryBoom | GreatBoom
11:15:25 <bifunc2> i'm sorry that was a lousy example. i have some other fields in therre too
11:15:33 <bifunc2> not just the bool
11:15:38 <bifunc2> the question is about "is"
11:16:25 <ski> @type even
11:16:27 <lambdabot> Integral a => a -> Bool
11:16:35 <ski> @type elem
11:16:37 <lambdabot> (Eq a, Foldable t) => a -> t a -> Bool
11:16:38 <ski> @type isInfixOf
11:16:40 <lambdabot> Eq a => [a] -> [a] -> Bool
11:17:24 <[exa]> bifunc2: IMO the correct name would be probably something derived from 'size', I'm not a fan of bool-valued fields. In your case, isGreat is probably better for causing less collision with other stuff
11:19:28 <tabemann> isGreat on one hand is probably clearer, but on the other hand reminds me of Java
11:19:54 <bifunc2> :)
11:20:38 * tabemann notes at work that in the Java code we have a lot of stuff like isIsGreat, because we have things named isGreat on the JavaScript side which come over in JSON, and get converted to isIsGreat by the JSON to POJO converter
11:21:47 <ski> wonderful
11:22:09 <ggole> One more layer and it makes sense again: isIsisGreat
11:22:25 <ggole> (Perhaps not the intended effect.)
11:22:35 <bifunc2> lol things getting more great over time
11:22:48 <tabemann>  bbias
11:22:50 * ski . o O ( `makeIsisGreat' )
11:23:26 * ski . o O ( `unsafeUnveilIsis' )
11:27:48 <tabemann> I really need to figure out some way to make my IRC client not expand the window rightwards every time I join a channel
11:28:04 <tabemann> and to be able to actually shrink the window leftwards effectively
11:30:45 <[exa]> tabemann: what's your client btw?
11:30:48 <zachk> tabemann, I use hexchat and have no problem like that
11:31:16 <tabemann> [exa]: Amphibian IRC, an IRC client I wrote in Haskell using GTK3
11:31:32 <ski> it seemed shy
11:31:44 <tabemann> zachk: it's some issue with GTK
11:32:00 <tabemann> the thing with hexchat is it seems to use a custom text box widget
11:32:01 <[exa]> oh wow okay :]
11:32:38 <tabemann> whereas I'm using a standard GTK text buffer
11:32:43 <tabemann> *text view
11:32:45 <zachk> tabemann, coolness, have a link? 
11:33:28 * ski . o O ( Cursed GTK <https://web.archive.org/web/20040419075108/http://zemljanka.sourceforge.net:80/cursed/screenshots/xchat-2.png>,<https://web.archive.org/web/20040219095549/http://zemljanka.sourceforge.net:80/cursed/screenshots/xchat-1.png>,<https://web.archive.org/web/20080511194130/http://zemljanka.sourceforge.net/cursed/>,<http://atrey.karlin.mff.cuni.cz/~pavel/cursed/cursed.html> )
11:33:33 <tabemann> https://github.com/tabemann/amphibian]
11:33:36 <tabemann> whoops
11:33:40 <tabemann> https://github.com/tabemann/amphibian
11:34:38 <tabemann> I don't guarantee that it'll compile because I last compiled it like a year ago
11:34:54 <tabemann> and I haven't updated my Stack since then
11:35:55 <tabemann> it's not very good Haskell either - it's basically all written imperatively
11:35:56 <[exa]> ski: oh wow, that's from a guy from my faculty
11:36:10 <ski> oh
11:36:15 <ski> zemljanka ?
11:37:27 <[exa]> ski: no, pavel machek
11:37:34 <ski> okay
11:38:08 <[exa]> interesting, never noticed they worked on something like that
11:38:49 <[exa]> thanks for the link :]
11:39:18 <ski> np :)
11:41:58 <tabemann> I would assume they haven't ported that to GTK3
11:45:34 <K29> hi, check this out.. http://krmdev.altervista.org/pythonhexagon/
11:46:49 <Berengal> If I have a function like `foo x y = let f = expensive x in f y`, will f be duplicated if I pass around `g = foo someX`?
11:49:24 <c_wraith> Berengal: this is a very ghc-specific answer - yes
11:49:33 <[exa]> tabemann: since the last development seems to be from 2004... probably not.
11:50:13 <c_wraith> Berengal: but not if you eta-reduce it.  foo x = expensive x
11:51:00 <c_wraith> Berengal: this is because ghc takes optimization cues from the number of arguments written in the definition
11:51:10 <c_wraith> Berengal: I think that's weird behavior, but it's what ghc does
11:52:39 <Berengal> c_wraith: so `foo x = let f = expensive x in \y -> f y` ?
11:53:07 <Berengal> assuming it doesn't reduce quite that easily
11:54:55 <cocreature> note that -ffull-laziness which is part of -O2 (maybe also -O I forgot) can float things out of functions which means that they will be shared
11:54:56 <ski> yes
11:54:57 <ski> (s/eta-reduce/use function extensionality/)
11:56:39 <Berengal> cool
11:57:25 <ski> your `f' would sometimes be called a "serious curried function"
11:57:36 <ski> also "run-time compilation"
11:57:50 <ski> ("seriously" ?)
11:58:11 <Berengal> run-time compilation is exactly what I'm thinking about
11:58:17 <Berengal> regex compilation to be exact
11:58:30 <ski> that's a typical example of this, yes
12:04:52 <ggole> There's no particularly good alternative to choosing the arity from the number of syntactic arguments, unless maybe you are doing WPO
12:07:28 <ski> ("WPO" ?)
12:07:51 <erisco> WordPress optimisation
12:08:15 <ski> what's that ?
12:08:28 <ggole> Whole program optimisation
12:08:36 <ski> oh
12:08:49 <ski> ty
12:08:54 <int-e> ski: thanks for asking
12:08:57 <ggole> The idea being that you look at every possible application of a function and choose the arity to be the number of arguments seen the most
12:08:57 <erisco> You don't have join and part messages on do you
12:09:31 <ski> int-e : hm ?
12:09:57 <int-e> ski: about WPO I mean. I was wondering as well.
12:10:21 <ski> (erisco : i do. if you're asking me)
12:10:26 <ski> ok
12:13:50 * hackage ersatz 0.4.7 - A monad for expressing SAT or QSAT problems using observable sharing.  https://hackage.haskell.org/package/ersatz-0.4.7 (ryanglscott)
12:25:36 <habbah> I am trying to use a package which uses an older version of stack and an older version of Aeson than what I use in my own project. What should I do in this situation?
12:27:40 <glguy> The stack model is that you manually determine a build plan that you want, to do that you can either change resolvers to one that has the packages you want or try and assemble some extra-deps: that get what you want
12:53:06 <jkachmar> ls
12:53:13 <jkachmar> whoops, wrong window. ignore me
13:12:45 <KissMe_98> Starting my Live in a few minutes? I am going to touch & play with myself. Special Requests are OPENED (so it will be DOUBLE FUN!) Enter and reserve your seat (FREE for next 5 people): http://1w.tf/eRpts
13:14:08 <argent0> Can you explain how to use recursion schemes whit monads? ^^
13:14:44 <argent0> s/whit/with/
13:15:05 <ski> for `foldr' and `cata', you can just use a monadic result type
13:15:57 <ski> @type foldM  -- this is like a monadic version of `foldl', though
13:15:59 <lambdabot> (Monad m, Foldable t) => (b -> a -> m b) -> b -> t a -> m b
13:17:21 <argent0> ski: Yes but I _think_ i need something more like unfold. ana' :: (a -> m (Base t a)) -> m a -> m t
13:17:41 <argent0> or maybe (m a -> m (Base t a))
13:18:03 <argent0> bc. I want to use the `m a` action repeatedly
13:21:51 * hackage rattletrap 9.0.0 - Parse and generate Rocket League replays.  https://hackage.haskell.org/package/rattletrap-9.0.0 (fozworth)
13:31:31 <argent0> Here is what I've got so far: https://bpaste.net/show/38e709a227f7
13:33:22 <ski> argent0 : yea. was it you who i spoke to about a monadic `ana', the other day ?
13:34:15 <argent0> I don't think so. I spoke about `cataA` though
13:35:07 <ski> mhm
13:35:13 <ski> with what signature ?
13:36:18 <argent0> cataA :: Recursive t => (Base t (f a) -> f a) -> t -> f a 
13:37:23 <ski> how's that different from the plain `cata' ?
13:37:53 <ski> (apart from having a more specialized type, obviously)
13:39:03 <argent0> The docs say: This is a type specialisation of cata.
13:42:03 <lyxia> yeah it's the same but I guess it is easier to find at first if you're not familiar with the fact that cata can be specialized like that
13:49:59 <ski> argent0,lyxia : i see
14:04:16 <argent0> fun fact: if I use `makeBaseFunctor ''Foo` (template haskell) my code doesn't link any more.
14:05:20 * hackage dbus 1.2.8 - A client library for the D-Bus IPC system.  https://hackage.haskell.org/package/dbus-1.2.8 (blaze)
14:55:20 * hackage GPipe 2.2.4 - Typesafe functional GPU graphics programming  https://hackage.haskell.org/package/GPipe-2.2.4 (TobiasBexelius)
17:26:21 * hackage massiv 0.2.8.1 - Massiv (–ú–∞—Å—Å–∏–≤) is an Array Library.  https://hackage.haskell.org/package/massiv-0.2.8.1 (lehins)
17:31:20 * hackage massiv 0.3.2.1 - Massiv (–ú–∞—Å—Å–∏–≤) is an Array Library.  https://hackage.haskell.org/package/massiv-0.3.2.1 (lehins)
18:19:43 <jackdk_> is there a library that provides `tryReadChan :: Chan a -> IO (Maybe a)`? All I can find are 8-year-old proposals where people say it's probably a good idea, but it doesn't seem to have been built?
18:21:00 <monochrom> Probably they lost interest because TChan has tryReadTChan (much easier to implement)
18:24:09 <Nevoic> Something random that's been bugging me, is I have this feeling that I can represent anything I've done in Haskell in some arbitrary OO language, but the inverse isn't true.
18:24:10 <Nevoic> I know this isn't actually the case, I'm sure Haskell can represent something with far greater ease than I could in say Ruby or Kotlin, but does anyone have an actual example of this?
18:24:24 <jackdk_> Likely true. Unfortunately I'm stuck with Chans because this is code that interfaces with reflex: https://hackage.haskell.org/package/reflex-0.6.1/docs/Reflex-TriggerEvent-Base.html#v:runTriggerEventT
18:24:56 <Nevoic> It feels like I'm losing an entire way of thinking (i.e inheritance hierarchies, if I want to represent a classification of Animals I have to use some level of composition instead of inheritance, where in OO I could do either).
18:25:12 <jackdk_> Nevoic: Have you read Hughes' "Why Functional Programming Matters"? There are some pretty cool examples there. There's also a talk version if you don't like papers
18:25:21 <Nevoic> I have not.
18:25:47 <Nevoic> Damn, that's like 30 years old.
18:25:49 <Nevoic> I'll take a look though.
18:26:52 <jackdk_> https://www.youtube.com/watch?v=vGVJYoKIzjU - talk; https://lambdajam.yowconference.com.au/slides/yowlambdajam2017/Hughes-WhyFPMatters.pdf - slides; https://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf - paper
18:27:24 <jackdk_> this Chan stuff could be an XY problem. The backstory is here: https://github.com/qfpl/reflex-backend-socket/issues/5
18:29:10 <Nevoic> Do you think most of this stuff is still relevant today? One of the first sections (just glossing over it initially) is on "gluing functions together", which certainly isn't just a functional thing earlier.
18:29:10 <Nevoic> I'm definitely of the mindset that other languages have been made better by functional concepts (higher order functions, first class functions, etc.).
18:30:23 <Nevoic> To me all I've seen is the benefits of limiting yourself, which are definitely important. One reason I like Kotlin more than Python is you have the option to limit yourself in a lot of ways (val/private etc.), Haskell takes that a step further and forces you to limit yourself in a lot of ways, which surely has benefits, but that's pretty much the o
18:30:23 <Nevoic> nly thing I can lay out to someone I'm trying to convince that Haskell is good.
18:30:51 <Nevoic> I also like that the syntax feels like it "gets out of the way" and it seems generally quite expressive, but it's hard to quantify those things.
18:31:26 <jackdk_> there's also Snoyman's talk "what makes haskell unique" - https://www.youtube.com/watch?v=DebDaiYev2M
18:32:24 <jackdk_> functions like `mapConcurrently :: Traversable t => (a -> IO b) -> t a -> IO (t b)` are quite easy to specify and use safely, which is something you only get if you say "ok, we're going to track side-effects properly"
18:33:57 <Nevoic> jackdk_: üëç watching that talk now.
18:34:24 <Nevoic> I don't follow what you mean with mapConcurrently.
18:34:35 <Nevoic> That's partially because I don't know what the Traversable constraint does.
18:35:17 <jackdk_> oh, well replace t with lists then, does that help? (a -> IO b) -> [a] -> IO [b]
18:36:08 <Nevoic> So you're executing some IO action on a list of items?
18:36:36 <Nevoic> i.e printing each item in [a]?
18:36:41 <Nevoic> or something like that
18:37:23 <Nevoic> seems like you could call:
18:37:23 <Nevoic> mapConcurrently print ["one", "two"]
18:39:00 <jackdk_> correct. But also forking out a thread for each of them, and probably also lazily returning the result downstream as threads terminate (in order)
18:40:11 <Nevoic> Are you saying that's necessarily the case due to something that's true about Haskell, or the type signature, or that mapConcurrently is just a good Prelude function?
18:40:14 <Nevoic> assuming it's in the prelude.
18:40:49 <Nevoic> Because other languages have mapping split across threads (Java streams have ways of doing this IIRC and Java has one of the worst implementations of higher order functions in most of the languages I've tried).
18:41:22 <Nevoic> Not by default, but like mapParralel or whatever.
18:42:34 <jackdk_> it's not prelude but it's somewhere reasonably easy to find. I claim that the type signature makes it exceptionally clear, and that you won't find as elegant an implementation of this pattern in most other languages
18:42:40 <jackdk_> behold: `mapConcurrently f = runConcurrently . traverse (Concurrently . f)`
18:44:37 <Nevoic> I'm not necessarily following how `:: (a -> IO b) -> [a] -> IO [b]` is giving any indication of multi-threaded behavior or lazy behavior (although I'd just assume lazy because Haskell is by default lazy).
18:45:20 <Nevoic> I.E other languages have (a -> b) -> [a] -> [b] (mapping), and obviously you get the downside of not knowing whether or not the function is pure, this is definitely a benefit of Haskell, but in terms of concurrency or laziness, I see no difference.
18:45:48 <jackdk_> That's right
18:46:17 <jackdk_> I'm more gesturing at how elegantly it captures a particular concurrency pattern, not that the type forces it.
18:46:37 <Nevoic> Is this just some Haskell convention, or am I missing something?
18:47:03 <Nevoic> As in, I don't see what's capturing the concurrency pattern, other than the name.
18:47:11 <Nevoic> And having well named functions isn't a uniquely Haskell thing, obviously.
18:48:02 <jackdk_> that's true. The non concurrent version is traverse, which if you specialise some of the typeclasses also has (a -> IO b) -> [a] -> IO [b]
18:48:39 <Nevoic> I feel like generally this is just an elaborate example of what my original "pro Haskell" point was (i.e that you're limited in some regards).
18:49:22 <Nevoic> (a -> IO b) -> [a] -> IO [b] and (a -> b) -> [a] -> [b] are different in Haskell but the same in OO languages, but that's just a (good IMO) limitation.
18:50:14 <jackdk_> hm. possibly. I would claim that it's not a limitation if you can do the things you could previously do, and do them while speaking more precisely
18:52:44 <Nevoic> Yeah that's fair, I suppose it's only a limitation if you're talking about the possible implementations of `(a -> b) -> [a] -> [b]`, but that's not the whole picture. 
18:53:23 <jackdk_> I spent two years writing boring webservicey stuff in haskell full-time, never really missed the ability to do OO stuff and found it easier to maintain logical separation between layers and external dependencies etc 
18:54:10 <jackdk_> I don't say "boring" like it's bad, fwiw: for a language to be industrially useful you have to be able to do that
18:54:56 <Nevoic> Yeah, when I write Kotlin I find myself writing mainly functional code (immutable code with function composition and literally 0 classes in my entire domain layer, only interfaces). 
18:55:23 <Nevoic> That's one reason why I started learning Haskell, I naturally tended towards functional things after learning about Clean Architecture and things like that. 
18:56:22 <Nevoic> But it's been a more intense learning curve than any other language I've gone through, and learning C or Rust for the first time wasn't easy lol
18:57:01 <jackdk_> yeah it's pretty brain bendy once your for loops are taken off you. my learning really accelerated when it became a full-time job for me
18:58:36 <Nevoic> Yeah, I started hating for/while etc. loops well before I got into my first functional language too.
18:58:42 <jackdk_> Your initial claim has me thinking about lenses - I can't show you the code because it's work-related stuff, but lenses over trees like pandoc or html are really cool, and nobody had to sit around and implement an xpath runtime to make them go
18:58:55 <Nevoic> I was very comfortable with translating mutable/imperative flows into functional ones (chained higher order functions etc.)
18:59:10 <jackdk_> like a handful of lines to pull every table from a document that matches some predicate, and then do something to some of the columns, and then ...
19:00:22 <jackdk_> and you can do lenses etc in java - there was a full implementation of profunctor optics in the open-source release of the minecraft DataFixerUpper IIRC - but it's not pretty and the amount of code you have to write for the encoding is pretty big
19:13:50 * hackage lazyboy 0.2.1.1 - An EDSL for programming the Game Boy.  https://hackage.haskell.org/package/lazyboy-0.2.1.1 (rose)
19:52:06 <gbd_628> Hi, so, I found a case where GHCi's inferred type isn't accepted by GHC. I think it's a bug, but maybe it's just one of the many weird results of -XAllowAmbiguousTypes?
19:52:08 <gbd_628> https://gist.github.com/greatBigDot/5fb2171f2f9968bc619178d6d1cac066
19:54:04 <gbd_628> The documentation for -XAllowAmbiguousTypes describes how you can have `foo :: t`, but not `(foo :: t) :: t`. Is this like that? Or should I file a report? (I don't 100% understand the ambiguity stuff, so I'm not sure.)
19:54:54 <ski>   bar :: forall s t. Foo s t => t
19:54:55 <ski>   bar = foo @s
19:55:12 <ski> `ScopedTypeVariables' and `TypeApplications'
19:55:52 <lyxia> it's subtle but it doesn't look like a bug.
19:58:10 <gbd_628> Okay, thanks. But then why is `bar = foo` is accepted (unless the monomorphism restriction is enabled)?
19:58:38 <lyxia> without the type signature, GHC takes whatever constraints are required and puts them in the inferred signature. With the explicit type signature, it tries to satisfy the constraint using what is provided by the signature.
19:59:59 <lyxia> however, while the signature provides (Foo s t), foo might not use the same s
20:00:19 <ski> hm, so this is a case of the typing relation not being steadfast ?
20:02:07 <lyxia> I don't know what a typing relation being steadfast means
20:02:42 <ski> a relation/predicate being "steadfast" is logic programming terminology
20:03:22 <ski> not being steadfast means that logical reasoning starts to break down
20:04:25 <ski> more specifically, if you provide more information/knowledge upfront, to a predicate call, that should only ever cause solutions to disappear, and (generic) solutions (involving variables/parameters) to become more specific
20:04:47 <ski> it should never cause new solutions to appear
20:05:50 <ski> in Prolog `elem x xs' is spelled `member(X,Xs)'. `member(X,[2,3])' has solutions `X = 2 ; X = 3' (`;' being "or")
20:07:37 <ski> however, there's a variant of member/2, called memberchk/2, which commits to the first solution. so `X = 3,memberchk(X,[2,3])' has solution `X = 3', but `memberchk(X,[2,3]),X = 3' fails (has no solutions) .. so now conjunction is no longer commutative :/
20:07:55 <ski> memberchk/2 is not steadfast
20:10:31 <ski> in gbd_628's case, `(bar :: tau) /\ (tau = forall s t. Foo s t => t)' (inferring type `tau', then checking upto alpha) succeeds, but `(tau = forall s t. Foo s t => t) /\ (bar :: tau)' (aka `bar :: forall s t. Foo s t => t') (checking `bar' has type `forall s t. Foo s t => t') fails
20:12:49 <ski> hm .. though i suppose in this case, it's not that a solution is added, when more information is given. so perhaps this wouldn't actually be counted as non-steadfast ? however, commutativity of conjunction still fails :/
20:13:43 * ski wonders whether there's any readily available example of this type of situation, in Prolog
20:14:36 <ski> (you can obviously construct such an example, with var/1,nonvar/1,cut or conditional)
20:20:35 <gbd_628> Okay, I guess I sort of get what's happening now... Thanks @ski and @lyxia
20:23:28 <newhoggy> Anyone know a good way to find infinite loops in a Haskell process?
20:25:27 <newhoggy> Particularly in the context of a property test (hedgehog) that doesn't terminate.
20:27:30 <newhoggy> Hmm, actually its a Hedgehog shrinking problem.  I continues shrinking forever :/
20:27:45 <newhoggy> `  ‚ÜØ <interactive> failed after 72 tests and 495 shrinks (shrinking)`
20:31:32 <royal_screwup21> can I ask a logic question on here? It's not directly related to haskell programming :)
20:32:38 <DigitalKiwi> it's more related than asking to ask :-)
20:32:56 <royal_screwup21> In the 2nd example, could someone explain to me how the bottom 3 places in the petri net all have tokens?  https://www.techfak.uni-bielefeld.de/~mchen/BioPNML/Intro/pnfaq.html
20:33:00 <royal_screwup21> I don't understand the logic. There are only two tokens to begin with
20:33:05 <royal_screwup21> and the weight of each arc is 1 by default
20:44:50 * hackage polysemy 0.3.0.0 - Higher-order, low-boilerplate, zero-cost free monads.  https://hackage.haskell.org/package/polysemy-0.3.0.0 (isovector)
20:55:59 <lyxia> royal_screwup21: the number of tokens is not a constant
20:56:32 <royal_screwup21> lyxia but p1 and p2 have one token each
20:57:27 <lyxia> sure
20:58:01 <pavonia> Don't confuse the tokens as being objects that move around
20:59:59 <royal_screwup21> I don't get it 
21:00:29 <royal_screwup21> is the right part of the second example different from the left part?
21:00:38 <royal_screwup21> I thought they were both logically related 
21:02:19 <blankhart> are there situations when cabal should be installing multiple versions of the same dependency in a single build?
21:02:50 <lyxia> royal_screwup21: yes they are related
21:03:20 <blankhart> i am trying to make sense of this output https://gist.github.com/blankhart/be8b963be7fd75b6d97b7fdc326de65a where cabal wants to install multiple different versions of proto-lens and proto-lens-protoc
21:03:50 <lyxia> when the transition fires, it takes one token from p1 because the arc capacity is 1, one token from p2 because the arc capacity is 1, and it puts on token in each of P3,P4,P5 because their arc capacities are 1.
21:07:23 <royal_screwup21> lyxia ah thanks for clarifying :)
21:08:23 <royal_screwup21> i'm trying to understand how inhibitor arcs work in the context of petri with this example: https://prnt.sc/nwhx8h am I right in thinking that, even though the inhibitor arc is present, there will still be a loop from the bottom state to the top one?
21:09:50 * hackage polysemy-zoo 0.1.2.0 - Experimental, user-contributed effects and interpreters for polysemy  https://hackage.haskell.org/package/polysemy-zoo-0.1.2.0 (isovector)
21:12:52 <lyxia> royal_screwup21: the bottom transition can still fire, if that's what you mean.
21:14:22 <royal_screwup21> lyxia ah okay...and after it fires, the top transition can still fire? I don't understand how the inhibitor arc changes anything. Like, if I didn't put the inhibitor arc, I don't undnerstand how things would be different 
21:14:50 <pavonia> The inhibitor only permits the first transition to fire if the second state is empty, so you can't have two tokens in state 2
21:16:01 <royal_screwup21> ohh okay
21:16:42 <royal_screwup21> okay, now it's all making a bit more sense: I was previously associating transition with those arrows...turns out they're arcs 
21:18:46 <royal_screwup21> y'all are so smart, how do you just get stuff in one go? :)
21:23:08 <pavonia> It's a gift .. and a curse :3
21:25:24 <royal_screwup21> I'm trying to figure out if (b) is bounded https://prnt.sc/nwi0rq
21:26:20 <royal_screwup21> I'm confused as to how it it works: the top transition could take one token from the state, fire out two tokens, then of of which goes to the top state, the other to the bottom one  
21:26:29 <royal_screwup21> from the top state*
21:26:39 <royal_screwup21> is that correct?
21:26:51 <royal_screwup21> s/top state/ p1 
21:26:57 <royal_screwup21> s/bottom state/ p2
21:27:50 <royal_screwup21> oh man let me rephrease: the transition could take one token from P1, then create two tokens, one of which is fired back to P1, the other is fired into P2. Is that accurate?
21:58:08 <slack1256> On reactive-banana, I don't understand the difference between a `Behaviour a` and a `Moment a`, their denotations are the same. Can somebody help me?
22:21:50 * hackage twitter-types-lens 0.8.1 - Twitter JSON types (lens powered)  https://hackage.haskell.org/package/twitter-types-lens-0.8.1 (TakahiroHimura)
