00:47:44 * hackage transient 0.6.3 - composing programs with multithreading, events and distributed computing  https://hackage.haskell.org/package/transient-0.6.3 (AlbertoCorona)
01:19:11 <phaul> can someone help me debugging this https://gist.github.com/phaul/6f9d924dd676ab8cb4d1e6f263772a89?
01:19:46 <phaul> on line 72 the traceShow shows that bytes are not all 0. but memory comes back as all '0's
01:20:19 <phaul> on the other hand if I change byte on line 75 to be a non 0 constant the memory will be filled with the constant
01:35:44 * hackage gitter 0.5 - Gitter.im API client  https://hackage.haskell.org/package/gitter-0.5 (cblp)
01:49:06 <phaul> nm found the issue
01:52:43 * hackage butcher 1.3.2.2 - Chops a command or program invocation into digestable pieces.  https://hackage.haskell.org/package/butcher-1.3.2.2 (lspitzner)
01:54:44 * hackage mssql-simple 0.1.0.3 - SQL Server client library implemented in Haskell  https://hackage.haskell.org/package/mssql-simple-0.1.0.3 (tkmsm)
02:22:29 <maskal> Hey
02:22:32 <maskal> and ((max 0 11) == (max 10 0), (min 0 11) == (min 10 0))
02:22:39 <maskal> Why does that return True when it should be returning False?
02:23:26 <maskal> and (11 == 10, 0 == 0)
02:23:30 <maskal> Shouldn't this return False?
02:23:51 <fendor_> > and ((max 0 11) == (max 10 0), (min 0 11) == (min 10 0))
02:23:54 <lambdabot>  True
02:24:17 <maskal> Well, why?
02:24:21 <fendor_> Foldable Instance of (,) is to blame
02:24:41 <maskal> What does that mean?
02:24:42 <fendor_> sum ("text", 2)
02:24:47 <fendor_> > sum ("text", 2)
02:24:49 <lambdabot>  2
02:24:54 <fendor_> :t and
02:24:55 <lambdabot> Foldable t => t Bool -> Bool
02:25:12 <fendor_> `and` uses the type class Foldable
02:25:24 <fendor_> Foldable takes a single type parameter
02:25:34 <fendor_> :t Foldable
02:25:36 <lambdabot> error: Data constructor not in scope: Foldable
02:25:43 <fendor_> @hoogle Foldable
02:25:44 <lambdabot> Prelude class Foldable t
02:25:44 <lambdabot> module Data.Foldable
02:25:44 <lambdabot> Data.Foldable class Foldable t
02:25:51 <fendor_> @src Foldable
02:25:51 <lambdabot> Source not found. Take a stress pill and think things over.
02:25:58 <maskal> How would I do this in Haskell: "return expr && expr"
02:26:16 <fendor_> you can do it just like that
02:26:20 <fendor_> True && True
02:26:23 <maskal> Oh
02:26:25 <fendor_> > True && True
02:26:27 <lambdabot>  True
02:26:29 <maskal> What is "and" for then?
02:26:37 <fendor_> for a list of boolean values
02:26:43 <fendor_> > and [True, True, False]
02:26:45 <lambdabot>  False
02:26:46 <maskal> Oh
02:26:48 <maskal> Alright thanks
02:26:57 <fendor_> or, a list like thing, like foldable
02:27:29 <fendor_> also, there is `||` and `or` with respective meaning
02:27:35 <fendor_> > or [False, False, True]
02:27:37 <lambdabot>  True
02:46:47 <zincy> How do you pinpoint where memory is being retained and not garbage collected when detecting a space leak. I am starting by just looking at the output of memory profiling with the retainer flag and seeing which module is retaining the most memory. Is this a good approach?
02:55:18 <Lycurgus> how do you know there's in fact a problem with gc?
02:55:42 <Lycurgus> (as opposed to a lack of control of hs)
02:56:14 * hackage tagged-identity 0.1.3 - Trivial monad transformer that allows identical monad stacks have different types  https://hackage.haskell.org/package/tagged-identity-0.1.3 (mrkkrp)
02:57:23 <Lycurgus> in any case valgrind is the standard tool
02:58:38 <Lycurgus> i'm sure it's happened but I don't ever recall hearing of an actual leak in haskell which is a managed lang
02:59:42 <Lycurgus> with its notorious space/time complexity, such a thing would be fairly dire for it (haskell)
03:00:41 <zincy> sorry don't follow
03:01:17 <zincy> what makes me think there is a space leak is that the memory footprint of my server grows rapidly
03:01:21 <zincy> and indefinitely
03:01:22 <[exa]> Lycurgus: there are leaks but they have a different meaning
03:01:32 <[exa]> certainly not "lost pointer" like in C
03:02:06 <zincy> a build up of unevaluated thunks is what is typically regarded as a space leak in Haskell
03:02:13 <[exa]> zincy: what kind of application is that btw?
03:02:37 <zincy> [exa]: https://github.com/therewillbecode/haskell-poker/tree/counter
03:02:43 <zincy> multiplayer poker serber
03:02:47 <zincy> *server
03:03:17 <Lycurgus> [exa], yes that confirms what I said
03:04:06 <Lycurgus> as does zincy's report of the problem
03:04:19 <[exa]> zincy: does it grow so that it goes OOM or does the growth stop?
03:04:31 <zincy> OOM
03:04:48 <zincy> Actually
03:04:52 <zincy> Let me verify that
03:05:03 <zincy> OOM is "out of memory" right?
03:05:09 <[exa]> yes
03:05:57 <[exa]> the funny thing when your app swaps everything else out, the whole box gets slowww and finally it gets a OOM coup de grace from kernel
03:08:41 <Lycurgus> (i.e. a leak caused by ghc, whose developers would be the only ones to use valgrind)
03:08:59 <Lycurgus> (as opposed to other haskell implementations)
03:10:21 <zincy> [exa]: So actually before I run the server I had 1gb mem free after a few minutes of running some bots playing lots of games against each other free mem hits a low of 140mb then bounces between 140 and 250mb
03:12:32 <[exa]> zincy: OS-reported free memory is not even remotely good metric for measuring actual memory use
03:12:37 <zincy> Would a space leak just eventually put you OOM?
03:13:00 <zincy> oh really
03:13:02 <[exa]> "it takes around 75% memory and oscillates around there" is a common good behavior
03:13:20 <zincy> Yay! So it is actually fine and I can stop worrying?
03:13:43 <[exa]> not too much GC pressure when it's not needed, but still quite a bit of memory for others to get
03:14:00 <[exa]> yeah, if it doesn't push other apps to swap or go OOM, I wouldn't worry
03:14:12 <zincy> cool thanks for the help
03:14:21 <[exa]> if you want to keep the footprint really minimal, you may play with RTS opts to limit the maximal allocation
03:14:29 <zincy> At least I learned how to run memory profiling
03:14:50 <zincy> Yeah there is a library for automating the process of which GHC flags are most performant for your app
03:15:08 <zincy> https://hackage.haskell.org/package/ghc-gc-tune
03:15:34 <[exa]> zincy: that's for performance
03:15:51 <[exa]> I wouldn't worry for server apps that don't bottleneck on data structure handling
03:15:51 <zincy> Ah so not for memory
03:17:06 <zincy> Should I be afraid of lazy IO
03:17:29 <zincy> I keep reading that it is generally avoided by experienced haskellers in production
03:17:42 <[exa]> if you want to press the program down to say 200MB, this will probably work for you: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#rts-options-to-control-the-garbage-collector
03:17:59 <zincy> Oh thanks
03:18:13 <zincy> So what is the impact of constraining memory like that on performance?
03:18:23 <[exa]> well lazy IO may explode into your face just as well as strictly loaded heap of big requests
03:18:50 <[exa]> but the other explosion can be handler by several correctly placed checks
03:18:53 <[exa]> *handled
03:19:40 <[exa]> zincy: probably not much unless you give it so little memory that it starves out
03:19:52 <zincy> ok
03:20:13 <zincy> Incidently from my memory profiling mapAccumL seems to use a lot of memory
03:20:20 <zincy> Curious ...
03:20:24 <[exa]> btw you want the -K option
03:20:42 <[exa]> and -M
03:21:50 <zincy> stack and heap size right?
03:22:03 <[exa]> and also check out -c if you want the server to run for years
03:22:21 <[exa]> very roughly, yes
03:22:44 * hackage th-bang-compat 0.0.1.0 - Compatibility for bang-type template  https://hackage.haskell.org/package/th-bang-compat-0.0.1.0 (KeiHibino)
03:23:46 <zincy> How would -c prolong the life of a running server process?
03:24:02 <zincy> Does it minimise the chance of OOM?
03:27:12 <[exa]> zincy: as I get it it prevents fragmentation so in extreme case it can help, but you'd better ask someone with deeper knowledge of haskell GC
03:27:29 <[exa]> there should be a paper about how the GC works also
03:28:03 <[exa]> anyway, in short -- if you run it in amazon instance, don't worry, the defaults are probably right; and you can eventually just add the -c to be double sure
03:29:11 <cocreature> copying garbage collection doesn’t suffer from fragmentation.
03:29:51 <cocreature> but it needs more peak memory since it has to allocate the new region, copy to it and then free the old one
03:31:19 <[exa]> oh so
03:31:22 <[exa]> good to know, thanks
03:34:43 <[exa]> hm. If I have a program that has a single OS thread and calls a fat FFI C function, I assume the call will block the lightweight threads?
03:35:12 <[exa]> (context: what's the simplest way to run some computation on the background in Gloss play without losing framerate)
03:35:38 <cocreature> use the threaded runtime
03:36:03 <cocreature> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ffi-chap.html#multi-threading-and-the-ffi
03:37:34 <[exa]> oh good, that was simpler than I thought
03:39:04 <cocreature> note that you need to mark it is important that you mark it as "safe"
03:40:33 <[exa]> ok it seems to work automagically, thanks a lot :]
05:11:45 <Ariakenom> cocreature: but later ghc generation don't copy, right?
05:17:43 <JoeCordingley> join #manjaro
05:18:01 <JoeCordingley> hi
05:21:10 <JoeCordingley> hi, I tried installing manjaro but on restart I have been dropped in grub rescue
05:21:40 <JoeCordingley> error: file '/grub/i386-pc/normal.mod' not found.
05:21:41 <JoeCordingley> grub rescue>
05:21:43 <gehmehgeh> JoeCordingley: wrong channel
05:21:44 <gehmehgeh> :)
05:21:52 <gehmehgeh> JoeCordingley: you're still in #haskell
05:22:00 <JoeCordingley> am I still in haskell?
05:22:34 <JoeCordingley> ha! thanks
05:22:51 <gehmehgeh> JoeCordingley: you forgot to actually type the "/" in front of "join" ;)
05:44:58 <cocreature> Ariakenom: the docs for -c state “By default, the oldest generation is collected using a copying algorithm; this option causes it to be compacted in-place instead”. But I’m not too familiar with GHC’s GC so I can’t tell you much more
05:53:21 <Ariakenom> cocreature: oh ok
05:55:57 <__monty__> Ariakenom: Afaik all the generations are copy collected, by default that is.
07:35:10 <jusss> why Just 3 >>= (\x -> Just "!" >>= (\y -> Just (show x ++ y)))
07:35:23 <jusss> equal to Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y)
07:40:11 <nil> how else would you parenthesise it?
07:41:46 <nil> i suppose it could be  Just 3 >>= (\x -> Just "!") >>= (\y -> Just (show x ++ y))  , but that isn't quite as useful
07:43:03 <jusss> nil: yours is equal to Just 3 >>= (\x -> Just "!" >>= (\y -> Just (show x ++ y))) ?
07:43:26 <nil> no
07:44:57 <jusss> nil: but in the last lambda, we can get x from the ahead expressions
07:47:10 <nil> in your version, yes. in mine, no.
07:47:39 <jusss> nil is this related with monad's third law?
07:47:57 <jusss> f >> g >> h  == f >> \x -> g x >> h
07:49:06 <nil> no
07:49:49 <jusss> nil ok, so in your version, how it can get x? where is x from ?
07:50:16 <nil> it can't, that's my whole point
07:50:59 <nil> my version would result in an error, unless x was bound to something else before
07:51:30 <nil> hence "not quite as useful", except for situations where you don't need to reuse variables from previous lambdas in future lambdas
07:52:22 <jusss> nil I don't get it, your version is look like Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y)
07:52:33 <jusss> nil but the Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y) got Just "3!"
07:52:44 <jusss> Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y)
07:52:49 <nil> but it isn't equivalent, because the parenthesisation for that expression is the one you showed
07:52:55 <jusss> Just 3 >>= (\x -> Just "!") >>= (\y -> Just (show x ++ y))
07:53:47 <nil> lambda abstractions, if thought of as an operator, have the lowest precedence. they just extend as far as possible to the right
07:54:25 <jusss> nil aha, right associate, right?
07:54:57 <nil> not exactly
07:55:14 <jusss> still confused
07:55:40 <jusss> so what Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y) equal to ?
07:55:43 <nil> well, you can think of it like that if it helps you
07:56:00 <nil> jusss: you know that, it's the core of your original question
07:56:07 <nil> <jusss> why Just 3 >>= (\x -> Just "!" >>= (\y -> Just (show x ++ y))) 
07:56:18 <nil> that's what it parenthesises to.
08:03:56 <jusss> nil and it equals to Just 3 >>= (\x -> (Just "!" >>= (\y -> Just (show x ++ y)))) ?
08:04:41 <nil> yes, there's no ambiguity there
08:05:14 <nil> (hm, there is, actually.)
08:05:22 <nil> but yes.
08:07:57 <jusss> nil ok it seems right associate in lambda to me 
08:08:39 <jusss> no
08:09:31 <jusss> nil it's the end of the lambda
08:09:59 <jusss> if we don't put a ) to close (, then lambda will not end ?
08:10:43 <nil> i don't know what you mean.
08:11:42 <jusss> nil Just 3 >>= \x -> ... >>= \y -> ... >>= \z -> ... equal to Just 3 >>= (\x -> ... \z -> ..) ?
08:12:51 <jusss> Just 3 >>= (\x -> (... >>= \y -> (... >>= \z -> ...))) ?
08:16:37 <[exa]> jusss: open lambda goes all the way to the end of block, so \a -> ... \b -> ... parentheses as (\a -> ... (\b -> ...))
08:19:50 <[exa]> jusss: the other way, ... (\a -> ...) (\b -> ...) is a bit confusing. You can read '\a ->' as abstracting 'a' from now on
08:19:59 <jusss> [exa]: Just 3 >>= (\x -> Just "!" >>= (\y -> Just (show x ++ y))) equal to Just 3 >>= \x -> Just "!" >>= \y -> Just (show x ++ y) ?
08:20:24 <[exa]> jusss: yeah that should work
08:23:37 <jusss> [exa]: ok, I miss the scheme's lambda
08:24:23 <unfixpoint> The Liar paradox "A: This statement (A) is false" is basically the fixpoint of `\a. not a`, right?
08:24:26 <__monty__> Why? You can include all the parens you want in haskell.
08:24:32 <[exa]> jusss: do you mean the parentheses?
08:24:33 <unfixpoint> Or `fix not` really
08:24:41 <jusss> [exa]: yeah
08:25:06 <[exa]> jusss: if you become lisp god, parentheses disappear
08:25:12 <[exa]> :]
08:25:31 <jusss> __monty__: >>= is infix, and scheme is prefix
08:25:38 <cocreature> __monty__: that doesn’t really help given that you will have to read other people’s code :) (not that I personally think that is a problem)
08:26:22 <jusss> in this complicate lambda nested lambda, I think prefix is better than infix
08:26:23 <[exa]> unfixpoint: well that's its value if you want to evaluate it boolean-ishly
08:26:58 <unfixpoint> How to evaluate it differently?
08:26:59 <unfixpoint> :)
08:27:11 <[exa]> why not curry-howard it?
08:27:21 <jusss> OO call is like infix, but function call still like prefix
08:27:43 <unfixpoint> Curry's paradox?
08:28:48 <[exa]> unfixpoint: no, translate the sentence into some kind of intuitionistic logic and show there's no program that proves it
08:29:19 <[exa]> unfixpoint: like here: https://en.wikibooks.org/wiki/Haskell/The_Curry%E2%80%93Howard_isomorphism
08:29:54 <[exa]> but you'll probably need λμ for saying a self-referential statement simply
08:30:45 <unfixpoint> I see, yeah I meant to work around that by using `fix` :D
08:30:56 <jusss> I still have one question, lets forget the reader monad, focus on >>= :: (e->a) -> (a -> (e->b)) -> (e->b) , so (e->a) and (e->b) both are functions, lets assume f x = x+1 , so (f 3) >>= ? and how the >>= is like?
08:31:36 <jusss> or I should use f >>= ?
08:32:03 <jusss> when function contain monad or functor is really confused to me
08:33:02 <[exa]> unfixpoint: yes, IIRC you'll arrive at the situation where you will want a term that can not be easily generated using fix
08:33:06 <jusss> Maybe and Either or List, those monads are easy to understand, but this e->a is not
08:34:05 <unfixpoint> jusss: You can do `succ >>= (+)` applied to 1 gives (2+1)
08:34:21 <unfixpoint> or try `succ >>= (,)` gives `(2,1)` with 1
08:34:27 <[exa]> jusss: the problem is that 'f 3' is not of type (e->a)
08:34:51 <jusss> unfixpoint: f >>= g  =  \x -> f (g x) x,  this is really weird 
08:35:17 <jusss> I know what it equals, but I don't understand the meaning,
08:35:21 <unfixpoint> jusss: Yeah, use `(<*>)` ;)
08:35:21 <jusss> why this form
08:35:23 <unfixpoint> S-combinator
08:37:39 <jusss> [exa]: unfixpoint why this f >>= g  =  \x -> f (g x) x, whats this meaning? what it's used for?
08:38:54 <jusss> and you all call it Reader Monad, and make a form to get the input value, and I don't know why
08:39:30 <jusss> why when function contain monad and functor, they all get weird
08:39:36 <lavalike> jusss: do you understand State somewhat?
08:40:26 <jusss> lavalike: I saw State Monad,  s->(r,s) whatever, and I don't
08:40:49 <unfixpoint> We can have `fix ((&&) <*> not)` for a rough translation
08:40:52 <jusss> I know there're Stete, Reader, Writer
08:40:53 <lavalike> jusss: maybe start with that, Reader is almost like half of it, where you can only "get" the state, and never "put" it
08:41:08 <lavalike> yeah and Writer is the other half, you can only do the reverse, in a sense
08:41:20 <lavalike> State is simpler to make sense of
08:41:43 <jusss> lavalike: can we describe this monad e-> without reader moand form ?
08:41:53 <jusss> just use function to describe
08:42:10 <jusss> forget reader moand that form or shape whatever you called
08:42:27 <jusss> why not just use function?
08:42:41 <lavalike> my point is to try to grok State and then Reader and Writer become easier to grasp
08:43:58 <jusss> what about flip the sequence, reader writer then state?
08:44:20 <lavalike> that's what you were already doing
08:44:39 <jusss> lavalike: state is related with e-> ?
08:44:55 <c_wraith> @unmtl State s a
08:44:55 <lambdabot> s -> (a, s)
08:45:39 <jusss> and this (a,s) is a tuple? right? why not a list?
08:45:50 <c_wraith> because that would be something else
08:46:04 <jusss> 'cause tuple doesn't have the sequence or order
08:46:09 <c_wraith> The whole point of State is to package up the idiom of explicit state-passing
08:46:21 <c_wraith> lists require every element to be the same order
08:46:29 <jusss> c_wraith: what is that something else? s -> [a,s] is ?
08:46:42 <lavalike> don't confuse the notation for types for the notation for values
08:46:51 <c_wraith> that's not a type.  s -> [(a,s)] is a type.
08:47:09 <lavalike> the type constructor [] takes exactly 1 argument, another type, and gives you a type: the type of lists of the given type, not 2
08:47:09 <c_wraith> or s -> ([a], s)
08:48:12 <lavalike> so [] applied to Int, i.e. [] Int, or also [Int] for nicety, is the type of values of lists of `Int's: [] a s or [a,s] is an error as [] only takes 1 type argument
08:50:02 <jusss> this is beyond my comprehension...
08:50:12 <jusss> now
08:50:39 <c_wraith> Then don't worry about it.  The pieces come together eventually.
08:51:31 <jusss> ok
08:52:01 <jusss> c_wraith: actually I was wondering how about share state stuff 
08:52:22 <jusss> and they said something about reader monad 
08:52:51 <jusss> I read them from some articles
08:53:32 <jusss> I wonder the magic, avoid to create global variable to store a value or state whatever
08:53:41 <c_wraith> There's no magic involved
08:54:00 <c_wraith> It's replacing a global variable with just passing a value around
08:54:25 <[exa]> jusss: let's go the scheme way, let's say you have (lambda (a) (+ (* 2 a) (^ 2 a)))
08:54:40 <[exa]> jusss: in haskell, that's like: (\a -> (+) ((*) 2 4) ((^) 2 4))
08:54:48 <[exa]> oh noes
08:55:00 <[exa]> this way: (\a -> (+) ((*) 2 a) ((^) 2 a))
08:56:08 <[exa]> now, because single-parameter functions are functors (and also applicatives and monads), you can eliminate a bit of manual parameter forwarding and write this:
08:56:39 <jusss> c_wraith: but hey, global variable can store values and you can visit it any time, but passing a value around ? you only passing it in a chain, you store values in a chain, the outer function still can't get the value unless they join the chain
08:56:55 <[exa]> jusss: ((+) <$> (2*) <*> (2^))
08:57:01 <[exa]> % ((+) <$> (2*) <*> (2^)) 5
08:57:01 <yahb> [exa]: 42
08:57:05 <c_wraith> jusss: yes, that's a good thing.  It means you need to be *explicit* about what has access to what
08:57:06 <gobby> I'm confused about this type `type Handler = HandlerT MyApp IO` seen here (https://www.yesodweb.com/book/routing-and-handlers). Why is it not ``type Handler a = HandlerT MyApp IO a`
08:57:29 <[exa]> jusss: and the functor/applicative/monad framework for singleparameter function just nicely silently passes the argument around
09:00:04 <[exa]> jusss: aaand, if you dig a bit in how that's achieved, you'll eventually find that the rule '(f <*> g) x = f x (g x)' (together with its monadic counterpart) exactly allows all this to happen
09:01:00 <jusss> c_wraith: [exa] and I think to construct that chain will be difficult
09:01:24 <c_wraith> jusss: constructing the chain automatically is what types like State get you.
09:01:44 * hackage lens-regex-pcre 0.1.0.0 -   https://hackage.haskell.org/package/lens-regex-pcre-0.1.0.0 (ChrisPenner)
09:01:50 <jusss> c_wraith: [exa] I don't know if you use python or js or scheme, re-assign is really easy to do something
09:02:16 <[exa]> jusss: reassign is also an easy way to make your language intractable to static analysis
09:04:50 <jusss> [exa]: but reassign can make you to store values, and you can visit those values any time, but in a chain? you can't visit it from outside and any time, you can only visit it if you put the visitor in the chain
09:05:50 <cocreature> you can use actual mutable state in Haskell which is important for concurrency
09:06:04 <c_wraith> But that's rare to actually need.
09:06:05 <jusss> I don't know to construct that chain how long it will take, maybe it's a long time
09:06:37 <[exa]> jusss: have you seen the do-notation?
09:06:39 <c_wraith> For the programmer or the computer?
09:06:46 <jusss> [exa]: yep
09:06:58 <jusss> c_wraith: for the programmer 
09:06:59 <cocreature> c_wraith: well I’d say concurrency is quite common in Haskell and then mutable state in the form of MVars/TVars/… is quite common
09:07:09 <[exa]> jusss: it looks just like python, even with assignments and everything, right?
09:07:12 <cocreature> but yeah it’s definitely less common than in other languages
09:07:23 <unfixpoint> I usually use unsafePerformIO to write/read from files, Haskell's pretty annoying at at times
09:07:35 <cocreature> that is not a good idea
09:07:38 <c_wraith> unfixpoint: cool
09:07:41 <[exa]> unfixpoint: oh noes!
09:08:02 <__monty__> unfixpoint: Sounds like you're afraid of the IO monad.
09:08:11 <__monty__> Or just IO, let's drop the monad.
09:08:35 <jusss> [exa]: I haven't tried it, maybe I should, construct a chain is the right way to avoid global variable? 
09:08:54 <[exa]> jusss: 'do' basically constructs the chain for you
09:09:27 <jusss> [exa]: but other languages don't have do notation... unless we implement it in others
09:09:56 <c_wraith> jusss: other languages *really wish* they had do notation.  Have you noticed how many times it gets reinvented?
09:10:23 <c_wraith> async/await, null coalescing operators, etc
09:10:25 <[exa]> jusss: taken to extreme, 'do' notation is just about having a polymorphic, overloadable code-block construct
09:10:29 <c_wraith> all special cases of do notation
09:11:18 <[exa]> jusss: in C, all commands in blocks separated by semicolons can be though as do-blocks of IO operations
09:11:24 <[exa]> jusss: similarly in python, js, etc.
09:12:02 <gobby> I'm confused about this type `type Handler = HandlerT MyApp IO` seen here (https://www.yesodweb.com/book/routing-and-handlers). Why is it not ``type Handler a = HandlerT MyApp IO a`
09:12:14 <[exa]> jusss: you might notice a similarity with Scheme's (begin), although 'do' does a bit more work in carrying some extra information between the "commands"
09:13:40 <jusss> c_wraith: [exa] but the books always use 'let' to explain do-notation
09:14:03 <[exa]> which books?
09:14:13 * hackage hw-excess 0.2.2.0 - Excess  https://hackage.haskell.org/package/hw-excess-0.2.2.0 (haskellworks)
09:15:47 <unfixpoint> gobby: `type Lsit = []` `:t map :: (a->b) -> Lsit a -> Lsit b`
09:15:50 <jusss> [exa]: ghci> let x = 3; y = "!" in show x ++ y   from http://learnyouahaskell.com/a-fistful-of-monads
09:15:53 <unfixpoint> same as `type Lsit a = [a]`
09:16:34 <gobby> unfixpoint: so it's implicit in the definition
09:17:00 <gobby> in the type synonymn*
09:17:40 <unfixpoint> Yes
09:17:42 <[exa]> jusss: there's no "do" yet, they're just showing what happens if you run the monadic computation manually without having the extra Maybe around (for handling failures)
09:18:11 <[exa]> jusss: the magic comes 2 samples lower, right next to the owl picture
09:18:14 * hackage imm 1.6.0.0 - Execute arbitrary callbacks for each element of RSS/Atom feeds  https://hackage.haskell.org/package/imm-1.6.0.0 (koral)
09:21:02 <gobby> unfixpoint: Thanks
09:25:44 * hackage haskell-gi 0.22.3 - Generate Haskell bindings for GObject Introspection capable libraries  https://hackage.haskell.org/package/haskell-gi-0.22.3 (inaki)
09:25:52 <jusss> [exa]: ok, maybe I should keep do-notation in mind and use it to construct the chain then write it on the paper with bind form
09:26:41 <jusss> [exa]: I haven't implement do-notation in other languages yet, but I implemented bind
09:29:34 <[exa]> jusss: do notation is just syntactic sugar for bind, nothing more
09:46:37 <Berengal> In emacs using haskell-mode, how do I get it to work properly when working on tests in a stack project?
09:47:02 <Berengal> It not using the test parameters for the package
09:51:43 * hackage lens-regex-pcre 0.1.0.1 -   https://hackage.haskell.org/package/lens-regex-pcre-0.1.0.1 (ChrisPenner)
10:33:02 <gobby> where does yesod log its errors? $logError, $logInfo etc?
10:34:17 <gobby> I'm running a server on localhost and I'm not entirely sure where these errors are sent/written to
10:36:45 <gobby> ignore me, it's printed to the terminal 
10:57:29 <jsjolen> Does anyone here know if GHC uses dictionary passing for implementing type classes or if it's changed in some manner? I read Wadler's 'make ad-hoc polymorphism less ad hoc' and am interested in implementing it :-).
11:00:25 <cocreature> jsjolen: it does use dictionary passing but GHC tries to specialize pretty aggressively so often it can deduce which instance is used and inline the implementation instead of passing dictionaries.
11:00:55 <jsjolen> cocreature: Okay, as long as there hasn't been a revolution in `the basics' I'm happy!
11:03:47 <cocreature> jsjolen: I’m curious what you’re up to. what kind of compiler are you hacking on? :)
11:07:39 <Berengal> There's no way to implement dynamic dispatch without *some* kind of dictionary passing
11:07:44 * hackage lens-regex-pcre 0.1.1.0 -   https://hackage.haskell.org/package/lens-regex-pcre-0.1.1.0 (ChrisPenner)
11:08:52 <jsjolen> cocreature: https://github.com/stylewarning/coalton this! But really, I haven't spent enough time on it to say that I'm hacking on it ;-), maybe "perusing it"
11:09:11 <cocreature> jsjolen: nice, have fun :)
11:09:16 <ggole> Unconditional specialisation is the usual alternative, and runtime specialisation is another.
11:09:55 <jsjolen> Thanks cocreature!
11:09:55 <stylewarning> jsjolen: something like type classes would be a cool feature (:
11:10:48 <jsjolen> stylewarning: Aw crap, I didn't expect you to be here! Well, wish me luck :)
11:11:07 <stylewarning> (Jk, sort of, it’s got to be usable before adding cool new features)
11:12:14 <Berengal> You can't do dynamic dispatch with specialisation
11:12:38 <ggole> Indeed. Specialisation is the alternative to dynamic dispatch.
11:13:44 <Berengal> I don't really see them as working on quite the same axis
11:14:41 <Berengal> dynamic dispatch is just late-binding ad-hoc polymorphism, while specialisation is a way to implement parametric polymorphism (among other things)
11:15:21 <Berengal> Though it does work for early-bound ad-hoc polymorphism
11:15:26 <ggole> You can specialise on dictionaries (or in general, static values) just as well as on types.
11:15:47 <ggole> That's how some other languages (C++, Rust) compile similar features.
11:16:39 <ggole> They do incur some limitations with that approach, running into some trouble with polymorphic recursion, but it is a serious alternative.
11:16:56 <Berengal> Yes, but it's not quite the same due to the timing of the binding
11:17:39 <ggole> Not the same in what way? Operationally?
11:19:21 <Berengal> Semantically. Specialisation makes a decision right away while dynamic dispatch delays the decision as much as possible
11:20:22 <ggole> That's not a difference in semantics though?
11:20:22 <Berengal> But ad-hoc polymorphism is a weird topic if you think too hard about it
11:20:55 <ggole> (As far as I know the two approaches differ only in their operational characteristics, with the program retaining exactly the same meaning either way.)
11:21:27 <Berengal> No, not all cases of dynamic dispatch can be specialised
11:21:45 <Berengal> Those who can, yes, they are semantically the same
11:21:56 <ggole> Well, that depends on the language.
11:22:36 <ggole> Haskell probably needs dictionary passing or some equivalent.
11:22:53 <Berengal> Rust and C++ also needs dictionaries in some cases
11:23:51 <ggole> I don't think C++ templates (which I'm taking as the 'equivalent' feature here) ever result in dictionary passing
11:24:01 <Berengal> No, but C++ virtual methods do
11:24:24 <ggole> That's a different feature though.
11:24:31 <Berengal> No, that's dynamic dispatch
11:26:11 <ggole> Are you arguing that because virtual methods require dynamic dispatch, type classes require dynamic dispatch?
11:26:55 <Berengal> Yes, you can construct situations where you can't specialise a type class away
11:27:50 <Berengal> Well, with WPO you can, but you'll be specialising to ad-hoc dispatching (aka conditionals) anyway
11:29:52 <ggole> Which situations?
11:30:38 <Berengal> Existentials for one
11:32:15 <ggole> Type classes don't require existentials, though. It's quite reasonable to consider compiling languages with type classes, but without existentials.
11:32:43 <Berengal> You get into the same situation with trait objects in Rust
11:34:26 <ggole> Trait objects are pretty much first-class dictionaries, yeah
11:34:56 <ggole> But they don't prevent Rust from implementing type classes (traits) by specialisation.
11:35:09 <Berengal> No, and ghc does allow specialisation
11:35:36 <Berengal> There's specialise pragmas, and inlining can often lead to de-facto specialisation
11:35:45 <Berengal> But not every case can be specialised
11:36:20 <ggole> That's partly because GHC compiles a language that does meet the restrictions that I talked about
11:36:28 <Berengal> Everything can be done with dynamic dispatch. If you want to get philosophical and weird about it you could say the CPU is doing dynamic dispatch on op-codes
11:36:38 <ggole> Excuse me, 'doesn't'
11:37:33 <Berengal> You mean polymorphic recursion?
11:38:13 <ggole> Yeah. (And rank-n types, maybe.)
11:38:35 <Berengal> Well, you *can* have polymorphic recursion in both Rust and C++... It just requires dynamic dispatch
11:38:44 <heatsink> Rust has a restriction on which traits can be used in trait objects, which are existentials.  They call it object safety.  They need it so that they can implement traits by specialization.
11:55:14 <kostas> I have a thread which forks another thread and waits for a Message on a shared MVar. Any exception thrown at the child thread during the creation of the Message, should be rethrown at the parent thread. A solution I found is to catch any exception as SomeException, pass it through the MVar and rethrow it. Does this look like a good solution or is too ad-hoc?
11:55:54 <kostas> Can async be used for this?
11:56:54 <Rembane> kostas: Yes, use the async package for this, it will handle all the weird edge cases for you
11:57:26 <bbear> what do you think of the dart language ?
11:58:34 <kostas> Rembane: The issue is I want the forked thread to continue exist after the Message is created. Not sure if it's still possible to use async.
11:59:24 <Rembane> kostas: Why not restart the thread? 
12:00:14 * hackage butcher 1.3.2.3 - Chops a command or program invocation into digestable pieces.  https://hackage.haskell.org/package/butcher-1.3.2.3 (lspitzner)
12:00:35 <kostas> Rembane: I think I will need to have an OS bound child thread
12:01:05 <Berengal> kostas: You can use throwTo to throw an exception to a different thread, so bracket your new thread with that
12:01:38 <Berengal> If async doesn't provide what you need
12:02:46 <kostas> Berengal: Maybe I need to try this, but will I be able to later catch this kind of exception if necessary?
12:03:19 <Berengal> Yes, you can catch it like any other exception, but you have no idea where in the code it will be raised
12:04:30 <Berengal> It's an extremely poor control flow mechanism, best left as an implementation detail in some dark corner somewhere where regular, upstanding code will never have to look at it
12:05:52 <Berengal> kostas: Your original idea isn't too bad either. It's what async does internally (iirc)
12:06:41 <cocreature> definitely try to use async first, it’s fairly easy to get this wrong in various ways so better let someone else get it right for you :)
12:08:44 * hackage wuss 1.1.14 - Secure WebSocket (WSS) clients  https://hackage.haskell.org/package/wuss-1.1.14 (fozworth)
12:09:44 * hackage tasty 1.2.3 - Modern and extensible testing framework  https://hackage.haskell.org/package/tasty-1.2.3 (RomanCheplyaka)
12:22:46 <kostas> Maybe link from async is what I want.
12:37:51 <solonarv> kostas: link does sound like exactly what you want
12:39:10 <JappleAck> hey guys, where i could read about NamedWildCards extension with some code examples?
12:40:15 <JappleAck> unfortunately i can't find anything useful
12:40:52 <solonarv> well, the extension is called RecordWildCards in the actual (GHC) implementation
12:41:22 <lavalike> how about https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-NamedWildCards
12:41:25 <solonarv> the GHC manual should have an explanation and some example code
12:41:43 <solonarv> oh, don't mind me
12:41:54 <solonarv> well, pointing at the GHC manual was still correct
12:42:01 <solonarv> I just didn't know that extension existed
12:42:16 <lavalike> I only knew about RecordWildCards also!
12:50:32 <kostas> solonarv: for link there seems to be some race condition. What if the exception is thrown before I link? I haven't reproduced it yet though..
12:54:21 <kostas> ah nevermind, I don't think that's an issue.
13:02:07 <kostas> But unfortunately I can't find a way to later `unlink` the child thread.
13:06:14 <Berengal> kostas: Yes, you can't unlink with link
13:31:35 <kritzefitz> When I have a value `x :: (Foo a) => a` is there a way to turn it into `y :: Maybe b` which becomes `Just x` when `a` is at least a general as `b` and `Nothing` otherwise.
13:33:59 <lyxia> what does it mean to be more general than a type
13:35:02 * Lycurgus was hoping for a response about kinds or type classes
13:35:24 <kritzefitz> I might be using the wrong terminology, but I mean that `a` is more general than `b` when I can use a value of type `a` wherever a value of `type` b is expected.
13:36:38 <kritzefitz> But I think I got it the wrong way around.
13:37:15 <kritzefitz> Wait a second, I will write up a proper example.
13:38:22 <inotanoob> hi, does associated type families subsume functional dependencies?
13:38:46 <Berengal> Haskell doesn't have subtyping, so the only type that can be used where a `type` a is expected is precisely a
13:39:15 <[exa]> Berengal: coercions?
13:39:36 <Berengal> That's an assertion that two types are the same
13:39:52 <inotanoob> ,type coerce
13:40:10 <[exa]> :t coerce
13:40:11 <lambdabot> error:
13:40:11 <lambdabot>     • Variable not in scope: coerce
13:40:11 <lambdabot>     • Perhaps you meant ‘coerced’ (imported from Control.Lens)
13:40:16 <[exa]> f.
13:40:25 <int-e> inotanoob: not really? I mean, you can express a single functional dependency with a type family, but how would you express  class Foo a b | a -> b, b -> a?
13:40:50 <Berengal> int-e: data families
13:41:13 <lyxia> int-e: you can use two families
13:41:33 <int-e> lyxia: and where do you put the information that they're inverses of each other?
13:41:57 <monochrom> Bijective type family...
13:42:10 <monochrom> Because injective is not enough >:)
13:42:12 <lyxia> class (F a ~ b, G b ~ a) => Foo a b   ?
13:42:35 <Berengal> data families are bijective, aren't they?
13:42:41 <int-e> lyxia: eww :)
13:43:31 <Berengal> Though that's less useful now I think about it
13:45:25 <lyxia> int-e: that doesn't look worse than the fundep to me
13:45:33 <kritzefitz> So, my question is if there is some way to implement `magic` in this example: https://gitlab.com/snippets/1865033
13:45:42 <Berengal> Speaking of type families, thoughts on this? https://gist.github.com/Berengal/fabbceb842a1dc976496dc4073ec2cde
13:45:58 <int-e> lyxia: maybe not but you now have extra boilerplate to write
13:46:28 <int-e> lyxia: But I guess you do get all the inferences that functional dependencies give you that way.
13:47:19 <lyxia> I'm not that familiar with fundeps, I've always wondered whether I could be missing some corner case.
13:48:44 <int-e> Well, class Foo a b c | a b -> c means that from (Foo a b c, Foo a' b' c', a ~ a', b ~ b') one should be able to infer c ~ c'.
13:49:30 <kritzefitz> inotanoob, I think `coerce` doesn't solve my problem, because it doesn't compile when the types don't match, but I want it to return `Nothing` in that case.
13:49:54 <c_wraith> kritzefitz: that sounds like cast
13:50:09 <Berengal> kritzefitz: check out Data.Typeable
13:50:13 <inotanoob> cast :: (Typeable a, Typeable b) => a -> Maybe b
13:50:50 <int-e> lyxia: Which you can if you express that dependency as  class (F a b ~ c) => Foo a b c.
13:51:48 <int-e> lyxia: But I'm also not sure whether that covers all corner cases.
13:51:53 <bbear> is there a good atom plugin for haskell ?
13:51:56 <inotanoob> is there any application that uses fused-effects?
13:53:57 <lyxia> inotanoob: https://github.com/github/semantic
13:54:39 <Berengal> How do I use emacs haskell-mode to write tests in a stack project? The repl doesn't pick up the test-only dependencies
13:56:40 <kritzefitz> c_wraith, Berengal, inotanoob, yes it looks right at first sight, but the problem is that in my case the argument to `cast` has an ambiguous type.
13:57:14 <kritzefitz> I could fix that by making the value monomorphic, but I actually want it to stay polymorphic.
13:59:02 <Berengal> kritzefitz: add a type signature
13:59:22 <kritzefitz> But then it's monomorphic, right?
14:00:10 <Berengal> No, cast is polymorphic
14:00:12 <c_wraith> you can turn on ScopedTypeVariables and refer to a type variable from the signature
14:00:31 <Berengal> Unless you're thinking about the constraint?
14:02:09 <kritzefitz> c_wraith, yes but which variable would I use? I can't use the type of the return value, as the input to cast might actually have a different type than the output and I don't think there are any other type variables I could refer to.
14:02:49 <kritzefitz> Berengal, maybe I misunderstood your suggestion? What type would you suggest would the signature specify for the not-yet-casted value?
14:02:53 <c_wraith> If you don't know what type you're casting to, there certainly *is* a problem. :)
14:02:54 <inotanoob> don't think you can implement cast without Typeable
14:03:38 <kritzefitz> c_wraith, I know what I'm casting to, I just don't know what I'm casting from.
14:04:06 <Berengal> then (Typeable a) => a -> Maybe Foo
14:04:31 <kritzefitz> But then `a` is ambiguous, isn't it?
14:04:42 <Berengal> no
14:05:18 <inotanoob> kritzefitz: is there an example for your use case maybe it would make it clear?
14:06:07 <kritzefitz> inotanoob, give me a second to reduce my use case to something readable.
14:06:51 <Berengal> kritzefitz: If you're trying to figure out if a type is an instance of a class, that's not possible
14:07:18 <kritzefitz> Berengal, I'm afraid, that's what it boils down to, but I'm not exactly sure.
14:08:50 <Berengal> Essentially you're trying to prove that a type belongs to a class or not, and only the compiler can prove that directly
14:10:14 <Clint> https://hackage.haskell.org/package/ifcxt
14:10:37 <Berengal> You could do it with an existential, but that requires wrapping your type up in a box
14:11:11 <kritzefitz> Berengal, I don't think what I need, needs to happen at runtime, so letting the compiler figure out the types, shouldn't be problem.
14:11:49 <kritzefitz> Clint, that might be exactly what I need.
14:13:10 <Clint> it would be nice to have a method that doesn't require TH
14:58:13 * hackage hlint 2.1.23 - Source code suggestions  https://hackage.haskell.org/package/hlint-2.1.23 (NeilMitchell)
15:09:18 <glguy> Is there a 'data Some f where Some :: f a -> Some f' somewhere in the stack of dependencies related to lens?
15:42:29 <kritzefitz> inotanoob, https://gitlab.com/snippets/1865045 should sum up my actual usecase from before.
15:53:50 <lukelau> Is there a way to prevent a cabal component from being installed by default
15:54:04 <lukelau> I still want it to be buildable, but just not copied/symlinked with `cabal install`
15:56:13 * hackage tracing 0.0.2.2 - Distributed tracing  https://hackage.haskell.org/package/tracing-0.0.2.2 (mtth)
16:03:11 <mac10688> lol ok I've finally done it. I've moved my linux environment over to nixos. So now what's the usual workflow for haskell projects?
16:03:34 <mac10688> what's the best way for me to maintain different haskell versions and dependencies for each project?
16:07:33 <solonarv> lukelau: pretty easily, just create a flag like 'build-foo' and make it off by default
16:08:16 <solonarv> then you can add a 'if (!build-foo)\n  buildable: false' to that component's section in your cabal file
16:09:32 <solonarv> mac10688: I've never used nix myself, but there are Nix expressions for various GHC versions and package sets buildable with those
16:09:36 <solonarv> part of nixpkgs even
16:10:09 <mac10688> oh ok, i'll look around. thank you
16:10:12 <solonarv> and there are some tools like cabal2nix and callHackage to interface with the Haskell ecosystem more easily
16:11:14 * hackage tracing 0.0.2.3 - Distributed tracing  https://hackage.haskell.org/package/tracing-0.0.2.3 (mtth)
16:50:45 <lukelau> solonarv: thanks!
16:51:22 <Berengal> how do I get haskell-mode to load the test configuration in a stack project?
17:30:44 * hackage hedgehog-classes 0.2.0.1 - Hedgehog will eat your typeclass bugs  https://hackage.haskell.org/package/hedgehog-classes-0.2.0.1 (chessai)
18:05:13 * hackage tracing 0.0.2.4 - Distributed tracing  https://hackage.haskell.org/package/tracing-0.0.2.4 (mtth)
18:26:51 <Tentsunino> n
18:52:14 * hackage aeson-typescript 0.1.3.0 - Generate TypeScript definition files from your ADTs  https://hackage.haskell.org/package/aeson-typescript-0.1.3.0 (thomasjm)
18:54:18 <justsomeguy> What's a good, but very concise, book to learn Haskell from?
18:54:21 <justsomeguy> (The ones I'm reading are too long winded.)
18:55:42 * Lycurgus .oO( "hs for dummies"? )
18:56:37 <nisstyre> justsomeguy: I've heard "Thinking Functionally With Haskell" by Richard Bird is good
18:56:40 <nisstyre> can't vouche for it myself
18:56:56 <nisstyre> I learned from Real World Haskell which was just a huge mistake in hindsight
18:57:09 <justsomeguy> The tiger book!
18:57:49 <sm[m]> @where PIH
18:57:49 <lambdabot> "Programming in Haskell" by Graham Hutton in 2007-01-15,2016-09-01 at <http://www.cs.nott.ac.uk/~pszgmh/pih.html>
19:00:58 <justsomeguy> Awesome. Looks like both Thinking Functionally by Richard Bird and Programming in Haskell by Graham Hutton weigh in at around 300 pages.
19:01:22 <justsomeguy> ...and they both really know their stuff. :)
19:18:56 <gobby> is yesod auth hashdb reliable? It's my first time building a website and this solution seems to be the most straightforward.
19:19:24 <gobby> is it secure? What are people's thoughts on this 
19:22:44 <alx741> gobby: By Snoyman's description on how it is implemented, I trust it's pretty secure. 2^16 re-hash, salted, etc. Everything is there
19:23:33 <gobby> alx741: Is this one of the simpler ways to do authentication?
19:23:41 <gobby> vs saying using facebook or google
19:26:40 <alx741> gobby: not necessarily simpler... but sometimes required. If you can avoid it and haveusers authenticate with external services, that might be simpler and more secure. An even secure password is one that you don't store after all.
19:28:10 <alx741> haven't used facebook, google auth plugins myself, but from the outside it seems a little simpler to use. Though if the standard email-auth module fits your needs, it isn't hard either
19:29:47 <alx741> *even more secure
19:57:33 <nisstyre> the strategy I've used for authentication in the past is basically: authenticate user with OAuth authentication of user's choice (e.g. github, twitter, google), issue signed bearer token for that user, user stores token locally and passes it with every authenticated request, server decodes it and verifies it to get their username (and hence access their private data)
19:57:46 <nisstyre> rinse and repeat whenever the bearer token expires or they need to issue a new one
19:58:17 <nisstyre> downsides: depends on some kind of local storage or stateful connection
19:59:13 <nisstyre> upsides: more secure against forgery attacks than session cookies
20:01:02 <nisstyre> also if the secret used to sign the tokens gets compromised then you need to force everyone to re-auth
20:01:21 <Lycurgus> the norm is to trust authenticated clients, so having the server also have trusted clients is worth the price/downside
20:01:21 <Welkin> oh god
20:01:25 <Welkin> json web tokens again?
20:01:30 <nisstyre> Welkin: nope
20:01:32 <nisstyre> this is not JWT
20:02:10 <nisstyre> and this is the norm for building a distributed system that is secure and scales well
20:02:32 <nisstyre> that may or may not be a requirement in this case
20:06:28 <nisstyre> Welkin: people seem to be overlooking the insecure properties of session cookies
20:06:40 <nisstyre> they make attacks like CSRF possible
20:06:48 <Welkin> sure
20:07:04 <Welkin> you can use tokens to guard against that
20:07:15 <Welkin> or just don't use cookies, if you use a websocket connection
20:07:16 <nisstyre> yeah, and I agree JWT does seem to be overcomplicated and badly designed
20:07:22 <nisstyre> it's sad there's not a better spec for this
20:07:23 <Welkin> use a one-time use token to verify yourself
20:07:31 <nisstyre> that's basically what I'm talking about
20:07:33 <Welkin> JWT is only meant as a one-time use token
20:07:40 <nisstyre> but you do the initial auth using an external OAuth provider
20:07:44 <nisstyre> just to prove who the user is
20:40:51 <jusss> (Just f) . (Just g) == Just(f.g) ?
20:56:01 <iqubic> That is true.
20:56:12 <iqubic> Or acutually, not.
20:56:32 <iqubic> Because the left hand side doesn't type check.
20:56:38 <iqubic> :t (.)
20:56:39 <lambdabot> (b -> c) -> (a -> b) -> a -> c
20:57:13 <iqubic> (b -> c) /= Maybe a
21:08:43 <jle`> jusss: you might be thinking of liftA2 (.), not (.)
21:09:00 <jle`> (.) normally only works for functions
21:10:12 <jle`> alternatively there is an "overloaded" version of (.) in base that would support non-functions
21:10:28 <jle`> kind of like how fmap is like an overloaded map
21:13:44 <iqubic> :t (liftA2 (.))
21:13:45 <lambdabot> Applicative f => f (b -> c) -> f (a -> b) -> f (a -> c)
21:14:48 <jle`> jusss: liftA2 here lifts an (a -> b -> c) over a (Maybe a) and  (Maybe b) to produce a (Maybe c)
21:14:59 <jle`> it's like the binary version of fmap
21:53:44 * hackage pads-haskell 0.1.0.0 - PADS data description language for Haskell.  https://hackage.haskell.org/package/pads-haskell-0.1.0.0 (KarlCronburg)
21:56:56 <jusss> jle`: what is composeM look like?
21:58:00 <jle`> what is composeM ?
22:00:08 <slack1256> maybe Data.Functor.Compose.Compose ?
22:19:43 <jusss> jle`: composeM :: (a->m b) -> (x-> m a) -> (x -> m b)
22:20:55 <jusss> f composeM g = \x -> (g x) >>= f
22:22:26 <slack1256> @type (<=<)
22:22:28 <lambdabot> Monad m => (b -> m c) -> (a -> m b) -> a -> m c
22:22:58 <slack1256> composeM seems to be the kleisky(sic) arrow
22:23:15 <jusss> slack1256: and what this <=< pronouce ?
22:24:45 <slack1256> I've seen it called the "fish" operator
22:25:24 <slack1256> but you can also say it is the composition operator on the kleisky category
22:25:39 <jle`> jusss: does this answer the question you asked earlier, 'what is composeM look like?'
22:26:02 <jusss> slack1256: kleisli ?
22:26:53 <jusss> jle`: sort of
22:27:23 <jusss> jle`: actually I'd like to see the function definition, not type signature
22:28:47 <jle`> isn't that what you just gave?
22:29:29 <jle`> 22:20:15 | f `composeM` g = \x -> (g x) >>= f
22:29:33 <jle`> or are you looking for something more, maybe
22:30:46 <slack1256> jusss: https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.12.0.0/src/GHC-Base.html#%3D%3C%3C 
22:31:09 <slack1256> the code for (<=<)
22:31:25 <jusss> jle`: yeah, more about f and g's definitions
22:31:52 <jle`> they are parameters to a function
22:32:00 <jle`> for example, `myFunction x y = x + y`
22:32:09 <jle`> myFunction takes two inputs, x and y, and returns a value
22:32:22 <jle`> so for `composeM f g = ...`, it takes two inputs, f and g
22:32:33 <jle`> and rethrns \x -> g x >>= f
22:35:44 <jle`> x `myFunc` y = ..., is a way of defining a function using infix notation
22:35:49 <jle`> it's equivalent to myFunc x y = ....
22:44:13 * hackage webby 0.1.1 - A super-simple web server framework  https://hackage.haskell.org/package/webby-0.1.1 (AdityaManthramurthy)
23:00:58 <slack1256> Is MonadFix dependent on lazy evaluation?
23:01:30 <slack1256> To me yes, but maybe someone can iluminate why is that not the case
23:06:42 <jle`> slack1256: it depends on the instance
23:06:50 <jle`> but a lot of them do rely on knot-tying
23:07:33 <slack1256> I thought all of the depended on knot-tying (as MomentIO on reactive-banana)
23:07:58 <slack1256> on top of your head, is there an instance that doesn't use knot-tying?
23:08:52 <jle`> hm, i want to say Proxy
23:08:59 <jle`> but i can't find it on the instance list for some reason
23:10:08 <slack1256> haha Proxy it always the counter-example, lol.
23:14:25 <jusss> jle`: oh, I see
23:19:13 * hackage egison 3.8.2 - Programming language with non-linear pattern-matching against non-free data  https://hackage.haskell.org/package/egison-3.8.2 (SatoshiEgi)
23:23:31 <jusss> jle`: wait a sec, "<jle`> and rethrns \x -> g x >>= f" this f need to return a function as result?
23:23:59 <jle`> the function composeM returns a function?
23:24:00 <jle`> yes
23:24:14 <jle`> i wouldn't say it "needs" to return a function; that was probably just the intent of whoever wrote it
23:24:18 <jusss> jle`: no, just this f
23:24:20 <MarcelineVQ> not that particular f, no
23:24:33 <jle`> jusss: f has to be a function, yes
23:24:41 <jle`> but it doesn't necessarily need to return a function
23:24:43 <jusss> jle`: and f has to return a function?
23:24:55 <jle`> no, it could be something like `Int -> Maybe Bool`
23:25:05 <jle`> it just needs to be, itself, a function
23:25:13 <jusss> jle`: g >>= f,  g is a function, f is a function, f can return a normal value?
23:25:44 <jusss> jle`:  (\x -> x) >>= (\x -> x+1)  is ok?
23:25:45 <jle`> if you mean 'return' as in, the result type of f, then yeah, an example is f could have type `Int -> Maybe Bool`
23:25:59 <jle`> jusss: not quite, remember that the types of g and f are constrained
23:26:18 <jle`> f has to have type (a -> m b), for some choice of a, m, or b
23:26:22 <jle`> *a, m, and b
23:26:22 <jusss> 'cause this >>=,  Just 3 >>= \x -> Just (x+1)
23:26:32 <jle`> and g has to have type (x -> m a), for some choice of x, m, and a
23:26:53 <jusss> Just 3 here is m a,   so f return a normal value, like 3, it will not be m a
23:26:58 <jusss> monadic value
23:27:37 <jle`> yeah, it would have to return something within the same 'm' as g's return value
23:27:52 <jle`> so if g :: String -> Maybe Int, then f has to be Int -> Maybe ???
23:28:02 <jle`> it has to be Maybe
23:28:15 <jle`> or at least, it has to match whatever the output type of 'g' is
23:30:08 <bolverkr> hello, can anyone help? I am trying to run the test suite here: https://github.com/qfpl/sv/tree/master/examples . I tried cabal new-test but it just fails and I am not sure what to make of it.
23:30:14 <jusss> jle`: this return is just like other return, not the pure, unit
23:30:34 <bolverkr> I also tried opening a new-repl and running the functions directly and it just fails with exit code -4
23:30:51 <jle`> the 'return' in what i said refers to the result type of a function, which is admittedly a bit confusing
23:31:09 <jle`> for example in a function of type 'Int -> Bool', some people say that that function returns a Bool
23:31:12 <jle`> it has nothing to do with monadic return
23:31:17 <jusss> jle`: you see, g >>= f,  g and f are functions, monad is like (e->)  
23:31:17 <nshepperd_> "mfix (return . h) = return (fix h)" says to me that only Proxy doesn't rely on laziness for mfix
23:31:43 <jle`> (e->) is one monad, yes
23:31:57 <jusss> jle`: the >>='s result has to be a function, 'cause g and f are functions
23:32:50 <jle`> not necessarily
23:33:03 <jle`> the result of >>= is not necessarily a function
23:33:17 <jle`> consider, (>>=) :: Maybe Int -> (Int -> Maybe Bool) -> Maybe Bool
23:33:18 <jusss> jle`: but the monad here is (e->)
23:33:20 <jle`> in that case it returns a Maybe Bool
23:33:30 <jle`> okay, if the monad is (e ->), then yes, it returns a function
23:33:52 <jusss> that's why I wonder how f's definition
23:34:07 <jusss> 'cause g and f are functions, so f has to return a function as result
23:34:18 <jusss> so I wonder how f's definition looks like
23:34:39 <jle`> well, composeM has to be designed in a way that ignores f's definition
23:34:48 <jle`> so f could be defined in any way you like, as long as it typechecks
23:38:02 <jle`> so for m ~ (e->), we get composeM :: (a -> e -> b) -> (x -> e -> a) -> x -> e -> b
23:38:11 <jle`> as long as f has type (a -> e -> b), you are good
23:39:14 <kaol> Why haven't I used type holes before. What a lovely feature.
23:40:34 <jusss> jle`: ok
