00:13:31 <jsomedon> so I am trying to write (a->) as an Applicatives, just want to check with you guys that I got it correct, so my pure and <*> are:
00:13:35 <jsomedon> pure = const
00:13:45 <jsomedon> f <*> g = \x->((f x) (g x))
00:14:25 <EvanR> :t \x -> (f x) (g x)
00:14:26 <lambdabot> error:
00:14:26 <lambdabot>     • Could not deduce (Show t0) arising from a use of ‘f’
00:14:26 <lambdabot>       from the context: (Show t, FromExpr t1)
00:14:46 <EvanR> looks right in any case.
00:14:56 <EvanR> <*> is the S combinator
00:15:30 <EvanR> :t \f g x -> f x (g x)
00:15:32 <lambdabot> (t1 -> t2 -> t3) -> (t1 -> t2) -> t1 -> t3
00:15:59 <jsomedon> uhm ok
00:16:40 <EvanR> if F = (t1->), that says F (t2 -> t3) -> F t2 -> F t3
00:16:54 <jsomedon> yes by F I mean that
00:17:52 <jsomedon> uhm is there any other way to "simply" definition of <*> I have? I mean like `fmap = .` and `pure = const`
00:18:18 <EvanR> i'm guessing it's going to be ugly AF
00:18:26 <EvanR> @pl \f g x -> f x (g x)
00:18:26 <lambdabot> ap
00:18:36 <EvanR> lol
00:18:40 <MarcelineVQ> hehe that doesn't count :>
00:18:58 <jsomedon> what's this @pl
00:19:10 <EvanR> @pl \f g x -> f x x (g x)
00:19:10 <lambdabot> ap . join
00:19:21 <EvanR> @pl \a b c -> c b a
00:19:21 <lambdabot> flip (flip . flip id)
00:19:33 <EvanR> pointless form, no-variables form
00:19:44 <jsomedon> ha interesting
00:19:59 <jsomedon> is it like, the compiler automatically fitgure out that for me?
00:20:11 <EvanR> the bot figured it out
00:20:14 <jsomedon> :t ap
00:20:16 <lambdabot> Monad m => m (a -> b) -> m a -> m b
00:20:23 <jsomedon> uh
00:20:33 <EvanR> ap is the monad-constrained <*>
00:20:40 <EvanR> it predates Applicative
00:20:46 <jsomedon> so can I do same thing as this @pl thing in my ghci repl?
00:21:01 <jsomedon> oh
00:21:48 <jsomedon> didn't look into monad yet, was about to work on some exercises of Applicatives before moving onto next chapter
00:22:49 <Rembane> You can do those transformations in your head too. 
00:23:03 <jsomedon> haha yeah
00:23:26 <jsomedon> I just wondered if this is actually supported directly by the ghci
00:23:33 <Rembane> I have a tendency to program in pointfree/pointless style which gives my colleagues something to do and point out in code reviews.
00:23:57 <jsomedon> haha
00:24:12 <Rembane> I haven't seen any direct support for it in ghci, but I might've missed something.
00:24:42 <EvanR> https://hackage.haskell.org/package/pointfree
00:25:13 <Rembane> But you can talk to lambdabot directly and use @pl as much as you like without bothering the rest of the channel. 
00:25:41 <Welkin> monad is more fundamental than applicative
00:25:50 <EvanR> after the apocalypse and lambdabot is no longer with us you can use the command line version
00:25:59 <jsomedon> I would really appreciate if I have a colleague like you
00:26:19 <tdammers> Welkin: in what sense? the fact that all monads are applicatives, but not the other way around, suggests the exact opposite
00:27:04 <Welkin> monad can replace applicative, and functor
00:27:58 <tdammers> sure
00:28:14 <tdammers> but that's the same kind of "fundamental" as untyped languages replacing typed ones
00:28:25 <EvanR> and ArrowApply can replace all of them?
00:28:36 <tdammers> monads can do everything functors and applicatives can, and then some
00:28:52 <jsomedon> uh, to be clear, I am still learning haskell, it's just how the book I am using ordered topics this way
00:29:00 <tdammers> which one of them is more "fundamental" depends on your definition of "fundamental", i.e., from which end you start
00:29:08 <EvanR> jsomedon: the ordering seems right
00:29:12 <EvanR> to me
00:30:07 <tdammers> anyway, yes, for learning purposes, I'm inclined to say go Functor -> Applicative -> Monad, not the other way around
00:30:12 <EvanR> Welkin's version of fundamental means quaternions are fundamental, complex, reals, rationals, integers are more derived notions
00:30:55 <EvanR> weve been doing it backwards this whole time
00:31:19 <EvanR> God created quaternions, all else is the filtering of man
00:31:27 <tdammers> EvanR: yes, indeed. And you can kind of look at it that way - a real number is a trivial case of a complex number (one where the imaginary part is 0)
00:31:36 <tdammers> but it's not very helpful in understanding those concepts
00:31:44 <tdammers> because they move from abstract to concrete
00:32:11 <tdammers> natural numbers appear fairly clearly in daily life, we count things all the time. most people have never even heard of quaternions though.
00:33:28 <EvanR> of course what i said is the exact opposite of functor and monad
00:33:48 <EvanR> you have functors, and only some of them have a chance of being a monad
00:34:22 <EvanR> you have semigroups and only some of them can be a monoid
00:34:34 <EvanR> so magmas are fundamental
00:34:47 <Welkin> you use monads all day every day in haskell
00:34:51 <Rembane> What's a magma? 
00:34:55 <Welkin> not so with applicatives or even plain functors
00:35:06 <EvanR> a type with an associative operator
00:35:12 <Rembane> EvanR: Oh. Nice! 
00:35:24 <Rembane> Welkin: We do not write the same kind of Haskell I'm afraid, one of my best tools is fmap. 
00:35:46 <EvanR> oh, it doesn't even need to be associative
00:38:19 <heatsink> EvanR: Linear algebra sort of introduces concepts that way, though.
00:38:37 <heatsink> They teach general matrices first, then interesting special cases such as orthogonal matrices
00:38:52 <heatsink> Which is kind of like teaching complex numbers and then pointing out that the reals are an interesting subset
00:39:15 <EvanR> in fact complex numbers are special kind of matrices :P
00:39:30 <heatsink> indeed
00:39:57 <EvanR> matrices are fundamental (cue a throng of math people groaning)
00:40:32 * Rembane throws an APL at EvanR 
00:40:53 <EvanR> i can't help it, i just think in matrices
00:41:33 <Rembane> You do? How did you end up like that? :)
00:42:00 <EvanR> this is a play on OOP but i could imagine it happening various ways
00:44:18 <ski> matrices are just linear transformations between free vector spaces
00:46:59 <tdammers> Welkin: a beginner haskeller uses lots and lots of monads and functors all the time, but that's not the point; until they encounter the explicit abstractions, they are really just using lists, maybes, eithers, IO, etc.
00:47:23 <Rembane> EvanR: ^^
00:47:25 <tdammers> so you can fmap over a Maybe, and you can fmap over a list; that's like how you can perform addition on Ints and Doubles alike
00:47:42 <tdammers> you don't need to know about the Num typeclass to use the addition operator
00:47:48 <tdammers> that insight comes later
00:47:59 <tdammers> *after* you have developed the intuition that + works on both
00:48:08 <tdammers> and you can do the same for Functor and Monad
00:48:21 <tdammers> fmap works on all sorts of things. >>= works on all sorts of things
00:50:25 <ski> (even after separately defining particular versions on lists, `Maybe's, &c.)
01:22:12 <tdammers> yep
01:22:49 <tdammers> so from "fmap works on all sorts of things" and ">>= and return work on all sorts of things", you can develop an intuition for Functor and Monad (and similarly for Applicative)
01:23:01 <tdammers> and *then* you realize that they are related
01:23:26 <tdammers> that Functor operations can be expressed in terms of Applicative operations, and Applicative in terms of Monad
01:29:05 <jsomedon> so <$> is another name for fmap??
01:29:22 <kaol> Correct.
01:29:30 <jsomedon> k
01:31:02 <dibblego> also, it has to be, by the type
01:41:34 <jsomedon> so I am reviewing functor laws and applicative laws, and my intutition on these laws is that, my implementations(the pure the fmp the <*>) should not touch the structure when they are fmaping or <*>-applying over values "packed in" the structure?
01:42:17 <jsomedon> so really these laws are about leaving structures untouched and just unpack those values, do some work on them, then pack them back?
01:43:03 <tdammers> dibblego: technically "same type" doesn't automatically guarantee "same thing", though in this case it holds due to the limitations of the Functor typeclass and the Functor - Monad superclass relationship
01:43:16 <tdammers> :t (+)
01:43:18 <lambdabot> Num a => a -> a -> a
01:43:20 <tdammers> :t (-)
01:43:21 <lambdabot> Num a => a -> a -> a
01:43:26 <tdammers> same type, different thing ;)
01:44:06 <dibblego> No they are different types. All things with that type are fmap
01:46:29 <dibblego> Sorry I misread, yes they are the same type. Not all types have only one inhabitant. The type of fmap does.
01:47:30 <tdammers> yeah. it's obvious once you understand what the type of fmap suggests, and how many ways there are to implement it for any given instance
01:47:39 <tdammers> :t fmap
01:47:41 <lambdabot> Functor f => (a -> b) -> f a -> f b
01:48:07 <tdammers> the only thing you can do here is "apply the given function 'inside the functor'"
01:48:12 <EvanR> jsomedon: fmap can't change structure, true
01:48:16 <tdammers> well, or you can bottom out
01:48:57 <tdammers> because the only way to gain a `b` is to apply the first argument to an `a`, and the only way to gain an `a` is to 'look inside the functor'
01:49:27 <dibblego> fast and loose reasoning is morally correct
01:49:31 <tdammers> yes
01:49:45 <tdammers> which is why I said "the only thing you can do here"
01:50:09 <tdammers> although you can write unlawful instances at least for some types
01:50:23 <tdammers> e.g. instance Functor Maybe where fmap f a = Nothing
01:50:36 <tdammers> it fits the type, but it's not actually fmap
01:51:16 <EvanR> jsomedon: you might enjoy this alternative equivalent version of Applicative,  unit :: f (), combine :: f a -> f b -> f (a,b) with some monoid-like laws left as exercise for the reader :P
01:51:56 <jsomedon> EvanR: hmm what's this
01:52:06 <EvanR> Applicative in a different form
01:52:24 <jsomedon> EvanR: so you mean instead of pure and <*>, if I defined such unit and combine, it's also an Applicatives?
01:52:29 <EvanR> yes
01:52:44 <EvanR> can do the same stuff. You can prove it to yourself by implement each with the other
01:52:57 <jsomedon> EvanR: ha let me try that
01:53:02 <EvanR> once you have the unit and combine laws, also prove the laws of the other with each
01:53:24 <jsomedon> so the type of unit :: f () ???
01:53:35 <EvanR> yeah
01:53:41 <jsomedon> uhmm waht is this f ()?
01:53:53 <sim590> How do I use newStdGen with randomR. Whatever I do in GHCI, I can't use it. It outputs all sorts of messages impossible to understand.
01:53:57 <jsomedon> f is Functor?
01:53:58 <merijn> jsomedon: That depends on the Functor :p
01:53:59 <EvanR> :t [(),(),(),()]
01:54:00 <lambdabot> [()]
01:54:04 <EvanR> f is a functor
01:54:09 <merijn> :t newStdGen
01:54:10 <lambdabot> IO StdGen
01:54:21 <merijn> sim590: How are you trying to use it in ghci?
01:54:36 <merijn> :t randoms
01:54:37 <lambdabot> (Random a, RandomGen g) => g -> [a]
01:54:37 <jsomedon> ok f is a functor, and () is, I think I saw similar type notation in IO ()
01:54:49 <EvanR> @src ()
01:54:49 <lambdabot> data () = ()
01:54:54 <EvanR> the unit type
01:55:03 <merijn> % take 10 . randoms <$> newStdGen :: IO [Double]
01:55:04 <yahb> merijn: [0.7366226946120807,0.6409428956810069,0.4155287315353686,0.5729245522685379,5.276972291052551e-2,0.4314654188711897,0.41888508818123493,0.17208081712790735,0.8335239026540311,0.18844285445558928]
01:55:05 <jsomedon> huh never seen that before..
01:55:13 <EvanR> p. important
01:55:20 <sim590> merijn: newStdGen is in IO, so I use >>= like this: newStdGen >>= randomR (1,5) but it doesn't work.
01:55:33 <merijn> :t randomR
01:55:34 <lambdabot> (Random a, RandomGen g) => (a, a) -> g -> (a, g)
01:55:51 <EvanR> it's just a type with 1 boring element
01:55:55 <merijn> sim590: Can you be a bit more specific about doesn't work? :)
01:55:58 <sim590> even though I put return $ randomR (1,5) it doesn't work.
01:56:07 <merijn> jsomedon: You can think of () as equivalent to "data Unit = Unit"
01:56:15 <jsomedon> merijn: ah that helps
01:56:35 <sim590> I get uncomprehensible things like this: https://paste.debian.net/1104664/
01:56:38 <EvanR> () is special syntax, supposed to suggest to you "zero-tuple"
01:56:39 <merijn> jsomedon: It's, basically the most boring type in existence, and therefore useful to indicate things are boring :)
01:56:58 <merijn> jsomedon: Such as "the value returned by print" because we usually don't care
01:56:59 <merijn> :t print
01:57:01 <lambdabot> Show a => a -> IO ()
01:57:18 <jsomedon> alright
01:57:27 <merijn> sim590: Oh, yeah, you don't want >>= there
01:57:31 <merijn> :t (>>=)
01:57:32 <lambdabot> Monad m => m a -> (a -> m b) -> m b
01:57:48 <merijn> sim590: Note that the right hand side function of >>= must return something "m b" (IO in this case)
01:57:52 <merijn> :t randomR
01:57:53 <lambdabot> (Random a, RandomGen g) => (a, a) -> g -> (a, g)
01:58:02 <sim590> hence return I put, no?
01:58:03 <int-e> :t newStdGen >>= return . randomR (1, 5)
01:58:04 <lambdabot> (Random a, Num a) => IO (a, StdGen)
01:58:08 <jsomedon> so say it's for Maybe, unit = Just ()
01:58:24 <merijn> sim590: "x >>= return . foo" works, but that's just "fmap foo x" :)
01:58:28 <sim590> god damn
01:58:44 <jsomedon> combine ... what is that notation f (a,b)
01:58:59 <sim590> I've been stripping my hair off for a )!(@)! dot
01:59:00 <merijn> sim590: The problem is that "newStdGen >>= return $ randomR (1, 5)" parses as "(newStdGen >>= return) $ (randomR (1,5))"
01:59:19 <int-e> and x >>= return = x ... is pretty useless
01:59:23 <EvanR> (a,b) is the product type of a and b, pairs of 1 a and 1 b. If you don't know () and (a,b) yet maybe don't do my exercise yet
01:59:26 <merijn> int-e: I just mentioned that ;)
01:59:41 <merijn> sim590: Try: "randomR (1, 5) <$> newStdGen" :)
01:59:42 <jsomedon> EvanR: so it's another type
01:59:49 <merijn> % randomR (1, 5) <$> newStdGen
01:59:50 <yahb> merijn: (2,1615949077 1655798172)
02:00:09 <jsomedon> EvanR: something like data Product a b = Product a b ?
02:00:14 <EvanR> yes
02:00:33 <EvanR> @src (,)
02:00:33 <lambdabot> Source not found. It can only be attributed to human error.
02:00:43 <sim590> merijn: thanks for your assitance.
02:00:54 <merijn> sim590: You can also use randomRs to generate a lazy infinite list of random values (which can be easier to work with)
02:01:01 <jsomedon> ok whenever I see parenthesis is used in some ways I don't recognize I panic haha
02:01:11 <EvanR> yep there's a few of those
02:01:14 <merijn> % randomRs (1, 5) <$> newStdGen
02:01:20 <yahb> merijn: [1,5,2,3,3,2,2,4,2,2,1,3,1,5,1,1,4,5,3,3,5,2,2,5,4,1,4,5,4,4,4,4,5,4,4,2,2,1,1,1,5,2,1,5,4,1,4,5,1,1,2,1,4,1,3,4,1,5,5,5,3,2,2,5,5,2,1,2,3,4,5,2,5,1,3,3,2,5,1,3,1,5,3,3,2,4,4,4,4,3,5,5,5,1,4,4,4,4,1,5,4,5,3,4,3,5,4,3,5,5,1,1,2,3,4,1,2,2,5,3,3,2,2,3,1,3,5,3,4,2,5,4,2,2,2,4,5,2,5,4,5,3,4,2,5,5,5,2,1,4,4,5,3,5,2,4,4,3,2,1,1,4,4,4,4,4,2,1,2,5,2,2,3,3,5,3,2,2,3,3,4,1,2,4,1,3,5,5,3,1,1,4,1,2,4,4,5,5,4,2
02:01:38 <EvanR> *that's so random*
02:03:06 <int-e> @dice d5+d5+d5+d5+d5+d5
02:03:07 <lambdabot> int-e: 4 + 2 + 2 + 5 + 2 + 5 => 20
02:03:09 <jsomedon> so for Maybe, combine should only give me Just of Product when both args are Just value right?
02:03:43 <EvanR> that's all you can do 
02:03:59 <jsomedon> then
02:04:32 <jsomedon> combine (Just a) (Just b) = Just (a,b)
02:04:46 <jsomedon> combine _ _ = Nothing?
02:04:49 <jsomedon> liek this?
02:04:54 <EvanR> sure
02:05:03 <jsomedon> ok now i have code
02:05:13 <jsomedon> I need to do, what? prove sometthing
02:05:31 <EvanR> implement pure and <*> in terms of unit and combine
02:05:36 <jsomedon> oh
02:05:45 <EvanR> prove the applicative laws in terms of unit and combine laws
02:06:31 <jsomedon> so this unit is like empty box while pure is at least a box with one stuff..
02:08:33 <EvanR> pure x not only has stuff, it also "does nothing" (similar to a monoids unit element)
02:08:40 <merijn> There's no builder for Text?
02:10:04 <jsomedon> pure a = ... -- how to put `a` in to `f ()` so I get `f a`??
02:10:31 <jsomedon> also, that Product type
02:11:00 <EvanR> yeah you somehow need an f () -> f a
02:11:44 <jsomedon> if I "Multiply" (if the Product type supports such mutiplication function) a Unit data with some other value what do I get? I assueme I get that value back??)
02:11:57 <koz_> merijn: Does this one not count? http://hackage.haskell.org/package/text-builder
02:12:01 <EvanR> multiply means "pair up" here
02:13:06 <merijn> koz_: I just meant that ByteString has a builder inside the library, not sure how tested that library is
02:13:06 <jsomedon> so if I pair up a () and, say, 100, in code that wouldbe ((),100)?
02:13:10 <EvanR> yes
02:13:27 <koz_> merijn: Ah, OK. Yeah, that is an odd omission from text, I agree.
02:13:37 <jsomedon> well I thought I could make use of combine adn unit to get this f a..
02:13:56 <jsomedon> but that ((),someValue) thing doesn't look like what i am lookign for
02:14:39 <EvanR> follow the types
02:16:38 <EvanR> pure :: Functor f => a -> f a
02:17:00 * hackage irc-conduit 0.3.0.4 - Streaming IRC message library using conduits.  https://hackage.haskell.org/package/irc-conduit-0.3.0.4 (barrucadu)
02:17:51 <sim590> merijn: yes, but I really just want two numbers. I have made a whole exercise in a book about this but I forgot everything. I don't get why this https://paste.debian.net/1104666/ makes these errors: https://paste.debian.net/1104667/. I'm lost. Even though I have practice monads and transforms already, I just don't know how to do anything other than the exercises in my book. Everything is complicated.
02:18:37 <ski> @quote follow.the.types
02:18:37 <lambdabot> NeilDeGrasseTypson says: "Follow the types, wherever they lead you."
02:18:52 * ski . o O ( "Follow the types where they lead. Follow the types where they lead. Follow, follow, follow, follow -- follow the types where they lead." )
02:19:00 * hackage irc-client 1.1.1.1 - An IRC client library.  https://hackage.haskell.org/package/irc-client-1.1.1.1 (barrucadu)
02:19:38 <EvanR> this channel is not a cult i swear
02:23:56 <jsomedon> last time I hear that saying (well actually that was the first time I hear that saying as well) was when monochrom gave that weird functor puzzle like several weeks ago
02:24:32 <jsomedon> and that puzzle was really painful to solve
02:26:17 <lavalike> now you're obliged to paste it!
02:26:20 <merijn> sim590: You're close, but randomR's result is not of type StateT
02:26:47 <merijn> :t randomR (1, 5) `asAppliedTo`
02:26:49 <lambdabot> error:
02:26:49 <lambdabot>     parse error (possibly incorrect indentation or mismatched brackets)
02:26:50 <merijn> eh
02:26:56 <merijn> :t randomR (1, 5) undefined
02:26:57 <lambdabot> (Random a, RandomGen g, Num a) => (a, g)
02:27:05 <EvanR> 1 weird functor puzzle you won't believe
02:27:08 <merijn> :t randomR (1, 5)
02:27:09 <lambdabot> (Random a, RandomGen g, Num a) => g -> (a, g)
02:27:30 <EvanR> category theorists hate it
02:27:36 <merijn> sim590: You have correctly spotted that that type is closely related to StateT, however it isn't a StateT yet
02:28:01 <merijn> :t StateT
02:28:03 <lambdabot> (s -> m (a, s)) -> StateT s m a
02:28:46 <merijn> You probably don't even need "StateT StdGen IO a", probably nicer to use "State StdGen a" and push the newStdGen to the outside
02:29:26 <merijn> :t state -- I think I wanted this
02:29:27 <lambdabot> MonadState s m => (s -> (a, s)) -> m a
02:29:39 <merijn> ugh, mtl ruins things again
02:30:14 * ski idly tries to recall whether the puzzle was `Cont o'
02:31:17 <merijn> :t state (randomR (1,5)) :: State StdGen Int
02:31:18 <lambdabot> State StdGen Int
02:31:25 <ski> merijn : hmm .. now i'm wondering whether a pattern synonym could save the day
02:31:47 <merijn> ski: There's a state in transformers, it's just that lambdabot has mtl imported
02:32:14 <jsomedon> EvanR: so this Product type, any functions other than paringup I can call over such types?
02:32:26 <merijn> sim590: Consider writing your code as "State StdGen Int" and pushing the newStdGen way outside
02:32:40 <sim590> merijn: I changed to `State StdGen Int` and I use `getStdGen` instead, but I'm still not there yet..
02:33:03 <jsomedon> EvanR: also to double check, I should never call Maybe's data cotr direclty right?
02:33:07 <EvanR> jsomedon: fst, snd, which just serve the same purpose as pattern match
02:33:13 <jsomedon> oh
02:33:23 <sim590> meh getStdGen is also IO.
02:33:28 <merijn> sim590: So you'd have "myCode :: State StdGen Foo" and "main :: IO (); main = do { g <- newStdGen; return (runState myCode g) }"
02:33:34 <EvanR> Maybe isn't really involved 
02:33:51 <EvanR> this is supposed to work for all f 
02:34:30 <merijn> sim590: The entire point of "State StdGen" is to write your code with the assumption "I'll get a stdgen at some point from someone" and keeping the logic of "what to do with it" separate from "how you get it"
02:34:32 <ski> % :t MkState
02:34:32 <yahb> ski: (s -> (a, s)) -> State s a
02:34:37 <ski> % :t \case MkState f -> f
02:34:37 <yahb> ski: State s a -> s -> (a, s)
02:35:34 <jsomedon> ah right, was too focused on Maybe hah
02:36:26 <ski> > take 10 (randoms (mkStdGen 10891))
02:36:28 <lambdabot>  [-8397568277604307620,-7565340792708659456,8918473093576782337,-473843896127...
02:36:40 <ski> > take 10 (randomRs (0,9) (mkStdGen 10891))
02:36:42 <lambdabot>  [5,7,4,4,9,0,5,4,9,8]
02:37:10 <merijn> sim590: Maybe this sketch helps (warning, I haven't tested or even typechecked this and the imports are missing): https://paste.debian.net/1104671/
02:37:28 <ski> sim590 : generally, you want `newStdGen' over `getStdGen'
02:38:01 <merijn> sim590: Note that that the "random" code doesn't have to know about IO at all in this example
02:39:54 <ski> merijn : perhaps `mtl' should have a module with those ?
02:41:09 <k0ral> Hello
02:41:17 <ski> hello k0ral
02:42:20 <sim590> Ok. I'm remembering some things now. 
02:42:42 <k0ral> is there a practical way to manipulate Data.Natural that doesn't involve a lot of fromInteger boilerplate each time it is combined with Int ?
02:44:16 <k0ral> e.g. (1 :: Int) + (2 :: Natural) fails to compile
02:45:28 <jsomedon> EvanR: pure f = \f -> (snd (combine unit f))  ??
02:45:44 <jsomedon> EvanR: ah wait.. 
02:45:56 <EvanR> doesn't seem to type check
02:46:48 <ski> suspicious shadowing stares
02:47:19 <EvanR> rename pure f to pure x and try again
02:52:07 <ski> k0ral : probably not
02:52:22 * ski idly ponders the coherence problem
02:52:34 <merijn> k0ral: Well, what should that do?
02:52:52 <EvanR> everywhere you need Int, make a version that takes Natural
02:52:59 <EvanR> assuming that makes sense
02:53:06 <EvanR> make wrappers
02:53:26 <EvanR> or more likely, this is why no one uses Natural
02:53:38 <EvanR> jsomedon: heads up i need to go to sleep
02:53:47 <k0ral> well, (+) is defined as part of Num, which demands that both operands are of the same type; I wish there were a distinct typeclass that makes it possible to implement a distinct (<+>) for any pair of operand types
02:53:48 <EvanR> glhf!
02:54:17 <jsomedon> EvanR: ok have good sleep :-)
02:54:44 * ski . o O ( `min :: Natural -> Natural -> Natural & Integer -> Natural -> Natural & Natural -> Integer -> Natural & Integer -> Integer -> Integer' )
02:55:30 <ski> (er .. rather, s/Integer/NaturalInf/. not sure why i wrote `Integer')
02:58:17 <k0ral> class CanBeAdded a b c where (<+>) :: a -> b -> c; instance CanBeAdded Int Natural Int where ...
02:58:41 <k0ral> could there be useful laws with such class ?
02:58:49 * ski was just about to ask about that
02:59:06 <ski> (also, any FDs ?)
02:59:55 <merijn> k0ral: Many people have tried to define classes like that, none have seen mass adoption
03:02:34 <k0ral> merijn: ok, I guess that's the kind of answer I was looking for; now I know I should just drop Natural unless I am in a domain where there is absolutely no Int at all
03:05:25 <k0ral> now that I think about it, it would be great to have a reference "documentation" about areas in Haskell that have been extensively explored by the community but failed to produce any interesting pattern/abstraction
03:08:24 <k0ral> something like the 100 greatest unproven mathematical conjectures, but for Haskell :)
03:12:40 <merijn> k0ral: Oh, there've been plenty of interesting patterns/abstractions there and people building entire algebra based typeclass hierarchies
03:13:00 <merijn> k0ral: It's just that "in the real world" they involve more hassle than working around the current Num hierarchy does
03:15:54 <k0ral> I guess I meant "interesting from an engineer's perspective" rather than "interesting from a theoretical perspective" :)
03:17:56 * k0ral is discovering numeric-prelude, just for the viewing pleasure
03:19:43 <maralorn> Isn‘t CanBeAdded a bit similar to Category?
03:20:20 <ski> howso ?
03:21:27 <maralorn> If a and b are Types of morphisms and c is the Type of their composition?
03:24:27 <maralorn> Well, actually CanBeAdded is much more general.
03:28:22 <merijn> If anyone's bored, I've got a good puzzle I need to solve but don't have time for: Given N columns and their average and maximum widths and a max total size, determine the ideal assignment of columns widths so that the largest number of columns align properly
03:32:06 <MarcelineVQ> hey, someone already invented the knapsack problem :<
03:34:20 <merijn> MarcelineVQ: Good, than someone has also solved it already :p
03:35:41 <MarcelineVQ> does align properly imply that each n has a minimimum width too?
03:36:19 <ski> maralorn : so, you're saying `a' and `b' should determine `c' ?
03:36:52 <merijn> MarcelineVQ: Basically, I'm padding all columns to a computed width, which is (ideally) equal to the max width (then everything is always straight and aligned), but obviously if that doens't fit, I want to pad less so that MOST columns fit (at the cost of the max ones ruining the alignment)
03:37:13 <merijn> MarcelineVQ: So I'm using the average width as a minimum to pad to
03:51:59 <__monty__> merijn: Since you talk about fit it sounds like you already have a hard maximum in mind. So why not pad to that, not touching longer lines?
03:53:30 * hackage morpheus-graphql 0.3.1 - Morpheus GraphQL  https://hackage.haskell.org/package/morpheus-graphql-0.3.1 (nalchevanidze)
03:54:42 <maralorn> ski: I’m not sure, if I am saying that. In general the instance implementation determines c. The longer I think about this the more I reach the Conclusion that CanBeAdded is something like "the generic operator".
03:54:43 <merijn> __monty__: Say I have N columns with (max) widths w_0, w_1,...,w_n, how do I pad each column such that the largest number of colums align while staying within my total max width W
03:55:25 <maralorn> But being independently polymorphic in the return type looks like a constraint solving nightmare.
03:57:16 <__monty__> merijn: Ah, table alignment. Ok, that's indeed quite a different thing.
03:59:12 <merijn> __monty__: I mean, I'm sure someone has solved this before, I just don't know how to google for it >.>
04:10:52 <__monty__> merijn: Closest thing is bin packaging but where you have multiple sequences of bins whose size interdepends but also the objects are kinda liquid... Yeah, that's not gonna help googling.
04:37:33 <merijn> It has been 0 minutes since I last was annoyed by GHC's lack of cyclic import support
04:37:37 * merijn sighs
04:42:53 <jsomedon> I would gladly take any puzzles about Applicatives
04:43:08 <jsomedon> or functor
04:44:43 <ski> i suppose you already saw Typeclassopedia ?
04:46:06 <jsomedon> ski : I just googled it, the one on wiki.haskell.org?
04:47:07 <ski> @where Typeclassopedia
04:47:07 <lambdabot> http://www.haskell.org/haskellwiki/Typeclassopedia
04:47:12 <ski> looks like it
04:47:50 <ski> @where AAM
04:47:50 <lambdabot> http://www.haskell.org/haskellwiki/All_About_Monads
04:48:00 <ski> might also be fun to take a look at, at some point
04:48:41 <jsomedon> wow it's good
04:52:22 <maerwald> merijn: there's a solution :P
04:52:44 <merijn> maerwald: Dump everything in a single module? >.>
04:52:55 <maerwald> boot files
04:53:12 <merijn> Despite 10 attempts I've *never* managed to get boot files to work
04:53:31 <maerwald> how's that
04:53:42 <merijn> So as far as I'm concerned boot files are a fairy tale people tell frustrated Haskell developers to make them calm down
04:54:07 <merijn> maerwald: I always just got endless cryptic errors no matter how much I fiddled with them
04:54:20 <merijn> I've also never seen a working setup of them in a real package
04:54:25 <maerwald> works for me https://git.io/JeCt8
04:54:30 <Fairy> I don't like boots :(
04:57:53 <macroprep> does anyone know how to implement a Vector space in a programming language
04:59:30 <[exa]> that's an extremely abstract question
04:59:55 <[exa]> but yes, obviously: https://hackage.haskell.org/package/vector-space-0.16/docs/Data-VectorSpace.html
05:00:09 <dibblego> jsomedon: https://github.com/data61/fp-course/blob/master/src/Course/Applicative.hs
05:01:34 <HKei> Which vector space? There are lots of vector spaces that are easy to implement, like R^n vectors of polynomials
05:01:47 <HKei> *or* polynomials I mean
05:02:13 <macroprep> oh
05:02:36 <macroprep> one that would allow me to implement a Hilbert space
05:08:23 <jsomedon> dibblego: ah nice!
05:08:38 <macroprep> HKei: 
05:10:38 <pavonia> "AdditiveGroup v => VectorSpace v"  Heh, I read that as AddictiveGroup
05:11:56 <HKei> macroprep: Again, whether or not you can "implement" one depends not so much on the programming language but whether or not you can write down an implementation
05:12:15 <macroprep> as i already have Vector's implemented, but i dont know how to go about implementing a Vector space
05:12:24 <HKei> Haskell can give you tools for writing abstractions like "if T is a vector space, then this equation holds for T"
05:13:17 <maralorn> macroprep: Well you can define a type class for vector space and a type class for Hilbert space.
05:13:20 <HKei> macroprep: What do you mean you have vectors implemented but not a vector space?
05:13:25 <macroprep> all i know is that it contains some sort of array of vectors and that it MUST contain a zero vector
05:13:58 <macroprep> as well as a subspace
05:14:20 <maralorn> macroprep: Well you need to define scalar multiplication and addition. (and they need to be lawful.)
05:14:46 <maralorn> But there are multiple implementations of finite dimensional vector spaces on hackage.
05:15:07 <HKei> I'm still unclear if you're trying to write an implementation for a particular vector space or if you're asking about how to abstract over vector spaces
05:15:10 <maralorn> I am sure some of them also come with a skalarproduct.
05:15:28 <HKei> these are very different problems, although solving one may make it easier to conceptualise a solution for the other
05:15:32 <macroprep> eg excluding all "functions", i do not know how to correctly structure the vector space such that it would operate as expected for a standard vector space
05:16:59 <macroprep> HKei: what would be the most simplest type of vector space?
05:17:01 <maralorn> macroprep: Excluding all "functions" there is nothing to say about a vector space at all. (If by "functions" you mean scalar multiplication and addition.)
05:17:18 <macroprep> maralorn: yea
05:19:04 <maralorn> macroprep: I fear this is not the answer you are looking for, but I am kinda obliged to tell you that the simplest vector space is the set with one element. { 0 }.
05:20:19 <macroprep> maralorn: seems simple, how would i construct it
05:20:51 <macroprep> eg what would the internal structure of it look like
05:20:51 * ski idly wonders why macroprep is thinking in terms of arrays of vectors (including a zero vector)
05:20:55 <HKei> `data TrivialVectorSpace = TrivialVectorSpace`
05:20:58 <HKei> you're done
05:21:22 <merijn> ski: Because he thinks "vector spaces" are a single specific thing, rather than an abstraction describing lots of different things
05:21:30 <maralorn> I would say: data TrivialVectorSpace = Null or something. 
05:21:46 <HKei> same difference
05:21:57 <maralorn> scale alpha Null = Null
05:22:03 <maralorn> add Null Null = Null
05:22:36 <maralorn> Exercise: Proof all 8 vector space axioms.^^
05:22:39 <HKei> you can turn it into a hilbert space too,
05:22:50 <HKei> scalarProduct Null Null = 0
05:24:04 <ski> macroprep : i'm still not sure what you meant by "and how would i go about implementing it, MutableList of elements?","i want to use it for a Hibert space", in ##math, two days ago, btw ..
05:24:37 <ski> (and i don't think i got an answer to "are you sure you're not confusing vector spaces with individual vectors inside them ?", either)
05:25:46 <maralorn> Yeah I think at this point we really need to know. What you are really trying to accomplish before we throw more abstract nonsense at you.
05:26:33 <macroprep> maralorn: i want to build a quantum turing machine
05:26:55 <macroprep> in which, from wiki, "The set of states Q {\displaystyle Q} Q is replaced by a Hilbert space."
05:27:30 <HKei> have you read the final paragraph
05:27:47 <HKei> where it points out that this is not actually definition
05:28:30 <macroprep> HKei: i know
05:28:32 * ski doesn't see anything about Hilbert spaces on
05:28:36 <ski> @wiki Vector-space
05:28:36 <lambdabot> https://wiki.haskell.org/Vector-space
05:28:39 <HKei> the idea is when they say it's "a" hilbert space you have to pick one, and it's a different kind of turing machine depending on which one you choose
05:28:58 <ski> (and i didn't find another page mentioning Hilbert spaces, either)
05:29:29 <macroprep> ski: https://en.wikipedia.org/wiki/Vector_space#Hilbert_spaces
05:29:40 <ski> oh, Wikipedia
05:29:59 <ski> (that's another WikiWiki)
05:30:06 <macroprep> :P
05:30:42 <HKei> Don't attempt to implement anything based on the wikipedia description
05:30:52 <macroprep> o.o why
05:31:08 <HKei> because wikipedia is an encyclopedia, not a cook book
05:31:12 <ski> (if someone says "Wiki" here, i tend to assume the Haskell WikiWiki, or, maybe, the WikiWiki, at C2, <http://wiki.c2.com/>, from which all others sprung)
05:31:32 <macroprep> ok
05:32:17 <HKei> It has references though. Seems like they got their description of a QTM from [3], so you should check that out for a more detailed description of what they actually mean
05:32:45 <maralorn> Just for the record the typeclass we are looking for seems to be: https://hackage.haskell.org/package/vector-space-0.16/docs/Data-VectorSpace.html#t:InnerSpace
05:33:50 <HKei> Yeah but I think we've already established that this isn't really going to help macro here
05:41:04 <maralorn> macroprep: For Quantum Computing you want a finite dimensional complex hilbert space. That means a vector is an array (or something similar) of n complex numbers. (where n is your dimension.)
05:42:10 <macroprep> maralorn: so i wouldnt need a vector space? just a vector
05:42:32 <maralorn> Well
05:42:38 * ski sighs
05:43:05 <maralorn> macroprep: A vector space is a set of all the vectors it contains.
05:43:28 <ski> (arguably, if you have a vector, then you already have a vector space (the one from which the vector is taken))
05:43:40 <pavonia> maralorn: Would the dimension be the analog of the bitwidth of standard computers?
05:44:11 <ski> ("having a vector space", in terms of implementation, in no way implies that you have an object / a value, in your program, which represents a vector space)
05:44:18 <maralorn> pavonia: In a quantum turing maching? No. very much not so.
05:44:43 <pavonia> Hhm, what does that dimension represent then?
05:45:26 <macroprep> anyway, thid https://hackage.haskell.org/package/vector-space-0.16/docs/src/Data.VectorSpace.html#VectorSpace itself is a... (complete/accepted?) implementation of a vector space right?
05:45:29 <macroprep> this*
05:45:36 <maralorn> pavonia: Well if I have a quantum computer with n qubits. The dimensiom of the Hilbert Space to describe it would be 2^^5.
05:46:06 <maralorn> Wait this is only true for n=5.^^
05:46:22 <ski> macroprep : no, it's not an implementation at all. it just describes the interface, what operations an implementation of a vector space must provide
05:47:11 <pavonia> maralorn: Ah, so this is where the exponential complexity comes from
05:47:26 <ski> macroprep : for implementations, look for where it says `instance ... VectorSpace ...'
05:47:30 <maralorn> Yep
05:48:39 <macroprep> ski: this? #define ScalarType(t) \   instance VectorSpace (t) where \     { type Scalar (t) = (t) \     ; (*^) = (*) } ; \   instance InnerSpace  (t) where (<.>) = (*)
05:49:11 <HKei> no
05:49:18 <macroprep> or would the implementation itself be in a different src file
05:49:29 <HKei> this just a helper to add the trivial definitions of vector spaces for scalar types
05:50:23 <HKei> macroprep: You're still completely on the wrong track. There's no "thing" called "a vectorspace". A lot of things are vector spaces, and they're all implemented differently. They just show similar behaviour if you look at them from sufficiently far away
05:51:08 <macroprep> ;-; ok
05:52:21 <HKei> It's like saying, "you can use a form of locomotion to get from A to B"
05:52:22 <maralorn> macroprep: You can think (very crudely) of a vector as a list of numbers. For every list of numbers you get one vector. If you change just one number in the list you have a different vector. The set of all possible lists with a fixed length would then form a vector space. But you never have all of the possible vectors in RAM at the same time, because that doesn‘t really make sense. So yes, if you have a
05:52:24 <maralorn> vector, you have the vector space. Because the space is just an abstraction that you don‘t really need to represent in data.
05:52:29 <HKei> there's no thing called "a Locomotion"
05:52:30 <ski> macroprep : e.g. that,yes. but also later
05:52:53 <HKei> you can *walk*. You can travel by car. You can travel by plane. Heck, if you're sufficiently sci-fi you can teleport
05:53:16 <HKei> these things have nothing to do with each other, other that they can all be used to get from a to b in some fashion
05:53:25 <HKei> and there are some general rules, like for instance
05:53:44 <HKei> if you can get from A to B using one method, and from B to C using the same method, then there's also a path from A to C
05:53:56 <macroprep> ok, then what type of hilbert space is required in order to implement a quantum turing machine, and subsequently, what type of vector space is required in order to implement the required hilbert space
05:53:59 <HKei> a vector space is a similar sort of abstraction
05:54:13 <ski> (and the mediate path isn't shorter than the immediate path)
05:56:32 <maralorn> macroprep: I use https://hackage.haskell.org/package/hmatrix-0.20.0.0/docs/Numeric-LinearAlgebra.html for quantum calculations.
05:56:51 <maralorn> I have the feeling there could be something better. But it’s enough for playing around.
05:58:06 <maralorn> The type you are looking for in there is "Vector (Complex Double)".
06:02:58 <pavonia> HKei: “there's no thing called "a Locomotion"”  Kylie Minogue would disagree with you :3
07:39:34 <merijn> hmm, conduit doesn't have a fold that also yields something?
07:42:20 <merijn> mapAccumWhile and concatMapAccum are tantalisingly close, but not quite it :\
07:45:47 <merijn> ugh and weird ass CPP around it's definition so I can't even easily copy it :\
08:07:45 <flebron_> Hi folks. Suppose I have an x, y, z :: ExceptT e (State a) b. Is there a combiner for "Run x, and if that fails run y, and if both fail run z."?
08:08:28 <merijn> flebron_: Check if ExceptT has an Alternative instance? (I'd assume so?)
08:09:07 <Squarism> I hoped that Applicative operations on Either would return a concatenation of Left's. 
08:09:11 <Squarism> %(pure (*)) <*> Left "a" <*> Left "b"  
08:09:41 <merijn> Squarism: You want Validation :)
08:09:49 <Squarism> ah ok
08:09:50 <merijn> Squarism: That instance can't have a Monad
08:09:53 <Squarism> Sounds good
08:09:55 <merijn> @hackage either
08:09:55 <lambdabot> http://hackage.haskell.org/package/either
08:10:23 <flebron_> The semantics I'm after are "Please don't modify the state if the computation throws, and don't try to run later computations if an earlier one succeeded."
08:10:57 <merijn> flebron_: Honestly, sounds more like STM :p
08:12:47 <flebron_> merijn: Were you suggesting that plan <|> should do that?
08:13:24 <merijn> flebron_: Maybe, nesting ExceptT and StateT is complicated enough that I'm too lazy to figure out what happens
08:13:43 <merijn> Or rather, I was suggesting <|> would do that, yes. But I don't know if it actually does :p
08:14:03 <flebron_> It seems to want to append the errors, so my e would need to be a Monoid...
08:14:16 <flebron_> http://hackage.haskell.org/package/transformers-0.5.6.2/docs/src/Control.Monad.Trans.Except.html#line-202
08:16:55 <ski> @unmtl ErrorT e (StateT s m) a
08:16:55 <lambdabot> s -> m (Either e a, s)
08:17:07 <ski> @unmtl StateT s (ErrorT e m) a
08:17:07 <lambdabot> s -> m (Either e (a, s))
08:23:29 <macroprep> welp imma give up on building a quantum state machine
08:23:43 <macroprep> quantum turing machine*
08:32:03 <pavonia> Already?
08:33:40 <merijn> Ok, anyone know how to make GHC's errors less verbose? Getting 40 lines of "context" and relevant bindings is becoming obnoxious >.<
08:36:18 <higherorder> Hi! Anyone familiar with the `functor-combinators` library? I am wondering if it exposes a class like the `:<:` one from "Datatypes a la Carte" which automates the injections into a functor sum (:+:), c.f. https://hackage.haskell.org/package/functor-combinators-0.1.1.1/docs/Data-Functor-Combinator.html#t::-43-:
08:37:24 <higherorder> Nevermind, I think that's https://hackage.haskell.org/package/functor-combinators-0.1.1.1/docs/Data-Functor-Combinator.html#t:Inject
08:39:50 <merijn> hmm, it doesn't appear to be -ferror-spans, anyone else know where this endless contextual spam comes from?
08:40:31 <c_wraith> I'm pretty sure there's a flag to control the number of suggestions that can be set to 0, but I don't recall the name of it
08:40:56 <merijn> c_wraith: These aren't suggestions, but the context of "in this expression"
08:41:56 <merijn> c_wraith: For example: https://paste.debian.net/1104746/
08:42:09 <merijn> That's a single error >.< I'm not programming C++...
08:42:42 <merijn> And I have like 20 of those...
08:42:52 <merijn> I just want to enable "ultra-terse" mode :\
08:44:22 <merijn> There's a bunch of verbosity flags, but I can't seem to find the magic one
08:46:02 <merijn> It's not: -fmax-relevant-binds, -fno-error-spans, or -fno-typechecker-elaboration
08:46:09 <macroprep> pavonia: yup
08:46:45 <macroprep> i am unable to construct a Vector Space
08:47:12 <macroprep> thus i am un able to construct a Hilbert Space
08:48:17 <pavonia> People already told you that you don't need an implementation for it, just a vector data type and the required operations on it :S
08:51:01 <macroprep> prove it :P
08:51:06 <maralorn> Well, perhaps this is a lot of miscommunication. But I think what would help macroprep the most would be to attend a lecture about linear algebra.
08:51:50 <macroprep> wikipediais truth
08:52:38 <maralorn> wikipedia is a terrible teacher.
08:52:51 <macroprep> :P
08:53:11 <maralorn> Let’s start with letters we have "abcdefg ... xyz". 
08:53:23 <pablo-pie[m]> <maralorn "wikipedia is a terrible teacher."> the math section of it is actually quite accurate.
08:53:30 <pablo-pie[m]> just not detailed enought
08:53:41 <merijn> pablo-pie[m]: Accuracy is not the main requirement of a teacher
08:54:14 <merijn> I can't be the only one going insane from the verbosity of GHC's errors...
08:54:26 <pablo-pie[m]> wat u mean?
08:54:32 <maralorn> Great now all of you can read and write!
08:54:50 <merijn> pablo-pie[m]: The most important criterium is being to explain and foster understanding, wikipedia is terrible at that
08:55:19 <geekosaur> do you start with throwing a ball, or with general relativity?
08:55:47 <hyperisco> Encyclopedias are records of information, not tutorials
08:56:41 <pablo-pie[m]> <merijn "@pablo-pie: The most important c"> I dunno what foster understanding means
08:58:30 <pablo-pie[m]> <geekosaur "do you start with throwing a bal"> yeah, math is kinda like that in a sense. it's kind of a never ending macro expension (you expand definitions untill you get to the base)
08:58:40 <pablo-pie[m]> i'm a math undergrad btw
08:58:52 <hyperisco> The base is a lie.
08:58:54 <merijn> pablo-pie[m]: I don't know what you're doing in your client, but that quoting is super annoying
08:59:09 <__monty__> merijn: It's matrix.
08:59:12 <geekosaur> this is the point though, a teacher knows which level to teach at, wikipedia just infodumps
08:59:22 <merijn> geekosaur: In a random order too
08:59:47 <merijn> Also, tragically apparently there is no flag to control error verbosity in GHC and I need to just suck it up unless I patch GHC...
09:00:12 <pablo-pie[m]> <merijn "@pablo-pie: I don't know what yo"> wat?
09:00:29 <__monty__> pablo-pie[m]: Matrix's reply-to feature or something doesn't interact nicely with the irc bridge. It'd be great if you could avoid using it. Thank you.
09:00:30 <geekosaur> "<merijn "@pablo-pie: I don't know what yo"> wat?"
09:00:40 <pablo-pie[m]> <geekosaur "this is the point though, a teac"> i see, makes sense
09:00:41 <geekosaur> is what you just sent to us. it's annoying
09:01:26 <pablo-pie[m]> ok
09:01:28 <pablo-pie[m]> I'm using Riot lol
09:04:31 <pablo-pie[m]> could it be a bug in it? I just updated it
09:05:52 <__monty__> pablo-pie[m]: No, it's a quoting or replying feature. We've had matrix users do it and then *stop* doing it before.
09:07:39 <pablo-pie[m]> ok, did I messed something up then? I don't get it.
09:08:05 <pablo-pie[m]> I've already stopped using the reply thing
09:08:24 <__monty__> pablo-pie[m]: Then it's probably fine.
09:48:24 <tralaa> test
09:48:24 <tralaa> tes
09:48:24 <tralaa> t
09:48:24 <tralaa> sex
09:49:00 * hackage postgresql-typed 0.6.1.0 - PostgreSQL interface with compile-time SQL type checking, optional HDBC backend  https://hackage.haskell.org/package/postgresql-typed-0.6.1.0 (DylanSimon)
09:49:58 <fr33domlover> o/ Which library should I use for parsing XML these days? Basically it's XML with a known structure, I'd love to parse it the same way I parse JSON with aeson
09:51:22 <Squarism> is there a value to represent a type that can also be used to provide signature. Im thinking something (SomeRep a) i could give this function : read :: a => SomeRep a -> a ? It seems GHC.Generic models Values of a type. Im more interrested in values that just represents the type and not value of the type. some value that is possible to pattern match on (at cost of arbitrary manual coding) to be able _handle_ a value of that type.
09:53:00 * hackage feed 1.2.0.1 - Interfacing with RSS (v 0.9x, 2.x, 1.0) + Atom feeds.  https://hackage.haskell.org/package/feed-1.2.0.1 (AdamBergmark)
09:53:01 <geekosaur> is this not Typeable? a TypeRep includes a fingerprint
10:05:49 <Squarism> geekosaur, maybe it could be. Gonna test it some
10:09:14 <shapr> drbrule: HI THERE
10:09:20 <drbrule> Hey shapr
10:09:35 <shapr> topos: is there an IRC channel that's good for discussing category theory?
10:10:00 <uniquerockrz> I am beginner to haskell, I am trying to find out what I am doing wrong in this program. I am trying to find the largest divisor of a number (except itself). 
10:10:10 <uniquerockrz> https://paste.ubuntu.com/p/2y4r2TGr48/
10:10:46 <merijn> uniquerockrz: What's going wrong?
10:10:55 <uniquerockrz> when I try to load this in ghci, it says Couldn't match expected type ‘Int -> Int’ with actual type ‘Int’
10:11:31 <merijn> uniquerockrz: oh, you forgot to give largestdiv an argument :)
10:12:46 <uniquerockrz> Oh. My bad. Got it now
10:12:52 <uniquerockrz> Thanks for the quick response
10:13:59 <cocreature> shapr: ##categorytheory maybe?
10:15:08 <shapr> cocreature: sounds good to me
10:17:03 <higherorder> Hi; is there a maintained equivalent of http://hackage.haskell.org/package/operational ?
10:28:53 <geekosaur> there's multiple free monad packages
10:29:45 <fr33domlover> Hmmm XML thoughts: HaXML docs are so hard to find, scary to use it in new code. I think I'll try using HXT picklers
10:30:30 <cocreature> fr33domlover: I’ve used xml-conduit the past few times I’ve had to deal with xml and have been quite happy with it
10:30:57 <merijn> xml-conduit is nice, but doesn't do any sort of schema validation
10:31:38 <merijn> cocreature: It's still broken on the large project I'd like to work on, but at least I fixed ghcide and some smaller stuff and holy shit is it fast with reporting errors :O
10:31:46 <fr33domlover> cocreature: I just need to parse XML into a Haskell type in the same way aeson does with JSON :)
10:31:47 <merijn> s/and some/on some
10:32:50 * fr33domlover will check xml-conduit too
10:33:07 <cocreature> fr33domlover: xmlbf is the closest to “aeson for xml” iirc but it’s been ages since I’ve looked at it
10:33:10 <merijn> fr33domlover: xml-conduit is definitely much simpler than HaXML and HXT :)
10:33:48 <sm[m]> merijn: great.. what prevents ghcide working on the big project ?
10:34:05 <cocreature> merijn: are all the issues TH stuff?
10:34:11 <merijn> cocreature: Maybe?
10:34:32 <merijn> They mostly seem to be TH, but there might be some nasty component related issues lurking, I suppose
10:35:46 <merijn> sm[m]: ^^ mostly TH
10:35:56 <cocreature> not too worried about component-related stuff, fixing TH is the bigger issue
10:37:10 <sm[m]> it's always TH :/
10:37:58 <merijn> TH, can't live with it, can't live without it ;)
10:40:38 <slack1256> Can anyone give me the link to the `Any` type family on GHC? The term is too generic for google/duckduckgo.
10:41:50 <cocreature> slack1256: there isn’t really more to it than the docs say afaik. you can safely unsafeCoerce anything to Any and back from it
10:42:12 <sm[m]> https://hoogle.haskell.org/?hoogle=Any&scope=set%3Astackage&=
10:42:25 <koz_> slack1256: https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Exts.html#t:Any <-- this one?
10:49:19 <slack1256> That one. Thanks koz_
11:04:06 <dinkpad> hi,  I'm trying to use a type such that (double, double)
11:04:54 <dinkpad> I want to take a list of that type and sum the two numbers i.e. 
11:05:45 <wildtrees> so you would have a list of pairs, dinkpad, [(Double,Double)] so you could have no pairs , one pair, or more than one pair 
11:05:47 <dinkpad> (a,b), (x,y) -> (a+x, b+y)
11:07:22 <dinkpad> I'm not really sure on the correct nomeclature to search for what I want to do
11:09:01 <wildtrees>  > let f (a,b) (x,y) = (a+x, b+y) in f (1,2) (3,4)
11:09:28 <wildtrees> dinkpad: you probably want to look up how to define functions in haskell and maybe a bit of pattern matching as well 
11:09:52 <dinkpad> sorry the list can range from 1 point to n points
11:10:03 <dinkpad> what you wrote I know how to do lol
11:10:25 <wildtrees> how do you want to operate over the list? if you have a list you also should handle the empty list [] as well 
11:10:40 <merijn> dinkpad: I think you just want foldl?
11:10:46 <dinkpad> I can assume I wont ever have an empty list in this function
11:11:12 <wildtrees> foldr1 or foldl1 then, perhaps 
11:11:24 <wildtrees> @type foldr1 
11:11:25 <lambdabot> Foldable t => (a -> a -> a) -> t a -> a
11:11:29 <merijn> Why use those if you can just use foldl/foldr with a 0 element?
11:11:53 <heatsink> dinkpad: Try solving it for specific list sizes first, then look for the pattern that relates the list sizes
11:11:55 <wildtrees> sometimes a 0 element isn't well defined for certain fold operations 
11:12:13 <merijn> wildtrees: He wants to do addition, 0 is obviously well defined
11:12:16 <dinkpad> does foldl work with user defined types
11:12:31 <merijn> dinkpad: It works with any types you can write a function for
11:12:34 <merijn> :t foldl
11:12:34 <dinkpad> oh ok
11:12:35 <lambdabot> Foldable t => (b -> a -> b) -> b -> t a -> b
11:12:43 <dinkpad> I think thats more complicated then I need
11:13:05 <geekosaur> it's general. but not mre general than you need here
11:13:13 <dinkpad> I think my root issue is im not sure how to access a member of a type
11:13:27 <dinkpad> I know like f (pt _ y) = 
11:13:43 <geekosaur> for tuples you want fst and snd, or just use pattern matching. someone showed you earlier
11:13:43 <dinkpad> would let me work off the y member of my point type
11:13:51 <wildtrees> fst and snd? 
11:13:56 <geekosaur> wait, is it a sum or a tuple?
11:14:16 <dinkpad> its a list of "points"
11:14:18 <geekosaur> if you defined (x,y) then you have a tuple and can use fst and snd to access the parts
11:14:37 <dinkpad> point  = pt double double derriving (show)
11:14:51 <geekosaur> sorry, product. trying to go too fast here. if you defined Point x y then you have a type which you can use pattern matching to deconstruct
11:15:13 <geekosaur> or you can define Point {x :: Int, y :: Int} and use record syntax
11:18:27 <dinkpad> I think I'm close lol
11:19:35 <geekosaur> how exactly is your data type defined? show the actual code
11:21:30 <dinkpad> data point = Pt double double deriving (Show, Eq)
11:23:18 <geekosaur> I assume you got your case correct, since that won't work as written
11:23:26 <wildtrees> dinkpad: Types and type constructors are capitalized in haskell 
11:24:06 <dinkpad> sorry yes Point and Double
11:24:16 <geekosaur> addPt (Pt x y) (Pt a b) = Pt (x + a) (y + b) -- pattern matching
11:24:31 <dinkpad> I can define sum for any type correct?
11:25:08 <geekosaur> if you mean (+), you must also define a number of other things required by typeclass Num.
11:25:36 <dinkpad> ok I think I have enough info to plot this together ill report back 
11:25:38 <wildtrees> how would you multiply points? 
11:26:45 <heatsink> Multiplication usually isn't defined on points or vectors.  Unless you mean multiplication by a scalar.
11:27:08 <geekosaur> but you need to define it for a Num instance
11:31:13 <rotaerk> hmm the manual for shake says to run it with stack ... does it actually depend on stack?
11:31:38 <geekosaur> no
11:33:21 <rotaerk> I'm thinking shake will be my solution to compiling my GLSL shaders to SPIR-V, rather than trying to get cabal to do it for me
11:34:18 <rotaerk> cabal's build-type Configure just doesn't seem to work for that. build-type Custom ... might work, but I'm not sure; it's complicated.
11:34:47 <heatsink> cabal isn't really suited to compiling non-haskell code
11:35:11 <heatsink> As I recall, Custom means you write your own build script, which can be a makefile or shell script or whatever
11:37:25 <dinkpad> thank, I got this to work
11:37:49 <dinkpad> I'm still trying to break out of oop though with member access ect
11:38:00 * hackage ansi-terminal 0.10.1 - Simple ANSI terminal support, with Windows compatibility  https://hackage.haskell.org/package/ansi-terminal-0.10.1 (mpilgrem)
11:44:46 <dinkpad> thanks a lot guys, I got this function to find the average point out of a list of points, learned a lot 
11:45:21 <wildtrees> dinkpad: congratz and good luck programming in Haskell! 
12:14:42 <dinkpad> say i have data Shape = Circle | Square
12:15:27 <dinkpad> and i have f shapeA shapeB = shapeA:~:shapeB 
12:15:47 <dinkpad> that will determing if theyre the same ie circle circle -> true
12:17:26 <EvanR> did you want to use shapeA == shapeB
12:17:37 <EvanR> or form a type level equality
12:20:06 <dinkpad> I want to check that the two shapes are the same type
12:21:05 <EvanR> are you talking about DataKinds, or... otherwise Circle and Square are already the same type
12:21:29 <EvanR> == will check that they are equal and return a Bool
12:21:33 <dinkpad> otherwise 
12:21:44 <dinkpad> by equal you mean both circles right?
12:21:53 <EvanR> or both Square
12:22:25 <dinkpad> yes
12:22:36 <dinkpad> so circle and square is false
12:22:58 <EvanR> try it in ghci
12:26:37 <shapr> I have something in my emacs haskell-mode that shows me type signatures when my cursor is over that piece of code, is there something equivalent for vim?
12:28:21 <shapr> I helped someone with a cabal problem today, they'd named their library stanza something different from the package name. Should that work?
12:28:44 <shapr> Does anyone create multiple library stanzas in their cabal file, each with different names?
12:28:54 <shapr> or is the convention only one single library stanza?
12:29:51 <hpc> can there be multiple libraries?
12:30:05 <hpc> i thought that was only executables
12:30:42 <shapr> hpc: don't know, thus my question
12:30:47 <shapr> guess I should dive into the cabal docs
12:30:56 <merijn> hpc: There can now
12:31:15 <merijn> shapr, hpc: Until very recent versions of the CABAL spec there was only one library per package and thus it had no name
12:31:32 <merijn> As of a while now you can define multiple libraries, but all except one must be internal
12:31:38 <shapr> merijn: so, single library stanza until cabal 3 and later?
12:31:45 <merijn> There's work on going to support multiple external libraries
12:32:11 <merijn> readthedocs is down for me, so I can't check
12:33:13 * shapr reads https://www.haskell.org/cabal/users-guide/developing-packages.html
12:33:33 <merijn> shapr: You want https://cabal.readthedocs.io/en/latest/ probably
12:33:50 <merijn> shapr: It has a reference for what was changed/added in each cabal format version
12:34:00 <merijn> Except I can't load it to link to the right page >.>
12:34:26 <shapr> ah, that has cabal 3.2 in addition to what I was reading
12:34:58 <geekosaur> https://cabal.readthedocs.io/en/latest/file-format-changelog.html
12:36:10 <dinkpad> ok so I think i need to constrain my Shape type to Eq
12:36:28 <shapr> geekosaur: that implies there's still only one library stanza, and it can't have a name
12:37:36 <geekosaur> section 7.5, cabal 2.0
12:37:55 <geekosaur> "Add support for internal library stanzas"
12:38:07 * shapr reads again
12:38:46 <shapr> oh, so my friend is using cabal less than 2.0 so that's the problem?
12:38:53 <shapr> geekosaur: thanks for the help!
12:39:09 <shapr> now if someone knows how to do type signature popups in vim, I'm set :-)
12:39:18 <geekosaur> cabal library version, at east, but if they're on cabal-install 1.24 then they can't I think be using Cabal library 2.x
12:39:47 <shapr> they were trying to get ghc-mod working, and that required an older stack lts ... 
12:39:48 * shapr shrugs
12:41:20 <shapr> hoi tromp, hoe gaat het?
12:42:02 <shapr> tromp: last I checked, you no longer live near NYC, right?
12:42:45 <koz_> shapr: What do you mean by 'type signature popups'?
12:44:08 <shapr> in emacs my status bar shows common type signatures (pulled from haddocks maybe?) when my cursor moves over those names.
12:46:03 <koz_> shapr: Ah, OK. I read something analogous to that here: http://marco-lopes.com/articles/Vim-and-Haskell-in-2019/
12:46:13 <koz_> Disclaimer: I don't use this and probably never will.
12:46:21 <koz_> (although I am a Haskell-in-Vim person)
12:48:50 <merijn> koz_: Have you trie ALE (the asynchronous linter) together with ghcide? Aside from ghcide currently being broken on TH it's amazing
12:49:22 <koz_> merijn: I use ALE, but ghcide has never worked for me ever.
12:49:34 <dinkpad> Ok so I restricted my function f :: (Eq) => a ->a -> Bool
12:49:35 <koz_> Nor has any variant of anything other than 'ALE plus a bunch of hacks to make it work with cabal new-build'.
12:49:44 <dinkpad> that worked but idk if I was allowed to do that
12:49:52 <dinkpad> lol
12:50:57 <EvanR> dinkpad: f from earlier looked like Shape -> Shape -> Bool
12:50:59 <LnL> I hacked something in ale to get the type signatures out of the hover text recently
12:51:38 <merijn> koz_: hmmm apparently I haven't pushed my ALE linter to github so I can't link you to it, but it was fairly straightforward
12:51:52 <koz_> merijn: Is yours based on ghcide?
12:52:21 <koz_> Mine's a relatively straightforward .vimrc hack that makes a custom command which is basically 'exactly their cabal build, but with new-build instead'.
12:52:38 <merijn> koz_: new-build is slow as shit, though
12:52:47 <koz_> merijn: I haven't noticed.
12:53:12 <koz_> Except _maybe_ on my first lint, which might take a second or so.
12:53:15 <merijn> koz_: For me new-building my codebase can easily take like 30s or longer
12:53:38 <merijn> Maybe like 1-2 minutes if it needs to build everything from scratch
12:54:12 <koz_> merijn: It seems I was a bit dishonest there - I actually use cabal new-exec -- ghc with -fno-code.
12:54:18 <merijn> I have this autoload stuff related to ghcide (if I've tested it more I might open a PR to add it to ALE): https://github.com/merijn/dotfiles/blob/master/dotfiles/vim/autoload/ale_linters/haskell/ghcide.vim
12:54:24 <mpickering> it's quite surprising how fast ghcide is..
12:54:39 <koz_> (again, it's a direct rip of ALE's ghc linter, just with 'cabal new-exec' instead of 'cabal exec')
12:54:45 <merijn> koz_: Then this to enable ghcide: https://github.com/merijn/dotfiles/blob/master/dotfiles/vim/ftplugin/haskell.vim#L1-L9
12:54:55 <merijn> mpickering: Word.
12:55:10 <koz_> merijn: Can I use cabal new-install to build ghcide?
12:55:17 <mpickering> Sure
12:55:20 <koz_> And will it cause GHC versioning issues?
12:55:23 <merijn> On the few simple projects where it works it's often finished compiling/annotating errors before vim is done exiting insert mode
12:55:32 <mpickering> That's how I built it
12:55:35 <merijn> koz_: I new-installed it, so sure :p
12:55:41 <mpickering> you have to build it with the same version of ghc that you use
12:56:14 <koz_> mpickering: In that case, I don't think it'll work very well for me.
12:56:24 <mpickering> So clearly the typechecking part of GHC is quite fast
12:56:55 <mpickering> I set up my shell.nix to provision the right version 
12:57:14 <mpickering> but if you don't do that then not sure what is the currently recommended way
12:57:19 <aplainzetakind> Is anyone familiar with the Chart library?
13:04:00 <mpickering> irc etiquette: just ask the question
13:05:45 <aplainzetakind> I can't figure out from the documentation hoe to add some sort of padding around the data. The chart boundary is tight around plot points.
13:05:50 <rotaerk> maybe that was the question; maybe it's just a poll for familiarity
13:09:42 <mpickering> none of the examples seem to show this so perhaps it's not possible (having never used the library)
13:11:36 <mpickering> aplainzetakind: https://github.com/timbod7/haskell-chart/issues/123
13:11:59 <mpickering> this comment in particular seems relevant - https://github.com/timbod7/haskell-chart/issues/123#issuecomment-229820235
13:14:03 <aplainzetakind> mpickering: Indeed. Thanks.
13:15:38 <tromp> hi shapr; that's right; I moved back to Amsterdam in summer '17
13:32:30 * hackage google-static-maps 0.6.0.1 - Bindings to the Google Maps Static API (formerly StaticMaps API)  https://hackage.haskell.org/package/google-static-maps-0.6.0.1 (mpilgrem)
13:43:08 <sternmull> Is there a well established function "c -> Maybe a -> (a -> c) -> c"  that takes a default output, a Maybe and a function that produces the non-default if it is not Nothing? My workaround is "(flip $ maybe dflt) myMaybe $ myFunc" but i know i will be unable to understand that tomorrow.
13:44:53 <merijn> :t maybe
13:44:54 <lambdabot> b -> (a -> b) -> Maybe a -> b
13:44:57 <merijn> sternmull: That one? :p
13:45:13 <merijn> oh, wait, you already had that one
13:45:34 <EvanR> arguments permuted
13:45:37 <sternmull> merijn: Yes, the only thing i want is to change the order of the arguments
13:45:51 <sternmull> because my function is actually a do-block.
13:46:09 <merijn> sternmull: The solution is to, instead of that cryptic thing, just define a new function with a name and use that
13:46:14 <EvanR> there was this funny trick to swap arguments before opening a do... what was it...
13:46:39 <EvanR> useful with from-the-hip runState etc
13:47:09 <EvanR> or fix
13:47:57 <sternmull> merijn: Before defining my own function i wanted to ask if there is already a common function that does exactly that. I guess it is not that uncommon to have a do-block or lambda as function and want it as last argument.
13:52:33 <tydeu> Integer literals desugar to a `fromInteger` call which is polymorphic in its return type. So how is it that integer literals can be passed to functions with polymorphic inputs? How does it know to choose the `Integer` instance in those casses rather than the `Int` instance, for example?
13:53:11 <lyxia> there is an ad-hoc defaulting mechanism going on
13:54:54 <tydeu> Oh. Is there any way to simulate that with user-defined classes?
13:55:33 <merijn> tydeu: Not really, afaik
13:55:40 <merijn> tydeu: What are you trying to do/solve?
13:55:56 <doyougnu> I thought that was the purpose behind "default" signatures
13:56:05 <doyougnu> here: https://downloads.haskell.org/~ghc/7.2.1/docs/html/users_guide/type-class-extensions.html
13:56:22 <doyougnu> could be wrong though, never really used them
13:57:23 <tydeu> doyougnu: afaik that is not what default signatures do
13:57:25 <EvanR> is that what tydeu was asking? 
13:57:38 <merijn> default signatures are something else entirely
13:57:43 <doyougnu> ah my mistake then
13:58:13 <EvanR> you can pass integer literals to polymorphic functions in cases that have nothing to do with defaulting
13:58:15 <merijn> You can add extra defaults, but that just extends the set of potential results for the typeclasses that already default (i.e. the numerical ones)
13:58:47 <EvanR> as long as there is enough type information around to choose the Num instance when it matters
13:59:42 <EvanR> when that and defaulting fail, you get an ambiguous type error
14:01:01 <tydeu> merjin: I was mostly just curious how it worked. However, I have had many cases where the one to many, many to one problem in polymorphism is annoying so I was interested in the possiblity of simulating the solution literals seem to have.
14:01:34 <merijn> tydeu: I mean you can trivially "simulate it" by just adding an annotation :p
14:03:30 <tydeu> merijn: lol, that is not generally the prettiest solution (and when it requires `TypeApplications` and `ScopedTypeVariables` it can become even more burdensome) XD
14:03:57 <merijn> I rarely run into situations where my code requires that much
14:07:59 <tydeu> merijn: interesting, do you think that you would encouter more of thiose stiutations if the built-in defaulting didn't exist?
14:08:30 <EvanR> honestly defaulting hasn't really come up much at all in real code, only on ghci where you don't use annotations
14:08:36 <merijn> tbh, I try to avoid defaulting entirely
14:08:58 <tydeu> well isn't it required for something as simple as `3 + 4`?
14:08:59 <EvanR> which is why i think the answers earlier were misleading
14:09:07 <EvanR> you probably aren't experiencing defaulting in real code
14:09:21 <merijn> tydeu: Only if the result isn't passed to something with a type signature
14:09:33 <merijn> tydeu: I rarely write "3 + 4" without doing something else with it
14:10:09 <EvanR> yeah tydeu asked about passing literals to a polymorphic function
14:10:33 <EvanR> based on how it's used, it probably didn't need defaulting to work
14:11:14 <EvanR> the only reason you need to scoped type variables when dealing with rank N is type variables aren't scoped by default
14:13:05 <tydeu> the expression `toInteger (3 + 4)` desugars to `toInteger ((fromInteger 3) + (fromInteger 4)))` requires defaulting right (as it could use the `Int` instance for summing instead, for example)
14:13:10 <EvanR> no
14:13:21 <EvanR> only if you write that in ghci in isolation
14:13:42 <tydeu> why not?
14:13:43 <EvanR> or rarely some weird spot in code
14:14:09 <merijn> tydeu: It only require defaulting if toInteger's argument is polymorphic
14:14:33 <EvanR> youre right toInteger (3 + 4) would default, but it's not realistic code obviously
14:17:28 <tydeu> EvanR: I am not quite sure why that is unrealistic, but okay, how about `fmap toUpper "hello"` with `OverloadedStrings`?
14:17:47 <EvanR> yeah, OverloadedStrings tends to trigger ambiguous type error
14:18:08 <merijn> I have overloadedstrings all over the place and can't remember the last ambiguous type I had
14:18:23 <EvanR> yeah it's mitigated when your code knows what it wants
14:18:30 <EvanR> but anyway the string literals don't default
14:18:31 <tydeu> And because of defaulting
14:18:36 <EvanR> it's not a feature
14:18:54 <tydeu> Oh, I didn't know that -- are you sure they don't default?
14:18:58 <EvanR> and if it did default that would probably be bad
14:19:08 <EvanR> since you probably didn't want String
14:19:36 <EvanR> "code knows what it wants" = type signatures
14:19:49 <merijn> -Wall warns about defaulting, iirc (or did I manually enable that warning?)
14:20:24 <lyxia> it does
14:21:35 <tydeu> I just tested, it does default
14:21:41 <EvanR> really...
14:22:49 <merijn> I still have 0 defaulting/ambiguous type warnings in all my codebases without actively trying to avoid it, so it's really not that hard, imo
14:23:07 <EvanR> i get ambiguous type error in GHCI, but i have a pretty old ghc
14:23:32 <Lycurgus> 'pretty old' is not a build mark
14:23:44 <EvanR> ok, mildly ancient
14:23:55 <Lycurgus> so 7 sumthin
14:24:07 <Lycurgus> late 7, early 8
14:24:20 <Lycurgus> that fits the specified linguistic value
14:24:22 <EvanR> 7.10.2
14:24:23 <merijn> Early 8 isn't ancient >.>
14:24:33 <merijn> 8.0 is "fairly recent" >.<
14:24:37 <Lycurgus> hedged by midly
14:24:41 <Lycurgus> *mildly
14:25:02 <Lycurgus> oh, nailed it
14:25:23 * Lycurgus basks in the reveal
14:27:31 <EvanR> a large chunk of understanding C code is comprehending what amounts to a network of defaulting rules
14:27:36 <tydeu> interesting, I tested it on GHCi and it defaulted, I wrote a program to test it and it produced an ambuguous type error -- so I am not exactly sure what happens (maybe OverloadedStrings works differenly in GHCi?)
14:27:47 <EvanR> i'm glad it's not like that in haskell
14:28:24 * Lycurgus is baffled by people that are baffled by C
14:28:44 <EvanR> so baffling cancel out or compound
14:28:49 <EvanR> or phase shift
14:29:07 <Lycurgus> yeah the nugatory generational thing
14:29:23 <tydeu> I think my problem is I tend to work with highly polymorphic code (due written my code in a pseudo-depedently typed style) and thus end up with these problems more often
14:29:24 <merijn> Lycurgus: I'm baffled by people who *aren't* baffled by C, but that's a topic for -offtopic
14:30:04 <Lycurgus> for "fairly recent" i would say "8.4ish"
14:31:31 <wildtrees> what should I replace netwire with and I think I also need to replace cloud-haskell as well, any suggestions for either of those or both?
14:31:48 <Lycurgus> an ANSI C compiler is often included as an example in a compiler compiler toolkit, image that for hs
14:31:52 <Lycurgus> *imagine
14:32:19 <merijn> Lycurgus: Correctly implementing Haskell2010 (no extensions) is fairly simple compared to C
14:32:20 <Lycurgus> i.e. a fully functional compiler
14:32:47 <merijn> If, at punishment of death upon deviation from the spec, I had to write a compiler I'd pick Haskell over C any time
14:33:03 <dmwit> no way
14:33:06 <merijn> I'm not convinced C compilers that correctly implement the spec even exist
14:33:12 <dmwit> You'd have to implement recursive modules. ;-)
14:33:22 <merijn> dmwit: Easy-peasy compared to C
14:34:00 <dmwit> GHC doesn't even do it all these years later.
14:34:27 <merijn> dmwit: Retrofitting a feature can be significantly harder then implementing it from the start
14:35:00 <merijn> dmwit: Also, there's not a lot of demand for recursive imports and no papers to be had implementing it, so no reason for regular GHC contributors to invest much time and effort
14:35:39 <heatsink> I'm not sure it's possible to determine what behavior is correct according to the C spec
14:35:46 <merijn> heatsink: Agreed
14:36:04 <merijn> heatsink: But I don't think anyone complies with the agreed upon parts either :p
14:36:12 <evelyn> We should extend the C spec to have object orientated features and lots of extra colons
14:36:21 <EvanR> can you please wait for me to get the popcorn before you take this convo to ##c :P
14:36:22 <heatsink> ah, ok
14:36:28 <svipal> recursive modules would be really comfortable
14:36:38 <merijn> I don't think most people in ##C would disagree
14:37:00 <svipal> hs-boot can get the boot
14:37:27 <hpc> i agree
14:37:47 <Lycurgus> c rooms, #lisp, some others don't suffer or pity a fool
14:37:48 <maerwald> evelyn: you mean D?
14:38:01 <Lycurgus> here ur good tho
14:39:22 <evelyn> Stop bringing more programming languages into our great C brawl!
14:39:25 <evelyn> /s
14:40:50 <dsal> ##C?  Is that the channel for discussing the sharp-C language?
14:42:00 <EvanR> hyuck
14:45:44 <hpc> i do have to admit, parsing layout would give me a bit of a pause
14:49:47 <merijn> hpc: Sure, but compared to correctly implementing the rules for, say, promoting integral literals in C...
14:51:24 <jsomedon> fmap fmap fmap
14:51:29 <jsomedon> is this valid code?
14:51:32 <jsomedon> in haskell?
14:51:50 <jsomedon> saw this on typeclasspedia
14:52:01 <hpc> :t fmap fmap fmap
14:52:02 <lambdabot> (Functor f1, Functor f2) => (a -> b) -> f1 (f2 a) -> f1 (f2 b)
14:52:03 <svipal>  I'm not doing nofmap november this year
14:52:21 <jsomedon> uh
14:52:23 <hpc> jsomedon: the first fmap ends up being (.), so it's
14:52:26 <hpc> :t fmap . fmap
14:52:27 <lambdabot> (Functor f1, Functor f2) => (a -> b) -> f1 (f2 a) -> f1 (f2 b)
14:52:36 <hpc> which takes a function and applies it extra deeply to a data structure
14:52:50 <hpc> or whatever
14:53:28 <EvanR> :t fmap fmap
14:53:29 <lambdabot> (Functor f1, Functor f2) => f1 (a -> b) -> f1 (f2 a -> f2 b)
14:53:44 <EvanR> is something else entirely
14:53:54 <hpc> odd-numbered fmaps keep going deeper and deeper
14:54:04 <hpc> even-numbered fmaps get... interesting
14:54:07 <hpc> :t fmap fmap fmap fmap
14:54:08 <lambdabot> (Functor f1, Functor f2, Functor f3) => f1 (f2 (a -> b)) -> f1 (f2 (f3 a -> f3 b))
14:54:17 <EvanR> what about
14:54:18 <hpc> i guess not that interesting, but still
14:54:22 <EvanR> :t (fmap fmap) (fmap fmap)
14:54:23 <lambdabot> (Functor f1, Functor f2) => (a1 -> a2 -> b) -> f1 a1 -> f1 (f2 a2 -> f2 b)
14:54:42 <EvanR> :t fmap (fmap fmap) fmap
14:54:43 <lambdabot> Functor f => (a1 -> b) -> (a2 -> a1) -> f a2 -> f b
14:54:57 <hpc> large numbers of fmaps are a good benchmark for a type checker, as well
14:56:07 <Squarism> this type signature seems to confuse ghc : requireRepeat :: (FormEvaluator b) => FormInputs -> ComplexField -> Writer FormVars ([ComponentEvaluation b])
14:56:16 <Squarism> Gives Could not deduce (FormEvaluator [b]) arising from a use of ...
14:57:11 <EvanR> "you can't go wrong with fmap"
14:57:26 <hpc> i say you can't go wrong enough
14:57:51 <hpc> Squarism: something in the definition of requireRepeat doesn't line up with the type signature you gave it
14:57:52 <Squarism> its like there needs to be symmetry between between class and and result. 
14:58:14 <Squarism> ok
14:58:20 <hpc> you're probably using some method of FormEvaluator on [value] instead of value
14:58:30 <jsomedon> EvanR: about yesterday's puzzle, can I use fmap when writting pure and <*>
14:58:38 <EvanR> yes
14:58:42 <Squarism> hpc, ok thanks
14:58:52 <shapr> which puzzles?
14:58:57 <dinkpad> hello again
14:59:14 <jsomedon> EvanR: nice! initially I thought I could only use unit and combine
14:59:14 <dinkpad> it appears I'm still missing a fundemental concept with comparing types
14:59:14 <EvanR> implement Applicative using ThisOtherThing class, unit :: f (), combine :: f a -> f b -> f (a,b)
14:59:23 <dinkpad> say I have data Tree a = EmptyTree | Node a (Tree a) (Tree a) deriving (Show, Read, Eq)  
14:59:26 <EvanR> jsomedon: hence the type signature emphasizing Functor f
15:00:05 <dinkpad> i want to comp (Node l _ r) = if l is same type as r -> True
15:01:05 <dinkpad> as in node = node -> true node = EmptyTree -> false
15:01:22 <jsomedon> EvanR: yeah, I guess if you hint me I can use fmap explicitly, it becomes too obvious that pure use fmap haha
15:02:00 <hpc> pure doesn't necessarily use it, it just can
15:02:18 <EvanR> you'd need to use it if you were implementing all Applicatives at once
15:02:48 <EvanR> instance ThisOtherThing f => Applicative f where
15:03:41 <jsomedon> hpc: how would I implement pure without using fmap
15:04:12 <hpc> just define it
15:04:15 <jsomedon> EvanR: hpc: pure a = fmap (const a) unit -- this is my verison
15:04:17 <hpc> https://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.Base.html#line-841 - for example
15:04:48 <hpc> oh ugh, i missed that this is specifically for another class
15:04:50 <jsomedon> hpc: ah you mean for a specific type
15:05:10 <hpc> yeah, that will use fmap
15:05:15 <hpc> is this for homework?
15:05:32 <jsomedon> hpc: nope
15:06:09 <jsomedon> hpc: just trying to get my understanding on Applicatives as solid as I can, then EvanR gave me this exercises
15:06:20 <hpc> ah
15:06:35 <hpc> when you go to use Applicative in real code, "instance ThisOtherThing f => Applicative f" has one subtle problem
15:06:49 <hpc> which is you're writing an instance of Applicative for all 'f'
15:07:10 <hpc> and then oh by the way, it has to satisfy ThisOtherThing f
15:07:16 <jsomedon> uh
15:07:20 <hpc> so that means you can't write any more instances without overlapping
15:07:29 <hpc> because they all match f
15:07:57 <jle`> the same way how id :: a -> a, can work for Int -> Int, Bool -> Bool, etc.; an instance Applicative f will work for IO, Maybe, Either e, [], etc.
15:07:58 <jsomedon> ok uhm then I will keep what I learnd from this exercises as just a thought experiment
15:08:02 <jle`> it will overlap for all of those
15:08:08 <hpc> it's still a good thought experiment, yeah
15:08:10 <EvanR> yeah, better implement ThisOtherThing instead :)
15:08:18 <EvanR> since it's equivalent
15:08:30 <hpc> just be ready to write real instances more like that Maybe link
15:08:39 <jsomedon> got it
15:09:04 <EvanR> jsomedon: short story long, Applicative is way more convenient than that formulation
15:09:17 <jsomedon> k
15:09:17 <EvanR> all it is is sort of making Applicative look more monoidal
15:09:34 <EvanR> (which you may not have noticed if you didn't get to the laws)
15:11:10 <jle`> 'convenient'? debatable :)
15:11:37 <jle`> the laws are a little easier to see as intuitive things you might have thought of yourself, though, at least
15:12:04 <EvanR> the usual formulation of Applicative is way more convenient, just to be clear
15:14:41 <dinkpad> pattern matching was the answer again for me, isSameType (Bin _ _ _) Tip = False
15:14:53 <dinkpad> this language is quite strange
15:15:05 <dinkpad> thanks for all the help
15:15:38 <MarcelineVQ> eventually all the others ones seem strange
15:16:49 <jle`> EvanR: ah sorry, i misread what you meant by 'that'
15:17:09 <EvanR> i would love to hear the debate on the utility of the other one :P
15:18:37 <nshepperd> An Applicative is a monoid in a category of endofunctors, where the tensor is Day convolution... i think
15:19:08 <davr0s> speaking of which, has anyone made haskell neural net frameworks
15:19:52 <MarcelineVQ> sure, grenade is an interesting one
15:19:57 <davr0s> or is it pointless with NN frameworks being an interface between IO (setting up problems) and low level computation (CUDA etc)
15:20:00 <nshepperd> (f, unit :: Identity ~> f, combine :: Day f f ~> f)
15:20:30 * hackage google-maps-geocoding 0.5.0.1 - Bindings to the Google Geocoding API (formerly MapsGeocoding API)  https://hackage.haskell.org/package/google-maps-geocoding-0.5.0.1 (mpilgrem)
15:20:49 <jsomedon> nshepperd: what does this ~> notation mean??
15:23:14 <nshepperd> jsomedon: ignore me. (But the answer to your question is f ~> g = forall a. f a -> g a. also called 'natural transformation')
15:24:21 <jsomedon> uh that answer makes me wonder more stuff haha
15:25:20 <jle`> that's the classic haskell trap
15:25:33 <jle`> ask an irrelevant question and get an irrelevant answer that makes you curious to learn more
15:25:41 <nshepperd> haha
15:25:44 <davr0s> yikes
15:25:45 <jle`> end up taking a two month detour to learn a concept that should have taken 2 hours
15:25:50 <jsomedon> haha
15:26:00 <hpc> natural transformations are a pretty interesting detour at least
15:26:42 <evelyn> I asked how to concatenate lists and got a monoid primer instead.
15:26:49 <jsomedon> so uh, can someone explain what that . notation means there?
15:27:02 <jle`> (i tried)
15:27:09 <jsomedon> like `forall a. f a -> g a.`
15:27:16 <jle`> as in, i tried my best to warn you ;)
15:27:16 <heatsink> Have you learned about generics/parametric polymorphism yet, jsomedon?
15:27:29 <jle`> davr0s: there's some good benefits i think
15:27:30 <hpc> the last . is just the end of a sentence
15:27:35 <jsomedon> heatsink: I don't know the term you are mentiioning..
15:27:44 <jsomedon> hpc: ah.. ok
15:27:45 <hpc> the first . is just part of the syntax
15:27:49 <evelyn> It is part of the notation
15:27:50 <jle`> davr0s: one problem with ANN frameworks in other languages is that the programs you build are very brittle
15:27:53 <hpc> it's a separator like the "->" in lambda syntax
15:27:59 <hpc> or "in" in let-in
15:28:02 <jle`> davr0s: this is evidenced by the current fiasco with tensorflow 2
15:28:17 <heatsink> What is up with tensorflow 2?
15:28:19 <jle`> debugging is tough, maintaining is a nightmare
15:28:34 <jle`> heatsink: upgrading anything frmo tf1 to tf2 is going to be a huge nightmare
15:28:39 <jle`> and probably it's better to just rewrite your program
15:28:47 <heatsink> I see
15:29:15 <jle`> davr0s: so the benefit of an ANN library in haskell would be to help use type-driven development and the lego-like nature of haskell types to help you build robust programs that scale and you can maintain long-term
15:30:18 <jle`> there probably wouldn't be any practical benefits in terms of things like performance, for the reasons you mentioned
15:31:41 <EvanR> i'm wondering about the space usage of act >>= k for IO. If act continues to "tail call" and never complete, what happens to this k?
15:32:06 <Squarism> I feel im dealing with something I just dont know. Can anyone spot it? 
15:32:08 <Squarism> https://paste.ofcode.org/Js4Tf9UMfikAGmjkcVWWnj
15:32:22 <Squarism> code, then error
15:32:50 <EvanR> if act then "does" more things like act >>= k, do k's leak?
15:33:04 <jle`> Squarism: is FormEvaluator your own typeclass?
15:33:14 <Squarism> yes
15:33:42 <jle`> it might help to write some instances then of the types you would want to use it with
15:33:45 <jle`> right now there are no instances
15:34:15 <jle`> alternatively you can explicitly ask for an instance of [b] in the constraints of requireRepeat
15:34:21 <jle`> but that's just delaying the inevitable
15:34:38 <EvanR> if so, is there any possible implementation of IO that doesn't leak k's
15:35:36 <jsomedon> so in a notation like f ~> g, f and g are types? and they are, applicatives?
15:35:48 <EvanR> functors
15:35:53 <jsomedon> oh
15:35:56 <Squarism> i have 2 instances but didnt paste them as error was in that function i pasted. (its called by instances)
15:36:08 <Squarism> jle ^
15:36:18 <jle`> jsomedon: f ~> g is just a way of writing `f a -> g a`, where the 'a' must "not matter"
15:36:30 <jle`> they must work for all a's
15:36:30 <heatsink> The intuitive idea is that a natural transformation reorganizes containers without examining their contents.
15:36:42 <jle`> for example, a function like `listToMaybe` can be cosidered [] ~> Maybe
15:36:44 <jle`> :t listToMaybe
15:36:46 <lambdabot> [a] -> Maybe a
15:36:55 <jle`> it is [] a -> Maybe a, but works for any 'a' without caring what it is
15:37:05 <jle`> contrast this to, say, (Just . sum)
15:37:10 <jle`> :t Just . sum
15:37:12 <lambdabot> (Foldable t, Num a) => t a -> Maybe a
15:37:19 <jle`> :t Just . sum :: [Int] -> Maybe Int
15:37:20 <lambdabot> [Int] -> Maybe Int
15:37:26 <jle`> this one doesn't count because it only works if 'a' is Int
15:37:36 <jle`> it "uses" the intiness of the 'a'
15:38:14 <jsomedon> so `aFunction::f ~> g` means, this aFunction can unpack a value in a functor box and pack that into another functor box 
15:38:23 <jle`> not necessarly unpack/pack
15:38:37 <jle`> it just means f a  -> g a, yeah, as long as it doesn't 'touch' any of the a's, pretty much
15:38:53 <jle`> for example this function `myFnction _ = Nothing`, myFunction :: IO a -> Maybe a
15:38:59 <jle`> but it doesn't pack or unpack any functor boxes
15:39:05 <jle`> * myFunction :: IO ~> Maybe
15:39:10 <EvanR> you're clearly allowed to forget some of the a's though heh
15:39:22 <EvanR> or all of them
15:39:42 <jsomedon> so really it just changes the box
15:39:52 <jle`> if by box you mean type constructor then yeah
15:39:55 <jle`> but it works for non-box things
15:39:59 <jsomedon> ah yes
15:40:13 <jsomedon> right, so all those structures
15:40:41 <EvanR> :t \(Identity x) -> (x,x,x)
15:40:43 <lambdabot> Identity c -> (c, c, c)
15:40:52 <jle`> yeah. one nice thing about natural transformations as a concept is that because of parametric polymorphism, you can actually predict a lot of things about their behavior
15:41:02 <EvanR> if (c,c,c) was Triple a = MkTriple a a a
15:41:05 <EvanR> functor
15:41:22 <EvanR> so it could also replicate some of the elements
15:41:56 <jsomedon> very interesting
15:42:22 <jle`> for example, if 'f' is some natural transformation, and g is some normal function, then f (fmap g x) must be equal to fmap g (f x)
15:42:40 <jle`> er, f :: F ~> G, g :: A -> B, x :: F A
15:42:49 <jle`> in all of those cases you get a G B in return
15:43:08 <jle`> but knowing that f is a natural transformation, lets you conclude that it doesn't matter if you fmap-then-transform, or if you transform-then-fmap
15:43:37 <jle`> this is a little abstract, so we can pick some specific natural trnasformations and functions, like `listToMaybe` and `show`
15:43:38 <EvanR> zip then button? or button then zip? With Functor pants doesn't matter
15:43:48 <jle`> > listToMaybe (fmap show [1,2,3])
15:43:50 <lambdabot>  Just "1"
15:43:52 <EvanR> er, Natural Pantsformations?
15:43:55 <jle`> > fmap show (listToMaybe [1,2,3])
15:43:57 <lambdabot>  Just "1"
15:44:15 <jle`> replace 'listToMaybe' with any other natural transformation from lists, and you will still get that equality
15:45:34 <jsomedon> yeah I mean it's like, if I have a box of apple and I am gonna change it into a bucket of banana
15:45:37 <jle`> @let ntLength :: [a] -> Const Int a; ntLength = Const . length    -- ntLength :: [] ~> Const Int
15:45:38 <lambdabot>  Defined.
15:45:44 <dmwit> (Is the pile of dirty laundry on my floor a natural pants formation?)
15:45:45 <jle`> > ntLength (fmap show [1,2,3])
15:45:47 <lambdabot>  Const 3
15:45:55 <jle`> > fmap show (ntLength [1,2,3])
15:45:57 <lambdabot>  Const 3
15:46:41 <jle`> jsomedon: but yeah, the 'point' i guess of invoking the concept is that instead of dealing with all f X -> g X functions, you get to talk about only f a -> g a's that follow certain nice properties
15:47:51 <jsomedon> jle`: so I really focuse on the functionally of changing box of a into bucket of a, but I don't need to worry about if it'
15:48:08 <jsomedon> if it's box of apple or box of banana or box of whatever
15:48:12 <EvanR> dmwit: ok people are still awake out there
15:48:20 <jsomedon> like this?
15:48:48 <EvanR> box of _1 to bucket of _1
15:48:54 <EvanR> not _1 to _2
15:49:01 <jle`> jsomedon: yeah, it's the transformation of 'box', without using any specific property of any of the items inside it
15:49:02 <jsomedon> yeah
15:49:06 <jle`> to use the box analogy
15:49:33 <jsomedon> so it's a function that changes the structure
15:49:39 <jle`> so listToMaybe is a valid natural transformation, because it doesn't use any specific property of Int-ness of the items inside the list
15:49:53 <jsomedon> I see
15:50:01 <jle`> jsomedon: changes the structure in a way that is independent of the types of the values inside it
15:50:03 <jsomedon> it couldbe any list, list of anything
15:50:42 <jsomedon> I see
15:51:04 <jsomedon> so it'x exact opposit of fmap
15:51:06 <jsomedon> uhm
15:51:10 <jsomedon> I mean
15:51:12 <jle`> so one that doesn't count is `myFunc xs = if sum xs > 3 then Just (sum xs) else Nothing`
15:51:16 <jsomedon> functor?
15:51:42 <jle`> because that function uses the numerical properties of the values in the list to determine whether or not to return Just or Nothing
15:51:46 <EvanR> fmap promotes a function on specific things to function on the box
15:52:03 <jle`> jsomedon: hm, i wouldn't really say it's the opposite necessarily; they're actually sort of indpendent concepts that interact together in nice ways
15:52:03 <EvanR> a natural transformation doesn't promote anything
15:52:16 <EvanR> it's a specific operation on the box
15:52:32 <EvanR> it's a function on boxes that must be compatible with fmaps
15:53:08 <jsomedon> uhmm I was trying to say, one(the natrual trans) is touching box but not touching value, the other(thought it's functor but I see not really) touches value but not box
15:53:20 <jle`> ah, that's an interesting way of looking at it
15:53:28 <EvanR> what is the 3rd level thing called? the thing between natural transformations?
15:53:34 <jle`> that's true. fmap f will modify the 'results' but not the structure
15:53:35 <jsomedon> what ?
15:53:48 <jle`> natural transform is allowed to transform the structure, but not touch or modify any specific result
15:53:53 <jsomedon> what 3rd yuou mean EvanR 
15:54:06 <EvanR> there's some categorical thing between two given N.T.'s from f to g
15:54:16 <jsomedon> jle`: yeah I was trying to compare them that way
15:54:17 <EvanR>  hold on
15:54:48 <jsomedon> between two ~>?
15:54:57 <jle`> jsomedon: so one of the consequences of the functor laws is that fmap can't ever change the length of a list
15:55:06 <jsomedon> yeas
15:55:12 <jle`> but natural tnraformations famously can change them
15:55:18 <jle`> one popular one is `take 3 :: [] ~> []`
15:55:23 <jsomedon> yes the outlaw
15:55:34 <jle`> take 3 can clearly modify the length of a list. but it isn't allowed to "touch" any specific value and modify it
15:55:42 <jle`> it has to use values inside it gets as-is
15:56:06 <EvanR> https://math.stackexchange.com/questions/1143252/higher-transformations-between-natural-transformations-and-so-on
15:56:09 <jle`> aside from things like duplicating or forgetting values within the list ... which are all things you can do without inspecting the value itself
15:56:29 <EvanR> apparently it "can't exist" (in any interesting way)
15:56:44 <jle`> jsomedon: this might actually get to the heart of what i was saying earlier with f . fmap g = fmap g . f
15:57:05 <jle`> if f is the natural transformation and g is the value-inside-function
15:57:21 <jle`> jsomedon: then this is saying that 'mapping the values inside, then transforming the shape with a NT, is the same as tranforming the shape with an NT and then mapping the valeus'
15:57:36 <jle`> so fmap and the NT are touching two 'independent' aspects of the value
15:57:39 <jsomedon> yeap
15:57:42 <jsomedon> yeap
15:58:19 <jsomedon> makes sense
15:59:01 <jsomedon> maybe these two can be parallized
15:59:15 <EvanR> talk to conal :)
15:59:22 <jsomedon> parallelized
15:59:26 <jle`> interesting idea :)
15:59:27 <jsomedon> wrong spelling
15:59:29 <jsomedon> I mean
15:59:44 <jsomedon> if I am chaning a box of apple to a bucket of banana
15:59:46 <jle`> in practice we use this pretty often in haskell but mostly for refactoring and performance tweaks/program rewriting
16:00:05 <jle`> a lot of times one order will be faster for the other, so we can recognize this and swap them to get a better program
16:00:17 <jsomedon> I don't have to sequence my works, I can do them with two guys at the same time, one guy change box to bucket, the other guy change the fruits
16:00:38 <jsomedon> oh
16:01:36 <jle`> jsomedon: that's an interesting concept. i think some of the evaluation/laziness based parallelism methods in haskell can take advantage of that
16:02:10 <jsomedon> jle`:  I have no clue what evaluation/laziness based parallelism mean haha
16:03:13 <jle`> ah. what i'm saying is that there are a lot of ways we can do parallel coding in haskell, and one of the ways is methods based on laziness
16:03:33 <jle`> and in those methods it may be able to express the sort of parallelism you are describing
16:03:55 <koz_> I think some important Haskeller wrote a whole book on this.
16:04:43 <jsomedon> is that book beginner friendly?
16:04:58 <jsomedon> I assume not really hah
16:05:06 <jle`> koz_ might be referring to Parallel and Concurrent Programming in Haskell
16:05:12 <jle`> and it actually is pretty accessible
16:05:13 <jsomedon> ah
16:05:24 <jsomedon> oh you mean that is the tile
16:05:25 <jle`> i think it's a good "second book" for learning haskell actually, since it teaches a lot of nice general idioms as well
16:05:27 <jsomedon> title
16:05:54 <jsomedon> nice
16:06:03 <jle`> i think after reading a beginner introduction book to haskell, P&CP is a great second book because it builds on beginner knowledge with robust techniques and useful idioms while teaching neat methods of parlalelism
16:06:06 <hpc> it's a good way to learn concurrency in general too
16:06:07 <koz_> It's very accessible.
16:06:13 <jle`> i definitely wouldn't read it as a first book though
16:06:16 <koz_> It's probably like, the _second_ book I read.
16:06:22 <jle`> or as a way to learn haskell from scratch
16:06:28 <jsomedon> sounds fantabulous
16:06:29 <jle`> actually yeah heh it was my second haskell book
16:06:33 <koz_> Definitely found it very easy to follow, and well-motivated.
16:06:35 <hpc> it gets you thinking about things in a way that's really consistent
16:06:46 <jle`> yeah, it helped me understand concurrency in other languages too
16:07:16 <hpc> a lot of problems become really obvious just from looking in the perspective it teaches
16:07:58 <jsomedon> sounds prefect, I am leanring haskell for the sake of making me a better programmer in general, so that sounds like a must read to me
16:08:48 <koz_> jsomedon: I would agree with jle` that you wanna have a good understanding of Haskell basics before you dive into it.
16:09:06 <jsomedon> ok
16:10:09 <jsomedon> so this book is from Marlow? published by OReilly
16:10:11 <jsomedon> ?
16:10:17 <jsomedon> this one right?
16:10:37 <koz_> jsomedon: I believe so, yes.
16:11:02 <jsomedon> 2013, I assume it's still relevant?
16:11:10 <jellostahps> Hey guys, is this code wrong and the line#12 myor function should be taking in a [Bool] somewhere? https://pastebin.com/tW3WM9hN
16:12:31 <jle`> it should be for the most part, maybe just some API's of libraries are different now
16:12:32 <jellostahps> Because, Line 9 would execute on myOR [Bool] = foldr myor False [Bool]. Which means 'myor' then runs on arguments 'False' and [Bool]
16:13:32 <jle`> jellostahps: your definition of myor seems good on matching the type expected
16:13:50 <jle`> jellostahps: also note, myOr never runs myor on False and a [Bool]
16:13:58 <jle`> it only ever runs the given function on individual values
16:14:32 <jle`> foldr myor False (False:True:False:[])
16:14:46 <jellostahps> jle`: in my understanding of (.) , line#9 would first execute 'myor' and use that result with line #9 foldr, right?
16:14:46 <jle`> becomes myor False (foldr myor False (True:False:[]))
16:15:13 <jle`> jellostahps: you'd have to just look at the dinfiion of foldr
16:15:25 <dmwit> jellostahps: There is no (.) in your paste.
16:16:24 <jle`> jellostahps: if we are trying to see how foldr myor False [False,True,False]
16:16:41 <koz_> jsomedon: Most of it still is. Some of the libraries move a bit quicker than others, but the basics should still be enough for you to figure out what's happening.
16:16:52 <jle`> remember that that is just foldr myor False (False:(True:(False:[])))
16:17:03 <jle`> jellostahps: so to evaluate this, we have to look at the definition of foldr, and see what pattern it matches
16:17:17 <jle`> does it match the case in line #4, or the case in line #5 ?
16:17:18 <jellostahps> isnt  f.g x = f(g(x)) , similarly, foldr myor False [...] = foldr (myor(False [...]). Isn't that the definition of (.)?
16:17:33 <jellostahps> :t (.)
16:17:34 <lambdabot> (b -> c) -> (a -> b) -> a -> c
16:17:37 <jle`> jellostahps: hm, those two things are unrelated
16:17:45 <jle`> foldr myor False [..] is (foldr myor False) [..]
16:17:52 <jle`> (.) isn't used anywhere here
16:18:26 <jellostahps> I though tit was implicitly... ah this is confusing
16:18:35 <jle`> there is no such thing as an implicit (.) :)
16:18:47 <jle`> any more than there would be an implicit (+)
16:18:55 <jellostahps> wh isn't it   foldr (myor False [..])
16:19:09 <jle`> here is how you would look at it, from the beginning
16:19:13 <dmwit> Because it is more common to apply a function to multiple arguments than to apply a function to a complex argument.
16:19:20 <jle`> you are evaluating myOR [False, True, False], right?
16:19:25 <jellostahps> yes
16:19:33 <jle`> so, to do this, you expand things by their definition
16:19:51 <jle`> now it looks like myOR is defined as foldrmyor False
16:20:01 <jle`> so that means that myOr [False, True, False] is (foldr myor False) [False, True, False]
16:20:15 <jle`> hm ... maybe we can look at a simpler situation from algebra
16:20:23 <jle`> let's say you want to expand x * 9
16:20:27 <jellostahps> no that makes sense
16:20:32 <jle`> and i tell you that x = 3 + 5
16:20:38 <jle`> so then x * 9 turns into (3 + 5) * 9
16:20:45 <jle`> it doesn't turn into 3 + (5 * 9)
16:20:57 <jle`> that's because the x is the single unit of 'thing' you are expanding...so you would make sure it stays associated that way
16:21:18 <jle`> that's the same thing that is happening here when we expand myOR [False, True, False]
16:21:29 <jle`> we see that myOr = foldr myor False, just like x = 3 + 5
16:21:41 <jle`> so we can just put in foldr myor False in the place of myOR, just like how we put 3 + 5 in the case of x
16:22:00 <jle`> so that turns myOR [False, True, False] into (foldr myor False) [False, True, False]
16:23:03 <jle`> but in Haskell function application is left-associative, so the parentheses are redundant. we would usually just write ((foldr myor) False) [False, True, False] as foldr mor False [False, True, False], for brevity
16:23:43 <jle`> if we all agree to interpret the latter as the former
16:24:10 <jle`> like how we can write (1 * 2) + 3 as 1 * 2 + 3 if we all agree on PEMDAS, as a society 
16:24:26 * heatsink never agreed to this
16:24:34 <jle`> you might have missed the day we voted
16:24:39 <jellostahps> okay we get (foldr myor False) [...], but aren't we doing this : foldr (myor False [...]) because that is the arguments foldr needs...in which case x*9 -> (3+5)*9 = 3+(5*9)?
16:25:14 <jle`> jellostahps: the second is different from the first
16:25:26 <jle`> just like how (3 - 2) - 4 is different from 3 - (2 - 4)
16:26:06 <jellostahps> okay i get it. so my left associative, u mean look at the function applications starting from the right (so look at foldr as a function before mror),?
16:26:07 <jle`> but you might be trying to say: we are "calling" foldr with the arguments myor, False, and [False, True, False]
16:26:20 <jle`> which is true, writing f 1 2 3 is how we would say we call f with arguments 1, 2, and 3
16:27:04 <jellostahps> jle`: alright thanks, hopefully this will aply globally to other examples I come across
16:27:10 <jellostahps> apply*
16:27:33 <jle`> jellostahps: so the next steps you would take is to look at foldr myor False (False:True:False:[]), and see which of the cases (line 4, or line 5) match
16:27:42 <jle`> if it matches the first, you would replace that whole thing with the RHS of line 4
16:27:51 <jle`> if it matches the second, you would replace the whole thing with the RHS of line 5
16:28:16 <jellostahps> thats the current thing im practicing, im going to look at your answer u r posting once i try it out, thx
16:29:39 <jle`> jellostahps: also i missed one thing you said earlier, but (3 + 5) * 9 is definitely not the same thing as 3 + (5 * 9), heh
17:02:15 <EvanR> i'm starting to think free monads for less part 3 is a red herring
17:04:01 <MarcelineVQ> Is that what your IO question was about earlier?
17:04:44 <MarcelineVQ> this might be relevant to you if so https://www.janis-voigtlaender.eu/papers/AsymptoticImprovementOfComputationsOverFreeMonads.pdf
17:04:58 <EvanR> data MyIO a = PleaseDo :: ffi o i -> o -> MyIO i; IOBind :: IO a -> (a -> IO b) -> IO b, where return could be implemented as an ffi no-op, lets you combine unknown actions together without fmap+join
17:05:14 <EvanR> do not see how to accomplish same thing with their post
17:05:43 <MarcelineVQ> Oh part one of that mentions codensity right away haha
17:05:56 <MarcelineVQ> So my link is probably not gonna add anything useful
17:06:24 <EvanR> instead now to execute act >>= k, recurse on act until you see PleaseDo _ _ >>= k, then execute
17:07:00 <EvanR> (where >>= = IOBind)
17:07:13 <MarcelineVQ> And IOBind is MyIO?
17:07:21 <EvanR> yes, oops
17:07:37 <EvanR> IOBind :: MyIO a -> (a -> MyIO b) -> MyIO b
17:09:48 <MarcelineVQ> What do you mean by k's leaking? The pattern stack blowing up?
17:10:06 <MarcelineVQ> I should probably read/do these posts before asking more
17:10:33 <EvanR> i think i stopped worrying about it, since it doesn't seem like a sane way to program
17:10:47 <MarcelineVQ> Which it?
17:11:09 <EvanR> having an act >>= k, but act never becomes PleaseDo
17:11:14 <EvanR> for whatever reason
17:11:28 <EvanR> like, never leaving an exception handler and even going into new ones
17:13:03 <EvanR> in which case i saw this leaking and fmap+join leaking in a different way
17:13:59 <MarcelineVQ> I'll try to go through these later on and we'll see together
17:20:26 <freeman42xx> any ideas for a solutions to this? https://github.com/haskell/haskell-ide-engine/issues/1404
17:24:09 <rotaerk> hmm, I have this shake file: http://ix.io/1XJx
17:24:50 <rotaerk> if I run `shake spv/shader.vert.spv`, it successfully builds that file from `shaders/shader.vert`
17:25:49 <rotaerk> but if I run `shake spv/*.spv`, when spv/ is empty, it doesn't work
17:26:33 <rotaerk> is there a way for me to configure it so that it will compile all the .frag and .vert files in the shaders/ folder, putting the resulting .frag.spv and .vert.spv files into spv/, even if spv/ is empty?
17:26:42 <rotaerk> without listing each one explicitly within the shake file
17:40:58 <tydeu> Why are there no class families?
17:42:27 <EvanR> there are multi-parameter type classes
17:43:47 <EvanR> (when questioning the meaning of type classes i like to recommend youtube video Type Classes vs The World )
17:43:48 <tydeu> EvanR: That does not allow for type indexed classes though, every constraint of a multi-parameter class still has the same methods
17:44:13 <EvanR> you also have associated type families within a class
17:44:23 <EvanR> which let you name an associated type along with your instance
17:45:26 <tydeu> The reason I ask is that every polymorphic function more or less requires a class, this polutes the namespace. If we had class families, one could write each class as an offshoot of a single dictionary (the family) rather than individual names for each
17:45:52 <EvanR> mkay... so you also have constraint kinds
17:46:04 <EvanR> now you can parameterize the contraints instead of hard coded them as whatever class
17:47:15 <EvanR> and i have seen people reflect dictionaries
17:47:35 <EvanR> which uses uh... GADTs ?
17:47:45 <EvanR> and black magic
17:47:49 <tydeu> EvanR: I'm confuse as to how ConstraintKinds or GADTS helps with my example?
17:47:52 <lyxia> I don't understand what your solution that doesn't "pollute the namespace" looks like
17:48:45 <jsomedon> I saw this online that data cotr are natural transformation??
17:49:15 <jsomedon> so like Just is a natural trans? is this correct?
17:49:48 <EvanR> you'd have to identify the two functors the natural transformation is between, at least, before that made sense
17:50:25 <jsomedon> so in case of `Just`, does this saying hold?
17:50:56 <jsomedon> Just is a value to functor right? not a functor to functor
17:51:05 <jsomedon> I mean if Just is a function
17:51:20 <EvanR> yeah category theory has a way of not yielding to "kinda" 
17:51:32 <EvanR> either there are two functors involved, or it's not a NT
17:51:36 <jsomedon> ok
17:51:39 <lyxia> It's hard to answer those questions because they make no sense.
17:52:06 <jsomedon> I just saw this online, wondered if it's valid or not
17:58:24 <lyxia> Can you provide more context
18:02:34 <jsomedon> lyxia: https://www.reddit.com/r/haskell/comments/6k1sob/are_value_constructors_natural_transformations/
18:03:54 <EvanR> myJust (Identity x) = Just x   would qualify
18:04:08 <EvanR> F=Identity G=Maybe
18:04:10 <jsomedon> so really we need that Identity right
18:04:13 <EvanR> i don't know about all data constructors
18:04:17 <rotaerk> ah... I think I see the answer to my shake problem...
18:04:29 <EvanR> for instance ... Nothing
18:05:56 <jsomedon> yeah
18:07:07 <jsomedon> so back to Just, what I am confused is, its type is a -> Maybe a, but not Identity a -> Maybe a?
18:07:09 <jle`> jsomedon: you can sort of imagine Just (the function) as a natural transformation Identity ~> Maybe. it doesn't fit cleanly into this neat picture
18:07:26 <jle`> but `Identity a` is the same as 'a'
18:07:31 <jle`> when we analyze things, we treat them as the same type
18:07:35 <jsomedon> oh
18:07:39 <jle`> newtype Identity a = Identity a
18:07:51 <jle`> we just use things here to get things in the proper "kinds" to match up
18:08:03 <jle`> sort of like book keeping/boilerplate
18:08:17 <jsomedon> you mean both conceptually and in terms of language implementation, they are same thing?
18:08:35 <jle`> Just is a -> Maybe a, but if we imagine the 'identical' function newJust (Identity x) = Just x; newJust :: Identity ~> Maybe
18:08:41 <jle`> then we get to think of it as if it were a natural transformation
18:08:50 <jsomedon> yea
18:09:00 <jle`> in terms of the actual language we have to put up with basically what is syntactical noise
18:09:07 <dmwit> (It may be worth introducing the difference between functors and Functors at some point.)
18:09:40 <jsomedon> huh?
18:10:11 <jle`> ah we use the capital vs. lowercase distinction to indicate the difference between the actual concepts vs. the in-language typeclasses we use to represent some manifestations of them
18:10:14 <dmwit> Category theory has a concept of functors that is more general than the Functor typeclass in Haskell.
18:10:17 <jle`> for example, Int is a monoid but not a Monoid
18:10:22 <jsomedon> ah
18:10:26 <dmwit> (Int, (+), 0) is a monoid
18:10:37 <jle`> Int you can think of as monoidal with + or *  -- yeah, what dmwit is clarifying
18:10:38 <dmwit> Sum Int is a Monoid
18:10:38 <jsomedon> monoid, I didn't learn it yet
18:10:45 <jle`> but in haskell you won't see it have a Monoid instance
18:10:56 <jle`> ah it's kind of funny that you're learning about functors and applicatives etc. before monoids
18:11:01 <dmwit> There is an identity functor which just literally takes a type and spits it back out.
18:11:05 <EvanR> Identity Int isn't the same type as Int. (Identity is a newtype after all). But Identity Int is isomorphic to Int
18:11:23 <EvanR> why? to confuse you
18:11:23 <dmwit> But there is no Functor which does that. The Identity type constructor is a Functor that takes a type and spits out an *isomorphic* type, which is very close.
18:11:47 <jsomedon> hum the book I am reading introduces Functor -> Applicatives -> Monad, maybe it talked about Monoid and I somehow skipped???
18:12:05 <EvanR> Monoids kind of underlie everything
18:12:06 <jle`> yeah that's ... interesting
18:12:06 <dmwit> So: with this distinction in mind, Just is a fine natural transformation between the identity functor and the Maybe functor.
18:12:08 <jle`> what book is it?
18:12:25 <jsomedon> Programming in Haskell by Garahm I think?
18:12:39 <jsomedon> Graham
18:12:43 <dmwit> But to make it a natural transformation between Functors, you have to do an isomorphic thing and make it Identity . Just to be a transformation between the Identity Functor and the Maybe Functor.
18:12:49 <rotaerk> jle`, were the types different from today when you wrote https://blog.jle.im/entry/shake-task-automation-and-scripting-in-haskell.html ?
18:12:52 <jsomedon> Hutto
18:12:53 <jle`> ah, interesting
18:12:54 <jsomedon> Hutton
18:12:58 <jle`> rotaerk: very likely different
18:13:07 <jle`> i think that was one of the very first blog posts i ever wrote, in like 2013 ?
18:13:14 <rotaerk> I see you're doing `need <$> srcFiles` but I think you'd need `need =<< srcFiles`
18:13:18 <rotaerk> ah k
18:13:30 <rotaerk> it's been helpful regardless :P
18:13:31 <jle`> rotaerk: ah wait, is srcFiles a list i defined there?
18:13:46 <rotaerk> srcFiles is a `Action [FilePath]` you defined
18:13:52 <jle`> oh
18:14:09 <jle`> then...that looks wrong even in 2013
18:14:12 <rotaerk> heh
18:14:48 <jle`> that was back before i implemented the system where i code in an actual haskell file ... so i didn't yet typecheck stuff
18:14:55 <rotaerk> lol
18:15:05 <jle`> thanks for the catch :)
18:15:12 <koz_> jle`: Any chance that could get an update?
18:15:23 <koz_> I'm thinking of using Shake for something, and your exposition would be awesome to have.
18:15:43 <rotaerk> btw one thing I noticed that changed is *> was replaced with %>, due to the former's clash with applicative
18:16:51 <jle`> koz_: i thiiink for the most part things should be the same, with minor type things like ^
18:17:06 <jle`> i actually use shake still to build my blog
18:17:14 <jle`> (which is static)
18:17:14 <koz_> jle`: Even more reason to have an update. :P
18:17:30 <jle`> so apparently it has worked without much changes for all these years
18:17:34 <jle`> ah yeah, might as well just make it modern
18:18:14 <koz_> I tried to get into Shake several times, but the official docs have put me off quite badly.
18:18:20 <koz_> (similar sentiment to Dhall)
18:19:11 <jsomedon> dmwit: do you mean Just . Indentity??
18:19:31 <jle`> huh i always thought dhall docs were pretty nice. shake has some good examples too
18:19:38 <jsomedon> dmwit: I mean like JustThatIsNT = Just . Indentity
18:20:06 <jellostahps> you can't explicitly do this without a function right? [1,2]:[3,4]
18:20:52 <koz_> jle`: Maybe I'm strange, but Dhall docs confuse me and seem to not track the current version, and the Shake docs also confuse me.
18:21:16 <jle`> ah yeah. dhall moves ... blazingly fast
18:21:20 <koz_> (at least last I checked both, which was a few months ago for both)
18:21:25 <jle`> jellostahps: Just . runIdentity
18:21:33 <jle`> er sorry that was for jsomedon ^
18:21:47 <jle`> jellostahps: what are you trying to do
18:21:52 <jle`> do you want to get [1,2,3,4] as a result?
18:21:55 <jellostahps> [1,2,3,4]
18:22:06 <jellostahps> yea
18:22:12 <jellostahps> i know how to do it with append
18:22:13 <jle`> because [1,2]:[3,4] would give you [[1,2],3,4], which doesn't typecheck nicely usually
18:22:19 <slack1256> What is the usefulness of the "Any type family"? The docs says you can safely `unsafeCoerce` any lifted type and back. I don't know why I would want that.
18:22:41 <jle`> jellostahps: yeah, getting [1,2] and [3,4] into [1,2,3,4] is best done using a function
18:22:51 <jle`> but then again so is getting 1 and [2,3] into [1,2,3], with the (:) function
18:22:54 <jellostahps> :t (:)
18:22:55 <lambdabot> a -> [a] -> [a]
18:23:13 <koz_> slack1256: Heterogenous lists I guess.
18:23:16 <jellostahps> okay I see, interesting
18:23:19 <jle`> slack1256: are you familiar with Data.Dynamic
18:23:31 <jle`> it's basically an unsafe version of Data.Dynamic's Dynamic
18:23:48 <CSP-SOFT>    b='i'
18:24:04 <slack1256> jle`: I know about Dynamic (I've never used outside toy programs though)
18:24:04 <EvanR> Any and unsafeCoerce is for when you think you're smarter than the type system
18:24:19 <EvanR> which is rare ime
18:24:21 <jle`> slack1256: so basically it's like the situations where you would use Data.Dynamic, except unsafer
18:24:37 <jle`> a lot of times i draft my code using Data.Dynamic, and then switch to Any once I know it works, for performance
18:24:52 <jle`> so it's like a 'faster' version of Data.Dynamic, where you trade type-safety for speed
18:25:04 <CSP-SOFT> were i is 'for a in {a..z} ; do printf $a ; done
18:25:13 <CSP-SOFT> try thiz
18:25:21 <slack1256> I see, seems useful.
18:25:25 <jle`> if you can imagine a situation where you would use Data.Dynamic, you can think of Any as being a faster and unsafer alternative for those same situations
18:25:28 <EvanR> big difference, Dynamic involves a type-representation check, unsafeCoerce doesn't and doesn't care what you use it on
18:25:41 <slack1256> Does it complicate the consistency of the type system?
18:25:52 <jsomedon> jle`: ah so this runIndentity is like :: a -> Identity a ?
18:26:02 <jle`> :t runIdentity
18:26:04 <lambdabot> Identity a -> a
18:26:07 <jle`> :t Just . runIdentity
18:26:09 <lambdabot> Identity a -> Maybe a
18:26:19 <jle`> slack1256: not really any more than fromJUst does
18:26:23 <jsomedon> ahahah
18:26:30 <jsomedon> right
18:26:36 <CSP-SOFT> a = a++ < 13
18:26:59 <jle`> slack1256: just think of it like fromDynamic only instead of returning `Maybe a`, it returns `a` and error "bad bad bad" instead of Nothing
18:27:20 <slack1256> jle`: I see, you're right.
18:27:32 <EvanR> except unsafeCoerce doesn't do that
18:27:34 <jle`> only instead of error "bad bad bad" you might sometimes not get an error and your program keeps on chugging along until something later down the line crashes
18:27:40 <EvanR> it causes monkey's to fly out of your nose
18:28:11 <jsomedon> jle`: I do :t runIdentity on my repl and it throws error.. how come you :t on it here and it works?
18:28:23 <jsomedon> jle`: not a builtin?
18:28:25 <jle`> jsomedon: you might have to import it
18:28:28 <jle`> from Data.Functor or something
18:28:28 <slack1256> Another question
18:28:32 <jsomedon> oh ok
18:28:53 <jle`> slack1256: the main thing to worry about is you might accidentally false-positive a dynamic'd False as LT or something
18:29:00 <koz_> Data.Functor.Identity I think.
18:29:10 <jle`> so using Dynamic if you pack a False and unpack it back into an Ordering, you'll get a Nothing
18:29:28 <jle`> but using Any/unsafeCoerce if you pack a False and unpack it back into an Ordering it'll just happily give you LT (for GHC)
18:29:31 <jsomedon> koz_: works :-)
18:29:32 <CSP-SOFT> if a could be =b a=c a=d at the same time? nop
18:29:45 <jellostahps> If expressions are left associated, then how is this evaluating? a:(b:c:d:[]). Assume a,b,c,d are all Chars. Does a:(...) run first or does it run from the right?
18:29:51 <CSP-SOFT> only on quantum pc
18:29:57 <jle`> slack1256: but because these things usually are boxed, you won't get anything too messed up like segfaults
18:30:13 <jle`> jellostahps: expressions are not left-associative
18:30:21 <jle`> (:) is right-associative
18:30:33 <jle`> `a:(b:(c:(d:[])))` is already fully-evaluated
18:30:40 <jle`> at least, up to the list constructors
18:30:46 <EvanR> you get worse than segfaults, you get wrong answers
18:30:47 <jle`> so there isn't anything deeper to go down
18:30:51 <jellostahps> wait, then what is left associated?
18:30:56 <jle`> jellostahps: function application
18:31:07 <jle`> f 1 2 3 is ((f 1) 2) 3
18:32:00 <jle`> jellostahps: but for a:(b:(c:(d:[]))), you're already "done"
18:32:13 <jellostahps> hmm
18:32:40 <jle`> yeah, i would never just write my program directly with Any first
18:32:42 <slack1256> Now a question about "open variants". On Ocaml these are open sum types, if we had them the Either monad for error handling would be more useful, as we wouldn't have to think a priori each failure state but at the `runEither` call site. What is the idiomatic way to archive this?
18:32:45 <jellostahps> (:) is a function definition and is right associated
18:32:58 <jle`> i've tried that before and only got nothing but sadness and misery
18:33:14 <slack1256> I know IO exceptions are extensible in that sense, but aren't case-checked at `catch` call-site.
18:33:14 <jsomedon> what does (***) do?? typed :t on it and didn't work
18:33:19 <CSP-SOFT> jle' quantum entanglement does nothing to do with arrays multitasking! me I want a =b = c = d per quantum entanglement spin but not per nanosecond
18:33:22 <jle`> nowadays i just use Dynamic and switch to Any once I know my code is correct, and only if the performance is worth it
18:33:31 <koz_> > :t (***)
18:33:33 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
18:33:39 <koz_> :t (***)
18:33:40 <lambdabot> Arrow a => a b c -> a b' c' -> a (b, b') (c, c')
18:33:51 <jle`> jsomedon: for the most part, people used to use it before we had bimap in base
18:33:59 <jle`> > bimap (*2) not (5, True)
18:34:00 <lambdabot>  (10,False)
18:34:05 <koz_> Yeah, it's basically a more general bimap I think.
18:34:06 <jle`> but now that we have bimap it is mostly useless
18:34:16 <jle`> it's not quite a more general bimap; it generalizes in a "different direction"
18:34:24 <jle`> but a direction that people usually don't care about
18:34:37 <koz_> Yeah, because instead of (->) you have a more general 'a'.
18:34:42 <koz_> (I think)
18:34:51 <jsomedon> so bimap is like mapping a function on two boxes instead of one
18:34:53 <jle`> here we're using foo :: (a -> c) -> (b -> d) -> (a, b) -> (c, d)
18:35:05 <jle`> bimap asks "what if i generalize over (,)?"
18:35:13 <jle`> (***) asks "what if i generalize over (->)?"
18:35:26 <koz_> Galaxy brain asks "What if I generalize over both?".
18:35:42 <jle`> > bimap (*2) not (Left 3)
18:35:44 <lambdabot>  Left 6
18:35:48 <jle`> > bimap (*2) not (Right True)
18:35:50 <lambdabot>  Right False
18:36:14 <koz_> (said galaxy-brain function needs to be named b***p obviously)
18:36:30 <jle`> that's reason enough to lobby for mixed operator/letter names
18:36:38 <jsomedon> oh wait so, it's mapping two f, and each f goes to corresponding postion on the box?
18:36:51 <jle`> yeah, for tuples
18:37:03 <koz_> Tuples are the most obvious Bifunctor example.
18:37:05 <jle`> if you're reading it it's 80% probably going to be on tuples
18:37:07 <koz_> I think Kleisli is another.
18:37:26 <jle`> the common bifunctor examples are Tuples and Either
18:37:28 <koz_> (no wait Kleislis are profunctors not bifunctors, derp)
18:37:38 <jle`> the common arrow examples are (->) and kleisli :)
18:37:48 <jle`> but don't worry too much about Arrow, it's more or less a dead abstraction
18:37:55 <koz_> So -> and >=>. :P
18:38:31 <koz_> jle`: I think HXT is the biggest remaining user of Arrow.
18:39:00 <jsomedon> so in terms of how generally it is used, bimap is not as general as fmap? because it's only used structures with exactly two thing? like `SomeType a b`?
18:39:19 <jle`> yeah
18:39:21 <jle`> :t fmap
18:39:23 <lambdabot> Functor f => (a -> b) -> f a -> f b
18:39:24 <jle`> :t bimap
18:39:25 <lambdabot> Bifunctor p => (a -> b) -> (c -> d) -> p a c -> p b d
18:39:36 <jle`> you can imagine the next level, a hypotehtical trimap
18:39:38 <jsomedon> Bifunctor... that's how you guys call it?
18:39:54 <jsomedon> hypothtical? I thought it does exists
18:40:03 <koz_> jsomedon: I'm not aware of a Trifunctor.
18:40:08 <jle`> trimap :: Trifunctor p => (a -> b) -> (c -> d) -> (e -> f) -> p a c e -> p b d f
18:40:10 <koz_> Or Triapplicative, etc.
18:40:20 <jle`> it "exists" in a mathematical sense but it's not a common haskell abstraction
18:40:36 <koz_> Other than (,,), I can't think of a natural example of a Trifunctor.
18:40:37 <jle`> also there aren't really many instances you would encounter
18:40:42 <koz_> Or a natural application of them either.
18:41:03 <jle`> 2 seems to be a sweet spot for a stopping point
18:41:18 <koz_> I guess it's also why we have Eq1 and Eq2, but not Eq3 etc.
18:41:25 <jle`> even bifunctor is sort of controversial because there aren't that many Bifunctor instances either
18:41:29 <jellostahps> jle`: You sai (foldl myor False) [True] was left associated, and tey are a bunch of functions, so why is 'a':'b':'c':'d':[] right associated?
18:41:32 <jsomedon> then uhm, this bimap must be really useful, at least sovles some problems occuring frequenlty, for having a seat in haskell
18:41:42 <jle`> most of the instances are basically variations of tuple and either
18:41:58 <jle`> jsomedon: it's definitely not as useful as Functor but enough people wanted it, heh
18:42:09 <koz_> jsomedon: Speaking only for myself, I've found bimap to be useful in function pipelines where I have to process two things in different ways, then combine them back together again.
18:42:12 <jle`> jsomedon: here (:) is an operator
18:42:18 <jle`> jellostahps: here (:) is an operator
18:42:18 <koz_> It doesn't happen often, but it's really handy when I need it.
18:42:26 <jle`> so it has its own association rules
18:42:30 <jsomedon> and not enough people wanted trimap or even quadmap as badly as bimap?
18:42:33 <jellostahps> so if it is infix it is always an operator?
18:42:38 <jle`> jellostahps: yes :)
18:42:49 <jellostahps> so :t (:) does not apply to infix?
18:42:51 <jle`> jsomedon: i don't think anyone has ever wanted trimap
18:42:53 <koz_> jsomedon: I don't think anyone has ever asked for Trifunctors as a thing.
18:42:58 <jle`> heh, jynx?
18:43:01 <koz_> jle`: Who owes who a soda now?
18:43:02 <jsomedon> alright
18:43:09 <jle`> jellostahps: 1+2 is sugar for (+) 1 2
18:43:17 <jellostahps> yes
18:43:38 <EvanR> bimap is enough to emulate a trimap
18:43:42 <jle`> so 1:2:3:[] is sugar for (:) 1 ((:) 2 ((:) 3 []))
18:43:55 <koz_> I believe bimap can be used to emulate *map for any * over 2.
18:43:58 <jle`> and at that point we're back to normal function application, which associates how it do
18:44:12 <koz_> You can have dodecamap if that's what you need. :P
18:44:15 <MarcelineVQ> ​:t applies to expressions and an infix operator all by itself isn't quite an expression
18:44:19 <EvanR> next we need infinite dimensional fmap
18:44:24 <jle`> like i said even Bifunctor is of questionable utility
18:44:40 <jle`> "i want to use the same mapping function for both (,) and Either!"
18:44:42 <MarcelineVQ> as opposed to something like :info which doesn't require an expression, e.g. :info :
18:44:42 <jle`>   but like ... why
18:44:58 <jellostahps> jle`:  'a':'b':'c':'d' :[]    =  (:) 'a' 'b' ... wouldn't this lead to a type error since 'b' isn't a list?
18:45:06 <koz_> jle`: I mostly treat bimap as if it only worked on (,), so if it were specialized to (,), I wouldn't notice. :P
18:45:09 <jellostahps> :t (:)
18:45:10 <lambdabot> a -> [a] -> [a]
18:45:19 <jle`> jellostahps: that's 'a':('b':('c':('d':[])))
18:45:26 <jle`> so you get (:) 'a' ((:) 'b') ... )
18:45:32 <jle`> so no type errors :)
18:45:48 <jle`> jellostahps: howver if you did do ('a':'b'):[], you would get some type errors indeed
18:46:11 <jellostahps> how the hell do u type so fast, any reccomended typing practce websites that are coding specific?
18:46:33 <jle`> before we started typing i actually prepared a list of possible messages i might send
18:46:39 <jle`> so i just copy and paste from it based on your responses
18:46:39 <jellostahps> :D
18:46:41 <MarcelineVQ> he's predicted the conversation and has the lines prepared ahead of time
18:46:44 <MarcelineVQ> ffffff-
18:46:51 <koz_> jle` is an elaborate neural net.
18:46:55 <jellostahps> :t jle'
18:46:56 <lambdabot> error: Variable not in scope: jle'
18:47:00 <koz_> (a dependently-typed one at that)
18:47:04 <jle`> technically true i suppose? but i'm a BNN
18:47:04 <jellostahps> guess u arent a haskell function
18:47:08 <EvanR> in before, he prepared a bunch of responses before the convo started
18:47:14 <EvanR> dang
18:47:15 <jle`> jellostahps: yup i'm a machine code instruction
18:47:29 <EvanR> "including this one"
18:47:37 * Clint squints.
18:47:42 <koz_> Jump if Less Than or Equal To.
18:47:50 <jsomedon> lol
18:48:01 <jsomedon> I also wondered how come he types so fast
18:48:17 <jellostahps> koz i actually have no diea if u r joking now
18:48:18 <koz_> jsomedon: As I said, elaborate dependently-typed neural net.
18:48:19 <EvanR> probably covfefe
18:48:20 <jellostahps> idea*
18:48:29 <koz_> inb4 someone links jle`'s library for dependently-typed neural nets.
18:48:29 <jsomedon> lol
18:48:35 <koz_> jellostahps: I am almost never serious.
18:48:44 <koz_> (as anyone who spends any length of time in here can attest to)
18:48:59 <koz_> I either ask stupid Haskell questions, make stupid meme jokes, or occasionally say something sensible.
18:49:03 <MarcelineVQ> Except for just now.
18:51:38 <koz_> Speaking of dependently-typed backpropagation libraries: http://hackage.haskell.org/package/backprop
18:55:13 <freeman42xx> how can we use cabal repl, ghci and ghcid with GHCJS?
19:13:03 <rotaerk> hmm ... I added this to my cabal file:  shaders/spv/*.spv
19:14:04 <rotaerk> and I do indeed have two *.spv files in <project>/shaders/spv/
19:14:38 <rotaerk> when I cabal run, it gives me the path to these when I call getDataFileName
19:14:57 <rotaerk> but when I run `cabal install`, it says:  cabal: filepath wildcard 'shaders/spv/*.spv' does not match any files.
19:15:07 <rotaerk> any idea why?
19:18:07 <rotaerk> whoops.  I should've said I added this to my cabal file:  data-files: shaders/spv/*.spv
19:20:58 <jellostahps> jle`: Ah I just cant wrap my mind around it. Would u be able to give explicit examples of left and right association. In both function definitions, and in expressions?
19:21:24 <rotaerk> oh I see... I think there's a bug in cabal's wildcards
19:21:51 <jellostahps> Like this is a function definition:    f :: x -> y -> z . And I understand what is meant by right associated here.
19:22:16 <rotaerk> my shaders/spv/ path contains "shader.vert.spv" and "shader.frag.spv"; these aren't matching "*.spv"
19:22:21 <rotaerk> but if I add a "blah.spv", that matches
19:22:31 <rotaerk> basically, it doesn't like the double dot
19:24:05 <jellostahps> Nut when it comes to expressions. f x y z  = x+y+z is tight associated, but f x y z = funcX funyY Z is left associated (as in f x y z = (funcX funcY) Z)
19:25:03 <jellostahps> So if there are no operators, in the expression, it is left associated, otherwise it is right associated?
19:26:01 <rotaerk> ah... wildcard matching was fixed for 3.0, and even though I'm running 3.0, it wasn't in effect because my cabal file has an old cabal-version specified...
19:27:19 <rotaerk> jellostahps, left/right association refers to when you have, say, `a % b % c` where % is some binary operator
19:28:11 <rotaerk> if it's left-associative, then that will be evaluated as `(a % b) % c`.  if it's right-associative, it'll be evaluated as `a % (b % c)`
19:28:55 <rotaerk> for, say, + or *, the associativity doesn't *matter* because they are "associative" operators.  as in `(a + b) + c == a + (b + c)``
19:29:14 <rotaerk> but that's not true for all operators.  for instance `(a - b) - c` doesn't match `a - (b - c)`
19:29:38 <rotaerk> which means that it *matters* whether - is left or right associative when you read `a - b - c`
19:30:54 <rotaerk> because (-) is left-associative, you can count on `10 - 3 - 1` being evaluatedd to 6.  if it were right-associative, then it would evaluate to 8, or `10 - (3 - 1)`
19:31:02 <rotaerk> jellostahps, do you follow so far?
19:31:13 <jellostahps> yes ik what left and right association are
19:31:31 <rotaerk> well for function application, you can look at the space between the function and its argument as an operator
19:31:59 <rotaerk> `f x y` is equal to `(f x) y` if function-applicattion is left-associative, and it's equal to `f (x y)` if it's right-associative
19:32:05 <rotaerk> in haskell it's left associative
19:32:28 <jellostahps> is f x y the left side of an expression?
19:32:43 <rotaerk> it *is* an expression
19:33:01 <jellostahps> i know an expression to be f x y = x+y for example it has a left and right side
19:33:13 <rotaerk> `f x y = x+y` isn't an expression
19:33:30 <jellostahps> what is it called then?
19:33:36 <jellostahps> f :: int -> int
19:33:42 <jellostahps> f x y = x + y
19:33:48 <EvanR> f x y = x + y   <---- an equation
19:34:06 <jellostahps> is it also called an evaluation?
19:34:09 <rotaerk> I think the term in haskell is binding
19:34:26 <EvanR> it implies bindings to x and y in this case
19:34:37 <EvanR> it's not an evaluation
19:34:51 <jellostahps> then whats an evaluation? :(
19:35:00 <EvanR> also at some level equations are also expressions, but not the kind you can have on either side, in this case
19:35:05 <rotaerk> evaluation is the reduction of an expression to a value
19:35:41 <rotaerk> e.g. bringing `1 + 2 + 3` to 6 is evaluation of the expression `1 + 2 + 3`
19:36:00 * hackage staversion 0.2.3.2 - What version is the package X in stackage lts-Y.ZZ?  https://hackage.haskell.org/package/staversion-0.2.3.2 (debugito)
19:36:59 <jellostahps> okay, I guess my quesiton is specific to an equaltion then.
19:37:00 * hackage predicate-transformers 0.1.0.0 - A library for writing predicates and transformations over predicates in Haskell  https://hackage.haskell.org/package/predicate-transformers-0.1.0.0 (edmundnoble)
19:37:33 <EvanR> f x y = x + y -- also in haskell "defining equation"
19:37:37 <rotaerk> I'm not aware of "associativity" being relevant to a binding
19:37:53 <rotaerk> unless you're adding an associativity to it, for when the bound thing is later used
19:38:23 <jellostahps> f x y = foldr map someFunct [x,y] is evaluated as left associated. But f x y z = x:y:z:[] is right associated? What is going on on the right side of the equation?
19:39:13 <jellostahps> (foldr map someFunct) [x,y]    vs     (x:(y:(z:[])))
19:39:24 <rotaerk> jellostahps, `foldr map someFunct [x,y]` is evaluated as `((foldr map) someFunct) [x,y]`, because function-application is left associative
19:39:36 <rotaerk> and (:) is right-associative
19:39:47 <tydeu> a decelaration
19:39:52 <EvanR> yeah not much to do with the equation as much as the right side
19:39:53 <jellostahps> yeah but Y
19:40:15 <jellostahps> whats the difference b/w a functino-application and a (:) in my example?
19:40:15 <rotaerk> because that's how (:) is defined
19:40:54 <rotaerk> function application is built-in to the syntax, so that's just the language saying it's left-associative.  (:) on the other hand can be re-written manually, and explicitly declared as right-associative
19:41:03 <EvanR> try to define the associative of function application and : backwards, you'll find it won't work very well
19:41:41 <rotaerk> for instance define this:  `x @#$ y = x + y; infixl 6 @#$`
19:41:46 <jellostahps> :t (:)
19:41:47 <lambdabot> a -> [a] -> [a]
19:41:50 <jellostahps> :t foldr
19:41:52 <lambdabot> Foldable t => (a -> b -> b) -> b -> t a -> b
19:42:02 <jellostahps> aren't they both right associated then?
19:42:22 <EvanR> foldr doesn't have an associativity of it's own, but it's a function so application is left assoc
19:42:35 <EvanR> you can define operators with whatever assoc you want
19:42:36 <rotaerk> or maybe a better example is:  x @#$ y = x - y; infixl 6 @#$
19:42:44 <rotaerk> 5 @#$ 6 @#$ 7 = -8
19:42:52 <jellostahps> where can I 'see' that (:) is right associated?
19:42:59 <EvanR> @src (:)
19:42:59 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
19:43:02 <rotaerk> but if you change the infixl to infixr, suddenly 5 @#$ 6 @#$ 7 evaluates to 6
19:43:06 <EvanR> it might be built in
19:43:15 <jsomedon> wow what's that @#$ thing, is that a varibale name you just defined?
19:43:20 <rotaerk> jellostahps, open up ghci, and do:  :i (:)
19:43:47 <rotaerk> jsomedon, it's a custom operator yes; not something I'd ever actually use, I think
19:43:52 <rotaerk> not the prettiest operator name :P
19:44:10 <jsomedon> I really wodner what chars are valid for varibale name
19:44:22 <jellostahps> smh so functions also have right and left associativity attributes, jeez
19:44:41 <rotaerk> jellostahps, binary operators do.
19:44:44 <EvanR> operators have a much wider alphabet allowed
19:44:54 <rotaerk> though functions can be wrapped in `` to turn them into binary operators, and in that case they do as well
19:44:58 <jsomedon> you mean liek the space alpahbet
19:45:08 <jellostahps> so anything not a binary operator will be left associated?
19:45:08 <EvanR> > let x ☃ y = (x,y) in 4 ☃ 'c'
19:45:10 <lambdabot>  (4,'c')
19:45:16 <jsomedon> spaceship alphabet
19:45:23 <jsomedon> <$> <*>
19:45:58 <rotaerk> jellostahps, run this in ghci:  minus x y = x - y; infixl 6 `minus`
19:46:06 <rotaerk> then rrun:  10 `minus` 3 `minus` 1
19:46:18 <rotaerk> you'll see it evaluates to (10 `minus` 3) `minus` 1
19:46:19 <tydeu> All operators including functions have an associativity and precedence. If not specified operators have a precedence of 9 and are left associated
19:46:21 <rotaerk> or 6
19:46:46 <EvanR> ah
19:46:49 <rotaerk> then re-run the definition of minus, but change its associativity to r, and you'll see the result change
19:48:02 <tydeu> Note that signatures (`::`), function arrows (`->`), and function application (`f a`) are not real operators and thus work differently
19:48:22 <jellostahps> okay so in my example,   (foldr map someFunct) [x,y]  , what if we have (foldr (:) someFunct) [x,y]
19:48:36 <jellostahps> both function application, and a right associated operator, which takes precedence?
19:48:58 <jellostahps> (assuming this equation somehow works)
19:49:09 <rotaerk> jellostahps, the associativity of (:) doesn't matter there, because you're not applying it as a binary operation
19:49:26 <rotaerk> it's only relevant in the context of `a : b`
19:49:34 <jellostahps> ooh, okay that clears it up a bit, it is used as a function and not an operator
19:50:08 <jellostahps> So if function application -> left associated. If operator application <- depends on if operator is left or right associated?
19:50:38 <tydeu> Note: just as the tick mark turns identifiiers into operators (`\`minus\`` is an operator )  parentheticals turn operators into identifiers (`(:)` is an identifier) 
19:50:56 <jellostahps> identified is a function?
19:51:03 <rotaerk> jellostahps, with function application you can think of the space between the function and the argument as a sort of binary operator ... sortof
19:51:15 <rotaerk> and in that sense, the function application "operator" has left associativity
19:51:37 <rotaerk> but it's distinct from actual binary operators; it's its own distinct language mechanism
19:53:02 <jellostahps> I just wanna check my understanding. So,these are all 'equations', not expressions, and the only 2 that are equivalent are i) and iv) ?
19:53:05 <jellostahps> https://pastebin.com/Zjnv5BBP
19:53:26 <rotaerk> all those are expressions, not equations
19:53:30 <rotaerk> do you see an equals sign? :P
19:53:58 <EvanR> none of this has to do with equations
19:54:09 <tydeu> jellostahps: Operators are functions -- the distinction being made here is between syntatic operators (i.e. mostly non-alphanumeric words) and identifiers (mostly alphanumeric words) both of which can be used to represent functions
19:56:05 <tydeu> jellostahps: If you're curious, it might be worthwhile to look through the haskell report: https://www.haskell.org/definition/haskell2010.pdf
19:56:29 <jellostahps> alright ty for help ppl.
19:56:55 <tydeu> Of note is section 2.4 Identifiers and Operators
20:08:40 <dmwit> jsomedon: Oof, two mistakes in one. I meant Just . runIdentity, not either of the ones you or I said at first. ^_^
20:18:21 <rotaerk> koz_, https://github.com/Rotaerk/vulkanTest/tree/master/sandbox/sandbox
20:18:32 <rotaerk> a shake file I just finished getting working
20:18:38 <rotaerk> in case you're interested in seeing it as an example
20:19:08 <koz_> Is there a way _not_ to jam all the build targets into main?
20:19:39 <koz_> Like, I can understand what that says, but the fact all the build targets are jammed into main like that kinda bothers me.
20:19:48 <rotaerk> I'm not sure if there's a good way to move things outside of Shakefile.hs, since you're using runhaskell to run it, basically ... but you don't have to have them all directly in main
20:20:07 <koz_> rotaerk: I don't mind if it's all in Shakefile.hs.
20:21:03 <koz_> So suppose I wanted your "shaders" target to be a separate function, rather than written directly in main. How would that be spelled?
20:22:11 <rotaerk> for instance I could do... https://gist.github.com/Rotaerk/d5802065004a1bb1b2640df591eefea7
20:22:26 <heatsink> koz_: You can put build rules into other top-level definitions, and then just run them in main.  With a little extra work, you can make it feel like including a makefile in another makefile
20:22:51 <koz_> rotaerk: Ah, OK. _Now_ it makes sense.
20:22:52 <jsomedon> dmwit: yep
20:23:38 <koz_> rotaerk: I think I like Shake much more now, having seen that. One big thing putting me off is 'omg giant main no factoring'.
20:23:55 <koz_> (I know, it's a weird thing to get weirded out about)
20:24:03 <rotaerk> one of the problems I had to figure out was ... how to get all my shader files to build without explicitly listing them in the file
20:24:44 <koz_> rotaerk: I guess that's the "shader" target?
20:24:50 <rotaerk> because the `shadersOutDir </> "*.spv"` one is what actually builds the shaders, but it can't *discover* the shader source files without being told of a target file to build
20:25:01 <edmundnoble> Just came out with a library for writing predicates, for example to write tests
20:25:03 <rotaerk> so basically you have to "need" a specific shader file for it to do that
20:25:03 <edmundnoble>  If you like lens, I think you'll like this. http://hackage.haskell.org/package/predicate-transformers-0.1.0.0
20:25:45 <rotaerk> koz_, and that's what the shaders one does; it looks up all the shader *source* files, transforms them into their expected out file names, and then "needs" those file names
20:25:58 <rotaerk> which forces the rule below to run
20:26:08 <koz_> Ah, so you basically 'cook up' a target for each file based on what you find?
20:26:12 <rotaerk> edmundnoble, I never knew you were on freenode
20:26:22 <rotaerk> koz_, yep
20:26:23 <edmundnoble> Yep, mostly lurking
20:26:35 <koz_> rotaerk: That's really good to know, because I'm gonna need something very similar.
20:26:51 <koz_> (mine's slightly different because it'll be config-file-driven, but the idea is much the same)
20:27:51 <heatsink> rotaerk, btw, there's a way to make a rule depend on whether a directory's contents have changed.  Sometimes it's useful for this situation
20:27:59 <rotaerk> oh?
20:28:09 <heatsink> You don't need it because you're unconditionally running the "shaders" rule
20:28:26 <rotaerk> ah k
20:29:39 <heatsink> It's described in the "oracle rules" section of the haddock docs.  I've found it handy for getting shake to rebuild the right things if the project was reconfigured with different options
20:31:12 <koz_> heatsink: So does this mean rotaerk's current setup _always_ recompiles all shaders, whether they've changed or not?
20:31:13 <rotaerk> interesting; I think I mentally blocked that out because "Oracle" brings me nothing but pain at work
20:32:00 <rotaerk> koz_, no, it always looks at the shader source to determine what shader output files are expected, then it iterates through those to determine which need to be built, and only builds them if they are out of date
20:32:33 <koz_> Ah, that's right - since you cook the targets on demand, it can check whether things have changed or not for each one.
20:32:36 <heatsink> Actually, shake's getDirectoryFiles does that dependency check, so this is the right way.
20:33:14 <rotaerk> what dependency check?
20:33:30 <rotaerk> it's the need in front that is forcing the dependency check, I think
20:34:01 <heatsink> Consider a naive implementation of getDirectoryFiles that, when it runs, reads and returns the directory contents.  That won't do the right thing.
20:34:17 <heatsink> The first time it builds, it will behave like you expect
20:35:12 <heatsink> But at that point, shake has cached the directory contents, and its dependency tracking is based on that
20:35:33 <heatsink> If you add another file to the directory, shake won't notice.
20:36:04 <rotaerk> hmm so the actual implementation of getDirectoryFiles will look back at the original?
20:36:05 <heatsink> Shake's implementation of getDirectoryFiles creates an extra rule to check if the directory contents have changed.
20:37:08 <macroprep> ok lets try this again, a vector space is defined as an array of N-dimensional vectors in which are needed to plot a coordinate in the given space, right?
20:37:09 <heatsink> It will get the directory contents again, and check if it has changed since last time
20:37:29 <rotaerk> makes sense
20:38:20 <koz_> macroprep: Do you mean 'in the mathematical sense'?
20:39:08 <heatsink> macrop: Vector space is a more general term.  There are vector spaces of N-dimensional vectors like you're describing.  There are also other kinds of vector spaces.
20:40:44 <macroprep> koz_: yes
20:41:46 <koz_> heatsink, or rotaerk, or whoever can Shake: Is the difference between 'need ["file.txt", "file2.txt"]' and 'need ["file.txt"]; need ["file2.txt"]' the fact that the first call allows the files to be built in parallel, but the second forces it to be done serially?
20:41:49 <edmundnoble> Vector spaces are commutative rings which are "acted on" in a certain way by a field (the "scalars")
20:41:53 <koz_> macroprep: https://en.wikipedia.org/wiki/Vector_space#Definition
20:42:07 <rotaerk> koz_, as I understand it, yes.
20:42:10 <edmundnoble> ^ The expanded version of what I said
20:42:58 <edmundnoble> Mm commutative groups, ring was too much
20:43:03 <heatsink> koz_, yes
20:43:15 <koz_> Oh, cool.
20:43:36 <macroprep> koz_: an array of vectors, right?
20:43:57 <koz_> macroprep: What I linked did not say anything about arrays of vectors.
20:44:01 <edmundnoble> There's nothing at all to do with plotting anything or anything about a space
20:44:08 <edmundnoble> In the definition of a vector space
20:44:21 <macroprep> then how tf does a set differ from an array
20:44:31 <macroprep> both are lists
20:44:37 <koz_> macroprep: Uhh, no?
20:44:45 <koz_> You're confusing interface and implementation.
20:45:14 <koz_> (plus, mathematically there _is_ no concept of 'array', although there _is_ a mathematical concept of set)
20:45:28 <edmundnoble> Call it a "collection" if you want, doesn't matter, the rest of the definition is too *specific* to work with all vector spaces
20:45:28 <koz_> This is why I asked for whether you were referring to a mathematical concept of a vector space or something else.
20:46:56 <macroprep> then what exectly IS a vector space
20:47:03 <macroprep> and what does it look like
20:47:18 <koz_> macroprep: The thing I linked is what a vector space is. Anything which fits that definition, and follows those rules, is a vector space.
20:47:21 <edmundnoble> https://en.wikipedia.org/wiki/Vector_space#Definition
20:47:30 <koz_> What it 'looks like' depends on the specific thing that happens to be one.
20:47:49 <koz_> 'Vector space', like 'ring', 'field' or 'Abelian group' is not one specific thing, but a range of things with similar properties.
20:47:57 <edmundnoble> You need a set V, and a field F, and some definitions of "scalar multiplication" and "vector addition" which satisfy certain properties
20:48:07 <edmundnoble> The members of V will be your "vectors"
20:49:18 <tydeu> koz_: You can most certainly mathemtically define the concept of an array
20:49:36 <koz_> tydeu: You can, yes. I guess I worded that badly.
20:49:51 <jle`> macroprep: do you know what a monoid is?
20:50:13 <koz_> (I believe there's even at least one array calculus out there)
20:50:14 <jle`> (the common haskell abstraction)
20:50:19 <koz_> (someone's PhD thesis IIRC)
20:50:44 <macroprep> ok, so in psuedo, a vector space in minimal terms, would be VectorSpace = (V = (Array(Vector(1,2),Vector(2,3))), F = ???) where V is a "set" of vectors, correct?
20:51:08 <edmundnoble> There is no guarantee that your "vectors" are sequences of values in F
20:51:19 <jle`> macroprep: hm, i'm not sure how to interpret that pseudo code
20:51:25 <edmundnoble> For example, "function spaces" are vector spaces where V is a set of *functions*
20:51:54 <koz_> macroprep: You can think of 'vector space' as a type class with laws.
20:52:04 <jle`> macroprep: since you're in #haskell, are you familiar with some haskell abstractions like Monoid, etc. ?
20:52:07 <jle`> Semigroup
20:52:29 <koz_> If your whatever-the-heck can be a law-abiding implementation of said type class, it doesn't matter what exactly the whatever-the-heck is.
20:52:36 <jle`> just the common ones found in base at least
20:52:41 <heatsink> macroprep: In this context, when we talk about a mathematical set, it corresponds to a programming-language data type
20:53:06 <jle`> if you're familiar with Monoid, Semigroup, etc., then we can show how a vector space is pretty much the same type of thing
20:53:15 <heatsink> macroprep: Different vector spaces have different sets, so if you try to implement different vector spaces, you would be writing different data types
20:53:31 <iqubic> That's correct.
20:53:39 <edmundnoble> I think they don't always have different sets, to be pedantic, they may just have differing operations
20:54:01 <edmundnoble> Though I'm not sure in practice if that's true specifically for vector spaces, it's true of type classes and algebraic structures in general
20:54:34 <macroprep> for example, V1 = Vector3(1,2,3), V2 = Vector3(1,2,3), VectorSpace = (V = Array(V1, V2), F = ???) such that VectorSpace.V == (1,2,3,1,2,3),   or something like this right?
20:54:34 <edmundnoble> (functors would be the kind of "counter-example" I'm thinking of, seeing as there is only ever one valid functor instance for a type constructor)
20:54:47 <heatsink> edmundnoble: Right. I wasn't being that precise
20:54:54 <iqubic> Whatt are we talking about here?
20:54:57 <koz_> edmundnoble: _At most_ one, to be even more pedantic. :P
20:55:20 <jle`> macroprep: that is starting to look like an attempt at a vector space, but that vector space doesn't follow the laws
20:55:29 <jle`> it isn't closed with respect to addition
20:55:51 <jle`> macroprep: but, the definition of a vector space becomes pretty simple if we can explain it in terms of haskell abstractions like Monoid and Semigroup
20:55:52 <heatsink> macroprep, in your example, V = Vector3.  V is a type.
20:56:00 <jle`> are you familiar with haskell common abstractions like Monoid and Semigroup?
20:56:08 <macroprep> nope
20:56:15 <jle`> hm ... what haskell do you know?
20:56:17 <jle`> or are familiar with
20:56:17 <iqubic> Oh dear. Here we go.
20:56:22 <macroprep> none
20:56:35 <jle`> ah. is there any reason why you're asking on #haskell? are you looking for an answer in terms of how it relates to haskell?
20:56:43 <iqubic> That would have been nice to know earlier.
20:56:45 <macroprep> i got directed here lol
20:56:53 <koz_> macroprep: By whom and from where, may I ask?
20:56:59 <jle`> interesting. that seems kind of funny. vector spaces actually aren't a common haskell abstraction
20:57:02 <iqubic> I too would like to know.
20:57:18 <jle`> haskell has some similar abstractions commonly used, but vector spaces aren't one of them
20:57:37 <macroprep> koz_: not sure, irc history gone lol
20:57:39 <suzu> lol
20:58:06 <jle`> macroprep: do you have any programming experience in another language, maybe?
20:58:16 <macroprep> C, C++, and Kotlin
20:58:29 <koz_> macroprep: OK, in that case: is your goal to understand vector-spaces-the-mathematical-abstraction, or is your goal to understand how-do-I-implement-the-notion-of-a-vector-space-in-language-X for some X?
20:58:44 <macroprep> second one
20:58:47 <koz_> Those are related, but ultimately different, things, and the degree to which we can help with each is also different.
20:58:57 <koz_> OK, so then the question is this: what language do you want to implement them in?
20:59:07 <koz_> Because if that language isn't Haskell, you're not in the right place. :P
20:59:36 <macroprep> x.x
20:59:43 <jle`> macroprep: it is probably also worth noting that the computer science term 'vector' (an ordered sequence in contiguous memory, like array etc.) is very different from the math concept of vectors and vector spaces
21:00:02 <jle`> there is some connection, but it's...not very strong
21:00:17 <koz_> The connection seems to be 'implementational convenience in some domain-specifically-useful cases'. :P
21:00:28 <jle`> computer science vectors are an abstract data type with some guarantees on memory storage and access profiles
21:00:30 <koz_> (well, performance-oriented convenience too I guess)
21:00:43 <jle`> math vectors and vector spaces are not really that at all
21:00:44 <macroprep> so which goal uses which concept
21:01:03 <jle`> so if you want to learn how to implement 'vectors', then looking into vector spaces is sort of the opposite direction
21:01:09 <jle`> 'vectors' in the computer science sense
21:01:28 <macroprep> as im pretty sure im NOT lokking for an array of contiguous memory implementation lol
21:01:31 <macroprep> looking*
21:01:57 <koz_> macroprep: Let me ask a slightly more general question then: what are you trying to do exactly?
21:02:10 <macroprep> implement a Hilbert Space
21:02:13 <koz_> And why do you believe implementing vector-spaces-the-notion would help you here?
21:02:14 <koz_> OK.
21:02:18 <koz_> What's the goal there?
21:02:41 <HaskellNoob> Hi I am trying to combine a Writer, Reader and List monad using type classes from the mtl library, but I am not having success. Please look at my pastebin: https://pastebin.com/raw/R4NFA5Zy the first funciton is an example of the behavior i want, the second function will not compile
21:02:47 <jle`> note that there is a difference between implementing a *specific* hilbert space, and implementing an abstraction uniting all hilbert spaces
21:03:04 <jle`> so do you want to implement a specific hilbert space, or are you trying to write an abstraction that would work over all hilbert spaces?
21:03:28 <jle`> vector spaces, and hilbert spaces, etc. in CS terms are essentially abstractions. like "Comparable" or "Printable"
21:03:36 <koz_> Or 'Eq'. :P
21:04:15 <jle`> and implementing a specific vector space or a specific hilbert space vs. implementing them as anbstraction is the same difference between implementing a specific C++ class vs. creating a new interface/abstract class
21:04:49 <heatsink> HaskellNoob: You have (l1, l2) <- ask; x <- l1.  I think you want l1 to be an int, but you're using it like a monadic value
21:05:27 <macroprep> would the difference between an abstraction and a type be that the TYPE is simply a modified version of an Abstraction that is intended to be used for a different task
21:05:53 <jle`> HaskellNoob: your second function is meant to work for "all" instances of MonadWriter ... m, but as you wrote it, it only works for a specific one (based on lines x <-, y <-)
21:06:05 <jle`> HaskellNoob: try using tell and return instead of directly binding <-
21:06:06 <macroprep> for example, from this Abstraction, any other type COULD be constructed
21:06:22 <jle`> HaskellNoob: oh hm i read this wrong. yeah, you should try tell l1
21:06:31 <jle`> macroprep: not quite, it might be the other way around
21:06:42 <jle`> macroprep: for example, consider the abstraction of "things that can be prepared for equality"
21:06:47 <heatsink> HaskellNoob: For that line x <- l1, do you want to convert [Int] to m Int using the MonadPlus instnace?
21:07:00 <jle`> macroprep: even if you somehow built an abstraction for "things that can be compared for equality"
21:07:09 <jle`> macroprep: that wouldn't ever actually help you implement any specific thing that can be compared for equality
21:07:17 <jle`> macroprep: for example, Integers are a thing that can be compared for equality
21:07:31 <jle`> macroprep: but if you set out to implement an abstraction for "things that can be compared for equality", you are no closer to implementing integers
21:07:48 <jle`> so creating the abstraction does not help you create the actual instances of it
21:07:53 <macroprep> how so
21:08:02 <HaskellNoob> heatsink: yes, I believe so... I'm attempting to use hte list monad for nondeterminism. 
21:08:16 <jle`> macroprep: well, if you created an abstraction for "things that can be compared for equality" ... that abstraction would not help you implement the concept of Integers
21:08:32 <jle`> macroprep: and it wouldn't help you implement, say, strings or hashmaps or red-black trees
21:08:50 <macroprep> ok, what is an abstraction
21:08:59 <jle`> macroprep: an abstraction is something that unites many different types of things
21:09:09 <jle`> for example, we can have an abstraction on "things that can be compared for equality"
21:09:20 <jle`> in this case, it unites integers, strings, hashmaps, lists, etc.
21:09:29 <koz_> You can think of it as a collection of rules or behaviours that many things have 'in common'.
21:09:34 <jle`> so we can all use them under some unified abstraction for equality-comparing
21:09:50 <jle`> in Haskell implementing something like that would be something like class Eq a where (==) :: a -> a -> Bool
21:09:51 <heatsink> HaskellNoob: you can use msum for that
21:10:20 <jle`> macroprep: in C++ that would be like creating an Abstract Class, where you have a virtual method for equality testing
21:10:34 <macroprep> ok
21:10:43 <jle`> macroprep: so now you've made your abstraction. great. now implement integers
21:11:05 <jle`> you'll see the problem there: *making* the abstraction "comparable for equality" doesn't actually help you at all with implementing integers
21:11:25 <jle`> so making that abstract class "Comparable" in C++ ... doesn't help you at all with actually implementing an integer type
21:11:29 <jle`> or an integer class
21:11:41 <HaskellNoob> heatsink: can you give me an example? 
21:11:53 <jle`> macroprep: making an abstraction doesn't help you implement the things you are abstracting over
21:11:53 <koz_> As an aside, is it some kind of running joke in Haskell that a 'sample' IO action involves firing missiles?
21:11:54 <heatsink> HaskellNoob: x <- msum l1
21:12:08 <koz_> heatsink: Wouldn't 'return l1' also work here?
21:12:34 <jle`> macroprep: in this case here, making an abstraction uniting different vector spaces won't actually help you with actually implementing any specific vector space
21:12:54 <jle`> macroprep: you can spend time and create an abstraction for vector spaces. great. but you can't use it to do anything useful until you actually implement a specific vector space
21:13:08 <jle`> macroprep: and in implementing that specific vector space, the abstraction doesn't help you at all
21:13:29 <heatsink> koz_, not for this example.  In the non-generic version, l1 :: [Int].  They use x <- l1 to visit all list elements
21:13:31 <nshepperd1> koz_: yeah. Good old launchMissiles :: IO ()
21:13:37 <macroprep> say for example, i have a mathametical class containing implementations for addition and subtraction, and i implement two different classes using this mathematical class, could this mathematical class be considered an abstraction class
21:13:57 <jle`> macroprep: yeah, you can create an abstraction uniting different things that can be added and subtracted
21:14:01 <koz_> heatsink: Oh, I see.
21:14:02 <heatsink> koz_: l1 is an [Int], x gets an Int
21:14:31 <macroprep> eg math.addition, A.addition, B.addition (A and B are implemented from math class)
21:14:32 <nshepperd1> koz_: sometimes used as a good example for why unsafePerformIO is unsafe (causing international side effects!)
21:14:46 <jle`> macroprep: yeah, the abstraction would basically say "to be addable, you must implement addition"
21:14:48 <koz_> nshepperd1: OK, makes sense lol.
21:15:07 <jle`> macroprep: all the abstraction says is "you must do this". but the specific types/classes are the things that actually have to do implement the work, not the abstraction
21:15:13 <koz_> jle`: Ideally followed by 'such that it is commutative, associative, and has 0 as a unit'.
21:15:28 <tydeu> a bit off-topic, but does anyone know what the term for the number of operations in a algebraic structure is?
21:15:36 <nshepperd1> koz_: http://hackage.haskell.org/package/acme-missiles-0.3/docs/Acme-Missiles.html
21:15:57 <macroprep> another example would be, for example, creating a contigous memory implementation for any class that wants to be able to implement indexing, eg Arrays, Strings, and others
21:16:27 <jle`> macroprep: yes, that would be an abstraction
21:16:36 <jle`> or well, an abstraction would be "things that can be indexed"
21:16:45 <jle`> and then the arrays, strings, others would be instances of that abstraction
21:17:10 <jle`> so note that just *creating* the abstraction "things that can be indexed" -- that doesn't actually help you implement arrays or strings
21:17:46 <heatsink> HaskellNoob: Looking again, msum is not quite right
21:17:56 <jle`> you have to implement arrays and strings on their own, first.  and then after that, you can start thinking about how they fit under the abstraction
21:19:59 <macroprep> how so
21:20:30 <jle`> which part are you asking about?
21:20:30 * hackage html-conduit 1.3.2.1 - Parse HTML documents using xml-conduit datatypes.  https://hackage.haskell.org/package/html-conduit-1.3.2.1 (MichaelSnoyman)
21:22:01 <macroprep> for example, if you create a contigous memory implementation, and then you wanted to create a string implementation, would you basically need to reimplement a contigous memory implementation for the string implementation, and THEN think about how to abstract that to the other contigous memory implementationthat was previously implemented
21:22:41 <jle`> if you created two different contiguous memory things that can be indexed, at that point you can then start thinking about how to unite them under a common interface/abstraction
21:22:55 <jle`> ah, note that i don't mean 'implementation'
21:23:01 <jle`> the point isn't to unite their implementation
21:23:27 <jle`> their implementations might still be separate and different. but the abstraction will let us talk about both of them in the same "language"
21:23:46 <HaskellNoob> yes, i still can't seem to get it woring how i want
21:24:01 <koz_> It would also let us write stuff that works for both of them, even if their implementations are highly different.
21:24:21 <macroprep> so for example, make a String and an Array abstraction such that both can be used interchangably for Strings or Arrays?
21:24:47 <jle`> macroprep: yeah, allowing users to work with Strings and Arrays under a common interface, and you can swap them out to have code that works for either
21:24:54 <jle`> HaskellNoob: ah, looked closer at your thing
21:24:59 <macroprep> eg create a string using String and an array using Array, or a string using Array, and an array using String
21:25:01 <mtae> hey y'all
21:25:02 <jle`> HaskellNoob: msum doesn't get the right result?
21:25:08 <koz_> mtae: Sup?
21:25:10 <jle`> macroprep: ah no, that's not what i mean
21:25:23 <mtae> I know that category theory for programmers is popular (and perhaps controversial)>
21:25:23 <mtae> Is there a programming (in haskell) for category theorists?
21:25:26 <jle`> macroprep: i'm saying that you can now write code for "all indexable things", and then you can use that same code to work with strings and also with arrays
21:25:34 <mtae> koz_: hey :)
21:25:43 <mtae> asking for a friend who is a mathematician
21:26:24 <jle`> HaskellNoob: ah yeah you need to msum and "lift"
21:26:33 <macroprep> jle`: ok...
21:26:39 <jle`> HaskellNoob: msum essentially lifts you one layer, you need to lift the final layer
21:26:57 <jle`> HaskellNoob: try x <- msum (pure <$> l1)
21:27:31 <jle`> mtae: that's a good question! i seem to recall some sort of haskell for mathemeticians resource somewhere
21:27:56 <jle`> but to be honest most modern haskell introductions will assume you are learning haskell to write programs/executables
21:28:29 <koz_> Bartosz might know of something.
21:28:32 <jle`> honestly i don't think having a math background would help you that much with learning haskell itself
21:28:48 <jle`> so maybe just going down the normal route wouldn't be too bad
21:28:55 <Lycurgus> u tbh'd
21:29:29 <jle`> mtae: what is the end goal of your math friend's haskell journey?
21:29:57 <mtae> he's working on formal verification and writing a parser for some absurd grammar in EBNF form
21:30:20 <koz_> Just a parser?
21:30:30 <Lycurgus> he'll wanna know about bnfc if he doesn't
21:30:36 <koz_> I'd imagine there'd be more than only that.
21:30:47 <jle`> mtae: hm. yeah i don't think having a background in mathematics would help you 'kick start' things in any meaningful way
21:30:56 <jle`> at least for that sort of goal
21:31:19 <Lycurgus> Ganz Falsch
21:31:31 <jle`> at least, writing a parser is usually like a midterm project for most haskell courses
21:31:42 <jle`> so even if you're learning haskell "from scratch", getting to the point where you can write a parser is pretty fast
21:32:02 <koz_> Amusingly - that's probably the first thing I wrote in Haskell. :P
21:32:08 <jle`> it's not like having a math background can move it from Week 6 to Week 4
21:32:10 <koz_> (in fact, it _was_ the first thing)
21:32:17 <HaskellNoob> jle`: yes, that does work, thank you... though I'm not quite sure why... 
21:32:33 <jle`> HaskellNoob: msum [x,y,z] is x <|> y <|> z
21:33:00 <jle`> HaskellNoob: so it only works if the items in the lists are already "monadic actions" of your end goal
21:33:09 <jle`> HaskellNoob: msum :: [m a] -> m a
21:33:24 <jle`> so using pure turns your [a] into [m a]
21:33:29 <jle`> which you can now <|>-up
21:35:03 <jle`> mtae: there is a misconception that haskell is a very math-heavy sort of programming language, where you turn cat theo and similar concepts into code
21:35:12 <mtae> https://scontent-iad3-1.xx.fbcdn.net/v/t1.15752-9/72450712_370991730495562_7819436365543636992_n.png?_nc_cat=103&_nc_oc=AQk3pgR96UUllj2ELyIAqA4NkHR3aW8f_rfs6j-X_dkLqAt3duJVScODageFjxC50l8&_nc_ht=scontent-iad3-1.xx&oh=733bd906e5f2281f0bad76f0a8b4890d&oe=5E3757F3
21:35:20 <mtae> even if the parser is for this grammar lol?
21:35:27 * Lycurgus wonders what part of CS isn't math
21:35:30 <mtae> this is i believe a fifth of this
21:35:35 <mtae> *of the grammar
21:35:35 <jle`> mtae: in actuality, using haskell isn't any more math-heavy than any other language. the only difference is haskellers like math ... it's some weird coincidence
21:35:52 <jle`> mtae: well, the math might help you understand the grammar, but it's not going to help you understand the haskell
21:36:34 <jle`> the understanding of the haskell part is going to come through some learning process that maths won't help you with
21:36:50 <HaskellNoob> Ok, hmm... that is a bit more clear. Thanks for the help
21:36:53 <jle`> having a background in math will probably be most effective as general domain knowledge
21:37:10 <jle`> sort of like how having a background in physics will help you write a physics simulator in haskell
21:37:15 <jle`> it won't help you with the haskell part
21:37:20 <jle`> it will help you with the physics simulation part
21:37:43 <jle`> having a background in physics will help you write a physics simulator in any language. haskell is irrelevant
21:38:00 <Lycurgus> they don't call it hassle for nuthin, it's a ball breaker that prides itself on its learning curve
21:38:34 <Lycurgus> without being useless like say brainfuck
21:38:51 <Lycurgus> the opposite of that, practicality wise
21:39:04 <jle`> let's say you had a background in fashion design and you want to use haskell to create tools for other fashion designers
21:39:20 <jle`> having a background in fashion design will help you a lot with that, because you would know the domain of your application very well
21:39:20 <koz_> jle`: I am endlessly amused by this thought experiment. :P
21:39:26 <jle`> but it won't help you with the learning Haskell part
21:39:56 <jle`> similarly if you have a background in math and you want to create tools for mathemeticians, it will help you because of your domain knowledge. it won't help you learn haskell.
21:40:22 <jle`> having a math background would help you as much as having a fashion design background would
21:41:03 <koz_> As a complete aside: what would you folks suggest as a portable library, or combination of libraries, in Haskell that would let me render SVG into PDF?
21:41:26 <Lycurgus> which in this domain specific case is obviously a lot
21:42:18 <Lycurgus> if it could be arguably said that its model of computation is pure math, some type theory, etc. then ... .
21:42:52 <jsomedon> jle`: huh I thought all these concept like functor, applicatives are from math hence people who already learned these concept from math would have way much easier time when they learn haskell?
21:42:54 <heatsink> koz_: You could do that with inkscape from the command line
21:43:16 <heatsink> https://inkscape.org/en/doc/inkscape-man.html
21:43:29 <koz_> heatsink: I'm aware, but this isn't the question I asked.
21:43:40 <jle`> jsomedon: i don't think it would help you in actually using those concepts and abstractions
21:43:40 <jellostahps> When I compute line #1, I will eventually have to compute mymap f (a:as) = (\x -> x>7) (4).    If 4 is associated with the variable 'a', then how does the function (\x -> x>7) know to use it? https://pastebin.com/HyNMeiM0
21:43:42 <sm[m]> Whatever shows up on hackage koz.. not that many options I’m guessing ?
21:44:06 <jle`> jsomedon: the most it would help with is being able to appreciate the context and background behind those ideas
21:44:15 <koz_> sm[m]: What do you search? 'svg'? 'pdf'? Whenever I've asked here, I've usually gotten very helpful suggestions.
21:44:37 <sm[m]> Yup. Unless.. perhaps the mighty pandoc.. ?
21:44:46 <jle`> pandoc shells out for pdf too i believe
21:45:03 <koz_> I don't think Pandoc can ingest SVG last I checked.
21:48:53 <Lycurgus> a combination shouldn't be necessary unless you need to do stuff, a single program such as the one noted should suffice for svg to pdf
21:48:53 <sm[m]> svg-tree -> rasterific-svg -> Rasterific -> pdf ?
21:50:03 <koz_> sm[m]: Can Rasterific create a multi-page PDF this way from multiple SVGs?
21:50:09 <koz_> If so, that's _exactly_ what I require.
21:50:51 <Lycurgus> the string svg2pdf should snag stuff, but maybe not of much worth, portability is elusive in this case other than that in svg
21:50:52 <sm[m]> No idea, just hackaging from my phone :)
21:51:12 <sm[m]> But I’m guessing it can
21:51:52 <sm[m]> Probably the weak link will be can this read your real world pdf
21:52:01 <sm[m]> Svg, I mean
21:52:11 <koz_> I'd have to test that.
21:53:57 <Lycurgus> pdf is ofc portable too but pdf that actually renders everywhere after passing thru such a pipe is another matter
21:57:37 <jellostahps> :i map
21:57:44 <jellostahps> :t map
21:57:45 <lambdabot> (a -> b) -> [a] -> [b]
22:04:55 <jellostahps> map f (a:as) = ( f a): (map f as)       ;   if f is  (\x -> x > m) and (a:as) = [4,3,9], then how does the anonymous function know to look at 4 as its 'x'? Do anonymous functions just take the next things after it as its argument ? cuz 'a' would just be the Integer 4.
22:06:39 <jellostahps> ^ with respect to (f a)
22:11:41 <jsomedon> the list you gave is [4, 3, 9] and the (a:as) part matches `a` as first of list(which is 4) and `as` as rest of list(whcih is[ 3,9])
22:11:51 <iqubic> That is correct.
22:12:05 <jsomedon> not sure if this is what you are confused with
22:12:26 <iqubic> That is why the lambda uses 4 as it's argument.
22:12:35 <jsomedon> so `ap` is another name for <*>/
22:12:37 <jsomedon> ?
22:12:44 <iqubic> That is correct.
22:13:10 <jsomedon> or they are different? I :t on ap and <*> and well they are not exact same
22:13:17 <jsomedon> :t ap
22:13:18 <lambdabot> Monad m => m (a -> b) -> m a -> m b
22:13:24 <jsomedon> :t (<*>)
22:13:25 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
22:14:06 <jsomedon> I mean do these two name refer two exact same fucntion or they are implementd as different function? just curious to know
22:14:38 <iqubic> Ah, right. Yes. They have the same functionality, but <*> requires Applicative while ap requires applicative.
22:14:39 <koz_> Historically, Monad was a thing before Applicative.
22:15:04 <jsomedon> on some post I read it says haskell people pronounce <*> as "ap" so hence my question..
22:15:05 <koz_> So when Applicative first got spotted, folks realized that a lot of things that we thought needed a Monad constraint would be OK with just Applicative.
22:15:39 <koz_> Some of these got retrofitted (replicateM) and some got kept as two separate things (such as ap and <*>).
22:15:45 <jsomedon> ok
22:15:55 <koz_> I can't really say why each was done the way it was though, but someone in here might know.
22:15:56 <jsomedon> so Applicative is the new kid
22:15:56 <iqubic> :t replicateM
22:15:57 <lambdabot> Applicative m => Int -> m a -> m [a]
22:16:06 <iqubic> That's an odd name for that.
22:16:15 <koz_> iqubic: It used to have a Monad constraint, that's why.
22:16:17 <iqubic> :t replicateA
22:16:18 <lambdabot> error:
22:16:19 <lambdabot>     • Variable not in scope: replicateA
22:16:19 <lambdabot>     • Perhaps you meant one of these:
22:16:24 <iqubic> I know that.
22:17:02 <koz_> But yes, replicateA would be better.
22:17:11 <koz_> Also of note:
22:17:12 <iqubic> Yeah.
22:17:13 <koz_> :t mapM
22:17:15 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
22:17:19 <koz_> :t traverse
22:17:20 <lambdabot> (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
22:17:24 <iqubic> WHY?!?!
22:17:27 <iqubic> Just why???
22:17:51 <jsomedon> huh these two looks so simialr
22:17:59 <koz_> jsomedon: Similar story to ap and <*>.
22:18:04 <jsomedon> lol k
22:18:17 <MarcelineVQ> jellostahps: Yes, the items that follow a function application are its arguments. If a is 4 and f is (\x -> x > m) then "f a" is "(\x -> x > m) 4", which is (\x -> x > m) applied to 4, binding 4 to the name x, anywhere x appears it means 4 now. similarily (\x y -> x + y) 3 2 is (\x y -> x + y) applied to 3 and 2, where x is 3, and y is 2
22:18:44 <jellostahps> MarcelineVQ: thank you, very clear
22:19:00 <jellostahps> didn't een have to read that 4 times
22:19:04 <koz_> MarcelineVQ: Much explain? :P
22:19:04 <jellostahps> even*
22:19:17 <jellostahps> its perfect
22:19:36 <jellostahps> please start writing textbooks immediately, people need you
22:23:26 <MarcelineVQ> ehe there's a few of those out there already, I found haskellbook.com to be a good fit for me but most of what I know probably comes from in here
22:26:09 <iqubic> Same here.
22:27:03 <jsomedon> yeah this irc is like light-year-much-more helpful than any book
22:28:15 <iqubic> Correct.
22:29:05 <koz_> Lots of accumulated wisdom here.
22:29:08 <macroprep> i back
22:31:49 <dmwit> Is there a Hackage library that offers the obvious direct implementation of `\n act -> reverse <$> replicateM n act`?
22:32:37 <dmwit> (I looked on Hoogle, which didn't have it, but maybe somebody knows a trick I don't.)
22:35:18 <shachaf> You mean the "tail recursive"-style implementation?
22:41:31 <dmwit> I've written `backwardsReplicateM n act = go n [] where go 0 vs = pure vs; go n vs = do { v <- act; go (n-1) (v:vs) }`, but would prefer an import to keeping that code.
22:42:23 <dmwit> So I think the answer to your question is "yes".
23:03:52 <HaskellNoob> anyone read "Practical Haskell" ? It's been a good book for me seems like a good replacement for the older Real World Haskell
23:12:00 * hackage libmpd 0.9.0.10 - An MPD client library.  https://hackage.haskell.org/package/libmpd-0.9.0.10 (psibi)
23:34:49 <CSP-SOFT> l
23:55:20 <yeboi> hey, would anybody be able to help me with using foldr?
23:55:31 * hackage hopencc 0.2.0.0 - Haskell binding to libopencc  https://hackage.haskell.org/package/hopencc-0.2.0.0 (PaulMeng)
23:56:34 <koz_> yeboi: What are you after?
23:58:36 <yeboi> I've got a list of booleans, & if any of them are true, it should return true
23:58:40 <yeboi> using foldr
23:58:52 <yeboi> at the moment, I have:
23:58:59 <yeboi> any :: [Bool] -> Bool
23:59:11 <yeboi> any xs = foldr (||) True xs
23:59:37 <yeboi> but it gives me true instead of false for a test list [false, false, false]
