00:06:23 <boothead> Hey folks, any servant users around? I'd like to know how to use runRoute given a server and a path and payload. I'm not quite clear how to get hold of the things to pass to the HasServer.route function to get hold of the router...
00:09:39 <alp> boothead, hello. yeah, I should split out the router machinery into its own package... and give a proper API. in the meantime:   route (Proxy :: Proxy YourAPI) EmptyContext (emptyDelayed $ Route yourhandlers)
00:09:46 <alp> that gives you the Router value
00:10:29 <boothead> Aha - perfect! Thanks @alp, it was the last bit I was missing :-)
00:34:55 <maerwald> suddenly my hspec tests take 2:30 hours instead of 10 minutes and I have no idea what dependency caused it
01:19:31 * hackage rpmbuild-order 0.3 - Order RPM packages by dependencies  https://hackage.haskell.org/package/rpmbuild-order-0.3 (JensPetersen)
02:06:34 <absence> i have two Maybe values and would like to <> them, but the type inside doesn't have a Semigroup instance. while i could make a newtype wrapper with such an instance, is there a less verbose way that would let me just pass a function to do the "multiplication" or something similar?
02:07:23 <merijn> absence: What's the type inside them?
02:07:42 <merijn> i.e. why would <> even make sense if there's no Semigroup?
02:08:01 <absence> merijn: some black box from a library
02:08:16 <merijn> absence: So what should happen if one of them is Nothing?
02:08:47 <absence> merijn: that's governed by Maybe's Semigroup instance?
02:09:08 <absence> it'd pick the other
02:09:43 <merijn> absence: That logic only works if the content is a semigroup. You said you wanted to apply something other than <> instead
02:10:20 <absence> merijn: yes. in the case that both are Just, they'd have to be somehow combined into one
02:11:17 <merijn> absence: The only solution other than "defining a newtype that's a Semigroup" is "implement that logic yourself"
02:11:52 <merijn> Well, I suppose you could do "foldr myFun defaultVal $ catMaybes [maybe1, maybe2]"
02:12:12 <absence> no free lunch huh. ok, thanks!
02:17:22 <Ariakenom> :t \f -> maybe id (fmap . f)
02:17:23 <lambdabot> Functor f => (a1 -> a2 -> a2) -> Maybe a1 -> f a2 -> f a2
02:25:55 <Ariakenom> ... no thats not right
02:38:58 <cheater> can someone suggest a good representation of non negative numbers? the implementation i use right now (package non-negative) makes my program slow.
02:39:15 <cheater> non-negative integers specifically
02:40:46 <Ariakenom> cheater: Numeric.Natural?
02:42:54 <Ariakenom> jalkh. It uses underflow when it should use overflow. D: how are numbers in haskell so good and yet so bad
02:42:58 <MarcelineVQ> depends a bit on the behavior you want. for natural 3-5 is an exception, compared to just getting 0 which might be desirable
02:43:56 <cheater> let me try that Ariakenom thanks
02:44:35 <MarcelineVQ> regardless, your speediest (performance) way will be to use an Integer newtype with checks for the behavior you want built into its numeric instances
02:48:51 <cheater> i want an exception here
02:49:03 <cheater> i don't want clamped integers
02:49:44 <Taneb> > 3 - 5 :: Natural
02:49:46 <lambdabot>  *Exception: Natural: (-)
02:49:53 <Taneb> cheater: like that?
02:49:56 <cheater> that's very descriptive
02:50:01 <cheater> yes, that's good
02:50:02 <cheater> thanks
02:50:04 <cheater> :)
02:50:18 <Taneb> Numeric.Natural, which has been in base for the past few versions, and before that I think it was in semigroups?
02:50:38 <Taneb> No, nats
02:51:36 <Taneb> Been in base since GHC 7.10
02:51:58 <cheater> tbh i've been doing a little bit of profiling and i'm not 100% sure what i should be looking for. i looked at individual %time and %alloc, does that sound like the right place to look at? that's what led me to trying to find a replacement for non-negative.
02:52:12 <cheater> Taneb: thanks, i'll try that
02:52:17 <cheater> > 0 :: Natural
02:52:19 <lambdabot>  0
02:52:22 <cheater> alright
02:52:31 <cheater> is there a version of this that starts with 1? (i need both)
02:52:52 <merijn> cheater: "It Depends"
02:53:25 <merijn> cheater: You may also want to run with "+RTS -sstderr" and check the productivity of your program
02:54:01 <merijn> cheater: How big is the percentage of time that for whatever thing you're using?
02:57:40 <cheater> there are two entries like this, for two sides of a comparison
02:57:47 <cheater> 1 sec
02:57:57 * Lycurgus guesses efficiency
02:57:58 <cheater>                     compare                               Numeric.NonNegative.Wrapper        src/Numeric/NonNegative/Wrapper.hs:32:18-20             967948702147216   12.4    0.0    12.4    0.0
02:58:10 <merijn> cheater: Can you pastebin the entire profile report?
02:58:13 <cheater> in total over 25% of all %time
02:58:53 <cheater> not entire, no, but i can remove the lines that contain 0.0 0.0 0.0 0.0 on individual and inherited %time and %alloc if you'd like, is that good?
03:01:10 <haskelllisp[m]> How to get the value of the key from a Request object?  content-type=form-data,  Is there an iterative method to take each key one by one?
03:03:53 <cheater> merijn ^
03:18:13 <piyush-k`> backpack question: Suppose there is a signature package foo.sigthat exposes two signatures A and B and there is a client library that only uses the stuff from A. Is there a way (in the .cabal file) to say that the client's requirement is only A and not B (thus it can be satisfied by mixing in a concrete implementation for A alone) ? 
03:40:43 <george_____t> Anyone got experience setting up ghcide with vs-code?
03:42:28 <Ariakenom> MarcelineVQ: Natural looks speedily implemented. I don't think a custom wrapped Integer will beat it.
03:43:12 <Ariakenom> it has lots of MagicHash
03:50:32 <Ariakenom> but non-negative's wrapper doesn't look too bad at a glance
03:50:33 <MarcelineVQ> No but when you want your own behaviors instead of GHC.Natural's, wrapping Integer will beat the snot out of any naive form like data Nat = Z | Succ Nat
03:51:30 <tdammers> wait what, GHC.Natural uses peano numbers?
03:51:40 <Ariakenom> no
03:51:58 <tdammers> OK, sanity restored
03:53:17 <Ariakenom> GMP naturals among other things afaict
03:54:11 <Ariakenom> Numeric.NonNegative.Chunky.T is though. But I presume cheater used Numeric.NonNegative.Wrapper.T Integer
03:54:53 <Ariakenom> losing out on let y = min (1+y) 2 in y
04:23:31 * hackage single-tuple 0.1.0.0 - a class for single tuple implementations  https://hackage.haskell.org/package/single-tuple-0.1.0.0 (kakkun61)
04:24:01 * hackage list-tuple 0.1.0.0 - List-like operations for tuples  https://hackage.haskell.org/package/list-tuple-0.1.0.0 (kakkun61)
04:25:01 * hackage homotuple 0.1.0.0 - Homotuple, all whose elements are the same type  https://hackage.haskell.org/package/homotuple-0.1.0.0 (kakkun61)
04:32:45 <__monty__> Is that just someone trying to pad their hackage resume?
04:33:27 <Rembane> Or they got really inspired by npm.
04:34:02 <fendor> maybe this is reduce compile-time and only pull in deps you actually need?
04:34:10 <fendor> *to
04:34:27 <__monty__> Looks like graduate level course work to me.
04:36:14 <fendor> at least, documentation is on par with most hackage packages
04:37:09 <cheater> __monty__: 3 packages are not so bad. there are people with over 100 packages, and they list a link to the list on their online resume. that's padding.
04:37:24 <MarcelineVQ> Maybe they're working towards machinery to make instances for tuples longer than 2, like for Functor :>
04:37:45 <sicklorkin> CFGO="${HOST_SHORT}.config.yaml"
04:48:51 <phadej> I have over 100 packages on Hackage :(((
04:49:54 <phadej> (or am a maintaner of, they aren't all mine)
04:55:11 <Athas> Condolences.
04:58:01 * hackage servant-swagger-ui 0.3.4.3.23.11 - Servant swagger ui  https://hackage.haskell.org/package/servant-swagger-ui-0.3.4.3.23.11 (phadej)
04:59:01 * hackage servant-swagger-ui-redoc 0.3.3.1.22.3 - Servant swagger ui: ReDoc theme  https://hackage.haskell.org/package/servant-swagger-ui-redoc-0.3.3.1.22.3 (phadej)
05:01:16 <fendor> I love the servant-swagger-ui. it is so cool
05:07:18 <phadej> thanks
05:10:18 <phadej> btw, looks like some haskellx videos are already online
05:28:24 <lavalike> where?
05:38:17 <phadej> https://skillsmatter.com/conferences/11741-haskell-exchange-2019#program
05:42:12 <boxscape> "Higher-Order Type-Level Programming" immediately followed by "Stick to Simple Haskell", nice
05:44:24 <phadej> they were concurrent, weren't they
05:44:34 <phadej> like pick one :)
05:44:45 <boxscape> oh, right
05:44:51 <boxscape> what makes sense :)
05:44:53 <boxscape> that*
05:54:09 <int-e> boxscape: hmm, concurrent, put them on the same podium, have a shouting match.
05:54:34 <int-e> and, most importantly, set up a betting pool beforehand.
05:59:46 <boxscape> How would the winner be determined?
06:27:01 <dminuoso> What might be the point of defining bindings like `foo :: ...; Parser foo = ...` ?
06:27:51 <merijn> dminuoso: So you can easily use foo?
06:28:20 <dminuoso> merijn: Sure, but what's the point of that Parser newtype then?
06:28:42 <merijn> Depends where it's defined
06:29:41 <dminuoso> What do you mean?
06:30:29 <merijn> dminuoso: If you use Parser elsewhere or it comes from a library...
06:31:24 <dminuoso> merijn: Does it matter either way? Its not like you will have an actual binding of some Parser lying around to use.
06:32:08 <merijn> dminuoso: I guess I'm not sure what leads to the question "what's the point of defining bindings like that"
06:32:29 <merijn> dminuoso: The obvious answer seems to be "because you want to access 'foo'"
06:32:46 <dminuoso> merijn: You dont need the Parser newtype to define foo to do that.
06:32:50 <dminuoso> You can just wrote `foo = ...`
06:33:04 <dminuoso> Assuming that:
06:33:17 <dminuoso> newtype Parser d v = Parser (d -> Result d v)
06:33:25 <merijn> dminuoso: The right hand side is returning a parser and you don't want a parser...
06:33:38 <absence> sometimes when putting values in a map, the key is extracted from the value, e.g. M.insert (getId val) val. ideally i guess one should make a new type that contains everything except the key, and insert that instead, but is there a key-value-like data structure that gets around this by using a function/view for the key instead?
06:34:00 <merijn> dminuoso: The obvious assumption is that the code on the right handside *already exists* and returns a parser for some reason
06:35:16 <merijn> So anyone here experienced with GHC's profiling? I'm trying to make my profiles a bit more readable/understandable but there's a bunch of clutter and I don't know how to best get rid of it (if at all possible)
06:36:03 <merijn> Specifically, it's attributing a HUGE amount of time to IDLE, which obscures the interesting parts of my profile
06:37:26 <dminuoso> absence: In some sense whats Representable functors are about.
06:38:01 * hackage protolude 0.2.4 - A small prelude.  https://hackage.haskell.org/package/protolude-0.2.4 (sdiehl)
06:39:04 <dminuoso> absence: Either way, you could construct your own `inserting f = \x -> insert (f x) x` trivially
06:40:04 <dminuoso> merijn: I see. So this is basically a shorthand for something like `foo = runParser foo'; foo' = someDef` where you'd write `Parser foo = someDef`
06:40:24 <dminuoso> (For when you don't care to have an actual Parser for the entire thing)
06:40:32 <dminuoso> merijn: I completely missed that the RHS was a parser too. :)
06:41:13 <merijn> dminuoso: It's just pattern matching/destructuring
06:42:51 <dminuoso> merijn: I guess I would prefer to just wrote `foo :: ...; foo = runParser $ stuff` rather than `Parser foo = stuff`
06:43:02 <dminuoso> In this case they seem to be equivalent
06:43:18 <merijn> dminuoso: That doesn't work for multi-field datatypes, though
06:43:43 <dminuoso> merijn: sure, in this case its just a newtype
06:50:02 <Philonous> newtype Parser <whatever> = Parser <whatever> -- now you don't have any choice but to pattern match since there's no runParser 
06:51:23 <Philonous> Tough honestly it took me a minute to figure out what the code was even supposed to do, it really is extermely uncommon to see pattern matches in top level bindings 
06:54:13 <merijn> Philonous: It shouldn't be, it's great!
06:56:40 <Philonous> When for example? 
06:57:12 <merijn> I know I have a couple in my codebase, but I don't remember where >.>
06:57:17 <Philonous> I mean, can you give an example for a practical use?
06:58:40 <merijn> Eh, unpacking records? Like, I don't really see what's so weird about it...
06:58:42 <Philonous> It seems to be too restrictive to be of much practical value, you can only have a single pattern and the RHS is static, so you could just constant-fold it 
06:58:52 <merijn> Specifically computed record
06:59:12 <merijn> Philonous: That assumes your RHS is some simple static thing
06:59:48 <Philonous> Maybe if the RHS is TH-generated or is injected via backpack?
06:59:51 <merijn> Philonous: Or that you even have access to the parts of the RHS
06:59:59 <merijn> Philonous: Can just be defined in a library
07:00:23 <merijn> Philonous: Or computed via a non-trivial function
07:01:10 <Philonous> You could still just run the function once and then replace it with the result... But yes, I see some limited use 
07:01:30 <merijn> Philonous: I use it in Tasty.Travis to get access to the contents of one of the default ingredients, for example: https://github.com/merijn/tasty-travis/blob/master/Test/Tasty/Travis.hs#L136
07:01:56 <merijn> Philonous: I could *technically* copy the code from the consoleTestReporter implementation, but now if that ever changes my code breaks
07:02:12 <merijn> Philonous: This way it always matches the existing consoleTestReporter as intended
07:02:30 <Philonous> Except that's not a top-level declaration. 
07:02:43 <merijn> Philonous: Neither was dminuoso's example, afaict
07:02:56 <merijn> Philonous: Anyway, I've used them at the top level before too
07:21:12 <dmwit> Philonous: I have used it occasionally when I have a parser for a complicated file format and I'd like a default value, for example.
07:21:49 <dmwit> `Right config = parseConfig "..."` can be more readable than `config = {- some crazy complicated AST with a lot of Haskell constructor noise in it here -}`.
07:23:42 <dminuoso> dmwit: Interesting, what happens if you evalutae config and parseConfig produces a Left?
07:23:51 <merijn> dmwit: Use validated-literals and you can even check the thing at compile time! ;)
07:23:57 <merijn> dmwit: It crashes due to incomplete pattern
07:24:04 <merijn> s/dmwit/dminuoso
07:30:58 <merijn> Is there a library that does shell escaping/quoting for strings?
07:31:01 <dmwit> dminuoso: Purity says it's gonna give the same thing every time, so no big deal. You just check once real quick and you know it will work forever.
07:31:23 <dmwit> If you're extra nervous, toss it in a test!
07:31:40 <Philonous> "forever" = until you build against a different version of your libraries. Or the compiler flags change. 
07:31:44 <merijn> dmwit: Or use validated-literals and have it skip the parsing step at runtime AND auto-checked at compile time :p
07:38:00 <dminuoso> dmwit: Fair enough
08:10:11 --- topic: 'https://www.haskell.org | https://wiki.haskell.org/IRC_channel | Paste code/errors: https://gist.github.com/ | Logs: http://tunes.org/~nef/logs/haskell/?C=M;O=D | https://www.reddit.com/r/haskell | Admin: #haskell-ops | Offtopic: #haskell-offtopic | https://downloads.haskell.org'
08:10:11 --- topic: set by glguy on [Sat Jan 05 07:21:52 2019]
08:10:37 <novum> wow. I came in here but I just forgot parentheses .. why do you need parens here: map (toUpper . head) $ words "Hello world foo"
08:10:57 <novum> I am getting better and better! sleep helps. how's everything going, haskell heads? ^u^
08:14:05 <lyxia> because map toUpper . head $ words   means   (map toUpper) . head $ words
08:14:38 <lyxia> function application has higher precendence than operators.
08:15:27 * novum nods and memorizes. thanks a bunch for your response to my trivial question
08:15:39 <lyxia> you're welcome :)
08:23:00 <novum> I am kind of stuck. I need to apply the above map to a string, as above, but I also need to apply another function to the same set of `word`s. Maybe you can help. I need to join together  map (toUpper . head) $ words "HyperText Markup Language"  AND  map (filter isUpper . tail) $ words "HyperText Markup Language"  in order as if zipping them together. I am thinking of a way to use the cons
08:23:03 <novum> operator so that I can take the (toUpper . head) and cons it with the  (filter isUpper . tail)  but I simply have too limited of knowledge :(
08:24:13 <novum> essentially, "HyperText Markup Language" becomes "HTML" ^u^ but I can only get one piece or the other. I don't know how to EASILY stick 'em together u_u
08:25:30 <novum> is there a function that takes something and duplicates it so that I can apply a two functions to each and then .. somehow cons them together?
08:26:28 <novum> oh. maybe I can use a lambda function. I have never done that before. Is that apt here?
08:28:17 <lyxia> that would probably be useful. Have you also seen the zip function?
08:29:49 <tdammers> there's also zipWith
08:29:53 <tdammers> :t zipWith
08:29:54 <novum> I think I got it:  concat $ map (\x -> (toUpper . head) x : (filter isUpper . tail) x) $ words "HyperText Markup Language"
08:29:54 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
08:30:06 <novum> Is the above a rather concise and efficient implementation?
08:30:31 <novum> implementation, I mean not to use your name in vain. Please forgive me :o ^u^
08:30:38 <lyxia> if you're aiming for "HTML" as a result I wonder why this wouldn't be good enough   filter isUpper
08:30:56 <novum> lyxia, because the input could also be  "hyperText markup language"
08:31:28 <novum> or "xtensible markup language" for example. It neeeeds to acquire the head of each word as well as the captials in the words
08:31:44 <novum> in the tails of the words rather
08:32:51 <novum> I am very happy that I was able to do that. I am very newby in haskell. Still, I aim to get better. Hence, I inquire about its conciseness and efficiency
08:34:23 <tdammers> so something like: concat . (map $ \(h:t) -> toUpper h ++ filter isUpper t) . words -- then?
08:35:49 <novum> :o is that pattern matching inside a lambda function? uwot
08:36:21 <novum> holy bonhongaloobs. mind=blown
08:36:29 <tdammers> sure
08:36:59 <novum> "sure" as in "not really" or "yes, it's pattern matching inside of a lambda"
08:37:01 <tdammers> I could have spelled it out using head and tail, but this is more concise and, I believe, gets the point across even better
08:37:16 <Cale> Of course, that crashes if it's ever provided an empty list, but it shouldn't be, because words won't produce empty strings.
08:37:20 <tdammers> "sure" as in "why yes, of course it's pattern-matching on a lambda argument"
08:37:29 <tdammers> Cale: yes, it's slightly naughty
08:37:38 <Cale> You can also use a case expression to pattern match anywhere
08:37:42 <novum> Mine doesn't crash *dances*
08:38:07 <Cale> > (\(h:t) -> toUpper h ++ filter isUpper t) []
08:38:09 <lambdabot>  error:
08:38:09 <lambdabot>      • Couldn't match expected type ‘[Char]’ with actual type ‘Char’
08:38:09 <lambdabot>      • In the first argument of ‘(++)’, namely ‘toUpper h’
08:38:25 <novum> concat . map (\x -> (toUpper . head) x : (filter isUpper . tail) x) $ words []
08:38:27 <novum> > concat . map (\x -> (toUpper . head) x : (filter isUpper . tail) x) $ words []
08:38:28 <tdammers> mine doesn't crash either, but I can only prove it manually, the type system doesn't guarantee it
08:38:29 <lambdabot>  ""
08:38:36 <tdammers> concat [ toUpper h ++ filter isUpper t | (h:t) <- words str ] -- this, btw., would be fine
08:39:02 <tdammers> > let str = "hypertext eXtension language" in concat [ toUpper h ++ filter isUpper t | (h:t) <- words str ]
08:39:04 <lambdabot>  error:
08:39:04 <lambdabot>      • Couldn't match expected type ‘[Char]’ with actual type ‘Char’
08:39:04 <lambdabot>      • In the first argument of ‘(++)’, namely ‘toUpper h’
08:39:06 <tdammers> oh
08:39:08 <novum> guys guys guys and gals gals gals: I am just newby, so I was just wondering if my soln is adequate or I am severely off track?
08:39:09 <tdammers> ofc
08:39:14 <tdammers> > let str = "hypertext eXtension language" in concat [ toUpper h : filter isUpper t | (h:t) <- words str ]
08:39:16 <lambdabot>  "HEXL"
08:39:44 <Cale> ah yeah, that should have been a (:)
08:39:54 <Cale> > (\(h:t) -> toUpper h : filter isUpper t) [] -- error
08:39:56 <lambdabot>  "*Exception: <interactive>:3:2-39: Non-exhaustive patterns in lambda
08:40:15 <novum> see I am doing this https://exercism.io/my/solutions/869c1f9863c24bceaf6df3b16ce72105  I don't know if you can see it if you don't log in
08:40:34 <tdammers> one of the best things about list comprehensions is that you can use them to hide failed pattern matches D:
08:40:46 <novum> I believe it to be a fine and dandy implementation, but if I am absolutely just writing terrible code, please let me know
08:42:05 <novum> also this \x notation for lambda is such a brilliant and concise notation. I am beginning to transition from hating haskell as the bane of my existance to loving the concise, provable, mathematical langauge
08:44:39 <tdammers> login wall btw, so no, can't see it
08:44:41 <oats> do y'all have a general rule for when you use a combination of maps and filters or when you use a list comprehension?
08:44:44 <novum> however, with the help of you all, I have changed it to  abbreviate xs = concat . map (\(y:ys) -> (toUpper y) : (filter isUpper ys)) $ words xs
08:45:00 <novum> which handles empty string and everything for the exercise. thanks, all
08:45:03 <tdammers> anyway, don't aim for the shortest possible implementation, aim for the most readable one
08:45:15 <novum> that is indeed what I was trying ot do, tdammers
08:45:19 <novum> do you think my impl was not?
08:45:48 <oats> novum: imo, the list comprehension implementation is easier to understand
08:45:55 <oats> but to each their own
08:46:00 <oats> and I think I just answered my own question
08:46:23 <novum> oats, what is the list comprehension one?
08:46:31 <jle`> novum: note that concat + map happens so often that people have defined a concatMap for covenience
08:46:44 <novum> :D
08:46:47 <novum> ok thanks
08:46:51 <jle`> so you can write abbreviate xs = concatMap (\(y:ys) -> toUpper y : filter isUpper ys) $ words xs
08:47:03 <jle`> or just abbreviate = concatMap (\(y:ys) -> toUpper y : filter isUpper ys) . words
08:47:10 <novum> indeed; I just changed it
08:47:31 <novum> ohh interesting currying. I am never "on the lookout" for stuff like that
08:47:35 <jle`> but i do think the list comprehension way is nice too
08:47:43 <jle`> that's not quite currying, it's more like ... function composition?
08:47:56 <jle`> like seeing myFunc x = f (g x) and seeing that myFunc is just the composition of f and g
08:48:03 <jle`> so myFunc = f . g
08:48:07 <novum> can someone lambdabot:> the "list comprehension" way. I must have missed it
08:48:18 <novum> jle`, ok .. gotcha
08:48:40 <jle`> eearlier tdammers wrote `concat [ toUpper h : filter isUpper t | (h:t) <- words str ]`
08:49:12 <oats> > "a hypertext eXtension" & words & concatMap (\(y:ys) -> toUpper y : filter isUpper ys)
08:49:14 <novum> ah. holy bananas. I have not learned this yet.
08:49:14 <lambdabot>  "AHEX"
08:49:18 <jle`> but list comprehensions have a natural concatenation function you can take advantage of too
08:49:19 <oats> oh that's not bad
08:49:23 <novum> that is rather crazy
08:49:35 <oats> novum: are you familiar with set notation from mathematics?
08:49:41 <oats> er, *set builder notation
08:49:48 <novum> I have learned list comprehension, and I am familiar with set builder notation of course
08:49:55 <oats> ah, ok
08:50:05 <jle`> [ newWord | y:ys <- words str, newWord <- (toUpper h : filter isUpper t) ]
08:50:18 <jle`> er, i mixed up a few things
08:50:19 <novum> however, jamming together functions with the cons operator inside list comprehension is rather weird
08:50:28 <oats> list comprehensions are nice
08:50:32 <oats> I use them all the time in python
08:50:42 <novum> same :) I use python way too much
08:51:04 <jle`> > let str = "hypertext eXtension language" in [ newWord | y:ys <- words str, newWord <- toUpper y : filter isUpper ys ]
08:51:06 <lambdabot>  "HEXL"
08:51:28 <jle`> hm the original explicit-concat version might have been cleaner
08:51:47 <novum> all in favor say AYE. The AYEs have it. *gavel bang*
08:52:01 * novum has learned more than they bargained for. thanks ^u^
08:52:20 <jle`> fun times in #haskell :)
08:52:31 <EvanR> fast times at #haskell high
08:53:12 <novum> dammit I failed some tests. *angry*
08:53:42 <oats> you could also pull out the the mapping function into a `where` if you wanted to be more explicit
08:54:00 <oats> > "hypertext eXtension language" & words & concatMap abbrevWord where abbrevWord y:ys = toUpper y : filter isUpper ys
08:54:01 <lambdabot>  <hint>:1:63: error: parse error on input ‘where’
08:54:04 <novum> apaprently "GNU Image Manipulation Program" fails .. so, it seems I need to discard tails that have all caps >:O
08:54:10 <oats> oh, does lambdabot not do wheres?
08:54:18 <EvanR> yeesh what is everyone using & for
08:54:27 <novum> or just discard all the "initial caps" rather
08:54:30 <oats> EvanR: I like it ¯\_(ツ)_/¯
08:54:36 <oats> it's easier for me to think left to right
08:54:38 <novum> I will figure it out. thanks so much for the direction!
08:54:58 <EvanR> ok but is it evaluating left to right?
08:55:18 <EvanR> like python would
08:55:26 <freeman42x> anyone familiar with Nix could help with this? https://stackoverflow.com/q/58326843/750216
08:55:30 <oats> EvanR: sorry, I don't follow
08:55:59 <EvanR> in blam().flooze().snaz(), what do you expect to evaluate first
08:56:26 <oats> blam()
08:56:36 <EvanR> right
08:56:50 <EvanR> just as in the haskell code f (g (h x))
08:57:36 <oats> EvanR: I'm not sure I understand what point you're trying to make
08:57:46 <EvanR> i am asking a question
08:57:54 <oats> ah
08:58:04 <oats> there I'd expect (h x) to be evaluated first
08:58:09 <EvanR> in h x & g & f, what evaluates first
08:58:23 <oats> also (h x)
08:58:33 <EvanR> in f (g (h x)), h x is not first
08:58:49 <oats> oh right, because lazy evaluation, right?
08:58:54 <EvanR> yes
08:59:05 <EvanR> h x may never happen
08:59:42 <oats> see that makes things more complicated for my brain :<
08:59:54 <EvanR> me too, when i look at h x & g & f :)
09:00:01 <oats> maybe I should, but I'm not often thinking about lazy evaluation when I'm chaining functions together
09:00:22 <EvanR> well evaluation strategy unforunately has direct implications on performance
09:00:31 <EvanR> or even whether the code freezes up
09:00:37 <lyxia>  x & h & g & f   I find nicely understandable as a series of transformations applied to x
09:00:56 <oats> lyxia: that's my thought process exactly
09:00:57 <EvanR> but does it evaluate like that
09:01:07 <EvanR> or does it evaluate as f (g (h x))
09:01:08 <oats> it's the same for monad binds
09:01:18 <oats> I find it much easier to model in my head left-to-right
09:01:20 <maerwald> heh, well... purity makes reasoning about expressions easy, laziness makes it hard ;)
09:01:38 <EvanR> oats: right well, now you can think of f (g (h x)) as left to right :)
09:01:47 <oats> :<
09:01:50 <lyxia> well if you care about performance you have to be aware of how things evaluate either way, and I don't think either way is inherently easier to think about
09:02:03 <EvanR> yes you have to understand all the ways
09:02:15 <EvanR> such is programmering
09:02:24 <maerwald> lyxia: what do you mean
09:02:26 <lyxia> that "f (g (h x))" evaluates "left-to-right" is also pretty naive
09:02:45 <EvanR> it's true that f could be doing shenanigans
09:02:57 <EvanR> but it's also true f applies to that is first
09:03:04 <boxscape> hmm, seems odd that :i works with infix operators without parentheses, *except* for (->), which only works with parentheses
09:03:18 <boxscape> I mean it's obviously because it's wired in
09:03:19 <boxscape> but still odd
09:03:32 <EvanR> @src (&)
09:03:32 <lambdabot> Source not found. You untyped fool!
09:03:57 <EvanR> i have a feling that in x & h & g & f, f applied to everything to the left of it is first
09:04:08 <EvanR> opposite of python
09:04:20 <oats> EvanR: sorry, I think I should've been more clear. I'm thinking about how data is "flowing" through functions, not necessarily the evaluation order. I don't think these are the same thing
09:04:35 <EvanR> no?
09:04:38 <oats> when I'm trying to understand how code works, I don't think about evaluation order
09:04:45 <EvanR> why
09:05:41 <maerwald> because strict evaluation semantics are more intuitive and look a little bit more like "how data flows" 
09:06:08 <EvanR> wouldn't it seem bizarre to being working at a PHP job, and declare that to understand how code works, we don't consider how PHP variable environment works. In javascript, to understand how code works, I do not consider what loads first
09:06:46 <oats> because I can intuit "information on a conveyer belt" much more easily
09:06:55 <EvanR> i understand that part
09:07:08 <oats> I understand that this is not how haskell works
09:07:10 <EvanR> and it seems off to me seeing as how that's not what haskell is doing
09:07:27 <EvanR> in general that is. If there are no bottoms anywhere, what you're saying does work modulo performance
09:07:36 <oats> but for understanding what a piece of code actually means, I think this is an appropriate way to think about it
09:08:03 <EvanR> heh, the metaphorical meaning? ok
09:08:10 <oats> yeah, exactly!
09:08:17 <oats> code is for humans, not machines
09:09:00 <EvanR> i've made myself look pretty silly arguing that in the face of misbahaving code
09:09:20 <maerwald> oats: absolutely
09:09:51 <EvanR> as if when losing at a board game or video game, saying "the game cheataed"
09:10:01 <oats> now for quick anonymous functions, like for `map` or whatever, sure. function composition feels like a natural thing to do
09:10:19 <oats> but I really dislike the `h . g . f $ x` notation
09:10:25 <EvanR> me too
09:10:37 <EvanR> because of the $ x at the end
09:11:05 <EvanR> but that is definitely denoting h (g (f x))
09:13:56 <EvanR> i think it's important and powerful to know when fast and loose reasoning is exactly correct rather than just morally. There are cases when evaluation order doesn't change results
09:18:24 <maerwald> if evaluation order changes results, then the language is not pure :P
09:18:36 <EvanR> welp
09:18:53 <petercommand> haskell is not pure by this definition~
09:32:14 <boxscape> because of pure functions interacting with lazy IO? Or even without any IO?
09:32:56 <Philonous> let x = 1:x in x -- Depending on evaluation order this is either _|_ or [1,1,1,1... ] 
09:33:22 <boxscape> ah, fair
09:33:39 <EvanR> so technically it can change the existence of results
09:34:08 <boxscape> although it kind of seems like [1,1,1,..] is still bottom considering it never terminates, but I'm probably wrong because I don't know the exact definitions
09:34:20 <boxscape> oh but
09:34:21 <boxscape> I see
09:34:28 <boxscape> if you have `take 10` x
09:34:36 <boxscape> it's different and does terminate in only one case
09:34:42 <boxscape> uh, `take 10 x`, rather
09:34:52 <Philonous> Exactly
09:35:11 <EvanR> you can say 1:1:1:... is productive, though i'm not sure if there's a precise definition of that
09:35:26 <EvanR> rather than terminating
09:35:30 <boxscape> aren't there totality checkers based on that? Seems like you'd require a precise definition for that
09:35:42 <EvanR> a productivity checker, yeah
09:36:16 <Cale> But that's the only difference (apart from unsafeInterleaveIO/unsafePerformIO-related stuff). Any evaluation order which terminates produces the same result.
09:39:35 <EvanR> also if some order would produce results, lazy evaluation finds it
09:39:48 <EvanR> lazy evaluation is best evaluation!!!11
09:39:51 <novum> does a function like this already exist? tailDropChars c xs  | (xs !! ((length xs)-1)) == c = tailDropChars c (init xs) | otherwise = xs
09:40:48 <novum> usage: tailDropChars '-' "Hello---"  =>  "Hello"
09:42:05 <boxscape> >  takeWhile (/= '-') "Hello---"
09:42:07 <lambdabot>  "Hello"
09:42:10 <boxscape> not sure if that captures everything you want
09:42:26 <novum> Mmm unfortunately I don't think it does
09:42:39 <novum> > takeWhile (/= '-') "Hello-world-foo-bar---"
09:42:40 <lambdabot>  "Hello"
09:42:59 <novum> I just want to drop the trailing '-'s
09:43:15 <dmwit> > reverse . dropWhile ('-'==) . reverse $ "Hello-world-foo-bar---"
09:43:17 <lambdabot>  "Hello-world-foo-bar"
09:43:30 <dmwit> Bonus: this is O(n), instead of O(n^2) like yours.
09:43:32 <novum> well really I want to be able to make this work: getHyphenChars xs = map (\x -> xs !! (x+1)) ( findIndices ('-' ==) xs )
09:43:47 <novum> reverse twice is efficient??????? what?????
09:44:08 <dmwit> It is when the alternative is iteratively calling (!!) and init.
09:44:16 <ghoulguy> Wow, you were really surprised!
09:44:23 <boxscape> ah yeah dmwit's solution is more accurate than mine
09:44:29 <EvanR> two reverses? hmmmmm
09:44:30 <novum> s/\?+/?/g  sorry
09:44:36 <dmwit> > wordsBy ('-'==) "hello-world-foo-bar----"
09:44:37 <EvanR> i think this is a job for foldl!
09:44:37 <lambdabot>  ["hello","world","foo","bar"]
09:44:40 <Philonous> Text has takeWhileEnd 
09:45:05 <novum> hm. I did see wordsBy and .. I was thinking of using it .. if .. I can use wordsBy just like words but ALSO split on '-'s
09:45:15 <boxscape> > intersperse '-' $ wordsBy ('-'==) "hello-world-foo-bar----"
09:45:17 <lambdabot>  error:
09:45:17 <lambdabot>      • Couldn't match type ‘[Char]’ with ‘Char’
09:45:17 <lambdabot>        Expected type: [Char]
09:45:23 <boxscape> > intercalate '-' $ wordsBy ('-'==) "hello-world-foo-bar----"
09:45:25 <lambdabot>  error:
09:45:25 <lambdabot>      • Couldn't match expected type ‘[Char]’ with actual type ‘Char’
09:45:25 <lambdabot>      • In the first argument of ‘intercalate’, namely ‘'-'’
09:45:30 <boxscape> goddammit
09:45:32 <novum> :o rest in pupperoni
09:45:37 <dmwit> > wordsBy (`elem` "- ") "hello world-foo-bar baz---"
09:45:39 <lambdabot>  ["hello","world","foo","bar","baz"]
09:45:52 <novum> WoW
09:46:02 <novum> *sparkles and sunshine* amaze
09:46:17 <boxscape> > intercalate "-" $ wordsBy ('-'==) "hello-world-foo-bar----"
09:46:20 <lambdabot>  "hello-world-foo-bar"
09:46:42 <Philonous> > intercalate "-" $ wordsBy ('-'==) "foo-----bar----"
09:46:43 <lambdabot>  "foo-bar"
09:46:46 <novum> why you is wrap elem in backticks to make infix? wouldn't ((elem) "- ") work? or somethin?
09:46:58 <dmwit> Try it and see!
09:47:07 * novum giggles hmmmmmm ok
09:47:45 <EvanR> @pl \y -> f y x
09:47:45 <lambdabot> flip f x
09:48:06 <gaze__> Hey folks. Any idea why Rasterific has chosen a free monad encoding instead of final tagless? https://github.com/Twinside/Rasterific/blob/master/src/Graphics/Rasterific/Command.hs
09:48:43 <novum> From WHENCE cometh wordsBy?
09:48:56 <dmwit> ?hoogle wordsBy
09:48:56 <lambdabot> Data.List.Split wordsBy :: (a -> Bool) -> [a] -> [[a]]
09:48:56 <lambdabot> Data.List.Split.Internals wordsBy :: (a -> Bool) -> [a] -> [[a]]
09:48:56 <lambdabot> Data.List.Extra wordsBy :: (a -> Bool) -> [a] -> [[a]]
09:49:47 <dmwit> It would be cool if Hackage offered a "find package by module name" feature.
09:49:54 <novum> I have not these packages
09:50:10 <dmwit> Anyway, in the meantime, the web version of hoogle will tell you that part.
09:50:24 <novum> import Data.List.Split -> Errrrror
09:54:13 <Geekingfrog> How do I find where an instance is coming from? I'm having some weird error with something like `a <|> b :: Either Text Int` and I'd like to have a look at the instance of Alternative for (Either Text)
09:54:43 <dmwit> You can ask with :i in ghci. The haddocks often, but not always, also say.
09:58:24 <Geekingfrog> Cheers
10:00:38 <novum> I don't want to cabal install. not possible to get wordsBy then?
10:01:34 <dmwit> No. You may install it another way than through cabal, or you may implement it yourself; I assume both of those qualify as "no" for your intended question.
10:03:16 <novum> your assumption may be equated with what may be perceived as the truth given my perspective of the problem at hand. thanks
10:09:02 <novum> JEEZ tor is booty sometimes
10:09:05 <dmwit> > fromMaybe "" . foldr (\c res -> if c == '-' then (c:)<$>res else Just (c:fromMaybe "" res)) Nothing $ "abc-def---"
10:09:07 <lambdabot>  "abc-def"
10:09:20 <novum> I didn't see anything since dmwit said "No."
10:09:21 <dmwit> EvanR: foldr is good enough ;-)
10:09:39 <dmwit> (no need to drag foldl into things)
10:10:25 <novum> I give up. I am not good enough at haskell. I never will be. YOU CAN'T FIRE ME I QUIT.
10:10:29 <EvanR> foldl feels LEFT out :(
10:10:47 <EvanR> see what i did there
10:11:02 <dmwit> Sure, it's easy to see, it's RIGHT there.
10:11:21 <novum> you two are both backwards
10:11:57 <dmwit> ooo
10:12:11 * EvanR flips a table why does foldl even exist!
10:12:18 <dmwit> > fold . foldr (\c res -> if c == '-' then (c:)<$>res else Just (c:fold res)) Nothing $ "abc-def---"
10:12:20 <lambdabot>  "abc-def"
10:12:38 <dmwit> fold is prettier than fromMaybe "" ^_^
10:13:05 <novum> I am not able to solve exercism's exercise. I am suck.
10:13:32 <dmwit> Keep working at it then!
10:14:37 <novum> maybe someone can make a haskell-lite for newbies that suck at haskell like me
10:14:43 <novum> haskelll for short
10:15:19 <sm> haskell lite/haskellscript is a good idea!
10:15:36 <sm> only a matter of time, hopefully
10:15:45 <oats> novum: hey, don't be so hard on yourself
10:16:05 <wildtrees> there is runghc/runhaskell for running haskell programs as scripts already 
10:16:08 <oats> haskell is a lot of stuff to digest if you come from an imperative background
10:16:17 <oats> but it can be so much fun when it starts to click
10:16:18 <nshepperd2> jle`: the equipping-your-library link in https://hackage.haskell.org/package/backprop-0.2.6.3/docs/Numeric-Backprop.html is broken
10:16:31 <sm> wildtrees: and stack, which does it better
10:16:52 <sm> and maybe cabal does that now as well ?
10:16:57 <dmwit> sm: What would you drop from Haskell to make -lite?
10:17:19 <sm> dmwith: good question! big topic
10:17:25 <EvanR> there are many features you'll find uncuttable once you learn them
10:17:34 <EvanR> making haskell-lite harder to define
10:18:44 <cocreature> can I get haskell-heavy?
10:18:47 <sm> perhaps as a first step, you'd make it "haskell with the most helpful extensions & legacy cruft jettisoned"
10:19:17 <sm> it would need its own stackage snapshots of compatible packages I suppose
10:19:18 <oats> cocreature: haskell, but a fallback imperative language for when you write nonsense functional code :P
10:19:32 <EvanR> yeesh..
10:19:33 <nshepperd2> fortified haskell, for those cold winter nights
10:19:36 <cocreature> oats: we all know that Hakell is the best imperative language, right? :)
10:19:42 <oats> hehe
10:20:02 <EvanR> doesn't haskell already have inline C
10:20:27 <novum> don't try to make me feel better! I *deserve* to be unhappy! ;_; sigh thanks oats. it's a hard knock life.
10:20:28 <sm> perhaps as step two you'd give it a new, full-featured prelude (eg rio)
10:21:17 <oats> I once came across a JIT compiler for something written in haskell that had its own monadic x86 asm dsl
10:21:45 <cocreature> oats: we have a monadic dsl for llvm in llvm-hs :)
10:21:58 <oats> that's awesome :P
10:22:03 <sm> it would have to be supported by ghc
10:22:31 <oats> novum: what's the exercise you're doing?
10:22:58 <novum> an evil, evil one titled "Acronym", but you must be logged in on exercism.io to see it.
10:23:00 <oats> cocreature: like llvm ir?
10:23:04 <cocreature> oats: yeah
10:23:13 <oats> cocreature: linky?
10:23:14 <novum> it's actually probably a rather easy one, but I just SUCK. so,
10:23:55 <cocreature> oats: https://github.com/llvm-hs/llvm-hs/blob/llvm-9/llvm-hs-pure/test/LLVM/Test/IRBuilder.hs#L312
10:24:27 <novum> oats, here is the test https://github.com/exercism/haskell/blob/master/exercises/acronym/test/Tests.hs#L26
10:25:17 <oats> cocreature: that's dirty
10:25:18 <oats> I love it
10:25:55 <novum> any way to convert the character after any - to upper case :D
10:26:00 <cocreature> oats: thanks to `MonadFix` you can even have forward references :)
10:27:35 <oats> hmm, I haven't seen MonadFix before
10:27:39 <oats> :i MonadFix
10:27:49 <oats> that is not ghci
10:28:15 <petercommand> :info MonadFix
10:28:30 <petercommand> oh, not this one either
10:28:33 <oats> hehe
10:28:42 <novum> it seems rather hard to achieve this since recursion and list comprehension both deal with the character at hand. how can you "remember" the previous character
10:29:52 <novum> or use a map of sorts to apply a function to the character that follows if it does not exceed the length of the list
10:30:29 <sternmull> novum: You could use a pattern like "a:b:rest" to match the next two characters and then decide how to continue.
10:30:39 <novum> what the unicode
10:32:53 <novum> sternmull, I guess you're using emoji.lua or something in weechat. did you type :b:? is that "a:b:rest"? I cannot really read it
10:33:42 <EvanR> > let xs = "hello world" in zip xs (drop 1 xs)
10:33:44 <lambdabot>  [('h','e'),('e','l'),('l','l'),('l','o'),('o',' '),(' ','w'),('w','o'),('o',...
10:33:47 <petercommand> novum: the latter
10:33:55 <EvanR> novum: trick to iterate over adjacent characters
10:34:10 <oats> novum: what do trailing hyphens have to do with this exercise?
10:34:11 <sternmull> novum: i typed plaintext, its your client that truns it into emojis...
10:34:55 <novum> oats, nothing; however, I did not want my function  getHyphenChars xs = map (\x -> xs !! (x+1)) ( findIndices ('-' ==) xs )  to break when it had trailing hyphens
10:35:10 <novum> and I will no longer be using getHyphenChars for a couple of reasons
10:42:27 <novum> got it. thanks again.   upperAfter c xs = (head xs) : [ (if x1 == c && isAlpha x2 then toUpper x2 else x2) | (x1,x2) <- zip xs (drop 1 xs) ]
10:44:31 * hackage aeson-gadt-th 0.2.1.2 - Derivation of Aeson instances for GADTs  https://hackage.haskell.org/package/aeson-gadt-th-0.2.1.2 (abrar)
10:49:19 <oats> novum: yikes, this is a tricky one
10:49:29 * oats is poking at it
10:50:16 <novum> with the expert help of you all - for which I am ETERNALLY greatful - I have been able to hack away at the solution until I was finally able to solve it. You can view it here <https://exercism.io/tracks/haskell/exercises/acronym/solutions/869c1f9863c24bceaf6df3b16ce72105> but I would recommend that you create an account and try it yourself.
10:50:43 <novum> it's not very readable
10:53:05 <novum> when I first started, I thought it was going to be an easy problem for a baby haskeller, like me. It was not.
11:00:57 <monochrom> Does exercism require the use of stack?
11:02:09 <oats> monochrom: I think so
11:02:18 <novum> it basically does a stack new for you, renames src/lib.hs, and provides test/Tests.hs
11:02:34 <novum> you don't HAVE to use it. You can just do $ exercism submit src/*.hs
11:02:55 <ghoulguy> exercism is stuck using package.yaml files, so you'll need a copy of hpack around
11:03:58 <oats> ghoulguy: I thought package.yaml was the way stack currently works
11:04:30 <trcc> Is there a roadmap for ghc 9, or is that not a thing?
11:04:55 <sm[m]> stack will use a package.yaml, but doesn’t require it
11:13:14 <ghoulguy> oats: Yes, but the topic was on not having to use stack
11:15:32 <oats> ahh
11:19:21 <oats> http://ix.io/1YfJ/hs
11:19:26 <oats> there's the solution I came up with
11:21:50 <novum> oats, how u doin
11:22:12 <oats> novum: http://ix.io/1YfJ/hs
11:22:58 <novum> you used Data.List.Split cheater :P
11:23:18 <novum> cool nice
11:23:22 <oats> just using the tools at my disposal ¯\_(ツ)_/¯
11:23:37 <novum> :3 well donezo
11:26:12 <novum> splitWhen (`elem` "- ")  possibru?
11:27:52 <hseg> w/quit
11:31:21 <sternmull> Is there some good intermediate material to get a better feeling the use of currying, recursion and higher order functions? I am fine writing fairly complex recursive functions. But something like "const id" takes some time to understand and i still fail to understand more complex stuff like "foldr (\x f xs -> f (x : xs)) id xs []". I guess i need to learn some basics about this and do some exercises.
11:34:15 <trcc> When building with Stack, is there a way to specify a path to where it should place the executable?
11:34:25 <trcc> cannot find it in stack build --help
11:34:44 <jle`> nshepperd2: oh no :O
11:35:15 <jle`> thanks for letting me know
11:35:39 <jle`> sternmull: for that the best way to understand it i think is to just practice evaluation
11:35:41 <jle`> by hand
11:36:30 <jle`> for example try evaluating foldr (\x f xs -> f (x : xs)) id [1,2,3] [] by hand
11:36:36 <jle`> sternmull: to do this, look at the definition of foldr
11:36:38 <jle`> @src foldr
11:36:39 <lambdabot> foldr f z []     = z
11:36:39 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
11:36:43 <jle`> and figure out which pattern it matches on
11:36:57 <sternmull> jle`: I did this for the fold expression wiht "abc" as argument and ended up with the correct output. But even with seeing the steps it took i am unable to get the concept.
11:36:57 <jle`> and replace that pattern appropriately with the right hand side
11:37:10 <oats> novum: it would probably pass the tests, but isSpace tests for a few other whitespace charactors
11:37:15 <jle`> i'm afraid there isn't anything higher to 'get', maybe
11:37:32 <jle`> if you can go through it and get the final result, then you understand everything about it for the most part
11:37:35 <jle`> sometimes some functions are just boring
11:39:15 <novum> @src wordsBy
11:39:15 <lambdabot> Source not found. My pet ferret can type better than you!
11:39:22 <pikajude> does haskell-ci support non-travis sources?
11:39:28 <pikajude> err platforms i guess
11:39:46 <sternmull> I think with years of background in C++ and Python it confuses something deep inside my brain when "a -> b" becomes "a -> (b -> c)" which is "a -> b -> c". I know what is going on... but it breaks my intuition.
11:40:08 <Cale> sternmull: I'm trying to think of what the best way might be to explain what's going on with that foldr. It's basically a trick to get "state"
11:40:30 <Cale> sternmull: i.e. you're starting out with an [] (this is the argument provided at the end to the function which gets constructed)
11:40:42 <Ariakenom> sternmull: I always make a point of not reusing variables for examples like that
11:40:49 <Cale> and then each of the elements of xs is added to the beginning of the "state", in turn
11:41:00 <Cale> So the outcome is that the list is reversed
11:41:15 <Cale> and when the input list is exhausted, id is applied to the result
11:41:20 <Cale> (which does nothing)
11:41:35 <Cale> So the result is just to reverse the input list
11:41:45 <jle`> hm, what does the function do actually? ghci doesn't seem to be happy with it on my end
11:41:52 <Cale> > foldr (\x f xs -> f (x : xs)) id [1,2,3] [] -- hopefully I'm right?
11:41:54 <lambdabot>  [3,2,1]
11:41:57 <Cale> yes :)
11:42:04 <sternmull> Cale: I get that the third argument is used to accumulate the reversed list. But i think what confuses me is that the "accumulator" of the fold is a function... and i always used to think about it as a value.
11:42:13 <jle`> ah, i typo'd
11:42:22 <jle`> sternmull: it's still a value here, though
11:42:33 <jle`> functions are just normal values
11:42:48 <Cale> sternmull: Well, functions are values too -- we're basically accumulating a function which is going to take an arbitrary list, and add the input list, reversed, to its beginning
11:43:00 <Cale> sternmull: It might help to change perspective a little bit
11:43:01 <jle`> in this case it might be helpful to imagine 'f' as a diff list
11:43:20 <jle`> here maybe the pointfulness harms us
11:43:21 <Cale> > foldr (\x f -> f . (x:)) id [1,2,3] []
11:43:22 <lambdabot>  [3,2,1]
11:43:26 <Cale> This is the same thing
11:43:33 <jle`> foldr (\x f -> f . (x:)) -- woops, was writing the same thing
11:43:56 <jle`> here f is a "diff list", or what sometimes people call a "Builder"
11:43:58 <Cale> Now, let me introduce you to a trick...
11:44:12 <Cale> Maybe I'll start by writing reverse in a more naive and simple way
11:44:14 <jle`> sternmull: maybe the thing is that you are thinking of functions as verbs, but here this function is a noun
11:44:17 <Cale> reverse [] = []
11:44:28 <jle`> it's a 'thing' we build.  a Builder we construct
11:44:30 <Cale> reverse (x:xs) = reverse xs ++ [x]
11:44:43 <Cale> Here we have reverse :: [a] -> [a]
11:45:03 <Cale> A problem with this function is that xs ++ ys takes O(length xs) time to compute
11:45:08 <Cale> (necessarily)
11:45:25 <Cale> So this reverse is quadratic time in the length of the input list
11:45:27 <Ariakenom> > foldr (\x f -> f . (x:)) id [x,y,z] [] :: Expr
11:45:29 <lambdabot>  error:
11:45:29 <lambdabot>      • Couldn't match expected type ‘Expr’ with actual type ‘[Expr]’
11:45:29 <lambdabot>      • In the expression:
11:45:37 <sternmull> jle`: I understand the concept of higher order functions. But applying an argument to the result of foldr still confuses me. But i think the explanation of Cale gets me much closer to understand what is going on.
11:45:51 <Ariakenom> > foldr (\x f -> f . (x:)) id [x,y,z] [] :: [Expr]
11:45:53 <lambdabot>  [z,y,x]
11:46:10 <Cale> But here's the trick: instead of constructing a list, we can construct a function, which when applied to any list, will add the elements we want to it.
11:46:12 <jle`> sternmull: it might be confusing that the BUilder is 'nakedly' applied to the reuslt
11:46:20 <jle`> @let runBuilder f x = f x
11:46:21 <lambdabot>  Defined.
11:46:24 <Ariakenom> > foldr (\x f -> f . g) id [x,y,z] [] :: [Expr]
11:46:24 <Cale> i.e. so we can then apply that function to an empty list to obtain our result
11:46:26 <lambdabot>  error:
11:46:26 <lambdabot>      • No instance for (FromExpr [Expr]) arising from a use of ‘g’
11:46:26 <lambdabot>      • In the second argument of ‘(.)’, namely ‘g’
11:46:38 <jle`> > runBuilder (foldr (\x f -> f . (:x)) [1,2,3])      []
11:46:40 <lambdabot>  error:
11:46:41 <lambdabot>      • Couldn't match expected type ‘[a] -> c’
11:46:41 <lambdabot>                    with actual type ‘[Integer]’
11:46:45 <jle`> > runBuilder (foldr (\x f -> f . (:x)) id [1,2,3])      []
11:46:47 <lambdabot>  error:
11:46:47 <lambdabot>      • Occurs check: cannot construct the infinite type: a ~ [a]
11:46:47 <lambdabot>        Expected type: [a] -> [a]
11:46:52 <Cale> This means that instead of constructing a result of type [a], we'll construct a function of type [a] -> [a]
11:46:57 <Cale> and instead of [] we'll use id
11:47:06 <Cale> (because that takes any list and adds no elements to it)
11:47:22 <jle`> > runBuilder (foldr (\x f -> f . (x:)) id [1,2,3])      []
11:47:24 <Cale> instead of the singleton list [x] we'll use (x:)
11:47:24 <lambdabot>  [3,2,1]
11:47:33 <Cale> (the function which adds x to any list)
11:47:43 <jle`> @let initialBuilder x = x
11:47:44 <lambdabot>  Defined.
11:47:51 <Cale> and instead of (++) we'll use function composition(.)
11:48:14 <Cale> This is a win, because while xs ++ ys is O(length xs) time, f . g is constant time no matter what
11:48:32 <Cale> reverse [] = id
11:48:44 <Cale> reverse (x:xs) = reverse xs . (x:)
11:48:57 <Cale> reverse :: [a] -> ([a] -> [a])
11:49:29 <Cale> and then to recover our original function, we can just do something like  reverse' xs = reverse xs []
11:49:37 <Cale> (or perhaps I should have named them the other way around)
11:49:44 <Cale> good?
11:50:07 <Cale> If you understand this, we can go back and understand that foldr in a new way
11:50:21 <sternmull> Cale: I will have to re-read your words and think carefully about it. But it starts to actually make sense now! Thank you very much!
11:50:46 <jle`> this diff list pattern is actually a common thing used in a lot of places
11:50:51 <jle`> for example it's what the Show typeclass uses internally
11:51:04 <jle`> if you've ever wondered why Show is defined in terms of shows instead of show
11:52:12 <Cale> This is an example of something referred to in some older papers as the "worker-wrapper transformation", the idea is just that sometimes in order to obtain a more efficient algorithm, all we have to do is find a way to translate back and forth to a type which supports the operations we want to perform more efficiently.
11:52:44 <jle`> @let newtype Builder a = B { runBuilder :: [a] -> [a] }
11:52:45 <lambdabot>  .L.hs:162:1: error:
11:52:45 <lambdabot>      Multiple declarations of ‘runBuilder’
11:52:45 <lambdabot>      Declared at: .L.hs:158:23
11:52:53 <jle`> @let newtype Builder a = B { runB :: [a] -> [a] }
11:52:55 <lambdabot>  Defined.
11:53:12 <jle`> @let initBuilder = B id
11:53:13 <lambdabot>  Defined.
11:53:26 <jle`> :t foldr (\x (B f) -> B (f . x)) initBuilder
11:53:28 <lambdabot> Foldable t => t ([a] -> [a]) -> Builder a
11:53:31 <jle`> :t foldr (\x (B f) -> B (f . (x:))) initBuilder
11:53:33 <lambdabot> Foldable t => t a -> Builder a
11:53:35 <jle`> oops
11:53:55 <jle`> so this foldr is the same function as your original one.  only instead of returning an [a] -> [a] directly, we return a "list builder"
11:54:05 <jle`> @let reverseBuilder = foldr (\x (B f) -> B (f . (x:))) initBuilder
11:54:06 <lambdabot>  Defined.
11:54:14 <jle`> > runB (reverseBuilder [1,2,3]) []
11:54:16 <lambdabot>  [3,2,1]
11:54:21 <sternmull> I wonder if you guys are so quick to understand this fold only because you already know the pattern, would you also be able to quickly see  its meaning from more basic building blocks if you would not be aware of the pattern? If so, what are the fundamental "tools" you have to master?
11:54:33 <jle`> this builder will append the reversing thing ot wahtever list you give
11:54:36 <jle`> > runB (reverseBuilder [1,2,3]) [0,0,0]
11:54:39 <lambdabot>  [3,2,1,0,0,0]
11:54:51 <Cale> sternmull: Well, that actually isn't the *first* way that I thought about that foldr
11:55:00 <Cale> sternmull: Let's look at another example...
11:55:27 <jle`> hm yeah for me i saw it through familiarity with this "builder" pattern, which happens for a lot of cata's like foldr
11:55:36 <Cale> > foldr (\x xs s -> s : xs (s+x)) (\s -> [s]) [1,2,3,4,5] 0
11:55:38 <lambdabot>  [0,1,3,6,10,15]
11:55:43 <jle`> instead of returning a value directly of the type you want, return a "builder" of that value
11:55:52 <jle`> so here instead of returning directly a reverse list, we return a "reversed list builder"
11:55:58 <Cale> Here, it's as if we have an additional 'state' parameter s
11:56:03 <Cale> which starts out as 0
11:56:32 <Cale> and as we walk through the list, we're emitting the present value of the state in the resulting list, before proceeding with (s+x) as the new state
11:56:51 <jle`> "returning a builder" is a common pattern to invert control because for functions like foldr, fold from the inside-out, but reverse demands you fold from the outside-in
11:56:59 <Cale> and then if we reach the end of the list, we emit one more element with the final state in it
11:57:13 <jle`> so "returning a builder" allows you to turn an inside-out function like foldr and make it work outside-in
11:57:19 <Cale> You can just sort of read the foldr this way directly
11:57:30 <jle`> it's essentially how you also can implement foldl (an 'outside-in' fold) in terms of foldr
11:57:41 <Cale> It might take a bit of thinking to work out why this is a valid interpretation of what's taking place
11:57:55 <Cale> But regardless, you can see that the result is consistent with that
11:58:01 * hackage happstack-server 7.5.4 - Web related tools and services.  https://hackage.haskell.org/package/happstack-server-7.5.4 (JeremyShaw)
11:58:34 <Cale> [0,1,3,6,10,15] = [0, 0+1, 0+1+2, 0+1+2+3, 0+1+2+3+4, 0+1+2+3+4+5]
11:59:34 <jle`> sternmull: please de-calate mine and cale's messages heh they are basically unrelated :) sorry for interspersing them like that
11:59:53 <jle`> actually this pattern of "returning a builder" to invert control flow is something i talked about in a blog post earlier this year, https://blog.jle.im/entry/tries-with-recursion-schemes.html
12:00:09 <jle`> we have a higher order function that folds up a trie inside-out
12:00:18 <jle`> but we needed to write a function (Trie lookup) that is essentially outside-in
12:00:34 <jle`> so instead of returning our looked-up value, we return a looker-upper function
12:00:40 <sternmull> no problem. I will have to meditate over the last messages anyway. But i think they are extremely helpful to getting it.
12:03:02 <jle`> sternmull: i would suggest if you are looking for a logical next step, try implementing foldl in terms of foldr
12:03:36 <jle`> foldl is inherently outside-in, so you can't directly return your result from it using the inside-out foldr
12:04:12 <jle`> so you have to he creative with returning "builders". or "folders" in this case technically
12:04:55 <sternmull> sounds like a good exercise
12:31:16 <kiwi_59> I have this code that I'm expecting to run lazily and grab items from an infinite list, but it seems to be executing strictly and running forever -- could anyone help me figure out what I have wrong? (https://gist.github.com/charleskinbote/4c08d86a391eb61ef34f9346cfd40d24) 
12:33:58 <monochrom> kiwi_59: Does "Control.Monad.Loop" come from monad-loops?
12:34:02 <opqdonut> kiwi_59: iterateM_ doesn't do what you think it does
12:34:24 <kiwi_59> monochrom yes
12:34:41 <opqdonut> iterateM_ never returns a value (look at the type!)
12:34:47 <opqdonut> I guess you want unfoldM from that library?
12:34:58 <opqdonut> or just write the loop out yourself to know what it does :)
12:35:00 <kiwi_59> opqdonut my impression is that it repeatedly applies a function f to an input, continually feeding the output of f(x) like f(f(f(...(x)))
12:35:11 <opqdonut> yes, but it never returns anything
12:35:20 <opqdonut> iterateM_ :: Monad m => (a -> m a) -> a -> m b
12:35:37 <opqdonut> you see how the return value is "m b"? the type "b" occurs nowhere else so it can't return
12:35:38 <monochrom> Monad m => (a -> m a) -> a -> m nothing_to_do_with_any_input
12:35:40 <kiwi_59> seems like it returns an "m b"?
12:35:56 <EvanR> f(f(f(f(...)))) no x
12:36:28 <opqdonut> even if it would return, wouldn't the right type be "State StdGen [[a]]"?
12:36:32 <EvanR> you drop a rock off the cliff into the darkness waiting to hear it hit the floor but nothing
12:36:34 <monochrom> For a simpler example, if I give you "f :: a -> b" you know that f is useless.
12:37:17 <kiwi_59> monochrom that doesn't entirely make sense to me, there are lots of trivial functions of that type
12:37:36 <EvanR> forall a b . a -> b is impossible
12:38:11 <kiwi_59> ah ok, so let me back up for a minute then and explain what I'm trying to do...
12:38:16 <monochrom> You're probably thinking I have a specific type "a" and a specific type "b" in mind, like I have "Int -> Bool" in mind but I'm just not telling you.
12:38:36 <monochrom> But no, I have "f :: for all a, for all b, a->b" in mind
12:39:04 <kiwi_59> I have a function that is of type (a -> State StdGen a) and I want to effectively call (input >>= f) n times, is there a function for that?
12:39:36 <monochrom> unfoldM sounds more like it.  You want to produce an infinite list.  iterateM_ produces nothing, it's only point is the effects, e.g., if m=IO and you just want to call putStrLn infinitely many times.
12:39:36 <kiwi_59> feeding the output into the next input (intput >>= f >>= f ... { n } ... >>= f)
12:40:50 <monochrom> I think we figured out that much.
12:41:01 <kiwi_59> ok, ill look into unfoldM
12:41:02 <kiwi_59> thanks
12:41:06 <monochrom> Our question is do you want to obtain an output list or not.
12:41:14 <kiwi_59> ah, yes I do
12:41:34 <monochrom> Because iterateM_ is advertising that it won't do that.
12:42:43 <kiwi_59> ok, understood now. wouldn't iterateM do what I want, then?
12:43:11 <monochrom> Does it exist?
12:43:21 <EvanR> what's the type of iterateM
12:43:32 <EvanR> it's pretty much all you need to know to answer that
12:44:20 <monochrom> unfoldrM is the closest fit.
12:45:06 <EvanR> i never use monad-loops. I always need a specific kind of monad loop, and it may exist, may not. But since it will take 1 line of code i don't install monad-loops
12:45:11 <monochrom> But normally I wouldn't even download monads-loops I would just handcode my own.
12:45:48 <EvanR> JINX
12:49:25 <kiwi_59> this is what ended up working for me, thanks guys: https://gist.github.com/charleskinbote/d3175777191b4ce627fae59a6b89ef2e
12:51:36 <boxscape> % f | let x = 4, x > 3 = 5 -- I just found out you could do this through spj's haskellX talk, I had no idea you could use let bindings like this in guards
12:51:36 <yahb> boxscape: 
12:52:00 <enrio> hi guys
13:02:56 <boxscape> are `f | x <- y` and `f | let x = y` the same thing?
13:06:16 <ghoulguy> boxscape: Yeah, in the case of a simple variable `x` in that position
13:06:35 <boxscape> ghoulguy is there a more complex case where they're not?
13:06:44 <boxscape> oh wait
13:06:46 <ghoulguy> f | Just x <- y 
13:06:53 <ghoulguy> and f | let Just x = y =
13:06:57 <boxscape> right, if y isn't used, right?
13:07:15 <ghoulguy> No, it's not related to things being used
13:07:43 <ghoulguy> its related to a pattern that needs to be matched
13:07:48 <boxscape> right, okay
13:09:53 <boxscape> (I mean x not being used, actually. But I realize it's not quite that straightforward)
13:11:00 <ghoulguy> > let f | Just _ <- Nothing = 'a' | otherwise = 'b' in f
13:11:02 <lambdabot>  'b'
13:11:07 <ghoulguy> > let f | let Just _ = Nothing = 'a' | otherwise = 'b' in f
13:11:09 <lambdabot>  'a'
13:11:34 <[exa]> quick question: Does Brick work on windows?
13:11:40 <ghoulguy> [exa]: no
13:11:52 <ghoulguy> At least not natively
13:13:15 <cheater> hi
13:13:45 <[exa]> ghoulguy: oh noes.
13:13:51 <[exa]> any good workarounds?
13:13:54 <cheater> i'm using for on a list of lists and instead of iterating over the single lists inside it, i'm somehow iterating over permutations.  any ideas why?
13:14:12 <ghoulguy> [exa]: cygwin, WSL, (not using Windows)
13:14:15 <Rembane> :t for 
13:14:16 <lambdabot> (Traversable t, Applicative f) => t a -> (a -> f b) -> f (t b)
13:14:20 <Rembane> cheater: That for? 
13:14:57 <[exa]> ghoulguy: OK I kindof expected that
13:15:05 <[exa]> (I'm not on windows but some students are)
13:18:12 <ghoulguy> [exa]: Tell them not to play games during class :)
13:19:06 <[exa]> :]
13:19:56 <siraben> Is it possible to get Haskell to complain about partial functions?
13:20:10 <siraben> Like incomplete pattern matching, etc.
13:20:13 <c_wraith> honestly, wsl is really good. for those not on win10, cygwin is... sort of OK. 
13:20:24 <c_wraith> siraben: -Wall
13:21:18 <c_wraith> it can't catch everything, since incompleteness checking is Turing-complete 
13:21:27 <c_wraith> but it catches common errors. 
13:21:50 <int-e> . o O ( There's the lazy approach to this problem where the complaints are delayed to the runtime ;-) )
13:23:50 <Rembane> So you can also write tests that exercise all code paths.
13:29:11 <EvanR> unless you can't
13:29:24 <EvanR> infinite code paths
13:46:59 <cheater> hi. why would this iteration behave like some sort of permutation thing? http://paste.ubuntu.com/p/hKcY8FZNvg/  output: http://paste.ubuntu.com/p/SPrwsN4spG/      i would expect idPairs and concat listOfLists to have the same amount of elements.
13:47:57 * nshepperd2 . o O ("Unlimited Code Paths!")
13:50:26 <cheater> is the list monad somehow weird?
13:50:58 <Rembane> I don't know, but the Applicative instance for lists is weird.
13:51:23 <cheater> we're not using applicatives here though, just Functor
13:51:46 <Rembane> > (,) <$> [1..5] <*> [6..10]
13:51:49 <lambdabot>  [(1,6),(1,7),(1,8),(1,9),(1,10),(2,6),(2,7),(2,8),(2,9),(2,10),(3,6),(3,7),(...
13:52:23 <cheater> that's not exactly what i want - the right list should change based on the element of the left list we're looking at
13:53:31 * hackage hjsmin 0.2.0.3 - Haskell implementation of a javascript minifier  https://hackage.haskell.org/package/hjsmin-0.2.0.3 (ErikDeCastroLopo)
13:57:21 <lavalike> > concat $ zipWith (\xs ys -> (,) <$> xs <*> ys) [[1,2],[3,4]] ["ab","cd"]
13:57:23 <lambdabot>  [(1,'a'),(1,'b'),(2,'a'),(2,'b'),(3,'c'),(3,'d'),(4,'c'),(4,'d')]
13:58:37 <boxscape> what does the [safe] mean in something like "instance [safe] Sized Bool" (in a compiler message)
14:02:42 <phadej> that it's defined in {-# LANGUAGE Safe #-} module
14:03:52 <boxscape> I see
14:04:36 <cheater> figured it out: for is not flip map
14:04:45 <cheater> it's flip traverse
14:05:06 <cheater> i don't know how traverse iterates exactly ...
14:05:52 <cheater> lavalike: also not exactly what i want :)
14:05:59 <cheater> but i think i've fixed my bug now. thank you.
14:09:58 <ziman> is there a short name for (foldr (<|>) empty) in the stdlib?
14:11:26 <jle`> ziman: asum, or msum
14:13:16 <ziman> ah, Data.Foldable.asum, thank you!
14:13:22 <jle`> np :)
14:13:34 <jle`> it's pretty useful, yeah
14:13:51 <jle`> wish there was some idiom for asum . fmap _, though, that worked for non-traversables
14:13:55 <jle`> er, non-functors
14:14:35 <jle`> right now the only ways to do a asumMap are kind of clunky
14:17:15 <nshepperd1> :t alaf Alt foldMap
14:17:16 <lambdabot> forall k2 (t :: * -> *) (g :: k2 -> *) (b :: k2) a. (Foldable t, Monoid (Alt g b)) => (a -> g b) -> t a -> g b
14:21:57 <fizbin> Hey, did something happen the the "-hT" RTS option in recent GHC? I'm trying to follow http://blog.ezyang.com/2011/05/anatomy-of-a-thunk-leak/ and when I try "+RTS -hT" my program says "invalid heap profile option: -hT" followed by the standard "you said an RTS option wrong" text.
14:24:34 <fizbin> Or does -hT only work if you *don't* compile something with profiling?
14:26:38 <ChaiTRex> fizbin: Think you need no profiling, though they might have fixed that: https://gitlab.haskell.org/ghc/ghc/issues/15086
14:27:03 <nshepperd1> jle`: backprop is a really neat library btw
14:27:21 <jle`> nshepperd1: ah, thanks :)
14:27:26 <jle`> it was a lot of fun to write actually
14:27:35 <jle`> but i've been meaning to do a rewrite for a more gpu-accessible background
14:28:58 <jle`> ah, the docs page should be back up now
14:29:20 <nshepperd1> \o/
14:30:17 <nshepperd1> It definitely fills the gap of "something like ad, but extensible"
14:32:20 <jle`> the 'compound types' part is the trickiest thing, being able to handle product types, which is most data models
14:36:23 <nshepperd2> i was wondering earlier if gpu could be handled by adding another layer of abstraction. like you'd define matmulOp :: Op [Tensor [a,b], Tensor [b,c]] (Tensor [a,c]) 
14:37:07 <nshepperd2> where Tensor is some abstract non-materialized representation of what needs to be done to make the tensor, which means the ops can be pure
14:37:49 <nshepperd2> which is later materialized with some Tensor xs -> IO (RealTensor xs) operation which actually executes everything
14:37:54 <nshepperd2> basically the tensorflow model
14:39:24 <nshepperd2> at least that's how I might attempt to do it without modifying the library at all
14:46:15 <EvanR> man i just did some bizarre convolution with this functor + state code
14:47:06 <EvanR> F (State S Int) -> State S (F Int)
14:48:15 <c_wraith> that's commuting the effects 
14:48:28 <EvanR> what is the effect of a functor...
14:48:46 <c_wraith> whatever it is that the functor does. 
14:49:06 <monochrom> Depends on which functor.
14:49:09 <EvanR> it's just a tree with a paramertized leaf in one spot
14:50:05 <EvanR> anyway to get the implementation of that to type check i wrote some code that looks terrible
14:50:26 <monochrom> That sounds like there is no single natural thing we should expect of  F (State S Int) -> State S (F Int)
14:51:11 <cheater> why is for different than flip map?
14:51:34 <EvanR> wait, maybe this is just a Traversible?
14:53:12 <dminuoso> jle`: Are you around?
14:55:05 <EvanR> sequence
14:56:11 <EvanR> but the code was to avoid writing out a huge case statement to map F A to F B for mostly constants
14:56:17 <EvanR> which Applicative would make me do
14:56:39 <monochrom> "for" and "flip map" would be the same in an imperative language.  And even then you would have to assume that the only functor/applicative/monad is IO.
14:57:20 <monochrom> Outside that context there is no reason to even consider them related.
14:58:05 <monochrom> If you say "but they sound so similar intuitively" then that means your intuition is still defined by imperative languages and narrowing to IO.
14:58:25 <monochrom> even s/defined/confined/
14:58:39 <EvanR> ah no Applicative needed
14:59:22 <EvanR> the code collapsed yay
14:59:47 <dminuoso> Also I must say, Unsaturated Type Families might be my favourite language extension to look out for!
14:59:51 <EvanR> the types check so the result must be right
14:59:56 <dminuoso> It's the missing link to make type families true fun to use.
15:00:57 <monochrom> What does unsaturated type family look like?
15:01:42 <dminuoso> monochrom: https://www.microsoft.com/en-us/research/uploads/prod/2019/03/unsaturated-type-families-icfp-2019.pdf
15:02:28 <monochrom> Wow what are those seals of approval!
15:03:18 <monochrom> Also I get a feeling that if the artifacts are written in assembly they will still stamp with "artifacts evaluated functional" >:)
15:03:31 <dminuoso> monochrom: As a very simple motivation, consider a list of types and some tyfam - try writing another tyfam Map that applies the tyfam to a list of types.
15:03:53 <jle`> dminuoso: here and there
15:04:17 <jle`> nshepperd2: yeah, that's the Applicative style that i try to advocate
15:04:31 <boxscape> monochrom csongor gave a talk about it at haskell exchange https://skillsmatter.com/skillscasts/14588-higher-order-type-level-programming
15:04:42 <dminuoso> jle`: Ive tried to dive into this topic of These1 and I couldn't quite figure out the connection to this TList/Free (from phadej)
15:04:42 <jle`> nshepperd2: the problem is that in order to allow for 'pattern matching', you have to be able to directly inspect the value to know how to branch
15:04:51 <dminuoso> boxscape: Are you in London?
15:04:56 <boxscape> nope
15:05:05 <jle`> nshepperd2: so you have to give up dynamic branching (or make it awkward and use some sort of reified case system)
15:05:19 <monochrom> Oh! That kind of unsaturated.
15:05:32 <jle`> dminuoso: ah. you mean, you aren't sure what Free These1 is?
15:05:43 <merijn> jle`: I know what it is!
15:05:46 <jle`> in the same way that you know what Free Compose is, and Free (:*:) is, and Free Day is
15:05:49 <merijn> jle`: Confusing as fuck!
15:05:57 <jle`> merijn: heh, the actual type isn't that bad! :O
15:06:04 <jle`> it has a nice concinse description that makes it useful
15:06:08 <jle`> and is equivalent to a common type
15:06:25 <dminuoso> jle`: Wait wait. We started out with monoids in monoidal categories - and then you had this fancy thought of "what if the tensor was These1" -> how do we get from there to free anything?
15:06:27 <jle`> ah we're talking about FreeT from that phadej blog series, or TList
15:06:45 <jle`> dminuoso: well for a given tensor, it's interesting to think about what the 'free monoid' on that tensor is
15:07:04 <jle`> just like seeing how the free monoid arising from Compose is the free monad, a tree
15:07:16 <jle`> and the free monoid arising from Day gives you the free applicative, sequential actions
15:07:27 <jle`> free monoid arising from (:*:) gives you...a list
15:08:03 <jle`> or well TList (:*:) Proxy ~ Compose []
15:08:16 <monochrom> Is unsaturated type family application in GHC 8.8?
15:08:25 <boxscape> no, it's not even in HEAD
15:08:36 <boxscape> the proposal is not even accepted
15:08:39 <boxscape> but there is a proposal
15:08:46 <monochrom> Ah OK. Will have to read this paper then. Was hoping to just read the GHC user's guide.
15:08:46 <boxscape> https://github.com/ghc-proposals/ghc-proposals/pull/242
15:08:49 <jle`> but you have heard of me
15:09:07 <boxscape> monochrom the proposal might be easier to quickly get into
15:09:11 <boxscape> though I haven't read the paper
15:09:14 <jle`> dminuoso: TList/Free just gives you an interesting perspective on certain tensors
15:09:29 <jle`> so exploring what TList applied to a given tensor is can give you some insight into the nature of the tensor
15:10:00 <dminuoso> jle`: I see. So the idea of TList is just the Free construction of whatever the underlying monoid is for `EFMonoid These1 Void1 f` given some adequate f? 
15:10:31 <jle`> TList *is* the monoid, it gives 'f' a monoidal sturcture
15:10:31 * hackage fast-tags 2.0.0 - Fast incremental vi and emacs tags.  https://hackage.haskell.org/package/fast-tags-2.0.0 (EvanLaforge)
15:10:38 <jle`> like how [a] gives a a monoidal structure
15:10:52 <jle`> so you wouldn't really call the 'a' in '[a]' an "underyling monoid"
15:11:20 <jle`> rather it gives 'a' a monoid instance, if it didn't have one already
15:11:22 <dminuoso> jle`: I think we've got our wires crossed.
15:11:24 <jle`> s/if/even if
15:12:00 <jle`> so `TList Compose Identity f` is now itself a monoid in the category of endofunctors, no matter what 'f' is. even if f itself doesn't have any inherently monoidal properties
15:12:20 <jle`> so even if f wasn't a Monad, `TList Compose Identity f` is a Monad, 'for free'
15:12:30 <jle`> and even if f wasn't an Applicative, `TList Day Identity f` is one.
15:12:40 <monochrom> Yeah the proposal is a good TLDR
15:13:08 <jle`> dminuoso: but yeah i don't know if all of the other tensors have a neat typeclass to associate with them
15:13:29 <jle`> TList (:*:) Proxy f does have a neat typeclass from semigroupoids
15:13:32 <dminuoso> jle`: To put it into perspective, Ive started with this sort of typeclass https://gist.github.com/dminuoso/9ab392f7ec4a68b3a6a2feedff950d0c
15:13:52 <jle`> but even apart from the typeclasses, `TList (:*:) Proxy f` is *already* a useful type in and of itself
15:13:55 <dminuoso> jle`: And you talked about this TList suddenly, and my head started spinning because I couldn't figure out how these two are related.
15:14:11 <jle`> and TList Day Identity f is *already* a useful data type, even without ever considering Applicative
15:14:17 <dminuoso> Sure!
15:14:19 <jle`> TList Compose Identity f is already a useful type, even if we enver talk about monads
15:14:28 <dminuoso> I understand TList on the bass that TList generalizes these monoids
15:14:32 <dminuoso> *basis
15:14:42 <jle`> so i guess my original question to you all those months ago was to characterize what kind of type TList (:+:) Void f is, and what kidn of type TList These1 Void f is
15:15:06 <dminuoso> o.o
15:15:07 <jle`> in the same way we can identify that TList (:*:) Proxy ~ Compose []
15:15:35 <jle`> TList (:*:) Proxy f a, for all its fanciness, is "just" [f a]
15:15:36 <nshepperd2> jle`: hmm, branching inside of a compution on BVars?
15:15:54 <jle`> nshepperd2: right, we cna currently branch because a BVar s a "contains" an a, at runtime
15:16:06 <jle`> but honestly branching isn't too big of a deal, i don't think it's overall that important in the grand scheme of things
15:16:16 <dminuoso> jle`: Sure that all makes sense.
15:16:19 <jle`> i don't know of any ML models that rely on branching at a high level
15:16:37 <jle`> just some minor branchings like reLU, which can be implemented directly by supplying explicit gradients
15:16:47 <nshepperd2> right, usually with gpu you try to avoid bring info back to the cpu at all cost
15:16:49 <jle`> er, "any ML models" => "any differentiable programmign based models"
15:16:59 <jle`> so maybe i should just 'give it up' and strip the ability to branch
15:17:27 <nshepperd2> relu is handled by pushing the branch into compute kernels
15:17:38 <dminuoso> jle`: Put it differently. Was your mention of These1 in any way related to what I wrote in the gist?
15:18:12 <MarcelineVQ> What/where is TList?
15:18:17 <jle`> dminuoso: yeah i do'nt know this gist can really handle These1/(:+:) because there isn't really a "typeclass" we associate with their associated monoids
15:18:44 <dminuoso> jle`: Wow okay! That explains why I was so confused then.
15:18:56 <jle`> MarcelineVQ: it's from that post uniting free applicative/free monads
15:19:12 <jle`> dminuoso: yeah, actually i'm not sure if there are any actual concrete type f's that would actually be able to be monoids under them
15:19:17 <MarcelineVQ> Aright, which is that post? :>
15:19:23 <dminuoso> jle`: When we talked about switching Compose to Day/(:+:)/(:*:) you mentioned These1 right afterwards, and I tried plugging it on... :)
15:19:26 <jle`> actually that might be an interesting thing to look into...what concrete f's are monoids under These1 or (:+:)
15:19:43 <jle`> dminuoso: ah, sorry :) i guess all of this is just different layers of abstraction
15:20:03 <dminuoso> jle`: Under the assumption that there was a solution behind it, and then you mentioned TList as being the solution (but you were thinking about something else) heh.
15:20:08 <jle`> data TList t i f a = TNil (i a) | TCons (t f (TList t i f a))
15:20:10 <jle`> ^ MarcelineVQ 
15:20:20 <dminuoso> jle`: Right okay, so that makes more sense then.
15:20:23 <jle`> dminuoso: ah. well, actually, TList *is* a solution there
15:20:42 <dminuoso> jle`: Well sure, it could be used if you constrain f some more.
15:20:47 <jle`> you can have instance EFMonoid These1 Void (TList These1 Void) where ..
15:20:52 <jle`> dminuoso: acutally, it should be an instance for all f
15:21:05 <jle`> * instance EFMonoid These1 Void (TList These1 Void f)
15:21:12 <jle`> that's the "point" of TList
15:21:20 <dminuoso> Right sure
15:21:23 <jle`> dminuoso: actually yeah, with EFMonoid you can write:
15:21:33 <jle`> instance EFMonoid t i (TList t i f) where
15:21:45 <jle`> and write one for all t/i/f
15:22:10 <jle`> hm. well that would only work if t was a tensor with i as its identity, of course
15:22:15 <jle`> so you'd have to constrain t and i there
15:22:18 <dminuoso> Sure, we already have that assumption
15:22:21 <dminuoso> Its implicit here
15:22:28 <dminuoso> jle`: Sure that makes perfect sense since TList gives me a free monoid there.
15:22:35 <jle`> so yeah, try writing: `instance EFMonoid These1 Void (TList These1 Void f)`
15:23:18 <jle`> and then actually once you get a feel for "what exactly is TList THese1 Void f anyway", you can write data TheThing f a = ...
15:23:30 <jle`> and write instance EFMonoid These1 Void (TheThing f)
15:23:43 <dminuoso> Wait what is TheThing here?
15:23:45 <jle`> just like how you can write instance EFMonoid (:*:) Proxy (Compose [] f)
15:23:58 <jle`> dminuoso: TheThing is the mystery thing i have assigned you to identify, that is equivalent to TLIst These1 Void
15:24:10 <dminuoso> Ahhh
15:24:15 <dminuoso> Okay,
15:24:17 <jle`> just like how Compose [] f equivalent to TList (:*:) Proxy
15:24:21 <EvanR> using Traversable and recursive do this seemingly effort-requiring task became this https://paste.ofcode.org/TWhNmPkbHFTcm2HUyEHdsZ
15:24:36 <dminuoso> jle`: So how I have finally uncovered the task. :
15:24:38 <dminuoso> :-)
15:24:41 <dminuoso> *now even
15:25:10 <jle`> ah.  well, maybe first write the TList instance specifically, then write the EFMonoid (:*:) Proxy (Compose [] f) instance to get a feel of the final goal :)
15:25:18 <evelyn> /
15:25:21 <evelyn> whoops
15:25:24 <jle`> yeah, there's a lot of layers of abstraction/thinking here, it's easy to miscommunicate heh
15:25:46 <EvanR> now i can convince people haskell is easy
15:25:53 <jle`> dminuoso: but if you haven't identified it already, it might be easier to start with TList (:+:) Void
15:25:55 <MarcelineVQ> jle`: is this the post you refer to? http://oleg.fi/gists/posts/2018-02-21-single-free.html
15:26:05 <jle`> dminuoso: identify a type TheThing f where TList (:+:) Void ~ TheThing f
15:26:14 <jle`> er, TList (:+) Void f ~ TheThing f
15:26:29 <jle`> MarcelineVQ: that looks right yes :)
15:26:39 <jle`> MarcelineVQ: the TList we are talking about is called Free in that post
15:27:05 <jle`> dminuoso: "what" TList These1 Void1 is, is probably harder than what TList (:+:) Void1 is
15:27:50 <jle`> and actually TList (:+:) Void1 as a 'simple' data type already exists somewhere on hackage in a popular library
15:28:00 <jle`> and TList These1 Void1 also exists on hackage in a slightly less popular library
15:28:22 <jle`> the only one that exists in base probably is TList (:*:) Proxy
15:29:58 <dminuoso> jle`: Just to be sure, but the Void above should be Void1 right?
15:30:28 <jle`> yeah, the Voids above should have been data Void1 f a
15:30:46 <dminuoso> you mean `data Void1 a`
15:30:53 <jle`> ah yeah, that's right :)
15:30:54 <dminuoso> (Funnily I made that same mistake earlier)
15:31:04 <jle`> aka Const Void
15:31:08 <dminuoso> Right
15:31:25 <jle`> aka (,) Void too i suppose
15:31:28 <jle`> algebra is neat
15:32:15 <jle`> nshepperd2: i'm somewhat inclined to give up branching and go to that method. but i haven't had the time to get around to it yet
15:32:48 <jle`> hm. actually thinking about my struggles last time i tried this, it isn't quite easy
15:33:07 <jle`> one of the common operations a BVar might go thorugh is sequenceVar :: BVar s [a] -> [BVar s a]
15:33:27 <jle`> it isn't immediately obvious but this would require branching an inspection, and would be a no-go if you're on gpu
15:33:34 <jle`> *branching and inspection
15:33:48 <jle`> so now you lose the ability to work with flexible-shape containers
15:33:58 <jle`> and you can only ever work with fixed-sized containers
15:34:15 <jle`> which isn't *that* bad, but abandons some core haskell idioms
15:36:52 <jle`> hm i've had to re-discover this several times over the past year or so, i should probably write it all down
15:48:41 <phadej> :t V1
15:48:42 <lambdabot> error:
15:48:43 <lambdabot>     • Data constructor not in scope: V1
15:48:43 <lambdabot>     • Perhaps you meant variable ‘_1’ (imported from Control.Lens)
15:48:48 <phadej> :t GHC.Generics.V1
15:48:50 <lambdabot> error:
15:48:50 <lambdabot>     Not in scope: data constructor ‘GHC.Generics.V1’
15:48:50 <lambdabot>     No module named ‘GHC.Generics’ is imported.
15:48:52 <phadej> :(
15:48:59 <phadej> % :t GHC.Generics.V1
15:48:59 <yahb> phadej: ; <interactive>:1:1: error:; Not in scope: data constructor `GHC.Generics.V1'; No module named `GHC.Generics' is imported.
15:49:09 <phadej> % import GHC.Generics
15:49:09 <yahb> phadej: 
15:49:11 <phadej> % :t GHC.Generics.V1
15:49:11 <yahb> phadej: ; <interactive>:1:1: error:; Not in scope: data constructor `GHC.Generics.V1'; Perhaps you meant one of these: `GHC.Generics.U1' (imported from GHC.Generics), `GHC.Generics.K1' (imported from GHC.Generics), `GHC.Generics.M1' (imported from GHC.Generics); No module named `GHC.Generics' is imported.
15:49:16 <phadej> % :kind GHC.Generics.V1
15:49:16 <yahb> phadej: GHC.Generics.V1 :: k -> *
15:49:24 <phadej> there you go
15:49:41 <phadej> % :kind GHC.Generics.U1 -- is also nice name for Proxy
15:49:41 <yahb> phadej: GHC.Generics.U1 -- is also nice name for Proxy :: k -> *
15:52:22 <Axman6> ha
15:52:48 <Axman6> kind -- Comment :: Comment
15:55:36 <dmwit> Const Void is better than (,) Void, because it has more kinds
16:02:52 <Axman6> how kind of it
16:22:01 * hackage lzlib 0.3.0.0 - lzlib bindings  https://hackage.haskell.org/package/lzlib-0.3.0.0 (vmchale)
16:24:01 * hackage cpkg 0.2.3.5 - Build tool for C  https://hackage.haskell.org/package/cpkg-0.2.3.5 (vmchale)
16:25:41 <nshepperd2> jle`: wouldn't you do BVar s [Tensor a] -> [BVar s (Tensor a)]? which yeah, means the length of the list is determined 'statically' (but then how often do you create a variable sized list based on results from the gpu anyway?)
16:26:17 <jle`> nshepperd2: the length of the list must be known statically, but nothing in the BVar type has the information to do that
16:26:21 <jle`> unless the BVar contains the actual list itself
16:26:29 <jle`> oh, i misread
16:26:43 <jle`> i thought you meant BVar s (Tensor [a]) -> [BVar s (Tensor a)], which would be impossible, yeah
16:26:55 <jle`> nshepperd2: ah, that's true.  how often would Tensor [a] come up?
16:27:30 <jle`> but i think it gets back to the original issue, which is that disallowing "normal" lists gets rid of a lot of haskell idioms
16:27:40 <jle`> but i guess if you're working in the GPU you're already abandoning those
16:28:52 <nshepperd2> I'm imagining here that BVar is exactly what it currently is. so it contains a real haskell list of Tensor (which are virtual representation of promised gpu data operations)
16:29:54 <jle`> ah hm. so maybe giving up branching wouldn't be thaat bad.
16:31:04 <jle`> because in this case you're branching on the list of tensor-actions, not the results
16:31:15 <jle`> er, i mean, i guess *keeping* branching wouldn't be that bad.
16:32:17 <jle`> one of these days i'll just have to take a whack at testing it with gpu stuff
16:32:20 <nshepperd2> yeah, you can still branch on data which is known "statically", which includes the size of the list, and presumably the dimension of its tensors
16:38:00 <nshepperd2> in theory this has good results, because the end result of calling 'backprop' on your function would be presumably a collection of Tensors, containing an abstract description of the whole gpu computation graph and you can then separately implement scheduling these operations according to some optimal topological order
16:38:49 <jle`> yeah, that should work actually
16:39:08 <jle`> it'd be easy enough to just test this with something like `IO Matrix`, even
16:39:11 <nshepperd2> and try to minimize memory usage etc
16:39:28 <jle`> to make sure at least the system is sound/implementable
16:39:36 <jle`> then looking at a 'smarter' IO could be fun.
16:40:30 <nshepperd2> yeah, start with IO Matrix that computes the result, then upgrade it into an IO Matrix that caches the result (observable sharing)
16:45:47 <EvanR> recursive do feels like cheating
16:47:00 <nshepperd2> it's time travel
16:49:46 <EvanR> bill and ted style, works as long as you agree to go back in time and fix things up "later"
16:50:55 <jle`> so maybe it's more Prisoner of Azkaban style
16:54:11 <monochrom> Dependent Haskell IO can check user input at compile time!
16:55:30 <EvanR> that much power must come at a great cost
16:56:11 <monochrom> Yeah but it's time travel.
16:56:33 <nshepperd> remember, it's a GDPR violation to use time travel to crack users' passwords
16:56:37 <EvanR> oh you weren't joking
16:57:20 <nshepperd> btw is anyone else here at haskellx
16:57:53 <monochrom> I thought I would use time travel to undo GDPR...
16:58:27 <nshepperd> i'm sure i know people here but the only person I actually know the face of is spj
16:59:54 <oats> is spj an irc'er?
17:05:31 <nshepperd2> not that I know of
17:20:44 <boxscape> % case undefined of !_ -> 5
17:20:44 <yahb> boxscape: *** Exception: Prelude.undefined; CallStack (from HasCallStack):; error, called at libraries/base/GHC/Err.hs:78:14 in base:GHC.Err; undefined, called at <interactive>:24:1 in interactive:Ghci7
17:20:48 <boxscape> if this fails, why doesn't this?
17:20:51 <boxscape> let f | !_ <- undefined = 5 in f
17:20:54 <boxscape> % let f | !_ <- undefined = 5 in f
17:20:54 <yahb> boxscape: 5
17:23:52 <kiwi_24> is this a good place for a reader monad (https://gist.github.com/charleskinbote/9d2ee3529252a59fbe5efeba7ab7fc79)? I'm threading my config everywhere -- any thoughts on how to make that better?
17:24:45 <kiwi_24> updated link: https://gist.github.com/charleskinbote/9d2ee3529252a59fbe5efeba7ab7fc79
17:24:48 <EvanR> kiwi_24: does literally everywhere need the config?
17:25:08 <kiwi_24> lots of places, well, read from it, but not necessarily in _every_ function
17:25:31 <EvanR> personally i don't see anything wrong with your code. Assuming all 3 of those functions need the config
17:26:50 <kiwi_24> just the `step` function actually
17:27:05 <EvanR> not popSize and numGenerations?
17:27:39 <EvanR> oh those are accessing the fields
17:27:45 <kiwi_24> `step` is the only place cfg is passed in, the rest are record getters and so pass in values to their callers
17:28:13 <kiwi_24> i guess the more precise thing to say is that `step` is not a record getter
17:28:18 <EvanR> you can also use wildcards to access the fields in the pattern
17:28:36 <EvanR> then you don't need to apply the field accessor within the body of the code
17:29:03 <EvanR> also field punning
17:29:55 <kiwi_24> not familiar with field pruning, but the config has about 10 parts to it, isn't that what record syntax is good at avoiding: placing lots of wildcards in the function input?
17:30:39 <EvanR> records are good at grouping values
17:31:05 <EvanR> some record-related features are good at (try to help with) making records easier to use
17:32:28 <EvanR> loop cfg@(GAConfig {..}) = do
17:33:01 <EvanR> now you can use popSize and numGenerations as is. Though ... I think it would be better to signify that in the pattern
17:34:05 <kiwi_24> got it, thank you
17:34:30 <EvanR> loop cfg@(GAConfig {popSize=popSize,numGenerations=numGenerations}) = do
17:34:42 <EvanR> popSize=x,numGenerations=y also works
17:34:58 <kiwi_24> thats a feature i didn't know about
17:34:59 <kiwi_24> thanks
17:35:28 <EvanR> loop cfg@(GAConfig {popSize,numGenerations}) = do -- works with NamedFieldPuns
17:36:08 <EvanR> the .. example needs RecordWildCards
17:37:08 <bbaren> I’ve got a custom Setup.hs with a preConf hook, but Cabal doesn’t seem to want to build my Setup.hs before it configures my project. I do have `build-type: Custom` and a custom-setup stanza. What am I doing wrong?
17:38:52 <kiwi_24> EvanR with that most recent example you gave, how does the compiler know which fields you're grabbing when there may be more to grab, is it name sensitive?
17:39:07 <kiwi_24> is that what you mean by named field puns
17:40:48 <kiwi_24> ah ok i need the extension {-# LANGUAGE NamedFieldPuns #-}
17:42:57 <kiwi_24> meta question, do those language extensions cause conflicts? why aren't they just made part of the language?
17:44:03 <koz_> kiwi_24: The 'default' is Haskell2010.
17:44:16 <koz_> All those do _more_ than that.
17:45:05 <kiwi_24> what's the next planned release, Haskell2020? If it's something like that will it include some of those language extensions by default
17:46:08 <koz_> kiwi_24: If you're curious about what might make it into the next Haskell standard, I think there's a place for discussions and suggestions for it.
17:46:20 <koz_> _When_ it's going to be, or indeed, what will be in it, I dunno.
17:47:06 <EvanR> kiwi_24: nah, you have to enable extensions that you want to use. You can also enable a bunch at once with flags
17:47:40 <EvanR> supposedly if another haskell compiler existed they might not want to / be able to implement the zillion GHC extensions
17:48:44 <EvanR> since there is only 1 haskell compiler really, you don't need to be worried about using extensions
17:51:10 <EvanR> some extensions are incompatible with each other but i think that's rare
17:51:24 <koz_> "No one shall expel us from the paradise GHC has created for us." - David Hilbert, probably :P
18:18:28 <monochrom> Hilbert's 24th problem: Solve the other 23 problems in GHC at the type level >:)
18:19:40 <monochrom> (There is a real 24th problem: https://en.wikipedia.org/wiki/Hilbert%27s_twenty-fourth_problem )
18:20:36 <MarcelineVQ> So when someone says "Gosh, what's his problem..."
18:22:14 <EvanR> syzygies really
18:22:43 <EvanR> is that even a real word
18:27:00 <rocket_man> > Hilbert's syzygy theorem concern the relations, or syzygies in Hilbert's terminology, between the generators of an ideal, or, more generally, a module
18:27:02 <lambdabot>  <hint>:1:47: error: parse error on input ‘,’
18:27:06 <rocket_man> yup that's enough wikipedia for one day
18:27:18 <jusss> y = Y f = f (Y f) ; f y =y;  the recursion function would be which one? 
18:27:30 <EvanR> sounds like homework
18:27:54 <rocket_man> well one of them is clearly the identity function, so ...
18:36:31 * hackage can-i-haz 0.2.0.1 - Generic implementation of the Has and CoHas patterns  https://hackage.haskell.org/package/can-i-haz-0.2.0.1 (0xd34df00d)
18:37:17 <monochrom> I don't even understand the question.
18:37:55 <rocket_man> monochrom: I think he's asking about https://en.wikipedia.org/wiki/Fixed-point_combinator#Fixed_point_combinators_in_lambda_calculus
18:39:57 <rocket_man> the wikipedia article is astoundingly hard to read, wow. Essentially it's a way to implement named recursion with only unnamed recursion available
18:40:18 <EvanR> wikipedia articles can suffer
18:40:33 <EvanR> well, i guess it's ultimately the reader who suffers
18:40:43 <monochrom> On top of that, the Y combinator is not a good start on this.
18:41:18 <EvanR> Y was the first fixed point combinator discovered?
18:41:55 <monochrom> A good start is the simpler diagonal combinator (lambda x. x x) or even manually do the self-application yourself: lambda f f n . ... f f (n-1) ...
18:42:19 <monochrom> err, lambda f n . ... f f (n-1) ...
18:43:10 <monochrom> After you have fully grasp how diagonal and/or self-application gives  you recursion, then the Y combinator is packaging.
18:44:05 <monochrom> But if you are a beginner and you confront the Y combinator directly first, you confront two separable concerns in one go.
18:44:33 <EvanR> i just took it as a blackbox :)
18:44:40 <jusss> those stuff are fascinating, and hard to understand...
18:44:49 <EvanR> 0 separatable concerns
18:44:59 <jusss> recursive type, y combinator
18:45:18 <rocket_man> I don't understand your self-application function. Is that `(lambda x. x x)` applied to `f f n`?
18:45:44 <monochrom> Technically Y is the first fixed point combinator discovered, yes, but only because when you say "fixed point combinator" you insist of the super nice API spec "Y f = f (Y f)" which is not directly satisfied by the diagonal combinator.
18:46:19 <monochrom> But Y is clearly not the first "obtain recursion somehow" idea discovered.
18:47:00 <monochrom> s/insist of/insist on/
18:47:38 <monochrom> f f n = (lambda x. x x) f n
18:48:58 <monochrom> Suppose you want to write factorial.  Here is my way:  Define mkfac = lambda f n. if n=0 then 1 else n * mkfac mkfac (n-1).  Then fac = mkfac mkfac.
18:49:35 <monochrom> Err no.
18:49:43 <monochrom> Suppose you want to write factorial.  Here is my way:  Define mkfac = lambda f n. if n=0 then 1 else n * f f (n-1).  Then fac = mkfac mkfac.
18:49:52 <rocket_man> ah because `f f n` is the same as `(f n) (f n)`
18:49:58 <monochrom> No!
18:50:21 <monochrom> f f n = (f f) n = ((lambda x. x x) f) n
18:50:50 <koz_> monochrom: Doing everything twice is fun. :P
18:51:04 <rocket_man> dang it, I always get the operator precedence wrong
18:51:40 <monochrom> Another of my way is to define diagonal = (lambda x. x x), fac = diagonal (lambda f n. if n=0 then 1 else n * diagonal f (n-1))
18:52:50 <rocket_man> this isn't haskell syntax, right? In haskell `(\x -> x x) f n` wouldn't be the right number of arguments
18:53:28 <koz_> :t \x -> x x
18:53:29 <lambdabot> error:
18:53:29 <lambdabot>     • Occurs check: cannot construct the infinite type: t ~ t -> t1
18:53:29 <lambdabot>     • In the first argument of ‘x’, namely ‘x’
18:53:34 <monochrom> This is Haskell syntax, just not Haskell static semantics. (Type system doesn't like it.)
18:53:43 <EvanR> let iter :: a -> (a -> a) -> N -> a. fac = fst (iter (1,0) (\(a,n) -> (a*n,n+1)))
18:53:43 <koz_> (as can be seen from above)
18:53:59 <EvanR> i guess that's the stage of haskell programmer i'm at
18:54:22 <monochrom> In Haskell, consider "(\x -> x) (\x -> x) (\x -> x) (\x -> x) (\x -> x)"
18:54:29 <jusss> % newtype Fix f = MkFix (f (Fix f))
18:54:30 <yahb> jusss: 
18:54:41 <EvanR> ala https://www.cs.utexas.edu/~cannata/cs345/Class%20Notes/10%20Haskell%20Programmer%20Evolution.html
18:54:51 <monochrom> If you're in a currying language you lose a theoretical sense of "how many arguments".
18:55:11 <monochrom> @quote monochrom 17-ary
18:55:11 <lambdabot> monochrom says: I am 17-ary, going on 18-ary, I can take curry of you
18:55:18 <jusss> % t MkFix (Just (MkFix Nothing))
18:55:18 <yahb> jusss: ; <interactive>:28:1: error: Variable not in scope: t :: (f0 (Fix f0) -> Fix f0) -> Maybe (Fix Maybe) -> t
18:55:57 <rocket_man> what does it mean to not have a fixed number of arguments? can you just keep applying functions indefinitely?
18:56:08 <koz_> :t (\x -> x) (\x -> x) (\x -> x) (\x -> x) (\x -> x)
18:56:09 <lambdabot> p -> p
18:56:19 <koz_> Ya got me good, monochrom.
18:56:54 <EvanR> looks like a skipped a few steps on the Beginning Graduate Haskell
18:57:01 <rocket_man> that makes sense to me actually, you're applying the identity function to the identity function 4 times
18:57:19 <koz_> rocket_man: Yeah, it makes sense, but you gotta think about it a bit first.
18:57:30 <koz_> Luckily GHC can frequently be smarter than me. :P
18:58:11 <koz_> I'm definitely the 'Points-free' Haskell Programmer at least. :P
18:58:24 <rocket_man> I still don't get the factorial example, where is `f` coming from?
18:58:57 <monochrom> it's a parameter.
18:59:13 <rocket_man> but factorial only takes one argument and you also have an argument `n`
19:00:24 <monochrom> OK go to http://www.cs.utoronto.ca/~trebla/CSCC24-2019-Summer/Interpreting.hs and search for "Do you believe that I can do factorial?")
19:06:03 <rocket_man> ok, I think I see. The recursion never ends and it just short-circuits when it gets to 0?
19:06:17 <monochrom> Yeah, the if-then-else helps.
19:06:52 <monochrom> But even with built-in recursion you need the help of if-then-else or really yeah any short-circuiting.
19:06:52 <rocket_man> my brain hurts lol
19:07:13 <EvanR> all our loops are infinite. They continue in some quantum multiverse and the only reason anything terminates is wavefunction collapse
19:07:39 <EvanR> sorry too many other channels lately
19:08:11 <rocket_man> someone told me once that all you need to be turing complete is jump-less-than and add
19:08:15 <rocket_man> (or something like that)
19:08:38 <EvanR> you have to admit that instruction is kind of cheating
19:08:47 <monochrom> With lambda calculus, typed or untyped, be careful with your preconception of "number of arguments".  Lambda calculus is very flexible about that.
19:08:50 <EvanR> subtract and jump if less than
19:09:16 <monochrom> I could have (\x -> x) (\n -> n+1) 3 and it's just 3+1 after the dust settles.
19:09:16 <rocket_man> how can you have a typed lambda calculus with an arbitrary number of arguments?
19:09:21 <EvanR> might as well just posit machine with "runs C program" (actually lambda moo is built on something similar to this)
19:09:45 <EvanR> *single instruction
19:09:56 <monochrom> If untyped, I could also have (\x -> x x) (\f n -> n+1) 3 and it's still 3+1 after the dust settles.
19:11:05 <monochrom> OK so (\x -> x) has principal type (or whatever it's called) "forall a. a->a".  And this totally doesn't mean "1 argument".  Because I'm going to set a = Int -> Int.
19:11:36 <monochrom> (Int -> Int) -> Int -> Int now suddenly it looks like 2 arguments
19:11:36 <rocket_man> oh I see  (\x -> x x) (\f n -> n+1) 3 => (\f n -> n+1) (\f n -> n+1) 3 => (n -> n +1) 3 => 4
19:12:44 <monochrom> Or I can go wild. Set a = Int -> b.  Set b = Int -> c.  Set c = Int -> d. etc etc.
19:12:51 <monochrom> This is what I meant by:
19:12:56 <monochrom> @quote monochrom 17-ary
19:12:56 <lambdabot> monochrom says: I am 17-ary, going on 18-ary, I can take curry of you
19:16:08 <monochrom> Okassaki took this idea on steroid and figured out a way to let you write in Haskell "push 3 push 4 push 5 ... push n pop" and it pushes 3, then pushes 4, then pushes 5, then ... then pushes n, then pop.
19:16:47 <monochrom> It also caused GHC's type inference engine to take exponential time in program length.
19:17:03 <rocket_man> lmao
19:22:54 <monochrom> Some researchers once hoped that the idea had a practical application: When you use applicatives, are you tired of writing "f <$> x1 <*> x2 <*> x3 <*> x4"?  Would you like to write "begin f x1 x2 x3 x4 end" instead?
19:23:24 <EvanR> silly researchers
19:23:28 <monochrom> They got it to work, but no one uses it :)
19:23:45 <monochrom> Instead, now the buzz is with ApplicativeDo.
19:23:59 <rocket_man> :t f <$> x1 <*> x2 <*> x3 <*> x4
19:24:00 <lambdabot> error:
19:24:00 <lambdabot>     • Variable not in scope: x1 :: f ()
19:24:00 <lambdabot>     • Perhaps you meant one of these:
19:24:27 <monochrom> I think you need to ask this:
19:24:34 <EvanR> another great example of haskell working "left to right"
19:24:41 <EvanR> when you write it the proper direction
19:24:52 <monochrom> :t \f x1 x2 x3 x4 -> f <$> x1 <*> x2 <*> x3 <*> x4
19:24:53 <lambdabot> Applicative f => (a1 -> a2 -> a3 -> a4 -> b) -> f a1 -> f a2 -> f a3 -> f a4 -> f b
19:31:07 <jusss> what is the term `data type`?
19:32:21 <koz_> This is more math-y (but with Haskell implications): suppose I have two monoids M1 and M2, and f as a monoid isomorphism between M1 and M2. Is f always unique?
19:34:13 <iqubic> I don't think so.
19:34:17 <iqubic> But I have no idea.
19:34:26 <rocket_man> not necessarily, consider plus: Z -> Z and sub: Z -> Z. Both are isomorphisms but they are clearly not the same function
19:34:29 <EvanR> let M1=M2=the 
19:34:31 * hackage predicate-transformers 0.3.0.0 - A library for writing predicates and transformations over predicates in Haskell  https://hackage.haskell.org/package/predicate-transformers-0.3.0.0 (edmundnoble)
19:35:00 <koz_> rocket_man: What do you mean by 'plus' and 'sub' here, sorry?
19:35:04 <Cale> koz_: No, in general there will be a lot of isomorphisms between any pair of monoids.
19:35:08 <EvanR> integers under addition. You can isomorph then using identity or negate all numbers
19:35:29 <rocket_man> yeah addition and subtraction
19:35:44 <Cale> You probably wanted id and negate there...
19:35:49 <rocket_man> (probably could have picked better names)
19:35:49 <koz_> Cale: _Monoid_ isomorphisms too? Specifically, you gotta have f(mempty) = mempty and f(x <> y) = f(x) <> f(y) (to borrow Haskell terms).
19:36:00 <Cale> koz_: Sure.
19:36:10 <Cale> koz_: Are you familiar with linear algebra?
19:36:17 <koz_> Cale: Barely, but try me.
19:36:31 <monochrom> Yeah I used vector spaces to help me answer this question too.
19:36:40 <Cale> koz_: Linear transformations are also monoid homomorphisms, if you consider that vector spaces are monoids under addition
19:37:07 <koz_> Cale: Wait, vector _spaces_ are monoids under addition?
19:37:11 <Cale> yes
19:37:19 * koz_ checks his definitions.
19:37:27 <monochrom> Let M1=M2=(real numbers, +, 0).  You have many isomorphisms, e.g., (\x -> x), (\x -> x*2), (\x -> x/2), ...
19:37:46 <rocket_man> what does it mean to add two vector spaces?
19:37:57 <koz_> That's kinda what I'm asking.
19:37:59 <monochrom> For discrete monoids EvanR's (\x -> x*(-1)) helps.
19:38:07 <Cale> You don't add monoids
19:38:13 <Cale> (at least not usually)
19:38:25 <rocket_man> what's the binary operation, then
19:38:31 <Cale> The monoid operation combines the elements of a monoid
19:38:32 <monochrom> rocket_man: We just mean add two elements in a vector space.
19:38:39 <Cale> Addition of vectors in this case
19:39:15 <rocket_man> oh oh that makes more sense, I thought you meant the set of all vector spaces was a monoid
19:39:40 <EvanR> tensor product of vector spaces...
19:39:42 <Cale> No... well, there's a sense in which that's kind of true-ish, but that's not what I'm talking about :)
19:40:00 <koz_> Yeah, I get what you mean now Cale.
19:40:05 <koz_> Thanks folks, that helps!
19:40:07 <Cale> (and it's not really a monoid exactly, but a monoidal category)
19:40:33 <koz_> Figured I'd chime in here, because many of the folks here are mathematically capable.
19:40:46 <Cale> So yeah, if you consider some vector space V, and the linear transformations V -> V which are invertible, that gets you a whole bunch of monoid isomorphisms V -> V
19:41:13 <koz_> Yeah, I see now.
19:41:31 <Cale> As a special case, if we pick V to be the real numbers R, the invertible linear transformations R -> R are the functions which multiply by some nonzero constant, which is the example that monochrom gave
19:41:50 <koz_> That makes sense, yes.
19:43:08 <rocket_man> and actually you're always guarenteed at least 2 for any monoid because if f is an isomorphism that implies f has an inverse f^-1 which is an isomorphism
19:43:46 <EvanR> bzzz... if f is id
19:43:50 <EvanR> id^-1 = id
19:44:25 <EvanR> so all the examples earlier were really group isomorphisms, since the monoids in question happened to be groups too
19:44:59 <rocket_man> oh you're right I was thinking of groups
19:45:04 <EvanR> next up give an example of two (three? id doesn't count?) isomorphisms of monoids that aren't groups
19:45:29 <rocket_man> see I don't know any monoids that aren't groups so I don't know where to start lol
19:45:41 <EvanR> kind of funny we go straight to groups, when in haskell we rarely have a group
19:45:58 <EvanR> rocket_man: think of pretty much any Monoid in haskell
19:46:02 <rocket_man> I guess the set of all matrices under matrix multiplication? since not all matrices are invertible
19:46:28 <rocket_man> EvanR: just started Haskell last week  ¯\_(ツ)_/¯
19:46:31 <EvanR> oh
19:47:06 <monochrom> strings...
19:47:33 <rocket_man> under concatenation! ok, I believe it
19:47:51 <koz_> EvanR: {0, 1} under logical or. Or logical and. Or logical XOR.
19:48:03 <EvanR> i know those
19:48:07 <monochrom> xor gives you a group.
19:48:16 <EvanR> now gimme the nonunique isomorphisms
19:49:29 <rocket_man> here's an isomorphism on strings: rotate all the letters to the right one place
19:49:54 <monochrom> Wait, you need a binary operator.
19:50:12 <EvanR> is that supposed to be an isomorphism from string to string
19:50:15 <rocket_man> yeah
19:50:21 <EvanR> i don't think it's even a homomorphism
19:50:23 <monochrom> Oh, nevermind
19:51:01 <rocket_man> ah shoot you're right I was thinking of bijections
19:51:36 <EvanR> rotate in the other direction, add 1 to each unicode char with wrapping
19:52:31 <kiwi_92> has anyone ever profiled with stack before? I am building my project with `stack build --profile` but when I run with `stack exec <my_exe> +RTS -p` im getting `stack: the flag -p requires the program to be built with -prof`
19:52:44 <rocket_man> still a bijection, you only have 1 input, you need 2 to be a binary operator
19:53:15 <EvanR> an isomorphism is a mapping with 1 arg
19:53:39 <rocket_man> oh yeah ignore me
19:53:59 <EvanR> wrapping makes it invertible
19:55:07 <rocket_man> and it doesn't matter whether you apply it before or after concatenation because it's element-wise
19:55:45 <rocket_man> hey there's an idea, what about multiplication by a constant on square matrices?
19:56:16 <MarcelineVQ> kiwi_92: that's a common issue recently for some reason, I can't rememebr the exact issue, it's either it's executing the old one it has not the profiled one it built, or the rts args are being eaten by stack
19:56:26 <EvanR> matrices is kind cheating since you can just exclude the non-invertible matrices to get a group
19:56:52 <rocket_man> no but I'm specifically including the non-invertible ones
19:57:04 <kiwi_92> MarcelineVQ yeah unfortunately running a clean build isn't helping either
19:57:26 <koz_> EvanR: Can't we just go 'equidimensional matrices full of values from some monoid, with <> being element-wise <>'?
19:57:27 <rocket_man> and I claim that f(x) => 2x is an isomorphism of M_n, not just GL_n
19:57:31 <MarcelineVQ> maybe: stack exec --RTS -- <my_exe> +RTS -p
19:57:33 <EvanR> now what happens if you exclude "non-invertible strings" :)
19:58:04 <koz_> (apologies for mixing Haskell and maths like that)
19:58:11 <EvanR> koz_: a zip basically
19:58:31 <koz_> EvanR: Yeah, a zip.
19:58:34 <EvanR> kind of boring but works. That is basically Applicative
20:00:21 <EvanR> or, representable functor something or other
20:00:31 <EvanR> i don't know
20:00:44 <EvanR> the function monoid at least
20:03:17 <EvanR> yeah, koz_ equidimensional matrices is a kind of (haskell) functor, and is representable in haskell using a function. And there is a very handy monoid instance for functions to a monoid
20:04:00 <EvanR> i'm not sure what the criteria on functors are that let you express them with a function
20:04:30 <koz_> EvanR: I recall this instance, but not its specifics.
20:04:41 <EvanR> it's all in the type
20:04:59 <koz_> (a -> m) -> (a -> m) -> a -> m
20:05:01 <koz_> ?
20:05:01 <EvanR> instance Monoid m => Monoid (a -> m) where
20:05:12 <MarcelineVQ> representable functors sure are coming up a lot lately
20:05:36 <koz_> MarcelineVQ: Should I make some kind of joke regarding voting now? :P
20:05:50 <MarcelineVQ> If you have one
20:06:01 <koz_> MarcelineVQ: I'm afraid not. Not a concrete one anyway.
20:06:19 <EvanR> a generalized abstract joke
20:06:33 <koz_> EvanR: Wait, do you just grab the a, then feed it to both functions, then mash the results together with <>?
20:06:36 <MarcelineVQ> All the ballots are the same, once fmap coerce = coerce
20:06:46 <koz_> So like \x -> (f x) <> (g x)?
20:06:53 <EvanR> koz_: yeah, but what about mempty
20:07:11 <koz_> EvanR: const mempty.
20:07:15 <EvanR> \o/
20:07:30 <EvanR> if only wheel of fortune's last round was that easy
20:07:40 <koz_> 'const something' basically exists as an answer to every trick question.
20:07:48 <kiwi_92> MarcelineVQ can't get it to work unfortunately
20:08:43 <koz_> I should remember this instance, because I have a feeling I could make my code a lot more concise with it.
20:08:56 <koz_> Since I am officially of the Cult of Monoid.
20:09:45 <EvanR> yes, esp if you are dealing with monoids
20:09:51 <EvanR> like in diagrams
20:11:04 <MarcelineVQ> that's not a reply I can work off of :> what do you see?
20:11:35 <koz_> EvanR: I'm kicking around an idea that relies on monoid isomorphisms. Nothing concrete yet, but I'll let it stew.
20:11:44 <koz_> (besides, I have more Finitary stuff to finish)
20:11:51 <koz_> (although this is technically also Finitary stuff :P)
20:13:24 <Lears> I'm a bit late, but re non-uniqueness of Monoid isomorphisms, you can compose any two automorphisms on either side to get a new one, and automorphism groups are usually sizable. At least for groups, they're guaranteed to be no smaller than the group itself.
20:14:48 <MarcelineVQ> kiwi_92: Seems to me like the profiled version isn't being put on the path. if you stack clean --full then stack build --profile does your executable show up with stack exec -- which myexecutable ? it doesn't for me.
20:15:39 <koz_> Lears: Forgive my ignorance, but what does it mean for a group to be 'sizable'?
20:16:11 <MarcelineVQ> kiwi_92: you can get around this by writing stack build --RTS --profile --exec "myexecutable +RTS -p"
20:16:17 <kiwi_92> MarcelineVQ you're right (i haven't done what you've mentioned yet) i think because it can't find my exe when i type the name of it in `stack exec <my_exe>` after compiling with profiling options
20:16:20 <MarcelineVQ> Which is awful
20:17:53 <Lears> koz_: That's not jargon, I just mean they will have a meaningful number of elements rather than collapsing into a trivial group.
20:18:16 <MarcelineVQ> --RTS is for ghc and it says, stop looking for rts options passed this point, because otherwise +RTS might get used by stack instead of passed to myexecutable, because stack is also a ghc haskell program
20:18:36 <koz_> Lears: Ah, OK. I'm not very knowledgeable about groups, so I couldn't be sure if that was jargon or not. :P
20:18:45 <MarcelineVQ> It might not be neccesary but it's good to know about when diagnosing rts options issues
20:20:06 <kiwi_92> that's helpful, thank you
20:20:36 <MarcelineVQ> There's probably a more straightforward way to work with profiled exeutables but I don't know it
20:28:48 <sm[m]> MarcelineVQ, kiwi_92: after stack build —profile, you have to stack exec —profile to get the right version of the executable in path
20:29:25 <sm[m]> A very easy mistake, I think there’s an issue for it
20:29:28 <MarcelineVQ> gerp, that's a little odd because --profile isn't listed in stack exec --help :X
20:30:38 <kiwi_92> where does the profile file go when calling in that way?
20:30:54 <kiwi_92> it doesn't show up at the root project level
20:31:16 <MarcelineVQ> not sure find -iname "*.prof" should resolve that though
20:32:50 <sm[m]> https://github.com/commercialhaskell/stack/issues/4983
20:33:20 <sm[m]> If you do stack exec [—profile] — which EXE you’ll see the different path
20:35:43 <kiwi_92> thanks
20:37:12 <sm[m]> upvote the issue if you like
20:47:21 <kiwi_92> ok, so given that i can now profile my code, does anyone have any advice on how to reduce the time given to System.Random here? https://gist.github.com/charleskinbote/e65648c4361596723188abe7013cd717
20:47:40 <kiwi_92> the profiling information is towards the bottom of the gist
20:48:10 <jusss> % :t  MkFix (Just (MkFix (Just (MkFix Nothing))))
20:48:11 <yahb> jusss: Fix Maybe
20:48:15 <kiwi_92> looks like its also taking a lot of memory
20:50:49 <jusss> % :t MkFix Nothing
20:50:49 <yahb> jusss: Fix Maybe
20:52:40 <jusss> % :t MkFix
20:52:40 <yahb> jusss: f (Fix f) -> Fix f
20:58:55 <siraben> Anyone have solutions to Richard Bird's Introduction to Functional Programming using Haskell 2nd ed?
20:59:56 <siraben> https://github.com/nd/bird/tree/master/ch10 has partial solutions, but I'm trying to wrap my head around exercise 10.4.1 and 10.4.2 on combining the writer monad transformer and the exception monad transformer
21:04:56 <ysangkok> siraben: sorry, don't have a solution, but am curious about that book. would you recommend it over e.g. haskellbook.com?
21:06:11 <jackdk> what is the question?
21:06:16 <siraben> Hm, I haven't been reading the whole book, just the chapter on monads and monad transformers.
21:07:26 <siraben> Here's the question from the book: http://ix.io/1Yiq
21:09:12 <jackdk> > Also, define instances to ensure that if m is an exception or state monad then so is OUT m, and that if m is an output monad then so are ST m and EXC m.
21:09:14 <lambdabot>  <hint>:1:5: error: parse error on input ‘,’
21:09:35 <jackdk> sorry lambdabot . siraben, do you understand the shape of the instances you are being asked to write here?
21:11:24 <sm[m]> kiwi_92: can you use fewer random numbers ? You’re generating 24 million it looks like
21:11:25 <siraben> jackdk:  yes
21:12:46 <kiwi_92> sm[m]  that's exactly in line with the genetic algorithm i've written, every individual has chromosomes that are mutated with some probability
21:12:46 <sm[m]> kiwi_92: secondly, I think the default random generator is slow and you can find a faster one on hackage
21:13:34 <kiwi_92> 3000 generations * 0.8 mutation rate * 100 individuals * 100 chromosomes is the 24M you're seeing
21:13:42 <kiwi_92> hmmm ok i'll look for a faster one
21:14:11 <siraben> jackdk:  I'm assuming my OutMonad class is right: "class Monad m => OutMonad m where
21:14:12 <siraben>   putStringLn :: String -> m ()"
21:14:37 <sm[m]> mwc-random might be one
21:15:05 <siraben> And I can lift it to, say EXC. "instance OutMonad m => OutMonad (EXC m) where
21:15:06 <siraben>   putStringLn = promote . putStringLn"
21:17:52 <jackdk> something like that, and vice versa to say instance ExMonad m => ExMonad (Out m) too
21:24:01 * hackage hw-balancedparens 0.3.0.2 - Balanced parentheses  https://hackage.haskell.org/package/hw-balancedparens-0.3.0.2 (haskellworks)
21:24:33 <siraben> jackdk:  Ah, finally solved it!
21:24:46 <siraben> The magic line was; 
21:24:46 <siraben> instance Monad m => OutMonad (OUT m) where
21:24:47 <siraben>   putStringLn s = MkOUT $ return (MkOut (s, ()))
21:39:31 * hackage hw-uri 0.1.1.10 - Supports IO on URIs  https://hackage.haskell.org/package/hw-uri-0.1.1.10 (haskellworks)
21:45:01 * hackage hw-simd 0.1.1.5 - SIMD library  https://hackage.haskell.org/package/hw-simd-0.1.1.5 (haskellworks)
21:45:12 <jle`> ah the MkOUT monad
21:51:18 <__dingbat__> hello, I need  help fixing this code please, hopefully this can be done better https://www.codepile.net/pile/Zg6G9NdR
21:52:02 * hackage hw-parser 0.0.0.4, hw-prim 0.6.2.36 (haskellworks): https://qbin.io/ratio-ambien-d8oe
21:52:24 <jle`> __dingbat__: is there anything wrong with it right now?
21:53:56 <__dingbat__> yes, I updated the link with error
21:54:12 <__dingbat__> I think its the case block , line number 8
21:54:36 <jle`> ah yeah, line 8 should provide an IO action, not a Maybe
21:54:55 <jle`> it isn't clear what action you want to do if lookupMax mp is Nothing
21:55:01 <__dingbat__> lookupMax returns Maybe type, I want to address Nothing case with something like an empty Lazy.Text
21:55:02 * hackage hw-json-standard-cursor 0.2.1.2, hw-json-simple-cursor 0.1.0.2, hw-json-simd 0.1.0.4 (haskellworks)
21:55:21 <jle`> you can do return "" then, maybe
21:55:24 <mozzarella> is haskell fast?
21:55:35 <jle`> __dingbat__: if that is what you want jsonRequest to be in the case of Nothing 
21:55:56 <jle`> mozzarella: it can be fast, depending on how you write your code and the situation
21:56:27 <__dingbat__> jle`: Actually, I should skip making a further call to fetchResource in case of Nothing
21:56:34 <__dingbat__> how do I do that please?
21:57:30 <__dingbat__> jle`: doing a - return "" gives me this error
21:57:31 <__dingbat__> Expected type: m Data.Text.Internal.Lazy.Text
21:57:32 <jle`> __dingbat__: do you just want to do nothing for the rest of the action and skip to the end?
21:57:33 <__dingbat__>         Actual type: m [Char]
21:58:00 <__dingbat__> yes
21:58:16 <jle`> ah yeah you can do return mempty, or turn on -XOverloadedStrings
21:58:19 <jle`> for that error
21:58:22 <siraben> What source code prettifiers do people use?
21:58:31 <jle`> __dingbat__: in that case, you can move the rest of your do block into the Just
21:58:59 <jle`> __dingbat__: so just move lines 9 to 18 into where line 7 is now, adjusting indentation properly
21:59:20 <jle`> then you do'nt have to bind the result either
21:59:31 * hackage hw-rankselect-base 0.3.2.2 - Rank-select base  https://hackage.haskell.org/package/hw-rankselect-base-0.3.2.2 (haskellworks)
21:59:34 <jle`> __dingbat__: you still don't want to loop again either, right?
22:00:01 <__dingbat__> jle`: then will i still be able to recurse like it is now?
22:00:43 <jle`> hm, do you see how the control flow works here?
22:00:53 <jle`> you just need to put what you want to happen in the branch where it is supposed to happen
22:01:10 <jle`> so if fetchResource should only happen if the lookup is Just, move it to the 'Just' case branch
22:01:25 <jle`> if liftIO/threadDelay  should only happen if the lookup is Just, move it to the 'Just' case branch
22:01:32 * hackage hw-aeson 0.1.0.2 - Convenience functions for Aeson  https://hackage.haskell.org/package/hw-aeson-0.1.0.2 (haskellworks)
22:01:39 <jle`> if loopCall mp is only supposed to happen if the lookup is Just, move it to the 'Just' case branch
22:01:51 <jle`> if it is meant to happen no matter what the lookup is, then put it after the whole case is over
22:01:53 <jle`> if that makes sense
22:02:01 * hackage hw-bits 0.7.0.8 - Bit manipulation  https://hackage.haskell.org/package/hw-bits-0.7.0.8 (haskellworks)
22:02:04 <jle`> case lookupMax mp of
22:02:12 <jle`>   Just c -> do   -- all the stuff you want to do if lookupMax mp is Just
22:02:15 <__dingbat__> jle`: but in line 4 I am assigning jsonRequest  and inside of the Just case i would be passing value of jsonRequest to fetchResource
22:02:18 <jle`>   Nothing -> return ()  -- or whatever
22:02:26 <__dingbat__> jle`: how does that work?
22:02:35 <jle`> __dingbat__: well you already have the thing you want to request, don't you?
22:02:39 <jle`> you call it 'y' on line 6
22:02:53 <jle`> or er, it's `rPCCall_request y`
22:02:59 <__dingbat__> jle`: yup
22:03:01 * hackage hw-excess 0.2.2.1, hw-eliasfano 0.1.1.1, hw-dsv 0.3.6, hw-dump 0.1.0.1 (haskellworks)
22:03:07 <jle`> so you can use fetchResource with `rPCCall_request y`
22:03:08 <__dingbat__> jle`: will try it out, thanks
22:03:21 <jle`> basically, just rearrange the logic in your control flow to happen where you want it to happen :)
22:03:29 <jle`> whatever is inside the Just -> .. branch will only happen if it is Just
22:03:37 <jle`> whatever is inside the NOthing -> ... branch will only happen if it is Nothing
22:03:49 <jle`> and whatever is after will happen in either case
22:03:51 <__dingbat__> what should be in the Nothing branch finally then?
22:03:59 <jle`> well, what do you want to happen when Nothing?
22:04:01 * hackage hw-hedgehog 0.1.0.4, hw-hspec-hedgehog 0.1.0.9, hw-fingertree 0.1.1.1 (haskellworks)
22:04:22 <__dingbat__> jle`:wait on another MVar
22:04:37 <jle`> in that case, put that logic there
22:04:48 <jle`> Nothing -> ... (all the stuff you would want to happen when Nothing occurs)
22:05:18 <jle`> the general plan is Just c -> ... (all the stuff you want to happen on Just) 
22:05:23 <__dingbat__> jle`: I kept getting some monad errors which I am clearly not comfortable with, so was wondering there was a simpler way to do this, instead of handle Just / Nothing
22:05:25 <jle`> Nothing -> ... (all the stuff you want to happen on Nothing)
22:05:32 <jle`> handling Just/Nothing is the simplest way
22:05:32 * hackage hw-ip 2.3.4.2, hw-int 0.0.0.4, hw-fingertree-strict 0.1.1.3, hw-conduit 0.2.0.6 (haskellworks)
22:05:43 <__dingbat__> jle`: ok, thank you again
22:06:12 <jle`> fwiw the errors you are getting aren't quite 'monad errors', they might just be non-monady type errors
22:06:27 <jle`> for example the first error you got was that you had a 'Maybe a' instead of an IO action :)
22:07:01 <jle`> ah, maybe there is one potential 'monad' error here
22:07:13 <__dingbat__> jle`: yes, but in general having a "do" block within a "do" block is okay?
22:07:14 <jle`> it's if you forget to include a liftIO maybe
22:07:23 <jle`> __dingbat__: yeah, do x; y; z is just sugar for x >> y >> z
22:07:46 <jle`> so a 'do in a do' is like x >> (y >> z) >> a
22:07:54 <__dingbat__> jle`: wonderful
22:08:24 <siraben> jackdk:  jle` : the final result; https://gist.github.com/siraben/a0d43c4d0d5e4fa6c393289ca965bd44
22:08:42 <siraben> the last 50 lines are various interpreters combining the monad transformers
22:08:53 <jle`> nice :)
22:09:02 <siraben> It's weird because the ordering of the transformers matter; evalOutEx :: Term -> OUT (EXC Id) Int is different from evalExOut :: Term -> EXC (OUT Id) Int
22:09:02 <__dingbat__> jle`: now i get The last statement in a 'do' block must be an expression
22:09:17 <__dingbat__> jle`: because the loopCall recursive call is the last line
22:10:01 <jle`> siraben: yeah, monad transformers are weird like that :|
22:10:10 <jle`> __dingbat__: hm, can you paste your code?
22:10:25 <siraben> jle`:  what about extensible effects?
22:10:27 <jle`> that error just means that you can't have a <- or let or something like that as the last line of a do block
22:10:34 * siraben shudders at the tower of abstraction of composing monads
22:10:48 <jle`> siraben: i don't really think of monad transformers or extensible effects as 'composing' monads
22:11:11 <siraben> Do extensible effects have such a layering to them?
22:11:18 <siraben> Right, it's more of "transforming" them?
22:11:34 <jle`> yeah, or enhancing. that's because if you notice, most monad trasformers aren't actually monad compositions
22:11:41 <jle`> compositions in the f (g a) sense
22:11:57 <__dingbat__> jle`: I have updated, please have a look
22:12:03 <jle`> extensible effects, it depends on how you want to 'interpret' them i think
22:12:07 <jle`> you can interpret them 'all at once'
22:12:11 <jle`> or layer-by-layer
22:12:27 <jle`> __dingbat__: ah yeah, your last line there is a ..  <- ...
22:12:33 <jle`> __dingbat__: you can just get rid of the jsonRequest <- part
22:12:43 <jle`> loopCall mp = case lookupMax mp of
22:13:12 <jle`> if i edit it, do you see my edits?
22:14:14 <jle`> __dingbat__: note that as you have the code now, you can't have Nothing be `return ""`, since it expects `m ()`, not `m String`
22:14:23 <jle`> so you could have `return ()` typecheck
22:14:40 <jle`> but in that case, the Nothing case would essentialyl "do nothing".  `return ()` is the no-op IO action
22:16:55 <__dingbat__> jle`: updated the link and new error 
22:17:03 <__dingbat__> basically what you just said
22:17:25 <__dingbat__> *did 
22:19:24 <jle`> __dingbat__: yeah, readMVar (snd c) :: IO Something
22:19:35 <jle`> but each line in a do block has to have the same type, it has to be m Something
22:19:39 <jle`> so try liftIO (readMVar (snd c))
22:20:30 <__dingbat__> jle`: great! am getting it now
22:20:43 <__dingbat__> I should probably read the tutorials first before hacking code further
22:20:50 <jle`> hah. what fun would that be :)
22:21:07 <__dingbat__>    • Couldn't match type ‘m’ with ‘IO’
22:21:09 <__dingbat__>       ‘m’ is a rigid type variable bound by
22:21:10 <__dingbat__>         the type signature for:
22:21:12 <__dingbat__>           loopCall :: forall env (m :: * -> *).
22:21:13 <__dingbat__>                       HasP2PEnv env m ServiceResource ByteString String ByteString =>
22:21:15 <__dingbat__>                       M.Map Int32 (MVar RPCCall) -> m ()
22:21:16 <__dingbat__> oops sorry
22:21:31 <__dingbat__> jle`: all working well now
22:21:41 <__dingbat__> jle`: thank you for your time!
22:22:01 * hackage hw-streams 0.0.0.11 - Primitive functions and data types  https://hackage.haskell.org/package/hw-streams-0.0.0.11 (haskellworks)
22:22:11 <jle`> no problem, glad it all works :D
22:23:04 <jackdk> siraben: I am about to dash to a meeting but congrats on making it go
22:27:31 * hackage hw-json 1.3.1.1 - Memory efficient JSON parser  https://hackage.haskell.org/package/hw-json-1.3.1.1 (haskellworks)
22:28:15 <siraben> jackdk:  Thanks
23:45:32 * hackage list-tuple 0.1.1.0 - List-like operations for tuples  https://hackage.haskell.org/package/list-tuple-0.1.1.0 (kakkun61)
