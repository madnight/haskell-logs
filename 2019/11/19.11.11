00:01:42 * hackage http-api-data 0.4.1.1 - Converting to/from HTTP API data like URL pieces, headers and query parameters.  https://hackage.haskell.org/package/http-api-data-0.4.1.1 (phadej)
00:08:28 <Squarism> Anyone know of a schema first IDL alternative to protobuf-X (of thrift for that matter) that support type functions, sum types and isnt centred around the ability to modify the protocol? (More haskell friendly one might say)
00:11:11 * hackage lightstep-haskell 0.4.1 - LightStep OpenTracing client library  https://hackage.haskell.org/package/lightstep-haskell-0.4.1 (DmitryIvanov)
01:06:03 <asheshambasta> So; since Intero has been EOL-ed I've been looking into giving HIE another shot; however, I'm totally lost on what other emacs packages it needs to be able to function. It "seems" to need flycheck in order to display messages on the current buffer, but for some reason Flycheck in emacs now creates *_flycheck.hs files for each haskell file I open. https://i.imgur.com/eoxs2KH.png 
01:06:34 <asheshambasta> Has anyone else seen the same? I'm probably doing something wrong, but I'm having a hard time grokking the dependencies HIE needs to function. 
01:12:40 <jneira_> asheshambasta: threre is an issue about (closed): https://github.com/haskell/haskell-ide-engine/issues/1307 
01:14:30 <asheshambasta> jneira_: I see; could be that problem. But all these dependencies seem to be tangled together. 
01:15:02 <asheshambasta> brb; restarting emacs. 
01:15:02 <jneira_> asheshambasta: i configured emacs time ago to work with hie but lately i am using vscode, my emacs config was: 
01:15:19 <jneira_> Uploaded file: https://uploads.kiwiirc.com/files/7c8e7a8dd7d8abd5659106e5db671fdc/pasted.txt
01:15:59 <asheshambasta> jneira_: thanks for that 
01:15:59 <jneira_> with emacs 26.2
01:16:25 <jneira_> you are welcome
01:16:42 <asheshambasta> hie seems to have come a long way since I tried it last (about a year ago)
01:16:50 <asheshambasta> anyway; brb. 
01:17:06 <jneira_> i found flycheck a little bit invasive :-/
01:17:47 <jneira_> but i suppose you can get used to it...
01:19:50 <jneira_> ithe config has commented out `'(add-hook 'haskell-mode-hook #'lsp)`
01:30:48 <asheshambasta> jneira_ thanks a lot. 
01:31:37 <asheshambasta> Another question is that whenever I open any file in the given project; I see an LSP message "connected to hie:someport"; does that mean a new hie process is being spawned for each file? 
01:32:41 <asheshambasta> indeed the memory usage has gone through the roof 
01:36:19 <asheshambasta> actually, never mind; the port numbers are the same. The memory footprint is still quite large though. 
01:37:14 <jusss> how to make persistent work with postgresql?
01:38:02 <phadej> jusss: https://hackage.haskell.org/package/persistent-postgresql
01:40:39 <jusss> ok
01:45:07 <jneira_> asheshambasta: yeah, memory usage is still high, we are working on that too ;-)  https://github.com/haskell/haskell-ide-engine/issues/1318
01:47:41 <jneira_> there are other options, maybe more lightweight although i've not used them personally: https://github.com/digital-asset/ghcide
01:48:29 <jneira_> and https://github.com/ndmitchell/ghcid
02:01:11 * hackage lightstep-haskell 0.4.2 - LightStep OpenTracing client library  https://hackage.haskell.org/package/lightstep-haskell-0.4.2 (DmitryIvanov)
02:13:11 * hackage keycloak-hs 1.1.0 -   https://hackage.haskell.org/package/keycloak-hs-1.1.0 (CorentinDupont)
02:44:39 <royal_screwup21> can I ask an algorithmic question
02:48:11 <__monty__> Sure, DATAJA. *Answers are not guaranteed and may take days.
02:52:11 * hackage keycloak-hs 1.1.1 -   https://hackage.haskell.org/package/keycloak-hs-1.1.1 (CorentinDupont)
02:57:11 * hackage core-text 0.2.2.2 - A rope type based on a finger tree over UTF-8 fragments  https://hackage.haskell.org/package/core-text-0.2.2.2 (AndrewCowie)
02:58:12 * hackage core-program 0.2.2.2, core-data 0.2.1.2 (AndrewCowie): https://qbin.io/mariah-bunch-oxfp
03:07:18 <Ciantic> I'm trying to understand this in terms of Haskell: https://www.schoolofhaskell.com/user/edwardk/snippets/fmap does it mean that in Haskell it's enough to check that identity law holds for lawful functors if it also type checks?
03:09:48 <__monty__> That's how I read it, yes.
03:10:49 <dminuoso> Ciantic: Yes.
03:11:13 <dminuoso> Ciantic: In other terms, each of the functor laws can be derived from the other thanks to parametricity.
03:11:48 <dminuoso> Ciantic: So its enough to show either `fmap id = id` or `fmap f . fmap g = fmap (f . g)` - and the other one follows from parametricity.
03:11:59 <dminuoso> (Generally its probably easier to show the first)
03:22:11 * hackage core-text 0.2.2.3 - A rope type based on a finger tree over UTF-8 fragments  https://hackage.haskell.org/package/core-text-0.2.2.3 (AndrewCowie)
03:23:11 * hackage core-program 0.2.2.3, core-data 0.2.1.3 (AndrewCowie): https://qbin.io/petite-sperm-mzkg
03:30:12 <bwe> How do I structure the code correctly into different files? (1) data MyType = ... ; (2) instance ToHtml MyType ... -- calls renderMyType, (3) renderMyType -- requires types from (1)
03:32:10 <Ciantic> dminuoso, how come the Hackage's functor page doesn't say this? Countless hours are spent prooving both laws.
03:32:11 <bwe> the compiler tells me I should place instances and types in the same file. If I do so with (1) and (2) into (A) and factor out (3) to a distinct file (B), (A) and (B) form a circular import.
03:32:39 <__monty__> bwe: 1 can be in its own module. 2 has to be either in the module defining the data type or in the module defining the ToHtml class and needs to import 3. 3 needs to import 1.
03:33:59 <bwe> __monty__: So, would go advise me to put the instance ToHtml into a separate file from the type definition (ignoring the compiler warning)?
03:34:30 <__monty__> bwe: No, I said either with the types or with the class definition. Not in a file by itself.
03:34:52 <__monty__> And you can only avoid the circular dependency if you put it with the class definition.
03:35:20 <__monty__> Otherwise it all has to be in the same module.
03:37:36 <bwe> __monty__: Okay, what is best practice in such a situation?
03:39:09 <__monty__> It depends on the situation. I'd usually go with types+instances though. Since you often create instances for classes you haven't defined.
03:45:41 * hackage th-tc 0.2.0.0 - Typechecking in Template Haskell  https://hackage.haskell.org/package/th-tc-0.2.0.0 (mniip)
03:50:11 <bwe> __monty__: Hm, I wonder how I can factor out the logic of the instance implementation (not the instance itself) to a different file (without creating the circular dependency).
03:52:56 <__monty__> Maybe parameterise on all the things you need from the circular dep? So if you use `f` from module A and you want to move the instance implementation to module B you just add an argument `f` to `impl`. Then pass in `A.f` when using `impl` in module A.
04:03:51 <bwe> __monty__: what is impl?
04:06:44 <__monty__> bwe: The function you implement the instance's implementation in.
04:13:32 <bwe> __monty__: OK. But still, as I read the experiences of others, I see similarities, actually I did put everything into a big Types.hs file, too, like https://mail.haskell.org/pipermail/haskell-cafe/2010-September/083318.html
04:16:01 <__monty__> Types.hs is a very common pattern.
04:16:36 <__monty__> It's not necessarily a bad pattern imo.
04:20:32 <bwe> Let's recap: I can't separate the function that is called by the instance from the types, since it requires the types. Conversely, it's disencouraged to separate instance definitions from type definitions.
04:21:13 <bwe> Variants: (1) global Types.hs, (2) parametrized functions, (3) instance orphans -- what did I miss?
04:22:19 <__monty__> You don't have to orphan the instances if you define the class.
04:23:35 <bwe> __monty__: What does make an instance orphan? An instance without its class in the same file?
04:25:45 <__monty__> Instances have two possible parents, class definitions or type definitions. Take both of those away and you end up with an orphan.
04:28:10 <bwe> btw: Why are orphans bad?
04:33:12 <__monty__> Good question, I like this answer: https://stackoverflow.com/a/3079748
04:39:33 <LCRERGO> Hi, in an expression like "s :: Response (Maybe Song)" How do I use only the Maybe Song part in another function?
04:39:45 <dminuoso> LCRERGO: You can't, in general.
04:39:55 <dminuoso> LCRERGO: What is Response exactly?
04:40:12 <dminuoso> How is it defined or where is it defined?
04:40:29 <LCRERGO> is a Monad
04:40:45 <f-a> will <- do LCRERGO ?
04:40:46 <LCRERGO> in Network.MPD
04:41:14 <MarcelineVQ> type Response = Either MPDError
04:41:14 <dminuoso> LCRERGO: type Response = Either MPDError 
04:41:30 <dminuoso> LCRERGO: So you can either pattern match on it, or use (>>=)  depending on what behavior you want.
04:42:04 <LCRERGO> I want to pipe it into sgGetTag in ghci to get the Title
04:42:18 <dminuoso> LCRERGO: What behavior do you want if there is an error?
04:42:36 <dminuoso> % :t fmap
04:42:36 <yahb> dminuoso: Functor f => (a -> b) -> f a -> f b
04:42:42 <dminuoso> LCRERGO: ^- this is your friend. :)
04:44:37 <dminuoso> % :t (=<<)
04:44:37 <yahb> dminuoso: Monad m => (a -> m b) -> m a -> m b
04:44:39 <dminuoso> This too
04:45:51 <LCRERGO> well, I got Just Nothing, but it still better than only getting errors, he he
04:55:51 <bwe> __monty__: Thanks, added that post to the list of things to read.
05:04:15 <mniip> is there any way to write rewrite-rules involving stock class methods? e.g. fmap
05:05:21 <mniip> the GHC user guide suggests having a synonymous alias for the class method that is marked noinline for the duration of the rewrite rule
05:05:35 <mniip> that obviously doesn't work very well for something like <$>
05:06:04 <mniip> I cannot change the definition of <$>, and it is unreasonable to expect users to use a special version of <$> in appropriate places
05:06:04 <fendor> can i get build plan out of stack?
05:16:41 * hackage MagicHaskeller 0.9.6.8 - Automatic inductive functional programmer by systematic search  https://hackage.haskell.org/package/MagicHaskeller-0.9.6.8 (SusumuKatayama)
05:33:19 <archonest> Hello.
05:35:32 <dminuoso> fendor: Use cabal.
05:35:56 <fendor> dminuoso, yeah, thanks, but I am debgging stuff so it works with stack :D 
05:36:23 <dminuoso> Or rather, that's one option to get *some* build plan.
05:36:40 <fendor> dminuoso, yeah, but with cabal everything works as expected
05:37:11 * hackage hdaemonize 0.5.6 - Library to handle the details of writing daemons for UNIX  https://hackage.haskell.org/package/hdaemonize-0.5.6 (jeremy)
05:38:50 <jneira_> fendor: there is a stack2cabal utility http://hackage.haskell.org/package/stack2cabal
05:39:02 <jneira_> "Convert stack.yaml / package.yaml to cabal.project / cabal.project.freeze/ *.cabal."
05:39:40 <fendor> jneira_, yeah, but the build plan might still be different, right?
05:39:44 <jneira_> or maybe its dpeendent package would be enough: http://hackage.haskell.org/package/stackage-to-hackage it converts stack.yaml to cabal.project
05:40:35 <jneira_> mmm it adds constraints in cabal.project to match the stack plan...
05:41:41 <jneira_> oh wait you want the other way around
05:42:01 <__monty__> fendor: Doesn't the .lock file have the versions?
05:42:12 * hackage hasbolt-extras 0.0.0.24 - Extras for hasbolt library  https://hackage.haskell.org/package/hasbolt-extras-0.0.0.24 (ozzzzz)
05:43:52 <fendor> __monty__, lock files look empty for me
05:46:00 <jneira_> fendor: `stack freeze`?
05:46:56 <fendor> not entirely sure i want that, does this also include the package depdencies for the packages in the project?
05:48:15 <fendor> ok, no problem with c-h, stack just seems weird
05:48:27 <fendor> oops, wrong chat, sorry
05:52:13 <jneira_> >  does this also include the package depdencies for the packages in the project?
05:52:16 <lambdabot>  <hint>:1:64: error: parse error on input ‘in’
05:52:39 <jneira_> fendor: the output for hie looks like:
05:52:47 <jneira_> Uploaded file: https://uploads.kiwiirc.com/files/2734c0637b384e016ab538c3930e60c7/pasted.txt
05:53:42 <fendor> jneira_, doesnt contain hie-plugin-api, right? 
05:59:58 <jneira_> oh true :-/
06:00:12 * hackage th-tc 0.2.1.0 - Typechecking in Template Haskell  https://hackage.haskell.org/package/th-tc-0.2.1.0 (mniip)
06:22:47 <corporor> hey guys, what are some up to date resources to learn parsec?
06:23:35 <corporor> i've skimmed the real world haskell chapter on it but i don't know which parts if any are deprecated
06:23:37 <merijn> corporor: Megaparsec had a pretty in-depth tutorial, I think?
06:24:07 <merijn> corporor: Basically, I'd say "almost all of the code has bitrotted, but it doesn't matter, because the API design is essentially identical"
06:24:37 <merijn> corporor: I think if you read that chapter you should have a pretty good idea of what the API of any parser combinator looks like
06:24:41 <tdammers> the general principles still apply; the improvements made since RWH (especially in megaparsec) are about performance and ergonomics
06:24:57 <corporor> oh nice to know that
06:25:00 <merijn> corporor: See also https://markkarpov.com/megaparsec/megaparsec.html
06:25:12 <tdammers> e.g., megaparsec reuses things like state monads and applicative combinators from the existing haskell ecosystem rather than reinventing those wheels
06:25:25 <corporor> ok, so i'm gonna check out megaparsec
06:25:32 <corporor> thanks!
06:26:06 <merijn> corporor: Most of the bitrot of parsec is that it predates a lot of stuff that is now everywhere (like, it predates Applicative and Alternative :)) and a lot of its operators got adopted in Control.Applicative, but with slightly different precedences.
06:26:07 <corporor> yeah the link seems to be just what i needed :D
06:51:30 <maerwald> selective is quite odd, when your monad already captures failure with Either, then you'll end up with another Either inside the right value for capturing the selective choice
06:53:41 <maerwald> https://git.io/JewCc
06:56:24 <tdammers> that's an unfortunate consequence of Either being both the generic "one or the other" type and the generic "failure with some additional information" type
06:56:54 <maerwald> yeah, and because of Either, the inner m always has to be Monad...
06:57:08 <maerwald> can't write an instance with just Applicative or Selective constraint
06:57:15 <maerwald> on the inner m
06:58:10 <maerwald> (in practice it's IO anyway, but...)
07:00:54 <MarcelineVQ> that indentation creep tho
07:01:04 <RandomOrder> Does Haskell have an equivalent of Python's functools.lru_cache, i.e. declare a function this way to have return values memoized.
07:03:57 <nesqi> I have this lens problem.... where i need to give a lens/prisma twice as it's bound to different conflicting types otherwise. An example below, setOrError - I proved the same get and set
07:04:02 <nesqi> setOrError a get set v = if ((a ^. get) == Nothing) then Right (set set v a) else Left (formatError v) 
07:04:07 <nesqi> there has to be a better way =)
07:05:08 <totycro> RandomOrder: i think this is called memoize in haskell
07:05:09 <nesqi> oh.. set is both a function and value here the input set could be called s instead =)
07:05:22 <totycro> RandomOrder: so googling for that you should find a lot of resources
07:09:15 <JordiGH> There's some coding style where you put commas at the start of a new line, right?
07:09:28 <JordiGH> I'm trying to think where I've seen something like that, and I thought it was in Haskell.
07:11:04 <JordiGH> Hm, maybe when defining data types...
07:11:23 <MarcelineVQ> sometimes that's done to line up list items, you might do it with | in datatypes or , in records
07:11:49 <MarcelineVQ> There isn't a particular right way though
07:12:26 <JordiGH> Records, right, I think that's where I've seen this style dominate.
07:12:41 <sm[m]> RandomOrder: uglymemo on hackage is a nice simple one
07:12:52 <tdammers> it's also somewhat common in list and tuple literals
07:12:59 <tdammers> and of course SPJ-style do notation
07:13:08 <merijn> JordiGH: prefixed commas is definitely common, yes
07:13:25 <merijn> I use it for lists and imports a lot too
07:13:29 <JordiGH> Anyone got a quick example I could show?
07:13:36 <JordiGH> I can't just ddg it.
07:14:23 <tdammers> https://github.com/tdammers/yeshql/blob/master/core/tests/Database/YeshQL/ParserTests.hs <- JordiGH 
07:14:36 <tdammers> ^ this one uses prefix-comma notation for both lists and records
07:14:39 <merijn> JordiGH: https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/ingest-src/Jobs.hs
07:14:49 <sm[m]> x = {a=1
07:14:50 <sm[m]>     ,b=2
07:14:51 <sm[m]>     }
07:14:51 <merijn> That has it for imports, lists, and datatypes at various parts
07:14:58 <JordiGH> Thanks you two.
07:22:11 * hackage diskhash 0.0.4.2 - Disk-based hash table  https://hackage.haskell.org/package/diskhash-0.0.4.2 (luispedro)
07:45:08 <Phillemann> Does anyone have experience with the "miso" framework? The examples seem to generate a complete HTML page with head and body. However, the code never mentions these elements.
07:45:20 <Phillemann> There seems to be some glue that gets added, but I'm not sure how.
07:47:26 <mjrosenb> I've used it a bunch.
07:49:04 <mjrosenb> which example?
07:57:11 * hackage dotenv 0.8.0.3 - Loads environment variables from dotenv files  https://hackage.haskell.org/package/dotenv-0.8.0.3 (stackbuilders)
08:05:11 * hackage cassava-megaparsec 2.0.1 - Megaparsec parser of CSV files that plays nicely with Cassava  https://hackage.haskell.org/package/cassava-megaparsec-2.0.1 (stackbuilders)
08:16:26 <dmj`> Phillemann: I have some experience with it
08:16:49 <dmj`> Phillemann: miso only works on the body element, since head elements have no visual implications on the page
08:17:18 <dmj`> Phillemann: but you can use the FFI to modify the head
08:17:47 <dmj`> Phillemann: but there is an option to mount a miso application on any element that is a child of body as well, can embed multiple apps anywhere
08:18:57 <dmj`> or just listen to mjrosenb :)
08:19:43 <dmj`> merijn: I have a question about making a preprocessor for Haskell code, similar to hsc2hs, but nothing related to FFI'ing into C. 
08:20:42 <merijn> dmj`: Yeah?
08:20:46 <dmj`> I'd like to run my own custom preprocessor similar to how hsc2hs does it, is this possible to do w/o modifying cabal or ghc ?
08:21:16 <geekosaur> there's an option to run a preprocessor
08:21:26 <dmj`> I specifically want to look for any TH splice and inline it. 
08:21:26 <geekosaur> (and I don't mean CPP)
08:21:31 <merijn> dmj`: You can do it via Setup.hs and "build-type: Custom", but hvr is the true expert on "can I do X without having to use build-type custom"
08:22:09 <dmj`> geekosaur: ohhh, that's nice.
08:22:34 <merijn> dmj`: Last time I called a non-standard preprocessor it was in the pre-v2 era and I haven't really touched that code since
08:22:37 <geekosaur> https://downloads.haskell.org/ghc/latest/docs/html/users_guide/phases.html#ghc-flag--F
08:22:44 <dmj`> I want a function that runs over all my modules String -> IO String (where String is the contents of the module). I parse the Haskell, find the TH, execute dump the splice, and inline it back into its original definition
08:22:48 <Phillemann> dmj`: Ah, I see.
08:23:21 <geekosaur> hm. have you seen the zeroth package? (it's somewhat bitrotted though)
08:23:38 <dmj`> geekosaur, merijn: do you think my inline-th idea as a preprocessor is a good one ? Are there better alternatives ?
08:23:47 <dmj`> geekosaur: I have not, let me check
08:24:14 <geekosaur> the big problem is what killed zeroth: things change too often for such code to be portable across ghc versions
08:24:16 <merijn> dmj`: I'm not sure I understand what it's supposed to do?
08:24:21 <electricityZZZZ> so i learned about automatic differentiation here first, i will give you guys credit for being ahead of the curve in regards to PL features :) but something i am failing to understand is how automatic differentiation is supposed to interact with things that i would naievely consider to be non-differentiable, like branching on a discrete variable in a program... i've tried searching for posts on this and haven't 
08:24:22 <electricityZZZZ> really found anything i am satisfied with 
08:24:39 <geekosaur> and I'm not sure what inlining beforehand gets you, since splices expand inline anyway
08:24:41 <dmj`> geekosaur: woooa, this seems to be /exactly/ what I want.
08:25:06 <geekosaur> especially as a preprocessor; zeroth was intended to run over a code base to remove a TH dependency
08:25:34 <dmj`> merijn: basically find places that have $(makeLenses ''Foo) and inlines them.
08:25:43 <merijn> dmj`: To what end?
08:25:46 <dmj`> geekosaur: Lemmih always has the *coolest* projects
08:26:49 <conal> electricityZZZZ: branching/conditionals can introduce points of discontinuity and thus non-differentiability. Mainly auto-diff and machine learning people ignore the issue and give possibly incorrect values at those points, but there are probably better options to be explored.
08:27:30 <dmj`> merijn: to the end of the entire codebase
08:27:43 <dmj`> merijn: here's my picke, I'm trying to cross compile to ARM, GHC->ARM doesn't support TH
08:28:14 <dmj`> merijn: so I'd like a preprocessor based on x86 that runs the TH and inlines it before the GHC->ARM compiler takes over and builds
08:28:25 <geekosaur> cross-compile could be a sticking point if any basic types have different sizes, iirc
08:28:36 <Logio> conal: Isn't it really the notion of differentiability that is the issue here? Nothing that is implemented in a computer is non-differentiable in the AD sense, by definition
08:28:37 <electricityZZZZ> conal: incorrect values? ignore the issue?
08:29:13 <geekosaur> TH already has this issue. and I thought the server stuff dealt with this in a portable fashion (nd ARM cross-compile was part of the reason for its existence)
08:29:43 <conal> Logio: I don't follow. By what definition?
08:29:48 <electricityZZZZ> furthermore although i am a heavy mathematica user i always human-supervise any significant calculation before putting it into a computer program because even mathematica can do dumb things, and it can do dumb things even with derivatives,... so to automatically differentiate you'd need to, for instance, be able to exclude singularities or othersuch things automatically,...
08:30:04 <merijn> dmj`: You could just "dump-splices" once and manually paste the result in the code?
08:30:05 <geekosaur> that is, TH already has a cross-compile issue with cross-compatibility
08:30:10 <Logio> conal: by the definition of the AD derivative, assuming those are always well-types
08:30:13 <Logio> *well-typed
08:30:16 <conal> electricityZZZZ: I don't know what you're asking in this last reply.
08:30:27 <dmj`> merijn: yea but that's a lot of work, since the dependency chain has a lot of deps. I'd have to do this for.
08:30:36 <dmj`> merijn: persistent in particular.
08:30:52 <electricityZZZZ> conal: well uh it's hard to think of how a derivative which gives incorrect values would be useful for anything
08:31:02 <conal> Logio: which definition of the AD derivative do you have in mind? I take the problem specification from calculus.
08:31:11 <merijn> dmj`: Well, lemme go ahead and recommend you just get rid of persistent instead >.>
08:31:45 <merijn> dmj`: Honestly, heed my warning or you'll be stuck like me, repeatedly patching/fixing/working around it because migrating off of it is more work than doing that >.>
08:31:50 <Logio> conal: that's exactly what I'm saying, the calculus definition differs from the discrete implementation
08:32:00 <conal> electricityZZZZ: oh, thanks. the derivative in those cases (standard AD/ML practice) is not dependable at the points where the condition changes. 
08:32:03 <dmj`> merijn: yea... I already recommended this approach, the tentacles are wrapped too tightly around the codebase at this point I think.
08:32:22 <Logio> but that doesn't mean that the discrete implementation is in any way wrong, it's just a different notion of derivative that is always defined and computable
08:32:23 <dmj`> merijn: I could always try to recommend this again of course :)
08:32:23 <conal> Logio: to what discreteness are you referring?
08:32:34 <electricityZZZZ> conal: maybe what's going on is that substantially all of the AD work is referring to taking derivatives of a specific class of functions, but people don't circulate that class definition widely? for exapmle maybe everyone is just concerned with taking derivatives of matrix-vector operations, maybe with some simple nonlinearities...?
08:33:02 <dmj`> merijn: oh you're saying just *using* persistent is more work than patching dependencies for cross-compilation ?
08:33:19 <electricityZZZZ> conal: are people supposing that the "measure of" these broken derivatives is essentially zero so they ignore it? (in the probably common case of differentiating things peppered with ReLU)
08:33:20 <conal> electricityZZZZ: i don't think so. AD is used for quite a wide variety of non-linear operations.
08:33:24 <Logio> conal: discreteness in the sense of the function class just mentioned by electricityZZZZ ^
08:34:01 <conal> electricityZZZZ: yes, on a set of measure zero. which is not a good argument in my ears, since we typically sample at those points.
08:34:10 <conal> (we sample non-uniformly)
08:35:43 <conal> electricityZZZZ: alternatively (to loss of correctness and handwaving rationalizations) one can use other mathematically well-defined generalizations of differentiation such as subdifferentiation.
08:36:23 <dmj`> merijn: alright... I'll try again
08:36:26 <dmj`> and thanks
08:36:36 <electricityZZZZ> conal: so wtf is automatic differentiation
08:36:45 <conal> i bet subdifferentiation is a special case of the generalized AD algorithm in http://conal.net/papers/essence-of-ad/
08:36:50 <Logio> conal: I don't think you lose correctness by generalizing, if you do it the right way 
08:36:58 <conal> electricityZZZZ: see the previous link.
08:37:30 <conal> Logio: i think we're agreeing here: generalization as an alternative to loss of correctness. 
08:38:01 <Logio> oh right, I misread what you were saying
08:38:42 <conal> Logio: it happens.
08:38:45 <electricityZZZZ> furthermore the ML community is obsessed with SGD but i haven't yet seen whether anything is wrong with derivative-free approaches to optimization,
08:39:52 <electricityZZZZ> do we know definitively that SGD is superior to derivative-free optimization?
08:39:56 <conal> electricityZZZZ: AD is a method of computing derivatives of functions described as programs. to do so correctly, one needs a bit of non-standard interpretation of those programs, and there are a variety of tricks for doing so, with compiling-to-categories (http://conal.net/papers/compiling-to-categories/) being one recent new basis.
08:39:58 <merijn> dmj`: I'm saying my larges Haskell project is build on top of persistent and the only reason I haven't dropped it is the fact that it would take too much engineering time
08:40:10 <LCRERGO> \quit
08:40:12 <merijn> dmj`: persistent is an endless time-sink in terms of trying to get stuff done
08:40:34 <conal> electricityZZZZ: no (about SGD).
08:40:52 <merijn> dmj`: If I had a time machine I'd go back in time and stop myself from using it >.>
08:41:13 <dmj`> merijn: what would you recommend as a replacement?
08:41:18 <electricityZZZZ> so if we don't need derivatives, maybe i can optimize simply by computing the values of my function of interest at certain points, and then i don't even care about infinitesmals and differentiability, right?
08:42:09 <conal> electricityZZZZ: SGD is a questionable alternative to full GD, which is a (non-dependable) strategy for finding *local* minima, which has some questionable arguments for being reasonably close to global minima in some situations.
08:42:11 * hackage tmp-postgres 1.9.0.0 - Start and stop a temporary postgres  https://hackage.haskell.org/package/tmp-postgres-1.9.0.0 (JonathanFischoff)
08:42:33 <merijn> dmj`: Probably just one of the *-simple libraries for your specific database. Selda and Opaleye look somewhat promising (but the latter is postgres only and the API seems a bit heavy weight) and Selda came out after I was already far into using persistent
08:42:46 <electricityZZZZ> conal: well the cool kids would disagree with your explanation there,
08:42:47 <conal> electricityZZZZ: and GD is practiced as a *discrete* algorithm, though naturally continuous instead.
08:42:52 <conal> electricityZZZZ: yep, they would.
08:43:10 <electricityZZZZ> conal: the cool kids say that local minima are measure-zero-ish
08:43:22 <electricityZZZZ> conal: and that really what is trouble is that there are common saddle points 
08:43:24 <conal> electricityZZZZ: yep.
08:43:59 <dmj`> merijn: hmmm, yea there doesn't seem to be a good alternative.
08:44:24 <chreekat> dmj`: *-simple or beam, those are my favorites right now
08:44:26 <merijn> dmj`: Because at some point you *will* want to do something persistent doesn't support and you'll be either forced to 1) migrate away from persistent, 2) invent a workaround, or 3) patch persistent yourself (or a mix of the last 2)
08:44:34 <conal> electricityZZZZ: and maybe they're right, but the ML field seems to me to be mostly accidental complexity, coping mechanisms, and fuzzy rationalizations. My 2 cents; ymmv.
08:44:34 <dmj`> merijn: I tried using postgresql-simple and then just wrote my own generics for a bunch of CRUD operations, it was pretty good. and postgresql-simple-migration was nice too.
08:44:39 <merijn> beam has a *ridiculously* overcomplicated API
08:45:01 <dmj`> chreekat: yea? What about squeal? It's like the servant of haskell db libs
08:45:14 <merijn> Just 5 seconds of looking at it has convinced I can *never* seriously recommend beam to anyone with a straight face
08:45:30 <dmj`> the only issue I have with *-simple is queries ain't type safe.
08:45:36 <electricityZZZZ> merijin: erlang beam?
08:46:22 <EvanR> https://hackage.haskell.org/package/beam
08:46:25 <merijn> electricityZZZZ: No, the haskell library
08:46:35 <merijn> EvanR: beam-core, that one is deprecated
08:46:52 <merijn> Just look how gloriously comprehensible the types are! 
08:46:55 <merijn> "join_ :: (Database be db, Table table, BeamSqlBackend be) => DatabaseEntity be db (TableEntity table) -> (table (QExpr be s) -> QExpr be s Bool) -> Q be db s (table (QExpr be s))"
08:47:16 <merijn> That looks like a one way trip to "haha, type errors longer than C++"
08:47:38 <chreekat> dmj`: no opinion on squeal, haven't really looked at it yet
08:47:48 <merijn> Or how about this
08:47:52 <merijn> "outerJoin_' :: forall s a b be db. (BeamSqlBackend be, BeamSqlBackendSupportsOuterJoin be, Projectible be a, Projectible be b, ThreadRewritable (QNested s) a, ThreadRewritable (QNested s) b, Retaggable (QExpr be s) (WithRewrittenThread (QNested s) s a), Retaggable (QExpr be s) (WithRewrittenThread (QNested s) s b)) => Q be db (QNested s) a -> Q be db (QNested s) b -> ((WithRewrittenThread (QNested s) s 
08:47:58 <merijn> a, WithRewrittenThread (QNested s) s b) -> QExpr be s SqlBool) -> Q be db s (Retag Nullable (WithRewrittenThread (QNested s) s a), Retag Nullable (WithRewrittenThread (QNested s) s b))"
08:48:08 <merijn> I'll be over here just write my SQL queries in text, if you don't mind >.>
08:48:30 <EvanR> this is where F# guy chimes in and says, oh, you don't try to read the type sigs do you?
08:49:03 <evocatus> @pl \x -> x
08:49:03 <lambdabot> id
08:49:12 <aveltras> what should i read to understand why ghc throws "You cannot bind scoped type variables" error in my code ?
08:49:15 <EvanR> or the physics guy chimes in and says, that type sig looks perfectly cromulent
08:49:21 <evocatus> @pl \f g x y -> (f x) `g` (f y)
08:49:21 <lambdabot> flip =<< ((flip . ((.) .)) .) . flip (.)
08:49:32 <EvanR> just needs some notation to shrink it
08:50:02 <electricityZZZZ> im a fan of doing very very simple SQL queries with an ORM and complex ones raw
08:50:25 <EvanR> i like doing both with a proper SQL lib
08:50:43 <EvanR> i don't pretend my database contains objects
08:50:49 <heatsink> > on (==) fst ("abc", 123) ("abc", 456)
08:50:50 <dmj`> EvanR: F# type providers are pretty sweet, that's just some TH with runIO though
08:50:51 <lambdabot>  True
08:50:53 <nshepperd> BeamSqlBackend be, BeamSqlBackendSupportsOuterJoin be seems redundant
08:51:04 <merijn> dmj`: Honestly, even with persistent most of my queries are handwritten and using rawQuery, so the only future I really actively use atm is the schema setup/migration and in hindsight handrolling my own schema and migration stuff would've been easier and more flexible (if a bit more work up front, which is why I didn't do it in the first place)
08:51:07 <electricityZZZZ> conal: i guess one question would be, can backprop be done without derivatives?
08:51:10 <evocatus> @hoogle on
08:51:10 <lambdabot> Data.Function on :: (b -> b -> c) -> (a -> b) -> a -> a -> c
08:51:10 <lambdabot> System.Directory.Internal.Prelude on :: () => (b -> b -> c) -> (a -> b) -> a -> a -> c
08:51:10 <lambdabot> Text.Regex.TDFA.Common on :: (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
08:51:23 <merijn> dmj`: But I think that upfront effort is dwarfed by the effort I've had to put in later
08:51:27 <nshepperd> electricityZZZZ: backprop is a method of computing derivatives
08:51:49 <nshepperd> if be is a BeamSqlBackend that SupportsOuterJoin it oughta already be a BeamSqlBackend
08:52:21 <conal> electricityZZZZ: i agree with nshepperd about backprop. 
08:52:23 <evocatus> heatsink: thanks
08:52:28 <heatsink> you're welcome
08:52:55 <electricityZZZZ> right but we agree that we need to be able to do this with discrete variables, for instance, where derivative has no definition
08:53:23 <conal> electricityZZZZ: although i think originally backprop was entangled with a particular *use* of differentiation. there is probably still such an entanglement in some practitioners' minds.
08:53:52 <dmj`> merijn: people always say stuff like, "Oh but the automatic migrations"
08:54:05 <merijn> dmj`: Oh, those only work in a tiny subset anyway
08:54:13 <heatsink> Why does it need to be done with discrete types, electricityZZZZ?
08:54:22 <merijn> dmj`: I've had to handroll my own migration stuff on top of it to make it work
08:54:42 <conal> electricityZZZZ: the person who taught deep learning where i work seemed to have exactly this entanglement in his mind, as he repeatedly referred to backprop as a way of "propagating errors" rather than a technique for differentiation.
08:54:58 <EvanR> .oO( for a discretely changing variable you could define a type of time derivative. data DiscrDeriv a = Static | Changing (a,a). And hope that points in time where the derivative is Changing (x,y) are isolated in time
08:55:03 <dmj`> merijn: yikes
08:55:17 <electricityZZZZ> conal: i take it that your description is suggesting that he didn't know what he was talking about
08:55:50 <electricityZZZZ> conal: but we need a working definition of backprop which doesn't invoke differentiation, because differentiation is undefined on integers
08:56:03 <conal> electricityZZZZ: i think he partly understood deep learning, but not the essence of what backprop is about.
08:56:09 <EvanR> a time derivative is really all information available around an infinitesimal region of time
08:56:31 <merijn> dmj`: Anyway, hence my recommendation to seriously consider whether any engineering effort/time put into this "inline TH code" effort might be better spend just dropping persistent and not having that much TH to begin with ;)
08:56:31 <nshepperd> i don't think it's incorrect to describe backprop that way either
08:56:35 <conal> electricityZZZZ: no. i think there's another confusion tripping you up here. 
08:56:49 <nshepperd> but, well, the 'errors in question are derivatives
08:56:52 <electricityZZZZ> conal: so you are saying that "backprop" is irrevocably tied to differentiation
08:57:00 <conal> nshepperd: it's not exactly wrong, but it misses the essence of what backprop is.
08:57:29 <conal> nshepperd: ie differentiation, and focuses instead on a use of differentiation.
08:57:47 <nshepperd> sure
08:58:11 * hackage tmp-postgres 1.9.0.1 - Start and stop a temporary postgres  https://hackage.haskell.org/package/tmp-postgres-1.9.0.1 (JonathanFischoff)
08:58:24 <conal> which makes it less clear that (a) there are other optimization techniques besides AD and (b) there are AD algorithms besides backprop (and better ones at that).
08:58:37 <heatsink> electricityZZZZ, They pretend that ints are reals for the purpose of differentiation.  Is that approximation unsuitable for some reason?
08:58:55 <electricityZZZZ> maybe integers are a bad example, i could just as well say enums or something
08:58:58 <nshepperd> electricityZZZZ: note that while you can't do AD on discrete domains like a set of integers, you *can* do AD on conditionals over a continuous domain
08:59:39 <electricityZZZZ> nshepperd: sure because then you just have those measure zero trouble spots which are treated as negligible for whatever reason
08:59:39 <conal> electricityZZZZ: in many cases, it is still meaningful to can differentiate a function of the reals where that function involves a conditional.
09:00:04 <nshepperd> electricityZZZZ: eg. the function (if x > 0 then x else 0) has a derivative of 1 when x > 0, and 0 when x < 0, and an undefined derivative when x is exactly 0
09:00:05 <conal> electricityZZZZ: just don't try to differentiate a function *of* a discrete domain (Int, etc).
09:00:07 <electricityZZZZ> conal: ^
09:00:11 <electricityZZZZ> conal: yes there we go
09:00:34 <conal> nshepperd: thanks. that's the sort of example i had in mind.
09:00:35 <electricityZZZZ> so i have f(x: i64, y: f64) -> z: i64
09:01:00 <electricityZZZZ> conal: can you provide a meaningful definition of backprop for f above?
09:01:01 <EvanR> you could define a difference function
09:01:18 <EvanR> how does the function change from one step to the next
09:02:26 <nshepperd> and you can just fill in the derivative at x = 0 with an artificial value like 0.5, which works because x is almost never 0
09:02:51 <conal> electricityZZZZ: do you mean backprop (algorithm) or differentiation (mathematical specification) or something else?
09:03:55 <conal> nshepperd: or a subderivative of [0,1] (the interval) at 0
09:03:57 <electricityZZZZ> conal: well we were discussing how differentiability is trouble for AD, and "backprop" is "essential" for "doing deep learning/modern ML", and you didn't like the idea that i was trying to talk about backprop without derivatives, so my question is, can you define backprop on f given above?
09:04:30 <conal> electricityZZZZ: who said backprop is essential for deep learning?
09:06:40 <electricityZZZZ> conal: well you have to compute a variable update somehow, and i was under the impression that the efficiency gain from backprop was vital to "making deep learning work" although i haven't checked how essential it is
09:08:12 * hackage amqp-utils 0.4.0.0 - Generic Haskell AMQP tools  https://hackage.haskell.org/package/amqp-utils-0.4.0.0 (woffs)
09:08:30 <conal> electricityZZZZ: i can guess about what you heard or what someone might have meant: reverse-mode AD is much more efficient than forward-mode AD for high-dimensional optimization problems of the sort that arise in deep learning. 
09:08:30 <dmj`> merijn: I'd trust your intuition, mind said the same, you gotta do what you gotta do I guess.
09:08:49 <dmj`> merijn: this would make life a lot easier
09:08:53 <dmj`> merijn: what about lenses though?
09:08:58 <dmj`> merijn: everybody uses the TH for makeLenses
09:08:59 <conal> electricityZZZZ: backprop is one implementation of reverse-mode AD in that setting, and it's a very popular choice, but it's not essential, and it does have significant drawbacks.
09:09:01 <nshepperd> "essential" seems like overstating what we know. what I know is that SGD works, and that non-gradient methods mostly haven't worked
09:09:26 <nshepperd> as far as obtaining impressive results like gpt-2
09:09:28 <conal> and SGD doesn't depend on backprop
09:09:37 <conal> it depends on differentiation.
09:10:15 <conal> and for efficiency, reverse-mode AD in particular, but not necessarily backprop.
09:11:16 <merijn> dmj`: Hope they don't have so many you can't easily manually inline them? >.>
09:11:25 <electricityZZZZ> conal: okay well i need an "encapsulating definition" for what is being computed which doesn't specialize to a specific algorithm
09:11:38 <merijn> I don't have very constructive things to say in that regard, I guess
09:11:50 <conal> electricityZZZZ: yes! the definition is differentiation, as in the differential calculus.
09:12:22 <electricityZZZZ> conal: sorry, i was making an effort to move away from derivatives
09:12:43 <conal> electricityZZZZ: check out the paper and talk "the simple essence of automatic differentiation" http://conal.net/papers/essence-of-ad/. I recommend the Microsoft Research version of the talk for its pace and thoroughness.
09:14:07 <dmj`> merijn: it's approaching 300 modules
09:14:08 <electricityZZZZ> okay we can use the definition in your paper: "tune a parametric model to closely match observed data"
09:14:38 <dmj`> merijn: saying, "leave persistent", is actually very constructive and reinforces what I've thought as well
09:14:47 <conal> electricityZZZZ: if you don't want derivatives, you don't want backprop. maybe you just want function optimization instead, where gradient descent (via differentiation) is only one strategy. in that case, you might check out "A Functional Reboot for Deep Learning" https://github.com/conal/talk-2018-deep-learning-rebooted#readme. Sadly the lighting and sound are poor in this recording.
09:17:14 <electricityZZZZ> conal: im reading...
09:19:09 <electricityZZZZ> conal: i dont understand your notation s "approximately equals" f s on page 20
09:19:31 <conal> electricityZZZZ: which document?
09:20:19 <electricityZZZZ> http://conal.net/talks/deep-learning-rebooted.pdf
09:21:13 <conal> electricityZZZZ: "isomorphic to"
09:21:28 <conal> electricityZZZZ: btw, I just updated the DL-reboot PDF on the web to eliminate the slide builds.
09:22:59 <EvanR> ah. here's "derivative" for V2 Integer -> Integer. Subdivide the domain by 2, and the range is now 0 or V2 (Delta Integer). At the original positions derivative is zero. And when crossing one of 8 directions to the adjacent cells you may have a delta or two tell you the jump
09:23:35 <EvanR> admittedly lousy for doing gradient decent
09:23:59 <conal> electricityZZZZ: i just changed that symbol (used accidentally) and updated the slides.
09:24:11 <electricityZZZZ> conal: i mean,... yeah i guess we can say that deep learning is just "minarg" as you say
09:24:46 <conal> electricityZZZZ: yes. and with a particular style of objective/loss function based on data samples.
09:25:33 <electricityZZZZ> and on top of that, a particular style of optimizing that loss function,... i think
09:25:51 <conal> electricityZZZZ: and if one is satisfied with a derivative-based argmin such as GD or SGD, then one just needs to figure out how to differentiate, eg forms of AD.
09:26:39 <electricityZZZZ> right. so then, if you can't take a derivative, are you hosed in terms of how much time it takes to compute updates in search of argmin?
09:27:01 <conal> electricityZZZZ: yes, i think that's the essence of DL, with things like graphs (neural *nets*) and arrays ("tensors") being unfortunate historical accidents.
09:28:21 <conal> electricityZZZZ: i suspect there are powerful, elegant, rigorous, and efficient hybrid discrete/continuous techniques to be found.
09:28:53 <conal> electricityZZZZ: which is part of why identifying the essential problem and shedding assumptions like graphs, tensors, and backprop matter to me.
09:29:08 <electricityZZZZ> right,...
09:29:20 <conal> in that they define some unfortunate choices into the problem statement itself! :( 
09:29:28 <electricityZZZZ> well this gets into something that i have been thinking about,... and now i bet i am going to get scooped for saying this
09:29:48 <electricityZZZZ> but if we look at what we can do with regards to optimization you rather quickly move towards SAT solvers
09:29:51 <EvanR> i guess what i just built was more like an anti-integral
09:30:19 <conal> electricityZZZZ: SAT for optimization rather than satisfiability?
09:30:28 <electricityZZZZ> why not?
09:31:02 <conal> electricityZZZZ: do you know of uses of SAT or SMT for optimization? 
09:31:18 <electricityZZZZ> i havent searched for publications but it seems obvious that you could just say:
09:31:36 <conal> i bet there's a lot to be done in integrating derivatives, interval analysis, SMT, and branch & bound techniques.
09:32:07 <electricityZZZZ> here is my f(x), does f(x) have an optimum less than y? answer: yes, does it have an optimum less than 0.5*y? answer: no, does it have an optimum less than 0.75*y, etc
09:32:25 <dmj`> merijn: how many modules is your large persistent application
09:32:27 <conal> ... on top of a really good, essential problem specification (dropping historical ML baggage).
09:32:51 <conal> electricityZZZZ: sure. similar to how interval analysis is used.
09:33:14 <electricityZZZZ> so here is what i think might be going on: GPUs have made it possible to dump huge parallel compute effort into these derivative based optimization routines
09:33:25 <electricityZZZZ> but SAT solvers still can't parallelize
09:33:53 <electricityZZZZ> so you can't really dump huge cluster compute and megawatts into SAT solvers and get any benefit
09:34:05 <electricityZZZZ> megawatt-hours ;)
09:34:27 <conal> electricityZZZZ: that perspective interests me as well. i don't know whether SAT/SMT solution is *inherently* resistant to (correct) massively parallel implementation. seems a very important question, considering the power of SMT.
09:35:20 <electricityZZZZ> well this is where i need to find people who can actually program SAT solvers to help work on this. i knew one of the chaff guys but i don't think i could get his attention
09:36:12 <electricityZZZZ> SAT solvers are fast (mostly) due to heuristics as i understand it
09:36:13 <conal> sometimes people (often experts) get attached to the wrong way to look at a problem (e.g. graphs & arrays in AD) and make things needlessly difficult.
09:36:22 <electricityZZZZ> and lots of smart people have tried and failed to parallelize SAT
09:37:00 <electricityZZZZ> so, dump deep learning into generating heuristics for parallelization of SAT
09:37:03 <conal> in particular, many programmers tend to think in operational and sequential terms, even though we haven't had genuinely sequential computers in decades.
09:37:22 <conal> electricityZZZZ: could work.
09:38:29 <electricityZZZZ> if computers are the undefeated go champions its hard to think of why we should expect humans to generate better SAT heuristics
09:40:51 <evelyn> I feel like it's problematic to say that computers 'think', especially with regards to comparing them against humans.
09:42:10 <electricityZZZZ> evelyn: i can't really say that humans think either, so maybe the true answer is that nothing thinks, and thinking is itself an illusion and we are no different from rocks.
09:42:54 <evelyn> well, people think and reason. There's a lot of academic debate about whether computers reason in the same way.
09:43:22 <electricityZZZZ> conal: target should announce a "target prime" subscription and compete directly with amazon
09:43:43 <electricityZZZZ> i get the impression that target has better supply chain management,...
09:43:55 <electricityZZZZ> anyway, sorry offtopic :)
09:50:39 <nshepperd1> Deep learning uses arrays because they can be efficiently parallelized on gpu hardware
09:51:00 <nshepperd1> operations over them, rather
09:51:41 * hackage dotenv 0.8.0.4 - Loads environment variables from dotenv files  https://hackage.haskell.org/package/dotenv-0.8.0.4 (stackbuilders)
09:52:48 <Ariakenom> arrays can be efficiently executed on different hw
09:57:27 <electricityZZZZ> conal: another issue with "automatic differentiation" as a concept which i have had, in the situation where you are working on a "differentiable" domain is that if you look at runge-kutta methods it becomes clear that not all methods of computing derivatives are created equal and some can have rather large impacts on the subsequent performance of your numerical results,... i don't see people in the AD community 
09:57:27 <electricityZZZZ> discussing this so i am unsure of whether they are paying attentio nto this
09:58:40 <conal> electricityZZZZ: runge-kutta methods are numeric approximations, and AD is not.
10:00:49 <electricityZZZZ> well one presentation on AD i was viewing was showing it as adding an epsilon variable to continuous variables and then dropping epsilon squared terms,...
10:00:58 <conal> electricityZZZZ: and certainly not all AD methods give similar performance. for instance reverse-mode is better for high-dimensional domain and low-dimensional codomain.
10:01:30 <conal> electricityZZZZ: yeah. that's a popular perspective, and i can see that it looks like an approximation, but it isn't.
10:02:14 <electricityZZZZ> codomain?
10:02:22 <conal> electricityZZZZ: it's more like working with Taylor series, and dropping all but the first two terms, to get a local affine approximation, which is exactly what differentiation is about.
10:02:42 <conal> electricityZZZZ: in a function type "a -> b", b is the codomain.
10:03:06 <conal> electricityZZZZ: and the "range" of a function f : a -> b is a subset of the codomain b.
10:09:52 <conal> electricityZZZZ: and i think there are better (more general and easier to prove correct) ways to understand AD than via dual numbers (those epsilons). i think i made a brief comparison in my Microsoft Research talk on "the simple essence of AD" linked earlier in this conversation.
10:11:06 <conal> also, dual numbers seem to lead to imprecise AD explanations and forward-mode AD (inefficient for optimization/ML).
10:12:09 <conal> "imprecise" in a precise sense: most functions from dual numbers to dual numbers are inconsistent with differentiation.
10:14:27 <electricityZZZZ> i have tried to understand categories several times and each time felt like i was too dumb
10:15:38 <conal> electricityZZZZ: there's a lot of depth in category theory, but you need almost none of it understand "the simple essence of AD". just think of Category as the type class in Haskell's Control.Category. 
10:16:08 <electricityZZZZ> i don't really know haskell either :-P
10:16:28 <tabaqui1> uh, what kind of error can jump out of "try @SomeException"?
10:17:02 <dsal> asynchronous?
10:17:14 <dmj`> tabaqui1: you can fromException and match on different types
10:17:14 <tabaqui1> I don't think so
10:17:27 <dmj`> :t fromException
10:17:29 <lambdabot> Exception e => SomeException -> Maybe e
10:17:30 <tabaqui1> yeah, I mean, that I don't catch this exception at all
10:17:49 <tabaqui1> my test-suite just exits with ExitFailure (-11)
10:18:47 <conal> electricityZZZZ: my own understanding of category theory is still fairly shallow, but i recognize that it's a very successful algebraic abstraction, and it's often exactly the right one to turn a complicated problem into a simple one. AD is an example of that success. The decades-long AD literature has made out reverse-mode AD as a quite complicated beast involving forward & backward graph traversals, and mutable state. The "simple essence" paper shows
10:18:49 <conal>  that reverse-mode AD is incredibly simple even in a form vastly more general than the AD literature had previously addressed.
10:19:32 <conal> electricityZZZZ: check out this talk for a friendly motivation: https://github.com/conal/2017-talk-teaching-new-tricks-to-old-programs#readme
10:19:50 <electricityZZZZ> i am looking up Control.Category and see Kleisli and am feeling dumb
10:20:13 <electricityZZZZ> i can suppose this means "something which has associativity and left and right identity"
10:20:56 <tabaqui1> nope, I mean what kind of error can do this? I have such code "tryAny (hspec smth) >>= either (die . show) pure", where "tryAny" is the specified "try"
10:21:22 <conal> electricityZZZZ: *differentiation itself* is neatly compositional w.r.t the vocabulary of categories, but not w.r.t the vocabulary of graphs or the lambda calculus, so it was inevitable (in retrospect) that AD would work out much more simply once rephrased in category terms.
10:21:50 <conal> electricityZZZZ: don't worry about Kleisli for now.
10:21:57 <tabaqui1> oh, negative int in ExitFailure means signal, right?
10:22:02 <tabaqui1> so it is sigSEGV then
10:22:05 <tabaqui1> damn
10:22:25 <conal> electricityZZZZ: yes. associativity and identity. just like a monoid, but with multiple types ("objects")
10:22:57 <tabaqui1> can anyone tell me how can I debug segfaults in GHC?
10:23:29 <MarcelineVQ> "<conal> electricityZZZZ: my own understanding of category theory is still fairly shallow," this is a scary sentence to me given that you wrote concat :>
10:24:17 <conal> MarcelineVQ: it's true, though! all i needed to know for compiling-to-categories was how to translate from typed lambda calculus to categorical vocabulary.
10:25:37 <conal> a little category theory (CT) goes a surprisingly long way! and more CT goes further.
10:26:09 <electricityZZZZ> i write my code in rust these days,... after horrifying experiences with GC in industry i am loathe to rely on GC,... and i dont want to have to get five phds to make my program run fast, so idiomatic speed (which i would argue haskell does not have and rust does) is something i care about
10:26:09 <conal> i've got a huge value from what little i learned, so i was motivated to learn more.
10:26:30 * shapr hugs conal
10:26:31 <electricityZZZZ> but i am definitely haskell-curious
10:26:48 * conal smiles and hugs shapr back
10:27:18 <electricityZZZZ> so i guess in the case of derivatives i haven't looked into the definition of derivatives on stochastic variables
10:27:46 <electricityZZZZ> an image would best be defined in most circumstances as an observation of a million stochastic variables
10:28:08 <electricityZZZZ> rather than an observation of a million continuous variables
10:30:00 <conal> electricityZZZZ: i've not thought much about derivatives of probability distributions, but they form a vector space (even when the underlying value space is discrete), so differentiation probably makes useful sense. or differentiate the expectation instead.
10:30:35 <electricityZZZZ> conal: your linear arrow is different on pg3 simple essence is the same as or different from the linear type people's linear arrow?
10:31:04 <electricityZZZZ> ack that sentence needs to be edited: is -o on pg3 the same as or different from the -o from linear types?
10:31:06 <conal> electricityZZZZ: different. it's linear functions/maps/transformation.
10:31:31 <electricityZZZZ> rather than linear, got it ;)
10:31:44 <conal> electricityZZZZ: derivatives *are* linear maps (not numbers, vectors, matrices, etc).
10:32:12 <electricityZZZZ> conal: whats fun is probably most variables people are working with in ML applications are stochastic rather than continuous
10:32:33 <electricityZZZZ> conal: not to mention that everyone is chasing correlations rather than causal associations
10:38:11 <electricityZZZZ> conal: well if i can make progress on this paper i might be able to justify understanding this on the grounds that i never had the patience to wrap my head around derivatives of tensors
10:39:18 <conal> electricityZZZZ: good. i suggest starting with the MSR talk and then reading the paper.
10:40:17 <conal> electricityZZZZ: are you using "tensors" the way ML people do, to mean multidimensional arrays?
10:40:55 <shapr> conal: if you get some time, interested in trying out the research paper annotation tool I'm building? https://imgur.com/gallery/YNez0sA
10:42:02 <electricityZZZZ> conal: well,... so i know that in theory mathematicians like to distinguish between linear transformations and matrices
10:42:56 <electricityZZZZ> or linear transformations and tensors
10:44:18 <conal> read the paper and watch the talk, and you'll see that exactly this distinction was crucial for simple, rigorous, efficient, and general AD.
10:44:28 <electricityZZZZ> i suppose you can say that the array is an inefficient representation of something which can be represented with fewer numbers,
10:45:08 <electricityZZZZ> but aside from notational differences i don't think i have seen an example where you cannot parametrize a linear transformation with a finite collection of numbers
10:45:31 <conal> electricityZZZZ: there's a simpler, safer, and more general alternative to (fortran-era) multi-dimensional arrays. see the functional-reboot talk.
10:50:09 <EvanR> a tensor is a kind of linear transformation. All matrices represent a linear transformation but not vice versa
10:50:32 <electricityZZZZ> EvanR: yeah, i am aware of this
10:51:20 <EvanR> i appreciate the concreteness of "matrix = grid of numbers", and am annoyed when physics calls almost anything "a matrix"
10:52:03 <EvanR> and sometimes an actual matrix "a tensor"
10:52:08 <conal> and simple, rigorous, efficient reverse-mode depends on *not* using matrices to represent linear transformations.
10:52:10 <EvanR> who do we fire
10:52:19 <dsal> The Wachowskis
10:52:47 <conal> *reverse-mode AD*
10:53:30 <MarcelineVQ> EvanR: even a matrix of granite?
10:53:53 <electricityZZZZ> conal: while i try to read these functional reboot slides, i have been wondering about something relevant to this discussion:
10:54:02 <EvanR> nice
10:54:12 <EvanR> that has no concreteness after all
10:54:19 <electricityZZZZ> if i want to add a rigid constraint to my model, does the ML community have a way of handling that?
10:55:06 <electricityZZZZ> for example if i am modeling the motion of some balls bouncing around , and i want to say that energy and momentum are conserved in this model, can i throw those constraints in easily?
10:55:30 <conal> electricityZZZZ: better ask someone in the ML community. but for my own curiosity, what do you mean by adding a rigid constraint to your model?
10:56:12 <jules000_> afaik there are no efficient general algorithms to deal with constrained optimisation problems except for linear constraints
10:57:24 <electricityZZZZ> conal: did i answer your question?
10:57:57 <conal> electricityZZZZ: ah. i missed it. thanks. yes.
10:58:20 <conal> Maybe Michael Gleicher's old "differential manipulation" work is relevant, as it used AD and constraints.
10:58:45 <conal> and i think Lagrange multipliers, iirc.
10:59:58 <electricityZZZZ> yeah ive done lagrange multipliers by hand and for some simple problems but haven't thought about what would happen if you tried to use them with a million params
11:00:45 <electricityZZZZ> like some nasty deep learning model, it feels like there are good odds that it is tough to add constraints,....
11:02:56 <conal> electricityZZZZ: btw, since you're concerned about efficient execution, note that Haskell programs can be compiled directly into massively parallel hardware (via a category). it's work in progress but seems a much better bet to me than continuing to use sequential languages in the age of parallelism.
11:04:41 <electricityZZZZ> conal: so yeah i have a few concerns in this department if you have some useful commentary
11:04:58 <conal> electricityZZZZ: this compilation target is exactly what motivated the compiling-to-categories work, of which AD is another instance. moreover, they combine, so one can write a simple functional program and get massively parallel, efficient derivative.
11:05:06 <electricityZZZZ> conal: one is that garbage collection (and maybe even dynamic memory allocation itself) seems to be trouble for efficient parallelization
11:05:30 <electricityZZZZ> conal: especially if you are doing something where you can't plan your computation in advance
11:05:36 <EvanR> GC is part of the usual interpretation of haskell programs
11:05:55 <electricityZZZZ> conal: due to amdahl
11:05:58 <EvanR> is it part of the circuit, parallel array, other other interpretations
11:06:15 <electricityZZZZ> if you are spending 1% of your program execution in GC, the best you can do is a 100x speedup
11:06:30 <EvanR> (ghc does have the parallel gc)
11:07:17 <conal> electricityZZZZ: i used to work for a company that made a parallel fpga-like machine that reconfigured itself at 2GHz. that's the sort of target architecture i have in mind. or massively parallel analog photonics. i don't intend to hefty computations on a cpu at all.
11:08:01 <electricityZZZZ> conal: oh hehe i had a conversation with some people about high frequency FPGA reconfig,... but i thought it took a lot longer than that to reconfig
11:09:16 <electricityZZZZ> conal: there is no photonic gate afaik, except there is some group out of princeton with quacky looking "neural lasing" papers published in credible journals,... either they have made some kind of actual research breakthrough or it is quantum computing
11:09:31 <electricityZZZZ> conal: and it is in my reading list but i haven't had time to review yet
11:09:52 <conal> electricityZZZZ: nope. the chip was running well, including haskell programs!
11:10:00 <electricityZZZZ> conal: ..wait a photonic computer?
11:10:26 <electricityZZZZ> conal: are you talking about the same group i am? one of the dudes was from princeton? i would have to do some foraging to find the names
11:10:30 <conal> electricityZZZZ: the chip was designed from the start for fast reconfig.
11:10:49 <electricityZZZZ> there ar elots of quacky photonics papers where they claim to do fast compute and then it's just some stupid linear transofmr
11:12:14 <conal> electricityZZZZ: i was talking about tabula (fast reconfig), but i have friends at luminous computing (analog photonics) as well.
11:13:12 <electricityZZZZ> luminous is a familiar name, there are at least two interesting and potentially credible photonic computing companies
11:14:19 <electricityZZZZ> found it, https://www.nature.com/articles/s41598-017-07754-z
11:21:12 <electricityZZZZ> so the luminous guys use haskell to program their systems? and their photonic computers are actually computers and can actually compute something other than a fourier transofmr?
11:22:25 <EvanR> soon i will be pwning on fortnite with my photonic rig
11:23:13 <MarcelineVQ> no pwning after 9pm mister
11:23:19 <electricityZZZZ> conal: i should say, the luminous rig is turing complete? and is there are some figures of merit regarding compute per watt or per second or something you can mention?
11:23:32 <electricityZZZZ> err i mean a turing machine, not turing complete
11:23:46 <Orbstheorem> Is there an frp framework that targets a tui? 
11:25:50 <shapr> Orbstheorem: target will probably be brick if anything https://github.com/jtdaugherty/brick/
11:33:23 <electricityZZZZ> i know the groq guys were using haskell but didn't understand the choice
11:33:40 <conal> electricityZZZZ: i'm unsure which details luminous would be comfortable with my discussing. i'm personally impressed with what they're doing. 
11:34:06 <electricityZZZZ> conal: well i might be interested to meet them if they are potentially interested to meet me
11:34:22 <electricityZZZZ> and i respect nondisclosure ;)
11:34:28 <conal> electricityZZZZ: i know the groq folks as well, and their choice of haskell makes a lot of sense to me. low-level languages may give short-term speedups, but i think of as a very bad long-term bet.
11:35:24 <electricityZZZZ> conal: well do you have an answer to the amdahl issue? the best i can see is hope that a "sufficiently smart compiler" will enable predictive static allocation or somesuch
11:35:33 <electricityZZZZ> or more practically there is GRIN/ASAP
11:35:36 <wroathe> I'm trying to define a newtype that contains a tuple where the first element is a Map of some arbitrary k to some arbitrary v, and the second element is a Map with a subset of keys from the first map. At first glance, it looks like I could generate an arbitrary listOf keys, and then shuffle that and generate a sublistOf those keys, but that seems inelegant
11:35:53 <wroathe> Can anyone here think of a cleaner way off the top of their heads?
11:36:12 <wroathe> This is for QuickCheck btw
11:36:38 <wroathe> the newtype is: newtype SubMapOf k v = SubMapOf (Map k v, Map k v)
11:36:45 <conal> electricityZZZZ: if you mean dynamically shaped data (sum types), then perhaps dynamic hardware reconfiguration. or your earlier answer of throwing machine learning at the problem.
11:37:14 <EvanR> wroathe: i'm not sure a newtype gains anything there over using a data type with two fields
11:37:37 <wroathe> EvanR: It allows me to define an Arbitrary instance to express this dependency
11:37:40 <wroathe> of map 2 on map 1
11:38:00 <EvanR> mkay...
11:38:28 <wroathe> EvanR: Unless you're saying there's an existing Arbitrary instance that implements "Generate two sets, where set 2 is a subset of set 1"
11:38:47 <wroathe> EvanR: Or maybe you're suggesting I do this within the quickcheck property itself
11:38:54 <electricityZZZZ> conal: https://making.pusher.com/latency-working-set-ghc-gc-pick-two/ is this quackery?
11:39:31 <EvanR> i was thinking newtype over a pair has no advantage over a data type with two fields, but you may have tuple-machinery already in place with quickcheck
11:41:02 <phadej> electricityZZZZ: http://www.well-typed.com/blog/2019/10/nonmoving-gc-merge/
11:41:06 <wroathe> EvanR: Doh. This is a case of putting on blinders. In the intro to quickcheck I read the guy used newtypes for everything and I've just been doing it that way. There's no reason I couldn't just use a product type
11:41:24 <wroathe> EvanR: But that's not material to the specific problem I'm trying to solve
11:41:40 <EvanR> it probably makes no difference at runtime
11:41:52 <EvanR> but it's less typing to use a data type ime
11:41:57 <electricityZZZZ> yeah i know about the lower latency GC, it's a little bit slower
11:42:16 <tabaqui1> allright, I think that I found out why my code causes segfaults
11:42:34 <tabaqui1> I was testing a code that uses HDBC-mysql
11:42:53 <tabaqui1> and this lib stores statements as ForeignPtrs
11:43:30 <tabaqui1> so the library doesn't finish statements after execution
11:44:13 <tabaqui1> and I use quickcheck for testing and it makes thousands of statements
11:44:21 <tabaqui1> and GC doesn't follow to clean them all
11:46:11 <phadej> electricityZZZZ: my implicit point: runtime things are fixable with "work", language design deficiencies are way harder to fix
11:46:43 <tabaqui1> it looks like segfault cannot be catched in Haskell code, but cabal tests run in forked process, so cabal has some info about them
11:47:01 <tabaqui1> exit code -11 to be precisely
11:48:21 <electricityZZZZ> phadej: well the link you posted and the reduced latency haskell GC won't help a lot with amdahl
11:49:38 <conal> electricityZZZZ: about that gc bog post, i assume the game changes considerably when moving from cpu to massively parallel execution (GPU, FPGA, etc).
11:50:25 <conal> electricityZZZZ: since i'm interested in large jumps in speed, i don't pay much attention to cpu-based execution strategies.
11:51:40 <phadej> tabaqui1: 11 sounds familiar that your system runs out of memory
11:52:03 <electricityZZZZ> conal: well GPUs can't really branch
11:52:13 <iqubic> foldr :: Foldable t => (a -> b -> b) -> b -> t a -> b
11:52:21 <iqubic> foldr1 :: Foldable t => (a -> a -> a) -> t a -> a
11:52:31 <iqubic> These are from Data.List
11:52:39 <iqubic> foldr :: (a -> b -> b) -> b -> Map k a -> b
11:52:46 <tabaqui1> phadej: if I understand correctly, negative exit code means "died by signal". And (-11) is sigSEGV in POSIX
11:52:49 <iqubic> That last one is from Data.Map.Strict.
11:52:50 <pta2002> Is there any function that takes a list and returns the number of repetions in that list
11:52:50 <pta2002> like
11:53:08 <pta2002> f [1,1,2,3,1,1] = [(2,1), (1,2), (1,3), (2,1)]
11:53:24 <dmwit> pta2002: Data.MultiSet.fromList
11:53:24 <iqubic> I wish Maps had an equivalent to foldr1 and foldl1.
11:53:26 <EvanR> > group [1,1,2,3,1,1]
11:53:26 <dmwit> ?hackage multiset
11:53:26 <lambdabot> http://hackage.haskell.org/package/multiset
11:53:28 <lambdabot>  [[1,1],[2],[3],[1,1]]
11:53:29 <electricityZZZZ> conal: FPGA i dont know as well maybe you can reprogram sufficiently quickly to branch like you were mentioning with tabula but i dont have access to fpgas at the moment and nervana's founder told me they were useless so i got scared away from them
11:53:35 <pta2002> EvanR: nah it's not group
11:53:38 <pta2002> dmwit: thanks
11:53:55 <EvanR> looks like a mapping of group
11:53:57 <dmwit> Wait, no, group is closer than what multiset does.
11:54:02 <hpc> you can zip the list with the length of each element
11:54:08 <hpc> after grouping
11:54:10 <dmwit> I didn't notice that you had kept the separation of 1s at the beginning and end.
11:54:28 <hpc> and sort first so you don't have repeat groupings
11:54:38 <dmwit> I think they *want* repeat groupings.
11:54:41 * hackage floskell 0.10.2 - A flexible Haskell source code pretty printer  https://hackage.haskell.org/package/floskell-0.10.2 (ecramer)
11:54:47 <dmwit> (See the spec.)
11:55:15 <pta2002> yeah i want repeating groups
11:55:23 <pta2002> i can easily do it with group just wondering if it's already there
11:55:28 <iqubic> Is there anyway I can get a version of foldr1 and foldl1 for Data.Map?
11:56:02 <EvanR> > (liftA2 (,) head length) [1,1,1]
11:56:04 <lambdabot>  (1,3)
11:56:25 <EvanR> not sure how that works but ok
11:56:51 <iqubic> It's using the Applicative instance of ((->) r)
11:56:53 <hpc> it's using the Reader applicative
11:56:58 <EvanR> cool
11:57:05 <EvanR> i figured it was something like that :)
11:57:06 <iqubic> Where r :: [a] in this case.
11:57:27 <EvanR> was just reflexive
11:57:55 <pta2002> ehh i'll just use something i can understand lol
11:58:07 <pta2002> group zipped with length it is
11:58:09 <EvanR> map (liftA2 (,) head length) . group
11:58:26 <EvanR> head is sound because group returns only non-empty lists
11:58:28 <pta2002> TIL (,) is a function
11:58:46 <pta2002> what does liftA2 do really?
11:59:04 <EvanR> it does the same thing as (,) <$> head <*> length
11:59:05 <hpc> liftA2 f x y = f <$> x <*> y
11:59:11 <hpc> (<$>) is fmap
11:59:18 <hpc> and (<*>) is more interesting
11:59:24 <hpc> :t (<*>)
11:59:25 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
11:59:29 <EvanR> same as pure (,) <*> head <*> length
11:59:35 <pta2002> i should probably brush up my haskell
11:59:42 <iqubic> In fact, what I really want is foldr1WithKey
11:59:44 <iqubic> foldrWithKey :: (k -> a -> b -> b) -> b -> Map k a -> b
11:59:46 <EvanR> "applicative function application"
12:00:04 <iqubic> Something like that, but In this case, I just don't have a sensible starting value.
12:00:19 <electricityZZZZ> conal: whatever your level of speed the percent of execution time spent in GC provides a fundamental limit on parallelization
12:01:37 <EvanR> garbage is a product of arbitrary aliasing in a way the compiler can't detect
12:01:51 <EvanR> which may not be a thing in the DSL that is getting compiled into GPU code
12:02:20 <iqubic> Well, actually, in this case, the starting value I want to use with foldrWithKey is just "(tail $ assocs map)" which is why I want foldr1WithKey.
12:02:23 <lavalike> > ((head &&& length) <$>) <$> group $ [1,1,2,3,3,1,1,1]
12:02:26 <lambdabot>  [(1,2),(2,1),(3,2),(1,3)]
12:02:54 <EvanR> :t (&&&)
12:02:55 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
12:03:00 <EvanR> man... Arrow is still a thing
12:03:15 <iqubic> Yeah... It is.
12:03:45 <lavalike> 💘
12:03:54 <iqubic> So is there a good way to get the behavior I want?
12:11:12 <electricityZZZZ> EvanR: yeah and i am under the impression that you either need to manually annotate the aliasing (rust), have some kind of ai-system (as yet unspecified), or be left with GC
12:13:33 <EvanR> a proof that those are precisely the three possibilities would be interesting
12:13:53 <EvanR> every language is difference
12:13:56 <EvanR> different*
12:14:09 <electricityZZZZ> like i mentioned i saw some interesting work on GRIN/ASAP for haskell but haven't looked into it
12:15:26 <electricityZZZZ> also i currently believe rust's philosophy that mutable state actually exists and merely needs to be handled carefully rather than eliminated entirely. that philosophy could be wrong.
12:19:27 <iqubic> I love how everyone is ignoring my question about folds over a map.
12:19:58 <electricityZZZZ> iqubic: i can be quiet, pardon :-P
12:20:17 <iqubic> No, feel free to keep talking.
12:22:12 * hackage fused-effects 1.0.0.0 - A fast, flexible, fused effect system.  https://hackage.haskell.org/package/fused-effects-1.0.0.0 (patrick_thomson)
12:24:14 <EvanR> electricityZZZZ: haskell uses mutable state in many places with various kinds of justifications for why it's not wrong. Also linear types could be used as a justification, though haskell doesn't
12:24:29 <conal> in this age of commodity massively parallel hardware (and much more on the way), mutable state seems an especially costly assumption; so it's probably worth some mental stretching exercises.
12:25:18 <conal> haskell inherited some old habits from sequential programming, but we don't need to be satisfied with keeping them.
12:26:03 <conal> haskell was more of a nonsequential language in its earlier history.
12:26:06 <EvanR> i like how Ur/Web gets away with just scribbling on memory forever, until the web request is done. No memory management
12:26:43 <tdammers> wasn't early PHP much like that too?
12:26:47 <EvanR> what an elegant solution
12:26:56 <tdammers> just leak memory like there's no tomorrow, let the OS clean up after you
12:27:12 <tdammers> process only lives as long as the request anyway, at least with oldschool CGI
12:27:22 <EvanR> i know, brilliant
12:27:41 <EvanR> though OS level process killing and spawning is now considered slow
12:28:13 <tdammers> IIRC the problem is not so much that it's slow, but that you don't do it ahead of time
12:28:20 <EvanR> Ur/Web running as it's own OS please
12:28:41 <tdammers> if you can spin up a worker process before the request comes in, then handing the request to that worker is blazing fast
12:28:47 <cheater> hi
12:29:12 <cheater> can someone suggest an online collaborative editor? preferably with haskell support?
12:29:19 <tdammers> and killing isn't time critical anyway, so you just let the request finish and then reap the process whenever
12:29:38 <sm[m]> tabaqui1: interesting about your segfaults
12:30:07 <EvanR> yes it seems java uses this strategy, keep all possible java programs ready to run so you don't have wait for them to boot up :)
12:30:10 <sm[m]> cheater: for small stuff, maybe http://repl.it ? Up to 4 users
12:30:28 <cheater> small stuff is great. thanks
12:30:51 <EvanR> something doesn't seem right about that strategy though
12:31:19 <sm[m]> cheater: well actually it can import a github repo or be saved as a repo so doesn't have to be small.. but it can only use the basic libs
12:32:42 <cheater> ok :) cool
12:33:31 <electricityZZZZ> conal: 
12:34:02 <cheater> conal: what sequential habits does haskell have?
12:35:17 <shapr> well, there's IO
12:36:11 * hackage terminal-punch 0.1.3 - Simple terminal-based time tracker  https://hackage.haskell.org/package/terminal-punch-0.1.3 (EmilAxelsson)
12:36:21 <conal> electricityZZZZ: "monadic [sic] IO", lists, absence of things like parallel-or.
12:38:11 * hackage serverless-haskell 0.9.3 - Deploying Haskell code onto AWS Lambda using Serverless  https://hackage.haskell.org/package/serverless-haskell-0.9.3 (AlexeyKotlyarov)
12:39:25 <electricityZZZZ> i once started reading paul graham's book on lisp. in the first few pages he was like "here is a loop in list. it's a gazillion times slower than C. to make it fast, you have to do this" and it was like this one page thing full of gobbledigook... so i stopped learning lisp
12:39:39 <electricityZZZZ> *in lisp
12:41:32 <dmwit> Through sheer force of will, the GHC folks have managed to make it 2x slower than C instead of a gazillion x.
12:43:36 <cheater> conal: if programs in haskell tended to be applicatives rather than monads, would that be better?
12:44:16 <conal> cheater: i don't think so.
12:44:32 <EvanR> facebook is making use of parallelism with their applicative-based thing
12:44:43 * dmj` whistles IO, IO, it's off to work we go
12:45:06 <conal> IO is a special case. It not only embraces sequentiality but also imperative programming, abandoning the otherwise mathematically/denotationally well-defined nature of Haskell and its benefits.
12:45:55 <conal> And IO is not a monad (or even a non-monad), iiuc.
12:46:25 <electricityZZZZ> conal: can you build a SAT solver in haskell which is faster than miniSAT or some other more modern (single-threaded) SAT solver (or separately ,parallel)
12:47:21 <electricityZZZZ> conal: you can even use whatever hardware you like to accomplish this... i know msft had an FPGA SAT solver project
12:47:54 <conal> electricityZZZZ: i think the fundamental question there is not about haskell, but rather about SAT/SMT. if there's a good parallel algorithm, then haskell would not imply an execution slow-down.
12:48:12 <fenedor> what are some nice packages for showing progress in the terminal? Mayb be linux exclusive 
12:48:15 <electricityZZZZ> there is probably no algorithm, just a large collection of heuristics
12:48:34 <electricityZZZZ> proof by time: nobody has found it
12:48:51 <conal> electricityZZZZ: further, analyzing the question in precise and elegant terms (not in terms of imperative programming) is where i'd expect to find good answers.
12:49:51 <conal> electricityZZZZ: i wouldn't underestimate the potential of just thinking differently about the problem. SAT & SMT are not my expertise, but then AD wasn't either.
12:50:30 <conal> It's easy for a whole community to get stuck in a rut, defining a problem so badly that they cannot discover good solutions.
12:50:50 <conal> (e.g., deep learning)
12:51:06 <fragamus> Howdy I think I need a comonad to abstract a (relative) seekable bytestring
12:51:10 <ptrcmd> conal: what do you mean defining a problem so badly
12:51:29 <fragamus> What do we have for that
12:51:46 <ptrcmd> conal: any example definitions?
12:53:03 <conal> ptrcmd: i mean missing the fundamental, simple & general essence of a problem and getting distracted by incidental and unfortunate choices. For instance, graphs (neural *nets*) and arrays ("tensors") for AD and deep learning. or imperative programming in general.
12:53:49 <conal> or pixels or streams for images or dynamic/time-varying systems.
12:54:15 <conal> (i.e. discreteness in space and time)
12:54:24 <ptrcmd> representation?
12:55:03 <conal> another example from earlier: matrices instead of linear transformations.
12:55:51 <conal> or arrays for parallel programming
12:56:01 <conal> or roman numerals for math.
12:57:10 <ptrcmd> If I understand you correctly, what you are saying is that some representations are better suited than others for some particular problem, and you are saying that sometimes people choose bad representations
12:58:29 <ptrcmd> so, representations and data structures
13:00:14 <conal> ptrcmd: thanks for paraphrasing & checking. that's part of what i'm saying. another part is that defining *any* representation into the problem statement (rather than a more abstract characterization) can be harmful. for instance, i define AD in terms the the abstract notion of linear transformations (and indeed much more generally than that), and then specialize to different representations for different settings, including forward mode, reverse mode,
13:00:15 <conal>  etc.
13:01:02 <ptrcmd> Ah
13:01:55 <conal> Oh, hey. I have a meeting now. 
13:01:58 <merijn> electricityZZZZ: tbh, I think one of the most underrated/undersold features of Haskell is how easy it is to write low-level C like Haskell, call out to existing C code, and most importantly how to wrap such low level code back up into nice higher level abstractions
13:02:52 <electricityZZZZ> i've given up on C i think
13:03:01 <electricityZZZZ> it's too hard to write correctly
13:03:21 <electricityZZZZ> a nice haskell/rust interface would be very nice to have though
13:03:50 <electricityZZZZ> and i think that if haskell embraced some of the things rust does to be kind to amateurs like me it could be a much more successful language
13:04:03 <EvanR> like what
13:04:06 <conal> oh, hey. i have a meeting now. catch you all later.
13:04:16 <electricityZZZZ> conal: hey its been fun thanks for sharing your knowledge
13:04:28 <electricityZZZZ> conal: i might email you
13:04:54 <electricityZZZZ> some nice things rust does for noobs:
13:05:13 <electricityZZZZ> 1. string handling is well-thought out, always utf8, no bizarre gotchas
13:05:16 <ptrcmd> EvanR: like...rust algebraic datatype <-> haskell algebraic datatype transforms I guess :D
13:05:23 <electricityZZZZ> 2. one true package manager, cargo
13:05:33 <ptrcmd> EvanR: data structure marshalling stuff
13:05:56 <electricityZZZZ> 3. no lazy io issues (maybe haskell needs a rewrite?)
13:06:01 <merijn> electricityZZZZ: I agree that C is too hard to write safely, especially in large pieces of code, but to be able to easily call it at the single function granularity is nice
13:06:11 <merijn> electricityZZZZ: There's is almost no lazy IO in haskell
13:06:20 <merijn> There's like 3-5 lazy IO functions in base, iirc
13:06:31 <electricityZZZZ> right but isn't it a library minefield...?
13:07:03 <merijn> Not really, I'm not really aware of any libraries using lazy IO among libraries I use
13:07:22 <electricityZZZZ> 4. this might be too much to ask for but use of garbage collection has been minimized to the greatest extent possible in rust, it would be nice if haskell had some way of linearizing as much as is reasonable/practical
13:07:55 <merijn> electricityZZZZ: Why? For 99% of applications GC is no problem
13:08:25 <jackdk> the number of times I hear people venting about String/str/&str I wouldn't call #1 "no bizarre gotchas". It's possible that the thought underlying it all is sound but, yeah. gotchas.
13:08:27 <tdammers> electricityZZZZ: at this point, you might as well program in Rust, no?
13:08:28 <merijn> I mean, I like the idea of Rust's ownership as "RAII on steroids", but the reality is that I basically never need it, which is why I still havent bothered learning Rust
13:08:38 <electricityZZZZ> tdammers: well, that's why i write in rust :-P
13:09:12 <merijn> electricityZZZZ: We already have Rust, what's the point of making Haskell "more like Rust" if people want that they can just write Rust to begin with
13:09:13 <electricityZZZZ> jackdk: okay, maybe it's possible to do better than rust, but i am afraid of the many haskell string typese
13:09:53 <electricityZZZZ> merijn: well i was calling out things which, as an amateur programmer, i find makes rust more of a relief to write code in
13:09:56 <merijn> electricityZZZZ: Why, there's like 2 different strings (3 if you count lazy Text, but I hardly ever use that, since it's main use case would be lazy IO...) and 1 for bytes
13:10:30 <electricityZZZZ> merijn: i was made to believe that haskell had many different string types used across libraries
13:10:37 <jackdk> If you want text: Text. if you want bytes: ByteString. Choose strictness/laziness as appropriate. Do not use String outside of a 100-series CS course
13:10:40 <merijn> electricityZZZZ: Yes, people like to exaggerate
13:10:51 <tdammers> not really. there's Text, lazy Text, and String. that's it.
13:10:59 <merijn> electricityZZZZ: In reality there's "String" and "Text", there's a few alternatives but those are all super niche
13:11:25 <tdammers> and Text / lazy Text use the exact same API, you just import different modules
13:11:30 <electricityZZZZ> okay so String should be banned,... is there an easy way i can ban it from the libraries i import? can i say #ban String and have ghc tell me whether my library is using it...?
13:12:16 <electricityZZZZ> i also am dependent on experts like you guys to figure out what the language is and tell me what to write,... the rust community makes a point of debating among itself and then adopting a single opinion, whereas in haskell
13:12:31 <electricityZZZZ> i see language extensions all over the place with varying choices and never know what to do
13:12:33 <merijn> Anyway, this conversation seems to basically be "why is Haskell not Rust", but that's not a very interesting conversation, since we might as well be discussing "why are apples not pears"?
13:13:21 <evelyn> Apples and pears are very closely related!
13:14:00 <electricityZZZZ> um, well, i am talking about impressions i have as an amateur programmer, which can be false, and maybe some of my impressions are true and shouldn't be corrected, and maybe some are true and should be corrected,...
13:19:40 <ptrcmd> merijn: well, discussions on how the lanugage design choices were / can be made can be interesting
13:20:03 <EvanR> after about 1 day of haskell, i think i got over the amateur programmer impressions. I think that was one of the valuable experiences of haskell
13:20:11 <EvanR> "everything you know is wrong"
13:21:41 <merijn> ptrcmd: Sure, they can be, but can be and are are different things :)
13:22:30 <ptrcmd> merijn: yeah
13:23:31 <EvanR> for one thing, "be sure to write all code using RAII just in case it would have been slow"... isn't necessary thanks to optimizations
13:24:08 <EvanR> if something really is slow, there are more or less crunchy ways to do work to speed it up
13:24:32 <EvanR> and we don't have to live with this crunchy way throughout the entire program
13:25:59 <EvanR> also coming from ruby i was ready to accept slowness, it couldn't get slower than ruby, which is wildly successful
13:26:37 <ptrcmd> lol
13:28:58 <sm[m]> interesting impressions electricityZZZZ. They differ a bit from our typical day to day experience I would say
13:30:37 <sm[m]> it's good to hear how life compares in other ecosystems
13:36:07 <sm[m]> I usually don't have trouble with too many string types, or lazy io, or laziness, or reasoning about performance, or memory footprint, or GC delays, or compilation speed (ok, that's a lie, always need more speed), or dependency hell, or too many package managers (one main one and one alternate is not bad)
13:37:15 <EvanR> heh
13:37:36 <EvanR> one problem haskell doesn't have is too many GUI libs though
13:39:32 <merijn> It has loads, just very few that are nice too use :p
13:39:34 <Ivan__1> I always thought that String is criticized not for being lazy, but because they occupy to much RAM (something like 10x increase in comparison with on disk size). 
13:39:44 <merijn> deech's fltkhs stuff looks usable, but not very pretty
13:40:11 <EvanR> i loved FLTK back in the day
13:40:16 <merijn> Ivan__1: String is super convenient for somethings, but indeed awful for many bulk text uses
13:40:36 <fragamus> Hi I have a question. I have a file that I want to read in a buffered way, with relative seeks and I like comonad semantics
13:40:58 <merijn> EvanR: In terms of ease of use and portability it seems pretty good: https://github.com/deech/fltkhs
13:40:58 <fragamus> What type classes exist for that
13:41:11 <sm[m]> I converted hledger from String to Text and didn't see much difference
13:41:20 <EvanR> but the look and the C++ leave much to be desired
13:41:33 <merijn> sm[m]: Yeah, but how much text did you have?
13:41:38 <sm[m]> fltkhs++, if only anyone used it
13:41:59 <sm[m]> lots of little texts, I guess
13:42:01 <EvanR> hledger uses fltk?
13:42:15 <merijn> EvanR: He was talking about String to Text conversion
13:42:16 <sm[m]> not yet!
13:42:42 <sm[m]> EvanR: I was just upvoting the recommendation of fltkhs
13:42:57 <EvanR> for lots of short strings... ShortByteString! yeeahhh
13:43:08 <EvanR> optimize the ** out of it
13:43:13 <merijn> sm[m]: I mean String is 24 bytes or so per character, vs ~2 for Text, but if you only have, say, 2k characters that's like a few kilobyte not something drastic you'd notice
13:43:42 <iqubic> So, this lack of foldr1withKey is pissing me off.
13:43:57 <Ivan__1> hledger parses input into a complicated data structure, validates corectness of input, saves all of the input in the said data structure, and only then proceeds to do something useful... 
13:44:02 <merijn> iqubic: That's trivially worked around, though?
13:44:09 <iqubic> How so?
13:44:18 <merijn> iqubic: Just use M.elems and foldr1 the list?
13:44:43 <iqubic> Well, It would have to be M.assocs I think.
13:44:51 <merijn> eh, whatever the right name is
13:45:16 <iqubic> M.elems :: M.Map k a -> [a].
13:45:37 <iqubic> I want M.assocs :: M.Map k a -> [(k, a)].
13:45:55 <sm[m]> Ivan__1: that's right, to the extent those things are required (laziness often helps out)
13:46:46 <iqubic> I thought a version of foldr from Data.Map would be more efficient. I guess not.
13:47:06 <Ivan__1> sm[m]: to use laziness an app should be written in streaming style, like unix pipes
13:47:47 <sm[m]> you mean, to use it robustly ? scalably ?
13:48:07 <iqubic> And actually foldr1 doesn't actually do what I want it to.
13:48:15 <iqubic> What is foldr1 even good for?
13:48:17 <merijn> iqubic: It might be a tiny constant fraction more efficient, but I wouldn't be surprised if this fuses away entirely and even if not since it's lazy it'll only be a smallish constant slowdown
13:48:23 <merijn> iqubic: Very few things :p
13:48:46 <Ivan__1> sm[m]: I mean I don't see musch sense to use lazy IO if at some moment all input data should reside in RAM
13:48:51 <EvanR> "i don't have a sensible starting value" is not one of them
13:48:58 <iqubic> Right.
13:49:16 <EvanR> foldr1 still requires a sensible starting value
13:49:23 <EvanR> it just comes from somewhere else
13:49:29 <iqubic> Where does it come from?
13:49:37 <EvanR> the non-empty Foldable?
13:50:23 <dsal> I've occasionally thought foldr1 would be useful, except I've not also had a guarantee that my input wasn't empty at the same time.
13:50:24 <sm[m]> Ivan_1: in hledger I use laziness like a magic optimising wizard, and it has been all win so far. It simplifies the coding task
13:50:34 <sm[m]> But yes a proper streaming implementation would be quite interesting, even though some of our features wouldn't work with it
13:52:07 <merijn> sm[m]: Why wouldn't they work?
13:52:19 <merijn> EvanR: There's ShortText too :p
13:52:24 <EvanR> oh nice
13:53:34 <EvanR> and in the end, after all our wealth of string types, we don't have one which is a flat dumb-as-dirt array of utf8 bytes
13:53:47 <sm[m]> merijn: some of the customary features of Ledger/hledger require analysing the whole data set, like detection of a canonical display style for each commodity, or processing special directives in the journal file.
13:54:21 <sm[m]> but those could be disabled if you wanted to process big data
13:54:57 <dsal> ShortText has a fancy big-O.  Apparently I can't copy and/or paste it:  (n)
13:55:47 <dsal> Ah.  \(\mathcal{O}(1)\)
13:55:52 <EvanR> https://imgur.com/a/JtM38EF
13:56:25 <dsal> Yeah.  It looks fancier here:  https://hackage.haskell.org/package/text-short-0.1.1/docs/Data-Text-Short.html
13:56:30 <sm[m]> hledger currently has a 10x speed disadvantage compared the C++ ledger. This is partly that we do more stuff, but it could be that a streaming implementation would fix this.
13:56:39 <dsal> Bringing in some kind of LaTeX syntax just to make an O(1) seems a bit overkill.
13:57:31 <Ivan__1> streaming would help with memory footprint, I am much less sure about speed
13:58:14 <sm[m]> well, those often seem to go together
13:58:15 <dsal> The talk on fused effects suggested some pretty major performance increases where applied, though it seems like applying it can be a bit of a pain.
13:58:21 <evelyn> I believe it is U+1D4DE
13:58:30 <evelyn> Mathematical bold script capital O
13:59:04 <dsal> 𝓞(1)
13:59:12 <iqubic> Oh!
13:59:14 <dsal> Weird.   Why  not just type that?  :)
14:00:26 * dmj` gets on his lazy I/O is faster than streaming soapbox
14:00:56 <EvanR> lazy I/O moves fast and breaks things
14:01:24 * dsal read that as 'faster than streaming smallpox
14:01:49 <merijn> dmj`: Sure, all you have to give up is sane error handling, control over resources, and your sanity!
14:02:02 <merijn> That's a deal if I've ever seen one!
14:03:03 <dmj`> merijn: lazy I/O is perfectly fine for many scenarios, this whole "lazy I/O is the great satan" was a pendulum swing to bump some libraries that were ripped off from oleg
14:03:16 <dmj`> </hottake>
14:03:53 <dibblego> \tiny{+1}
14:04:06 <merijn> And Haskell is just a ripped off Lazy ML!
14:04:41 <sm[m]> Ivan__1: re hledger memory usage, I don't think that "all input data resides in RAM" is always true, but probably sometimes there are chokepoints that make it so. If you know more, I'd be glad to hear it
14:04:45 <dsal> ⁺¹
14:09:18 <sm[m]> dmj` what's a rule of thumb for when lazy I/O is fine or not ?
14:11:50 <dmj`> sm[m]: when your data is small, for one shot things. If you have a long running TCP service that does a lot of disk I/O of heavy files, probably best to use a streaming library.
14:12:14 <dmj`> that haskell heap is so unpredictable these days
14:12:31 <merijn> dmj`: If your data is small, why bother with lazy IO at all, just load it in memory entirely
14:12:46 <sm[m]> "one shot" makes sense to me
14:13:09 <dmj`> merijn: well you might have to do lazy I/O to get it into memory first :)
14:13:30 <merijn> dmj`: Why would you need lazy IO for that?
14:14:31 <dmj`> I'm not anti-lazy IO
14:14:42 <sm[m]> or I guess "non-interleaved I/O" - no multiple threads doing I/O, no multiple I/O operations at different times potentially overlapping
14:15:02 <merijn> lazy IO always has tricky properties when it comes to error handling/exceptions
14:15:03 <electricityZZZZ> so this will be a potentially dumb question, rust is careful to force me to write functions which either never return an error or return a result type
14:15:09 <dmj`> merijn: you could use strict I/O sure, so you're saying there's never a case for lazy I/O ?
14:15:09 <merijn> That alone makes me avoid it at all cost
14:15:14 <electricityZZZZ> haskell, i think (??) has exceptions...? 
14:15:29 <electricityZZZZ> and so could i say that haskell is not a strict regarding explicit error annotation and handling...?
14:18:25 <merijn> dmj`: Anything that I want to be robust/maintainable needs predictable error handling, so even if we're going to assume "I don't care about resource management" then that is still an issue, and for most IO there's just no way to be sure there won't be any errors
14:19:20 <EvanR> electricityZZZZ: haskell has exceptions in IO. In non-IO code you have to use Maybe, Either, or something to do "exceptions"
14:19:21 <Ivan__1> sm[m]: in the datastructure Journal there is a field jfiles of type [(FilePath,Text)]
14:20:53 <EvanR> IO has many things for convenience but you lose some composability and guarantees, like knowing code won't throw an exception (ignoring bottoms)
14:21:13 <sm[m]> Ivan__1: yes..which commands actually force that to be evaluated ? I'm not sure
14:21:17 <EvanR> hence avoiding IO unless necessary
14:21:17 <Ivan__1> if Text is strict, then if this field is evaluated at some moment all the text goes to RAM, I think. I doubt it will be GC, but I can be wrong...
14:22:17 <evelyn> dsal: it's a unicode font variant of a character, most keyboards won't type that :P
14:22:20 <EvanR> if the field of type [(FilePath,Text)] is evaluated (to WHNF), no Text appears yet
14:22:33 <sm[m]> Ivan__1: it could be checked with a trace I guess
14:22:42 <iqubic> No I have to figure out how to write this as a fold.
14:22:43 <EvanR> you only get [] or <thunk>:<thunk>
14:22:49 <dmj`> merijn: "And for the vast majority of programming problems, lazy IO is entirely satisfactory. However, if you will be opening many files, or talking on many sockets, or otherwise using many simultaneous resources, an iteratee (or enumerator) approach might make sense."
14:22:57 <iqubic> What's the difference between foldr and foldl?
14:22:59 <dmj`> merijn: this is a quote from Don Stewart on stack overflow
14:23:07 <dmj`> merijn: you and him can duke it out
14:23:11 <EvanR> iqubic: r u serious :)
14:23:25 <iqubic> EvanR: I'll go look it up online
14:23:43 <sm[m]> oooh, invocation of dons
14:23:46 <EvanR> http://foldr.com/
14:23:52 <merijn> dmj`: Well, I disagree with him, then. tbh I care more about error handling sanity
14:24:10 <iqubic> EvanR: I don't fully understand that website.
14:24:11 <merijn> I think Haskell leaves quite a lot to be desired in that regard and lazy IO makes it infinitely worse
14:24:14 <EvanR> heh
14:24:23 <chreekat> merijn: I would imagine that lazy and strict IO would have the same issues with "predictable error handling". It's IO that presents the difficulty in that regard, particularly for the class of apps that just consume their input and exit
14:24:43 <merijn> chreekat: No, with strict IO exceptions can't leak out there handlers
14:25:04 <dsal> asynchronous exceptions around IO are typically quite surprising.
14:25:04 <electricityZZZZ> and then haskell calls stuff Left and Right because to hell with annotating which one is an Err?
14:25:15 <merijn> chreekat: With lazy IO the exception happens when the value is forced/evaluated, which will usually be way outside any handlers, which makes them essentially impossible to handle sanely
14:25:30 <merijn> dsal: Oh, we're not even considering async exceptions yet :p
14:25:32 <EvanR> electricityZZZZ: "haskell was discovered, not invented. I think you can tell" 
14:25:33 <chreekat> merijn: ah yeah
14:26:01 <sm[m]> electricityZZZZ: the error is the one that's not Right. Obviously.
14:26:02 <dsal> merijn: Oh, yeah.  I guess I'm thinking of that as an async exception.  It's different, though.
14:26:25 <merijn> Haskell's exception handling is entirely unsatisfactory, tbh. I have ideas on what it should look like, but I don't see any feasible to fit it into GHC in a backwards compatible way, which probably dooms any of it from the start
14:27:26 <dsal> I realized I can't reasonably exit a process from inside one of my mqtt callbacks because they catch too many kinds of exceptions and cause other exceptions that bubble up and I've lost the "meant to do that" vs. "supervised thing crashed"
14:28:05 <EvanR> given your framework, you'd have to send a message to whatever is responsible for ending th eprocess
14:28:29 <EvanR> such as the main thread which is stuck waiting for such a message while everyone else does work
14:28:55 <dsal> I thought about doing that, but plumbing the context seemed like too much work for a thing I probably don't need.
14:29:09 <dmj`> sm[m]: whenever I find myself in a corner, I just reference a Don S. quote, and I'm magically absolved.
14:29:22 <dmj`> of any and all wrongdoing
14:29:47 <merijn> dmj`: The real dons solution is to write less code and take more pictures of sunsets :p
14:30:28 <EvanR> dsal: could be shoe horned via global MVar :)
14:30:45 <dmj`> merijn: such is the fate of all old timer haskellers
14:33:04 <electricityZZZZ> sm[m]: what do you do with haskell
14:35:41 <dsal> EvanR: I kind of just  wanted _exit.  I learned that System.Exit.die just doesn't do what I thought it should.
14:36:36 <merijn> dsal: If you're ok with *nix only unix has a proper "Just exit, dammit!"
14:37:07 <merijn> dsal: https://hackage.haskell.org/package/unix-2.7.2.2/docs/System-Posix-Process.html#v:exitImmediately
14:37:48 <dsal> I have a program running on a Linux box in the cloud and had it getting itself into a weird state.  I'd rather actually fix the problem, but this sort of thing gives me a button on my phone that will fix it.
14:38:07 <dsal> Also, I may have fixed the problem.  It's one of those annoying things that only breaks under a weird arrangement of circumstances.
14:39:03 <dmj`> electricityZZZZ: you can do everything with haskell
14:39:08 <Ivan__1> sm[m]: I am not sure at the moment, I will to figure tomorrow
14:40:10 <dsal> exitImmediately looks good, though:  exitImmediately status calls _exit to terminate the process with the indicated exit status. The operation never returns.
14:40:14 <dsal> Kind of lame it never returns.
14:42:38 <EvanR> wait... how would 'exitImmediately' possibly return anything
14:42:53 <EvanR> and still live up to what it says on the tin
14:43:52 <Ivan__1> sm[m]: when I was experimenting few months ago I managed to narrow memory grow to `readJournal` function, I thought I found a reason for this at the time, but now I doubt I was correct... 
14:45:37 <hpc> EvanR: obviously it would return if it exited or not
14:46:32 <EvanR> ah makes sense
14:48:36 <iqubic> Is there a library which gives me access to a sorted list data type?
14:49:32 <iqubic> Wherein the elements stored have an Ord instance and every insertion added the new element into place such that the new list is still sorted?
14:50:43 <iqubic> Moreover, I specifically don't want this to be a set. I want to allow duplicates.
14:52:07 <dmj`> Data.Seq ?
14:52:13 <merijn> iqubic: "Set with duplicates" is just "Map with a count for each key", no?
14:53:57 <Axman6> insertWith (+) k 1
14:55:02 <EvanR> iqubic: Map k Int
14:55:10 <EvanR> oh merijn said that
14:55:26 <Axman6> a.h.a histogram
14:55:48 <EvanR> use the total map package and make the default number 0
14:55:59 <iqubic> EvanR: Does that work?
14:56:03 <EvanR> total map has the benefit of not dealing with Maybes
14:56:13 <EvanR> also you can compose them
14:56:14 <iqubic> What is a total map?
14:56:25 <EvanR> a map where all the keys have a value
14:56:30 <ammar2> every key has a value
14:56:40 <merijn> EvanR: findWithDefault means no Maybe's either :p
14:56:40 <iqubic> I see. That seems like something I want.
14:57:12 <EvanR> yeah but... my abstractions!
14:58:36 <dmj`> "If you could change one thing about the Haskell community, what would it be?"
14:58:39 <dmj`> clone SPJ
14:58:52 <iqubic> How easy is it to convert code from using Data.Map.Strict to using a total map?
14:59:47 <EvanR> i think the API is largely the same, but simpler
15:00:09 <iqubic> Also, do I want "total-map" or "TotalMap"?
15:00:25 <EvanR> or do what merijn was saying
15:00:44 <EvanR> total-map probably
15:01:15 <EvanR> wow it has almost no API nevermind :)
15:02:28 <iqubic> The API of total-map isn't on Hackage.
15:03:55 <iqubic> But yeah, also, I don't want that. Instead I'm going to use a Mp k Int to work with this.
15:04:04 <iqubic> s/Mp/map/
15:04:45 <EvanR> well
15:06:09 <iqubic> well what?
15:06:11 <EvanR> i recommend a look eventually. Also this should exist (Ord a, Ord b) => TMap b c -> TMap a b -> TMap a c
15:06:36 <iqubic> I can't find any of the documentation for TMap.
15:06:51 <iqubic> Really, what I want is a sorted set with duplicates.
15:07:35 <electricityZZZZ> dmj`: so you're saying that haskell is like the zombo.com of programming languages, it sounds like
15:08:00 <EvanR> iqubic: Map k Int
15:08:37 <EvanR> iqubic: to see docs for hackages, use haddock on the downloaded package
15:08:38 <iqubic> I'll use that.
15:08:43 <dmj`> electricityZZZZ: yes
15:17:23 <electricityZZZZ> i just tried installing arrayfire with stack and it didn't work, not even slightly,...
15:18:42 * hackage http-io-streams 0.1.1.0 - HTTP client based on io-streams  https://hackage.haskell.org/package/http-io-streams-0.1.1.0 (HerbertValerioRiedel)
15:31:22 <Axman6> electricityZZZZ: if you're wondering why no is offering to help, it's becasue "didn't work" doesn't tell us anything
15:32:11 * hackage prometheus 2.1.3 - Prometheus Haskell Client  https://hackage.haskell.org/package/prometheus-2.1.3 (wraithm)
15:32:28 <electricityZZZZ> ok ill paste an error after one moment...
15:35:20 <iqubic> zygomorphism confuse me.
15:35:42 <electricityZZZZ> unknown package: arrayfire
15:35:56 <electricityZZZZ> current stack version 2.1.3
15:36:23 <electricityZZZZ> https://hackage.haskell.org/package/arrayfire
15:36:32 <Axman6> stack update
15:36:55 <electricityZZZZ> ok i assumed that upgrading would update the package list :-P
15:42:07 <Axman6> did that help?
15:43:16 <electricityZZZZ> fiddling with stack ghci and stack exec ghci lead me to fail to import ArrayFire so i have built a project folder. even if i say stack build, it refuses to run stack exec test-arrayfire on my brand new unaltered stack new project
15:44:40 <iqubic> I wish I knew what zygomorphisms were.
15:45:51 <Axman6> electricityZZZZ: is test-arrayfire an execurable or a test?
15:47:07 <electricityZZZZ> i said stack new test-arrayfire, cd test-arrayfire, stack setup, stack build, stack exec test-arrayfire and it's refusing to run. "test-arrayfire" the literal is a name, unless stack is inheriting some kind of behavior from the project name, which imo is a nono
15:47:34 <Axman6> what does the cabal file say the executable's name is
15:47:41 <evelyn> In cabal, there's the extra-source-files section. If I add something there, where does that actually go? 
15:48:40 <electricityZZZZ> name: test-arrayfire
15:48:41 <evelyn> I have a directory contrib/font.ttf. If I load contrib/font.ttf in my code (the program is run at top of the repository), is it still exposed when installing the program with cabal?
15:48:48 <jackdk> evelyn: into the result of `cabal sdist`: https://www.haskell.org/cabal/users-guide/developing-packages.html#pkg-field-extra-source-files
15:49:06 <evelyn> ooh, oke!
15:49:09 <evelyn> thanks!
15:49:30 <sm[m]> Ivan__1: thanks for looking at hledger memory use. There is one issue where I looked into it, I can dig it up if you want. Happy to work on this with you in #hledger if you try again
15:49:37 <Axman6> electricityZZZZ: can you paste the cabal file somewhere
15:49:43 <electricityZZZZ> yeah one sec
15:49:57 <Axman6> stack tends to give executabl;es dumb names like test-arrayfire-exe
15:50:45 <electricityZZZZ> "tends to"? wtf?
15:51:00 <sm[m]> electricityZZZZ: I mainly build FOSS apps with haskell, such as the hledger accounting program
15:51:47 <electricityZZZZ> https://paste.rs/BPW
15:52:09 <Axman6> executable test-arrayfire-exe
15:52:18 <Axman6> stack exec test-arrayfire-exe
15:52:32 <electricityZZZZ> yeah, i see that now. that's pretty lame, but ok
15:52:41 <electricityZZZZ> the documentation for stack is wrong
15:52:59 <Axman6> They take PRs
15:53:16 <electricityZZZZ> i dont like posting stuff
15:53:19 <sm[m]> stack's docs have unfortunately been just "good enough" for a while now
15:53:23 <EvanR> heh
15:53:47 <electricityZZZZ> oops, the documentation isn't wrong, it just doesn't point out the -exe ending on the name,... that's technically my bad
15:53:55 <Axman6> "I have found an error. I can fix it. But I won't" :P
15:54:25 <electricityZZZZ> the dependency list doesn't have a version number...?
15:56:44 <sm[m]> electricityZZZZ: version bounds in build-depends are optional. Some are highly preferred.. which ones exactly is sometimes a debate
15:57:31 <electricityZZZZ> imo it should be mandatory but i am going to see how far i can take this
15:58:22 <sm[m]> it's your package, put them in :thumbsup:
15:59:10 <electricityZZZZ> i added - arrayfire and it can't find the damn package
15:59:11 * hackage predicate-typed 0.4.0.0 - Predicates, Refinement types and Dsl  https://hackage.haskell.org/package/predicate-typed-0.4.0.0 (gbwey)
15:59:42 <electricityZZZZ> ack nevermind
16:02:06 <electricityZZZZ> ...extra-deps?
16:02:12 <electricityZZZZ> why would i redundantly specify my dependency
16:02:53 <Axman6> if it's not on hackage then it will need to be an extra dep - stack will have told youy what to put in the extra-deps section
16:03:48 <electricityZZZZ> there is a long snippet including sha256 chars ending in ,4248  ... am i supposed to include this comma?
16:04:02 <Axman6> yes
16:04:08 <Axman6> and the - at the beginning
16:04:18 <sm[m]> it looks redundant, but it's not. build-depends specifies what your project requires in a general sense. When using stack, extra-deps specifies which versions of things that aren't in your specified stackage snapshot to pick
16:04:42 <electricityZZZZ> extra-deps:\n- arrayfire-0.5.0.0@sha256:(ugly),4248             right?
16:04:46 <Axman6> stack works of snapshots of package versions. if a package is not in ther snapshot you need to explicitly include specific version of it
16:05:09 <sm[m]> I never include those long hashes after the version number, that's for total reproducibility in the face of hackage revisions I think
16:05:19 <evelyn> Specific version + hash because there can be changes between versions of certain things which affect reproducibility
16:05:24 <evelyn> agh beaten to it
16:05:45 <evelyn> I never did understand what said changes were but it makes stack happy to do it properly
16:05:56 <Axman6> hackage revisions
16:06:21 <Axman6> which can be used to broaden the bounds of a package's deps post facto
16:06:45 <electricityZZZZ> i mean actually i think the hash is a good idea
16:06:49 <Axman6> ex post facto? who knows...
16:07:24 <electricityZZZZ> it's telling me invalid dependency arrayire-0.5.0.0
16:07:29 <electricityZZZZ> arrayfire-0.5.0.0
16:07:38 * electricityZZZZ is not on a macbook
16:08:34 <Axman6> paste the error you're getting
16:08:38 <sm[m]> electricityZZZZ: you might need to do a "stack update" 
16:08:40 <sm[m]> to see the latest stuff on hackage
16:09:17 <electricityZZZZ> still invalid... packaage.yaml: Error while parsing $dependencies[1] - invalid dependency "arrayfire-0.5.0.0"
16:09:47 <Axman6> paste the stack yaml
16:10:03 <Axman6> if you eant help you need to provide information -_-
16:10:17 <sm[m]> no! paste the package.yaml!
16:10:24 <Axman6> uh, that one
16:10:26 <sm[m]> 8-) 
16:10:27 <electricityZZZZ> it's just what i posted above with extra-deps:\n- arrayfire-0.5.0.0@sha256:(ugly),4248
16:10:28 <Axman6> both?
16:10:43 <sm[m]> get rid of the @ and the rest
16:10:53 <sm[m]> simplify, simplify
16:11:06 <electricityZZZZ> dependencies:\n-base >= 4.7 && < 5\n-arrayfire-0.5.0.0
16:11:23 <sm[m]> also extra-deps doesn't go in package.yaml, it goes in stack.yaml - right ?
16:11:29 <Axman6> yes
16:11:52 <electricityZZZZ> ok i killed @ And everything which followed, and ran stack update because stack can't figure that out,... same problem
16:12:30 <sm[m]> paste stack.yaml to Axman6 , package.yaml to me, store the .cabal file in a secure place, and we'll negotiate for information :)
16:12:38 <Axman6> ok, I'm going to stop helping now, it's like trying to ride a bike with no lights
16:12:43 <koz_> If I have 'newtype Foo a = Foo { unFoo :: Bar (SomeTypeFam a) Int }, what role would GHC assign to the 'a' type variable?
16:12:58 <electricityZZZZ> im on my laptop need to sign in from another machine, hold on :-P
16:13:04 <sm[m]> sorry, just having fun. I know getting started with haskell packaging is a bit of a pain
16:14:20 <electricityZZZZ> stack.yaml: https://paste.rs/PF5
16:14:47 <electricityZZZZ> package.yaml: https://paste.rs/yyb
16:15:22 <Axman6> - arrayfire-0.5.0.0 isn't valid in the dependencies in the package .yaml afaik
16:15:53 <sm[m]> why not Axman6 ?
16:15:59 <electricityZZZZ> so,... don't specify the version number? what's the fix?
16:16:31 <Axman6> I assume if you want it to be a specific versin it should be - arrayfire = 0.5.0.0 or... something else. just make it - arrayfire >= 0.5.0.0 && < 0.6
16:16:37 <sm[m]> ohh.. yes in this file it's cabal bounds syntax ? should be arrayfire ==0.5.0.0 ?
16:17:42 <electricityZZZZ> ok, thanks,... it's weird that i can't specify a specific version as an atom but ok
16:19:48 <sm[m]> it is, slightly. Despite the common suffix stack.yaml and package.yaml have different syntax, package.yaml's from the cabal world
16:19:55 <djanatyn> megaparsec is very fun, but it is surprisingly easy to summon oom-killer when i get "creative" with my parsers
16:20:29 <EvanR> memory was made to be eaten!
16:20:38 <Guest_72> Hello how can I download Haskell on my Mac plEASE
16:20:40 <sm[m]> with how much ram ?
16:20:53 <Guest_72> Wait is this some sort of chat room
16:21:04 <evelyn> this is a court room
16:21:09 <Guest_72> lool
16:21:41 <Guest_72> can the court give advice on how I can download Haskell on to Mac please
16:21:58 <Axman6> Guest_72: read https://www.haskell.org/downloads/
16:22:04 <sm[m]> haskell for mac from the app store, or https://docs.haskellstack.org/en/stable/README/#how-to-install
16:22:10 <iqubic> Gosh, this is starting to get hard. I'm using recursion-schemes and what I want is a stateful paramorphism.
16:23:01 <Guest_72> I saw these I just don't get how to run this
16:23:27 <Axman6> how to run what
16:23:34 <electricityZZZZ> heyy ok arrayfire ran yay thanks guys let me see if i can compute something
16:23:42 <Guest_72> are you guys from the uk or have I missed the convo were everyone introduced themselves 
16:23:53 <Axman6> electricityZZZZ: get your canny edge detection on
16:24:09 <electricityZZZZ> axman6: haha nah i have something more fun than that to do ;)
16:24:37 <Axman6> Guest_72: this is IRC, we're from all over the world, and this channel has been going non-stop for well over a decade
16:24:46 <sm[m]> Guest_72: you may want https://docs.haskellstack.org/en/stable/install_and_upgrade/#manual-download_1 . After download your browser may uncompress it for you, then you can run it
16:24:53 <sm[m]> in Terminal
16:26:24 <Guest_72> thankss
16:28:12 <sm[m]> if you want to get going faster and don't mind spending a few pounds, Haskell For Mac is excellent
16:30:07 <Axman6> Agreed, and Manuel the author is fantastic
16:30:42 <iqubic> So, I really wish I knew how to make paramorphism with my own state.
16:30:58 <iqubic> I guess I'll do this without fancy recursion schemes first.
16:32:55 <Axman6> electricityZZZZ: what're you going to do? I should play with arrayfire sometime
16:33:41 * hackage ip2location 8.2.0 - IP2Location Haskell package for IP geolocation.  https://hackage.haskell.org/package/ip2location-8.2.0 (ip2location)
16:33:55 <sm[m]> making a hs-arrayfire ?
16:36:26 <electricityZZZZ> i have a little known fractal that i like to render,... my goal was (1) to simply render it and then (2) see if i can make the rendering fast (i've done this before) (3) implement this exact same thing in rust, and then maybe (4) see about performing some calculations to spread out the computation of the fractal
16:40:14 <djanatyn> sm[m]: only 8GB on this machine (and i turned off swap, oops)
16:40:20 <sm[m]> sounds interesting!
16:40:45 <electricityZZZZ> bah it doesn't list CUDA as an available backend on my machine, that might be a dealbreaker :/
16:40:52 <sm[m]> djanatyn: wow.. I haven't experienced that kind of blowup with megaparsec
16:41:27 <shachaf> hi djanatyn. hanatyn.
16:41:50 <Axman6> electricityZZZZ: OpenCL?
16:41:56 <djanatyn> pAddressLine :: Parser T.Text; pAddressLine = do; skipMany space; T.pack <$> (dbg "addressLine") (some alphaNumChar)
16:42:05 <djanatyn> i didn't expect this to be useful but i did learn something writing it
16:42:06 <electricityZZZZ> yeah openCL is listed but ive had bad experiences with openCL
16:42:10 <djanatyn> shachaf: howdy :)
16:43:35 <electricityZZZZ> do i need to do weird stuff to make cuda work or is this arrayfire's fault
16:44:52 <electricityZZZZ> okay i'm running stack install cuda,... 
16:45:33 <Axman6> do you have cude installed?
16:45:37 <Axman6> cuda*
16:45:40 <electricityZZZZ> works with rust-arrayfire
16:45:43 <sm[m]> you must be doing something very "creative", djanatyn 
16:45:54 <Axman6> Apple hasn't used nVidia GPUs for quite a while
16:46:13 <electricityZZZZ> apple probably will be vertically integrating as far as they can go
16:49:21 <Axman6> do you have an nvidia GPU?
16:50:11 <electricityZZZZ> yeah, i'm not *that* dumb ;_) looks like it is complaining that it can't find the device, im going to do some sanity checks on my cuda install
16:54:07 <koz_> If I have 'newtype Foo a = Foo { unFoo :: Bar (SomeTypeFam a) Int }, what role would GHC assign to the 'a' type variable?
16:55:24 <Axman6> use :info in ghci maybe?
16:58:06 <koz_> I could, but I'd rather have someone tell me what the algorithm GHC uses would decide, so I'd have an understanding in all cases like this in the future.
16:58:37 <koz_> (and why).
16:59:38 <electricityZZZZ> okay i am trying to stack install cuda https://paste.rs/DQi
17:00:59 <jle`> koz_: i'd think it would be nominal, because Foo Int and Foo (Identity Int) could have different underlying representations
17:01:34 <koz_> jle`: That is also my suspicion. From my understanding of the algorithm GHC uses, once tyfams touch _anything_, it nominalizes by default for exactly this reason.
17:02:50 <jle`> i don't know too much about the algorithm that GHC uses, i'm just saying that following from what i see about the type declaration
17:03:48 <jle`> since the representation of Foo can be different even if 'a' is a newtype-wrapped version of a type
17:04:21 <koz_> Yeah, makes sense. Thanks!
17:04:30 <jle`> for example if type family SomeTypeFam a where SomeTypeFam Int = Bool; SomeTypeFam (Identity Int) = String, then you have different results for Int vs. Identity Int
17:04:42 <jle`> although actually i suppose it depends on what Bar's type parameters are
17:05:00 <jle`> i as assuming Bar's first type parameter is representational or nominal
17:05:02 <electricityZZZZ> stack install cuda complains cuda> /tmp/stack3823/cuda-0.10.1.0/.stack-work/dist/x86_64-linux/Cabal-2.4.0.1/build/libHScuda-0.10.1.0-6maTeRHjM0fI9oA9w7O7Sk.a(stubs.o):stubs.c:function cuStreamBeginCapture: error: undefined reference to 'cuStreamBeginCapture_v2'     cuda> collect2: error: ld returned 1 exit status
17:05:05 <jle`> but if it's phantom then 'a' should be phantom as well
17:05:19 <koz_> jle`: Nominal.
17:05:24 <electricityZZZZ> also relevant: cuda> /tmp/stack3823/cuda-0.10.1.0/.stack-work/dist/x86_64-linux/Cabal-2.4.0.1/build/libHScuda-0.10.1.0-6maTeRHjM0fI9oA9w7O7Sk.a(Device.o):s1tiV_info: error: undefined reference to 'cuDeviceGetUuid'
17:05:38 <jle`> if Bar's first parameter is phantom than 'a' cannot affect the runtime representation of Foo
17:05:48 <jle`> s/than/then
17:06:22 <jle`> Foo X, Foo Y, and Foo Z would all have the same runtime rep
17:06:30 <jle`> if Bar is phantom in its first parameter
17:06:48 <jle`> so you would be able to unsafeCoerce between all of them 'safely'
17:07:59 <koz_> Lol.
17:08:07 <koz_> notSoUnsafeCoerce :P
17:17:58 <wroathe> I've got some FFI code that's printf'ing a data structure for debugging. It seems like the FILE * buffering is entirely separate from Haskell's stdout buffering. Is there a straightforward way to fix this?
17:18:20 <wroathe> hFlush doesn't seem to flush the printf'd buffer
17:20:02 <electricityZZZZ> okay so am i a fool for trying to use cuda+arrayfire+haskell? i suppose i could use accelerate instead
17:21:28 <electricityZZZZ> "Accelerate tends to stress GHC's garbage collector, so it helps to increase the default GC allocation sizes. This can be done when running an executable by specifying RTS options on the command line" heh
17:21:28 <shachaf> wroathe: Write to stderr?
17:22:18 <shachaf> Or fflush(stdout); instead of hFlush stdout.
17:25:57 <wroathe> shachaf: I'll give that a shot
17:26:04 <sm[m]> electricityZZZZ: that error sounds like a mismatch between haskell cuda and C cuda versions, are you sure you have a C cuda the haskell cuda was tested with
17:26:49 <sm[m]> seems like you do, then I would search/raise it at https://github.com/tmcdonell/cuda
17:27:01 <sm[m]> ... /issues
17:27:34 <electricityZZZZ> i... dont... like...posting,....
17:28:37 <sm[m]> haha that is a problem
17:28:45 <sm[m]> just search then :)
17:33:44 <sm[m]> I note there are three "10.1" versions on the nvidia site
17:33:58 <electricityZZZZ> i hate computers
17:35:02 <electricityZZZZ> im using the one for ubuntu 16.04
17:35:18 <electricityZZZZ> but okay maybe i need update 2...? you think it's that sensitive?
17:35:29 <sm[m]> I saw an update1 and update2 (for mac). I don't know if it's relevant
17:35:37 <sm[m]> the release notes scared me
17:35:48 <reallymemorable> I wrote this script from a tutorial: https://gist.github.com/reallymemorable/3b974073cb1fee3209410988acc3b3d1
17:35:59 <reallymemorable> and queried it like this: curl -H "Content-Type: application/json" -d '{"timestamp": "thattesteset", "value": 1 }' localhost:8080/lights
17:36:10 <reallymemorable> But now I have it up on an ubuntu EC2, where I ran stack build.  How would I query it now?
17:36:33 <electricityZZZZ> proceeding to download 89GB of drivers for fortnite...
17:37:42 <sm[m]> hey there reallymemorable . You'd replace localhost with your server's IP address, hopefully
17:38:03 <reallymemorable> got it
17:38:07 <reallymemorable> and i guess in line 53 as well
17:40:53 <sm[m]> congrats
17:47:57 <dmj`> electricityZZZZ: you're no fool for using arrayfire-haskell, you might just be a genius
17:54:33 <electricityZZZZ> dmj`: lol i take it you work there
17:54:53 <jusss> https://paste.ubuntu.com/p/P35JhHSg8s/
17:55:01 <dmj`> electricityZZZZ: nah, I just took initiative to write some bridge glue code
17:55:11 <wejetheman> hi guys. im trying to figure out how to use this "ViewPatterns" thingy, but im doing something wrong. http://codepad.org/LrCuLlEH
17:55:14 <jusss> there's an error about postgresql with persistent
17:55:16 <electricityZZZZ> dmj`: ok, biased then ;)
17:55:38 <jusss> but it didn't show more details about the error
17:58:02 <dmj`> electricityZZZZ: heavily, but who isn't cmon'
17:58:12 <jusss> I can't find out the value about data Pool a from http://hackage.haskell.org/package/resource-pool-0.2.3.2/docs/Data-Pool.html#t:Pool
17:58:14 <dmj`> wejetheman: that looks right to me
17:58:28 <jle`> wejetheman: maybe are you using a really really really old vesion of ghc
17:58:43 <jusss> oh, I found it...
17:59:50 <wejetheman> 8.0.2
17:59:57 <jle`> wejetheman: ViewPatterns was introduced in GHC 6.10
17:59:59 <jle`> ah, hm
18:00:21 <wejetheman> didnt work in that code pad thingy either 
18:01:14 <wejetheman> oh wait its working in emacs, just not the codepad, i guess the problem is just with them
18:01:27 <jle`> it seems to run on my system
18:01:40 <jle`> wget http://codepad.org/LrCuLlEH/raw.hs && runghc raw.hs
18:02:24 <electricityZZZZ> ok guys installing arrayfire-3.6.4 gave me a CUDA option
18:02:46 <wejetheman> welp sorry for dumb question but thanks for the assist none the less
18:03:09 <jle`> ah this seems to be the problem 
18:03:11 <jle`> http://codepad.org/N7LuRQER
18:03:15 <jle`> codepad isn't running ghc, but hugs
18:03:46 <jle`> and the last release of hugs was 13 years ago
18:04:18 <dmj`> electricityZZZZ: that's fantastic to hear
18:04:31 <dmj`> electricityZZZZ: can you paste what it looks like? I've never seen that option, only OpenCL
18:04:44 <dmj`> wejetheman: coderpad is just anemic when it comes to extensions I bet
18:05:15 <electricityZZZZ> stack exec test-arrayfire-exe [CPU,CUDA,OpenCL]
18:06:02 <jle`> and yeah, the problem is that hugs doesn't support -XViewPatterns
18:06:14 <jle`> afaik only GHC does
18:06:52 <jle`> tracing back the history, -XViewPatterns was added to GHC in 2008 (about 11 years ago), two years after hugs died
18:07:40 <jle`> so poor codepad never stood a chance
18:07:55 <dsal> codepad is hugs?
18:08:01 <dsal> I remember hugs.
18:08:04 <jle`> indeed, from what we found earlier http://codepad.org/N7LuRQER
18:08:42 <dmj`> electricityZZZZ: can you call this function "info" http://hackage.haskell.org/package/arrayfire-0.5.0.0/docs/ArrayFire-Device.html#v:info
18:09:39 <djanatyn> i have written a proper megaparsec parser and i am very pleased with myself. the debug output for megaparsec is extremely useful
18:09:49 <jle`> djanatyn: congrats :)
18:09:53 <djanatyn> in fact i would say i am feeling quite satisfied
18:10:06 <jle`> megaparsec pun?
18:10:18 <djanatyn> jle`: definitely
18:10:28 <koz_> jle`: What's the pun?
18:10:50 <electricityZZZZ> wow that's hilarious. it ran when i changed the library without rebuilding, but now it refuses to build.
18:11:05 <jle`> `satisfy` is one of the more fundamental parser combinator primitives
18:11:14 <koz_> jle`: Oh lol.
18:11:15 <electricityZZZZ> it's looking for lib but there's only lib64... do i just symlink to lib64, or do i specify lib64 somewhere...?
18:14:33 <reallymemorable> When I use this library: http://hackage.haskell.org/package/persistent-sqlite
18:14:38 <reallymemorable> where is the db itself living?
18:15:02 <reallymemorable> i understand how to post data to it
18:15:23 <reallymemorable> but i dont understand how to find the “address” of where it’s all stored
18:15:39 <electricityZZZZ> ok after symlinking from lib to lib64, A.info gives: ArrayFire v3.6.4 (OpenCL, 64-bit Linux, build 1b8030c) [0] NVIDIA: GeForce GTX 1060 6GB, 6069 MB ()
18:19:33 <djanatyn> reallymemorable: you have to define it before you initiate a connection: http://hackage.haskell.org/package/persistent-sqlite-2.10.5/docs/Database-Persist-Sqlite.html#t:SqliteConnectionInfo
18:20:16 <dmj`> electricityZZZZ: that's wild
18:20:39 <dmj`> electricityZZZZ: embedded DSLs FTW
18:20:46 <reallymemorable> djanatyn: I wrote this script: https://gist.github.com/reallymemorable/3b974073cb1fee3209410988acc3b3d1
18:21:12 <reallymemorable> does that mean it lives in the function called `app`?
18:37:10 <sm[m]> oh neat, another haskell-running paste site (codepad). wejetheman what about http://repl.it instead
18:38:57 <sm[m]> reallymemorable: see the createSqlitePool "api.db" line, that means the db is in ./api.db
18:40:09 <reallymemorable> so if the address was localhost:8080/lights
18:40:22 <reallymemorable> the db lives at localhost:8080/lights/api.db?
18:40:47 <sm[m]> ah, no. The sqlite db is not exposed to the web, only your http web app is
18:41:06 <reallymemorable> but if i wanted to query data out of it
18:41:14 <reallymemorable> i would have to issue a GET to my API?
18:41:27 <sm[m]> the db is in the api.db file in the current directory where you run the web app on the server. You have to do it through the web app, yup
18:41:38 <sm[m]> or, ssh into that machine
18:41:47 <reallymemorable> right
18:41:47 <sm[m]> and use sqlite on the command line
18:41:58 <reallymemorable> i have one thing that streams data into the DB
18:42:06 <reallymemorable> and another program that i want to read data out of
18:42:08 <reallymemorable> to use as inputs
18:42:22 <reallymemorable> so i will just write a GET function in that second program
18:44:08 <djanatyn> reallymemorable: i was also surprised that the Text field in createSqlitePool isn't documented as the name of the database, but it is as sm[m] pointed out: http://hackage.haskell.org/package/persistent-sqlite-2.10.5/docs/src/Database.Persist.Sqlite.html#createSqlitePool
18:45:47 <sm[m]> electricityZZZZ: congrats!
18:46:27 <Axman6> reallymemorable: sqlite doesn't have a server, it's a library for interacting with sqlite databases on disk
18:46:58 <reallymemorable> is that a characteristic of sqlite in general?
18:47:03 <reallymemorable> is that what makes it "lite"
18:48:05 <jle`> the 'lite' is lightweight, as in it's a small application
18:48:08 <Axman6> yes
18:48:14 <Axman6> go and read sqlite.org
18:48:39 <Axman6> sqlite doesn't replace Oracle or PostgreSQL, it replaces fopen
18:48:54 <jle`> i like to read a yaml file into memory
18:49:06 <sm[m]> can't multiple programs interact with a single sqlite db ?
18:49:31 <Axman6> it's generally not a good idea
18:49:45 <jle`> an sqlite db is just a binary file that sqlite knows how to 'read' at a given location to get the data it needs
18:49:49 <Axman6> I think it can be done but it's best to have one app control the db
18:50:12 <reallymemorable> so as long as my POSTs and GETs happen throuogh my API
18:50:15 <reallymemorable> i will be fine
18:50:15 <sm[m]> the FAQ says it works
18:50:46 <jle`> i think reads should be ok, since it's basically like "oh i need item #3 of table #2, that means i have to start reading at byte 2890"
18:50:47 <sm[m]> yup
18:51:12 <sm[m]> "SQLite allows multiple processes to have the database file open at once, and for multiple processes to read the database at once. When any process wants to write, it must lock the entire database file for the duration of its update. But that normally only takes a few milliseconds." .. just sayin
18:56:56 <electricityZZZZ> ok don't laugh: https://paste.rs/ktn.hs
18:58:56 <dmj`> electricityZZZZ: instead of this "x1 <- 0.5*x + 0.866025404*y" try "let x1 = 0.5*x + 0.866025404*y"
18:59:21 <dmj`> electricityZZZZ: if you see it expects IO, use <-, if not, use let x = ... 
19:01:26 <electricityZZZZ> shouldn't haskell be able to deduce whatever type of assignment i need...? heh
19:01:36 <Axman6> no
19:01:44 <Axman6> it's not magic, there are rules
19:02:57 <dmj`> electricityZZZZ: its telling you what it expects, but it won't write the code for you.... yet
19:03:03 <Axman6> they're not different types of assignment, they have very different meanings
19:05:03 <jusss> I copy the last section code from persistent of its web doc, but I get this error, Debug SQL, what's wrong with persistent and pgsql? https://paste.ubuntu.com/p/MPf4Y6hzhG/  
19:12:42 <sm[m]> jusss: it looks like it's working, just logging some debug information
19:12:51 <dmwit> electricityZZZZ: Yes, in principle it is possible. But it doesn't do that in its current form.
19:13:44 <dmwit> And from my experimentation, adding that feature mostly just leads to ambiguous type errors writ large.
19:14:33 <wejetheman> im trying to learn how to use the Text type and its really slow going. the biggest problem is I cant find many resources on searches like everything else so far. any advice on how to check to see if all of the values inside of a Text are numeric? i would have just done "all isNumber string" with a string but anyway...
19:15:12 <dmwit> wejetheman: http://hackage.haskell.org/package/text-1.2.4.0/docs/Data-Text.html#v:all ?
19:15:48 <dmj`> :t Data.Text.all Data.Char.isNumber
19:15:50 <lambdabot> Data.Text.Internal.Text -> Bool
19:16:03 <wejetheman> ive looked at that about 500 times by now since its about all i can find with a search
19:16:15 <electricityZZZZ> dmj`: okay, generating a const array of dimension 1000 filled with ones?
19:16:19 <dmwit> The text folks spent a ton of effort making the API mirror []'s API.
19:16:35 <dmj`> electricityZZZZ: that's good
19:16:36 <wejetheman> Okay let me look at Data.Text.Internal
19:16:40 <dmwit> wejetheman: what no
19:16:45 <dmwit> wejetheman: Look at the link I gave you.
19:16:57 <Axman6> you shouldn't need .Internal unless you know what you're doing
19:17:06 <dmj`> electricityZZZZ: enter the matrix
19:17:07 <Axman6> yeah look at dmwit's link
19:17:22 <sm[m]> wejetheman: assume that many of the functions you'd use on a String can be imported from Data.Text. You have to do a qualified import, like you'll see in the examples.
19:18:20 <electricityZZZZ> dmj`: no i mean i mnot understanding how to generate a constant array of dimension 1000 filled with a specific value
19:18:50 <dmj`>  electricityZZZZ: let array = constant @Double [1000] 33.33
19:18:51 <electricityZZZZ> mkArray Float [1000] [1.0] ?
19:18:55 * sm[m] thinks reading all of http://hackage.haskell.org/package/text/docs/Data-Text.html is the thing to do
19:19:08 <dmj`> electricityZZZZ: that will fail at runtime
19:19:11 <Axman6> wejetheman: that response is like saying "My car radio's broken, I better replace the engine"
19:19:16 <electricityZZZZ> what is the significance of specifying constant?
19:19:35 <dmj`> electricityZZZZ: constant is in the ArrayFire.Data module, this has functions related to populating arrays, things like tiling, etc.
19:20:12 <dmj`> electricityZZZZ: so constant populates a scalar, vector, matrix, cube or tensor with a specified value
19:20:57 <dmj`> electricityZZZZ: the list is the dimensions, if omitted its filled with ones and only allows a single scalar value
19:21:17 <wejetheman> i thought i had tried "T.all isNumber (T.pack "1234")" already but i only tried something that i thought was equivalent and it isn't
19:21:21 <dmj`> electricityZZZZ: [3] means a vector of size 3, [3,3] means a 3x3 square matrix w/ 9 values, etc.
19:21:53 <dmj`> electricityZZZZ: the lists you supply are the columns in the matrix, since arrayfire is internally in column-major order
19:22:20 <wejetheman> i was trying to pattern match with view pattern like this "test (T.all isNumber -> True) = "matched""
19:22:57 <sm[m]> fancy!
19:23:27 <electricityZZZZ> dmj`: it seems like i can't use a Float constant...?
19:24:21 <jle`> wejetheman: btw matching on True is probably better done as a guard
19:24:29 <jle`> test x
19:24:33 <jle`>   | T.all isNumber x = "matched"
19:24:37 <jle`>   | otherwise = "sorry"
19:24:38 <wejetheman> i would except i cant nest guards
19:24:53 <wejetheman> i was going to do some matching here and some guards for further conditions 
19:25:04 <jle`> why can't you nest guards?
19:25:19 <wejetheman> i thought it was impossible 
19:25:41 <electricityZZZZ> let const_1       = constant @Float [1000] 1.0 complains Cannot apply expression of type ‘t1’
19:25:41 <electricityZZZZ>       to a visible type argument ‘Float’
19:26:09 <dmwit> wejetheman: What have you tried that didn't work? Better start there.
19:26:22 <dmj`> electricityZZZZ: is TypeApplications enabled ?
19:26:42 <jle`> that sort of error sometimes comes up when 'constant' is not imported
19:26:42 <dmj`> electricityZZZZ: want to run something wild ? 
19:26:54 <electricityZZZZ> dmj`: running haskell is running something wild.
19:27:18 <dmj`> electricityZZZZ: try this script https://gist.github.com/dmjio/c7eca65cccf93787886643a40a6b89bc
19:27:45 <electricityZZZZ> this had better not send you all my bitcoins
19:27:45 <wejetheman> well first i just wanted to match on text the way i do on strings i.e. f ('a':_) = "this Text starts with an a" but that didnt work for me
19:28:23 <dmj`> electricityZZZZ: scouts honor
19:28:34 <electricityZZZZ> jk i dont have any bitcoins ;)
19:29:27 <sm[m]> Lol nice try dmj
19:29:46 <wejetheman> so i went to guards http://codepad.org/Za7BAw4P but im going to end up piling on arbitrary additonal conditions to make it pass the tests for the exercise
19:30:09 <dmwit> electricityZZZZ: Joke's on you. Since you don't have any bitcoins, the snippet *does* send him all your bitcoins.
19:30:18 <wejetheman> i thought some simple matching would help abstract out a lot of useful stuff so i learned about ViewPattern as a way to pattern match Text
19:30:42 <wejetheman> since this kind of stuff wasnt working  f ('a':_) =
19:30:44 <sm[m]> wejetheman: as you see Text is sometimes a pain for simple stuff.
19:31:10 <wejetheman> using text is part of the exercise
19:33:10 <electricityZZZZ> free(): invalid size Aborted
19:33:22 <electricityZZZZ> but it does show up for a split second
19:34:38 <dmj`> sm[m]: caught me red-handed
19:34:53 <dmj`> dmwit: shhhh :) don't give it away
19:35:04 <electricityZZZZ> dmj`: https://paste.rs/fRI.hs   if you are curious
19:35:08 <dmj`> electricityZZZZ: what version of arrayfire-haskell are you using?
19:35:15 <electricityZZZZ> 0.5.0.0
19:35:41 <dmj`> can you just do stack build ?
19:35:43 <electricityZZZZ> assuming that npm didn't decide to change my yarn version number and install the previous docker kubernetes 
19:36:00 <electricityZZZZ> stack build says nothing, which i assume means everything is okay
19:36:20 <dmj`> electricityZZZZ: do 'stack exec -- ghc-pkg list arrayfire'
19:36:58 <electricityZZZZ> https://paste.rs/Y8h          i could just give you root on my machine if you want
19:37:04 <electricityZZZZ> then you can find out what's wrong
19:37:22 <dmj`> electricityZZZZ: that's a very generous offer
19:37:32 <sm[m]> and get the bitcoins
19:37:38 <dmj`> sm[m]: ugh, you gave it away
19:37:59 <dmj`> :)
19:38:10 <dmj`> electricityZZZZ: we can probably do this w/o root
19:38:13 <sm[m]> Damn must be cool, be cool sm
19:38:13 <dmj`> electricityZZZZ: are you on linux ?
19:38:43 <Axman6> electricityZZZZ: does stack exec main work? that one of the executables installed by arrayfire
19:39:28 <Axman6> that's*
19:39:35 <dmj`> electricityZZZZ: I know what the problem is, I think. I have a double free in there, that is a bug. I fixed it in this commit 7a5b6b7e40ff12374359fcf0d740a063237eb910
19:39:37 <dmwit> dmj`: If I don't give it away, can I get half the bitcoins?
19:39:39 <electricityZZZZ> wut stack exec main works but draws an empty black window
19:39:42 <dmj`> electricityZZZZ: you'll have to tell stack to fetch at that commit
19:39:50 <dmj`> dmwit: I'd definitely go 50-50 w/ you
19:39:54 <Axman6> electricityZZZZ: it was red for me
19:40:03 <Axman6> what is A.Cell? what are the -1's?
19:40:24 <electricityZZZZ> could this have anything to do with the fact that my "main" method is named someFunc rather than main?
19:40:31 <Digit> one of these days, i'm gonna refactor my fatherjackbot.hs.    there.  i've said it in #haskell, so now i'm committed to it.
19:40:47 <Axman6> electricityZZZZ: how are you running this?
19:40:47 <electricityZZZZ> dmj`: you can pm me how to do that stack fetch
19:40:51 <electricityZZZZ> stack
19:40:52 <dmj`> Axman6: that is the default value for an internal struct that ArrayFire uses. It has a public C++ API that abstracts over the af_cell struct w/ this grid abstraction.
19:42:06 <dmj`> electricityZZZZ: put this in your stack.yaml
19:42:10 <dmj`> electricityZZZZ: https://gist.github.com/981c1ba7d0e1d020082755f4fc34ac18
19:42:20 <electricityZZZZ> so like doesn't JPL say recursion is satan unless it has a finite bound, and furthermore all infinite data structures are satan?
19:42:57 <dmj`> Axman6: (-1) (-1) just tells ArrayFire that it should fill the screen with this visualization
19:43:11 <electricityZZZZ> dmj`: sorry i dont understand how to merge that with my stack.yaml
19:43:20 <dmj`> electricityZZZZ: can you paste your stack.yaml
19:43:28 <heatsink> JPL develops software for quite unusual and demanding situations
19:43:53 <dmj`> electricityZZZZ: if you don't already have a packages section, you can put this top-level
19:44:15 <electricityZZZZ> dmj`: https://paste.rs/NrZ
19:44:29 <electricityZZZZ> i may need to come to terms with the fact that i am not a programmer
19:44:50 <heatsink> JPL does have a publicly available coding guide that prohibits recursion.  That's probably what you have in mind
19:45:19 <dmj`> electricityZZZZ: ah, so that is a different file, that is the .cabal file, is there a stack.yaml file ?
19:45:24 <electricityZZZZ> heatsink: yeah i think they allow a couple of steps of recursion or soemthing
19:45:42 <electricityZZZZ> dmj`: my bad
19:45:56 <electricityZZZZ> dmj`: ok you want me to just throw that onto the bottom?
19:46:23 <electricityZZZZ> dmj`: nvm just spotted packages
19:47:37 <electricityZZZZ> dmj`: ok nvm https://paste.rs/tMu  it's barfing
19:48:17 <dmj`> electricityZZZZ: maybe try removing the last two lines
19:48:41 <electricityZZZZ> the commit and the extra-dep: true?
19:48:53 <dmj`> just this part
19:48:55 <dmj`> extra-deps:
19:48:56 <dmj`> - arrayfire-0.5.0.0
19:49:03 <dmj`> I think that tells it to fetch from hackage
19:49:06 <dmj`> but I'm not a stack user
19:49:30 <electricityZZZZ> Error in $.packages[1]: failed to parse field 'packages': expected Text, encountered Object 
19:49:42 <dmj`> oh man
19:50:09 <dmj`> I could just release 0.6
19:50:19 <electricityZZZZ> well if 0.5 is broken :-P
19:50:27 <electricityZZZZ> or 0.5.1 would be fine :-P
19:50:50 <sm[m]> maybe for bitcoins ?
19:51:42 <sm[m]> when do we get to see a fractal
19:51:54 <electricityZZZZ> sm[m]: want to help me with that?
19:52:23 <electricityZZZZ> let const_1       = constant @Float [1000] 1.0          was barfing
19:52:36 <dmj`> sm[m]: it's coming, its coming
19:52:52 <electricityZZZZ> Cannot apply expression of type ‘t1’ to a visible type argument ‘Float’
19:52:59 <sm[m]> I’ve maxed out my fun hacking time for today, but I’m helping from the armchair
19:53:47 <electricityZZZZ> btw rust compiles pretty quickly these days
19:55:36 <dmj`> electricityZZZZ: I'll push 0.5.1.0 
19:55:41 <dmj`> and it should work
19:55:52 <electricityZZZZ> dmj`: ok so ill run a stack update and try to remember how my files were before
19:55:59 <dmj`> electricityZZZZ: that type error is because TypeApplications isn't around
19:56:15 <dmj`> electricityZZZZ: you'll need to update your stack file to what it was before, except have arrayfire-0.5.1.0
19:57:01 <electricityZZZZ> dmj`: yep im on it
19:57:20 <electricityZZZZ> so uh, if this is haskell, how can there be a double free
19:58:06 <sm[m]> It’s frankenhaskell
19:59:42 * hackage arrayfire 0.5.1.0 - Haskell bindings to the ArrayFire general-purpose GPU library  https://hackage.haskell.org/package/arrayfire-0.5.1.0 (DavidJohnson)
20:00:09 <electricityZZZZ> and it seems weird that your main "event loop" is recursive when event loops are uh, loops
20:00:36 <electricityZZZZ> seems like it would be hard to limit the potential for memory leaks, especially if you are GC'ed
20:01:45 <electricityZZZZ> ok well i waited a little but, ran stack update, and it can't find arrayfire-0.5.1.0 on Hackage
20:01:56 <chew2> hello, I have a monad stack with type solve :: (Monad m) => MaybeT (StateT MyState (WriterT [Int] m)) (). I was using MaybeT for early failure but I wanted the Maybe to wrap the [Int] instead of the (), is there a good way to do this? Basically the writer log is what I'm interested in returning and I want it wrapped in Maybe
20:02:06 <electricityZZZZ> is this like DNS propagation where i have to wait
20:04:42 <electricityZZZZ> ok there now it's going
20:05:55 <electricityZZZZ> dmj`: yay it's a wavy thing
20:06:04 <dmj`> electricityZZZZ: it worked ?!
20:06:08 <dmj`> electricityZZZZ: nice :)
20:06:09 <electricityZZZZ> and there are lots of rando GC pauses, yeah
20:06:15 <dmj`> electricityZZZZ: is this 0.5.1.0
20:06:27 <dmj`> electricityZZZZ: run it again with +RTS -s
20:06:31 <dmj`> electricityZZZZ: it shouldn't use any GC
20:07:11 <dmj`> electricityZZZZ: that's great you see a wavy thing though
20:07:56 <electricityZZZZ> less pause-y but there are still pauses
20:08:42 <dmj`> electricityZZZZ: just in the beginning? That's how it is for me
20:08:49 <dmj`> electricityZZZZ: here I put it on youtube https://www.youtube.com/watch?v=9f9jX3sYUcs
20:08:58 <dmj`> this is what mine looks like
20:09:05 <electricityZZZZ> i like how it jiggles, but no it has pauses even though i am looking at more than a dozen of these wave things
20:09:24 <dmj`> electricityZZZZ: do you like my moon desktop background ?
20:10:12 * hackage profunctor-arrows 0.0.0.1 - Profunctor arrows  https://hackage.haskell.org/package/profunctor-arrows-0.0.0.1 (cmk)
20:11:01 <electricityZZZZ> yeah that youtube video isn't terribly pause-y.. my cycle time seems to be quite a bit slower
20:11:18 <electricityZZZZ> oh yeah mine definitely has substantial pauses
20:11:21 <dmj`> electricityZZZZ: hmmm
20:11:37 <dmj`> electricityZZZZ: it might not be GC, but just the math
20:11:54 <electricityZZZZ> well host device memcpy and allocation and whatnot
20:12:29 <electricityZZZZ> but um that had me wondering about a topic i was going to try to get to after i had successfully allocated a constant array (which i am still failing at)
20:12:52 <dmj`> electricityZZZZ:  did you add the {-# LANGUAGE TypeApplications #-} extension ?
20:12:59 <dmj`> electricityZZZZ: that example works for me
20:13:24 <electricityZZZZ> i think i had TypeApplications enabled but i will check.
20:14:22 <electricityZZZZ> like i said this pukes: let const_1       = constant @Float [1000] 1.0
20:15:39 <slack1256> @unmtl MaybeT (StateT String (WriterT [Int] m)) ()
20:15:39 <lambdabot> String -> m (Maybe (), String, [Int])
20:16:16 <electricityZZZZ> dmj`: it complains Cannot apply expression of type ‘t1’to a visible type argument ‘Float’
20:16:42 <dmj`> @electricityZZZZ  print $ constant @Float [10] 3.33
20:16:42 <lambdabot> Unknown command, try @list
20:16:55 <dmj`> electricityZZZZ: works on my machine
20:17:31 <dmj`> electricityZZZZ: your exact example works for me as well
20:17:42 <slack1256> chew2: You can have the [Int] when runnning/delayering the monad. You can convert it to a `Maybe [Int]` via pure/return.
20:18:22 <slack1256> chew2: But you haven't actually explined what you want to do. Your monad layers seems weird without knowing what you want to accomplish.
20:18:27 <electricityZZZZ> dmj`: ugh i had to use A.constant, the error message was misleading because something else must be defining constant
20:18:31 <dmj`> electricityZZZZ: https://gist.github.com/03c42ed237725f0d8efd6b8751ad40b8
20:18:36 <dmj`> oh...
20:18:41 * hackage pine 0.1.0.2 - Functional 2D Game Framework  https://hackage.haskell.org/package/pine-0.1.0.2 (Grinshpon)
20:18:57 <slack1256> chew2: For example, maybe what you want is "Optional logging"? Is that what you meant by wrapping the [Int] on a Maybe?
20:19:43 <slack1256> chew2: Otherwise you could "log" to the Writer layer values of type `Maybe [Int`
20:19:58 <chew2> ok understood. Basically it's for an algorithm problem and I'm incrementally building up a list (writerT) but there may not be an answer at the end so I want that log to be wrapped in maybe
20:20:32 <chew2> I considered changing the log type to Maybe [int] but I wasn't sure if it's the best approach. It seems like it wouldn't be as elegant
20:21:06 <slack1256> You could define a `Data MyVal = OKVal Int | NotGood
20:21:27 <chew2> so basically the issue is that in what I'm doing the real return type is the log itself, which seems to not be the typical use case for writer I think
20:21:27 <slack1256> Then layer with a monad `Writer MyVal ()`
20:21:47 <chew2> does that get me early exit still? I wouldn't want to continue the computation if there's a NotGood
20:22:44 <slack1256> Oh I see.
20:24:06 <chew2> tbh I might just need a fold or something instead of writer
20:25:23 <slack1256> I mean, you could do it a lot of ways. Sure you can compose a Writer and a MaybeT to get the early exit behaviour.
20:25:37 <slack1256> But maybe something like ListT (the list monad transformer) is what you want.
20:25:42 <electricityZZZZ> ugh just made a mistake because haskell allowed me to shadow a variable. shadowing is bad
20:26:55 <chew2> but I can't wrap the writerT log in maybeT, right?
20:27:04 <chew2> I can only wrap the writerT return type
20:30:48 <electricityZZZZ> dmj`: okay will things are working nicely. now i have 4 arrays, one of which is random uniform values between 0 and 1 floats, and i want to create a fifth array whose values come from the three arrays, depending elementwise on the random one whether each value is in a certain range. i don't quite remember the arrayfire operator for this but i think it exists
20:31:00 <LysergicDreams> electricityZZZZ: Compile with -Wall or -Wname-shadowing
20:31:45 <slack1256> chew2: Yeah, the outer layers only can "add" effects without interfering with the others belows. In that sense is composable.
20:32:46 <chew2> ok cool thanks! I think I'll give it another try with foldM and no WriterT
20:34:01 <slack1256> chew2: I already tried and "MaybeT (Writer [Int]) ()" does what you want (it seems).
20:35:59 <slack1256> > runWriter $ runMaybeT (lift (tell ([5] :: [Int])) >> lift (tell [9]) >> fail "gato" >> return "animal")
20:36:00 <lambdabot>  error:
20:36:00 <lambdabot>      Variable not in scope: runMaybeT :: t0 m0 [Char] -> Writer w a
20:36:14 <slack1256> Well that return "animal")
20:36:19 <slack1256> "animal")
20:36:44 <slack1256> Well that return (Nothing,[5,9]), which exhibits the early exit behaviour you want.
20:37:02 <slack1256> To know if the "log" is valid, you actually have to check if the result value is a "Just" or a "Nothing".
20:39:11 <dmj`> electricityZZZZ: you're exploring new territory, keep pushing further, onwards and upwards soldier
20:41:01 <dsal> Is there a convenient way to limit concurrency with mapConcurrently_ ?
20:41:51 <chew2> ohh and I could do first >> second to check
20:41:54 <Axman6> QSem
20:44:09 <Axman6> @hoogle QSem
20:44:09 <lambdabot> module Control.Concurrent.QSem
20:44:09 <lambdabot> Control.Concurrent.QSem data QSem
20:44:09 <lambdabot> Control.Concurrent.QSem.Lifted data QSem
20:49:11 * hackage numhask-space 0.3.0 - numerical spaces  https://hackage.haskell.org/package/numhask-space-0.3.0 (tonyday567)
20:55:11 * hackage tmp-postgres 1.9.0.2 - Start and stop a temporary postgres  https://hackage.haskell.org/package/tmp-postgres-1.9.0.2 (JonathanFischoff)
20:59:41 <dmj`> is there a lexer / parser for the R programming language ?
20:59:44 <dmj`> in Haskell
21:00:00 <Axman6> there's language-r, so maybe?
21:01:54 <dmj`> #package language-r
21:02:00 <dmj`> @package language-r
21:02:00 <lambdabot> http://hackage.haskell.org/package/language-r
21:02:12 <dmj`> package not found ;_;
21:04:39 <jluttine> why isn't Map an instance of Profunctor? isn't it contravariant in its key?
21:05:27 <Axman6> can you write f :: (a -> b) -> Map b c -> Map a c?
21:06:09 <jluttine> Axman6: as far as i understand yes.. just preprocess the key
21:06:32 <Axman6> give it a go
21:06:58 <Axman6> take note of the order of the a's and b'a in that signature
21:07:44 <Axman6> @djinn (a -> b) -> Maybe (b, c) -> Maybe (a,c)
21:07:44 <lambdabot> f _ _ = Nothing
21:08:22 <jluttine> Axman6: yep. the function preprocesses the key.. what am i missing.. i see Map as contravariant in its keys and covariant in its values
21:09:04 <Axman6> write the function with that type then, and show the it is contravariant in its key
21:09:12 <Axman6> that it is*
21:11:36 <iqubic> So, I have two maps from Data.Map. I want to combine them into one new map. But when the same key appears in both maps, I want to apply a binary function on the old values to compute the new value.
21:11:47 <Axman6> what _is_ a profunctor is functions of type a -> Maybe b (a.k.a Kleisli Maybe a b), which is what a map represents, but I'm not sure you can actually say that a map is contravariant in its key. it's definitely covariant in its key though
21:12:18 <Axman6> iqubic: read the docs, that's explicitly a function (or several) that exists
21:12:23 <iqubic> So something like comibine :: (a -> a -> a) -> Map k a -> Map k a -> Map k a
21:12:41 <Axman6> there might even be a whole module dedicated to those merges, go and look
21:12:51 <iqubic> Oh, that's unionWith. heh.
21:13:52 <iqubic> Also, Data.Map.Merge.Strict exists.
21:14:12 <iqubic> As does a Lazy version. But I only need a strict version here.
21:14:44 <nshepperd> unionWith (<>) is what the monoid instance for Map should have been. but alas
21:14:51 <iqubic> However Data.Map.Merge is way more tools then I need.
21:15:03 <iqubic> I'm just going to use unionWith.
21:15:06 <jackdk> YES! RISE UP! GIVE ME MONOIDAL MAPS OR GIVE ME DEATH!
21:15:26 <jackdk> Axman6: I am seriously considering releasing a package of different ways to combine filterable semialigns
21:16:26 <Axman6> do it, you won't
21:16:50 <MarcelineVQ> jackdk: you can't just make up words and think people won't notice
21:17:21 <iqubic> what does the Monoid instance of Map look like?
21:18:09 * Axman6 releases a package with floggable senpailines
21:18:10 <MarcelineVQ> It's good to be curious but that's a really easy one considering you just had the docs open. there's a link to source to the right of definitions
21:18:11 <nshepperd> iqubic: unionWith const
21:18:18 <jackdk> Axman6: https://github.com/qfpl/semialign-diff/blob/17c73b9c0b969c2c9a3a12753967e2589f837c37/semialign-merge/src/Data/Semialign/Merge.hs
21:18:21 <iqubic> I see
21:18:28 <iqubic> That's kinda pointless.
21:18:53 <jackdk> yeah, especially since you could recover that behavior with Map k (Maybe (Last a))
21:19:14 <jackdk> Axman6: though given how tiny these packages are, I might roll them both into a semialign-extras instead (depending on filterable pulls in lens transitively anyway)
21:20:09 <nshepperd> the secret to how 'lookup :: Ord k => k -> Map k v -> Maybe v' works even though Map is covariant in k is the Ord k constraint
21:21:35 <nshepperd> so really, what a map represents is 'Ord k => k -> Maybe v' or, when you combine the Ord k and the k, '(k -> Ordering) -> Maybe v'
21:22:22 <shachaf> I don't think I'd really call Map covariant in k.
21:22:39 <shachaf> I guess you have mapKeys.
21:22:51 <c_wraith> why wouldn't you?
21:23:27 <shachaf> Well, it's not a Functor instance in k. And it represents the thing nshepperd said.
21:23:31 <Axman6> covariantish
21:23:58 <jackdk> if you get key collisions `mapKeys f . mapKeys g` might not be the same as `mapKeys (f . g)`, so you couldn't make a Bifunctor instance, say
21:24:02 <c_wraith> oh.  I totally misread
21:24:22 <jackdk> maybe "covariant" but not "functorial" in `k`?
21:24:23 <nshepperd> it's covariant, but not a Functor
21:24:24 <c_wraith> I thought contravariant in k.  That's how I'd describe it.
21:24:45 <shachaf> I'd say that Map k a is morally contravariant in k.
21:24:52 <nshepperd> (as long as you don't feel like making a functor instance that makes an illegal Map)
21:24:59 <shachaf> I don't know what covariant means here if not a functor?
21:25:28 <jackdk> you can define `mapKeys` but not `contramapKeys`
21:25:32 <jackdk> I guess?
21:25:49 <c_wraith> Or at least I'd say that Map k v has the same meaning as k -> Maybe v, which means it should be a profunctor, except for details.
21:26:00 <nshepperd> the constraint on mapKeys is only required to maintain the invariants that make a Map legal
21:26:30 <shachaf> I would say the same things that c_wraith is saying.
21:26:44 <shachaf> But now I'm thinking about it a little more and I'm not so sure.
21:27:00 <nshepperd> a Map k v is basically just a fancy list of (k, v)
21:27:02 <shachaf> Set is contravariant by the same argument. But arguably it represents the covariant powerset functor.
21:28:47 <jle`> jackdk: you could recover that behavior with Map k (Last a)
21:28:55 <dmj`> Axman6: is language-r package a conspiracy
21:28:58 <jle`> jackdk: since M.unionWith (<>) only requires Semigroup
21:29:36 <jackdk> jle`: ah
21:29:43 <Axman6> yes
21:29:56 <nshepperd> (note that Map k () is interconvertible with Set k)
21:30:41 <shachaf> That's what I was intending to note.
21:38:13 <jle`> Map k v is a (univalent) relation on K and V
21:38:44 <dmj`> Axman6: I feared as much
21:39:04 <dmj`> has anyone here used iserv-proxy to cross-compile anything to ARM?
21:39:51 <jle`> i believe it's the morphisms in a subcategory of Rel
21:42:11 <jle`> so you cooouuuld call Map a profunctor in the subcategory of Rel with only univalent morphisms
21:43:13 <jle`> s/in/from
21:43:16 <nshepperd> different view: dimensional analysis. lookup :: (Ord k, k, Map k v) -> Maybe v takes items of dimension (k^-2, k, k^n v) and produces result of dimension v. so obviously n = 1
21:47:03 <jle`> nshepperd: ah yeah that does make lookup become an argument for (k,v) instead of for k -> v
21:50:04 <ammar2> what are some good introductory resources on category theory?
21:50:13 <ammar2> especially from a functional/programming standpoint
21:50:43 <jle`> ammar2: how about bartosz milewski's series
21:52:34 <nshepperd> Ord k being just 'compare :: k -> k -> Ordering', which is like... a metric on k, which lets you take inner products of covectors of k
21:53:14 <nshepperd> that is the weird vector-geometry based intuition i have anyway ;)
21:58:33 <jle`> treating map as a profunctor and as also a morphism in Rel we can write dimap :: (Ord a, Ord b, Ord c) => Map c a -> Map a b -> Map c d
21:59:51 <jle`> er. Map c a -> Map b d -> Map a b -> Map c d
22:03:50 <nshepperd> nice
22:04:32 <nshepperd> though you can't write any law about dimap id id since id doesn't exist
22:07:24 <jle`> hm, i guess this only works for sets that are enumerable
22:07:39 <jle`> id = M.fromList $ join zip universe universe
22:08:26 <jle`> but actually this is the case for all objects in Rel, that we can construct this map
22:09:13 <shachaf> Why would Map be an arrow in Rel? Rel is self-dual.
22:09:32 <jle`> the subcategory of Rel where the morphisms are univalent
22:10:39 <jle`> Rel if we exclude morphisms that are not univalent, essentially. id still exists and composition is closed i believe
22:11:19 <jle`> but i guess this isn't super-useful in Haskell because we can't model it since we can't generate id
22:12:44 <iqubic> I just realized that Dependent types are going to be a pain in the butt to work with when they land in Haskell.
22:14:00 <dmj`> long live haskell98
22:14:02 <iqubic> I just realized that all the stuff I've been doing for the past few days is basically theorem proving. I've been trying to teach my computer that (Add (Lit x) (Lit y)) is semantically the same as (Add (Lit y) (Lit x)) and it's a pain.
22:14:47 <jle`> you only have to really prove the theorems you care about being true
22:15:34 <iqubic> Yeah. But even that can be a pain in the butt.
22:15:42 * hackage network-messagepack-rpc 0.1.2.0 - MessagePack RPC  https://hackage.haskell.org/package/network-messagepack-rpc-0.1.2.0 (igrep)
22:15:50 <jle`> my point is that if it's too much of a pain to be worth it, you can skip it
22:15:57 <jle`> so you only ever take on the pain you want to
22:16:07 <heatsink> To prove associativity of + in general, you need structural induction.  Does Haskell have that at the type level?
22:16:34 <jle`> yes
22:19:57 <iqubic> It does? How so?
22:20:01 <nshepperd> I wonder what will happen. probably everyone won't immediately upgrade all their library APIs to be dependently typed
22:20:49 <iqubic> No. Probably not.
22:33:19 <dsal> Axman6: I got distracted after asking a question you answered.  I was able to use QSem to throw together a mapConcurrentlyLimited_ :: Foldable f => Int -> (a -> IO b) -> f a -> IO ()
22:48:30 <mjrosenb> class Monad m => MonadState s (m :: * -> *) | m -> s where --- it looks like this class wants instances to be monad transformers.  I'm guessing I can't easily implement this for a Monad which isn't a transformer?
22:49:07 <dminuoso> mjrosenb: Why do you think it needs instances to be monad transformers?
22:50:22 <jle`> mjrosenb: actually it only wants instances that are monads
22:50:23 <shachaf> mjrosenb: m is a monad, not a transformer. It has a kind * -> *.
22:50:25 <mjrosenb> what would m be for (State s a)?
22:50:27 <jle`> mjrosenb: monad transformers are not allowed to be instances
22:50:34 <shachaf> m would be State s
22:50:35 <dminuoso> mjrosenb: (State s)
22:51:02 <jle`> so actually it is impossible to write an instance of MonadState for any monad transformer, which goes against what seems to be your initial intuition
22:51:13 <mjrosenb> interesting...
22:51:19 <jle`> mjrosenb: the major hint would be seeing that m is constrained to be a Monad
22:51:30 <mjrosenb> true.
22:51:36 <dminuoso> mjrosenb: The declaration says the following 1. `Monad` is a superclass of `MonadState`. 2. MonadState takes two parameters (MPTC). 3. m is of kind * -> *. 3. There is a functional dependency such that m uniquely determines s.
22:51:39 <mjrosenb> perhaps I am too tired to be doing this right now.
22:51:54 <jle`> also remember monads and transformers are different 'kinds' of things
22:51:54 <dminuoso> Err that was wrongly phrased.
22:52:01 <dminuoso> *s is uniquely determined by m.
22:52:17 <jle`> so "i can't implement this for a Monad which isn't a transformer" is like saying "i can't implement this for a Monoid that isn't a Functor"
22:54:40 <mjrosenb> I guess the other thing that is confusing me is all of the instances listed in the docs: https://hackage.haskell.org/package/adjunctions-4.4/docs/Control-Monad-Representable-State.html
22:55:07 <mjrosenb> m is the monad argument, but the instance is a transformer being applied to that monad.
22:55:39 <jle`> yes, transformers take monads and return new ones
22:55:39 <dminuoso> mjrosenb: Think of a monad transformer as a type level construct taking a monad and returning a new monad, while giving it the flavor of a third.
22:55:53 <jle`> so it's sort of like seeing:
22:55:58 <jle`> instance Monoid m => Monoid (Maybe m)
22:56:10 <dminuoso> mjrosenb: So `StateT s` basically takes a monad, and adds "stateful" behavior to it, returning a new one. That means that `StateT s` applied to some monad gives you a stateful monad back
22:56:15 <jle`> m is the monoid argument and the instance is Maybe applied to m
22:56:34 <jle`> in a way, Maybe is a "monoid transformer" in this light
22:56:56 <jle`> the real instance we have is instance Semigroup m => Semigroup (Maybe m), so Maybe here is a 'semigroup transformer'
22:57:05 <jle`> it takes a semigroup and returns a new semigroup
22:57:13 <dminuoso> Ah thinking about the wrong instances, heh. :)
22:57:48 <dminuoso> mjrosenb: So some instances basically just lift the MonadState through transformer layers, like:  MonadState s m => MonadState s (ListT m)
22:57:50 <jle`> so `instance MonadState s m => MonadState s (MaybeT m)` is the same sort of thing as `instance Semigroup m => Semigroup (Maybe m)`
22:58:13 <dminuoso> mjrosenb: Which basically says "Hey if you transform something that already satisfies MonadState with ListT, its still a MonadState"
22:58:54 <dminuoso> mjrosenb:  Monad m => MonadState s (StateT s m) -- in the sense of transformer stacks could be thought as a base case in that regard.
23:01:53 <mjrosenb> hrm, the obvious thing isn't working, but that's probably something or other with the "| m -> s"?
23:02:02 <dminuoso> mjrosenb: What are you doing exactly?
23:02:20 <dminuoso> mjrosenb: And what error are you getting?
23:02:20 <mjrosenb> instance MonadState s (XState w s) where
23:03:07 <dminuoso> mjrosenb: And what error are you getting?
23:03:08 <mjrosenb> https://gist.github.com/mjrosenb/092a0d80dd92394db2b1bf778d8f35bd -- error
23:03:21 <dminuoso> Oops.
23:03:24 <dminuoso> mjrosenb: Enable the extension GHC has suggested.
23:04:11 <mjrosenb> I am not sure why that is necessary here.
23:04:31 <mjrosenb> is it necessary for all of the other instances from the adjunctions package?
23:04:41 <dminuoso> "All instance types must be of the form (T a1 ... an) where a1 ... an are *distinct type variables*"
23:05:03 <jle`> mjrosenb: the reason is pretty silly but it's just that the haskell standard is very very restrictive on what is allowed as an instance
23:05:14 <jle`> for example you can't write an instance of Show (MyType Int)
23:05:20 <jle`> only Show (MyType a)
23:05:42 <jle`> FlexibleInstances pretty much allows for instances as we would normally expect them
23:05:47 <dminuoso> mjrosenb: Essentially whenever you use MultiParamTypeClasses you almost always have to always use FlexibleInstances and FlexibleContexts.
23:05:57 <jle`> GHC hides it behind an extension because it isn't a part of the strict haskell standard
23:06:09 <dminuoso> (The latter one in usage sites, the former one in instance definition sites)
23:06:29 <dminuoso> These instances are perfectly fine and safe.
23:06:35 <dminuoso> *These extensions
23:07:01 <mjrosenb> well, it seems to have compiled.
23:07:19 <mjrosenb> I'll find out if it works in a week or so when I finish fixing the rest of these type errors
23:07:20 <jle`> mjrosenb: is your question "Why does my instance not follow the rules of distinct type variables?", or is your question "Why is distinct type variables required by the Haskell Report spec?"
23:08:56 <mjrosenb> jle`: I see the 's' duplicated in my instance, I'm kind of curious why it is there... Is it just there so it knowns the type of the stored state no matter what monad has implemented the interface?
23:09:01 <jle`> 'why that is necessary here' has two layers of meaning, potentially: it can mean that you don't understand the restriction, or it can mean that you understand the restriction but do not understand the motivation behind the restriction being in place
23:09:32 <mjrosenb> why the s is there as an argument to MonadState
23:09:35 <jle`> mjrosenb: ah, do you know what the arguments of MonadState mean semantically?
23:09:41 <mjrosenb> not at all.
23:09:44 <jle`> `MonadState s m` means that 'm' supports having a state of type 's'
23:10:07 <jle`> meaning you have a function modify :: (s -> s) -> m (), and get :: m s
23:10:28 <jle`> so writing MonadState Int MyMonad means that MyMonad supports working with a state of type Int
23:10:43 <jle`> `instance MonadState String MyOtherMonad` means that `MyOtherMonad` has an underlying state of type String
23:11:11 <jle`> `instance MonadState s (XState w s)` means that `XState w s` has an underlying state of type s
23:12:42 <mjrosenb> ok, that's more or less what I thought. This means I can have XState s w, and not worry about needing my state type to be in the correct place.
23:12:46 <jle`> so if i had `XState String Int`, it would be an instance of `MonadState Int`   --- you'd have `MonadState Int (XState String Int)`
23:13:25 <jle`> not sure what you mean by 'place'
23:13:27 <mjrosenb> although if it were "place", then it would need to be (XState w), and the MonadState would need to give it the type
23:13:56 <jle`> right, in general the state type might not even be in the monad type
23:14:03 <jle`> like in the case of `instance MonadState Int MyMonad`
23:14:13 <dminuoso> mjrosenb: That limits you to having only a single state type though. :)
23:14:52 <jle`> if it helps, i like to think of (MonadState s) as a typeclass constraint, partially applied like that
23:15:03 <jle`> so i read instance MonadState Int MyMonad as (MonadState Int) MyMonad
23:15:21 <jle`> an instance of `MonadState Int` has a state of type Int.  an instance of `MonadState Double` has a state of type Double
23:15:51 <mjrosenb> ahh, and m -> s is actually (XState w s -> s), which is very reasonable... I was thinking (XState w -> s), which is distinctly less reasnable.
23:16:00 <dminuoso> mjrosenb: No.
23:16:28 <jle`> mjrosenb: i think you get the right point. it means that from (XState w s), you can guess what 's' is
23:16:32 <dminuoso> mjrosenb: `m -> s` means m uniquely determines s.
23:16:55 <jle`> mjrosenb: you're trying to say that you realize that the m is `XState w s`, and not `XState w`
23:17:03 <mjrosenb> right, and here m = XState w s
23:17:05 <mjrosenb> yes, that.
23:17:15 <jusss> how to let yesod know if values in postgresql are changed?
23:17:32 <jusss> and let yesod update the page with new values?
23:17:54 <jle`> mjrosenb: in practice usually when you use a MonadState instance, the 's' won't even show up in the type of the monad, so this is the nice way to have it i think
23:18:10 <jle`> mjrosenb: in your case s is actually in XState w s, so it's sort of a degenerate/rarer case
23:19:07 <dminuoso> jle`: Oh hah you and I parsed that statement regarding -> very differently.
23:19:26 <jle`> dminuoso: i parsed it the same as you but i was trying to figure out the original intent heh
23:21:17 <mjrosenb> yes, as previously mentioned, I am quite tired, and am not very good at english at the best of times.
23:21:39 <jusss> or I needn't
23:21:43 <mjrosenb> anyhow, I am going to go to sleep and hopefully not forget everything.
23:21:54 <jle`> mjrosenb: have a good night :)
23:22:34 <dminuoso> jusss: You'd have to use websockets to communicate with the frontend and then implement that refreshing logic in some manner there.
23:23:30 <dminuoso> jusss: Though detecting changes in the database in general is rather tricky. You'd rather have the actor triggering the change communicate that with your yesod app/your frontend.
23:27:25 <jusss> dminuoso: I have a question,  every visit will trigger to run getHomeR ? if read sql values action is in getHomeR, then if values in sql are changed, the page will changed?
23:29:02 <jusss> write sql trigger is a better way?
23:29:53 <dminuoso> jusss: No. Relying on SQL triggers has several issues. 
23:30:08 <dminuoso> jusss: Just have the actor of that change communicate with yesod/frontend.
23:31:12 <jusss> dminuoso: what's the term `actor' here?
23:32:07 <dminuoso> jusss: The actor is the part that is responsible for the change in the database.
23:42:00 <jusss> dminuoso: what's the form of the actor? a single program out of yesod?
23:42:12 * hackage kafka-client-sync 0.1.1.0 - Synchronous Kafka Client  https://hackage.haskell.org/package/kafka-client-sync-0.1.1.0 (felixmulder)
23:42:22 <jusss> check the database in a loop?
23:42:32 <jusss> based on events?
23:42:34 <dminuoso> 08:16:52    jusss | how to let yesod know if values in postgresql are changed?
23:42:39 <dminuoso> jusss: What causes the values to change?
23:43:25 <jusss> dminuoso: it may be the database admin changed the database
23:43:35 <dminuoso> jusss: Dont manipulate the database
23:43:50 <dminuoso> jusss: Expose some interface within your yesod app, such that yesod can be aware of it.
23:43:59 <dminuoso> Manually fiddling around in databases is your biggest problem
23:44:00 <jusss> dminuoso: or like you said it's changed by the front page
23:45:00 <jusss> dminuoso: how to expose interfaces within yesod app? does yesod provide that function?
