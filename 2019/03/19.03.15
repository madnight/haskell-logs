00:15:47 <Kenran_> Hi, I'm in the following situation: I have a stack project Foo which depends on a remote repository which is also a (huge, and not ours) stack project. For various reasons I need to switch to cabal-new in my project Foo. The remote dependency cannot be built by cabal-new (at least not without significant changes that I cannot make). Does anyone have guidance on what I could try to make this work somehow?
00:21:45 <Kenran_> E.g., is there a way to build the dependency with stack, and then "install" it locally to reference that from my cabal project?
00:29:07 * hackage hs-server-starter 0.1.0.2 - Write a server supporting Server::Starter's protocol in Haskell  https://hackage.haskell.org/package/hs-server-starter-0.1.0.2 (hiratara)
00:44:03 <Heffalump> Kenran_: if you can get stack to install in the global package DB it might work, but it sounds quite messy
00:44:27 <Heffalump> how is it possible to have a project that only builds with stack? It's all .cabal files and dependencies under the hood
00:50:38 <Kenran_> Heffalump: I'm still trying to get it to run and it should be possible, but I get problems specifically with cabal new-build. It contains lots of autogenerated code.
00:51:04 <Kenran_> It's https://github.com/tensorflow/haskell to be specific.
00:54:25 <wz1000> is there anything weaker than Foldable with fold :: CommutativeMonoid m => f m -> m
00:54:32 <Kenran_> And (if that was not clear already :)) I'm relatively new to Haskell and its ecosystem, so I might just fail because I don't know better. I simply tried the switch from stack to cabal in my project and included the remote dependency accordingly and it failed. It seems to use cabal new-build to try and build tensorflow-haskell, and that does not work, at least not out of the box. Maybe it's possible to build TF with cabal v1 and then
00:54:54 <Kenran_> Looks like I'd have to do that manually as well though.
01:01:22 <sclv> Kenran_: looks like the issue is that the stack yaml isn’t just for one package but a collection, so with cabal you’d need to depend on all of them
01:01:57 <sclv> which shouldn’t be hard :-)
01:09:37 * hackage string-random 0.1.2.0 - A library for generating random string from a regular experession  https://hackage.haskell.org/package/string-random-0.1.2.0 (hiratara)
01:10:37 * hackage quickcheck-string-random 0.1.2.0 - Helper to build generators with Text.StringRandom  https://hackage.haskell.org/package/quickcheck-string-random-0.1.2.0 (hiratara)
01:25:06 * hackage reqcatcher 0.1.2.0 - A local http server to catch the HTTP redirect  https://hackage.haskell.org/package/reqcatcher-0.1.2.0 (hiratara)
01:33:41 <Kenran_> sclv: I'm not sure I understand that solution. For now, I created a cabal.project file (used a tool for that and manually checked) which seems to do exactly that - namely depend on the subdirs in the stack.yaml. My problem is that the build (with cabal) fails nevertheless. I then cloned tensorflow-haskell and tried (converting and) building that with cabal which also fails. cabal new-build has some issues with the .cabal files in th
01:34:07 <Kenran_> file does not work with cabal new-build at all.
01:34:20 <Kenran_> (in one of the subdirs of tensorflow).
01:35:31 <Kenran_> I'd love it if I could just get it to work without doing anything in tensorflow itself, that is, I'll check the first proposed solution (however hacky) to use stack to install tensorflow globally (it's inside a docker container anyway) and then try to reference that in my project.
01:43:01 <mpickering> Is there a way to combine `Lens s (f a) -> Iso a b -> Lens s (f b)`
01:46:54 <kelperhelper> !
01:48:53 <kelperhelper> any of you guys keen on blockchain topics & debates? eg PoW vs PoS - Kadena thats based on Haskell is doing an AMA on this topic next wednesday with Multicoin. Would be awesome to get input from the haskell dev community! 
01:49:03 <kelperhelper> (proof) https://twitter.com/kadena_io/status/1104102013355335680
02:10:36 * hackage language-docker 8.0.1 - Dockerfile parser, pretty-printer and embedded DSL  https://hackage.haskell.org/package/language-docker-8.0.1 (lorenzo)
02:27:07 * hackage serverless-haskell 0.8.6 - Deploying Haskell code onto AWS Lambda using Serverless  https://hackage.haskell.org/package/serverless-haskell-0.8.6 (AlexeyKotlyarov)
02:58:39 <zincy> Is the `a` a type constructor or a type variable? instance (Show a) => Show (MyType a) where  
02:59:38 <zincy> And am I write in saying that if the above is valid then the reason leaving out the a wouldn't be valid as in - instance Show (MyType) where 
03:00:19 <zincy> would be because MyType by itself has the kind * -> * and you can only instantiate a type class for types of kind *
03:03:32 <lyxia> you can only instantiate Show with types of kind *
03:03:50 <lyxia> % :k Show
03:03:50 <yahb> lyxia: Show :: * -> Constraint
03:03:56 <lyxia> % :k Functor
03:03:56 <yahb> lyxia: Functor :: (* -> *) -> Constraint
03:04:24 <lyxia> a is a type variable
03:05:46 <lyxia> As opposed to other things, variables are meant to be substituted. So that instance tells you things like  (Show Int => Show (MyType Int)), (Show [Bool] => Show (MyType [Bool]))
03:09:48 <zincy> Ah thanks
03:10:47 <zincy> So are multi parameter type classes ones that work on (* -> * -> Constraint)
03:11:24 <lyxia> that's one of their possible kinds yes
03:12:07 <zincy> And then functional dependencies are used to specify which type variable determines the type variable of the return type of typeclass methods?
03:12:54 <lyxia> there's no requirement on where the variables appear in typeclass methods.
03:13:25 <lyxia> you can make any variable depend on any other variables
03:13:42 <zincy> So if I define a MPTC for say (Maybe a) and [b] then I am essentially just adding more polymorphic type variables to my methods?
03:17:41 <lyxia> I'm not sure what that means
03:17:52 <kuribas> all type variables are polymorphic
03:19:33 <kuribas> there should be an equivalent to type signatures in let for (<-)
03:19:45 <kuribas> you cna do let x :: Type; x = ...
03:19:55 <kuribas> but not do x :: Type; x <- ...
03:20:02 <absence> if i get a type error "expected type IO a, actual type m a" with MonadIO => m, does that mean i have to look into unliftio or something?
03:20:32 <zincy> class MonadTrans t where
03:20:32 <zincy>   lift :: Monad m => m a -> t m a
03:20:53 <zincy> So where does `m` and `a` come from?
03:21:58 <zincy> I thought that in this case only `t` was the type variable in scope for this type declaration?
03:22:24 <kuribas> zincy: m and a are also type variables
03:22:43 <Ariakenom> kuribas: you can do "do x :: Type <- value". I think with XScopedTypeVariables
03:22:55 <kuribas> Ariakenom: ah, nice :)
03:23:09 <kuribas> IMO it makes code more clear
03:23:51 <zincy> So why would the MPTC extension be needed to write
03:23:54 <zincy> class Collection c e where
03:23:54 <zincy>     insert :: c -> e -> c
03:24:01 <zincy> why not just
03:24:07 <zincy> class Collection c where
03:24:07 <zincy>     insert :: c -> e -> c
03:26:27 <dminuoso> zincy: Because in standard haskell a typeclass may only be parametrized over one parameter.
03:27:14 <zincy> dminuoso: Thanks. Why does the second class not compile?
03:27:30 <zincy> In the case of 
03:27:33 <zincy> instance Collection [a] where
03:27:33 <zincy>     insert xs x = x:xs -- this doesn't work
03:27:49 <kuribas> zincy: you can do that if you have a way to extract e from c.  
03:27:58 <kuribas> zincy: using the type family extension.
03:27:58 <lyxia> zincy: in the first "insert" needs to insert only one type of "e" in a "c", in the second "insert" needs to insert any type of "e" in a "c"
03:28:20 <Ariakenom> % :set  -XScopedTypeVariables
03:28:20 <yahb> Ariakenom: 
03:28:29 <Ariakenom> % do {x :: Int <- pure 1; pure x}
03:28:29 <yahb> Ariakenom: 1
03:28:47 <kuribas> zincy: then you provide a mapping from c to e, which is called a Type Family
03:28:53 <Ariakenom> %kill
03:28:53 <yahb> Ariakenom: Done
03:28:55 <Ariakenom> % do {x :: Int <- pure 1; pure x}
03:28:55 <dminuoso> lyxia: Is it right to call the `c` inside the method declaration existentially quantified?
03:28:56 <yahb> Ariakenom: 1
03:29:05 <Ariakenom> > do {x :: Int <- pure 1; pure x}
03:29:07 <lambdabot>  error:
03:29:07 <lambdabot>      • Ambiguous type variable ‘m0’ arising from a use of ‘show_M495769450854...
03:29:07 <lambdabot>        prevents the constraint ‘(Show (m0 Int))’ from being solved.
03:29:46 <zincy> Ah! I think I get it now
03:30:12 <zincy> You need to define a relationship between types in order for the insertion operation to work after the initial one
03:30:53 <Ariakenom> > do {x :: Int <- (pure 1 :: Maybe Int); pure x}
03:30:55 <lambdabot>  Just 1
03:31:52 <dminuoso> zincy: It may be helpful to put the forall quantification explicitly.
03:32:54 <zincy> Is forall. essentially the explicit declaration of a type variable?
03:33:34 <dminuoso> zincy: class MonadTrans t where lift :: forall m a. Monad m => m a -> t m a
03:33:34 <zincy> In the example I gave how does the compiler "know" that in the first case the operation will work but afterwards it wont?
03:33:44 <lyxia> dminuoso: I don't think so. I would say it's more a matter of where the quantifier/binder is.
03:54:21 <kuribas> interesting, any time you would pattern match on a list, you can use foldr
03:54:36 <kuribas> :t foldr
03:54:37 <lambdabot> Foldable t => (a -> b -> b) -> b -> t a -> b
03:54:39 <kuribas> :t maybe
03:54:40 <lambdabot> b -> (a -> b) -> Maybe a -> b
03:54:47 <kuribas> :t either
03:54:48 <lambdabot> (a -> c) -> (b -> c) -> Either a b -> c
03:56:34 <kuribas> the question is of course if this is more readable than pattern matching or less
04:01:45 <warbo> kuribas: that's the idea behind church encoding (and extensions, like morgensen-scott encoding)
04:02:20 <warbo> with those encodings, we don't even need datastructures in the language; everything can be done with functions (like in lambda calculus)
04:03:27 <warbo> the fact that datastructures and (sometimes) pattern matching *are* added to most languages, seems to indicate that they make things more readable ;)
04:03:38 <Lears> Reorder the arguments so that the value being destructured is first, then place the argument for each case on its own line and it will read fine, so long as you don't have too big a sum-type. I've a reasonably sizable project written that way.
04:04:30 <kuribas> warbo: yeah, I agree
04:04:40 <kuribas> I often use maybe if the arguments are pointfree
04:04:48 <kuribas> but not with a lambda
04:08:05 <__monty__> Why exclude lambdas? I wouldn't use it with multiline definitions but lambdas seem fine to me.
04:19:55 <mtb34> Hello. How can we mute the join and quits in here to better see chatting?
04:20:11 <dminuoso> mtb34: Check your IRC client. It might have smart filter support.
04:20:24 <dminuoso> (Directly or via a plugin)
04:20:52 <mtb34> I joined from the webchat browser, was hoping for such a command
04:31:24 <kuribas> __monty__: because then I can just use pattern matching?
04:31:49 <kuribas> ah, foldr also does recursion, so it's not's exactly like pattern matching
04:32:55 <__monty__> mtb34: Not sure if it'll work but in irssi it's just /ignore * JOINS,PARTS,QUITS I think.
04:34:06 <mtb34> __monty__: Ignored * JOINS,PARTS,QUITS, to unignore type: /UNIGNORE * JOINS,PARTS,QUITS
04:35:04 <mtb34> doesn't work though
04:35:25 <__monty__> kuribas: But why prefer pattern matching syntax? `maybe` is basically pattern matching but in a way that composes better.
04:35:58 <kuribas> __monty__: it depends
04:39:28 <sshine> mtb34, http://wiki.xkcd.com/irc/hide_join_part_messages#qwebirc
04:40:45 <dminuoso> kuribas: https://wiki.haskell.org/wikiupload/3/3e/Right-fold-transformation.png
04:41:09 <kuribas> dminuoso: yeah, it's a catamorphism
04:41:51 <mtb34> that's it, cheers
04:45:56 <__monty__> Can anyone enlighten me as to why `4e-45 :: Rational` gives a different result than `toRational 4e-45`? Is the literal being interpreted as something distinct from Float/Double?
04:46:06 <oo_miguel> The hackage page about Control.Applicative states that it is sufficient for "context-free parsing". But I wonder If the Alternative class is not required at least?
04:47:19 <hpc> :t toRational
04:47:20 <lambdabot> Real a => a -> Rational
04:47:29 <lyxia> oo_miguel: I guess it is required
04:47:41 <hpc> i bet it's defaulting to Double for the numeric literal
04:47:44 <hpc> :t 0.5
04:47:45 <lambdabot> Fractional p => p
04:48:06 <dminuoso> lambdabot: Its not, strictly speaking.
04:48:10 <dminuoso> Sorry. lyxia.
04:48:11 <hpc> numeric literals go through fromRational
04:48:26 <hpc> so fromRational 4e-45 is basically id
04:48:30 <oo_miguel> lyxia: heh, ok. then it makes sense, thank you.
04:48:50 <dminuoso> oo_miguel: Alternative is not required.
04:48:59 <lyxia> really
04:49:27 <oo_miguel> dminuoso: hmmm.  I do not see how I can select between two parsers then?
04:49:31 <dminuoso> Mm, I guess it depends on how you think about Alternative.
04:49:56 <oo_miguel> dminuoso: I Want a parser that can parse one DIGIT or one LETTER
04:50:10 <oo_miguel> (as an example)
04:50:20 <oo_miguel> by combining to parsers
04:50:23 <oo_miguel> two
04:50:26 <dminuoso> https://byorgey.wordpress.com/2012/01/05/parsing-context-sensitive-languages-with-applicative/
04:50:44 <lyxia> I can see how you can write a context-free parser as "forall f. Alternative f => f Char -> f a" I don't see how you do it with Applicative.
04:53:27 <oo_miguel> dminuoso: it seems that when talking about Monad and Applicative... he is really talking about MonadPlus and Alternative.. if I understand the first paragraph correctly.
04:55:04 <lyxia> Well there's another point that Alternative allows you to parse more than context-free languages.
04:56:46 <lyxia> so maybe there's a more accurate abstraction to be found there
04:57:07 <__monty__> oo_miguel: Alternative is for context-sensitive, he does mention applicative is enough for context-free.
04:57:52 <__monty__> If you can make a parser that parses a DIGIT, surely you can make a parser that parses a DIGIT or a LETTER though?
04:59:30 <lyxia> You have digit :: Parser Digit, letter :: Parser Letter, the question is how do you write a  Parser (Either Digit Letter)  with only applicative combinators?
05:00:12 <__monty__> My point is that if you presuppose you can combine character parsers into a digit parser you can use the same technique to make a digit/letter parser : >
05:01:23 <lyxia> I thought we were talking about what base means when it says that Applicative is for context-free parsing
05:02:52 <oo_miguel> my original question was if Applicative (without Alternative) is sufficient for context-free parsing... and I admit that I still do not see how/if it is sufficient.
05:03:04 <__monty__> And I'm pointing out maybe thinking in Alternative terms makes you miss the forest for the trees.
05:04:15 <oo_miguel> I have some production rules of a context-free grammar, and want to combine simple parsers to match these.
05:07:53 <oo_miguel> It seems to me that these production rules can be easily and naturally constructed from Parsers when I use the (<|>) which comes with the Alternative class.
05:08:48 <oo_miguel> but I will think about it and read the article... 
05:09:03 <oo_miguel> thank you everybody
05:09:10 <__monty__> I think it works, just not as elegantly as with Alternative. You can sequence parsers but not compose them as with <|> so you have to make more monolithic components.
05:09:44 <oo_miguel> __monty__: I am afraid that it can become indefinitely unelegant in general ;)
05:11:05 <oo_miguel> In an extreme case I could write one parser for each possible valid input ;)
05:11:13 * Ariakenom notes the "without exception" use
05:13:13 <__monty__> Control.Applicative promises nothing about elegance. The other direction is obvious, Applicative is not sufficient for CSGs. I agree it'd be interesting to work out why they *are* sufficient for CFGs though.
05:14:28 <akersof> hi all, i was reading the core code of last function and i found something strange i never saw before: https://gist.github.com/akersof/302ff6ebf5f9c8646d37a9a108b371d3
05:14:58 <akersof> in line 11, i don't understand how the error for the empty list is handled?
05:15:29 <__monty__> oo_miguel: Alternative also seems too powerful already, giving you context-sensitivity.
05:15:44 <akersof> lastError is the accumulator here.. but it is never returned from the function passed to foldl
05:16:35 <akersof> so i can't see how we can get the error with an empty list passed foldl in last xs = foldl (\_ x -> x) lastError xs
05:16:46 <oo_miguel> __monty__: hmm, are you sure? I thought it lacks the context-sensitivity as opposed to monads?
05:17:07 <__monty__> <|> gives you the context of the lhs failing.
05:17:15 <oo_miguel> __monty__: aah sorry, I misread what you said. 
05:17:24 <oo_miguel> confused Applicative and Alternatvie
05:20:47 <oo_miguel> anyway, so my current picture (concerning context-free parsing) is that Alternative is too powerful, and Applicative alone is to unelegant to be feasible in general (however I still do not see how It can work when I accept the lack of elegance)
05:24:51 <oo_miguel> ...even given somthing trivial as well-formed parentheses which (according to wikpedia) is the canconcial exmaple of a cotext-free grammar.
05:24:56 <c_wraith> Alternative only gives you context-sensitive parsing if you create an infinite structure
05:25:15 <c_wraith> Any finite use of it is only context-free
05:26:19 <oo_miguel> c_wraith: At the moment I am only interested in context-free parsing
05:26:59 <__monty__> c_wraith: Wouldn't a finite alphabet require only a finite structure?
05:27:21 <c_wraith> __monty__: no, you need an infinite parse tree
05:28:15 <dmwit> oo_miguel: I want to engage in a tiny bit of pettifoggery that I promise has a real, fundamental point behind it.
05:28:37 <c_wraith> __monty__: like, for a typical "parse integer, parse <count> items" flow to work with Alternative+Applicative, you need a different construction for each integer.  
05:28:44 <dmwit> oo_miguel: Even if you allow yourself both Applicative and Alternative, that is *still* not enough for parsing CFGs, REs, or even single static strings.
05:28:59 <c_wraith> __monty__: which requires an infinite number of cases in the grammar.
05:29:34 <dmwit> oo_miguel: You *also* need at least a few primitives for matching individual tokens, something that neither Applicative nor Alternative give you.
05:30:10 <c_wraith> __monty__: you can do that just fine in Haskell, because you can express the patterns in the infinite grammar in such a way that every finite input is eventually matched.
05:30:32 <dmwit> oo_miguel: That is the pettifoggery. Now comes the point: primitives can give you the effects of Applicative or Alternative even if there's no instance. So one must be v. careful when asking whether "Applicative is enough".
05:31:06 <c_wraith> __monty__: but it's still a conceptually infinite grammar, which means it no longer *really* fits in the classical definitions of context-free or context-sensitive
05:31:31 <zincy> Is a functional dependency between types essentially saying that there is a unique mapping between types.
05:32:00 <zincy> So the purpose is to give the compiler the information it needs to prevent multiple mappings between sets of types
05:32:33 <dmwit> A unique mapping? No. `tys -> tys'` says that for any given choice of types assigned to `tys`, there is at most one choice of types you can assign to `tys'`.
05:32:38 <c_wraith> zincy: it's one-way only. m -> s says there's only one valid s for each m, but says nothing about how many valid m types there are for each s
05:33:24 <oo_miguel> dmwit: hmmm. ok thank you for confusing me even more ;). But I think I get your overall idea, however I can not put it into practice yet... You mean however that using some primitives (which can more than what an Alternative can do for me), even in an Applicative way will result in an overall parser that is obviously not only Applicative.
05:34:05 <dmwit> Right. I'm saying you need to carefully specify what non-class operations you allow to exist.
05:34:06 <zincy> Wait is a -> b (type signature) a functional dependency?
05:34:16 <zincy> I was talking about the language extension
05:34:23 <dmwit> zincy: No, fundeps and type signatures are easy to distinguish syntactically.
05:34:35 <c_wraith> zincy: nope.  I was giving an example of a functional dependency without the rest of the syntax around it
05:34:51 <zincy> ah ok
05:34:55 <c_wraith> class MonadState m s | m -> s where ...
05:35:12 <__monty__> oo_miguel: An example of such a primitive for applicative would be lookahead I think.
05:35:15 <oo_miguel> I would like to stay with this "trivial" example of constructing a parser for well formed parentheses when given primitve parsers for "(" and ")" already. (and not caring what they do internally)
05:35:27 <zincy> Need to go now but I will be back 
05:36:17 <__monty__> oo_miguel: I'm not sure that's fair. The grammar would be something like `(^n)^n` so why can't the primitives be `parse n (` and `parse n )`?
05:36:45 <c_wraith> __monty__: assume ()() is valid too. :P
05:36:55 <oo_miguel> the grammar is simply (Stolen from wiki) S->SS, S->"()" , S->"(" S ")"
05:37:11 <c_wraith> Indeed it is, by that grammar.
05:37:22 <oo_miguel> why is this unfair? 
05:37:34 <c_wraith> oo_miguel: you understand that grammar is ambiguous, right?  That adds a lot of potential complexity
05:37:50 <__monty__> oo_miguel: My point is if you restrict the primitives even monadic parsers may not be powerful enough.
05:38:12 <__monty__> That doesn't mean a monadic parser can't parse your grammar, just that it can't given you constraints.
05:38:20 <__monty__> *your
05:41:14 <oo_miguel> aaah ok
05:41:49 <oo_miguel> so if I agree with primitives "parse n (" and "parse n )" things will look different... 
05:43:18 <__monty__> Maybe, though I don't see how myself. The point stands though.
05:45:02 <oo_miguel> ok, I clearly agree that the choice of my primitives will have impact on what "powers" I need to combine them to get my final parser
05:47:25 <oo_miguel> c_wraith: hmmm.. but I do not understand that this grammar is ambigous... I think it will produce only all possible sets of well-formed parentheses.
05:48:06 <c_wraith> oo_miguel: ambiguous means that there are multiple different ways of getting the same output.
05:48:22 <c_wraith> oo_miguel: (when using it as production rules, rather than parsing rules)
05:48:31 <c_wraith> oo_miguel: for instance, the output ()()()
05:48:42 <TimoMeijer> I'm running into an issue with QuickCheck functionShow, which doesn't seem to work fro functions that take a String. Example: https://gist.github.com/TimoMeijer/29e7b220cc63586f9876269d00299962 Any help to get this to work would be greatly appreciated!
05:48:45 <oo_miguel> c_wraith: aah okok
05:53:59 <c_wraith> oo_miguel: for the sake of completeness, here's a non-ambiguous grammar that produces/accepts the same language:  S -> PS; S -> P; P -> "()"; P -> "(" S ")"
05:54:43 <c_wraith> oo_miguel: conceptually, all it's doing is forcing the tree to lean one direction in the cases where it's ambiguous in the original
05:55:27 <Solonarv> or you can allow yourself more notation:
05:55:27 <Solonarv> S -> P*
05:55:27 <Solonarv> P -> "()" | "(" S ")"
05:56:03 <c_wraith> looked like a chomsky-style grammar, so I stuck with that. :)
05:56:37 <Solonarv> I logged on a few minutes ago, so I haven't actually seen the original question :p
05:56:38 <oo_miguel> c_wraith: Solonarv: ok, I see how this is non-ambiguous as opposed to my original grammar
05:57:28 <oo_miguel> Solonarv: I was looking for examples/questioned the feasibility of Applicative-only parsing...
05:58:15 <oo_miguel> without having at least the possiblity of combining my parsers via <|> as offered by the Alternative class
05:59:33 <Solonarv> IIUC Applicative alone gives you only concatenation, so you indeed can't express very much without additional combinators
06:00:37 <Solonarv> the production 'S -> XY' corresponds roughly to 'parseS = parseX <*> parseY'
06:01:15 <dmwit> TimoMeijer: My reading of `functionShow` is that it can only be used on types which can `read` *any* possible String.
06:01:25 <dmwit> Which is... no existing types at all.
06:01:49 <oo_miguel> Solonarv: allright. I will just accept that and use Alternative as well for now. 
06:02:00 <oo_miguel> thank you everybody for their help. 
06:02:12 <dmwit> (Or rather: the result of `functionShow` can only be `show`n if the input type can `read` any possible String.)
06:02:47 <Solonarv> indeed; you need Alternative (or something equivalent) if you want branching/multiple possibilities
06:03:21 <dmwit> TimoMeijer: Generally, you cannot losslessly convert a function with infinite domain to a String in Haskell.
06:03:58 <oo_miguel> Solonarv: I was just initially confused by the claim at Control.Applictive on hackage, that it is sufficient for e.g. context-free parsing.
06:04:05 <Solonarv> dmwit: sure you can, if you have access to the original source code! :p
06:04:19 <dmwit> Solonarv: That would be stepping outside of Haskell.
06:04:46 <Solonarv> oo_miguel: I think that's supposed to mean "you don't need the full power of a Monad, Applicative with some extra combinators is enough"
06:04:48 <dmwit> I agree that lots more logical moves are available in the metatheory than in the theory.
06:04:59 <oo_miguel> I'm afk now for some while, thanks again
06:05:10 --- mode: ChanServ set +o Sigyn
06:05:26 <oo_miguel> Solonarv: yeah, I think it means a monad is way overpowered for that.
06:09:16 <mniip> Solonarv, that looks ambiguous to me
06:09:24 <mniip> S matches empty string
06:09:34 <mniip> so "()" and "(" S ")" intersect
06:09:58 <Solonarv> oh, duh - the first rule should be S -> P+, not S -> P*
06:14:11 <dmwit> TimoMeijer: In fact, I'm going to go even farther than I did before. This `(:->)` stuff is not suitable for use by library clients. It should not have been exported in the first place.
06:17:48 <dmwit> (...but if you want to `show` functions, and you're willing to accept the finite domain restriction, see Data.Universe.Instances.Reverse from the universe package.)
06:19:47 <TimoMeijer> dmwit: My usecase was just to provide the show instance for a datatype containing a function, which is a requirement to use the checkers library to verify certain laws. functionShow seemed like the correct way to do it, but I stand corrected! Back to the "stupid" default function show instance it is
06:30:01 <sshine> does Data.Vector and Data.Array share any common interface?
06:30:27 <sshine> like a type class that will give me length and index.
06:50:30 <merijn> byorgey: I just saw your february blog on worst sort. I wanna point you to my favourite CS paper ever: Pessimal Algorithms and Simplexity Analysis (https://mipmip.org/tidbits/pasa.pdf)
06:55:23 <byorgey> merijn: haha, thanks!
07:00:19 <Taneb> merijn: I'm a little surprised that that's not from sigbovik
07:22:13 <Zemyla> So my thought is that, since a Char is (currently) 21 bits, 3 chars is 63 bits, and the last bit can be used to determine if the 64-bit word has 2 or 3 characters in it.
07:22:49 <Zemyla> That makes it ideal for use as a Node in a fingertree-based string.
07:24:11 <merijn> Zemyla: What makes you say a Char is 21 bits?
07:25:28 <Zemyla> > finiteBitSize (ord maxBound) - countLeadingZeros (ord maxBound)
07:25:31 <lambdabot>  21
07:26:15 <Zemyla> > (printf "%x" (ord maxBound)) :: String
07:26:17 <lambdabot>  "10ffff"
07:41:31 <asheshambasta> With lenses, can something like this be 'simplified'? myList ^. to (map someFuncOnElem)
07:41:59 <asheshambasta> I'm pretty sure it can (so far, I've only used Lenses for previews and views, or maybe I'm missing something quite obvious here.)
07:42:05 <Taneb> asheshambasta: why not just "map someFuncOnElem myList"
07:42:23 <Taneb> If you want to use lenses, something like myList & mapped %~ someFuncOnElem works, too
07:42:43 <Taneb> This uses a Setter
07:42:54 <asheshambasta> Taneb: this is a simplified example; I'm getting to myList via someOtherValue ^. someField1 . someField2 . myList 
07:43:09 <c_wraith> My opinion is that "to" is basically always the wrong option.
07:43:20 <asheshambasta> Taneb: so I was doing . to (map fooBar), and I was wondering if the synax could be made cleaner. 
07:43:41 <asheshambasta> c_wraith: why?
07:44:19 <Taneb> asheshambasta: using "to" is no better than doing "map fooBar $" at the beginning
07:45:04 <c_wraith> asheshambasta: "to" loses most of the interesting stuff in lens.  let's be honest, Getters aren't exciting.  They're just function application.
07:45:26 <asheshambasta> Taneb: yeah; for some reason I wanted to avoid `$` 
07:45:46 <asheshambasta> c_wraith: makes sense
07:51:12 <lyxia> I can see the appeal of  view (a . b . to f . c . d)   instead of   view (c . d) . f . view (a . b)   or   view d . view c . f . view b . view a
07:51:34 <lyxia> it's pretty rare to see this particular pattern though.
07:51:52 <c_wraith> In those cases I'd just write a new lens/traversal that does what I want.
07:52:07 <c_wraith> It's like 2 lines of code for far greater usefulness
07:52:36 <lyxia> fair point
07:55:07 * hackage profiteur 0.4.5.1 - Treemap visualiser for GHC prof files  https://hackage.haskell.org/package/profiteur-0.4.5.1 (JasperVanDerJeugt)
07:55:13 <Zemyla> So when will we get newtype GADT wrappers around dictionaries?
07:55:28 <Zemyla> Like: newtype Dict c where Dict :: c => Dict c
07:58:04 <lyxia> when you go and implement it :)
07:59:00 <Taneb> Or when you go and look at the "constraints" library
07:59:54 <lyxia> I think the question is more about "newtype" than the "Dict" part of that definition.
08:00:18 <Taneb> ...maybe
08:09:59 <zincy> Right so functional dependencies. Am I right in saying you can mainly use them to allow only one class instantiation for a given set of types. For example take the multiparameter typeclass - class Add a b c where 
08:10:29 <zincy> You specify a functional dependency with class Add a b c | a b -> c where 
08:10:48 <zincy> Which says that for every a and b combination there is only one c ?
08:11:24 <Cale> Yeah
08:11:47 <zincy> Cool
08:11:59 <Cale> and so it means that whenever we know the types a and b, and that Add a b c is supposed to hold, we can look up what the type c is during type inference
08:12:27 <zincy> And type families are essentially a different method of definition a relation between types?
08:13:01 <Cale> Yeah, there's a good deal of overlap in terms of what's actually accomplished, but the syntax and how you think about it tends to be rather different.
08:13:09 <Cale> you could for example write
08:13:13 <Cale> class Add a b where
08:13:18 <Cale>   type AddResult a b
08:13:27 <Cale>   add :: a -> b -> AddResult a b
08:13:50 <Cale> and that would be roughly equivalent to the previous class with the fundep
08:14:12 <zincy> Is the `type` keyword defining a new type family?
08:14:22 <Cale> When it occurs inside of a class, yeah
08:14:42 <Cale> Each instance will define that type synonym for its particular a and b
08:15:12 <zincy> So is AddResult a b just a normal type?
08:18:05 <zincy> Why is this not a valid instantiation of the typeclass Add:
08:18:08 <zincy> instance Add Integer Integer where
08:18:08 <zincy>     add x y = x + y
08:18:36 <zincy>  Couldn't match expected type ‘AddResult Integer Integer’ with actual type ‘Integer’
08:20:08 <Cale> Well, you should define the type synonym
08:20:23 <zincy> Ah ok
08:20:25 <Cale>   type AddResult Integer Integer = Integer
08:20:25 <zincy> like:     type AddResult Integer Integer = Integer 
08:20:27 <Cale> yeah
08:20:56 <zincy> So how do type families differ from synonyms?
08:21:16 <zincy> I get that a type family is a function on the type level
08:22:07 <zincy> So perhaps the difference is that it isn't an alias like a synonym but allows for actually operations to be carried out to define the relationships between types such as pattern matching
08:23:05 <Cale> Yeah, the difference is that you have a family of type synonyms defined by pattern matching on the type arguments.
08:24:33 <zincy> So type families are useful where you want a type to be determined by another?
08:25:02 <Athas> Yes.
08:25:06 <zincy> Because normally when you have more than 1 type variable you cannot express any relationship between them say in type declarations.
08:25:18 <zincy> I guess that is what computation at the type level is.
08:25:24 <Athas> They are also sometimes called "indexed types" (because type families behave more like maps than full functions).
08:25:29 <Cale> Well, of course, you can express relationships using constraints
08:25:32 <zincy> Operating on types like you would with values.
08:25:37 <Cale> But this is just another way of doing that
08:26:04 <zincy> :)
08:26:52 <zincy> Is the difference in defining a typefamily with the class syntax purely syntactical?
08:27:30 <Cale> Well, apart from the fact that the rest of the instance comes along with it
08:28:46 <zincy> So could I have another function outside of any class declaration or instance that uses AddResult a b?
08:28:56 <Cale> sure
08:32:26 <zincy> Now I am not sure how to use  AddResult a b ? 
08:32:46 <zincy> I know I can only get one as the result of adding together two things
08:34:05 <zincy> AddResult a b is useless by itself right because the synonym is only defined when a and b are inhabited.
08:37:16 <Cale> ?
08:42:57 <zincy> Was I babbling?
08:53:27 <Cale> I'm not sure of what relevance a and b being inhabited would have. Every type in Haskell is inhabited (you have undefined), and even if this were not the case, we could still define an instance Add Void Void
08:53:48 <Cale> Presumably with type AddResult Void Void = Void
08:53:55 <zincy> I am probably misusing the term inhabited
08:54:10 <rayz> hieveryone
08:54:16 <zincy> hi
08:54:23 <rayz> i am new to haskell and keen to learn about it
08:54:27 <Cale> cool!
08:54:32 <zincy> Welcome
08:54:36 <Cale> Feel free to ask any questions you might have
08:55:07 <rayz> how different is it from javascript and java?
08:55:15 <Cale> very different
08:55:31 <Cale> To a reasonable extent, it'll be like learning to program all over again
08:55:43 <zincy> It was for me.
08:55:46 <rayz> that seems cool
08:56:02 <aplainzetakind> I have a function which treats some 19-element Vectors as 20-element Vectors, but not all, and : https://gist.github.com/aplainzetakind/da03fe1a7c2e59bf14acec9fbb8d3e07
08:56:05 <zincy> You will learn new concepts
08:56:10 <aplainzetakind> ...I'm stumped.
08:57:12 <rayz> it seems very much about math concepts
08:57:56 <Cale> aplainzetakind: What are you stumped about?
08:57:58 <rayz> i just wanna know where it can be used
08:58:12 <rayz> 'applications as in
08:58:36 <Cale> rayz: Almost anything. Where I work we use it to build web and mobile applications, and the backends for those applications.
08:58:38 <zincy> rayz: Can you find any examples of maths?
08:58:47 <zincy> Cale: Where do you work?
08:59:06 * hackage dot 0.3 - Datatypes and encoding for graphviz dot files  https://hackage.haskell.org/package/dot-0.3 (chessai)
08:59:09 <Cale> I work remotely for Obsidian Systems which is based in NYC
08:59:14 <rayz> I saw a job posting, they use haskell
08:59:14 <lyxia> aplainzetakind: what's the problem
08:59:24 <rayz> Obsidian systems
08:59:29 <rayz> yeah i have head of them
08:59:30 <rayz> cool
08:59:53 <aplainzetakind> v has 19 elements, as V.length v shows in the repl, but inside the function `trace` reports it as having 20.
09:00:15 <aplainzetakind> The repl session is the comment.
09:00:33 <Cale> aplainzetakind: ahh
09:00:38 <aplainzetakind> When doing the same thing with [1..19], it works.
09:00:42 <aplainzetakind> Pretty strange.
09:00:53 <Cale> I bet I have an idea about what's happening
09:01:28 <Cale> It has to do with the way you're defining the two lists l1 and l2
09:01:35 <Cale> and which numerical instances you're using
09:01:42 <Cale> > [1,3..20]
09:01:45 <lambdabot>  [1,3,5,7,9,11,13,15,17,19]
09:01:53 <Cale> > [1,3..20] :: [Double]
09:01:55 <lambdabot>  [1.0,3.0,5.0,7.0,9.0,11.0,13.0,15.0,17.0,19.0,21.0]
09:02:01 <Cale> ^^ check it out
09:02:09 <Cale> This is... sadly intentional.
09:02:34 <aplainzetakind> But see the last line, I ask what v is, and it shows 19 elements.
09:02:47 <Cale> But is it the same v?
09:02:56 <Cale> v is polymorphic
09:03:01 <Cale> Ask for its type
09:03:24 <aplainzetakind> Oh I see.
09:03:24 <Cale> I'm expecting something like (Num a) => Vector a
09:03:40 <Cale> Yeah, pretty confusing
09:03:49 <lyxia> ahaha nice find
09:04:25 <Cale> The instances of Enum for Float and Double treat the defined step size as a kind of precision for stopping.
09:04:37 <aplainzetakind> Wow, that's really absurd behaviour.
09:04:41 <aplainzetakind> Thanks.
09:05:09 <Cale> so they'll catch additional elements at the end when those elements are less than or equal to half a step off the defined endpoint
09:05:23 <Ariakenom> Cale: also for Rational D:
09:05:28 <Cale> Oh, right, haha
09:05:43 <Cale> It's really dumb, but good luck getting that changed
09:06:02 <Ariakenom> https://hackage.haskell.org/package/base-4.11.1.0/docs/src/GHC.Real.html#numericEnumFromThenTo
09:06:41 <Ariakenom> I keep a link to the source in my bookmarks ...
09:10:06 <zincy> Is there a function which applies another function to a starting value recursively n times?
09:10:31 <lyxia> nope
09:13:06 * hackage js-dgtable 0.5.2 - Obtain minified jquery.dgtable code  https://hackage.haskell.org/package/js-dgtable-0.5.2 (NeilMitchell)
09:13:47 <Guest97725> :t \n -> appEndo . mconcat . replicate n . Endo
09:13:48 <lambdabot> Int -> (a -> a) -> a -> a
09:34:19 <Gurkenglas> :t under (_Wrapping Endo) . Data.Semigroup.stimes
09:34:21 <lambdabot> Integral b1 => b1 -> (b2 -> b2) -> b2 -> b2
09:34:50 <Guest97725> :t under
09:34:51 <lambdabot> AnIso s t a b -> (t -> s) -> b -> a
09:35:38 <Gurkenglas> You can read "under (_Wrapping Endo)" as "lend me the instances of the Endo newtype"
09:36:01 <Guest97725> lens poetry
09:38:57 <Gurkenglas> (Why aren't we deriving _Endo as _Wrapping Endo?)
09:40:03 <Gurkenglas> It fits with and generalizes the prism naming convention
09:50:37 * hackage hadolint 1.16.1 - Dockerfile Linter JavaScript API  https://hackage.haskell.org/package/hadolint-1.16.1 (lorenzo)
09:53:36 * hackage curl-runnings 0.10.0 - A framework for declaratively writing curl based API tests  https://hackage.haskell.org/package/curl-runnings-0.10.0 (aviaviavi)
09:54:21 <Nevoic> Hey, I've been trying to understand monads on and off for probably about a year now. I find examples of monads to be easy to understand (Maybe, for example). The thing I have trouble with is nailing what exactly a monad is.
09:55:45 <Nevoic> My understanding right now is it's pretty much a parameterized type that needs two constructors, one of which handles the "base case" (or identity case I think it's more correctly called) and another case that handles Monad A -> (a -> Monad B) -> Monad B. Is that accurate?
09:57:30 <Nevoic> I meant Monad A -> (A -> Monad A) -> Monad A, idk what I was thinking. I'm still not solid on this.
09:58:22 <ldlework> Nevoic probably not a popular opinion in here but the best introduction on Monads I've seen is actually for F#: https://fsharpforfunandprofit.com/series/map-and-bind-and-apply-oh-my.html
09:58:51 <Nevoic> Thanks, I'll take a look! Was my definition of monads off then?
10:01:15 <Ariakenom> :t (>>=)
10:01:16 <lambdabot> Monad m => m a -> (a -> m b) -> m b
10:02:18 <Ariakenom> Nevoic: yes.     Monad A -> (A -> Monad B) -> Monad B
10:02:28 <adamCS> If I have a record-of-functions, how do I indicate that I want them inlined at their call-sites?  If it were a class, I would just add inline pragmas to the functions in the instances.  
10:05:04 <lyxia> maybe that happens automatically?
10:06:04 <Ariakenom> Nevoic: This course gets recommended quite a bit here. It's a general haskell course though https://www.seas.upenn.edu/~cis194/spring13/lectures.html
10:06:11 <adamCS> lyxia:  Probably!  But that's true of short class methods too, right?  In this case I'd like to make the same suggestion to the compiler.  Or even insist, for benchmarking purposes.
10:08:13 <adamCS> I guess I could write all the functions externally to the record, add inline pragmas, then just put the top-level names in the record.  But even that doesn't seem like a guarantee since there's another call, namely the one through the record itself.  Can you tell ghc to inline those?  That might be qutomatic...
10:17:36 * hackage cornea 0.2.1.0 - classy optical monadic state  https://hackage.haskell.org/package/cornea-0.2.1.0 (tek)
10:42:11 <habbah> #if MIN_VERSION_aeson(0,10,0)
10:42:20 <habbah> what is this?
10:43:07 <habbah> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/phases.html#standard-cpp-macros
10:44:19 <habbah> I see a lot of these in https://github.com/phadej/aeson-compat/blob/master/src/Data/Aeson/Compat.hs
10:44:52 <geekosaur> that usually comes from cabal instead of ghc, cpp macros defined based on the packages
11:16:44 <cocreature> habbah: see https://cabal.readthedocs.io/en/latest/developing-packages.html#conditional-compilation
11:23:07 * hackage possibly 0.0.0.1 - type Possibly a = Either String a  https://hackage.haskell.org/package/possibly-0.0.0.1 (ChrisDornan)
11:36:58 <gobby> Hey guys, I'm wondering if I should use resourcet or async
11:37:11 <gobby> I'm basically reading a bunch of files from disk and validating them
11:37:21 <gobby> im reading them as a `Stream`
11:38:52 <vaibhavsagar> gobby: are you hoping to do this asynchronously or in some order?
11:39:06 <vaibhavsagar> and what library are you using to get them as a stream?
11:40:04 <gobby> vaibhavsagar: http://hackage.haskell.org/package/streaming
11:40:36 <lyxia> ... this "possibly" library hackagebot just announced is just that one type synonym...
11:41:18 <gobby> vaibhavsagar: I'm running an executable that only streams the files and folds over them to give a result
11:41:26 <lyxia> it's not even eta-shortened
11:41:30 <fen> can we use an "algebra homomorphism" to represent functions over *all* values in a set?
11:41:42 <gobby> vaibhavsagar: I guess that means its not asynchronous?
11:41:49 <vaibhavsagar> gobby: it doesn't sound like you need any additional libraries in that case
11:42:03 <vaibhavsagar> no AFAICT
11:42:30 <gobby> vaibhavsagar: So just stream and fold as normal
11:42:53 <gobby> vaibhavsagar: If I ever begin to fork other threads doing other things then I will need a library like `async`
11:43:25 <vaibhavsagar> you never need async
11:43:38 <vaibhavsagar> it's incredibly useful and I would recommend using it
11:43:51 <fen> can we use an "algebra homomorphism" to represent functions over *all* values in a set?/
11:44:01 <fen> if the set was indexed by integers, we would write a vector, and have a function taking this vector be able to combine these values in a nolinear way, or use a matrix if its linear. but if we have some set parametrised by something like shapes, or some internal coordinates, how can we describe a function over all the values?
11:44:09 <fen> sorry for the repost, was a typo
11:44:39 <gobby> vaibhavsagar: I never need async?
11:45:25 <vaibhavsagar> gobby: http://hackage.haskell.org/package/async
11:45:44 <vaibhavsagar> "This package provides a higher-level interface over threads"
11:46:00 <fen> its like map? thats why algebra homomorphisms seem like they might work. a function that could take some value in the set can then be mapped over the whole set
11:46:03 <vaibhavsagar> you can certainly use threads without also using the `async` library
11:46:14 <gobby> vaibhavsagar: gotcha
11:46:35 <vaibhavsagar> but it's a good library
11:46:49 <vaibhavsagar> doesn't sound like you need it yet though
11:48:43 <fen> suppose there are some species stored as a set, and each has a concentration associated with it. a function that needed to combine in a nonlinear way *all* of the concentrations, could take a vector of concentrations over each species if they were indexed by integers. the idea is to be able to do this for arbitrary indexed sets, and have a generalised notion of vectors that nonlinear functions can act over
11:48:55 <fen> is that an "algebra homomorphism" ?
11:48:58 <unclechu-xmpp[m]> it's pretty cool, since you could just parallel computations like this: parallelStuffIO $ (,) <$> Async fooIO <*> Async barIO
11:49:07 * hackage cornea 0.2.2.0 - classy optical monadic state  https://hackage.haskell.org/package/cornea-0.2.2.0 (tek)
11:50:12 <fen> (we can think of the concentration function being mapped over the whole set of states, and being used as an argument to some function) 
11:50:21 <unclechu-xmpp[m]> you don't have to do all the MVars and other manual stuff to deliver data from different threads
11:51:56 <fen> and then, obviously, how is this represented in haskell (if indeed its the right way to represent this)
11:53:13 <fen> :t enumFromTo minBound maxBound
11:53:15 <lambdabot> (Bounded a, Enum a) => [a]
11:54:36 <fen> seems like the problem is to try and express at type level that a value eg a list of values from a set, contains every value of the set
11:55:01 <fen> so just passing the set itself as an argument seems reasonable (set valued functions are common, eg measures)
11:55:39 <fen> the question is if the act of mapping a function over a set valued argument is an "algebra homomorphism"
11:57:45 <fen> e.g. you could count the number of values in a set. eg you could partition into greater or less than one, and count the number of entries in the set above or below 0. then if we mapped a function over every value in the set, we could again count this number above and below 0. both the counting functions and the mapping take whole sets as arguments
11:58:20 <hololeap> are there any other interesting examples of an Adjunction in haskell besides ((,) a) and ((->) a)?
12:04:06 * hackage sockets 0.3.1.0 - High-level network sockets  https://hackage.haskell.org/package/sockets-0.3.1.0 (andrewthad)
12:07:13 <fen> hololeap: http://www.stephendiehl.com/posts/adjunctions.html
12:07:29 <fen> "every adjoint pair of functors gives rise to a monad"
12:07:46 <fen> "Can we recover an adjunction from a monad. The answer is Yes…"
12:09:44 <Cale> fen: But not always restricting ourselves to the category that the monad is on
12:10:22 <fen> yeah, it wasnt obvious what the method for construction this adjunction was...
12:11:04 <hololeap> that's cool and all, but i was looking for other possible instances of Adjunction that aren't in the adjunctions library
12:12:43 <fen> wouldnt a method to construct them be better?
12:12:46 <Cale> As far as I know, there aren't any examples which are fundamentally different from those ones
12:14:18 <Cale> See tabulateAdjunction for some rationale for why this is.
12:16:38 <hololeap> that's interesting. i thought there would be more of a point to the Adjunction typeclass.
12:17:11 <Cale> Well, it's a more useful concept when it's not constrained to all the same category.
12:17:25 <hololeap> right, i get that
12:17:27 <fen> so, the Bounded and Enum classes seem like a good way to get "all the values" from a type into a list, but these constraints correspond to an integer index to each value of the set. because we want to consider "shape indexed" values, maybe whats needed is something like enumFromTo minBound maxBound. but that would return something other than a list. and possibly take eg a list of bounds corresponding the the length of branches on a retu
12:18:34 <Cale> see http://hackage.haskell.org/package/universe-1.0/docs/Data-Universe.html
12:18:49 <Cale> for something that *does* result in a list, but doesn't require the Enum/Bounded bit
12:18:56 <fen> but, trying to abstract over the possible shapes of the returned container, we should just work with the set as is
12:20:28 <fen> Cale: thats close, but its still a constraint. it should be a value, something like a vector, but that would only work if it were indexed by an int, so is basically [a]. 
12:22:12 <fen> really seems like it should just be the set, and this whole idea of trying to embed the intrinsic shape of the index, (which is like taking the transpose!?) should be avoided. then the terminology for working with functions over sets is sought. and then also how to construct a set homomorphism from a function over the values of the set
12:22:17 <fen> which seems like fmap
12:24:32 <fen> these kind of set based actions seem really common in maths, but its not clear what formalism they occur within. eg, defining a probability space as a set, a set of subsets of this set, and a function returning a real number between 0 and 1 for each of these subsets
12:25:05 <fen> the idea of a "function taking a set as an argument" seems well defined
12:25:56 <fen> but without knowing the formalism this is based on, its not clear where to find the notion of this "fmap" like thing for constructing functions over sets from functions over values in the set
12:28:01 <fen> not sure if this is exactly the same, because not sure if its ok to represent set of `a' as Functor f => f a. but if that were ok then we could just ask "what is the mathematical function fmap" ?
12:28:10 <fen> but restricted to f = Set
12:29:33 <fen> kind of unsure about just writing fmap in math formulas with set valued arguments
12:31:39 <fen> e.g. given x \in X, and y = f (x) where y \in Y, f : X -> Y. want to write; g(fmap f X)
12:32:06 <fen> g: ? -> ?'
12:34:45 <fen> guess set builder notation would help (seems strange to try and invert the math notation -> haskell notation) {f x | x <- X }
12:36:24 <fen> g(\X -> fmap f X) : X -> (subset Y)
12:36:54 <fen> dont really know any set theory, is this totally wrong?
12:40:05 <fen> given the existence of category theory, this fmap symbol must already exist in maths? just a guess, is it the exponential thing?
12:40:56 <fen> to be clear, whats the symbol for {f x | x <- X } ?
12:45:15 <fen> there is this; https://en.wikipedia.org/wiki/Exponential_object
12:45:22 <fen> but the language is confusing
12:46:52 <Solonarv> fen: in set theory that'soften just written f(X); the fmap is implicit, basically.
12:47:41 <fen> it says the exponential object X^Y is the set of all functions between X and Y. we just want one element of this specified for some function
12:48:19 <fen> Solonarv: thanks, thats helpful. so can we say (f(X) :: X -> Y) \in X^Y ? 
12:49:03 <stevenxl> Hi folks. So I am working off of a book that says mechanically "the rank of a function is simply the number of arrows its deepest forall is to the left of". I have the type signature "b :: (a -> b) -> (forall c. c ->  a) -> b", and when I fully parenthesis that I get "b :: forall a b. ((a -> b) -> ((forall c. (c -> a)) -> b))". So based on that quote, is b rank-1, since forall c is nested to the left of only one arrow?
12:49:05 <Solonarv> if f : X -> Y then f(x) ∈ Y for x ∈ X
12:50:06 <fen> oh so f(X) : ? -> (some subset of Y) ?
12:50:26 <Solonarv> f(X) is abuse of notation for { f(x) | x ∈ X }, so f(X) ⊆ Y
12:50:41 <Henson> hello everyone, I was wondering if there's something like the Show class, but something that works in IO and is able to read and print values inside TVars and other things.  Maybe like showIO :: (ShowIO a) => a -> IO String
12:50:45 <Solonarv> f(X) is (generally) not a function!
12:51:06 <fen> whats the codomain of such an f?
12:52:15 <fen> Henson: why not just fmap show?
12:52:34 <fen> :t fmap show :: Show a => IO a -> IO String
12:52:35 <lambdabot> Show a => IO a -> IO String
12:53:01 <vaibhavsagar> Henson: Debug.Trace?
12:53:02 <Solonarv> f : X -> Y means "f is a function with domain X and codomain Y"
12:53:40 <fen> right, but thats for f taking x ∈ X, we want f(X) taking X ∈ ?
12:54:51 <fen> ? = the set of all sets?
12:56:28 <Solonarv> (going to use different letters for clarity)
12:56:28 <Solonarv> Suppose we have f : A -> B; x ∈ A; S ⊆ A
12:56:28 <Solonarv> Then: f(x) ∈ B
12:56:28 <Solonarv> We use f(S) as a shorthand for { f(s) | s ∈ S }, and we have f(S) ⊆ B
12:56:48 <Henson> fen: I've got a type that includes some records with types in TVars, and I would like to print out a string representation of the type at some time.  I can't put "deriving Show" at the end of it, because TVars have to be read in IO, and show isn't in IO.  I could write my own printing function that works in IO, but then I have to do it manually instead of whatever magic "deriving Show" uses...
12:57:30 <Henson> fen: to print everything out automatically.  I think Generics are a way that I could do the deriving automatically.  But I thought I'd check first to see if there's something obvious I'm unaware of that already does what I want.
12:59:09 <fen> really just want to do g : X -> R (R = the reals), f(X) = {g x | x ∈ X}, then have trouble writing the "type" of f, ie its domain and codomain. maybe its codomain is the set of sets of real numbers and the domain is then the set of sets of x ∈ X
13:00:01 <Solonarv> oh, that's easy
13:00:26 <fen> Henson: but you mean "string representation of the value" not "string representation of the type" ?
13:00:59 <Solonarv> f: P(X) -> P(ℝ)
13:00:59 <Solonarv> where P(S) is the powerset of S, i.e. P(S) = { s | s ⊆ S }
13:01:06 <Henson> fen: yes
13:01:39 <Solonarv> you can also write the powerset P(S) as 2^S or {0,1}^S, if you prefer
13:03:04 <fen> Henson: if you have a datatype that contains IO things, its not going to have a show instance, because it basically is an IO value, and would require an unsafePerformIO to get back to the pure return type of show
13:03:59 <fen> Solonarv: thanks, thats really helpful
13:04:52 <fen> using the powerset is a nice trick, it really just needs to be the one element set {S}, but the powerset also gives the nice extra use for the fact f might be surjective
13:04:54 <fen> awesome
13:08:23 <fen> now its easy to write functions that take infinite continuous sets of unorderable things like shapes, and return the concentration or probability distribution of each value as another set! which means this parametrised version of the continuous set of shapes can be taken as an argument to the time evolution function! 
13:08:30 <fen> brilliant! 
13:11:18 <Henson> fen: yes, that's why I wanted something like showIO.
13:11:27 <Henson> fen: thanks for you help, I have to go.
13:13:28 <dmwit> ?tell Henson One thing you can do is make an analogous "frozen" version of your type that you can derive Show for, plus a `freeze :: MyType -> IO FrozenMyType`.
13:13:28 <lambdabot> Consider it noted.
13:14:44 <dmwit> ?tell Henson e.g. for `data Foo a = Foo { left, right :: TVar a }`, you might write `data FrozenFoo a = FrozenFoo { frozenLeft, frozenRight :: a } deriving Show` and `freezeFoo foo = atomically (liftA2 FrozenFoo (readTVar (left foo)) (readTVar (right foo)))`.
13:14:44 <lambdabot> Consider it noted.
13:22:24 <dmwit> ?tell Henson The advanced version is `data Foo f a = Foo { left, right :: f a }`, which admits `Foo TVar` and `Foo Identity`, to reduce code duplication. 
13:22:24 <lambdabot> Consider it noted.
13:39:53 <fen> Solonarv: wait, if f(X) = {f x | x ∈ X}, then how are we supposed to write functions that take a set and *dont* fmap into it?
13:40:09 <fen> like f : P(X) -> R
13:40:37 <Solonarv> fen: keep in mind that using f(X) to mean { f x | x ∈ X } is merely convenient notation
13:40:55 <Solonarv> If there is ambiguity, don't use it and write { f x | x ∈ X } explicitly
13:41:11 <fen> wouldnt it be better to use the fmap symbol ?
13:41:29 <Solonarv> What fmap symbol? I'm not aware of one in "mainstream" math
13:41:37 <fen> hmmm
13:41:47 <fen> nothing from category theory?
13:41:57 <fen> to lift it into the set functor?
13:42:26 <Solonarv> It's usually pretty clear whether f( <whatever> ) is "f applied to a single element" or "the image of some set under f"
13:43:28 <fen> yeah, its the case "f applied to every element" that isnt so common
13:43:49 <fen> we have vectors for something close, but only when the set is "indexed by naturals"
13:45:17 <Solonarv> for vectors we often use the same abuse of notation, where we write f([x y z]) instead of [f(x) f(y) (f)z)]
13:45:17 <Solonarv> (goes for column vectors & matrices too but those are a pain to write in IRC)
13:45:35 <fen> then eg \vec{\dot{x}} = f (vec{x}) can be written componentwise as \dot{x_i} = f (x_i)
13:46:28 <fen> there is nothing similar for when this `i' index drawn from some arbitrary set, like as an index for "shape indexed sets"
13:47:36 <fen> so whats the concept of vectors but for index other than naturals?
13:48:15 <fen> like if we want to use different shaped trees as indexes
13:48:29 <fen> and there might not be a natural way to order them
13:48:43 <Solonarv> you can just do that, no special magic necessary
13:49:14 <fen> \dot{x_i} = f (x_i), i ∈ I ?
13:49:29 <fen> probably should be f_i too
13:49:32 <Solonarv> mathematical notation is way more flexible than programming languages, because the argument "obviously it has to mean *this* and not *that*" actually works
13:49:45 <Solonarv> I'm not sure what \dot{foo} is supposed to be
13:49:49 <koz_> Plus, mathematics is read by a human, not a compiler.
13:49:51 <fen> time derivative
13:50:44 <Solonarv> koz_: yes, that's why the "obviously, ..." argument works :p
13:50:58 <fen> sure, people will understand it if its explained, but maths is so thorough its likely the terminology is established and then there is no need to reinvent the wheel, but instead, to find what its actually called 
13:51:01 <Solonarv> fen: oh! yes, that's perfectly valid
13:52:51 <fen> \dot{x_i} = f_i (X), i ∈ I, x_i ∈ X, f_i : P(X) -> X 
13:53:15 <fen> still, not sure if the _i should actually be written as another argument to the function...
13:54:41 <fen> \dot{x(i)} = f (i,X), i ∈ I, x ∈ (I,X), f : (I,P(X)) -> X
13:55:55 <nshepperd_> fen: functions? Strictly speaking functions are already vectors
13:56:00 <fen> guess normally the subscript is used for summation convention for tensor contraction, but here its using nonlinear functions instead of matricies anyway
13:56:37 <nshepperd_> In terms of notation nothing stops you from putting non integer indexes in a subscript
13:56:39 <fen> nshepperd_: oh, thats interesting. hows that? something to do with pairing the inputs and outputs?
13:57:58 <fen> ah, just as the index can be used as another argument, the argument can be thought of as an index... hmmm
13:57:59 <nshepperd_> With lifted 0, + and * using the function Applicative
13:58:31 <fen> what!?
14:00:01 <nshepperd_> Specifically pure 0 for zero, liftA2 (+) for vector addition, \a v -> fmap (a*) v for scalar multiplication
14:00:46 <nshepperd_> In haskell terminology. A mathematician wouldn't describe it like that
14:03:06 <fen> ok kind of get that
14:04:41 <fen> oh right, it uses the applicative instance so that arbitrary lengths can be mixed together
14:04:54 <fen> making scalars and vectors alike, which is confusing
14:04:59 <nshepperd_> https://en.wikipedia.org/wiki/Vector_space#Function_space
14:05:37 * hackage enum-text 0.1.0.0 - A text rendering and parsing toolkit for enumerated types  https://hackage.haskell.org/package/enum-text-0.1.0.0 (ChrisDornan)
14:05:39 <nshepperd_> Lengths?
14:06:16 <fen> nshepperd_: yeah, the wiki article neatly glosses over the "zero" case, where you use a scalar
14:06:47 <nshepperd_> Oh, you just use const for 0
14:08:09 <fen> your still using the non-diagonal applicative then, otherwise it would be repeat..
14:08:19 <nshepperd_> Same as the zero vector in R^4 is [0,0,0,0], the zero vector in R->R is const 0
14:08:27 <fen> and yeah, const isnt a great additive identity
14:08:42 <nshepperd_> Ie. It returns 0 for every index
14:09:40 <fen> isnt the idea to move from R though? or even R^n
14:09:56 <fen> so that the general applicative constraint is doing the heavy lifting here
14:10:30 <fen> then is it that Sets are applicative?
14:10:53 <fen> since we want functions that can act on values in some set, and also functions that can act on whole sets
14:11:06 <nshepperd_> So vector addition of (\x -> sin x) and (\x -> 0) gives you (\x -> sin x + 0) = (\x -> sin x) as expected
14:11:39 <fen> sin x + const x
14:11:41 <fen> ok
14:11:55 <fen> no wait
14:12:07 <nshepperd_> sin x + const 0 x
14:12:15 <fen> yeah
14:12:50 <fen> does that mean we can write this idea of taking whole sets as inputs to a function in haskell using the applicative constraint?
14:13:18 <fen> probably of the powerset
14:13:36 * hackage taskell 1.3.6.0 - A command-line kanban board/task manager  https://hackage.haskell.org/package/taskell-1.3.6.0 (smallhadroncollider)
14:13:36 <nshepperd_> No idea. I was just addressing the "what if there were vectors indexed by things other than integers" question
14:13:47 <fen> cool
14:14:21 <fen> yeah, dont really like the idea of trying to understand what a type level powerset is!
14:14:54 <fen> nshepperd_: so how does the idea of applicative fit in with that?
14:15:31 <fen> by completely abstracting away the idea of the index?
14:16:56 <fen> oh, it was that "functions are already vectors" 
14:18:00 <fen> not sure how being able to add multiply and have id of the underlying field (them being vectors) has anything to do with them having non_Natural index...
14:18:57 <Solonarv> fen: I^F is a vector space for *any* set I and *any* field F
14:19:46 <wroathe> Is there a mathematical analog to the arrow operator we use to define function types in Haskell?
14:19:49 <Solonarv> for a simple example, ℝ^ℂ is a vector space, even though ℝ is in no way natural-ish!
14:20:09 <Solonarv> wroathe: yes, several in fact
14:20:16 <zachk> wroathe, I have seen mathematcians use f : A -> B as well 
14:21:30 <wroathe> In particular I'm curious about how mathematicians deal with arity > 1
14:21:46 <Solonarv> wroathe: tuples, usually
14:21:50 <fen> they seem not to really do the currying properly
14:22:09 <Solonarv> (or more properly, cartesian/tensor products)
14:22:20 <wroathe> The fact that an arrow is right associative has far reaching implications that's just now sinking in for me as I'm playing around with more complicated forms of composition
14:22:48 <fen> like everything is maximally uncurried for ease of reading proberly
14:23:18 <Solonarv> e.g. in set theory we have gcd : ℕ × ℕ → ℕ
14:23:46 <fen> Solonarv: still slightly confused about this tangent into vector spaces when talking about functions and what meaning it has
14:24:02 <Solonarv> if you need the partially-applied version you just write something like gcd(5, -) and it will be clear what you mean
14:24:18 <fen> yeah they do that for marginals too
14:24:38 <fen> meaning integration over one of the variables and leaving the other partially applied
14:25:13 <wroathe> What would be the notation for saying that a function returns a function in lambda calculus?
14:25:44 <fen> you just put the lambdas on the left?
14:26:03 <wroathe> Sorry, I'll google. Ignore me.
14:26:22 <fen> ie write it as though it was a function over all the arguments that would be needed by the function returned
14:28:03 <Solonarv> wroathe: you just write another lambda as the body of the outer lambda
14:28:59 <fen> Solonarv: just kind of intrigued by the idea of currying and this vector space of exponential maps
14:29:55 <fen> so all the inputs can be either uncurried or left as functions
14:30:29 <fen> have worked with that idea so much in haskell, never really thought how it might apply to maths
14:31:26 <fen> you cant uncurry the last thing though? the output needs to still be a function
14:31:46 <fen> or is a function just a pairing of sorts, between inputs and outputs
14:33:12 <fen> maybe if you cant uncurry the output at least you can curry all the inputs, but returning functions over the rest of the arguments from the first argument inst really a maths thing, unless thats kind of what the subscript thing is doing
14:33:35 <fen> for the index
14:34:34 <fen> huh, this is all really interesting, might write some better equations... though it seems to add a "design choice" aspect to it, wheras these stylistic choices are normally taken for granted
14:35:44 <fen> might stick with the index as a subscript and just have it over an arbitrary set, thats enough of a useful idea to work with for now, never mind currying and uncurrying the index to be an argument of the function or visa versa
15:23:43 <Guest88> Hi, I'm having trouble using GADT's with record syntax. I keep getting a parse error on '{'
15:28:24 <Solonarv> Guest88: can you post your actual code? preferably using some paste site.
15:31:37 <Guest88> Ok will do, just isolating it to something small
15:34:07 <Guest88> https://pastebin.com/Hq2nDHUd
15:34:39 <Guest88> I got it from here https://downloads.haskell.org/~ghc/6.6/docs/html/users_guide/gadt.html
15:44:14 <int-e> JoeCordingley: ghc-6.6 is really old, and the syntax has changed: Lit :: { var :: Int } => Term Int  (see https://downloads.haskell.org/ghc/8.4.4/docs/html/users_guide/glasgow_exts.html#generalised-algebraic-data-types-gadts )
15:45:19 <int-e> (hmm not sure why I'm using the ghc-8.4.4 docs and not the ghc-8.6.4 ones)
15:45:36 * hackage mattermost-api 50200.1.2 - Client API for Mattermost chat system  https://hackage.haskell.org/package/mattermost-api-50200.1.2 (JonathanDaugherty)
15:45:49 <int-e> JoeCordingley: and sorry, the => should be ->
15:46:01 <JoeCordingley> I tried -> and => too, both return the same error
15:46:10 <JoeCordingley> it complains on the first {
15:46:20 <int-e> JoeCordingley: note the :: after the "Lit"
15:46:37 * hackage matterhorn 50200.2.0, mattermost-api-qc 50200.1.2 (JonathanDaugherty): https://qbin.io/levy-sake-jy7k
15:46:49 <JoeCordingley> Ah that got it. Thanks!
15:47:28 <hpc> who picked that version number lol
15:47:46 <Solonarv> I'm sure there's a good reason
15:48:13 <glguy> It's probably linked to the matched upstream version of Mattermost
15:48:32 <hpc> oh, so there is
15:48:36 <hpc> and it's that
15:51:43 <Yukkuri> hi, how to express `map (^2) [1,2,3,4]` in math symbols? my naive approach was `[∀x∈[1,2,3,4] ⇒ x^2]`, but i'm not sure about two things: ∀ looks like it might screw order and if result of this expression would be new list constructed
15:51:51 <Yukkuri> i wonder if there is any math syntax checkers
15:52:58 <Yukkuri> and i would like to avoid explicit iteration with ∑ on overloaded list addition.
15:55:21 <c_wraith> math doesn't have one notation. it has thousands of them, usually determined from context.
15:55:33 <Yukkuri> eeeeh
15:55:39 <Cale> Yukkuri: What do you mean by "in math symbols"? That notation you've chosen isn't a common one
15:55:39 <Yukkuri> how do they work then?
15:56:24 <Yukkuri> well, i am looking for an equivalent of mapping operation
15:56:36 <johnw> I think it's just called a function, no?
15:57:10 <Yukkuri> what about application of a function to every element of the collection and outputing the result as the collection of elements, that are returned by mapped function?
15:57:33 <Cale> Yukkuri: You could just say f (x_1,...,x_n) = (f x_1,...,f x_n) somewhere and then use that notation.
15:57:36 <johnw> I think ∀x∈{1,2,3,4}, f = x ↦ x², f x
15:58:10 <Cale> Or you could define some sort of operator which acts on f to make it map over the tuples you're working with.
15:58:20 <Cale> It's unusual to talk about "lists" in mathematics at all.
15:59:08 <int-e> Yukkuri: but maybe you don't have lists in mind anyway... {x^2 | x in {1,2,3,4}} would be the set {1,4,9,16}.
15:59:13 <Cale> If you're actually dealing with sets, then you could write a set comprehension {x^2 | x ∈ {1,2,3,4}}
15:59:24 <Solonarv> Or you could just wave your hands, whisper "notation!", and write f({1, 2, 3, 4})
15:59:31 <Yukkuri> can this represent something like [1,2,2,2] ?
15:59:39 <Yukkuri> or is it exactly limited to unordered sets?
16:00:31 <Solonarv> It can represent whatever you want. There are no fixed rules, you're just usually trying to make sure the reader understands what you mean clearly.
16:01:35 <Yukkuri> then why they just not using code?
16:01:46 <Yukkuri> it has well-defined syntax and semantics
16:01:58 <Yukkuri> everyone would understand that
16:02:16 <Solonarv> I mean, some do
16:02:35 <hpc> which language lets you express everything in math? ;)
16:02:45 <Solonarv> But many mathematical objects can't really be represented in typical programming languages, so there's not much of a point
16:02:56 <Cale> hpc: English ;)
16:03:15 <Solonarv> Cale: no, LaTeX
16:03:15 <Yukkuri> well, there is always APL
16:03:17 <Solonarv> ;)
16:04:23 <Cale> Yukkuri: The important thing to understand is that mathematics is usually written for other humans to read, not computers
16:04:47 <Cale> So, we use symbolic notations only when we feel it's the best way to convey our ideas
16:04:53 <Yukkuri> and humans better understand things that can be documented
16:05:01 <Yukkuri> rather some obscure voinich glyphs
16:06:40 <Cale> So if you like, you can just say "let f(L) be the list obtained by applying f to each of the elements of the list L"
16:06:47 <Cale> and most people would understand that
16:07:23 <Cale> If you don't like overloading the meaning of f in that way, you can invent some other bit of syntax, like putting a hat on f or something.
16:07:58 <Solonarv> or you can just write "let map(f, L) be the list obtained by applying f to each element of the list L", even
16:08:11 <Cale> Indeed
16:08:17 <Solonarv> no sigils, no overloading, perfectly understandable
16:08:19 <Cale> Or map f L
16:08:20 <c_wraith> hence my statement that math has thousands of notations.
16:08:34 <c_wraith> people just write whatever
16:08:39 <Solonarv> Thousands? Surely there are more mathematicians than that on earth
16:08:59 <c_wraith> lots of thousands. :)
16:11:58 <Solonarv> whoa, estimates vary wildly
16:12:07 * hackage txt 0.0.3.0 - Text  https://hackage.haskell.org/package/txt-0.0.3.0 (MatthewFarkasDyck)
16:13:56 <Solonarv> according to this mathoverflow question [1] I'm not comfortable giving a tighter bound than 30k ± an order of magnitude
16:13:56 <Solonarv> [1] https://mathoverflow.net/questions/5485/how-many-mathematicians-are-there
16:46:07 <oo_miguel> Solonarv: about 3-300k mathematicians exist? or what do you mean by +/- order of magnitude :) ? Excuse my question, but I am not a mathemtician myself. 
16:49:14 <Solonarv> yep, that's what I meant
16:49:39 <Solonarv> I am also not a mathematician ;)
17:00:23 <oo_miguel> heh, quite generous margin of error ;)
17:13:16 <mniip> @djinn ((((A -> Void) -> B) -> ((A -> Void) -> B -> Void) -> A) -> Void) -> Void
17:13:17 <lambdabot> Error: Undefined type A
17:13:27 <mniip> @djinn ((((a -> Void) -> b) -> ((a -> Void) -> b -> Void) -> a) -> Void) -> Void
17:13:27 <lambdabot> f a =
17:13:28 <lambdabot>     void (a (\ _ b ->
17:13:28 <lambdabot>              void (a (\ c ->
17:13:28 <lambdabot>                       void (b (\ d -> a (\ _ _ -> d)) (c (\ e -> a (\ _ _ -> e))))))))
17:13:45 <mniip> ಠ_ಠ
17:17:20 <Solonarv> what's that? Not (Not ((Not a -> b, Not (Not a, b)) -> a)) ?
17:18:48 <mniip> consider classical hilbert style sequent calculus
17:19:08 <mniip> the LEM is formulated as (~ A -> B) -> (~ A -> ~ B) -> A
17:19:15 <mniip> this is the double negation encoding of that
17:21:00 <Solonarv> oh, makes sense
17:21:50 <Solonarv> I saw the double negation and had an inkling that LEM would be involved but was too lazy to work out how exactly :p
17:54:37 * hackage enum-types 0.1.1.0 - small enum types  https://hackage.haskell.org/package/enum-types-0.1.1.0 (andrewthad)
17:55:36 * hackage line-bot-sdk 0.4.0.0 - Haskell SDK for LINE Messaging API  https://hackage.haskell.org/package/line-bot-sdk-0.4.0.0 (moleike)
18:00:37 * hackage possibly 1.0.0.0 - type Possibly a = Either String a  https://hackage.haskell.org/package/possibly-1.0.0.0 (ChrisDornan)
18:02:06 * hackage enum-utf8 0.1.0.0 - An experimental Utf8 parsing toolkit for enumerated types  https://hackage.haskell.org/package/enum-utf8-0.1.0.0 (ChrisDornan)
19:16:07 * hackage liboath-hs 0.0.1.1 - Bindings to liboath  https://hackage.haskell.org/package/liboath-hs-0.0.1.1 (parsonsmatt)
19:17:30 <mniip> @djinn (((a -> b) -> Void) -> Void) -> ((a -> Void) -> Void) -> (b -> Void) -> Void
19:17:30 <lambdabot> f a b c = void (b (\ d -> void (a (\ e -> c (e d)))))
19:22:07 * hackage persistent-typed-db 0.0.1.1 - Type safe access to multiple database schemata.  https://hackage.haskell.org/package/persistent-typed-db-0.0.1.1 (parsonsmatt)
19:30:06 * hackage stratosphere 0.34.0 - EDSL for AWS CloudFormation  https://hackage.haskell.org/package/stratosphere-0.34.0 (jdreaver)
22:19:11 <pyggins> Hello, I have a question regarding some haskell code that I've been trying to get working. I have uploaded the code to http://dpaste.com/1D043VB . When I try to compile it, it gives me the logs at http://dpaste.com/0YQTW9Y .
22:19:44 <pyggins> I have tried to make a "Vector" typeclass, but there appears to be something wrong with how I've instantiated it.
22:20:17 <pyggins> I've just noticed that this channel uses a different paste service, should I re-upload my code/logs there?
22:20:49 <pyggins> Any assistance would be greatly appreciated.
22:25:32 <kaol> GHC doesn't know that the Num n on line 4 is the same one as on line 17. I think you would need to use a class Vector v n.
22:26:25 <ion> Try this: class Vector v where { dot :: Num n => v n -> v n -> n; ... }
22:26:53 <kaol> Or that.
22:31:20 <pyggins> Thank you, I will try that.
22:32:42 <pyggins> Should I change the Vec2D instance statement as well?
22:36:39 <pyggins> So I changed the class declaration to have v n instead of v and I changed the instance accordingly (I also put Num n where applicable), it is giving me a new set of errors now.
22:36:48 <pyggins> I will upload the code/logs shortly.
22:38:36 <pyggins> Updated code: http://dpaste.com/3A17HYB , updated output: http://dpaste.com/3650MM8
22:40:09 <pyggins> I see that I didn't update zero correctly, though even when I have added Num n to the type signature, it still gives the same errors.
22:40:37 <pyggins> The errors suggest adding Num n to the functions in the instance, but that is already in the typeclass.
22:41:56 <pyggins> Also, it suggests to add Floating n, but isn't that a subset of Num n?
22:44:24 <Lears> It may be a subclass, but you'd need it to be a superclass in order to have it, given Num n.
22:47:29 <pyggins> I see, I have updated the type signatures to have Floating n and RealFloat n where applicable and it works now.
22:47:48 <pyggins> It seems I didn't quite understand how type constraints work.
22:47:54 <pyggins> Thank you for your help.
22:52:41 <ion> pyggins: One way to think about "dot :: Floating n => Rec2D n -> Rec2D n -> n" is that "Floating n" is an additional parameter to the function that the compiler passes to it implicitly, and it comes with a record of functions such as "cos" which you then use in the definition.
22:54:49 <ion> Each instance of Floating (such as Double) has its own record which includes an implementation of cos.
22:57:56 <pyggins> I see, so the Num constraints were not working because they allowed the possibility for an argument to be passed that would not work with cos?
22:58:34 <pyggins> So Floating/RealFloat needed to be used to maintain compatibility with cos/sqrt/other floating point functions.
23:13:53 <ion> The function has no cos to call otherwise, it eventually receives it through the typeclass constraint.
23:18:25 <pyggins> I see
23:18:37 <pyggins> Well, thank you for your help and explanation.
23:51:41 <dtnsb> Howdy, #haskell. I'm trying to solve project euler problem 3, which requires finding all the prime factors of a very large number (600851475143). I can do this imperatively very fast, but I don't know how to create an allagory for that in haskell.
23:53:22 <Rembane> dtnsb: Do you have any code in Haskell?
23:53:25 <kadoban> dtnsb: Which part don't you know how to do in haskell?
23:54:09 <dtnsb> Here's the solution I have now, I don't know if it works cause  it takes too long: https://pastebin.com/HP1fD93J
23:55:14 <dtnsb> My solution which I wrote in python finds factors by stopping at the square root, and adds both the factor and its partner factor... which is much faster.
23:56:16 <kadoban> dtnsb: What was your 'isPrime' test in python?
23:56:28 <dtnsb> if factors = [1,n]
23:56:41 <dtnsb> Cause my factors function was pretty fast
23:57:05 <kadoban> So no sieve, just trial division?
23:57:37 <davean> dtnsb: Tried putting types on those functions?
23:57:47 <davean> Also I'll note you don't have it stopping at the square root
23:58:53 <kadoban> You can get a list of numbers stopping at the sqrt with something like: takeWhile (\i -> i * i <= x) [1..] 
23:58:59 <kadoban> Slightly naive, but it should work
23:59:15 <dtnsb> davean: I haven't put types, but that wouldn't improve the runtime much I don't believe
23:59:23 <davean> dtnsb: oh but you should try it ;)
23:59:33 <dtnsb> As a side note, is it generally good practice to type functions?
23:59:36 <kadoban> It's going to default to Integer. Int would be faster, and is good enough if you're on 64 bit
23:59:38 <davean> Definately
23:59:50 <davean> Right, Integer is infinite sized
23:59:53 <kadoban> Yes, usually every top-level definition gets an explicit type
