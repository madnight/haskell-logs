00:01:08 * hackage shh-extras 0.1.0.1 - Utility functions for using shh  https://hackage.haskell.org/package/shh-extras-0.1.0.1 (lukec)
00:15:23 <nfd> is anyone aware of a tool like Linda for Haskell?
00:15:23 <nfd> https://en.wikipedia.org/wiki/Linda_(coordination_language)
00:15:41 <nfd> figured i'd at least ask before running off and trying to implement it
00:16:11 <nfd> oh, dang
00:16:11 <nfd> https://github.com/bgaster/hlinda
00:16:48 <[exa]> oh great :]
00:17:16 <p0a> wow that was fast
00:19:24 <gentauro> nfd: what is it useful for?
00:19:48 <gentauro> (Linda)
00:19:55 <nfd> I'd been looking around on hackage/stackage/googling and had never thought to github search, hahaha
00:20:33 <nfd> gentauro: in essence, synchronization, coordination, data passing, or all of the above
00:21:49 <gentauro> nfd: distributed system?
00:21:51 <nfd> the general idea is there's just a bag of tuples sitting there. you commit tuples to the space, and they may be removed by anyone who knows how to patternmatch for them
00:22:00 <nfd> sure, you could use it for distributed systems
00:22:12 <nfd> maaaaaaybe isn't the most efficient primitive at all, but it'd work
00:22:36 <nfd> for like 4 months or so I've been sitting on this idea for tuplespace-oriented programming
00:22:54 <nfd> so i'm trying to get started writing an esolang
00:23:05 <p0a> I don't get how to do this exercise 
00:23:26 <gentauro> nfd: cool
00:23:29 <nfd> but i've never implemented a programming language more complicated than bf before, and i haven't taken on so many big haskell projects
00:23:42 <nfd> but now that i'm graduated, i guess i have nothing but time
00:23:50 <p0a> said noone ever
00:24:11 <gentauro> I'm actually working with MVar and I'm getting this a lot `client: thread blocked indefinitely in an MVar operation` so I'm doing something wrong for sure xD
00:24:38 <nfd> i just started learning MVar tonight, haha
00:24:56 <p0a> This is the exercise: Rewrite the function to use incremental transformations https://pastebin.com/8Ak08FQ5
00:25:07 <gentauro> I'm using `Neil Mitchells` Queue -> http://neilmitchell.blogspot.com/2012/06/flavours-of-mvar_04.html
00:25:17 <p0a> I have no idea how to do this. I clearly need an `if' clause of some sort to distinguish between the even/odd behavior 
00:27:06 <gentauro> p0a: what are you trying to achieve?
00:27:16 <gentauro> fun2 is not really saying anything ...
00:27:38 <p0a> gentauro: well just to rewrite fun2 really. somehow using functions like `sum', `filter', `iterate', `takeWhile', etc. 
00:27:42 <p0a> gentauro: well, I agree...
00:27:46 <nfd> gentauro: is there any chance that it could be proven that nothing will even be committed to that MVar again?
00:28:10 <nfd> like all other threads that were connected to it died or also were "blocked forever"
00:28:12 <p0a> gentauro: for example I was able to rewrite the previous exercise, which multiplied the even numbers in a list only, as fun1 xs = foldr (\x y -> (x-2)*y) 1 $ filter even xs 
00:28:20 <p0a> (the -2 is there because that was the formula the exercise had)
00:28:38 <gentauro> nfd: The trick with `MVar` in order to obtain `atomicity` is to instantiate it as and `empty value` and just `read` from it
00:28:56 <p0a> gentauro: whereas the original solution was recursive with an `if' clause
00:29:38 <gentauro> once a `MVar` is populated, all readers will be notified and will recieve the value
00:29:43 <nfd> yeah
00:29:51 <gentauro> it's only atomic if one updates
00:30:48 * ski . o O ( `SampleVar' )
00:31:31 <nfd> gentauro: i thought an MVar would wake up exactly one taker
00:31:33 <gentauro> p0a: in your patternmatch, you match `even n`, then you ensure that `otherwise` will be `odd`
00:31:37 <gentauro> it's basic math
00:31:57 <gentauro> so it's the equivalent to write `if even x then .. else ..`
00:32:03 <gentauro> so catch all cases
00:32:07 <nfd> anyway, if you're getting a "blocked indefinitely" error, it could be proven at runtime that the mvar would never be populated again
00:32:13 <p0a> gentauro: not sure I follow you 
00:32:15 <ski> nfd : Linda is a neat idea. perhaps you'd be interesting in checking out the CLP system called CHR, for Prolog ?
00:32:26 <nfd> ski: link me!
00:32:41 <p0a> gentauro: the exercise is to rewrite fun2 using `incremental transformations that operate on the data structure'
00:32:47 <ski> (it has some similarities, but the "tuples" in this case are "active", like reactive molecules combining and so on)
00:32:47 <p0a> or something like that
00:32:49 <nfd> i wanna bust out this esolang and send it to one of my old CS professors so he can be a dork about it in lecture in the future, haha
00:33:08 <gentauro> p0a: is this a school task or HackerRank?
00:33:24 <ski> nfd : <https://dtai.cs.kuleuven.be/CHR/>
00:33:29 <nfd> thanks
00:34:13 <p0a> gentauro: it's a upenn course I'm doing solo
00:34:44 <gentauro> p0a: roger that
00:34:49 <ski> (it's especially nice to have Linda in Prolog, since you can use ordinary (partially instantiated) Prolog terms as patterns for reading and grabbing)
00:34:56 <p0a> gentauro: If you don't see how to do it, then probably it's not important. I was curious if there was an obvious solution I'm missing
00:35:15 <gentauro> p0a: I think I'm missing `context` ;)
00:35:58 <p0a> gentauro: exercise 1, part 2. http://www.cis.upenn.edu/~cis194/spring13/hw/04-higher-order.pdf
00:36:06 <p0a> gentauro: if you're interested, take a look 
00:37:31 <nfd> hah, i oughta pick up some prolog eventually
00:37:39 <nfd> never personally used any logical languages yet
00:38:07 <nfd> nor array-based; i've yet to descend to that level of gremlin
00:38:10 <nfd> someday soon...
00:38:37 <gentauro> p0a: sure, I'll take a loo
00:38:42 <p0a> nfd: array based?
00:39:36 <nfd> like APL
00:40:58 <nfd> i guess i've used a little Ada, a little MATLAB, and a little R
00:41:12 <nfd> i was terrible at getting the hang of MATLAB though
00:42:43 <wuffie> in gtk2hs, how do i cast a GObject into a ListStore?
00:43:07 <nfd> p0a: fun stuff like this: life←{↑1 ⍵∨.∧3 4=+/,¯1 0 1∘.⊖¯1 0 1∘.⌽⊂⍵}
00:43:11 <wuffie> there doesnt appear to be any castToListStore method
00:43:26 <nfd> which would be how to make the next generation in a Game Of Life board
00:43:30 <wuffie> i can cast it into a TreeModel but how do i get a ListStore from there?
00:43:31 <gentauro> nfd: APL is horrible xD
00:47:33 <kuribas> is it bad practice to use unsafePerformIO for labeling expressions unique?
00:48:08 <kuribas> I was trying to find a way to compile an applicative expression to a state machine, but I see no other way to detect a fixed point, than to use unsafePerformIO.
00:49:44 <kuribas> like how would you know that "many p = pure [] <|> (:) <$> p <*> many p" is equal to star?
00:49:48 <gentauro> p0a: my brain this early is not suited for solving those problems ;)
00:50:23 <gentauro> p0a: but you might try to reach of to some papers explaining `wholemeal programming` with regard of Haskell
00:50:53 <p0a> gentauro: thank you 
00:51:06 <p0a> gentauro: that's a good idea. 
00:51:13 <p0a> well, gotta go now!
00:51:24 <kuribas> it seems that recursion spoils the nice features of regular languages...
00:53:20 <kuribas> I could make a custom Y combinator, but nothing would prevent people from using normal recursion
00:58:39 <ski> kuribas : perhaps there should be a nice syntax in which to write such DAGs in, possibly expanding to code generating I-vars
00:59:00 <kuribas> ah, I see that many is part of the typeclass, so it can be specialized!
00:59:16 <nfd> kuribas: which typeclass?
00:59:29 <ski> iirc, the Earley parser uses some kind of tagging for cycles, perhaps you could check that
00:59:31 <nfd> that just looks like the parser-combinators definition, yeah?
00:59:34 <kuribas> nfd: Alternative
00:59:41 <nfd> gotcha
00:59:56 <nfd> and that's a re-export so
01:00:07 <kuribas> ski: I also looked at regex-applicative, but that's not linear time, is it?
01:00:13 <ski> dunno
01:00:23 <nfd> kuribas: do you mean how we know it's equivalent to the Kleene star?
01:00:28 <kuribas> nfd: yeah
01:00:48 <ski> Matlab is an array-based language, i suppose. but a horribly designed language, from a programming languages viewpoint
01:00:50 <nfd> seems pretty straightforward to me
01:00:50 <kuribas> nfd: but since many is part of the typeclass, you can just define it as Kleene star :-)
01:00:58 <kuribas> nfd: problem solved :)
01:01:34 <nfd> if you're doing unsafe side effects off an Applicative, it sure would hurt some of Applicative's nice properties
01:01:48 <nfd> like being easily parallelizable 
01:02:03 <nfd> sounds like it'd be begging for trouble
01:02:09 <ski> (come on, why can't i say `f(x)[i,j]' instead of having to say `M = f(x);' and then `M[i,j]' .. also, you can't use statements in lambdas (which they finally added, after having some horrible `eval' thing that took a string))
01:02:19 <kuribas> nfd: is parallelizable a property of Applicative?
01:02:43 <kuribas> ski: there is julia, which is supposed to be better and faster
01:02:59 <kuribas> and python, which isn't that much better though
01:03:11 <ski> iiuc, Octave is more or less attempting to be bug-for-bug compatible, yes ?
01:03:16 <nfd> no, but it's a natural consequence of how Applicative operations are supposed to be associative (and no data dependency issues)
01:03:17 <nfd> ski: yeah
01:03:21 * ski hasn't looked at Julia
01:03:48 <nfd> kuribas: if you're doing unsafe side effects, how do you know that (<*>) is associative?
01:04:13 <ski> (also, it's ridiculous that one, in an array language, can't generically index a tensor with a vector, without lexically knowing the length of the vector (the dimension/rank of the tensor))
01:04:45 <ski> (well, you can, if you do some horrible conversion into cell arrays, that noone would write voluntarily)
01:05:26 <kuribas> nfd: well, the side effects shouldn't break referential transparency.  But as I said, there isn't any need for it, because I can define many as Kleene star.
01:06:32 <ski> kuribas : are you implementing intersection, union, subtraction, division (aka derivative) ?
01:07:25 <ski> (division from the left, specifically, which can be used for checking acceptance, iirc)
01:07:37 <kuribas> ski: no, I was looking if it's possible to compile an applicative regular expression to a DFA
01:08:23 <kuribas> ski: how would that help?
01:08:23 <ski> why do you need to support recursion ?
01:08:29 <kuribas> ski: I don't
01:09:32 <ski> iirc, you can, via division, feed one token at a time, reducing a regex to what's left to recognize
01:09:56 <ski> hm .. it may be that this could be used to determine the DFA
01:10:07 * ski doesn't recall details really :/
01:10:16 <kuribas> what's the derivative of a regex?
01:10:34 <kuribas> union is <|> ?
01:10:44 <ski> yea
01:10:57 <ski> (but intersection, and subtraction, is often really handy as well)
01:11:32 <kuribas> how would that work for an applicative though?
01:11:50 <kuribas> they'd need to be the same type?
01:11:56 <ski> same type as `(<|>)'
01:11:57 <ski> yep
01:12:45 <ski> say `t \ R', aka `d t \ d R' (or `D_t R'). then whenver `R' accepts word `[t] ++ w', then `t \ R' accepts word `w' (and no other words)
01:14:51 <ski> the general case, when the divisor can be an arbitrary regex, rather than just a single token, say in terms of languages instead, is (iirc) `S \ R = {u | forall v. v in S => (u ++ v) in R}'
01:15:41 <ski> `(S \)' is a right adjoint to `(S *)' (where `S * R = {v ++ u | v in S /\ u in R}' is concatenation/multiplication)
01:16:37 <ski> the adjunction meaning that `S * R =< T  <=>  R =< S \ T'
01:19:36 <ski> anyway, for derivative/division, you get rules like `d t \ d (R * S) = (d t \ d R) * S', in case `R' is not nullable, otherwise `d t \ d (R * S) = (d t \ d R) * S + d t \ d S'
01:20:25 <ski> this looks like some variant of Leibniz rule for differentiation of a product, which i suppose is why this is called regexen derivatives
01:22:21 <ski> (where "nullable" means that it contains/accepts the empty word. term is used in bottom-up parsers like e.g. LALR)
01:23:05 <ski> (the special case above is btw just an optimization. the "otherwise" case could handle all cases)
01:27:44 * ski is reminded of the `DIVIDE' (⌜÷⌝) operation in relational algebra, which has a similar feel. it's (obviously) also a right adjoint of a multiplication)
01:29:20 <ski> (<https://en.wikipedia.org/wiki/Relational_algebra#Division_(%C3%B7)>)
01:29:28 <kuribas> cool
01:31:16 <kuribas> neat, all words over an alphabet are a free monoid
01:31:29 <kuribas> over concatenation
01:31:44 <ski> yes, `[]'/`List' is the free monoid over a set
01:34:55 <ski> (and the free (say real) vector space over a set `B' is a vector space `|R^(B)' having the elements of `B' as basis. if the number of elements of `B' is `n', then this is just the plain old familiar `n'-dimensional vector space `|R^n'. the brackets in `|R^(B)' indicate that if `B' is infinite, then we only consider the functions from `B' to `|R' which have "finite support", has output zero for all but finitely many inputs (base vectors) in `B'
01:35:27 <ski>  a linear combination of base vectors is always finite, even if you have an infinite basis. this is because we get an inductive construction, not a coinductive one)
01:38:43 <gentauro> sshine: hey, you participated at FPComples `rio` seminar right? Ho was it?
01:59:55 <gentauro> s/Ho/How
02:17:56 <dariodsa> Can anyone suggest me a Haskell library which has the functionality like "msgget" and "msgsnd" , System V message queue.
02:44:37 * hackage reanimate 0.1.1.0 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.1.1.0 (DavidHimmelstrup)
02:44:38 <sternmull> is anyone using vscode and defined a tasks.json to build with stack? I keep getting nondeterministic rebuilds to to stack seeing "flags changed" and sometimes it even claims a dependency is not installed. All very strange. Never saw such problems when building on the commandline.
02:50:38 * hackage reanimate 0.1.2.0 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.1.2.0 (DavidHimmelstrup)
02:59:50 <oo_miguel> hmmm, should getting a value from an "UArray Int Word8" via (!) be not as fast as using "peek" via "withForeignPtr" on a ByteString. Or is it expected that the second approach is many many times quicker. (beacuse this is what I seem to experience)
03:00:50 <oo_miguel> but I hope I am doing something wrong in the first scenario
03:04:49 <byorgey> oo_miguel: (!) does bounds checking on the index, try using unsafeAt from Data.Array.Base perhaps?
03:12:49 <oo_miguel> byorgey: thanks, I ll try
03:18:50 <oo_miguel> byorgey: wow this results in a factor 10 speedup indeed, thank you very much!
03:19:16 <oo_miguel> closely matches the performance of the solution with the pointer (for my use case)
03:19:38 * hackage reanimate 0.1.4.0 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.1.4.0 (DavidHimmelstrup)
03:45:41 <Rembane> Good morning, are there any special tricks for how to build Haskell packages with C dependencies on Arch Linux? 
03:46:08 <Rembane> I need to build a package using GHC 8.0.2, so I can't use nix. 
03:47:42 <cocreature> Rembane: you shouldn’t need any special tricks. what problem are you running into?
03:47:59 <cocreature> also you probably shouldn’t use GHC 8.0 but presumably something is keeping you from upgrading :)
03:51:52 <cocreature> you should be able to use nix if you want but you might have to use an older version of nixpkgs or port the GHC derivation from an older version to a newer version of nixpkgs
03:59:25 <Rembane> cocreature: The linker can't find the system libraries, then I add --extra-include-dirs=/usr/include/postgresql --extra-lib-dirs=/usr/lib to stack build and things doesn't work in exactly the same way. :)
04:00:07 <Rembane> cocreature: Not upgraded packages on Hackage are holding me back. Package maintainers being humans are sometimes a bit frustrating.
04:01:22 <cocreature> Rembane: you’ll have to show us the actual error. which libraries is it complaining about without --extra-lib-dirs and which libs is it complaining about if you add that flag?
04:01:52 <Rembane> cocreature: Hang on, I'll create a gist. 
04:02:18 <cocreature> if a package still doesn’t work with GHC > 8.0, I would either stop depending on that package or try to fix it (worst case take over maintenance)
04:06:06 <cocreature> avoiding upgrades is a pretty bad long-term strategy
04:06:25 <Rembane> It is indeed. 
04:19:56 <Rembane> cocreature: libpq can't be found regardless, it does exist in /usr/lib though. https://gist.github.com/Rembane/635a2f0a416ac29c232942ec75e7e9e4
04:22:07 <cocreature> Rembane: --extra-lib-dirs doesn’t apply to your dependencies iirc
04:22:38 <cocreature> although if it’s in /usr/lib that shouldn’t be necessary
04:22:41 <Rembane> cocreature: Oh. That explains why I get the same error message in both cases. 
04:22:46 <cocreature> Rembane: what exactly is the filename in /usr/lib?
04:23:14 <Rembane> cocreature: This is the exact path: /usr/lib/libpq.so
04:26:37 <cocreature> that looks like it should work oob unless you messed around with some settings
04:27:00 <cocreature> you could try the use-pkg-config flag on postgresql-libpq
04:27:25 <cocreature> iirc cabal basically compiles a dummy c file with -lpq in this case so make sure that this works for you
04:29:25 <Rembane> Cool. I'll try that.
05:34:45 <thebigj> https://www.twitch.tv/jaysinhp
05:34:47 <thebigj> Learn you a haskell for a great good!
05:40:07 * arturas
05:40:37 * hackage type-operators 0.2.0.0 - Various type-level operators  https://hackage.haskell.org/package/type-operators-0.2.0.0 (Shou)
05:42:19 <fen> because the index of a Tree is Tree (), and because of the properties we get from the traversable instance of Trees on the way these Tree () "add" together, where we can obtain the difference between two *successive* values according to the traversable order the elements are encountered 
05:43:53 <fen> we need an operation to take this "difference" value,from one leaf to the next, to obtain this monoidal addition
05:45:50 <fen> the properties we have to construct this can be obtained from the traversable properties, namely, that "backwards" never occurs, instead "up" happens, only ever at the end leaf position in a list of branches, and acts to remove these already visited leaves from the tree
05:47:08 * hackage HSvm 0.1.1.3.22 - Haskell Bindings for libsvm  https://hackage.haskell.org/package/HSvm-0.1.1.3.22 (PavelRyzhov)
05:50:18 <fen> so at each leaf at position `i' :: Tree () there is the difference `di' consisting of a list of up,down,forwards - a tree segment
05:52:51 <fen> hmm, maybe its just up and down, and these are seperated into [up],[down] === ([()],[()]) which is a simple tree with a branch at the top, and unbranching stems of some length at either side
05:53:58 <fen> forwards would just be down . up, because up destroys the previous branch, and is only relevant at alist of leaves
05:55:46 <fen> this restriction on the shape of Tree () that can be "added" seems like it messes up the semigroup instance
05:57:00 <lemmih> Is it possible to use 'stack script' when you depend on libraries that are on Hackage but not yet in Stackage?
05:59:07 <sternmull> I need a "dynamic" RowParser for PostgreSQL.Simple because the selected columns depend on user input and are of different types. I think i should use a sum type for the fields and provide an adequate field parser per column. But how do get there?
06:18:37 * hackage yesod-auth-oauth2 0.6.1.1 - OAuth 2.0 authentication plugins  https://hackage.haskell.org/package/yesod-auth-oauth2-0.6.1.1 (PatrickBrisbin)
06:37:37 * hackage hailgun 0.4.2 - Mailgun REST api interface for Haskell.  https://hackage.haskell.org/package/hailgun-0.4.2 (cdepillabout)
06:51:38 * hackage recursion-schemes 5.1.2 - Representing common recursion patterns as higher-order functions  https://hackage.haskell.org/package/recursion-schemes-5.1.2 (gelisam)
06:54:08 * hackage chronos-bench 0.1.0.1 - Benchmarking tool with focus on comparing results.  https://hackage.haskell.org/package/chronos-bench-0.1.0.1 (knupfer)
07:00:08 * hackage chronos-bench 0.1.0.2 - Benchmarking tool with focus on comparing results.  https://hackage.haskell.org/package/chronos-bench-0.1.0.2 (knupfer)
07:02:37 <whtn> hello
07:05:57 <whtn> anyone here?
07:06:10 <fen> aye
07:08:16 <fen> its not a good idea to think of taking the difference between two trees.you can get a good "negate" on Int === [()], but not for trees 
07:08:33 <fen> because the negate does not commute through the tree structure
07:09:56 <fen> if the index of a list is an int, which is a list of (). and the index of a tree is a tree of (), which is Free [] (), then the index of a tree is [Int] === [[()]]
07:10:27 <zincy> So purity refers to whether or not a function return value is determined solely by its arguments AND a lack of side effects?
07:11:03 <zincy> The former meaning that the expression of its invocation can be swapped with its return value without changing the semantic meaning of the whole program
07:11:11 <zincy> Is that right?
07:11:27 <merijn> zincy: Sounds right to me
07:11:34 <zincy> :)
07:13:05 <fen> which is a sort of tree, as its a nesting of lists, but not like the original shape of the tree being indexed over. its [Int] corresponding to which branch to take. so taking the difference between two tree indexes is not just (<> . negate)... the negative values occur both within the list, and over parts of the whole list! your adding together 2 trees, *parts of which* are negative. 
07:13:24 <fen> nothing like Int which is *all* positive or negative
07:13:48 <zincy> What does this mean ` A fixed point of a function is a value that, when applied as the input of the function, returns the same value as its output.` ?
07:14:07 <zincy> What is 'its output'?
07:15:25 <fen> zincy: thats not a question
07:16:06 <zincy> let me try again
07:16:14 <fen> x = f x ?
07:16:35 <zincy> Right yes that is the answer to the question I am trying to write
07:16:58 <Rembane> The functions sin and cos come to mind.
07:17:03 <fen> seemed like it was the question too...
07:17:04 <Rembane> arcsin and arccos too. 
07:17:35 <fen> Rembane: in what context?
07:18:00 <c_wraith> there are many kinds of fixed points
07:18:04 <Rembane> fen: Fixed points. 
07:18:18 <zincy> Take the factorial function the fixed point is 1 right?
07:18:33 <cryptomonad> zincy: `it's output` is the functions output.
07:18:43 <zincy> Thanks
07:19:51 <cryptomonad> zincy: Are you trying to understand the content of the question regardless of how well the question is stated, or are you using us as a sentence parser?
07:19:59 <c_wraith> for a function like id, every single input is a fixed point
07:21:20 <zincy> I am trying to understand what a Y combinator is. A piece of prerequisite knowledge for this is understanding what a fixed point is.
07:21:33 <c_wraith> zincy: that's not actually a prerequisite.
07:21:43 <zincy> Oh right.
07:21:57 <black0range> zincy: Maybe you should try your hand at doing some lambda calculus with pen and paper :) 
07:22:08 <c_wraith> zincy: all you need to understand the Y combinator is that it's an abstraction over general recursion
07:22:50 <fen> if the index over a tree is tree () === Free [] () === [[()]]  === [Int]. how can we write (<>) ? not only might some of the Ints be negative, like shortening a [()], but you can also shorten the [Int] tree index... or add to it... like we can change the the length of contents and the container
07:23:07 <c_wraith> though yeah, doing it with pen and paper with lambda calculus is probably the only reliable way to see how it works.
07:23:31 <zincy> Okay are there any good introductions from scratch about the lambda calculus someone could link to?
07:23:51 <black0range> Give me minute i did read one a long time ago that i kinda liked
07:26:02 <black0range> zincy: https://arxiv.org/pdf/0804.3434.pdf
07:26:20 <zincy> Thanks!
07:26:46 <black0range> Come to think about it, it is pretty thorough, it may be worthwile to look somewhere else if you want an overview 
07:28:16 <fen> its easy to (<>) and ((<>) .negate) over Int === [()], using (++) for positive [()] and using the negative Int === [()] arg to (<>) to shorten the list from the right
07:28:43 <fen> how to do this for trees is madness
07:30:25 <fen> [Int] === [[()]] === Free [] () === Tree (), as a kind of higher dimensional version of an Int === [()]
07:30:53 <zincy> (λf.λx.f(f(x)))(λy.y2)      
07:31:02 <fen> just trying to take the difference between to tree indexes... 
07:31:37 <zincy> What does having two terms next to each other do?
07:32:21 <zincy> You have (λf.λx.f(f(x))) on the left and then another expression (λy.y2)   on the right. Does this mean that the expression on the left is a function that is applied to (λy.y2)  ?
07:33:19 <fen> yeah thats what the lambdas do, they nyam up the things to thier right
07:34:03 <zincy> Ah right thanks!
07:35:45 <zincy> Is this a valid lambda calculus expression (λx.λx.x)?
07:36:05 <zincy> Or is there a rule against having similarly named bound variables?
07:36:06 <fen> no you bound x twice
07:36:25 <fen> > :t \ x x -> x
07:36:27 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
07:36:31 <fen> :t \ x x -> x
07:36:32 <lambdabot> error:
07:36:32 <lambdabot>     • Conflicting definitions for ‘x’
07:36:32 <lambdabot>       Bound at: <interactive>:1:3
07:37:14 <zincy> Is it possible to prove how many fixed points a function has?
07:37:15 <glguy> zincy: that's fine, 
07:37:27 <zincy> glguy: Oh is it?
07:37:51 <zincy> glguy: Does the latter x just "override" the former?
07:37:53 <glguy> :t \x -> \x -> x -- works like this
07:37:54 <lambdabot> p1 -> p2 -> p2
07:38:32 <zincy> Thanks
07:38:47 <fen> soz
07:40:03 <zincy> fen: Don't be
07:41:14 <fen> the problem is that the to shorten a list of ints is like a list of (), counting the number of values to drop from the end
07:41:44 <fen> so its like [Either () ((Bool,Int))]
07:42:01 <fen> with the bool being the poitiveness of the Int
07:42:16 <zincy> Is every lambda must take one arg then why does f appear to be passed two here? (λf.λx.f (x x))   
07:43:05 <sternmull> can i simplify "\a b -> f1 <$> f2 a b"? My first thought was "fmap f1 . f2" but that led nowhere... i think i miss something obvious.
07:43:12 <Chousuke> zincy: (x x) is a single argument
07:43:14 <fen> :t \f -> \x -> f x x
07:43:15 <lambdabot> (t1 -> t1 -> t2) -> t1 -> t2
07:43:20 <fen> :t \f -> \x -> f (x x)
07:43:21 <lambdabot> error:
07:43:21 <lambdabot>     • Occurs check: cannot construct the infinite type: t2 ~ t2 -> t
07:43:21 <lambdabot>     • In the first argument of ‘x’, namely ‘x’
07:43:44 <zincy> So x is a funtion applied to itself?
07:43:52 <Rembane> sternmull: fmap f1 . f2 
07:44:08 <fen> f2 takes 2 args?
07:44:33 <zincy> In the lambda calculus every function takes 1 arg
07:44:42 <fen> :t \ f1 f2 a b -> f1 <$> f2 a b
07:44:43 <lambdabot> Functor f => (a -> b) -> (t1 -> t2 -> f a) -> t1 -> t2 -> f b
07:44:44 <sternmull> fen: yes
07:44:57 <Rembane> :t Data.Function.on
07:44:58 <lambdabot> (b -> b -> c) -> (a -> b) -> a -> a -> c
07:45:03 <fen> :t \ f1 f2 -> fmap f1 . f2 
07:45:04 <lambdabot> Functor f => (a1 -> b) -> (a2 -> f a1) -> a2 -> f b
07:45:40 <fen> :t \ f1 f2 a -> fmap f1 . (f2 a)
07:45:41 <lambdabot> Functor f => (a1 -> b) -> (t -> a2 -> f a1) -> t -> a2 -> f b
07:46:59 <fen> @pl \ f1 f2 a -> fmap f1 . (f2 a)
07:46:59 <lambdabot> (.) . (.) . fmap
07:47:25 <fen> obviously!
07:48:02 <sternmull> hm, i can't follow
07:48:08 <fen> @unpl (.) . (.) . fmap
07:48:08 <lambdabot> (\ x g x0 x1 -> fmap x (g x0 x1))
07:48:43 <fen> probably you want some intermidiate stage in that
07:49:10 <fen> "how to dot a function of one arg with a function of 2"
07:49:51 <sternmull> i want to map a function over the result of a two-argument-function
07:50:02 <fen> @pl \ f1 f2 a -> f1 . (f2 a)
07:50:02 <lambdabot> (.) . (.)
07:50:53 <fen> :t \f1 f2 -> fmap f1 ((.).(.)) f2
07:50:55 <lambdabot> (((a1 -> a2 -> b) -> a1 -> a2 -> c) -> t) -> (b -> c) -> t
07:51:08 <fen> maybe not...
07:51:31 <fen> :t \f1 f2 -> (fmap f1) ((.).(.)) f2
07:51:32 <lambdabot> (((a1 -> a2 -> b) -> a1 -> a2 -> c) -> t) -> (b -> c) -> t
07:51:36 <fen> help!
07:51:40 <Rembane> :t \f1 f2 -> (.) . (.) . (fmap f1) f2
07:51:41 <lambdabot> (a1 -> b -> c) -> (a2 -> a1) -> a2 -> (a3 -> a4 -> b) -> a3 -> a4 -> c
07:51:56 <Rembane> Interesting.
07:52:17 <Rembane> On this path lies madness: https://wiki.haskell.org/Pointfree
07:52:20 <Rembane> Fun madness! :D
07:52:31 <fen> stupid owl operator...
07:53:24 <Rembane> :t \f1 f2 -> (.) . (.) . (fmap f1) . f2
07:53:25 <lambdabot> (a1 -> c) -> (a2 -> b -> a1) -> a2 -> (a3 -> a4 -> b) -> a3 -> a4 -> c
07:53:30 <Rembane> Meh
07:54:14 <sternmull> i think... if there is no obvious simplification then i leave it as it is.
07:54:52 <Rembane> sternmull: You can remove the b, but that's about it. 
07:54:52 <fen> sure there is one, just trying to get the right combination of dots!
07:55:08 <fen> or the correct query to pl
07:55:39 <sternmull> Rembane: That won't make it more readable in my opinion
07:56:04 <Rembane> sternmull: Okay, that's cool.
07:57:12 <sternmull> trying to use . for a multi-argument function always confuses me. Some day i have to get to the bottom of that.
07:59:22 <Lears> > let (<$$$>) = fmap . fmap . fmap in ((*2) <$$$> (++)) [3,4] [5,6]
07:59:24 <lambdabot>  [6,8,10,12]
08:00:11 <Lears> It's a questionable here, but I actually do use double/triple fmap operators fairly often.
08:00:26 <fen> can anyone understand how to take the difference between two tree indexes?
08:09:07 * hackage verbosity 0.3.0.0 - Simple enum that encodes application verbosity.  https://hackage.haskell.org/package/verbosity-0.3.0.0 (PeterTrsko)
08:12:07 <fen> semigroup instance for tree indexes, whats the problem?
08:12:37 <EvanR> whats a tree index
08:13:03 <fen> a list index is an Int
08:13:54 <fen> a tree is a higher dimensional list, so a tree index must be a higher dimensional Int
08:14:45 <EvanR> um, higher dimensional list really?
08:15:02 <EvanR> can that be made precise
08:15:04 <fen> a list is indexed by a [()], so a tree must be indexed by Tree ()
08:15:28 <fen> ie a [Int]
08:15:44 <fen> (not quite sure why it truncates the Free to depth 2)
08:16:11 <Lears> That's rather a suspicious argument.
08:16:23 <fen> a higer dimensional container of dimension n, is that which is indexed by a n-1 dimensional container of Ints...
08:16:45 <EvanR> so what is n here
08:16:55 <EvanR> 2 ?
08:17:17 <Lears> I would suggest that a list is indexed by [1] and a binary tree is indexed by [2].
08:17:32 <fen> n=1 list. n=2 tree. n > 2 starts to be like Free Tree === Free (Free []) so not considering these
08:17:35 <Lears> I.e. [()] and [Bool]
08:17:54 <fen> no its a rose tree
08:18:00 <fen> Free []
08:18:24 <fen> you need a list of Ints, for which element of the list of branches to take 
08:18:46 <EvanR> what in a roundable way that answers my first question. now what does a difference do?
08:18:47 <Lears> In that case yeah.
08:19:03 <EvanR> well*
08:19:32 <fen> difference is like [(),(),()] - [(),()] = [()]
08:19:43 <fen> easy for Ints = [()]
08:19:44 <EvanR> umm
08:20:08 <fen> trying to extend this to trees is the task
08:20:14 <EvanR> extend what exactly
08:20:36 <EvanR> what aspect of - on Ints
08:20:42 <fen> well, for [()] all you can do is (++) or truncate,depending on if its negative
08:20:43 <black0range> fen: Wouldn't the easiest way to index a tree be by descibing the path you took going there?
08:20:59 <fen> yeah. thats [Int]
08:21:28 <fen> so if you go from one place to the other, there is the difference
08:21:30 <black0range> Assuming the nodes has an arbirary number of children, yes
08:22:10 <black0range> Oh, interesting
08:33:57 <fen> i think the shape of the tree might define the algebra, not sure
08:35:04 <fen> but as the path kind of ignores the rest of the tree, probably any 2 paths can be differenced, and there will be some trees it would work for
08:36:15 <fen> basically, going from the top of some tree to any 2 different places will have some common path. removing this from the combination gives the difference
08:37:12 <fen> and this corresponds to some crazy type of partial negation over [Int] being the higer dimensional int version of the list index int.
08:38:45 <fen> you a go up the path that was used to get to the first value. this correponds to truncating the [Int], ie, take only the common path. 
08:39:09 <fen> then, you can change the Int of the last value, to point down a different branch
08:39:28 <fen> and then add new Ints corresponding to the path taken over the rest of the tree
08:40:18 <fen> so the semigroup instance for tree indexes [Int] is truncating and adding to it
08:41:03 <fen> but the difference opperation is mad, because negate over the path behaves in a complicated way
08:42:17 <fen> obviously, (<>) over 2 completely positive paths is simple.
08:43:45 <fen> maybe the difference in 2 paths is an int for the amount the first path is longer than the common path, and [Int] for the rest of the second path
08:43:59 <fen> but the negate function just seems baffling 
08:44:11 <fosterite> :t (.)(.)
08:44:12 <lambdabot> (a1 -> b -> c) -> a1 -> (a2 -> b) -> a2 -> c
08:45:02 <fen> we want to define negate as that where difference = (<>) . negate
08:45:50 <fosterite> isn't the negation of a path every other path in the tree
08:46:09 <fen> thats more like a complement!
08:49:31 <fen> difference is not commutative
08:51:09 <fen> and apparently whatever it is that is "added" to the path, that is "negative" in some sense, depends on the original path, because of this notion of the common path used in the description of the difference  
08:54:52 <Logio> difference should probably be equal to mirroring the tree (left to right)
08:55:10 <Logio> sorry, negation 
08:56:17 <fen> its more like flipping it upside down, and going along it up from the end of the first path, starting a new branch where it deviates from going back along the first path
09:00:21 <excelsiora> Interesting insight, maybe obvious, and tell me if I'm wrong: in Haskell you want to operate on the head of a list, and keep the tail unchanged. If you treat a list like a stack, you push onto the head, and pop from the head... am I right?
09:00:23 <fen> the problem then is that while flipping upside down seems to makes sense for negate, the thing that results, when added using (<>) to the first path, would depend on this first path, like, how much of the negative path is truncating the original path
09:02:54 <fen> which then seems to justify the idea the the algebra is defined by a particular tree
09:05:17 <fen> but then the values which can be added to any specific value depend on this value and the whole tree. its so bizzare
09:08:12 <fen> maybe its not even a semigroup, how to represent this functionality needs some work
09:12:42 <fen> some of these ideas are here; https://pdfs.semanticscholar.org/3b65/0d5ee01ac35c721c5bd51e4859aebe3880e2.pdf
09:12:55 <fen> Higher Dimensional Trees, Algebraically Neil Ghani1, Alexander Kurz2
09:16:12 <kuribas> excelsiora: if you use a list as a stack, you push by consing, and pop by taking the tail.  Note that it's actually an immutable operation.
09:17:35 <kuribas> to mimic mutable state, you propagate the changes, or use a state monad.
09:19:21 <kuribas> excelsiora: so effectively, you always keep the whole structure intact, but create a new structure each time.
09:19:41 <kuribas> excelsiora: taking the tail doesn't remove the head from the list
09:22:06 <excelsiora> If you lose reference to the old head, isn't it garbage collected?
09:22:24 <sternmull> "taking the tale" sounds a bit misleading, i think you mean "separating the head from the tail" and not "taking the last element"
09:22:47 <sternmull> s/tale/tail
09:23:02 <excelsiora> tall tale about a long tail...
09:23:20 <kuribas> sternmull: there is no separation really
09:23:26 <sternmull> i know
09:24:01 <sternmull> its more like "reference the list without the head"
09:24:42 <kuribas> excelsiora: it's garbage collected if nobody refers to the old list
09:24:43 <sternmull> excelsiora: Yes it will get garbage collected. But you won't notice because without a reference you can't inspect it anyway.
09:26:13 <kuribas> sternmull: not taking the last element, tail is rest of the list, not the last element of the list
09:26:59 <kuribas> the correct term would be "pattern matching" on the list
09:27:33 <kuribas> so you can only "take" the tail when it's non-empty.
09:29:52 <excelsiora> so the original head's cons would be lost as well, right?
09:29:59 <sternmull> you are right. for some reason i interpreted your "taking the tail" as getting rid of the last element.
09:30:22 <kuribas> excelsiora: yes
09:30:30 <Zemyla> A datatype with definition data A = A {-# UNPACK #-} !Word8 {-# UNPACK #-} !Word8 {-# UNPACK #-} !Word16 will still use three words in memory, not one, right?
09:30:45 <excelsiora> yay, intuition correct!
09:30:45 <kuribas> excelsiora: but lost doesn't mean much, since nobody is referencing it, it cannot be reached.
09:31:08 <kuribas> excelsiora: so even if it's still in memory, it wouldn't be available to the program anyway.
09:31:15 <sternmull> and other places in the program could still reference the original cons
09:31:19 <kuribas> excelsiora: also garbage collection doesn't happen immediately
09:32:06 <kuribas> sternmull: if it's getting garbage collected, it doesn't.
09:32:17 <Zemyla> Three words + the tag, I mean.
09:33:20 <sternmull> kuribas: Thats right. I wanted to point out that the "stack" doesn't get mutated by taking the tail.
09:33:50 <kuribas> sternmull: as I said before?
09:33:55 <excelsiora> that makes sense. 
09:34:32 <excelsiora> So what are the biggest advantages of laziness?
09:35:00 <kuribas> I'd say modularity and compositionality
09:35:06 <sternmull> infinite data structures
09:35:54 <sternmull> you can write a function that returns an infinite list and only the part that actually gets used will be computed
09:36:30 <kuribas> for example "foldr1 const" will take the first element of any foldable
09:36:35 <kuribas> :t foldr1 const
09:36:36 <lambdabot> Foldable t => t b -> b
09:36:55 <kuribas> but without lazyness that would need to examine the whole structure
09:37:37 <sternmull> or working with something more explicit that generates the data on demand (like generators in python)
09:38:02 <excelsiora> Python dictionaries have a method called setdefault that get the value for a given key, but both return and set a default if the key isn't there. Strict evaluation means you shouldn't use it if the default is expensive to create... lazy evaluation would make that code a lot nicer.
09:40:35 <sternmull> i am not sure, lazyness does not imply automatic memoization
09:41:16 <sternmull> so if you compute something over and over again it will also be expensive for lazy evaluation
09:42:38 <kuribas> excelsiora: if you do getDefault = fromMaybe expensive, expensive will only be calculated once.
09:42:39 <cocreature> sternmull: I think you misunderstood excelsiora’s statement. what they are referring to is the case where the default isn’t used at all and laziness allows you to avoid computing it
09:42:43 <excelsiora> it looks like this: a_dict.setdefault('key', cheaply_evaluated_default_value) -> value
09:43:09 <zincy> How does laziness improve modularity and compositionality?
09:43:44 <sternmull> kuribas: You are just defining a constant
09:43:47 <zincy> I am not sure how the order of evaluation of expressions can have anything to do with those two things.
09:44:07 <excelsiora> that default value will be thrown away if the key is there, so it would be better to lazily evaluate it.
09:44:13 <kuribas> zincy: by allowing you to operate on a whole structure, even if you only need part of it.
09:44:22 <kuribas> zincy: see my foldr example.
09:44:24 <sternmull> cocreature: Ah, ok!
09:44:41 <kuribas> zincy: foldr works on the whole list in a strict language, but not in a lazy language
09:44:51 <fen> the main advantage could be that by differing the computation we can use fusion.
09:45:04 <fen> deferring* 
09:45:16 <kuribas> :t fromMaybe (sum [10000000])
09:45:17 <lambdabot> Num a => Maybe a -> a
09:45:23 <kuribas> sternmull: not a constant
09:45:49 <fen> like, we have a 0 cost verision of c++ style for loop with ++ It
09:45:56 <fen> Int*
09:46:07 <zincy> kuribas: So with laziness you can skip some operations which would be needed to extract the required elements of the list first in order to compose
09:46:27 <sternmull> kuribas: Now i see what you mean. It is a constant, but the computation will be delayed until its actually needed.
09:47:05 <fen> like you can have a lazy function on a traversed thing
09:48:02 <kuribas> sternmull: yes, and then reused
09:48:32 <zincy> Does recursion implemented using a Y combinator terminate when a fixed point is reached in the function it is applied to?
09:49:02 <sternmull> kuribas: You get the reuse also for strict evaluation because you store the value in the constant. Lazy evaluation only gives an advantage if the constant is expensive and never used.
09:49:40 <kuribas> zincy: IIRC the fixed point is the recursion itself
09:50:05 <kuribas> zincy: if you mean, when the terminating condition is met, then yes
09:50:11 <zincy> I thought the fixed point was the point at which f x = x
09:50:45 <int-e> Y f = f (Y f)
09:50:53 <int-e> looks like a fixed point of f to me
09:50:54 <Solonarv> indeed: any 'x' for which this equality holds is a fixed point of 'f'
09:52:20 <zincy> Oh so you are talking about the fixed point of Y itself
09:52:36 <zincy> That is why I was confused probably
09:52:42 <zincy> I didn't think of a combinator as a function
09:53:08 <Solonarv> in Haskell, the "Y combinator" is a plain old (recursive) function:
09:53:11 <zincy> I probably need to work it through on paper but I don't understand how it can ever terminate
09:53:21 <Solonarv> fix f = let x = f x in x
09:53:45 <zincy> :t fix
09:53:46 <lambdabot> (a -> a) -> a
09:53:53 <kuribas> zincy: recursion using the Y combinator is the same as without it.
09:54:16 <zincy> Thanks
09:54:19 <Solonarv> the key is laziness: if 'f' doesn't always fully evaluate its argument then the recursion can terminate
09:54:41 <kuribas> of if it's a function
09:54:52 <zincy> So how do you get termination in recursion with a strict languagew?
09:54:55 <[exa]> zincy: like, fix (const 5)
09:55:24 <kuribas> zincy: by returning a function
09:55:46 <Solonarv> so instead you end up with something like:
09:56:39 <Solonarv> fix' f = let x () = f x () in x
09:57:00 <Solonarv> which has the type '((() -> a) -> () -> a) -> () -> a'
09:57:06 <zincy> right so with laziness we can just say oh look 5 we dont care what the function is given in fix (const 5)
09:57:50 <zincy> Solonarv: Is your example basically adding an extra thunk in order to decide whether to proceed with evaluation?
09:58:07 <[exa]> zincy: in fact this happens all over the place; say in take 5 [1..]
09:58:14 <Solonarv> "thunk" isn't quite the right word but basicaly yes
09:58:27 <[exa]> Solonarv: you need to supply ()'s to that to continue evaluating?
09:58:36 <Solonarv> or rather, this isn't a "thunk" in the way that term is usually used in Haskell
09:58:58 <zincy> Ah ok so that extra function in the strict implementation basically determines if the function's argument is equal to its return value and terminates if so?
09:59:00 <Solonarv> [exa]: only a single ()
09:59:08 <[exa]> oic
09:59:09 <Solonarv> there's no equality checking here
09:59:38 <Solonarv> the dummy argument is used to defer evaluation and emulate the required laziness
10:00:24 <zincy> Ah ok its like manual laziness.
10:00:33 <Solonarv> yep
10:00:58 <zincy> So it lets the rest of the code decide if it wants to call it again it doesnt terminate by itself.
10:01:06 <Solonarv> it seems to be a pretty common technique in strict languages
10:01:08 <Solonarv> exactly!
10:01:26 <zincy> Solonarv: Awesome I understand now. Thanks!
10:02:02 <zincy> [exa]: Ah that makes sense it happens everywhere now I think about it.
10:02:04 <[exa]> Solonarv: oh it's the inner function that supplies infinite (), I see it now :]
10:02:24 <Solonarv> well, the inner function can supply anywhere between zero and infinite ()
10:02:42 <Solonarv> (though if it supplies infinitely many then (in a strict language) the recursion may never terminate)
10:03:01 <[exa]> yeah, 'potentially infinite' ofc :]
10:03:22 <finnkauski> Hi folks, new to haskell here. About 30 % into the Haskell Programming from first principles by Allen and Moronuki. Gotta say this whole functional 
10:03:28 <finnkauski> thing is awesome 
10:03:42 <[exa]> Hi finnkauski!
10:05:36 <zincy> finnkauski: Welcome, it only gets better with time.
10:06:26 <finnkauski> yeah one of my coworkers kept going on about it to the point where I got to curious not to try it 
10:07:05 <finnkauski> I've noticed how my thinking about a problem has changed and most of my code in python just became less pretty haskell code. 
10:08:05 <[exa]> I believe that effect already has a name somewhere
10:09:53 <nshepperd> in strict languages like C, top level function bindings are 'lazy'
10:10:48 <nshepperd> or rather, they don't need evaluation, because they're evaluated by the linker already
10:11:17 <ggole> That's because C functions are constants, not because they are strict
10:11:17 <finnkauski> Someone asked me why i wanted to learn FP and I said, well I don't really care about the language per say, so haskell was the obvious choice as it is the poster boy of FP atm. But i just wanted to learn the paradigm. So a buddy of mine brought up the analogy how a caterpilars digest themselves before rebuilding into a butterfly. And learning FP so far has had that effect on my brain. Thought that was a good analogy 
10:11:23 <nshepperd> so a function can point to itself
10:12:24 <ggole> There are plenty of strict languages in which top level bindings are straightforwardly evaluated.
10:12:41 <kuribas> ruby?
10:14:10 <nshepperd> sure. in python top level bindings are just evaluated in order, and stuff is looked up by name
10:14:13 <hpc> python, iirc
10:14:38 <kuribas> so function definition is mutation
10:15:07 <kuribas> not a true fixed point
10:15:30 <ggole> Not true in eg, ML or Scheme
10:15:41 <ggole> (Not sure about Scheme, top level is a bit strange there.)
10:15:46 <kuribas> (in python)
10:15:52 <ggole> Ah, ok.
10:16:11 <Solonarv> @quote is.the.solution
10:16:11 <lambdabot> quicksilver says: head-explosion is the solution, not the problem.
10:17:28 <cocreature> not sure all problems can be solved by exploding heads :)
10:17:52 <hpc> you just haven't been exploding enough heads
10:18:01 <nshepperd> exploding heads as a method of space travel
10:18:44 <Solonarv> if explosions didn't solve your problem you just didn't use enough explosions
10:21:31 <[exa]> explode more, explode often
10:34:44 <fendor> someone experience with darcs? would you recommend it to experiment with it?
10:35:27 <excelsiora> so I just created a stack project, and I want to write a unittest, what's the best way to go about that?
10:36:50 <cocreature> excelsiora: tasty and hspec are your main options
10:37:10 <cocreature> doesn’t matter that much which one you choose, personally I mostly tend to use tasty
10:37:37 <cocreature> excelsiora: if you haven’t already seen it, you might also want to look into QuickCheck (you can integrate it with both hspec and tasty)
10:44:52 <finnkauski> so quick question about the haskell ecosystem. I come from a python background and they have a very nicely tied up and organised ecosystem for scientific computing (numpy, pandas, sklearn etc.). Is there a project in haskell that tries to tie all this together?
10:45:17 <fosterite> short answer: no
10:45:37 <finnkauski> is it because its early days for that? or because there isn't a user base demanding it ?
10:45:40 <tdammers> explode early, explode loudly
10:45:58 <Solonarv> finnkauski: a bit of both, I'd guess
10:46:22 <c_wraith> also because there isn't a design for most of those libraries that actually makes people happy yet. 
10:46:46 <finnkauski> ^ fair 
10:47:07 <finnkauski> closest i found was https://www.datahaskell.org/
10:49:22 <fen> what functionality is required of this sciHaskell thing ?
10:49:32 <c_wraith> might need Dependent Haskell to land before someone finds a design that really is satisfying for equivalents to things like pandas
10:50:01 <reallymemorable> is `Maybe` a monoid?
10:50:14 <fen> :t catMaybes
10:50:15 <lambdabot> [Maybe a] -> [a]
10:50:31 <fen> oh nvm
10:50:58 <c_wraith> reallymemorable, not exactly. `Maybe a' is a Monoid if `a' is a Monoid
10:51:10 <reallymemorable> hmm ok
10:51:13 <excelsiora> cocreature: thanks
10:51:19 <Solonarv> c_wraith: actually, 'a' only needs to be a Semigroup now
10:51:29 <c_wraith> oh, yeah
10:51:32 <reallymemorable> but i thought that monoids were the containers for impure objects
10:51:38 <reallymemorable> does Nothing count as pure?
10:51:40 <fen> most haskell devs do programming for the computer science community as opposed to the numerical science 
10:51:46 <Solonarv> no, you're thinking of monads
10:51:48 <finnkauski> Monad
10:51:52 <reallymemorable> ah
10:51:53 <reallymemorable> yes
10:51:59 <reallymemorable> is Maybe a Monad?
10:52:02 <johnw> yes it is
10:52:10 <koz_> Maybe is many things.
10:52:16 <c_wraith> Monad doesn't mean impure.
10:52:27 <reallymemorable> but i thought you needed Monads to handle impure things
10:52:41 <c_wraith> nope.
10:52:45 <finnkauski> it depends on the Monad
10:52:47 <c_wraith> it just makes it easy.
10:52:54 <reallymemorable> got it
10:52:57 <finnkauski> I think a list is a Monad (correct me if I'm wrong)
10:53:00 <reallymemorable> it makes it easy to pass impure things through functions
10:53:09 <c_wraith> Haskell existed before Monad was added to the language
10:53:10 <reallymemorable> but is not 100% necessary
10:53:37 <c_wraith> Monad is just a pattern for composing operations of particular shapes.
10:53:55 <fen> finnkauski: are you saying that python "sci" packages are synonymous with machine learning tools?
10:54:03 <reallymemorable> composing operations = composing functions?
10:54:09 <c_wraith> IO, the type that is used to model impure operations, happens to be a monad.
10:55:26 <c_wraith> reallymemorable, depends on viewpoint. (bind says no, kleisli composition says yes, and they can be converted between mechanically).
10:55:48 <c_wraith> :t (.)
10:55:49 <lambdabot> (b -> c) -> (a -> b) -> a -> c
10:55:59 <c_wraith> :t (<=<)
10:56:00 <lambdabot> Monad m => (b -> m c) -> (a -> m b) -> a -> m c
10:56:14 <c_wraith> just about the same thing.
10:56:20 <c_wraith> and that's not a coincidence.
10:56:24 <reallymemorable> what is the second operator
10:56:29 <reallymemorable> a pipe?
10:56:39 <c_wraith> kleisli composition. it is a lot like a pipe.
10:57:16 <reallymemorable> its saying it links a function that creates a monad and nother function that creates a monad
10:57:29 <reallymemorable> and allows you to go through two iterations of monad
10:57:41 <reallymemorable> to get the final monad with just the input of the first thing
10:57:45 <reallymemorable> first function*
10:58:00 <reallymemorable> i figure i am using the jargon poorly, but I am new to this...
10:58:23 <c_wraith> yes, though I prefer slightly more rigorous terminology. only types are monads, so it doesn't "create" a monad. it returns a value of a monadic type.
10:58:48 <reallymemorable> so it lifts it into the monad level?
10:59:17 <Solonarv> well, it could do that, but it could also be e.g. 'readFile :: FilePath -> IO String'
10:59:33 <reallymemorable> ah
10:59:48 <reallymemorable> so that is a function that takes a FilePath (maybe type Text or String)
10:59:57 <reallymemorable> and gives you a string inside of the IO monad
11:00:03 <reallymemorable> so you can use it to interact with the outside world
11:00:53 <Solonarv> or another example: 'readMaybe :: String -> Maybe Int'
11:00:58 <Solonarv> again, there's no "lifting" going on
11:01:03 <reallymemorable> ok
11:01:12 <reallymemorable> i clearly dont understand lifting...my weekend homework...
11:01:41 <Solonarv> "lifting a value into a monad" is what 'pure'/'return' do (they're the same thing)
11:02:04 <reallymemorable> why have both?
11:02:14 <c_wraith> accident of history
11:02:33 <c_wraith> Haskell has been around for 30 years. lots of those.
11:02:37 <fen> lifting is a functor term right ?
11:02:54 <Solonarv> not really
11:02:59 <Solonarv> it can mean a bunch of different things
11:03:03 <fen> fmap lifts a function into a functor
11:03:16 <Solonarv> yeah, that's one of the meanings
11:03:34 <fen> but like, from category theory
11:03:36 <reallymemorable> that means it just lets you use it in a different set?
11:03:52 <reallymemorable> you have a transformation in one set and you want it to describe relations in another set?
11:04:13 <Solonarv> that's roughly accurate for the more general notion of functor
11:04:20 <c_wraith> template Haskell has a class named Lift that converts a value to a TH AST that represents it.
11:04:29 <Solonarv> haskell's Functor class onl talks about functors from Hask to Hask
11:04:43 <reallymemorable> i have 0 clue what you are talking about
11:04:50 <fen> you have morphisms between objects in a category which you lift
11:04:51 <ski> reallymemorable : "creates a monad" is wrong. a monad is not a value you pass around. `Maybe' (together with the corresponding, law-abiding, implementation of `return' and `(>>=)') is a monad. you should say "creates a monadic action"
11:04:51 <reallymemorable> but i suppose ill encounter it soon enough
11:05:12 <reallymemorable> and a function is a morphism
11:05:13 <c_wraith> as a general concept, I'd say "lifting" means converting a value from one representation to another in a way that keeps it somehow "equivalent"
11:05:27 <reallymemorable> that keeps the relationship equivalent
11:05:42 <reallymemorable> ski, thanks
11:05:51 <fen> lifts objects to objects and morphisms to morphisms 
11:06:16 <reallymemorable> so like
11:06:21 <reallymemorable> a -> a'
11:06:42 <ski> (or "monadic value", or (in some cases) "collection". people have also used "computation", and also "context", though i find the latter too vague for my taste)
11:06:56 <fen> guess return is that which lifts the objects, and fmap is that which lifts the morphisms
11:07:50 <fen> monadic wrapper?
11:07:57 <c_wraith> fen, no the type constructor is what lifts the objects
11:08:18 <fen> normally thats the implementation of pure though
11:08:38 <fen> :t (:[])
11:08:39 <lambdabot> a -> [a]
11:08:58 <c_wraith> fen, like given the Int object, the Maybe Functor lifts the object to Maybe Int. that is, objects are types, not values.
11:09:01 <Solonarv> fen: objects are types, not values
11:09:08 <fen> oh ok
11:09:46 <ski> fen : no, `Maybe' itself would lift the "objects" (the types)
11:10:08 * ski is apparently eternally late
11:10:19 <e> who isn't?
11:10:42 <fen> so apparently, after much work on making Traversable_i
11:10:46 <int-e> e: what a timely remark!
11:10:51 <fen> there is no use for it!
11:11:07 <fen> the comonad default instance is slow
11:11:26 <fen> it requires re-navigating the tree
11:11:56 <fen> while just recursing traverse kind of manages to avoid this somehow
11:12:05 <e> int-e: sadly the pun i was going to make would seem offensive if you read it in english so i'm going with "oh no, you got me"
11:12:40 <fen> and no costly navigation between values, the only use of `i' encountered during traverse_i is useless
11:14:15 <fen> there is a pathological case, where there is some kind of maze that needs to be solved between values, so that storing the solution would be faster than traversing all the dead ends
11:14:27 <fen> but whenever that would be used i have no idea¬!
11:16:09 <fen> if there is always a value at the leaves, there is apparently no point calculating the path between them, as is done via traverse_i
11:16:20 <fen> luckily didnt waste too much time doing that
11:38:37 <hyperisco> CI is unimportant because the team is small. However, there is the side practice of automatic building and testing before a merge is allowed. What is just that side practice called?
11:39:00 <hyperisco> I guess that is integration testing?
11:41:02 <Cale> hyperisco: We call that "CI"
11:41:12 <hyperisco> https://en.wikipedia.org/wiki/Integration_testing
11:41:18 <hyperisco> I am picking through the wikipedia right now
11:41:28 <hyperisco> thing is that CI refers to a larger practice of frequent code merges
11:41:43 <hyperisco> I'm not at all interested in that part because it isn't a problem given how many people are working on the code
11:41:54 <fragamus> i need a function to return the a that has the maximum b in [(a,b)]
11:42:08 <fragamus> does that exist or do I write it
11:42:15 <hyperisco> I am however highly interested in the testing part whereby changes cannot be merged unless unit tests pass
11:42:27 <hyperisco> and that the program compiles on a 3rd party (not the developer's) machine
11:42:34 <Cale> fragamus: There's maximumBy
11:42:38 <Cale> and comparing snd
11:42:43 <hyperisco> I've checked in local file paths too many times now that it is silly
11:42:55 <fragamus> :t maximumBy
11:42:57 <lambdabot> Foldable t => (a -> a -> Ordering) -> t a -> a
11:43:03 <Cale> > fst . maximumBy (comparing snd) $ [("a",4), ("b",6)]
11:43:05 <lambdabot>  "b"
11:43:16 <Cale> note that this falls over on an infinite list
11:43:17 <Cale> er
11:43:25 <Cale> sorry, I meant to say empty list
11:43:33 <Cale> but my hands typed infinite somehow, lol
11:43:47 <Cale> It also falls over on an infinite list
11:43:50 <Cale> but that's less interesting
11:44:22 <fragamus> thanks cale
11:44:36 <hyperisco> that initialisation problem to "what is the max" is definitely on the top 10 chart for annoying programming problems
11:45:02 <byorgey> I DEMAND THAT HASKELL GIVE ME THE MAXIMUM OF AN INFINITE LIST
11:45:16 <hyperisco> it does…
11:45:25 <Cale> I mean, how hard could it be to work out  maximum [1,1..]
11:45:28 <fosterite> p-adic: it's -1 yo
11:46:03 <hyperisco> in operational semantics all you get is a ceaseless procession of what-to-dos
11:46:10 <hyperisco> but in the denotational semantics of Haskell we know the answer!
11:46:20 <Solonarv> Cale: something something abstract algorithm?
11:46:34 <Solonarv> eh, I actually don't know if that works.
11:46:48 <byorgey> actually, this has come up in a teaching language I am designing.  In addition to things like [1..] it also allows sets like {1 .. }, but right now trying to evaluate {1 ..} just hangs.
11:46:49 <Cale> maximum (map isCounterexampleToGoldbachConjecture primes)
11:47:05 <byorgey> I am trying to figure out if there is a sensible semantics one could give it via some sort of deep embedding.
11:47:54 <Cale> fragamus: I should also say, you may wish to instead use Data.Map to store the elements initially
11:48:02 <fosterite> byorgey: you already know about this but have you considered logic language semantics for it?
11:48:20 <byorgey> fosterite: what do you mean?
11:48:28 <fragamus> yeah that's good advice
11:48:57 <Cale> maxView will then cheaply get you the maximum (and it produces a Maybe as well, so it's safer)
11:49:15 <Cale> or lookupMax
11:49:17 <fosterite> x = {1..} means any positive integer but only one at once. Perhaps you could keep some of the operational side but change the denotation
11:49:44 <hyperisco> that's why Foldable1
11:50:25 <byorgey> fosterite: ah, that's an interesting idea, but it doesn't really fit what I'm trying to do at all since the explicit goal is to allow students to work with *sets* (like they would encounter in a discrete mathematics course)
11:51:17 <byorgey> The denotation is the part I do want to keep =)
11:52:17 <imdoor> hi, how am i supposed to be linking stuff against shared object files produced by cabal's "foreign-library" stanza? i was expecting to use something like `g++ -o main main.o -lMyHashellLib` and add -lHSrts to get symbols for hs_init and hs_exit and be done with it
11:52:23 <imdoor> but now i see it's not that easy
11:52:29 <fosterite> byorgey: I see. do you have any examples? That sounds like a useful pedagogical tool
11:52:55 <byorgey> fosterite: https://github.com/disco-lang/disco
11:53:36 <byorgey> there actually aren't a lot of examples involving sets because I've just been developing that part
11:53:50 <byorgey> but there's lots of other stuff
11:53:51 <imdoor> working through ld errors i see that i also need other stuff (like,  -lffi, some -Wl,-u,... flags and stuff)
11:54:52 <imdoor> is it supposed to be this involved?
11:55:07 <fosterite> byorgey: thanks
11:57:36 <geekosaur> imdoor, normally you use ghc as the linker instead of gcc/g++.
11:58:13 <geekosaur> and in particular HSrts and friends aren't usually in the places gcc/g++ looks
11:58:46 <imdoor> geekosaur: yeah, i'm able to link with ghc just fine. the problem is that i ultimately want to use my lib in a native node.js module
11:59:16 <imdoor> and i wasn't able to figure out how to force it to use ghc instead of ld
12:00:07 <imdoor> the problem is that building node.js native modules involves using node-gyp
12:00:26 <imdoor> and that process is very involved as well
12:00:45 <imdoor> behind the scenes
12:00:46 <Lears> byorgey: I don't know how practical it is, but you could use something like `newtype Set a = Set { chi :: a -> Bool }`, then `{ 1 .. }` desugars to `Set (>= 1)`. I think most operations would be simple to implement?
12:02:08 <Solonarv> (covariant) 'map' is practically impossible to implement using that representation, and you don't have any way to enumerate elements
12:03:11 <geekosaur> you can at least extract the -u options from ghc-pkg: ghc-pkg --simple-output field rts ld-options
12:03:14 <fosterite> you could just change the language name to wildberger and not implement infinite sets :^)
12:03:50 <imdoor> the problem that made me stop trying to swap out ld for ghc withing the stuff that node-gyp was doing was that i think there were some linker flags ghc didn't understand. at least i think that was what was happening
12:03:52 <geekosaur> there's some other things you can probably extract that way, "ghc-pkg describe" will show you what's available for a package
12:04:12 <geekosaur> ghc would need -optl to pass some options through
12:05:52 <Lears> Enumeration would need to rely on an enumeration for the type in question, with which it's feasible but rather inefficient for sparse sets. The problem of 'map' is an interesting one..
12:06:52 <Solonarv> you can implement covariant map trivially if you can enumerate elements, but it's again inefficient
12:07:42 <ski> ooh, covariant vs. contravariant sets (really powerset functor)
12:07:51 * ski ranted about that the other day a bit
12:09:02 * ski . o O ( dinatural transformations, wedges, cowedges, ends, coends )
12:09:13 <ski> (also free theorems for `exists')
12:10:56 <imdoor> geekosaur: i think that'd only work if i made a fake ld that would translate the things passed to it to ghc's -optl. i think i don't have an option to control how node-gyp generates its ld flags
12:15:12 <byorgey> Lears: that's a nice suggestion.  I don't know how practical it is but it's definitely worth thinking about.
12:16:09 <ski> @free concat :: [[a]] -> [a]
12:16:09 <lambdabot> $map f . concat = concat . $map ($map f)
12:16:23 <ski>   $lmap ($map f) concat = $rmap ($map ($map f)) concat
12:18:15 <ski> (that's for `forall a. [[a]] -> [a]', an end)
12:20:04 <excelsiora> is there anything wrong with Hspec?
12:24:08 <imdoor> geekosaur: if i were to specify the linker flags manually trying to reproduce what ghc is doing internally, do you think that i'd need to use all of the few dozen flags that `ghc -no-hs-main main.o -lstdc++ -lMyHaskelLib -o main -v` shows me in the ***Linker section? https://gist.github.com/rihardsk/97218211f136658f8ad705c1498b75b2
12:25:34 <geekosaur> imdoor, I don't know offhand. some might be optional, but I'd be inclined to provide all of them. maybe by figuring out which ghc-pkg fields they come from and substituting invocations of that
12:25:53 <geekosaur> e.g. yyou get alll the -Wl-u's from the ghc-pkg field invocation I mentioned earlier
12:27:19 <cocreature> I would hope that cabal is capable of linking the Haskell dependencies statically into the lib produced by foreign-library
12:27:22 <ski> i guess given `foo :: (Natural -> [a],b -> IO ())' (say, for some particular `a' and `b'), we'd get
12:27:26 <ski>   $left ($rmap ($map f)) foo = $right ($lmap f) foo
12:27:30 <cocreature> then you should be able to remove all the flags specifying deps
12:27:37 <ski> where both sides get type `foo :: exists x. (Natural -> [x],x -> IO ())' (a coend)
12:29:04 <ski> (instead of getting a law about equivalency between different ways of using/consuming a polymorphic value, we get a law about equivalency between different ways of *producing* an abstracted value)
12:29:05 <geekosaur> cocreature, not easily, and that can cause problems if you are similarly linking multiple foreign libs
12:30:02 <ski> (and `f' has type `a -> b', as in the `concat' case)
12:30:38 <ski> (er, s/left/first/, and s/right/second/ ..)
12:31:21 <cocreature> geekosaur: I’m curious, why not easily? assuming they’re all built with PIC, it seems like that should be possible fairly easily on a technical level. (ignoring the case where you link multiple foreign libs, I guess in that case the RTS might cause problems)
12:31:45 <ski> byorgey : hm, i suppose if you viewed a set as a logic programming predicate of a single argument, which had an out mode, so that you could generate as many solutions as you liked ..
12:32:18 <geekosaur> (a) if you're PIC, static causes problems. (b) static linking rts into multiple objects that are later dynamically loaded is a lovely way to get multiple copies of the RTS running
12:32:41 <geekosaur> or, if you're lucky, duplicate symbol errors when it tries to load the second
12:33:16 <geekosaur> (PIC + static works on x86 but fails on x86-64, iirc)
12:33:33 <erikd> merijn: pong
12:33:40 <cocreature> we are building all Haskell code with -fPIC at work and only linking statically on x86-64
12:34:07 <cocreature> so I’d definitely be interest in learning in what kind of problems we are getting ourselves into by doing that :)
12:34:18 <ski> (e.g. `solutions_set' at <https://www.mercurylang.org/information/doc-latest/mercury_library/solutions.html> converts such a predicate to a set representation (finite in this case, but if you instead keep the predicate, it could itself represent the set, also infinite ones (as long as they're countable, i suppose)))
12:35:43 <geekosaur> hm, maybe it works in that direction then. the problems I recall are indirection pointers going wrong, so using PIC-configured data would be prone to crash or read garbage (writes more likely to crash)
12:36:42 <fvr> why doesn't stack pickup my system ghc-8.6.3 and instead tries to download ghc-8.6.4, with system-ghc: true set?
12:36:51 <geekosaur> I know the common x86 hack of loading static objects as if they were dynamic failed on x86-64 due to things like the above; suppose the other direction is more likely to work, the main problem would be slowness because everything's going through unnecessary GOT indirections
12:38:31 <imdoor> i took a look what `ghc-pkg --simple-output field rts ld-options` produces. using that might be the most feasible route actually. if i get all the -u flags that way i *only* have to add "-lHSbase-4.12.0.0 -lHSinteger-gmp-1.0.2.0 -lHSghc-prim-0.5.3 -lHSrts -lgmp -lm -lrt -ldl -lffi -lpthread" (or try to get that out of ghc-pkg as well as geekosaur suggested)
12:39:04 <imdoor> that and the corresponding -L flags
12:39:33 <byorgey> ski: yes, that sounds sensible.  I think some sort of hybrid scheme might work.  I wouldn't want to literally represent all sets as predicates becuase then just printing something simple like {10^10} would presumably take a very long time, since it would have to apply the predicate to all the natural numbers up to 10^10
12:40:54 <ski> byorgey : cutting off how many elements are generated, or having an interactive system that allows one to click on the `..' to expand it a bit, could be useful (cf. Vital)
12:41:20 <geekosaur> the field "depends" in base gives you most of the libs (recurse on those to get the others; look for the hs-libraries field in those)
12:41:26 <ski> (also, how to handle multiply generated elements ? you need equality to determine that you have a duplicate, to avoid listing it again)
12:41:34 <byorgey> ski: yes, I plan on doing things like that
12:41:55 <geekosaur> also the -Ls come from other fields, notably library-dirs / dynamic-library-dirs
12:41:59 <byorgey> ski: what is Vital?  do you have a link?  it doesn't seem very googleable =)
12:42:07 <geekosaur> so you could generate those once
12:42:16 <ski> byorgey : yes, a choice sequence results from taking any determined prefix and grafting it in front of another choice sequnce
12:42:51 <ski> so, when you have force the set a little, you have some "prefix" of already seen elements, and a computation for attempting to generate more
12:43:16 <byorgey> right, that makes sense
12:43:31 <byorgey> hmm, what if instead of a boolean predicate you used a function to N which told you how many values of the set are <= the argument.  Then you could binary search for elements.
12:43:38 <ski> byorgey : .. also, perhaps you could use Escardó's trick for actually comparing some infinite sets for equality
12:43:46 <byorgey> This only works for linearly ordered domain types of course.
12:43:59 <ski> @where Vital
12:43:59 <lambdabot> "Vital is a document-centered implementation of Haskell","The Vital project (acronym: Visual Interactive Typed Applicative Language) is investigating a /document-centered/ approach to functional
12:43:59 <lambdabot> programming with an emphasis on the display and /direct manipulation/ of complex data structures." (cf. spreadsheets) <http://www.cs.kent.ac.uk/projects/vital/>,<https://web.archive.org/web/2009052901
12:43:59 <lambdabot> 0107/http://www.cs.kent.ac.uk:80/projects/vital/>
12:44:52 <ski> old thing that was meant to be beginner-friendly. a sortof (potentially infinite) spreadsheet view of data in Haskell. it would compute more elements, as you scrolled more over
12:44:56 <byorgey> ski: yeah, I've considered that.  I kind of doubt those particular infinite sets will come up very often in an introductory setting though =)
12:45:51 <ski> "what if ..." -- only considering sets of naturals ?
12:46:02 <ski> hmhm
12:50:05 <dmwit> byorgey: You know about data-ordlist?
12:50:16 <dmwit> Perhaps you could make a data-ordzipper to get infiniteness in both directions.
12:50:27 <dmwit> (Is the question under discussion how to design a type for infinite sets?)
12:51:31 <dmwit> You lose a fair bit of efficiency this way compared to a balanced tree, but perhaps some tricks could be played with chunking into locally balanced trees.
12:51:35 <Solonarv> yes indeed
12:52:51 <byorgey> dmwit: thanks for the link, I'll have to study that
12:53:13 <imdoor> geekosaur: oh, nice. it seems i'll be able to automate the flag generation then. thanks :)
13:49:14 <mynameis> hey guys
13:49:33 <mynameis> i have a problem with monoids and wondered if i could find some help here
13:50:03 <mynameis> basically im following along this tutorial on domain modeling https://www.youtube.com/watch?v=pe6S5skZwNE
13:50:35 <mynameis> there's this guy 
13:50:39 <mynameis> data Report = Report     { budgetProfit :: Money     , netProfit :: Money     , difference :: Money     } deriving (Show, Eq)
13:50:47 <mynameis> instance Monoid Report where     mempty = Report 0 0 0     mappend (Report b1 n1 d1) (Report b2 n2 d2) =         Report (b1 + b2) (n1 + n2) (d1 + d2)
13:51:04 <mynameis> and this function
13:51:07 <mynameis> calculateProjectReport :: Project -> IO Report calculateProjectReport = calc     where         calc (Project p _) =             calculateReport <$> DB.getBudget p <*> DB.getTransactions p         calc (ProjectGroup _ projects) = foldl 
13:51:26 <mynameis> well that's awfully formated
13:52:11 <slack1256> yeah, use a pastebin
13:52:35 <mynameis> ok gonna set that up
13:57:23 <mynameis> ok the code is here https://pastebin.com/xycC80wb
13:57:52 <mynameis> I have trouble getting the function calculateProjectReport to work
13:58:50 <mynameis> that's the error I get https://pastebin.com/hJW7HVzT
14:02:30 <glguy> mynameis: If you're going to use pastebin.com, please use the "raw" links
14:04:45 <glguy> mynameis: In place of: foldMap calc projects, you could do: fold <$> traverse calc projects
14:05:04 <mynameis_> thank you
14:05:55 <glguy> traverse calc :: [Project] -> IO [Report]
14:07:10 <glguy> And then you can get rid of 'pure' from asProfit and change "getSum (foldMap asProfit transactions)" to "sum (map asProfit transactions)"
14:08:29 <glguy> Or instead of using 'pure' you could use 'Sum'. Generally I'd avoid trying to use these newtype wrappers with foldMap as an alternative to direct solutions like 'sum'
14:10:09 <mynameis_> yeah i'm new to using custom types and dealing with them
14:49:04 <reallymemorable> I'm reading about monoids and watching lectures by Milewski
14:49:18 <reallymemorable> I can grasp associativity / the other properties
14:49:39 <reallymemorable> but I am having trouble grasping where these concepts break into something practical / useful
14:49:57 <dmwit> Don't sweat it too much.
14:50:01 <reallymemorable> I can't see yet how monoids solve actual problems
14:50:14 <dmwit> There happen to be a lot of monoids, and it turns out to be handy to have a common name for those many operations.
14:50:17 <reallymemorable> they seem so importent
14:50:42 <reallymemorable> so its just the name of a typeclass?
14:50:53 <hpc> being able to use the same operators and way of thinking for all of them is the benefit, really
14:51:03 <dmwit> It's a mental chunking technique mostly, I think.
14:51:24 <dmwit> There's a couple operations that are generalized to handle any Monoid, so it's nice not to have to reimplement those operations over and over for each monoid.
14:51:45 <dmwit> But not nearly as many operations as there are for, say, the Functor-Applicative-Monad hierarchy. =)
14:52:10 <reallymemorable> So its like defining Int
14:52:32 <reallymemorable> in that it is generally helpful to know there are many kinds of numbers
14:52:42 <ski> > sortBy (comparing length <> compare) (words "The quick brown fox jumps over the lazy dog")  -- one nice monoids application : prioritized sorting (primarily sort by aspect A, secondarily by aspect B), aka lexicographical ordering
14:52:44 <lambdabot>  ["The","dog","fox","the","lazy","over","brown","jumps","quick"]
14:53:21 <ski> otherwise, when you want to "summarize" some information (logging, average, &c.)
14:54:23 <reallymemorable> ski: in that example the monoid rules are useful because you can measure length and order of letters?
14:54:43 <ski> "monoid rules" being ? the laws ?
14:54:45 <reallymemorable> the value is the flexibility to do multiple kinds of operations on the same data without transformations?
14:54:51 <reallymemorable> i guess yes
14:54:58 <reallymemorable> i am still not sure of myself with the language
14:55:46 <hpc> reallymemorable: eventually you'll encounter stuff where you go "oh that's a monoid, i don't have to learn anything new here" and then it'll make sense :D
14:55:50 <ski> one can think of monoids as being about "smashing together" an (ordered) (possibly empty) list of items, into a single itme
14:56:20 <reallymemorable> and i can recognize a monoid by its having (1) identity and (2) associativity?
14:56:30 <ski> (the smashing operation may, or may not care about the ordering. but the ordering is available, if the monoid should care.)
14:56:32 <dmwit> Yes, that is the definition of a monoid.
14:56:45 <reallymemorable> what is an example of something that is not a monoid
14:57:07 <ski> subtraction ?
14:57:11 <Rembane> Matrix multiplication! 
14:57:12 <dmwit> Numbers, together with division, is not a monoid.
14:57:23 <reallymemorable> because it lacks associativity
14:57:24 <ski> Rembane ?
14:57:37 <hpc> matrix multiplication loses commutativity
14:57:40 <Rembane> ski: I got it wrong. :(
14:57:40 <dmwit> ski: I guess the objection is that there's not a single, fixed identity, but rather one for each size of matrix.
14:58:05 <ski> dmwit : well, for each size, there's a different monoid :)
14:58:18 <dmwit> Matrix multiplication forms a category.
14:58:31 <ski> (talking about square matrices. arbitrary matrices is another thing, a category)
14:58:31 <dmwit> The objects are dimensionality, the arrows matrices.
14:58:38 <Rembane> Neat! 
14:58:38 <ski> yep
14:59:25 <dmwit> (...and composition is multiplication, identities are the usual matrices traditionally named I, to tie all the knots together.)
15:00:49 <LunarJetman> is God a monoid or a category error?
15:01:00 <ski> an infinite matrix as finite support on columns (vectors), but not necessarily on rows (covectors)
15:01:02 <reallymemorable> ok so there are monoids and a family of oeprations you can run on monoids
15:01:34 <reallymemorable> and they are useful because they give you ideas of what opeartions you can run on things you encounter
15:01:39 <reallymemorable> if you deduce that it's a monoid
15:02:32 <dmwit> That sounds right to me.
15:02:38 <reallymemorable> ok lol
15:02:57 <reallymemorable> after one hour of a Milewski lecture i was still like wtf when will i use this
15:03:11 <reallymemorable> 5 minutes on IRC fixed that
15:03:20 <dmwit> All three of those sentences seem to apply to just about any abstraction.
15:03:40 <reallymemorable> yeah but a monoid gives you a specific set
15:03:44 <reallymemorable> of operations
15:04:10 <LunarJetman> that propery isn't unique to monoids
15:04:14 <LunarJetman> property*
15:04:21 <reallymemorable> but the specific operations are
15:04:26 <reallymemorable> no?
15:04:33 <dmwit> This argument is silly.
15:04:41 <LunarJetman> is an integer a monoid?
15:04:55 <dmwit> There are many monoids on integers.
15:05:03 <LunarJetman> that wasn't the question
15:05:05 <ski> no, a single integer is not a monoid
15:05:16 <LunarJetman> is the "type" integer a monoid?
15:05:23 <ski> you need a set of things, and operations regarding that set
15:05:28 <LunarJetman> an integer has a set of specific operations you can use with it
15:06:23 <ski> LunarJetman : handwaving yes. strictly speaking, a monoid is a triple `(X,e,m)' where `e' is an element of the set `X' and `m' a binary operation on `X', that satisfy the monoid laws
15:06:32 <Solonarv> yes, there are many monoids on integers. Some examples (naming only the binary operation): +, *, gcd, lcm
15:06:43 <LunarJetman> you could argue that division is not supported by integers whilst multiplication is
15:07:31 <slack1256> that is not even discussed, it just known
15:07:40 <Solonarv> division isn't a monoid anyway, because in general x  / (y / z) ≠ (x / y) / z
15:08:00 <LunarJetman> I am not asking if an operation is a monoid I am asking if a type (integer) is a monoid
15:08:27 <ski> a type/set, *together* with two operations fitting the monoid signature, and satisfying the laws, is a monoid
15:08:29 <slack1256> monoids aren't just set, they are tuples of (Set, operations)
15:08:42 <ski> there are many ways to make the type/set `Integer' into a monoid
15:08:46 <ski> (different operations)
15:08:52 <Solonarv> Often there's more than one possible monoid on a set
15:09:19 <dmwit> The direct answer to your question is: No. There is no type X for which X is a monoid.
15:09:42 <reallymemorable> dmwit: is that directed at me?
15:09:55 <LunarJetman> it is Saturday night, shouldn't we be out partying rather than discussing such abstract concepts?
15:09:59 <ski> a better answer might be "not even wrong"
15:10:03 <dmwit> reallymemorable: No, it is directed at LunarJetman.
15:10:17 <dmwit> reallymemorable: Do you have a question that you feel was not yet answered?
15:10:21 <reallymemorable> I discovered Haskell a couple weeks ago and now all i want to do is learn about it
15:10:22 * ski thought we were having a party ?
15:10:24 <Solonarv> dmwit: but once we have dependent haskell then 'Dict (Monoid Foo)' is a type, and that arguably *is* a monoid! :p
15:10:32 <reallymemorable> yes i understand a lot better now
15:10:34 <reallymemorable> thanks a lot
15:10:39 <absence> trying to grasp the current situation on records in haskell. are vinyl and makeClassy in lens somewhat similar, and is the point of OverloadedRecordFields to get something like that into ghc itself?
15:10:59 <Solonarv> absence: roughly speaking, yes to all three of your sub-questions
15:11:34 <absence> Solonarv: cool, thanks
15:11:36 <dmwit> (Aren't there only two sub-questions?)
15:11:57 * ski goes out in search of sober spaces
15:12:09 <LunarJetman> isn't a sub-question just a question? or is a sub-question predicated on the parent question being answered?
15:12:10 <Solonarv> dmwit: (is vinyl somewhat similar?), (is makeClassy in lens somewhat similar?), (is the point of OverloadedRecordFields... ?)
15:12:52 * ski . o O ( some things are more similar than other )
15:13:36 <Solonarv> ski: of course, however (unlike most of the time :p) I didn't feel like going into detail
15:13:58 <reallymemorable> Identity is just a specific functor
15:14:01 <dmwit> I have a hard time imagining a situation in which the first two questions could possibly have a different answer.
15:14:07 <reallymemorable> that takes a monoid and gives you that monoid back?
15:14:13 <dmwit> s/a different answer/different answers/
15:14:38 <dmwit> reallymemorable: Although that's true, it doesn't seem... super relevant?
15:14:50 <dmwit> Identity always gives you back the same type it got, whether that was a Monoid or not.
15:14:51 <reallymemorable> im just trying to understand how to define identity
15:14:55 <reallymemorable> ok
15:14:57 <reallymemorable> but its a functor?
15:15:03 <dmwit> Sure, why not.
15:15:03 <reallymemorable> Identity is a specific functor
15:15:05 <Solonarv> yes
15:15:23 <reallymemorable> and it gives you the same thing back no matter waht input you give it?
15:15:26 <Solonarv> more generally, Identity is a functor which takes a <whatever> and gives you the same <whatever> back
15:15:41 <dmwit> reallymemorable: Up to isomorphism, yes.
15:15:58 <reallymemorable> so why include it in the definition of monoid?
15:16:03 <reallymemorable> if its relevant to any typeclass?
15:16:10 <dmwit> reallymemorable: But I wonder if the Identity you are thinking of and the identity that's spawning this question are really the same thing.
15:16:19 <dmwit> reallymemorable: Ah, see! It isn't the same thing at all.
15:16:21 <ski> `Identity' here is a function from `Hask' to itself, not from `Mon' to itself
15:16:40 <dmwit> reallymemorable: A Monoid's identity is a value of the monoidal type.
15:16:51 <ski> (the latter obviously also would have an identity functor on it ..)
15:16:52 <dmwit> In Haskell specifically, we use the name mempty to refer to that value.
15:17:05 <dmwit> Identity, a type constructor, is a completely different thing.
15:17:09 <reallymemorable> mempty is a value
15:17:18 <reallymemorable> and when you give something to mempty
15:17:18 <dmwit> mempty is a computation-level thing, yes.
15:17:23 <reallymemorable> it gives you that thing back
15:17:26 <dmwit> No. The question is wrong.
15:17:32 <dmwit> mempty is not (necessarily) a function at all.
15:17:58 * ski prefer to talk about a "neutral element" (or maybe "unit") belonging to a monoid
15:18:02 <dmwit> However, mappend mempty x = x and mappend x mempty = x, and this justifies the name identity.
15:18:25 <reallymemorable> is that bc of associativity?
15:18:36 <dmwit> No, it is the defining characteristic of an identity.
15:18:42 <dmwit> Associativity is a different property.
15:18:43 <ski> it's because of the left and right neutral element laws that dmwit just mentioned
15:18:59 <reallymemorable> im so lost
15:19:04 <dmwit> (Precision: it is the defining characteristic of a monoid's identity.)
15:20:16 <dmwit> reallymemorable: It might help to talk about a few examples?
15:20:19 <LunarJetman> how is mappend defined?
15:20:22 <dmwit> reallymemorable: Here's one you know.
15:20:51 <dmwit> reallymemorable: For numbers, the additive identity is 0. Specifically, this means 0+x = x and x+0 = x.
15:21:09 <dmwit> reallymemorable: Again for numbers, the multiplicative identity is 1. That is, 1*x = x and x*1 = x.
15:21:16 <reallymemorable> ok
15:21:18 <dmwit> reallymemorable: Notice how "identity" is always tied to a specific operation.
15:21:30 <reallymemorable> ok
15:21:35 <dmwit> Here's another operation you probably know well: list concatenation, which Haskell calls (++).
15:21:38 <reallymemorable> there is a different identity for each operation
15:21:41 <dmwit> What's the identity for (++)?
15:22:12 <reallymemorable> hmmm
15:22:15 <LunarJetman> that empty element thing
15:22:25 <excelsiora> [] ++ list_thingy?
15:22:29 <reallymemorable> "" ++ "yes" = "yes"
15:22:45 <dmwit> reallymemorable: Right! For String specifically, "" is the identity for (++).
15:23:04 <reallymemorable> ah
15:23:08 <LunarJetman> so how is mappend defined?
15:23:12 <dmwit> (The right generalization to other types of lists is to take the empty list [], for which "" is just another spelling.)
15:23:13 <excelsiora> *relurks*
15:23:27 <reallymemorable> ok
15:23:32 <dmwit> reallymemorable: Here's another operation you know well: (&&).
15:23:33 <reallymemorable> so a monoid must have some kind of identity
15:23:34 <dmwit> logical and
15:23:39 <dmwit> reallymemorable: What's the identity for (&&)?
15:23:50 <reallymemorable> True && True?
15:23:51 <dmwit> We're looking for a value foo such that foo && x = x && foo = x.
15:24:04 <reallymemorable> True && True = True
15:24:34 <dmwit> reallymemorable: Well, True && True is... two values, sort of.
15:24:38 <dmwit> We're looking for a single Bool.
15:24:59 <reallymemorable> hmmm
15:25:10 <dmwit> (I mean, you're kind of right? I think? But the way you answered makes me think you haven't *quite* figured out what I'm asking yet, so maybe tell me how I can be more clear or what's confusing.)
15:25:13 <reallymemorable> && True = True?
15:25:18 <LunarJetman> doesn't anyone know how mappend is defined?
15:25:36 <dmwit> LunarJetman: mappend is defined differently for each instance of Monoid. Which instance are you interested in just now?
15:25:46 <LunarJetman> any instance
15:25:50 <dmwit> reallymemorable: Sounds like you're guessing.
15:25:54 <reallymemorable> i am lol
15:25:55 <dmwit> LunarJetman: Okay. Then mappend = ()
15:26:07 <dmwit> LunarJetman: err, I mean mappend _ _ = () of course. sorry =P
15:26:42 <dmwit> reallymemorable: Okay. Let's start here: do you understand the question I'm asking?
15:26:50 <reallymemorable> Yes
15:26:57 <reallymemorable> what can you put with && and True
15:26:59 <reallymemorable> to get True back
15:27:08 <dmwit> Ah. No, I think you don't understand the question yet.
15:27:11 <LunarJetman> are we like, monks?
15:28:18 <reallymemorable> is it what can we put with && and any Bool to get that Bool back?
15:28:27 <reallymemorable> Nothing && True = True?
15:28:31 <dmwit> reallymemorable: Yeah, that's a better phrasing.
15:28:39 <dmwit> > Nothing && True -- eh?
15:28:39 <reallymemorable> I thought Bool had only two type constructors
15:28:41 <lambdabot>  error:
15:28:41 <lambdabot>      • Couldn't match expected type ‘Bool’ with actual type ‘Maybe a0’
15:28:41 <lambdabot>      • In the first argument of ‘(&&)’, namely ‘Nothing’
15:28:52 <dmwit> reallymemorable: Bool has only two *data* constructors, correct.
15:29:01 <LunarJetman> the reason why I ask that question is that reality could be an infinitely complex mathematical structure (see Mathematical Universe Hypothesis)
15:29:03 <ski> (dmwit : not `mappend () () = ()', then ?)
15:29:05 <dmwit> reallymemorable: So it shouldn't be hard to either find a value that works or prove that none do -- we only have to try two. =)
15:29:13 <dmwit> ski: Okay, I admit I'm not sure!
15:29:25 <reallymemorable> ok
15:29:27 <reallymemorable> I mean
15:29:31 <ski> (if you don't care about bottoms, it doesn't matter :)
15:29:39 <reallymemorable> I think I conceptually understand what you are saying but with only two data constructuros
15:29:44 <dmwit> ski: My answer was mostly intended to point out that the question sucked by answering as obnoxiously as possible. =)
15:29:49 <reallymemorable> I don't understand what else you could write besides True or False
15:29:57 <Solonarv> well, it must be one of those two then!
15:29:58 <dmwit> reallymemorable: can't write anything else
15:30:08 <dmwit> reallymemorable: Is it a problem that you can't write anything else?
15:30:13 <LunarJetman> dmwit: why did me question suck?
15:30:14 <reallymemorable> yeah so why isn't True && True = True correct?
15:30:23 <reallymemorable> && True = True?
15:30:40 <reallymemorable> am i discovering that Bool isnt a monoid?
15:30:41 <dmwit> That is a true fact, but not an answer, because the answer must be one of `True` or `False`. `True && True = True` is not one of `True` or `False`.
15:30:50 <ski> `True && True = True' isn't a single boolean, it's an equation
15:31:00 <reallymemorable> True && True == True
15:31:05 <LunarJetman> dmwit: are you an arrogant arsehold? why did my question suck?
15:31:23 <dmwit> LunarJetman: Because I cannot discern a consumer for the answer.
15:31:44 <dmwit> And to answer your other question, yes, I am indeed an arrogant arsehold [sic].
15:31:52 * ski . o O ( `(exists a. a) = ()' )
15:32:00 <LunarJetman> I need an answer because I am implementing haskell to I need to know what the primitives are.
15:32:14 <LunarJetman> s/to/so/
15:32:43 <Solonarv> 'mappend' isn't a "primitive", it's an ordinary typeclass method
15:32:56 <Solonarv> (it is part of the standard library, but that doesn't make it special or magical)
15:33:01 <LunarJetman> and by "primitive" I mean something that cannot be defined in terms of something else
15:33:29 <Maxdamantus> What's an example of something that's not primitive?
15:33:43 <LunarJetman> Maxdamantus: from the point of view of the Haskell language
15:33:54 <Solonarv> well in *that* sense it's a primitive, but then 'Bool' as defined in 'data Bool = False | True' is also a "primitive"
15:33:55 <Maxdamantus> LunarJetman: from your point of view.
15:34:26 <LunarJetman> Maxdamantus: I believe I have alrady answered that question
15:34:37 <Maxdamantus> LunarJetman: I don't see any examples.
15:34:47 <Solonarv> class Semigroup m => Monoid m where
15:34:47 <Solonarv>   mappend :: m -> m -> m
15:34:47 <Solonarv>   mappend = (<>)
15:34:47 <Solonarv>   mempty :: m
15:34:47 <reallymemorable> dmwit: was the conclusion that Bool is not a Monoid?
15:34:48 <dmwit> reallymemorable: I really want to help you further, but at this point I'm pretty lost about how. There's a fundamental gap here between us that I don't know how to bridge.
15:34:53 <LunarJetman> Maxdamantus: my point of view is how to implement a Haskell compiler
15:34:55 <reallymemorable> ok
15:34:56 <Solonarv> ^ there's the definition of mappend
15:35:03 <reallymemorable> I will go back and read more
15:35:12 <reallymemorable> thanks for the help, I partially understand
15:35:28 <Maxdamantus> LunarJetman: okay, that's not really answering my question though. My question was: what's an example of something that's not primitive?
15:35:42 <Maxdamantus> LunarJetman: because if `Boolean` is considered primitive, then what *ISN'T* considered primitive?
15:35:55 <LunarJetman> Maxdamantus: soemthing that is not implemented in terms of something else from the point of view of writing a Haskell compiler.
15:36:25 <dmwit> reallymemorable: Maybe arguing from the other direction would be helpful to let you see the category error I think you're making.
15:36:28 <geekosaur> Maxdamantus, tuples because support needs to be baked in to construct types "on the fly" (you don't, and can't, declare a 2-tuple as a new type before use)
15:36:29 <Solonarv> LunarJetman: you're just repeating your definition, but you're being asked to give an *example*
15:36:47 <geekosaur> note that Haskell allows a bunch of things that would be primitive in other languages to be defined within the language
15:36:49 <LunarJetman> I don't have an example which is why I am asking the fucking question. FOR FUCK'S SAKE.
15:36:52 <dmwit> reallymemorable: So, we've already said that for numbers, the identity for + is 0. Do you agree with that?
15:37:16 <Maxdamantus> LunarJetman: so if I write `data Possibility = Possible | Impossible`, is that considered to be implemented in terms of something else?
15:37:16 <reallymemorable> yes
15:37:35 <geekosaur> likewise lists are baked in for various reasons, more related to syntax than semantics
15:37:45 <LunarJetman> I want a definition of mappend that uses only Haskell language primitives 
15:37:53 <dmwit> reallymemorable: Cool. Okay, so now imagine asking the question: what number is the identity for +? And instead of getting back the answer "0", you get back the answer "0+0 = 0". What would you say to enlighten them that "0+0 = 0" is not a number?
15:38:04 <Solonarv> LunarJetman: I gave the actual definition as it is in the standard library, above
15:38:08 <Solonarv> did you miss that?
15:38:27 <geekosaur> most of the other primitives arent directly exposed untless you turn on MagicHash; for example, Int is not itself primitive, but it's defined in terms of Int# which is
15:38:34 <geekosaur> (signed machine word)
15:38:36 <LunarJetman> Solonarv: then you answered my question, thanks. Now would you please insert a carrot up Maxdamantus's arse? thanks.
15:39:03 --- mode: ChanServ set +o dmwit
15:39:07 <reallymemorable> dmwit: it's an operation
15:39:12 --- kick: LunarJetman was kicked by dmwit (That attitude is not appropriate.)
15:39:17 <reallymemorable> (am I missing the point?)
15:39:22 <Solonarv> dmwit: thanks, oof
15:39:23 --- mode: dmwit set -o dmwit
15:39:24 <geekosaur> Maxdamantus, that definition is based on language primitives, specifically how "data" constructs a new algebraic data type
15:40:03 <dmwit> reallymemorable: Well, it isn't an operation, either. It's an equation. But it's *definitely* not a number.
15:40:24 <reallymemorable> because it doesnt meet the requirements of typeclass num
15:40:44 <dmwit> reallymemorable: And "True && True = True" isn't a Bool, either. When you change it to "True && True == True" it happens to be a Bool by accident, but it's... really a sign that you've missed the point, since we're hoping for either True or False!
15:41:08 <reallymemorable> oh
15:41:11 <Maxdamantus> geekosaur: okay, but I was wondering what LunarJetman was asking when he was saying "primitive", because he seemed to be including Bool/True/False as "primitives"
15:41:12 <reallymemorable> So the identity of True
15:41:14 <reallymemorable> is True
15:41:29 <dmwit> True is not an operation. So it doesn't make sense to say "the identity of True".
15:41:47 <reallymemorable> return?
15:41:50 <reallymemorable> pure?
15:41:56 <LunarJetman> Maxdamantus: I don't recall mentioned anything associated with booleans.
15:42:07 <geekosaur> Maxdamantus, that's why dmwit has been remonstrating with him; there's a disconnect somewhre. possiby based on the fact that they can be in Haskell, but compilers for many other languages are forced to wire them in
15:42:10 <dmwit> And now I know I've lost. I can see you're trying to guess the teacher's password, which is an indictment of the teacher, not the student.
15:42:15 <dmwit> But I don't know how to fix it.
15:42:22 <reallymemorable> lol sorry
15:42:29 <reallymemorable> i will go back and study more
15:42:33 <reallymemorable> hopefully will understand more tomorrow
15:42:41 <reallymemorable> thanks for the help :P
15:42:43 <dmwit> (https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password in case you hadn't heard that term before)
15:42:57 <geekosaur> reallymemorable, consider that an expression is lazy in Haskell, and there are tricks whereby evaluation of that particular on won't evoke a side effect, but some others will (consider what getContents gives you)
15:42:58 <reallymemorable> i am trying to think about the problem
15:43:03 <reallymemorable> but i am just so new to this i think
15:43:08 <Cale> What was the original question?
15:43:14 <geekosaur> in a strct langage there's no difference between the two
15:43:33 <dmwit> Cale: We're exploring the concept of monoids together.
15:43:39 <geekosaur> in Haskell, an expression can be lazy and under soem circumstances can do I/O behind the scenes
15:43:40 <dmwit> Cale: He seems a bit stuck on what "identity" means.
15:43:45 <dmwit> ...or she
15:43:48 <reallymemorable> he 
15:43:52 * dmwit nods
15:44:10 <geekosaur> so you do wan t to keep straight the difference between a value and an expression that when evaluated produces that value
15:44:34 <geekosaur> especially if writing a compiler, which I believe is what started this? because in a compiler they are also different in terms of having different syntax trees
15:44:44 <reallymemorable> ok so i am trying to identify the value
15:44:52 <reallymemorable> not the expression
15:45:13 <geekosaur> True is a data constructor, therefore a value
15:45:28 <reallymemorable> right
15:45:29 <Cale> There's not much to it, the identity element of your monoid M is a value e :: M so that for any value x :: M, we have both e <> x = x and x <> e = x.
15:45:31 <Solonarv> reallymemorable: and keep in mind what we're looking for: we're trying to see if there is some way to complete (Bool, &&, _) to get a monoid
15:45:59 <geekosaur> ``True && True'' is an expression. to a compiler it's not the same as True, and a specific operation (constant folding) must be built into a compiler for it to determine that it has the same value at compile time as ``True''
15:47:33 <geekosaur> in Haskell, if there happens to be a different definition of (&&) in scope, constant folding isn't necessarily safe there — and under some circumstances, the replacement (&&) might be able to do unexpected things. (This is highly disrecommended because about the only reason you'd do that is to set a trap for someone looking at it later)
15:48:22 <geekosaur> (gcc's and clang's constant folding can both be tricked the same way. it's not at all trivial to get this stuff right 100% of the time)
15:48:24 <reallymemorable> ok so to state something super basic
15:48:38 <reallymemorable> you are asking me for the identity *value* of True
15:48:52 <LunarJetman> geekosaur: this is why I think implementing Haskell is going to be fun.
15:49:02 <geekosaur> oh, your problem here is the concept of identity in the context of monoids, as I understand it
15:49:48 <geekosaur> with respect to monoids, an identity is a specific value *with respect to a particular operator* which nullifies the effect of that operator
15:49:59 <reallymemorable> ah
15:50:00 <dmwit> reallymemorable: Okay, so the current hypothesis that I think is in your head, and which I will state again here to cement the terminology, is this: True is the identity for (&&).
15:50:02 <geekosaur> for (&&) this is True. for (||) it is False. for (+) it is 0
15:50:18 <dmwit> reallymemorable: Do you agree that this is your hypothesis? If so, we can test it out!
15:50:28 <geekosaur> because if you apply one of those operators to some value and its associatetd identity, you get the original valie back
15:50:48 <reallymemorable> so identity is a value-operater pair
15:50:52 <geekosaur> no
15:50:55 <reallymemorable> that nullifies the operator
15:51:03 <reallymemorable> oh
15:51:05 <reallymemorable> i see
15:51:08 <geekosaur> a monoid is. an identity appropriate for the operator is one of the members of the pair
15:51:10 <reallymemorable> its a value that nullifies an operator
15:51:17 <geekosaur> ((&&),True) is a monoid
15:51:39 <MarcelineVQ> That's the third new syntax for monoid introduced during this convo ^^;
15:51:40 <geekosaur> ((+),0) is a monoid
15:51:55 <Solonarv> (being pedantic: it's really (Bool, (&&), True) and so on for the others)
15:52:09 <geekosaur> well, monoid as such requires left and right identities to be the same
15:52:14 <reallymemorable> the first element of that tuple is just declaring the type
15:52:15 <reallymemorable> ?
15:52:18 <Solonarv> yes
15:52:36 <geekosaur> so you only do that figoing on to the next level, which is reaching a bit too far if we're unclear on identity in the context of monoids
15:52:38 * hackage sbv 8.1 - SMT Based Verification: Symbolic Haskell theorem prover using SMT solving.  https://hackage.haskell.org/package/sbv-8.1 (LeventErkok)
15:52:59 <geekosaur> oh, righ, sorry
15:53:03 <reallymemorable> so the combination of True + && on True
15:53:08 <reallymemorable> nullifies the effect of &&
15:53:19 * geekosaur needs to read more closely while typing, but yes there's a type. in Haskell; number theory monoids are a bit looser
15:53:33 <geekosaur> which is where the haskell one comes from
15:53:52 <Solonarv> geekosaur: even in the broader math context you usually have to specify the underlying set
15:53:57 <geekosaur> and the point here is that ``identity'' has a context
15:54:06 <Solonarv> (of course, sometimes it's obvious from context and people will leave it out)
15:54:41 <geekosaur> this is actually kind of unfortunate since terms end up meaning too manyu different things
15:55:05 <geekosaur> but the other direction means you get e.g. ``isomorphism'' and wonder why we didn't say ``equivalent'' or something
15:55:11 <reallymemorable> so (Bool, (&&), False) is also a monoid
15:55:13 <geekosaur> (``equal'' is an even worse fit)
15:55:20 <LunarJetman> Maxdamantus: I am really sorry; I confused you with dmwit who told me my question sucked not you.
15:55:38 <ski> reallymemorable : test that hypothesis !
15:55:54 <reallymemorable> in the form of an expression?
15:56:07 <reallymemorable> False && False == False?
15:56:08 <ski> does your suggested monoid satisfy the monoid laws ?
15:56:16 <geekosaur> identity has the same problem, we tend to call "identical" something which is actually an isomorphism (same 'shape' in some sense, but not precisely the same thing)
15:56:30 <ski> (what are the monoid laws, in terms of this suggested monoid with specific operations ?)
15:56:42 <reallymemorable> the monoid laws are identity and applicativity
15:57:16 <reallymemorable> I guess I am not knowledgeable enough about the jargon yet because I struggle to understand what format to write the response
15:57:17 <Cale> associativity, but it's more important to remember what it means than what the name is
15:57:20 <ski> can you spell out what you mean by those two terms (e.g. in the context of this suggested monoid) ?
15:57:45 <Cale> It means that for every x, y, and z in your monoid, you have x <> (y <> z) = (x <> y) <> z
15:57:54 <reallymemorable> associativity in this context is that it doesnt matter whether False comes first or second
15:58:01 <reallymemorable> it will have the same result
15:58:07 <reallymemorable> when used with &&
15:58:07 <Cale> uh
15:58:13 <ski> reallymemorable : sorry, that doesn't sound right
15:58:25 <Cale> You're thinking of the two parts of the identity law?
15:58:39 <ski> (presumably)
15:58:49 <reallymemorable> im trying to articulate why a Bool is a monoid
15:58:53 <Cale> There are really two identity laws, that mempty <> x = x
15:58:59 <Cale> and that x <> mempty = x
15:59:00 <ski> why `(Bool, (&&), False)' is a monoid
15:59:16 <Cale> But that's different from associativity
15:59:26 <dmwit> (I'm torn about whether it's useful to include explicit quantifiers here. for all x. mempty <> x = x)
15:59:30 <Cale> Note also that in general it may not be the case that x <> y = y <> x
15:59:42 <ski> dmwit : just describe them informally, like "always"
16:00:28 <Cale> Yeah, I'm leaving out the quantifiers there, these things have to work for all x
16:00:38 <ski> > "ab" ++ "c"
16:00:41 <lambdabot>  "abc"
16:00:42 <ski> > "c" ++ "ab"
16:00:44 <lambdabot>  "cab"
16:00:59 <ski> here `x' was `"ab"', `y' was `"c"', and `<>' was `++'
16:01:12 <reallymemorable> right
16:01:18 <michalrus> / Does it make, hmm… “conventional” sense to introduce a lot of my own booleans for readability/correctness? Like `data IsFakeUser = FakeUser | RealUser`?
16:01:34 <ski> the different results shows that `x <> y = y <> x' doesn't have to hold generally, depending on which monoid we're considering
16:01:41 <Cale> Also, did you mean (Bool, (&&), True) or did you mean (Bool, (||), False)?
16:01:54 <ski> michalrus : sometimes
16:01:55 <dmwit> michalrus: It can help to remember which "side" of the boolean is which.
16:01:58 <Cale> Or was the exercise to check that this isn't actually a monoid?
16:02:06 <michalrus> Okie.
16:02:11 <geekosaur> michalrus, it often does because reusing Bool means you can have logic errors that don't show up as type errors. (this one common enough that it has a name: boolean blindness)
16:02:31 <michalrus> Mhm. :) Thank you.
16:02:41 <Cale> Boolean blindness is a thing which can't actually be cured in Haskell
16:02:43 <ski> Cale : no, `(Bool, (&&), True)' was what they claimed was a monoid, and i suggested testing that hypothesis
16:02:47 <Cale> ahh
16:02:48 <dmwit> I don't think introducing a type isomorphic to Bool helps with boolean blindness.
16:03:00 <ski> @where boolean-blindness
16:03:00 <lambdabot> http://existentialtype.wordpress.com/2011/03/15/boolean-blindness/
16:03:02 <dmwit> Now if the RealUser constructor had a field with evidence that the user was real, that *would* help.
16:03:14 --- mode: ChanServ set +q $a:LunarJetman
16:03:22 <dmwit> e.g. that user's options or similar.
16:03:24 <geekosaur> well, it catches seeinga  True and thinking it represents a different status than it does
16:03:26 <MarcelineVQ> It helps if you don't also define your own if to hide it away again :>
16:03:42 <geekosaur> adding extra inforation does help more, but even the simple onehelps a lot
16:04:07 <geekosaur> and the problem with too much extra inormation is while it may be more reliable, it's also more work --- which encourages other kinds of errors
16:04:14 <geekosaur> you have to set a balance somewhere
16:04:21 <Cale> reallymemorable: Note that if True is supposed to be the identity element here, we ought to have for every x, that True && x = x
16:04:27 <reallymemorable> so (Bool, (||), False) is a monoid
16:04:58 <Solonarv> reallymemorable: yes
16:05:15 <Cale> reallymemorable: (and this holds, you can just check the two possible values)
16:05:59 <Cale> But if we tried to make it (Bool, (&&), False), then we'd need False && x = x, but in particular, that doesn't work when x = True
16:06:05 <reallymemorable> True && True = True
16:06:11 <reallymemorable> True && False = False
16:06:15 <Cale> yeah
16:06:17 <reallymemorable> the two possible x values
16:06:39 <reallymemorable> False || False = True
16:06:46 <reallymemorable> sorry
16:06:51 <ski> (Cale : er, sorry, i meant `(Bool, (&&), False)' ..)
16:06:53 <dmwit> So that shows True && x = x. (And the other way, showing that x && True = x, is similar.)
16:06:53 <reallymemorable> False || FAlse = False
16:07:01 <reallymemorable> False || True = True
16:07:17 <Cale> Right, so False satisfies the left identity law.
16:07:44 <reallymemorable> so in the realm of Bools
16:07:49 <reallymemorable> the identity value for || is False
16:07:58 <reallymemorable> and the identity value for && is True
16:08:52 <Solonarv> correct!
16:09:07 <reallymemorable> and we just need to know whether there is an identity value
16:09:14 <reallymemorable> to declare something a monoid
16:09:17 <reallymemorable> well that and associativity
16:09:23 <deech> Is there currently an issue with Hackage? Stack isn't finding the latest (3 day old) version of my package and trying to get me to use one that's 2 weeks old.
16:09:34 <reallymemorable> and if we have proven something is a monoid, we know about a universe of operations we can run on it
16:10:02 <dmwit> deech: Dunno if stack has anything like it, but in cabal you must run `cabal update` every once in a while to get the latest copy of Hackage's indexp.
16:10:11 <ski> reallymemorable : we also need to have a corresponding operation, even to be able to claim a value is a neutral element ("identity value")
16:10:17 <reallymemorable> deech: I dont know if it's related to what you're mentioning, but the Quandl API on Hackage and GitHub list the same version numbers but the Hackage one does not work
16:10:27 <reallymemorable> and cloning the GH version does
16:10:36 <MarcelineVQ> deech: stack's awareness of hackage does lag a little since it pulls from fpcomplete's version of things iirc, be sure to run stack update if you haven't
16:11:05 <reallymemorable> ski: so identity needs an identity value and a corresponding operation
16:11:32 <deech> I ran `stack update` a few times and it's still doing the same thing. Probably going to have to blow away my `.stack` at this point.
16:11:40 <ski> the neutral element law need a neutral element, and a binary operation, to state the law, yes
16:11:51 <deech> reallymemorable: That sounds like a similar situation.
16:12:02 <MarcelineVQ> That probably won't matter, but if you are going to do that you can just remove the .stack/indices dir
16:12:02 <ski> otoh, the associativity law only needs the binary operation, to be stated
16:12:33 <reallymemorable> ski, what do you mean
16:12:43 <reallymemorable> like 
16:12:44 <reallymemorable> ==?
16:13:04 <Solonarv> the "binary operation" is &&, or ||, or +, or whatever
16:13:43 <Solonarv> the associativity law is 'x <> (y <> z) = (x <> y) <> z' - as you can see, this doesn't mention the identity element at all
16:13:52 <ski> in general terms, it's called `<>' (in Haskell), while the neutral element is called `mempty'
16:14:20 <reallymemorable> binary operation is called <>?
16:14:26 <ski> for specific monoids, you can often give more specific "names", like `&&' and `True' for the conjunction monoid on `Bool'
16:14:27 <deech> Yep, I had to delete '~/.stack/indices'.
16:15:05 <Amras> isn't it the case that for a specific type (not a specific operation) you can only define one Monoid instance though, ski
16:15:17 <MarcelineVQ> deech: good to know that worked thank you, didn't expect it to :>
16:15:19 <Amras> hence the somewhat awkward wrapper types like First and Last for Maybe
16:15:24 <Solonarv> Amras: you can only define one monoid instance for each type, yes
16:15:36 <johnw> Amras: that's rigth
16:16:10 <ski> Amras : yes. we were talking about monoids in general, as opposed to `Monoid' instances in Haskell. but i suppose the distinction could have been clearer
16:16:15 <Amras> ah, right
16:17:13 <ski> `(Bool,(&&),True)' is a monoid, but to make a `Monoid' instance of it, we have to wrap `Bool' inside `All' (a `newtype')
16:17:49 <reallymemorable> and these laws are useful because testing for them on new values we encounter / create let us know what operations we can run on them
16:17:52 <reallymemorable> ?
16:17:54 <ski> (have to, because we also want other monoids on `Bool', and don't want to give any of more more privileged access directly to `Bool' than the others)
16:19:30 <ski> reallymemorable : the monoid laws are useful for : ensuring that if you get a list of values in the monoid, you can (first sprinkle any number of neutral elements across the list, if you want to, then) insert the binary operation inbetween every two values in the list, bracket however you want, and still get the same answer in the end
16:19:39 <ski> (hm, that's a bit of a mouthful)
16:20:10 <ski> for short, the laws are useful to define a function that takes a list of elements, and combines them all using the monoid operations
16:20:14 <Rembane> So as long as you don't change the order of the elements, you can combine them in any order you want? 
16:20:18 <ski> right
16:20:28 <dmwit> Indeed, even in parallel.
16:20:43 <ski> (the monoid structure imposes order. some monoids chose to ignore that order. that's fine)
16:20:49 <dmwit> MapReduce is a parallel implementation of foldMap. =)
16:21:44 <ski> @type mconcat
16:21:45 <lambdabot> Monoid a => [a] -> a
16:21:54 <ski> that's what this function is called, in Haskell
16:22:11 <Solonarv> or the more general version:
16:22:13 <Solonarv> @type fold
16:22:14 <lambdabot> (Monoid m, Foldable t) => t m -> m
16:22:27 <ski> `mconcat' can be used, instead of `mempty' and `(<>)', to define what a monoid is
16:23:59 <reygoch> Has anyone used miso and it's router module? I'm having some trouble understanding routing in miso.
16:24:00 <reallymemorable> ski: binary operation just means an operation that takes two arguments
16:24:03 <reallymemorable> ?
16:24:04 <ski> the laws that `mconcat' will have to satisfy, in order to get a monoid, is (a) `mconcat [x] = x' (empty list means no binary operation to perform, so nothing happens); (b) `mconcat (concat xss) = mconcat (map mconcat xss)' (a kind of generalized associativity law, also including the neutral element laws as special cases)
16:24:10 <MarcelineVQ> reallymemorable: correct
16:24:26 <ski> (and then you can define `mempty = mconcat []' and `x <> y = mconcat [x,y]')
16:24:45 <ski> reallymemorable : yep, and the two arguments has the same type as the result type
16:25:38 <ski> (s/empty list/singleton list/)
16:27:34 <ski>   mconcat [mconcat [aa,ab,...,az],mconcat [ba,bb,...,bz],.....,mconcat [za,zb,...,zz]] = mconcat [aa,ab,...,az,ba,bb,...,bz,.....,za,zb,...,zz]  -- perhaps a more easily grokkable way to express the second `mconcat' law (b)
16:28:14 <reallymemorable> and monoids are a category in which any two functions are composable
16:28:38 <reallymemorable> which presumably yields anotehr advantage from being able to check whether something is a monoid?
16:28:50 <ski> a monoid is a category which has exactly one object, which means that any two morphisms will be composable
16:29:11 <reallymemorable> what is the difference between what you said and what i said
16:29:16 <ski> (but there is also another category in which any two morphisms are composable : the empty category, having no objects, and no morphisms)
16:29:37 <ski> (and the empty category is *not* a monoid)
16:29:42 <reallymemorable> morphism = function?
16:30:05 <reygoch> Is there a way to run servant handlers by just supplying a URI?
16:30:06 <ski> the proper term is "morphism" (or "arrow", or sometimes "map")
16:30:20 <reallymemorable> because functions are just maps to new sets?
16:31:04 <ski> reallymemorable : consider the monoid of `Integer', with operations `(+)' and `0'. if you want to see this as a category, then it has a single object (unnamed), and the morphisms, which are all going from this object to itself, are the integers
16:31:28 <ski> reallymemorable : so the integers are the morphisms in thie category. do you really want to call these morphisms "functions" ?
16:31:50 <ski> (an integer doesn't appear to be a function from a set to a set, does it ?)
16:31:57 <reallymemorable> ah
16:32:02 <ski> (is `42' a function ?)
16:32:09 <ski> (depends on who you ask ..)
16:32:25 <reallymemorable> a morphism is the vector across which elements in a set change
16:32:33 <reallymemorable> vector is probably not the right word
16:32:34 <reallymemorable> but the feature
16:32:40 <Rembane> Arrow! 
16:32:43 <Rembane> Function! 
16:32:57 <ski> objects in categories don't have elements (in general)
16:33:04 <ski> objects need not be sets !
16:33:57 <ski> in another category mentioned a while ago, the objects were numbers (dimensions), and the morphisms were matrices (of the respective dimensions)
16:37:26 <ski> (one view of a number like `42' is that it's to be identified with the "add fortytwo" function. a better view along these lines might be to suggest that `42' is the function "repeat fortytwo times". we can think of repeating some action, such as kicking a car. or we can think of composing a function (any function) `f' with itself. so repeating `f' three times would be `f . f . f')
16:38:15 <ski> (and then `3' would be the function that given any function `f' as input, outputs the function `f . f . f')
16:39:31 <ski> (exercise : what is the type of `3' here ?)
16:42:25 * ski idly recalls looking in some paper (old), that reasoned along these lines, then started representing also non-natural numbers, like fractions, as functions
16:44:07 <Rembane> So you can get Peano number over some other Peano number? 
16:45:41 <ski> i don't know what you mean by "Peano number over ..."
16:46:26 <Rembane> (1 + 1 + 1 + ...) / (1 + 1 + 1 + 1 + ...)
16:46:29 <Rembane> Kinda
16:46:38 <ski> "Peano number", for me, means Peano's axiomatization, in terms of zero (traditionally one), and successor. it doesn't say what a number is, only how these operations on numbers should behave
16:46:50 <Amras> https://wiki.haskell.org/Peano_numbers
16:47:02 <Rembane> Yes! Those! 
16:47:18 <ski> (if you ask about Church numerals, then that's something else)
16:48:05 <Rembane> They are? Aren't they the same idea encoded in another way?
16:48:23 <Amras> surely you've just described multiplication, Rembane?
16:48:23 <Solonarv> well, church numerals satisfy the peano axioms
16:48:44 <Solonarv> so church numerals are a model of peano numbers (one of many possible models)
16:48:54 <ski> `Peano' there would be one possible representation/implementation that fullfils the Peano axioms, and therefore is one possible model for being "Peano numbers"
16:49:07 <ski> (another model could use a bit representation)
16:49:32 <Rembane> Cool. 
16:49:38 <ski> yes, Church numerals is also a model
16:49:44 <Solonarv> another model (the one traditionally used when constructing math from pure ZF set theory) is: 0 = {} , succ(n) = n ∪ {n}
16:49:56 <Rembane> Amras: Yeah, I had seriously bad luck when I thought there.
16:50:01 <Amras> if N is a morphism which takes f :: a->a and repeats it f.f.f... N times, and your f is another number M, then your result is something that repeats f N*M times
16:50:22 <Amras> er, repeats g N*M times, rather
16:50:31 <Solonarv> then the numbers are: 0 = {}, 1 = {0}, 2 = {0, 1} and so on
16:50:49 <ski> Rembane : hm, so your "over" was really about fractions, and (positive ?) rational numbers ?
16:51:00 <Rembane> ski: Exactly! 
16:51:24 <Rembane> ski: \frac{\s \s \s \s \0}{\s \s \s \s \0} % to say it in TeX
16:52:08 <ski> (i don't recall how the paper did fractions. i don't even recall the author or the title. maybe i have a hunch that i found it in a particular book, but i'm not sure of that either)
16:53:13 <Solonarv> the interesting thing about church numerals is that addition and multiplication are really simple
16:53:26 <ski> also exponentiation, iirc
16:53:27 <Solonarv> n + m = n . m; n * m = n m
16:53:49 <ski> (you may need `Rank2Types')
16:54:26 <ski> (hm, or was `ImpredicativeTypes' needed .. now i have a nagging feeling that that was the case)
16:54:39 <Solonarv> n ^ m = m (* n) 1
16:55:10 <Solonarv> % type ChurchNat = forall a. (a -> a) -> a -> a
16:55:10 <yahb> Solonarv: 
16:55:30 <Amras> At this point I'm just waiting for someone to mention Linderholm's "Mathematics Made Difficult" >_>
16:55:36 <ski> Solonarv : compare those with conjunction and disjunction in the two-level-continuation implementation of backtracking
16:55:57 <ski> Amras : ah :)
16:56:09 * ski should check that out, sometime
16:56:13 <Amras> it's a great book
16:56:52 <s00pcan> https://imgur.com/a/glucGsu just got this today
16:56:55 <Solonarv> % let czero, cone :: ChurchNat; czero = const id; cone = csucc czero; csucc :: ChurchNat -> ChurchNat; csucc n = \f -> f . n f
16:56:55 <yahb> Solonarv: 
16:57:03 <s00pcan> oh, sorry. Meant to be in ##hardware
16:57:53 <Solonarv> % let ctonat :: ChurchNat -> Natural; ctonat n = n (+1)
16:57:53 <yahb> Solonarv: ; <interactive>:69:48: error:; * Couldn't match expected type `Natural' with actual type `Integer -> Integer'; * Probable cause: `n' is applied to too few arguments; In the expression: n (+ 1); In an equation for `ctonat': ctonat n = n (+ 1)
16:58:02 <ski> zero
16:58:03 <Solonarv> % let ctonat :: ChurchNat -> Natural; ctonat n = n (+1) 0
16:58:04 <yahb> Solonarv: 
16:58:24 <ski>   cone = id
16:58:33 <Solonarv> indeed
16:59:04 <ski> one could also use `\f -> n f . f'
16:59:30 <Amras> most notably, the first chapter begins by asserting that most people cannot count, that the natural numbers are unnatural, and that we should consider whether 2+2 really equals 4
16:59:34 <Solonarv> % I didn't think about this at the time, but \f -> f . n f interacts a bit better with laziness
16:59:34 <yahb> Solonarv: ; <interactive>:71:38: error: parse error on input `,'
17:00:29 * ski . o O ( counting in the generic convergent sequence, aka the one-point compactification of naturals )
17:00:48 <ski> indeed it would
17:01:18 <ski> @src iterate
17:01:19 <lambdabot> iterate f x = x : iterate f (f x)
17:01:27 <ski> an alternate would be
17:01:50 <ski>   iterate f x = xs
17:01:54 <ski>     where
17:01:55 <ski>     xs = x : map f xs
17:02:19 <ski> (is this better or worse ?)
17:04:33 <Solonarv> I have no idea!
17:18:31 <ski> Solonarv : fwiw, the backtracking thing would be something like `newtype BackT m a = BT ((a -> m () -> m ()) -> m () -> m ())'
17:18:39 <ski> @unmtl ContT () (ContT () m) a
17:18:39 <lambdabot> (a -> (() -> m ()) -> m ()) -> (() -> m ()) -> m ()
17:20:18 <ski> @unmtl Cont (Cont (m ()) ()) a
17:20:19 <lambdabot> (a -> (() -> m ()) -> m ()) -> (() -> m ()) -> m ()
17:34:14 <koz_> ski: Yo dawg, we herd u liek delimited continuations?
17:38:43 <ski> heh
17:40:09 <shapr> I wish I had @src in ghci
17:42:05 <Solonarv> would be nice if it showed the actual source then, instead of a prebuilt (and often wrong) database
17:43:02 <Solonarv> hmm, and perhaps some way to select a particular instance for typeclass members
17:43:24 <shapr> that would be even better
17:43:33 <ski> @src [] fmap
17:43:33 <lambdabot> fmap = map
17:43:39 <ski> @src Maybe fmap
17:43:39 <lambdabot> fmap _ Nothing  = Nothing
17:43:39 <lambdabot> fmap f (Just a) = Just (f a)
17:43:43 <ski> ?
17:43:51 <shapr> you can DO that?
17:44:03 <Solonarv> oh, cool!
17:44:03 <ski> since forever
17:44:09 * ski thought everybody knew ..
17:44:13 <shapr> not me!
17:44:20 <Solonarv> (it's still just a dumb string->string database though, right?)
17:44:26 <ski> (yes)
17:44:33 <shapr> Solonarv: how could you do a live lookup?
17:45:06 <Solonarv> well, for most packages you have installed the source should be somewhere on your system too
17:45:30 <Solonarv> I don't know enough to say how feasible it would be to find it and extract the right declaration, though
17:46:13 <ski> (and what if it just punts to some worker which is not exported ?)
17:46:14 <MarcelineVQ> wonder how much info is in a hi file
17:46:32 <ski> (sometimes the whole implementation is in the `*.hi', iiuc)
17:46:35 <Solonarv> MarcelineVQ: "it depends"
17:46:53 <MarcelineVQ> :doc uses the hackage docs, perhaps some can be gleaned from hi or another building step when making libs
17:47:00 <Solonarv> IIRC it can contain the whole implementation *after* desugaring
17:47:00 <MarcelineVQ> *haddock docs
17:47:12 <Solonarv> (it = .hi files)
17:47:56 <Solonarv> the reason it's there at all is to enable cross-module inlining, and inlining happens in Core, not surface Haskell
17:48:17 <MarcelineVQ> % :t 3
17:48:17 <yahb> MarcelineVQ: Num p => p
17:48:22 <Solonarv> haddock has its own special "hi-like" format
18:03:00 <geekosaur> there's ongoing work on an enhanced .hi format to enable such documentation.
18:03:24 <geekosaur> but it's somewhat expensive as .hi loading is already a fairly expensive part of compilation, iirc
18:04:04 <geekosaur> (although the expensive part isn't the reading or parsing, so it may not matter for compilation)
18:32:38 * hackage shh 0.3.0.0 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.3.0.0 (lukec)
19:25:16 <deech> How do StaticPtr's (https://www.stackage.org/haddock/lts-13.11/base-4.12.0.0/GHC-StaticPtr.html) work with GC? If they're guaranteed to be stable do they need to be manually freed?
19:28:50 <koz_> deech: Why do you think this is necessary?
19:32:30 <deech> koz_: I'm want to use them to register callback functions with C and free them when the C struct is destroyed. 
19:35:15 <MarcelineVQ> sounds like you probably want ForeignPtr
19:35:48 <slack1256> I thought stable pointers where more related to cloud haskell
19:36:14 <MarcelineVQ> static pointers are, stable pointers are yet another thing :> https://ocharles.org.uk/guest-posts/2014-12-23-static-pointers.html
19:38:07 <slack1256> Oh, my bad
19:38:18 <koz_> So how many different Ptrs do we have?
20:23:29 <p0a> Hello I want to insert to a balanced binary tree
20:24:03 <p0a> thinking about it, I thought, I will insert in every possible position; then I will `choose' the insertion that happened at the lowest height to be returned as a value 
20:24:26 <p0a> my question is, will lazy evaluation guarantee that I am not creating 2^n trees and only 1 tree?
20:25:48 <p0a> Or for example, can I encapsulate the tree creation in a lambda that I later call, to guarantee lazyness/
20:33:46 <koz_> p0a: Are you making a binary _search_ tree, or just a binary tree?
20:33:57 <p0a> balanced binary tree 
20:34:07 <p0a> so I think, just binary.
20:34:20 <koz_> Why do you need a tree structure in this case?
20:34:27 <p0a> It's just HW 
20:34:38 <p0a> well, it's from HW. but not my HW or anyone elses. I'm just learning Haskell
20:38:36 <p0a> another question: How do I sort a tuple list by order of the first element of each tuple?
20:38:45 <koz_> :t on
20:38:46 <lambdabot> (b -> b -> c) -> (a -> b) -> a -> a -> c
20:38:57 <koz_> :t sort `on` fst
20:38:58 <lambdabot> error:
20:38:58 <lambdabot>     • Couldn't match type ‘[a]’ with ‘[a] -> c’
20:38:58 <lambdabot>       Expected type: [a] -> [a] -> c
20:39:05 <koz_> Ahem, one moment.
20:39:17 <p0a> I think `on' is not the right thing; there's on `Ord' in there 
20:39:28 <p0a> there's *no* `Ord', I meant.
20:39:57 <koz_> Yeah, `on` isn't quite right.
20:40:06 <p0a> I'm not sure what `on' does but I was just guessing 
20:40:09 <MarcelineVQ> tuples already sort on the first element
20:40:18 <koz_> :t sortBy (comparing fst)
20:40:19 <lambdabot> Ord a => [(a, b)] -> [(a, b)]
20:40:24 <koz_> Also what MarcelineVQ said.
20:40:39 <p0a> Huh? Say [(2, "hi"), (1, "world")] gets sorted to [(1, "world"), (2, "hi")]
20:40:58 <p0a> I don't understand what MarcelineVQ said 
20:41:00 <koz_> > sort [(2, "hi"), (1, "world)]
20:41:01 <lambdabot>  <hint>:1:30: error:
20:41:01 <lambdabot>      lexical error in string/character literal at end of input
20:41:06 <MarcelineVQ> What are you wanting it to do
20:41:07 <koz_> > sort [(2, "hi"), (1, "world")]
20:41:09 <lambdabot>  [(1,"world"),(2,"hi")]
20:41:11 <MarcelineVQ> with your example
20:41:16 <koz_> p0a: ^ that
20:41:28 <p0a> Oh they said tuples are in Ord or something
20:41:36 <p0a> okay kind of esoteric :P I wouldn't know that
20:41:47 <nexii> hello
20:42:10 <p0a> MarcelineVQ: what I'm *really* trying to do is insert in a balanced binary tree, for a toy problem I'm trying to solve
20:42:27 <p0a> MarcelineVQ: if you scroll up you'll see my question but I can repeat it if you'd like
20:44:27 <koz_> p0a: I don't see what sorting has to do with inserting into a binary non-search tree, binary or otherwise.
20:44:37 <koz_> Are you _absolutely sure_ you don't want a self-balancing BST?
20:44:59 <p0a> I want to insert into a balanced binary tree, preserving balancedness
20:45:05 <MarcelineVQ> I saw it, I don't really understand your plan though. Or have much experience with tress. If you think you can create what you have in mind we can see about making it efficient afterwards
20:45:18 <p0a> okay let me show my code it's almost done
20:45:29 <koz_> p0a: That would help.
20:56:55 <p0a> Now that I'm doing this I'm realizing that my code didn't work 
20:57:24 <p0a> so I'm not sure how to do this. I'm thinking about it 
20:58:51 <p0a> without a global mutable variable it's pretty confusing 
20:59:13 <p0a> how to get these different recursive function calls to communicate their results
21:01:17 <p0a> supposedly it can be done with `foldr'
21:06:22 <p0a> alright I'm not sure how to do this with `foldr' but without that function, I think I understand how to create a foldTree :: [a] -> Tree a
21:06:45 <p0a> You simply go to the middle of the list, use that for node, and split the rest between the left/right child nodes
21:08:08 * hackage inline-r 0.10 - Seamlessly call R from Haskell and vice versa. No FFI required.  https://hackage.haskell.org/package/inline-r-0.10 (AlexanderVershilov)
21:14:05 <p0a> Here's my code: https://pastebin.com/4DmGcqKU It's the solution to Exercise 2 from http://www.cis.upenn.edu/~cis194/spring13/hw/04-higher-order.pdf
21:14:26 <p0a> my issue is that I didn't use `foldr' as the .pdf instructs. I'm quite confused about that...
21:15:07 <p0a> there's a typo on line 14, `div`1 2 should be `div` 2
21:17:18 <p0a> MarcelineVQ, koz_ in case you are interested
21:23:42 <koz_> p0a: You construct top-down, but your first call on a non-empty list would construct your root as having height 0.
21:23:50 <koz_> Which is probably not what you want.
21:25:36 <p0a> I think that's what the pdf shows too 
21:25:49 <koz_> Nope.
21:26:01 <koz_> See the second line of the foldTree example.
21:26:49 <p0a> koz_: oh so the heights are inverted 
21:27:29 <koz_> p0a: Your code's heights are computed incorrectly. Your foldTree would assign your root a height of 0 irrespective of what (non-empty) list you give it.
21:28:46 <p0a> well yeah I thought height meant depth 
21:28:53 <p0a> good catch
22:00:44 <p0a> koz_: but how can I construct anything not top-down 
22:00:52 <p0a> I'm dealing with immutable trees 
22:05:43 <koz_> You can do bottom-up just as well. There's even an algorithm for doing this for ordered data that you can adapt to 'I don't care if it's ordered' data.
22:05:46 <koz_> Let me find you a link./
22:06:21 <koz_> https://hbfs.wordpress.com/2012/01/03/building-a-balanced-tree-from-a-list-in-linear-time/
22:06:44 <p0a> thank you
22:09:05 <p0a> koz_: doesn't look like immutable 
22:09:23 <koz_> p0a: It literally doesn't matter. You can assemble new trees from immutable old ones.
22:09:33 <koz_> It doesn't even involve that much copying.
22:10:03 <p0a> also why does [1,2] produce a tree of 3 elements?
22:10:43 <p0a> anyway I think you gave me an idea for the bottom-up creation 
22:11:19 <koz_> That was the goal. :P
22:11:30 <p0a> heh :)
22:15:36 <p0a> how can I use log in haskell? log 2 3 gives me type errors 
22:15:42 <p0a> it complains it's not Floating
22:15:52 <koz_> :t fromIntegral
22:15:53 <lambdabot> (Num b, Integral a) => a -> b
22:16:06 <koz_> For all your 'need more permissive numeric type' needs.
22:16:28 <MarcelineVQ> log only takes one argument
22:16:36 <p0a> doesn't work with fromIntegral 
22:16:37 <koz_> I think they meant logBase?
22:16:40 <koz_> :t logBase
22:16:41 <lambdabot> Floating a => a -> a -> a
22:16:51 <p0a> oh yeah. whoops
22:16:53 <koz_> > logBase (fromIntegral 2) (fromIntegral 16)
22:16:55 <lambdabot>  4.0
22:17:10 <p0a> mine worked without that even 
22:17:12 <p0a> > logBase 2 3
22:17:14 <lambdabot>  1.5849625007211563
22:17:25 <koz_> Huh, OK then.
22:17:31 <p0a> yeah my bad
22:18:01 <MarcelineVQ> you'll want to know about fromIntegral if you plan to pass argument to log, numeric literals just happen to be already wrapped in fromIntegral
22:18:10 <MarcelineVQ> *logBase/logBase
22:18:38 <koz_> MarcelineVQ: Since when?
22:19:55 <p0a> I just assumed that integers were a subclass or something
22:20:01 <MarcelineVQ> as long as I've used them, that's why :t 3 is Num a => a and not Integer, it's in the spec. https://www.haskell.org/onlinereport/haskell2010/haskellch6.html#x13-1360006.4.1
22:20:10 <koz_> MarcelineVQ: Oh, neat. TIL I guess.
22:20:17 <koz_> p0a: Sub-classes aren't a thing. :P
22:20:20 <koz_> (in Haskell anyways)
22:20:29 <p0a> Yeah I'm not sure exactly how it works 
22:20:41 <p0a> but there's some certain notion of that. 
22:20:45 <koz_> :t 3
22:20:46 <lambdabot> Num p => p
22:20:54 <koz_> ^ that's the notion it seems.
22:25:40 <p0a> oh what a mess trees are 
22:25:45 <koz_> Not really.
22:25:59 <koz_> They require additional thought relative lists, but they're actually very structured.
22:26:06 <p0a> well I don't think they're a mess after you figure them out 
22:26:16 <p0a> in Haskell they're pretty neat I would expect... I just need to figure them out
22:26:29 <p0a> not all of them, just balanced binary trees. :P
22:26:49 <koz_> In practice, balanced non-BSTs are of relatively little interest.
22:27:01 <koz_> And if you want a balanced BST, it's not like there isn't an embarassment of riches to choose from.
22:27:09 <koz_> (I can name five different ones just off the top of my head)
22:27:17 <koz_> (not including variants)
22:27:17 <p0a> stuff like Red/Black and such right?
22:27:21 <p0a> AVL and so on 
22:27:33 <p0a> things that brought me nightmares long ago 
22:27:44 <koz_> AVL, red-black, splay, scapegoat, ... OK that was four.
22:27:50 <p0a> when I was trying to do them in C :)
22:27:52 <koz_> Then there's left-leaning red-black and WAVLs.
22:29:21 <p0a> dang it
22:29:32 <p0a> I couldn't do my work so I took a break to learn some haskell but now I can't do haskell either
22:29:53 <koz_> Welcome to 'my state for the last three+ years at least'.
22:30:10 <p0a> lol
22:32:35 <p0a> well I resign for now. thank you for the help & Marceline VQ too 
22:42:04 <MarcelineVQ> lists, trees, graphs, categories, the hierarchy of "what am I looking at, how is this even useful"
