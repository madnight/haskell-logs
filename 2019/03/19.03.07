00:18:07 <dminuoso> Here might be a silly question.. if we have (), (,), (,,) and so forth, where is the tuple containing just one element?
00:18:28 <opqdonut> it's not really needed since we don't have any tuple polymorphism
00:18:31 <opqdonut> but e.g. python has it
00:19:00 <c_wraith> at least one library defines a type named Only to serve that purpose
00:19:05 <gentauro> % :t forever
00:19:06 <yahb> gentauro: Applicative f => f a -> f b
00:19:21 <dminuoso> c_wraith: Isnt that the postgresl-simple library?
00:19:23 <opqdonut> oh right and there's the Identity Monad/Functor
00:19:29 <c_wraith> dminuoso: yep
00:20:16 <dminuoso> opqdonut: Well yeah, its just suprisingly inconsisent. Consider how with MPTC we get to have nullary typeclasses.
00:20:23 <opqdonut> mmh
00:21:24 <dminuoso> I mean there's probably the issue of ambiguity (it would effectively require using something different than parens to denote grouping)
00:21:25 <opqdonut> otoh having a name like Identity is so much nicer than some sort of cryptic (1.) syntax
00:21:34 <opqdonut> even () is a bit esoteric
00:21:44 <opqdonut> but it's an idiom so it's kinda fine
00:22:10 <dminuoso> opqdonut: Consider traditional languages `foo()`, the equivalent invocation in Haskell would be `foo ()`
00:22:24 <opqdonut> yeah that's what I meant
00:23:01 <dminuoso> opqdonut: And considering the pattern of `(), (a, b), (a, b, c) ...` I think unit feels right.
00:27:15 <gentauro> "This library is production-quality. Therefore we have very high standards in terms of code style, API quality and testing." but no support for `HTTPS` how is that `prod-ready`? -> https://github.com/jaspervdj/websockets
00:28:48 <dminuoso> gentauro: There's little incentive providing builtin TLS support when you can delegate it to an external TLS termination proxy.
00:29:04 <dminuoso> Especially since you have to FFI into libressl/openssl/friends if you want a secure implementation.
00:34:25 <gentauro> dminuoso: is that what `Vincent` does here -> http://hackage.haskell.org/package/tls (FFI)
00:36:11 <dminuoso> gentauro: It's a fun implementation. I have strong doubts that Haskell is a good language for implementing side-channel free cryptographic schemes in.
00:36:38 <gentauro> `https://github.com/vincenthz/hs-tls/search?q=foreign&unscoped_q=foreign` -> "We couldn’t find any code matching 'foreign' in vincenthz/hs-tls"
00:36:46 <gentauro> it looks like there is no FFI (apparently)
00:37:10 <gentauro> I know Vincent from all the `OCaml` libs
00:37:20 <dminuoso> Your point being?
00:37:30 <gentauro> apparently he is somebody who knows what he is doing
00:38:02 <dminuoso> gentauro: Is Vincent a popular figure at ACNS, Crypto, RSA Conference or others?
00:38:36 <dminuoso> gentauro: Does he have a list of published papers on how to implement cryptographic ciphers and algorithms securely in Haskell?
00:38:51 <dminuoso> Is his implementation vetted and analyzed by cryptography experts?
00:38:55 <gentauro> dminuoso: yeah, I think he has
00:39:04 <gentauro> co-authored with PhD from INRIA so ...
00:39:30 <gentauro> are you implying just because he is not an academic he isn't allowed to make `crypto` libs?
00:39:36 <gentauro> that's a bit "harsh"
00:40:53 <gentauro> but from my `MirageOS` days, I know for a fact that their `TLS` lib has been somehow proven with `COQ`
00:41:10 <dminuoso> gentauro: proven to what extend?
00:41:20 <gentauro> so I'm guessing that their warranties are probably above other implementations I would say
00:41:25 <gentauro> (given my background)
00:42:41 <dminuoso> gentauro: The moment GHC gets into the way, you have a compiler that changes code. You'd need to analyse hundreds of side channel attacks in the presence of an STG generator with all the code transformations and optimizations GHC applies.
00:45:54 <Ariakenom> "side-channel free" probably isn't a thing. And anything called compiler changes code I'd think. But I am sceptic, too.
00:48:23 <Ariakenom> depends on cryptonite though https://hackage.haskell.org/package/cryptonite
00:53:51 <gentauro> dminuoso: so all those "fancy" libs you mention who were "tested" by "experts" ... could you explain "Heartbleed". I rest my case
00:53:54 <gentauro> (OMG)(
00:53:58 <gentauro> (OMFG)
00:58:49 <gentauro> "BTC Piñata is a MirageOS unikernel using not quite so broken software. It is written in OCaml, runs directly on FreeBSD VMM (using Solo5), and is using native OCaml TLS and X.509 implementations ... Update from March 2018: our donors transferred nearly all the bitcoins to other projects ... We are well aware that bounties can only disprove the security of a system, and never prove it. We won't take 
00:58:55 <gentauro> home the message that we are 'unbreakable', 'correct', and especially not 'secure'." -> http://ownme.ipredator.se/
00:59:26 <gentauro> I guess if you are in security, you tend to be "humble" about your work ...
01:00:55 <absence> is there a function in base for updating an entry in an association list [(a,b)], or do i need something like cons . filter or a third party library?
01:00:58 <dminuoso> Ariakenom: The code transformation is really important. There exist a class of side channel attacks that abuse measurable timings from the cache behavior.
01:01:31 <dminuoso> Ariakenom: Consider Cache-timing attacks on AES by Bernstein.
01:02:12 <dminuoso> Ariakenom: If you dont fully understand what your compiler does to your code, you can have a large number of unintended side channels induced by optimizations and undesirable caching behavior.,
01:04:02 <dminuoso> Or perhaps the more original paper: Kocher P.C. (1996) Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems. 
01:04:09 <gentauro> https://detunized.net/posts/2019-03-06-base64-decoding-bug-that-is-present-in-all-version-of-.net/ <- I guess a bit of `property-based testing` would have helped xD
01:05:29 <gentauro> my "non-expert implementation" (cos I don't give talks about the topic) is way more "robust" -> `echo -n "abc==" | ./decode` outputs "Invalid Base64 string" -> http://blog.stermon.com/articles/2018/08/13/haskell-safe-base64-only-depending-on-prelude.html
01:06:44 <Ariakenom> I was just arguing that it takes more than a different compiler
01:07:07 <Ariakenom> even a C compiler
01:07:25 <dminuoso> Ariakenom: Im not saying a C compiler is better, it's just much better researched and thus understood.
01:08:14 <Ariakenom> But not sufficient. it's still "a compiler that changes code"
01:08:38 <Ariakenom> I mostly tohught you made it sound too easy
01:08:40 <dminuoso> Ariakenom: Which is why parts in openssl are written in handcrafted assembly.
01:09:12 <dminuoso> Ariakenom: That's fair, that was not my intention.
01:09:49 <Cale> and then that effort is undermined by the CPU's interpretation of that assembly into microcode :D
01:10:18 <dminuoso> Cale: And then hyperthreading gets in the way, speculative code execution..
01:11:33 <Cale> Did you hear about the new "Spoiler" thing?
01:11:51 <dminuoso> Yeah it was in my google feed, havent had the chance to read about it yet.
01:11:55 <Ariakenom> Getting a compiler that emits the assembly you meant isn't enough. Getting a constant number of instructions isn't enough. you need to know what that assembly means.
01:12:10 <Cale> I haven't really had the chance to read up on it yet either, but it sounded like they had a way to make rowhammer-type attacks far more consistent
01:12:35 <Cale> (and fast)
01:12:39 <dminuoso> Rowhammer Id say is one of the most scary attacks I have seen.
01:12:47 <dminuoso> Though the impact was not so large for various reasons.
01:13:39 <dminuoso> Cale: So spoiler lets you somehow extract page table mappings?
01:14:11 <dminuoso> Okay I dont even need to read a paper to see why this is troublesome and how it connects to rowhammer.
01:14:41 <dminuoso> At times I wonder whether it's secretly AMD who finds those vulnerabilities..
01:20:38 <Ariakenom> It makes sense to look but I don't see why they would be secret about it
02:00:38 * hackage hsakamai 0.1.0.1 - Akamai API(Edgegrid and Netstorage)  https://hackage.haskell.org/package/hsakamai-0.1.0.1 (junjihashimoto)
02:33:08 * hackage hwhile 0.1.1.6 - An implementation of Neil D. Jones' While language  https://hackage.haskell.org/package/hwhile-0.1.1.6 (alexj136)
02:59:32 <kuribas> why isn't there $> ?
02:59:38 <kuribas> :t (<$)
02:59:39 <lambdabot> Functor f => a -> f b -> f a
02:59:43 <kuribas> :t ($>)
02:59:44 <lambdabot> error:
02:59:44 <lambdabot>     • Variable not in scope: $>
02:59:44 <lambdabot>     • Perhaps you meant one of these:
02:59:47 <owhit> I switched from using a list to a Data.Vector, and can't figure out why this snippet is running even slower now... ? https://pastebin.com/JyCUYJ8L
03:03:30 <Taneb> owhit: you're only doing one index into the list/vector, but in the vector version you have to read the entire thing, convert it from list to vector
03:03:50 <Taneb> If you were doing many lookups things would even out
03:04:56 <owhit> Taneb: I called V.fromList on the list, that doesn't work?
03:05:21 <Taneb> owhit: it does exactly what you asked it to, it converts the list to a vector
03:05:35 <Taneb> But to do that it has to read through the entire list
03:06:51 <owhit> Taneb: To read through the entire list, would I call V.! on each element before I run main?
03:07:06 <owhit> Seems like a strange solution
03:07:22 <ski> kuribas : suggested signature ?
03:07:39 <Taneb> owhit: I think I haven't explained properly
03:07:50 <kuribas> ski: Functor f => f a -> b -> f b
03:08:09 <Taneb> owhit: you already are reading through the list, because that's necessary to convert from list to vector
03:08:10 <ski> oh, so just `flip (<$)', then ?
03:08:14 <kuribas> skiyeah
03:08:43 <owhit> Taneb: Then I would expect my lookups to be lightning fast? But they are not
03:08:58 <Taneb> owhit: your lookups aren't the slow part of the program
03:08:59 * ski isn't sure why the name (or, symbol, if you prefer) `<$' was chosen
03:09:12 <Taneb> owhit: oh, I misread your program
03:09:24 <ski> (i'm not really fond of the symbol choice for `<*>',&c. either)
03:10:16 <Taneb> owhit: what's "lenghtDict"?
03:10:56 <ski> owhit : `randomRIO (0,len - 1)' ?
03:11:12 <owhit> Taneb: It gives us the number of lines in dict. The dict is just a file with every english word in it
03:11:25 <Taneb> owhit: you're doing that every loop
03:11:28 <owhit> ski: I want to access a random word
03:11:40 <ski> owhit : `len' is out of bounds, as an index
03:11:46 <ski> (off-by-one error)
03:11:47 <owhit> taneb: The length isn't memoized?
03:11:51 <Taneb> Nope
03:12:01 <owhit> Boggles my mind
03:12:12 <ski> `randomRIO (m,n)' has inclusive bounds, not inclusive-exclusive
03:12:15 <Taneb> If you use V.length dict instead, it might be faster
03:12:26 <owhit> ski: len - 1 wouldn't be out of bounds?
03:13:04 <Taneb> owhit: actually, looking at it, you're also reading the dictionary every cycle
03:13:11 <owhit> Taneb: how do I save my length so it doesn't waste time computing it a million times?
03:13:19 <Taneb> Which is... even worse
03:13:38 <ski> `lengthDict = V.length <$> dict' ?
03:13:38 <owhit> Taneb I clearly don't know what I'm doing
03:13:49 <Taneb> owhit: make a separate "loop :: V.Vector String -> IO ()" function, which takes the dict as an argument
03:14:11 <Taneb> owhit: pretty much nothing IO can memoize
03:14:12 <owhit> ski: return the length of the dict so that I know the bounds for accessing a random word
03:15:10 <owhit> Taneb: Why would that be faster?
03:15:26 <Taneb> owhit: because currently you're re-reading the file from disk every cycle, which slows things down hugely
03:15:29 <ski> owhit : valid indices `i' with inclusive-exclusive bounds `(m,n)' would be those such that `m =< i < n', in your case you have `(0,len)', and clearly `0 =< len - 1 < len', assuming `len > 0' (your file isn't empty. you should probably check for that as well ?)
03:16:17 <owhit> ski: woops! my bad, i thought i had -1 in there
03:16:25 <Taneb> owhit: if you read once then construct a new IO action which uses what you've read, you don't repeat the expense of reading the file and converting it to vector
03:16:26 <ski> np :)
03:16:28 <owhit> taneb thats bad
03:17:12 <owhit> taneb: fascinating.
03:17:17 <Logio> owhit: is the purpose really to print out random words ad infinitum, or to stop at some point?
03:17:47 <owhit> logio, right now the purpose is to learn how to make it fast, then do other stuff. I'm making a little hangman game
03:17:55 <owhit> it doesn't need to be fast. But the purpose is to learn
03:18:45 <Logio> do note that making it fast in the infinite loop case is different than making it fast in other cases 
03:19:03 <owhit> yikes
03:19:41 <Logio> though both are surely educational
03:24:29 <ski> > take 4 (STL.runST (do ref <- STL.newSTRef 1; let infiniteLoop = do n <- STL.readSTRef ref; STL.writeSTRef ref (2*n); ns <- infiniteLoop; return (n:ns) in infiniteLoop))
03:24:31 <lambdabot>  [1,2,4,8]
03:24:46 <kuribas> ski: the lt sign points to the value which is kept
03:25:06 <ski> but why `$' ?
03:25:17 <kuribas> ski: because it's like <$> but with const
03:25:52 <ski> yea, i'm not seeing how `const' is symbolized
03:26:37 * ski idly wonders what difference Logio had in mind
03:26:39 <kuribas> ski: it's not
03:26:43 <owhit> Taneb: This is now what I have. It's still just as slow. I suppose I just missunderstand how all this works. https://pastebin.com/6LfiZzDE
03:27:19 <kuribas> ski: but the result of the side which is not pointing is discarded
03:27:28 <ski>   main = do
03:27:36 <ski>     d <- dict
03:27:49 <ski>     loop d (V.length d)
03:27:50 <Taneb> owhit: the idea is you don't want to do the reading in "loop"
03:28:10 <Taneb> What you've passed in to loop isn't the dict, it's instructions on how to read the dict
03:28:13 <ski> then skip `len >>= \x -> ', replacing `x' by `len'
03:28:26 <Taneb> Same for the lenght
03:28:26 <ski> and similarly for `d >>= \x -> '
03:28:38 <ski> kuribas : mhm
03:29:03 <owhit> Taneb, ski, hmmm thanks let me try
03:29:10 <kuribas> ski: same for <* etc
03:29:14 <kuribas> :t (<*)
03:29:15 <lambdabot> Applicative f => f a -> f b -> f a
03:29:23 <kuribas> :t (*>)
03:29:25 <lambdabot> Applicative f => f a -> f b -> f b
03:29:46 <ski> owhit : so, you still have the same problem, repeating said instuctions (just abstracted a bit more). so now try actually performing the supposedly initial work before the loop
03:29:50 <ski> :)
03:30:27 <owhit> I'll try haha
03:30:29 <ski> kuribas : yea, that's the problem i'm having. not seeing how it would be parallel to `<*' and `*>'
03:30:33 <kuribas> ski: I read <$> as application ($) lifted over to a functor
03:30:46 <ski> yes (i don't like that name, either)
03:30:49 <kuribas> :t (<*>)
03:30:50 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
03:31:24 <ski> (imho, `<*>' should be `<$>', and `<$>' should be `$>' or `|$>' or something)
03:31:54 <ski> @type (<**>)  -- is also strangely named
03:31:55 <lambdabot> Applicative f => f a -> f (a -> b) -> f b
03:32:38 <kuribas> ski: then <$> should be flip <*>
03:33:08 <ski> how so ?
03:35:48 <ski> owhit : oh, and you ought to rename `dict' (and scrap `lengthDict', since you don't want to repeat that work, just call `V.length' directly on the file as i showed), since your `dict' is not the actual dictionary, but the instructions (the "recipe") for how to build it
03:36:10 <ski> @quote recipe.is.not
03:36:10 <lambdabot> ski says: <ski> `getLine :: IO String' is a recipe for how to interact with the world to acquire a `String'  <ski> the recipe is not the cake
03:36:27 <ski> @quote /bin/ls
03:36:27 <lambdabot> shachaf says: getLine :: IO String contains a String in the same way that /bin/ls contains a list of files
03:36:54 <owhit> ski: ghc is telling me that it doesn't like the first argument of loop d (Vector.length d)
03:36:57 <ski> (you could call it `builtDict', perhaps)
03:37:21 <ski> owhit : did you change the body of `loop' yet ?
03:37:31 <owhit> Expects a V.Vector (IO String), got a V.Vector String
03:37:54 <owhit> i changed this line to `word <- d V.! index`
03:38:16 <ski> oh, you dropped the `return'
03:38:37 <ski> instead of `word <- return (d V.! index)', you could say `let word = d V.! index'
03:39:25 <owhit> ski: What does that semantically change?
03:40:03 <ski> what's after the `<-' symbol in a `do'-expression is expected to be an action. so if you say `word <- d V.! index' is expected to be an (`IO'-)*action* that computes an (in this case) `String', rather than a plain `String'
03:40:24 <ski> `<-' executes the action to the right, and binds the thing to the left to the result
03:40:42 <ski> `let' otoh, merely gives a name to (/ binds) the expression. no action executing
03:40:48 <owhit> ski: WHOA. I just did the change you suggested, it compiled, and now runs as fast as the Cpp program. o_O
03:41:27 <ski> `return (...)' is an action that, when executed, actually does no effects, merely yielding back to the invoker the result value `...'
03:42:09 <ski> (yes, it has been suggested that the name `return' perhaps wasn't the best possible choice for this, in retrospect, comparing with what expectations people have from many other languages)
03:42:20 * ski smiles
03:42:30 <owhit> ski: Hmmm. What do you mean by "action"? I'm unfamiliar with the terminology in this context
03:43:41 <ski> think of an `IO'-action roughly as an (argumentless) procedure (or object with an argumentless `invoke'/`execute' method, if you prefer) that you can pass around and store in data structures
03:44:28 <ski> it is inert, doesn't do anything by itself. you can "append" other actions (and normal, "pure" post-processing steps) to it, making a bigger action
03:45:04 <ski> ultimately, an `IO'-action is only executed if/when it has been made part of (the executed part of) the `main' action
03:45:20 <ski> (or, any `IO'-action entered into the interactor, like GHCi)
03:46:01 <ski> when you say `len >>= \x -> ..x..', think of that as "now invoke/execute the action `len', yielding result `x', and then ..`x'.."
03:46:07 <owhit> ski: Hm. Ok... I just changed the code from the let statement to `word <- return $ d V.! index` (I forgot the return initially), and that also compiled and runs just as fast as the let statement. So theres no real difference in execution?
03:46:31 <ski> or more properly : when `len >>= \x -> ..x..' is (later, if at all, perhaps multiple times) executed, do <what i just sais above>
03:46:50 <ski> owhit : basically no
03:47:29 <ski> `IO'-actions are how we express I/O (Input-Output) interactions with the rest of the world (via the OS)
03:48:09 <ski> (also some other effectful stuff are dumped into `IO', like concurrency, randomness, mutable datastructures)
03:48:58 <owhit> How would I know when or why to prefer `let word = d V.! index` over `word <- return $ d V.! index`? The result appears the same. Sorry for being a tad lost
03:49:07 <ski> Haskell takes the idea of separating user interface (I/O) from internal ("pure") computation seriously
03:49:42 <ski> owhit : i would expect both to be as, or nearly as, efficient. but the former is preferred, stylistically
03:51:31 <ski> you should clearly distinguish between (a) descibing an ("internal"/"pure") computation, binding it to a name; and (b) describing an effectful action (which might sometimes be computed in a nontrivial way from other pieces of actions), and bind its yielded *result* to a name
03:53:22 <ski> binding an action (which is a kind of value/expression) to a name (like your `lengthDict = V.length <$> ...') is very different from binding its result value (when executed) (like in say `do ...; dict <- V.fromList <$> ...; ...') to a name
03:54:04 <owhit> ski: So, the act of passing my dict and length to another function is what forces my dict and length to evaluate?
03:54:40 <ski> (i say "effects", where one'd usually say *side*-effects in an imperative language. that's because, in Haskell, they are not implicit, are not happening on the *side*, and are actually *explicitly* accounted for both in interface (type signature), and in call and definition syntax)
03:54:55 <ski> owhit : evaluation is not execution
03:55:10 <ski> merely passing an action anywhere does not cause it to execute
03:56:17 <ski> if i compute the action `mapM putStrLn ["Hello","World"]', i get as result value a new action that describes outputting the strings `"Hello"',`"World"' on standard output, on separate lines
03:56:37 <ski> merely computing/evaluating the action does *not* cause any I/O to happen !
03:56:59 <owhit> ski: Ok I think that makes sense
03:57:19 <owhit> Then what forces execution? How did introducing my loop function force execution
03:57:31 <ski> it's like if you glue/tape two recipes (like cake and icing, say) together. you don't get an iced cake, you get a recipe for an iced cake. the work of executing the (combined) recipe is not (yet) performed
03:58:05 <owhit> ski: that makes sense
03:58:15 <ski> generally, you force execution by making an action part of a larger (compound) action, that is eventually executed
03:58:41 <ski> (sometimes a compound action only conditionally executes some part, though, e.g. `when' and `unless')
03:59:17 <ski> ultimately, to start off execution initially, you need to define the `main' action. ever I/O execution follows from that
03:59:26 <ski> (or an action written into the interactor)
04:00:27 <owhit> ski: was this not possible without introducing loop :: V.Vector String -> Int -> IO a?
04:00:50 <ski> <ski> think of an `IO'-action roughly as an (argumentless) procedure (or object with an argumentless `invoke'/`execute' method, if you prefer) that you can pass around and store in data structures
04:00:55 <ski> <ski> it is inert, doesn't do anything by itself. you can "append" other actions (and normal, "pure" post-processing steps) to it, making a bigger action
04:01:00 <ski> <ski> ultimately, an `IO'-action is only executed if/when it has been made part of (the executed part of) the `main' action
04:01:09 <ski> <ski> (or, any `IO'-action entered into the interactor, like GHCi)
04:01:18 <ski> <ski> when you say `len >>= \x -> ..x..', think of that as "now invoke/execute the action `len', yielding result `x', and then ..`x'.."
04:01:23 <ski> <ski> or more properly : when `len >>= \x -> ..x..' is (later, if at all, perhaps multiple times) executed, do <what i just sais above>
04:01:46 <ski> (since you seemed to have missed that, or possibly not understood at the time)
04:02:59 <ski> owhit : well, you wanted to do some work before starting the loop
04:03:04 <ski> you could have done
04:03:08 <ski>   main = do
04:03:21 <ski>     dict <- V.fromList <$> ...
04:03:34 <ski>     let len = V.length dict
04:03:39 <ski>     forever $ do
04:03:44 <owhit> OHHHHH
04:03:45 <ski>       ...
04:04:02 <owhit> Slowly starting to make sense.
04:04:06 <ski> then you could refer to `dict' and `len' directly in the latter `...' (the "loop body" of `forever')
04:04:19 <owhit> hmmmm
04:04:24 <ski> but `forever' is just defined as
04:04:30 <ski>   forever act = do
04:04:33 <ski>     act
04:04:36 <ski>     forever act
04:04:51 <ski> so it's just, more or less, a thin wrapper around what you were doing
04:05:07 <owhit> but if instead of forever $ do, i called main again, that would force dict <- to execute again, slowing down the program?
04:05:17 <ski> one very nice thing about treating actions as values is that you can "code up your own control structures"
04:05:26 <ski> (such as `forever', `mapM_')
04:06:26 <ski> (i should have used `mapM_', not `mapM', before. we're not interested in the resulting values (always `()', the uninteresting value, empty tuple, think of the `()' type as `void' in other languages) of executing `putStrLn' applied to the individual strings)
04:06:50 <owhit> ski: If my understanding is clear, every time `foo <- ...` is called, even in the same loop, it will always execute the `...`?
04:06:52 <ski> owhit : well, there's a variant, you could define `loop' inside `main'
04:06:55 <ski>   main = do
04:07:01 <ski>     dict <- ...
04:07:07 <ski>     let len = ...
04:07:13 <ski>         loop = do
04:07:20 <ski>           ...
04:07:22 <ski>           loop
04:07:26 <ski>     loop
04:07:43 <ski> this way, `dict' and `len' are still in scope in the `...' in `loop's body
04:08:01 <clever> you could also just add an argument to loop, and call it with that dict
04:08:05 <ski> if you define `loop' outside, you have to somehow transmit those two to it, e.g. by passing parameters
04:08:14 <clever> yep
04:08:38 <ski> clever : that's what they did in the paste (after suggestion)
04:08:51 <ski> owhit : yes
04:09:17 <owhit> ski, it's becoming clear.
04:09:56 <ski> owhit : also, it's probably better to say something like "`foo <- ...` is executed/invoked". to distinguish more clearly from calling functions
04:10:27 <owhit> ski: btw, why `dict <- ...` but `let len = ...`. Still not groking the discrepancy
04:10:56 <ski> (but people do get a bit sloppy here with words. it's more ok to be sloppy with words if you know (and the one you're talking to know) what you really mean. but when you're learning, it's (imho) a good idea to be extra careful, to get the concepts and distinctions straight in your mind)
04:10:58 <owhit> could i say let dict = ?
04:11:02 <ski> yes
04:11:23 <ski> but then you wouldn't execute `dict' at that point (assuming execution gets to that point to begin with)
04:11:37 <ski> you'd just "prepare" a new action `dict' for later possible execution
04:12:18 <ski> if you do `let foo = ...', then the types of `foo' and `...' are the same
04:12:43 <owhit> ski: So `len <- ...` seems more efficient, because you are binding the result then and there?
04:12:44 <ski> if you do `x <- ...', then the types of `x' and `...' are not the same. if `...' has type `IO T', then `x' gets type `T'
04:13:07 <owhit> ski, that makes sense
04:13:17 <ski> `<-' "removes" the `IO' (which in the types signify that you have an actio (value) which, when execute, will yield a value of the type `T')
04:14:01 <ski> "seems more efficient" -- they aren't directly comparable, commonly can't be used in the same situations (because of type mismatch between them)
04:14:18 <ski> (and when you can use both, you need some kind of impedance mismatch, as `return' above)
04:15:06 <owhit> ski: Gotcha. So `let len = ...` will be executed later, but that result is memoized, right?
04:15:16 <ski> btw, do note that actions are special kinds of values. you can have an expression that evaluates to an action (value), which later (may) get(s) executed
04:15:32 <ski> so, it's not "either execution or evaluation"
04:16:31 <Cale> To help explain the difference between execution and evaluation, sometimes it helps to see a simple IO-like monad defined by hand
04:16:50 <ski> (however, most commonly, the kind of evaluation that needs to be done to "compute"/"prepare" an action tends to be fairly trivial. but sometimes it can be more involved. one example might be taking in a description of a regular expression, and converting that into an efficient action that can be applied many times to match different inputs)
04:17:05 <Cale> data MyIO a = Done a | GetChar (Char -> MyIO a) | PutChar Char (MyIO a)
04:18:08 <ski> owhit : `len' will not be executed at all, unless it's an action (which you mistakenly had with `lengthDict'). ignoring that, it will be evaluated/reduced (to a value, or at least closer to a value .. you might not want to compute all of an infinite data structure, e.g.)
04:18:31 <Cale> We can have something like this which represents some primitive actions with data constructors that take as arguments any arguments the primitive action would take, plus a function from the result of the action to another MyIO a (or just a MyIO a in the case that it won't produce an interesting result)
04:19:10 <Cale> You can imagine an executor for this, written as a translator which consumes one of these and produces an IO action:
04:19:17 <Cale> execute :: MyIO a -> IO a
04:19:25 <Cale> execute (Done a) = return a
04:19:38 <ski> owhit : but yes, implementations typically (not required by standard, but is probably considered as the intended operational/procedural semantics) memoize/cache bindings of variables
04:19:47 <Cale> execute (GetChar k) = do c <- getChar; execute (k c)
04:20:12 <Cale> execute (PutChar c x) = do putChar c; execute x
04:20:43 <ski> owhit : note that in `let dict = V.fromList <$> ...' is also memoized .. but it's the ((fairly trivial) evaluation of the) *action* that is memoized
04:20:59 <ski> s/is also/`dict' is also/
04:21:18 * ski isn't sure how familiar owhit is with algebraic data types yet
04:22:12 <owhit> ski: I'm in a Abstract data structures class in college, but it's mainly trees and hash tables and stuff coded in c++
04:22:36 <ski> yea, i meant in particular how data types are expressed in Haskell
04:22:49 <owhit> not uber familiar
04:23:04 <owhit> Question
04:23:15 <ski> (since Cale's suggested understanding help requires having some idea of that, including pattern-matching, and laziness to some extent)
04:23:19 <ski> Answer
04:24:06 <owhit> What's the difference between String (IO a) and IO (String a)
04:24:14 <ski> the former is a type error
04:24:21 <Cale> Do you mean [IO a] and IO [a] ?
04:24:24 <owhit> cale, and thanks, i'm taking notes
04:24:54 <Cale> A value of the first type is a list of actions, the second is a single action which will produce a list when executed
04:24:58 <ski> but if you say <what Cale just said>, then the former is a list of, not yet executed, actions; while the latter is a single action, that, when executed, will produce a list
04:25:04 <owhit> cale, ski, well i noticed cale wrote Char (MyIO a)
04:25:09 <Cale> oh
04:25:16 <ski> there's a function `sequence :: [IO a] -> IO [a]' for converting from the former to the latter
04:25:19 <Cale> those were the argument types for my data constructor
04:25:30 <Cale> The syntax of data declarations goes like
04:26:21 <Cale> data <Type name> <type parameters> = <Constructor name 1> <types of its arguments...> | <Constructor name 2> <types of its arguments...> | ...
04:26:25 <ski> owhit : actually, they wrote `PutChar Char (MyIO a)', the `Char' and `MyIO a' there are types, but `PutChar' is not a type, it's a value (a data constructor). and it parses (conceptually) as `(PutChar Char) (MyIO a)', so `Char (MyIO a)' is not even a thing there
04:26:35 <gt[m]> If i've got a few different functions that take a variable number of string arguments, is it possible to do something to all but the last 3 args in a generic way? Feels like I need to do something with uncurrying and traversing tuples but not sure exactly what
04:27:32 <owhit> Ahhh
04:27:42 <ski> owhit : anyway, with a list of actions, you can shuffle around the actions (like reorder, multiply or drop actions), and also add stuff to them
04:27:56 <Cale> gt[m]: A safe way forward would be to assume the answer is no, and then see what you can do from there. It's possible to generalise over multiple function types of different arity, but it's not usually pretty.
04:28:16 <ski> owhit : with the latter you only have a single action. with a determined (fixed) execution order, in case it was built from a list of actions like in the former case
04:29:06 <ski> gt[m] : "variable number of [..] arguments" tends to be a PITA ..
04:29:07 <Cale> owhit: Anyway, the point of that code was just to show that IO actions might just be mostly-inert bits of data -- something like trees with some pure functions mixed in.
04:29:09 <owhit> Ok, so [IO a] vs IO [a] I guess is where I was going with it
04:30:08 <ski> ("that code" being the `MyIO' and `execute' stuff above)
04:30:08 <marvin2> IO [a] is an action that, when executed, gives [a]. [IO a] is a list of IO actions
04:30:34 <Cale> owhit: Let's write a function which takes a list of IO actions like that and glues them together into a single action
04:30:37 <owhit> marvin2, that's what I thought. cool
04:30:41 <Cale> That should help you see the relationship
04:30:54 <ski> % :t sequence @[] @IO
04:30:54 <yahb> ski: [IO a] -> IO [a]
04:30:58 <Cale> sequence :: [IO a] -> IO [a]
04:31:04 <Cale> sequence [] = ...
04:31:21 <Cale> if the list is empty, we want to produce an action which does nothing, and produces the empty list as its result
04:31:28 <Cale> sequence [] = return []
04:31:36 <[exa]> gt[m]: can you perhaps capture the argument variability in some simple data structure? (variable argument count is really not very good design pattern for fuctional programming)
04:31:39 <Cale> and that's what return gets us
04:31:51 <Cale> now if the list is nonempty...
04:31:55 <Cale> sequence (x:xs) = ...
04:32:12 <Cale> (having first element x, and the rest of the list being xs)
04:32:35 <Cale> We'll want to run the first action, x, and we'll obtain some result v
04:32:41 <Cale> sequence (x:xs) = do v <- x; ...
04:32:53 <[exa]> gt[m]: (possible inspiration: https://hackage.haskell.org/package/optparse-applicative-0.14.3.0 )
04:33:08 * ski . o O ( `unsafeInterleaveIO' )
04:33:18 <Cale> and then we want to run the rest of the list of actions and obtain a list of the results, which thankfully, we have a function to do already, it's the one we're writing
04:33:31 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; ...
04:34:07 <owhit> Cale, that is pretty cool
04:34:09 <Cale> and then lastly, we put the first result on the start of the list of the rest of the results, and that'll be the result of the combined action
04:34:13 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
04:34:28 <Cale> So, this sequence function is a primordial sort of loop:
04:34:45 <Cale> if you can decide ahead of time what your iterations are going to be, such that you can put them in a list
04:34:51 <Cale> it will glue them together end to end
04:35:11 <ski> there's also a version of it `sequence :: [IO a] -> IO ()' that discards the individual results of the actions, not building a result list
04:35:18 <Cale> In terms of it, we can write something like a for-each loop:
04:35:31 <Cale> ski: missed an underscore
04:35:38 <ski> er, yes, sorry
04:35:45 <ski> % :t sequence_ @[] @IO
04:35:45 <yahb> ski: [IO a] -> IO ()
04:35:58 <ski> (you should hopefully be able to define it yourself, if you followed what Cale just explained)
04:36:18 <Cale> mapM f xs = sequence (map f xs)
04:36:35 <Cale> mapM :: (a -> IO b) -> [a] -> IO [b]
04:36:44 <Cale> and, for convenience:
04:36:45 <ski> (the `@[] @IO' noise is because `sequence' and `sequence_' are generalized, also work on other data structures than lists, and also can work with other types of actions than I/O actions)
04:36:56 <Cale> forM xs f = mapM f xs
04:36:57 <gt[m]> [exa]: The variable argument string functions are generated functions for an REST api in a library, but the api has a strange authentication scheme that requires passing headers based on the query parameters. The headers are always the last 3 parameters. 
04:37:21 <ski> (but usually, you don't need to add such noise in the actual code, since it can be determined from the context (including arguments) of the call)
04:37:36 <Cale> So, here we give forM a list of elements, and a function which, given one of those elements, will produce an action to be performed
04:37:37 <gt[m]> Cale: what would be the ugly way?
04:38:09 <Cale> and it will apply the function to all of them and glue the results together with sequence
04:38:14 <ski>   forM aList $ \x ->
04:38:16 <owhit> ski, cale, thanks so much you guys. What a beautiful community.
04:38:21 <ski>     forM anotherList $ \y -> do
04:38:26 <ski>       ..x..y..
04:38:34 <ski> will produce a list of lists, when executed
04:39:04 <ski> replacing `forM' with `forM_', it'll not compute a result list. so just nested loops, executed for effect
04:39:20 <Cale> gt[m]: If they were always the first 3, then there would be an easy thing you could do
04:39:45 <Cale> gt[m]: at least, if you wanted to pre-apply them to fixed values
04:39:58 <Cale> I'm not sure I fully understand what it is that you're looking for
04:40:19 <ski> owhit : np
04:40:38 <Cale> forM [1..3] $ \x -> do print x; getLine
04:40:44 <Logio> gt[m]: you probably want to parse the whole set of arguments separately to some fixed record (that is more structured than just a list) and pass that on to your haskell functions
04:40:45 <Cale> ^^ you can try something like that
04:41:12 <ski> owhit : .. perhaps you now somewhat better see what i meant by
04:41:15 <ski> <ski> one very nice thing about treating actions as values is that you can "code up your own control structures"
04:42:28 <Cale> owhit: and it's also very nice that because of the separation between execution and evaluation, when we're doing this, it's never confusing when any particular action is going to get executed -- we have to say explciitly when
04:42:50 <gt[m]> Cale: I could probably switch the generation around to make them either the first or last params, but they depend on the values of the other params. Basically one of the three params needs to be the other params concatenated in a particular order and signed with something
04:42:52 <Cale> If execution of these effects were somehow a part of the evaluation, they could go off at random when we didn't intend
04:43:04 <ski>   forM [0 .. 1] $ \x -> do putStr ("Q" ++ show x ++ " :"); hFlush stdout; getLine  -- or this, to get more interesting result
04:43:08 <Cale> gt[m]: ohh
04:43:42 <Cale> gt[m]: Could you perhaps tackle that after the point where you've already got the params in some sort of Map or list?
04:43:58 * ski sometimes forget how painful it can be to determine when a side-effect happens, in an imperative language
04:44:44 <Cale> gt[m]: Presumably you need to eventually generate URLs, so it seems like the right time to do that is just before you actually make the URL
04:45:25 <ski> (of course, it can sometimes be hard as well in Haskell, if you use `IO' extensively (rather than as a thin UI wrapper around the "pure core"). but having the separation between execution and evaluations often *allows* actually writing the code so that it's much more obvious when effects happen)
04:45:26 <Cale> and then you just augment your parameter Map with an additional thing or two
04:45:33 <ski> (or may happen)
04:45:56 <e> the IO monad does feel like a bit of a blunt instrument
04:46:42 <ski> yes, it's a bit of a sin-bin :/
04:46:51 <tdammers> do you mean IO, or its Monad instance?
04:46:59 <Cale> Of course, this separation between execution of IO actions and evaluation of expressions means that if you think IO is too blunt an instrument, you're free to invent your own mechanism for describing how things ought to change over time
04:47:01 <e> IO
04:47:06 <ski> also (and relatedly), it's sometimes too course compared to what one'd prefer
04:47:13 <tdammers> then I agree
04:47:18 <Cale> and FRP systems are an example of that power
04:47:33 <Cale> I do a lot of programming with Reflex
04:47:44 <tomasa> Hi, any visual diagrams of monads for better understanding? I saw once, a kind of a boxes, but I can not remember where I got them. 
04:47:45 <ski> (cf. effect systems. or, partially comparable (for mutable state specifically), unique values in Clean (and Rust ?))
04:47:45 <tdammers> but the alternatives I've seen aren't any better, just bad in different ways
04:47:50 <e> i saw a paper by edwin brady once about the things idris uses for effects. but i didn't understand it at the time. i keep meaning to read it again
04:48:20 <tdammers> yeah, apparently you have a few more options in a fully dependently-typed language
04:49:25 <tdammers> he's implemented this "fuel" thing, where you encode a construct's capability of exposing certain effects at the type level, so that you can enforce things like "effect happens N times", or "does not terminate", or stuff like that
04:49:27 <ski> tomasa : hmm .. iirc Bartosz Milewski has some "train tracks" diagrams, for exceptional stuff (`Maybe',`Either',`ExceptT')
04:49:36 <tdammers> I must admit I don't fully understand how that works either D:
04:50:35 <tomasa> Let me check them out, @ski ;)
04:50:57 <ski> tomasa : dpiponi's <http://blog.sigfpe.com/2006/10/monads-field-guide.html> is another kind of visualization (may be useful for understanding compositions of monad transformers better)
04:51:05 <Cale> Also, STM is a good example of an application of that separation of effects
04:51:38 * ski idly notes that it's not IRC custom to prepend nicknames with `@' when you want to refer with them
04:51:53 <Cale> Because if you want STM to be sane, you really *need* that your memory transactions don't randomly end up with effects inside them, because they'll be run potentially many times
04:52:04 <Cale> (and it's fairly uncontrollable)
04:52:59 <Cale> The intention being that all the effects which are allowed in STM actions are memory effects that it's possible to track in a log and commit at once to memory.
04:53:16 <tomasa> ski last link is a page not found, it's not longer available. 
04:53:30 <gt[m]> Cale: yes, but i still need to pass everything from the list or map one by one into the function that calls the api
04:53:31 <ski> hm .. and i also think some monad papers had some diagrams. i may be thinking of the ST paper
04:53:44 <Cale> gt[m]: hm?
04:54:19 <ski> "Lazy Functional State Threads" by John Launchbury,Simon Peyton-Jones in 1993 at <www.microsoft.com/en-us/research/wp-content/uploads/1994/06/lazy-functional-state-threads.pdf>
04:54:21 <Cale> gt[m]: I mean, in the place where the query parameters are a single list or Map or something
04:55:14 <Cale> gt[m]: on the other side, where you're about to call the API
04:55:36 <Cale> maybe I don't understand what's going on
04:56:06 <Cale> But I would expect that at some point, you have some URL representation which is a little higher level than a string, but not by much, just breaking the URL into parts
04:56:11 <gt[m]> so there i can generate the "header" param from the list, but i still need to pass the first element of the list to arg 1, the second to arg 2, etc, until passing the header param to the last arg of the function
04:56:30 <ski> tomasa : Bartosz has monad (and category theory) explanations on YouTube. he also did a book (on CT for programmers), i think (i haven't checked it)
04:56:32 <gt[m]> Cale: yes that happens, but in generated code which i dont want to edit
04:56:39 <Cale> ah
04:56:44 <gt[m]> the api code is generated from a specification of the api
04:56:44 <Cale> what's generating the code?
04:56:59 <gt[m]> openapi-generator
04:58:15 <ski> tomasa : hrm. perhaps you (or a program, like an IRC client, or terminal, or browser, incorrectly) managed to copy the closing angle
04:59:16 <e> we should have standardized on <URL:...>
04:59:35 <ski> to distinguish from ?
05:00:07 <e> no idea, i just find it amusing
05:00:26 <Cale> is that a meta-scheme?
05:00:48 <e> i guess it distinguishes them from HTML elements that people might choose to include in their messages
05:01:57 <Cale> It's to distinguish from URIs which are something entirely different ;)
05:02:29 <Cale> gt[m]: hmm, I have no idea how to edit that.
05:02:38 * ski . o O ( "RFC 3986 - Uniform Resource Identifier (URI): Generic Syntax","Appendix C.  Delimiting a URI in Context" by IETF in 2005-01 at <https://tools.ietf.org/html/rfc3986#appendix-C> )
05:03:10 <ski> (an earlier version had `<URL:...>', i think (or maybe `URI' ?))
05:04:05 <gentauro> ski: you should really be called skk (the i is irrelevant) xD
05:04:35 <ski> less pronounceable :)
05:05:58 <ski> (ok, RFC 1808,2396)
05:05:59 <Cale> ah, https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator/src/main/resources/haskell-http-client and https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator/src/main/resources/haskell-servant
05:06:16 <Cale> It's that gross mustache thing
05:07:09 <kloffy> Hey, I have a quick question, is there any way to make the following code work? https://pastebin.com/vJdUVdWp
05:07:44 <ski>   Using <> angle brackets around each URI is especially recommended as delimiting style for URI that contain whitespace.  The prefix "URL:" (with or without a trailing space) was recommended as a way to used to help distinguish a URL from other bracketed designators, although this is not common in practice.  For robustness, software that accepts user-typed URI should attempt to recognize and strip both delimiters and embedded whitespace.
05:08:58 <Cale> kloffy: Maybe if you put in enough type signatures that it can figure out what's going on
05:09:12 <e> (ski: oh no i did ns info ski and now i'm contractually obliged to nag you to set an email address)
05:09:17 <ski> Cale : mustache ?
05:09:30 <e> i've used quite a bit of software that doesn't take advantage of <>
05:09:31 <Cale> ski: A "templating" language
05:09:35 <dminuoso> kloffy: Do you know what an ambiguous type variable is?
05:10:12 <kloffy> Well, not precisely, no.
05:10:39 <dminuoso> kloffy: It's when a type variable is not mentioned in the final result of a function, in short.
05:11:15 <tomasa> Thank you ski
05:11:25 <dminuoso> kloffy: so imagine you do `split a b`, where `b` has a polymorphic type. How can haskell possibly infer what type `b` is going to have now?
05:11:47 <ski> s/the final result of a function/the inferred signature of a function/
05:12:04 <ski> tomasa : did you find any useful Bartosz link ?
05:12:37 <kloffy> I see, so "r = (fs (0::Int)) :: (Int, (Int, (Int, ())))" works...
05:12:54 <kloffy> But obviously I would like to omit the types.
05:13:35 <hololeap> @djinn (Monad m, Traversable m, Applicative t) => m (t (m a)) -> t (m a)
05:13:35 <lambdabot> Error: Class not found: Traversable
05:13:46 <dminuoso> kloffy: Let's consider a simpler example
05:13:49 <kloffy> Is there any way to stop them from being ambigous, i.e. help the type checker?
05:14:34 <dminuoso> kloffy: class Sizeof a where size :: Int; instance Sizeof Int32 where size = 32; instance Sizeof Int64 where size = 64
05:14:46 <ski> hololeap : Djinn doesn't really understand classes, anyway (especially not higher-rank ones, by which i here mean ones that have polymorphic methods, like `fmap' in `Functor', but not like `(==)' and `(/=)' in `Eq')
05:14:51 <dminuoso> kloffy: So if I used `size`, it couldn't infer what type I wanted obviously.
05:16:53 <dminuoso> kloffy: The old trick to make such a typeclass work, is to introduce a Proxy, such that a consumer could specify the type via the Proxy pattern.
05:18:23 <ski> @djinn Functor f => f a -> (a -> b) -> f b  -- hololeap, note that this works
05:18:24 <lambdabot> Cannot parse command
05:18:32 <ski> @djinn Functor f => f b -> (b -> a) -> f a  -- but this doesn't
05:18:33 <lambdabot> Cannot parse command
05:18:42 <ski> er, it doesn't like comments
05:18:45 <ski> @djinn Functor f => f a -> (a -> b) -> f b
05:18:46 <lambdabot> f a b = fmap b a
05:18:49 <ski> @djinn Functor f => f b -> (b -> a) -> f a
05:18:49 <lambdabot> -- f cannot be realized.
05:19:16 <ski> hololeap : so it doesn't understand valid renaming of type variables in the signature of polymorphic methods
05:20:03 <ski> @djinn Functor f => (a -> b) -> f (f a) -> f (f b)
05:20:04 <lambdabot> -- f cannot be realized.
05:20:35 <ski> ^ also doesn't work, for basically the same reason. it doesn't instantiate the (non-class-head-bound) tyvars in signatures of polymorphic methods
05:21:11 <dminuoso> kloffy: Its a bit amusing. We should either chat here or there, but not mixed.
05:21:29 * ski idly wonders where "there" would b e
05:21:56 <dminuoso> kloffy: Is it possible you are responding to me using /msg? Because you are sending me private messages.
05:22:10 <kloffy> dminuoso: Sorry, I was a bit lost.
05:22:14 <dminuoso> Heh fair enough.
05:22:26 <dminuoso> kloffy: In Haskell polymorphism delegates the choice of a type to the *consumer* of something.
05:22:45 <ski> (e.g. caller, in case of a function)
05:23:43 <kloffy> Yes, that all makes sense so far.
05:24:03 <dminuoso> kloffy: Number literals are overloaded and have the type `Num a => a`
05:25:52 <dminuoso> kloffy: Now consider the type of (+)
05:25:55 <dminuoso> % :t (+)
05:25:55 <yahb> dminuoso: Num a => a -> a -> a
05:26:35 <dminuoso> kloffy: Here the type variable is returned, so if you used this like `x = 1 + 2` the type is still not decided, it's delegated to the consumer of x now (ignoring the dreadful monomorphism restriction on purpose)
05:26:55 <kloffy> Ok, but why does the following work (when I expand manually): split2 = \(f, (g, ())) -> \x -> (f x, (g x, ()))
05:27:37 <kloffy> split2 ((+1), ((+2),())) 0 == (1, (2, ()))
05:27:38 <dminuoso> kloffy: For the same reason why expanding my previous definition of `size` works.
05:27:50 <dminuoso> kloffy: that is, if you replaced `size` with just `64 :: Int` all is good.
05:28:58 <dminuoso> kloffy: Again: its the consumer that picks the type for a type variable, not the implementor.
05:30:14 <kloffy> Yes, that is all helpful, but I guess where I am stuck is how my manual code is different from the more general typeclass...
05:30:34 <kloffy> The same type information is provided.
05:31:02 <kloffy> One is unambiguous and the other one is ambiguous.
05:31:45 <kloffy> Something must be preventing the type checker from inferring the types.
05:32:12 <dminuoso> kloffy: The fact that you "ate" a type variable so to speak.
05:32:33 <dminuoso> kloffy: In order for a consumer to be able to pick a type, he has to "Get that type variable back"
05:32:45 <dminuoso> kloffy: https://gist.github.com/dminuoso/6231fb59bf50d66947ebe4113fe54d5d
05:32:49 <kloffy> Interesting, which type variable, the argument type?
05:33:09 <dminuoso> kloffy: in your class `a`
05:33:27 <kloffy> Yes, the argument type.
05:34:02 <kloffy> Hm...
05:34:07 <dminuoso> kloffy: Now consider my example in the gist.
05:34:40 <kloffy> Yes, I am looking at it.
05:35:38 <kloffy> Not sure, I would imagine it's inferring based on the type of the value...
05:35:58 <kloffy> What type is 1?
05:36:01 <dminuoso> kloffy: Num a => a
05:36:06 <dminuoso> kloffy: It's polymorphic.
05:36:14 <kloffy> Well, then it can't...
05:36:17 <kloffy> Can it?
05:36:19 <dminuoso> Precisely.
05:36:30 * ski beams
05:36:41 <kloffy> Hm...
05:37:37 * ski idly wonders whether kloffy has seen the `show . read' example, yet
05:37:49 <dminuoso> Oh this is truly wonderful. :)
05:38:21 <ski> (you could relate it, if you want to)
05:38:40 <kloffy> Yes, thank you for explaining, but I am not sure if this is the same problem as in my example?
05:38:46 <dminuoso> kloffy: It is.
05:39:27 <kloffy> Ok, well, what if I specify the argument type exactly?
05:39:38 <kloffy> Shouldn't the return type be deduced?
05:39:49 <dminuoso> kloffy: The return type is not the problem.
05:39:59 <dminuoso> kloffy: It's that GHC has to know what `0` is supposed to be.
05:40:22 <kloffy> I am not sure that is correct.
05:40:34 <oo_miguel> can someone recommend a light library that will fetch me data via https. (preferrable available on stackage)? I found "download" but it seems not to support https.
05:43:50 <kloffy> Because it is not enough to specify: r = (split ((+1), ((+2), ((+3), ())))) (0::Int)
05:44:11 <dminuoso> kloffy: you just moved the problem.
05:44:48 <kloffy> Well, it should know exactly what 0 is now, right?
05:51:13 <kloffy> Somehow I am stuck seeing what the difference is between the typeclass and r = (\(f, (g, (h, ()))) -> \x -> (f x, (g x, (h x, ())))) ((+1), ((+2), ((+3), ()))) 0
05:51:27 <owhit> I am very very confused. When I compile `main = do x <- return 3; print x; return ()` it tells me that `x` is not in scope. Wat?
05:52:05 <ski> owhit : indentation
05:52:26 <ski> presumably you have new lines in place of `;', yes ?
05:52:41 <ski> make sure that the three commands inside the `do' all start at the same column
05:52:49 <owhit> ski. odd. It was indentation. but everything looked right.
05:52:51 <owhit> works now
05:53:08 * hackage validity-bytestring 0.4.1.0 - Validity instances for bytestring  https://hackage.haskell.org/package/validity-bytestring-0.4.1.0 (Norfair)
05:53:12 <ski> (and check if you maybe have tabs vs. spaces issues, possibly caused by having your editor display tabs as something else than in terms of eight spaces)
05:53:15 <owhit> ski, probably happened when i switched editors for a second
05:54:06 <ski> (it's usually recommended that you don't use tabs at all for indentation, in Haskell. this can often be configured in your editor, so that the tab key inserts spaces)
05:54:08 * hackage ats-pkg 3.2.5.3 - A build tool for ATS  https://hackage.haskell.org/package/ats-pkg-3.2.5.3 (vmchale)
05:54:12 * hackage genvalidity-hspec-aeson 0.3.1.0, genvalidity-hspec 0.7.0.0, genvalidity-unordered-containers 0.3.0.0, genvalidity-containers 0.6.0.0, genvalidity-bytestring 0.5.0.0, genvalidity-aeson 0.3.0.0, genvalidity-text 0.6.0.0, genvalidity 0.8.0.0 (Norfair)
05:55:16 <ski> (it is possible to use tabs for indentation, but then one must do it consistently, and ought to break line after all layout-introducing keywords (`where',`let',`do',`of'), except if they're only followed by one indented "item")
05:55:31 <kloffy> So, I take it writing a general version of split - example: \(f, (g, (h, ()))) -> \x -> (f x, (g x, (h x, ())))) - using type classes and getting the same type inference is not possible?
05:55:54 <kloffy> (This was my attempt: https://pastebin.com/vJdUVdWp)
05:56:21 <dminuoso> kloffy: Ah okay, I think I can see the second half of the problem now.
05:56:46 <owhit> k
05:57:40 <dminuoso> kloffy: so lets consider a simplifier case: split ((+1), ())
05:57:55 <dminuoso> kloffy: The type of this expression is: split ((+1), ()) :: (Split (a1 -> a1, ()) a2, Num a1) => a2 -> (a1, ())
05:57:57 <kloffy> Sounds good, less parentheses... :D
05:58:34 <kloffy> Yes, a1 should be equal a2...
05:58:44 <dminuoso> kloffy: No it should not.
05:58:58 <Putonlalla> It works if you specify the types, kloffy.
05:59:11 <dminuoso> kloffy: It cant deduce the fact from just looking at this expression.
05:59:32 <kloffy> Putonlalla: Yes, but I have to specify all the types, which is a bit laboursome...
05:59:55 <dminuoso> kloffy: Ambiguous type variables means you have to pick those types because GHC cant infer them for you.
05:59:58 <kloffy> dminuoso: Yes, that seems to be the case.
06:00:04 <dminuoso> split :: fs -> (a -> (SplitR fs))
06:00:18 <Putonlalla> You can enable `AllowAmbiguousTypes`, `FlexibleContexts`, `FlexibleInstances`, `NoMonomorphismRestriction`, `MultiParamTypeClasses` and `TypeFamilies`. Then `r :: (Integer, (Integer, (Integer, ())))` will work.
06:00:50 * ski . o O ( ah, the fun of extensions )
06:01:34 <dminuoso> Presumable he has all but NMMR enabled already.
06:04:05 <kloffy> Yes, I did.
06:04:21 <kloffy> NMMR did not seem to make a difference.
06:04:47 <shader> I know this is a really easy question, but I'm having a hard time finding the answer... If I want to define a type "data Sequence = Sequence [String]", how do I make it so I can reuse the foldr operations from [String], without making Sequence an alias?
06:05:10 <dminuoso> shader: generalized newtype deriving, coerce, unwrapping/rewrapping
06:05:30 <dminuoso> (Or just deriving Foldable)
06:06:21 <shader> I get "Class ‘Foldable’ expects an argument of kind ‘* -> *’" when I add "deriving (Foldable)" though
06:06:37 <dminuoso> Oh right.
06:06:37 <kloffy> Sorry, NMMR does make a difference, my bad.
06:07:01 <ski> > ala Sum foldMap [2,3,5,7]
06:07:03 <lambdabot>  17
06:07:04 <ski> > ala Product foldMap [2,3,5,7]
06:07:06 <lambdabot>  210
06:07:13 <ski> @src Sum
06:07:14 <lambdabot> newtype Sum a = Sum { getSum :: a }
06:07:16 * dminuoso likes ala
06:07:16 <ski> @src Product
06:07:16 <lambdabot> newtype Product a = Product { getProduct :: a }
06:07:32 <shader> dminuoso: I'll look up the keywords you gave me, should be enough to find it
06:07:46 <dminuoso> shader: ^- ala would work too. :)
06:07:57 <dminuoso> shader: isnt ala just coerce in disguise?
06:08:03 <dminuoso> Sorry, I meant ski.
06:08:40 <kloffy> Putonlalla: Yes, that combination of extensions does work as long as you specify the exact result type, but it seems rather heavy handed...
06:08:52 <dminuoso> Putonlalla: What difference would NoMonomorphismRestriction make?
06:09:07 * hackage writer-cps-transformers 0.5.5.0 - WriteT and RWST monad transformers  https://hackage.haskell.org/package/writer-cps-transformers-0.5.5.0 (minad)
06:10:08 * hackage writer-cps-transformers 0.5.6.0 - WriteT and RWST monad transformers  https://hackage.haskell.org/package/writer-cps-transformers-0.5.6.0 (minad)
06:11:27 <kloffy> Hm, I wish I could continue the discussion, but it is getting rather late.
06:11:37 <kloffy> Thank you everyone for chiming in though.
06:11:42 * ski likes "Ala Gal" by Charles Deenen & Jeroen Tel / Maniacs of Noise in 1988 at <http://files.exotica.org.uk/?file=exotica/media/audio/High_Voltage_Sid_Collection/C64Music/MUSICIANS/D/Deenen_Charles/Ala_Gal.sid>,<https://www.youtube.com/watch?v=FaJokKSc7EY>
06:11:50 <Putonlalla> It should allow inferring the most general constraints for the unannotated test cases, dminuoso.
06:11:59 <Putonlalla> It may be unnecessary with `AllowAmbiguousTypes`.
06:12:23 <dminuoso> kloffy: Im gonna ponder about the problem though, but the way your split function is written, it's just too ambiguous.
06:12:35 <ski> @hackage newtype
06:12:35 <lambdabot> http://hackage.haskell.org/package/newtype
06:12:39 <ski> dminuoso ^
06:13:15 <kloffy> Yes, I feel like I need to add some constraints on the types.
06:13:21 <dminuoso> ski: Ah I was thiniking of the version from coercible-utils
06:13:24 <kloffy> Or maybe do the Proxy business...
06:13:27 <dminuoso> kloffy: Additional constraints wont help
06:13:48 <kloffy> Well, but as you said: split ((+1), ()) :: (Split (a1 -> a1, ()) a2, Num a1) => a2 -> (a1, ())
06:14:05 <kloffy> It should really be a1 -> (a1, ())...
06:14:06 <dminuoso> kloffy: the problem is that you have an ambiguous type variable in the constraint.
06:14:07 * hackage writer-cps-mtl 0.1.1.6 - MonadWriter orphan instances for writer-cps-transformers  https://hackage.haskell.org/package/writer-cps-mtl-0.1.1.6 (minad)
06:14:14 <ski> dminuoso : must be a newer version
06:14:37 <dminuoso> kloffy: well if you only allow `a -> a ... -> a` then it becomes solvable
06:14:57 <dminuoso> kloffy: I think I have an idea.
06:15:37 * hackage writer-cps-exceptions 0.1.0.1 - Control.Monad.Catch instances for the stricter CPS WriterT and RWST  https://hackage.haskell.org/package/writer-cps-exceptions-0.1.0.1 (minad)
06:15:59 <dminuoso> kloffy: are you looking to make that typeclass work, or find a solution for that problem?
06:16:26 <kloffy> Well, I suppose I would like to be a bit more general. The whole this is meant to do: ((a->r0), ..., (a->rN)) -> (a -> (r1, ..., rN))...
06:17:22 <kloffy> That the simplest instance of the general problem I am trying to solve.
06:17:40 <dminuoso> kloffy: At the risk of sounding naive, but is there a reason why want to do this with tuples?
06:18:17 <kloffy> I just wanted to stick to standard Haskell types to make it easy to follow...
06:20:00 <ski> s/tuples/any kind of record-like type of values/
06:20:04 <kloffy> It's just an implementation of the simple algebraic rule: r0^a * r1^a * ... * rN^a == (r0 * r1 * ... * rN)^a
06:20:46 <ski> (that rule would be parameterized, at least, by `N' also. or perhaps a tree, if you care about different ways to associate the product)
06:21:31 <kloffy> Well, the product is right associative in my implementation.
06:21:45 <kloffy> But I don't see how that matters here.
06:22:17 <kloffy> I can manually write out functions for a given N, but I would like a version that works for all N.
06:22:21 <kloffy> Hence the typeclass.
06:22:44 <ski> (what if `r0 = p0 * q0', so that `r0^a = p0^a * q0^a'. should you get `p0^a * q0^a * r1^a * ... * rN^a = (r0 * r1 * ... * rN)^a' or `(p0 * q0)^a * r1^a * ... * rN^a == (p0 * q0 * r1 * ... * rN)^a' ? note different `N's used in the algebraic rule)
06:23:12 <ski> you'd need some way to specify the `N'
06:23:43 <kloffy> Yes, it's in the type of the tuple.
06:24:05 <kloffy> ((+1), ((+2), ())) 
06:24:10 <kloffy> N = 2
06:24:52 <kloffy> You can use HList or your custom heterogeneous list implementation...
06:24:59 <ski> do you want `A * (B * (C * (1 * 1)))' to be interpreted as a product of four types, `A',`B',`C',`1', or as a product of three types `A',`B',`C' (note that `X * 1 = X' another algebraic rule) ?
06:25:22 <ski> you need to somehow specify `N', i think. explicitly, probably
06:25:24 <kloffy> X * 1 ~= X, yes.
06:26:03 <kloffy> I mean, this part already works.
06:26:27 <kloffy> https://pastebin.com/vJdUVdWp
06:26:36 <kloffy> It's just that you have to specify all the types.
06:26:48 <kloffy> (Note: All the types, not N.)
06:27:08 <kloffy> I am trying to get around having to specify all the types.
06:27:53 <ski> i don't see how `X * 1 ~= X' would be a "part" that "already works", in that paste
06:28:20 <ski> hmm. perhaps you could use type-level naturals
06:29:31 <kloffy> X*1 ~= X is of course only implicit, (a, ()) /= a, but they are effectively the same...
06:30:06 <kloffy> (aka isomorphic...)
06:32:03 <kloffy> Again, the whole "challenge" is to write \(f, (g, (h, ()))) -> \x -> (f x, (g x, (h x, ())))) :: (a->r0, (a->r1,(a->r2,()))) -> a -> (r0, (r1, (r2,()))) for any N.
06:33:00 <kloffy> Anyway, I will contemplate this some more tomorrow, thank you again everyone for the suggestions!
06:38:54 <kloffy> :t \(f, (g, (h, ()))) -> \x -> (f x, (g x, (h x, ())))
06:38:56 <lambdabot> (t -> a1, (t -> a2, (t -> a3, ()))) -> t -> (a1, (a2, (a3, ())))
06:41:17 <Lears> % (<*|) :: Applicative f => f a -> f b -> f (a, b); (<*|) = liftA2 (,); infixr 5 <*|
06:41:17 <yahb> Lears: 
06:41:28 <Lears> % :t \f g h x -> (f <*| g <*| h) x
06:41:28 <yahb> Lears: (t -> a1) -> (t -> a2) -> (t -> b) -> t -> (a1, (a2, b))
06:42:45 <Lears> % (+1) <*| (+2) <*| (+3) $ 0
06:42:45 <yahb> Lears: (1,(2,3))
06:43:07 <Lears> kloffy: ^ look good to you?
06:45:52 <kloffy> Woah... :D
06:47:31 <kloffy> On first glance that looks good indeed.
06:48:16 <dmwit> kloffy: https://gist.github.com/dmwit/4cceddecaf139b1428c0199378f044b3
06:49:14 <ski> hm, i was pondering something like `class Split (n :: Nat) fs a | fs -> n,(Split fs) n -> fs where ...', `instance Split 0 () a where ...',`instance Split n fs a => Split (n + 1) (r -> a,fs) a where ...', and call it like `split @3 (...) 0' (i think)
06:49:37 <dminuoso> dmwit: That looks sleek.
06:49:51 <dminuoso> It seems exactlyu like kloffy was trying.
06:49:52 <kloffy> Yeah, that's probably closest to where I was going.
06:49:57 <ski> however, it seems GHC doesn't like non-tyvars in FDs, docs suggesting one should introduce an (extra) auxilary type, and an equality constraint (yuck !)
06:50:14 <kloffy> Still trying to figure out Lears' magic...
06:50:35 <ski> oh, Lears' version is easy
06:50:55 <Lears> It's the least magical version, really.
06:51:03 <dminuoso> % :t liftA2 (,)
06:51:03 <yahb> dminuoso: Applicative f => f a -> f b -> f (a, b)
06:51:08 <dminuoso> kloffy: ^- its just this.
06:51:24 <dminuoso> kloffy: and using the "Reader" instance Applicative ((->) a)
06:51:26 <ski> it's the same idea as how `Applicative' operations (`<*>' and `pure', and also their combination `<$>') can *appear* to support variadic things
06:51:32 <kloffy> Well, least magical is magic on its own right. Simple solutions are the best....
06:51:38 <dmwit> More specifically: liftA2 (,) :: (e -> a) -> (e -> b) -> e -> (a, b)
06:52:21 <kloffy> Yes, I think it is slightly different, right?
06:52:26 <ski> kloffy : but if you already have a tuple, you can't use that
06:52:33 <kloffy> Exactly.
06:52:33 <dminuoso> kloffy: Nope.
06:53:03 <ski> (Lears' version encodes the natural number in the number of times `<*|' is used)
06:54:18 <kloffy> Yeah, maybe there is a way to do (f, (g, (h, ()))) -> (f <*| g <*| h), but probably we're back to the typeclass again...
06:54:35 <kloffy> So I think dmwit takes the cake.
06:56:41 <ski> oh, dmwit's looks nice
07:01:40 <ski> i would like to add an FD `(I a) -> a' to it
07:01:41 <kloffy> Yeah, it needs the result type explicitly specified, but still best one thus far...
07:02:01 * ski ponders whether that would help any with the ambiguity
07:03:18 <kloffy> How would you specify that though?
07:03:42 <kloffy> The I is in the typeclass...
07:06:30 <ski> like `class Foo a | (I a) -> a where type I a t; ...'
07:06:42 <ski> (but GHC doesn't like such FDs ..)
07:07:51 <kloffy> Yeah, unfortunately...
07:13:34 <ski> hm, too bad, `class Inv a (I a) ~ a => Foo a where { type I a :: * -> *; type Inv a :: (* -> *) -> *; foo :: I a t -> t -> a }; instance Foo () where { type I () t = (); type Inv () (I ()) = (); foo () _ = () }; instance Foo b => Foo (a,b) where { type I (a,b) t = (t -> a,I b t); type Inv (a,b) (I (a,b)) = (a,Inv b (I b)); foo (f,gs) t = (f t,foo gs t) }' doesn't seem to work
07:14:03 <slack1256> Has anyone used "Trees that grow" instead of vynil on some project? What has been you experience?
07:14:10 <maerwald> tdammers: https://github.com/well-typed/optics what is this :>
07:14:18 <ski> hmm
07:15:34 <tdammers> maerwald: well-typed's secret plan to take over the world
07:15:48 <maerwald> HEHE
07:16:06 <tdammers> seriously though, it's a lens library that uses a different lens encoding than the Van Laarhoven one used in Kmett's lens library
07:16:19 <tdammers> while trying to replicate the lens API as faithfully as possible
07:17:06 <maerwald> looking at the slides, one of the goals seem to be better error messages?
07:18:52 <tdammers> yes
07:19:23 <leshow> I'd like someones opinion on the most type-safe or idiomatic way to structure some code. If I have a sum type like data Events = A | B | C and product types like data EventA, EventB, etc.
07:19:36 <leshow> I want to associate the A constructor of Events to EventA
07:19:45 <tdammers> lens' error messages can be disturbing, because Lens and Getter and Prism and all those other things are just aliases for functions over Functors and similar things
07:20:11 <tdammers> leshow: associate how?
07:21:04 <leshow> tdammers: Well I'm parsing input data, each of those EventA has a json instance
07:21:28 <leshow> and I use the enum instance of Events to determine which variant of event I should deserialize
07:23:02 <leshow> Ideally, I'd be able to have them in the same type like, which events variant, and which record, I think
07:23:47 <tdammers> so what is the type you're deserializing into? or alternatively, what is the type of your parser function?
07:24:23 <leshow> I'm using Aeson to deserialize data sent over a unix socket
07:24:54 <leshow> the data is of the form <eventtype> <body> where eventtype is like 1,2,3,4,.. etc. Which is why Events is separate
07:25:02 <leshow> I'm using the derived Enum instance
07:25:51 <owhit> I am happy. I just had like 7 haskell epiphanies in the last 30 minutes
07:25:54 <leshow> It's just, because A isn't a type constructor, I can't write something like data Variants = VariantA A EventA | VariantB B EventB
07:27:04 <leshow> I want to write variants like that VariantX X EventX, where X is restricted to a single constructor of Events
07:30:57 <leshow> I suppose I could write a type like data Events = A EventA | B EventB then just manually implement Enum
07:31:33 <Solonarv> that would be a rather incorrect Enum instance
07:31:40 <leshow> Just wondered if there is a way to write Constructor TypeA TypeB where TypeA is restricted to a specific instance
07:31:46 <leshow> sorry, constructor
07:32:08 <tdammers> leshow: so the "here's how you get exactly what you're asking for" answer is "use GADTs"
07:32:26 <tdammers> leshow: but the more productive answer is to not use an enum like that
07:32:40 <leshow> why not?
07:32:58 <leshow> I don't have control over whats transmitted over the IPC
07:33:03 <tdammers> the data Events = A EventA | ... approach is pretty good
07:33:11 <tdammers> why do you need the Enum instance?
07:33:41 <leshow> because the IPC transmits 1, 2, 3 etc to tell the event type, then the body of the message is a json encoded event
07:33:59 <tdammers> so?
07:34:20 <tdammers> using Enum for that purpose seems like the wrong approach to me anyway
07:34:36 <tdammers> I'd take the dumb explicit approach
07:34:57 <leshow> I'd rather not literally write 1 and 2 to represent an event type
07:34:59 <tdammers> just write out the Int -> Event mapping
07:35:07 <tdammers> no, you don't have to
07:35:16 <leshow> then i'm just writing an enum instance explicitly
07:35:25 <tdammers> it's not an enum instance, really
07:35:32 <tdammers> you're not enumerating all the values
07:35:41 <leshow> it's a mapping of ints to constructors, which is what toEnum gives me here
07:35:53 <delYsid> Does haskell have a portable equivalent to createPipe/readFD/writeFD?
07:36:02 <tdammers> technically, yes; but that's not entirely what Enum is supposed to be about
07:36:31 <tdammers> Enum is mainly about enumerating values - but in this case, I'm not so sure that that's a useful concept here
07:36:47 <tdammers> you're not after enumerating all the values, you're after mapping certain integers to certain constructors
07:38:01 <Solonarv> which is only (sort of) the same thing as Enum when all the constructors are nullary
07:38:18 <maerwald> something wrong with the hackage mirrors? I get a few K/s
07:39:20 <leshow> okay so, assuming you had an empty file to represent the data idiomatically
07:39:29 <leshow> what would you pick
07:41:04 <leshow> tdammers: also, out of curiousity, what would that GADT look like
07:42:02 <tdammers> something like data Events where EventA :: A -> Events; ...
07:42:12 <Solonarv> no, that's not it
07:42:26 <leshow> yeah, A isn't a type
07:42:28 <Solonarv> % data EventType = A | B | C
07:42:28 <yahb> Solonarv: 
07:42:39 <tdammers> oh crap, right
07:43:15 <absence> monad transformers usually have a runXXX function to run/deconstruct/whatever the layer. if one were to refer to those functions as a group, what would be a good name? "runners" or "desconstructors" sound a bit awkward to me
07:44:02 <Solonarv> % data Event (ty :: EventType) where EventA :: { eventAData :: () } -> Event A; EventB :: { eventBData :: () } -> Event B
07:44:02 <yahb> Solonarv: 
07:45:14 <Solonarv> obviously you'd have actual fields instead of the '{ eventAData :: () }' parts
07:46:04 <leshow> Solonarv: that's super cool
07:46:46 <ski> absence : perhaps "executors" ?
07:47:02 <ski> (i think i've seen "run functions")
07:47:54 * ski idly wonders why `runCont :: Cont o o -> o' and `runContT :: Monad m => ContT o m o -> m o' are still MIA
07:49:12 <Solonarv> leshow: the problem there is that you have no way to recover the type 'A from the value A
07:50:25 <Solonarv> and also, you need to define a wrapper 'newtype AnEvent = forall ty. AnEvent (Event ty)' so you can feasibly pass around "an event of unknown type"
07:52:01 <absence> ski: i find names about running or executing a but unsatisfying, because they emphasise the operational aspect rather than the structural.. i haven't seen anything else though
07:52:37 <Solonarv> "unwrapper" works, I think
07:52:43 <ski> absence : well, in some sense, execution is evaluation in the Kleisli category
07:52:44 <slack1256> the structural aspect is reflected on the type signature though
07:53:32 <absence> ski: at the other end of the spectrum there's "natural translation to identity", but that's a bit too fleeting again :D
07:53:45 <absence> transformation*
07:53:50 <ski> (which is the correct way to think about monadic effects, "internally". remember, a monad is a DSL for expressing a particular kind of effectful computations. so you're already, conceptually, in a different language)
07:54:02 <codedmart> Is forkIO a bad idea? I have a servant server that I then run a job queue as well with forkIO. Also from the job queue I can run as many as 6 jobs at a time with uses forkIO. I ran into an error recently that was long the lines of `threadWait: ... bad file descriptor ...`.
07:54:08 <codedmart> Should I be doing this differently?
07:54:14 <ski> absence : yea, that doesn't work, except for the `Identity' monad
07:54:37 <leshow> Solonarv: I think I see what you mean
07:54:45 <absence> Solonarv: yes, maybe..
07:55:22 <slack1256> codedmart: that doesn't look like a problem with forkIO though... the error says it
07:56:40 <hasker> I'd appreciate some help with understanding how to approach applying a function to multiple types of applicatives. For example: f::Int->Int>Int, f <$> Maybe Int <*> IO Int
07:57:07 <merijn> hasker: You can't do that
07:57:13 <slack1256> hasker: short answer is you don't
07:57:15 <Solonarv> you can't do that in general
07:57:36 <Taneb> hasker: what are you expecting that to do?
07:57:38 <codedmart> slack1256: So in other words the file it is trying to operate on?
07:57:49 <codedmart> I was thinking that but my initial google threw me off.
07:58:22 <slack1256> codedmart: probably, I don't know what your code is doing. But forkIO stuff is kind of common and safe to do
07:58:25 <Solonarv> you can usually (actually always, I think) find an applicative which is a "combination" of Maybe and IO; lift your arguments into that; and then apply f across the arguments
07:59:05 <slack1256> codedmart: For concurrent stuff, I find debugging effects with Debug.Trace.traceIO really helpful
08:00:06 <hasker> I know I can't do that. I'm trying to understand how to approach this. Say I have a Maybe that I need a value from and if that Maybe has a value then I want to get the value from the IO.
08:00:39 <Solonarv> you're going to need some kind of "combination" applicative like I mentioned
08:00:40 <codedmart> slack1256:Thank you!
08:01:14 <Solonarv> Fortunately those always exist, because you can simply Compose them
08:02:13 <Solonarv> :t \f maybeA ioB -> getCompose (liftA2 f (Compose (pure maybeA)) (Compose (pure <$> ioB)))
08:02:15 <lambdabot> error:
08:02:15 <slack1256> hasker: do { i <- getInt :: IO Int ; let result = flip f i <$> maybeInt ; return result } ?
08:02:15 <lambdabot>     Variable not in scope: getCompose :: f2 c -> t
08:02:15 <lambdabot> error:
08:02:21 <hasker> Solonarv: Do you mean that I need to use transformers to do that? And if so, do I lift IO to Maybe or the other way?
08:02:40 <Solonarv> Transformers are one way, and probably what I'd use here
08:03:00 <Solonarv> (specifically, the "combined" applicative here will be MaybeT IO)
08:03:09 <slack1256> The other way is to do everything on IO (and de-structure the Maybe Int as a let/case).
08:03:25 <hasker> slack1256: Hmm. I'd like to avoid that
08:03:36 <ski>   f <$> MaybeT (fmap return blah) <*> lift bleh :: MaybeT IO Int  -|  blah :: Maybe Int , bleh :: IO Int
08:03:37 <Solonarv> :t \f maybeA ioB -> getCompose (liftA2 f (Compose (pure maybeA)) (Compose (pure <$> ioB)))
08:03:38 <lambdabot> error:
08:03:38 <lambdabot>     Variable not in scope: getCompose :: f2 c -> t
08:03:38 <lambdabot> error:
08:03:46 <Solonarv> @let import Data.Functor.Compose
08:03:48 <lambdabot>  Defined.
08:03:49 <Solonarv> :t \f maybeA ioB -> getCompose (liftA2 f (Compose (pure maybeA)) (Compose (pure <$> ioB)))
08:03:51 <lambdabot> (Applicative g, Applicative f) => (a1 -> b -> a2) -> g a1 -> f b -> f (g a2)
08:04:06 <slack1256> the two alternative are equally valid though
08:04:32 <Solonarv> ^ this works for any two applicatives, and you will get back a result in the composition of those two applicatves
08:05:15 <ski> (instead of `MaybeT (fmap return blah)', one could use `maybe mzero return blah', and instead of `lift' one could here use `liftIO')
08:05:53 <ski> @. hoogle type maybe mzero return
08:05:55 <lambdabot> Options.Applicative.Internal hoistMaybe :: MonadPlus m => Maybe a -> m a
08:05:55 <lambdabot> Control.Error.Safe justZ :: (MonadPlus m) => Maybe a -> m a
08:05:55 <lambdabot> Control.Monad.IfElse maybeMP :: MonadPlus m => Maybe a -> m a
08:06:02 <ski> @. hoogle type maybe empty pure
08:06:04 <lambdabot> Control.Applicative.Alternative afromMaybe :: Alternative f => Maybe a -> f a
08:06:04 <lambdabot> Control.Applicative optional :: Alternative f => f a -> f (Maybe a)
08:06:04 <lambdabot> Text.Parser.Combinators optional :: Alternative f => f a -> f (Maybe a)
08:06:23 <ski> oh, it's `afromMaybe'
08:07:18 <ski> (i wonder whether the laws (which ?) of `MonadPlus' would be preferable to those of `Alternative', since we're dealing with a monad (transformer) here, and so one might need to know about interactions with `(>>=)' ?)
08:08:05 <Solonarv> Alternative and MonadPlus seems to coincide so often that MonadPlus' operations default to the Alternative ones
08:08:07 <hasker> Thanks for all the info! I need to go wrap my head around it :o
08:08:26 <ski> hasker : do you want short-circuiting behaviour ?
08:08:37 <hasker> ski: Yes
08:09:09 <ski> (Solonarv's suggestion is different from mine. mine (i.e. using `MaybeT') would give short-circuiting)
08:10:00 <Solonarv> yeah, you have a choice in whether you go for Compose Maybe IO or Compose IO Maybe
08:10:13 <Solonarv> I think the first will get you short-circuiting but the second won't
08:10:36 <ski> well, at least if you then want to go on combining several `IO (Maybe T)'s, for various possibly different `T's, where each one could have been arrived at via Solonarv's thing
08:10:56 <ski> i suppose what Solonarv suggested didn't actually necessarily imply that, sorry
08:12:02 <ski> (i was thinking about the difference between the idiom `IO (Maybe T)', and the monad `MaybeT IO T' (which internally contains an action of the former type) (the latter being short-circuiting, the former not)
08:12:33 <phadej> ski: MaybeT IO a == IO (Maybe a)
08:12:43 <slack1256> not really
08:12:54 <ski>  the difference between `Maybe (IO T)' and `IO (Maybe T)' is a different difference. but yes, the former in this pair would also short-circuit. but not depending on run-time data arrived at via I/O execution, unlike `MaybeT IO T')
08:12:55 <slack1256> the (>>=) is different, which is the point ski is making
08:13:12 <ski> basically, yes
08:13:31 <phadej> i see
08:13:33 <ski> except monads don't compose. but you can compose the two idioms `IO' and `Maybe', getting a new idiom
08:14:04 <slack1256> That's a suprinsingly succint way to put it.
08:14:17 <ski> well, you can use the "distributive law" `sequence :: Maybe (IO a) -> IO (Maybe a)' to "impedance mismatch", giving a monad
08:14:41 <Solonarv> the fact that monads don't (in general) compose is indeed why monad transformers are a thng
08:14:57 <Solonarv> conversely, applicatives always compose, so there's no need for "applicative transformers"
08:15:23 <ski> (so that you can go from `IO (Maybe (IO (Maybe a)))' to `IO (IO (Maybe (Maybe a)))', to `IO (Maybe a)', as required for `join' (giving you `(>>=)', assuming `pure'/`return' and `fmap'))
08:15:34 <ski> yes
08:15:59 <Solonarv> (note that 'sequence' isn't the only operation you can use to compose monads; there's a paper about this)
08:16:09 <ski> and, indeed, i suppose doing it this way does short-circuit
08:16:29 <ski> i suppose that's equivalent to `MaybeT'
08:16:51 <ski> Solonarv : which paper are you thinking about ?
08:16:52 <Solonarv> the problem when composing monads 'M' and 'N' is that you need to write 'join :: M (N (M (N a))) -> M (N a)', which you can't do with only monad operations
08:17:01 <ski> right
08:17:03 <Solonarv> I don't recall the name, let me see if I can find it
08:17:41 <ski> hasker : long story short, you (afaict) want `MaybeT'
08:17:52 <Welkin> if I had a penny for every time I saw the title "Is $(random("wordlist.txt")) a monad?"
08:17:53 <Solonarv> Composing Monads <https://web.cecs.pdx.edu/~mpj/pubs/RR-1004.pdf>
08:18:38 <Welkin> moonads don't compose though
08:18:50 <Solonarv> Sometimes they do
08:18:58 <Solonarv> (in specific ways)
08:19:00 <Welkin> when they do, they choose dos equis
08:19:02 <maerwald> ski: do you have a nice example of the different short-circuiting behavior?
08:19:42 <Solonarv> for example, you can compose m . Maybe to get MaybeT m
08:20:09 <Solonarv> or ((->) e) . m to get ReaderT e m
08:20:20 <hasker> Just to make it easier on me, your discussion is beyond me right now, should I opt for MaybeT IO to get it working with short-circuit?
08:20:25 <Solonarv> yes
08:20:35 <hasker> Thanks :)
08:21:00 <hasker> And do I need to deep dive into MTL for this?
08:21:26 <Solonarv> no, in fact you don't even need mtl - just transformers :>
08:21:46 <Welkin> or autobots
08:21:55 <Welkin> if you feel dark, decepticons
08:22:10 <maerwald> use mtl
08:22:16 <maerwald> transformers are just painful :)
08:22:29 <Welkin> no maerwald, they are robots in disguise
08:22:31 <ski> maerwald : different ?
08:23:22 <Solonarv> I don't actually see anything Maybe-related in mtl's modules
08:23:22 <ski> maerwald : i think i was claiming it would be the same (for `MaybeT', vs. making a monad from the idiom `Compose IO Maybe', using `sequence' as distribution)
08:23:45 <hasker> Don't all the transformer types come from MTL package?
08:24:12 <reallymemorable> What am I doing wrong here?
08:24:13 <reallymemorable> https://paste.ofcode.org/5gMUw7WZSGtQnAidXUDpq4
08:24:18 <maerwald> ski: I was referring to MaybeT IO a == IO (Maybe a)
08:24:23 <owhit> I am happy. I just had like 7 haskell epiphanies in the last 30 minutes
08:24:24 <reallymemorable> I am trying to filter out to get a list of ages
08:24:30 <owhit> mistype lol
08:24:32 <Solonarv> the transformers themselves are defined in 'transformers', 'mtl' adds a bunch of type classes that make them much less painful to work with
08:25:10 <Solonarv> mtl also re-exports stuff from transformers
08:25:32 <hasker> Solonarv: Oh... I seee
08:26:19 <ski> maerwald : the different capabilities (not behaviour, you can't compare "apple" and "fruit" directly) would be for (monad) `MaybeT IO' vs. (idiom) `Compose Maybe IO' (`Compose IO Maybe' i believe i indicated can be made a monad, using `sequence', and that it would be equivalent to `MaybeT IO')
08:26:38 <hasker> I'll go fight GHC and see where it gets me
08:27:00 <ski> maerwald : well, i think i was saying that they'd not be different (if you use `sequence' to make the latter idiom, properly composed, into a monad)
08:27:12 <ski> Solonarv : ty
08:28:14 <Solonarv> although that Monad (Compose IO Maybe) instance wouldn't be compatible with the existing Applicative (Compose IO Maybe) instance
08:28:32 <Solonarv> because <*> ≠ ap
08:28:49 <Solonarv> (ap short-circuits, <*> doesn't)
08:28:51 <ski> Solonarv : ah, i remember seeing this at some point :)
08:29:06 <maerwald> ski: "the difference between `Maybe (IO T)' and `IO (Maybe T)' is a different difference. but yes, the former in this pair would also short-circuit." -- I was referring to that
08:30:08 <ski> (Solonarv : when you said "'sequence' isn't the only operation you can use to compose monads", i thought you meant a different operation (not being `sequence'), of the *same* type (for two specific functors))
08:30:37 <ski> maerwald : ah, ok. then they're comparable, directly
08:31:18 <Solonarv> oh, no - I was referring to the m (n (m a)) -> whatever operations from the paper
08:31:23 <Solonarv> although perhaps there are others
08:31:30 <ski> maerwald : with `Maybe (IO T)', you're, *maybe*, computing I/O-actions. only if you actually don't fail anywhere there, do you combine the I/O-actions. iow, possible failure happens before any I/O
08:33:12 <[exa]> Solonarv: which exact definition of `ap` were you referring to? (curious)
08:33:16 <ski> maerwald : while with `IO (Maybe T)', you're doing all the I/O, before attempting to execute the `Maybe' actions (which may fail). so failure can only happen after *all* the I/O here
08:33:54 <ski> maerwald : finally, with `MaybeT IO T', which internally contains `IO (Maybe T)' (and whose monad instance, i think, can be seen as derived for the composed idiom instance just above, using `sequence' as distributive law, as aforementioned), you do get an interleaving of possible failure and I/O, iow short-circuiting
08:34:07 <[exa]> Solonarv: oh there's now one in Control.Monad, got it now. Sorry :]
08:34:07 <Solonarv> the one in base: ap mf mx = do f <- mf; x <- mx; return (f x)
08:34:31 <ski> Solonarv : yea, i realized now, that i took a peek at the paper
08:35:33 <maerwald> ski: so MaybeT IO a is different from Maybe (IO a) and IO (Maybe a)
08:35:38 <ski> hm, i was pondering operations (natural transformations) like `m . n -> n' and `m . n -> m', at one time
08:35:55 <Solonarv> those would work too
08:37:01 <ski> e.g. `Reader rs . State rs -> Reader rs', `Maybe . [] -> Maybe', `[] . Const (Sum n) -> Const (Sum n)'
08:37:22 <Solonarv> although I don't know how often those exist when others (m . n -> n . m, m . n . m -> n . m, &c) don't
08:38:11 <ski> such would allow one to have variants of `(>>=)', of type `m a -> (a -> n b) -> n b',`m a -> (a -> n b) -> m b'
08:38:43 <Solonarv> hmm, interesting
08:40:40 <ski> actually, now i'm unsure if i got the middle example right, from memory
08:44:12 <ski> so, you could have an inclusion from `m' to `n', and a projection from `n' to `m'. or in the last case, only a projection, from `m' to `n'
08:44:22 <ski> (with obvious suggested coherence laws)
08:50:56 <habbah> how would I lift https://hackage.haskell.org/package/wai-3.2.1.2/docs/Network-Wai.html#t:Application into IO?
08:53:58 <habbah> or even how to lift https://hackage.haskell.org/package/wai-websockets-3.0.1.2/docs/Network-Wai-Handler-WebSockets.html#v:websocketsOr into IO
08:55:41 <marvin2> therećs nothing to lift, Application is a function that takes two arguments and returns IO ResponseReceived
08:57:01 <habbah> I put it in a do block initially thinking IO () should match with IO ResponseReceived and it tells me Expected type: IO () Actual type: Application
08:57:04 <marvin2> or, more precisely, Application is a type alias for such a function
08:57:32 <habbah> which is probably perfectly reasonable
08:59:00 <marvin2> actual code would be useful, but it sounds like you didn't apply app to req and respond
09:00:35 <habbah> the code is the example code for websocketsOr
09:00:41 <habbah> wrapped in a do block
09:01:24 <habbah> aha, maybe I need warp
09:02:40 <habbah> that compiles
09:03:25 <larryba> I'm doing something concurrently, and memory of my program grows to over two GB before throwing Out of memory exception. but if I print the downloaded data as I'm downloading it, it uses constant memory. do I need to use seq to get constant memory usage without printing? or maybe I should use strict data structure?
09:04:16 <dminuoso> habbah: Haskell requires you to explicitly throw things away. You could either follow it with `pure ()` or wrap the whole thing with `void`
09:05:18 <leshow> If you were writing a library that wraps around a unix socket, and you wanted to provide a stream of events from the socket, what would you use?
09:05:29 <leshow> I have a subscribe function that works, and I can get responses
09:05:43 <tdammers> I'd have the consumer provide a callback
09:05:52 <leshow> right, that would work
09:05:54 <dminuoso> leshow: Maybe use TQueue's?
09:06:02 <leshow> what about something like pipes
09:06:03 <tdammers> subscribe :: (SocketEvent -> IO ()) -> Socket -> IO () -- or some such
09:06:04 <leshow> or conduit
09:06:37 <tdammers> you could provide a TQueue API built on top of the callback API as well
09:07:16 <leshow> on top?
09:07:22 <leshow> or in addition to
09:15:12 <larryba> in what way is atomically $ x <- readTVar tvar; writeTVar tvar (updateX x)  better than an equivalent that uses locks around that block of code?
09:16:26 <Solonarv> you can forget to use locks, you can't forget to call 'atomically'
09:16:52 <Solonarv> and STM automatically tracks which TVars (etc) you've touched in a given transaction, so it can be much more granular
09:17:36 <larryba> you can do x <- readTVarIO tvar; atomically $ writeTVar tvar (update x).   while a bit more obvious that you made a mistake, it is still possible to do it
09:18:11 <Solonarv> of course
09:18:31 <dminuoso> larryba: The issue is not such mistakes.
09:18:45 <c_wraith> more generally, you can use atomically too many times.
09:18:59 <dminuoso> larryba: Locks tend to be very expensive when you overuse them (say protecting far more than you need to), and you get in so many deadlock issues.
09:19:00 <larryba> nested atomically don't deadlock?
09:19:07 <c_wraith> you can't nest them
09:19:10 <dminuoso> larryba: You cant nest atomically.
09:19:15 <larryba> oh, right
09:19:15 <c_wraith> the types don't work.
09:19:19 <larryba> yep
09:19:32 <larryba> good point
09:19:38 <Solonarv> well, you can with unsafePerformIO - and then you have a problem!
09:19:55 <dminuoso> (There's a reason unsafePerformIO contains the "unsafe" prefix)
09:19:57 <Solonarv> (IIRC you will simply get an exception, instead of wrong behavior)
09:20:04 <dminuoso> Yup.
09:20:17 <clever> dminuoso: there are worse functions!
09:20:27 <dminuoso> Solonarv: This is actually quite hilarious. If you use unsafePerformIO to newTVIO - and forget about lazyness.
09:20:29 <ski> didn't someone suggest nestable transactions (using a similar technique as nested threads/regions for `ST' ?) ?
09:20:32 <ski> (Oleg ?)
09:20:57 <c_wraith> there would certainly be utility in that
09:21:01 <dminuoso> Solonarv: The moment you use the tvar the thunk is evaluated and you end up with a nested transaction without it being clear.
09:21:03 <clever> dminuoso: https://github.com/haskell/bytestring/blob/master/Data/ByteString/Internal.hs#L564-L592
09:21:12 <dminuoso> clever: Yeah.
09:21:15 <larryba> dminuoso, what would happen?
09:21:39 <larryba> when you have a nested transaction
09:21:40 <larryba> deadlock?
09:21:45 <dminuoso> larryba: It lets you nest `atomically` effectively - which causes an exception.
09:21:49 <Solonarv> actually, that's why newTVarIO exists - unsafePerformIO (newTVarIO foo) seems to be safe in a transaction
09:21:53 <larryba> oh
09:22:09 <Solonarv> at least that's what its documentation suggests
09:22:13 <dminuoso> Solonarv: Oh must be confusing it with the other primitive.
09:22:17 <larryba> just plain top-level tvar <- unsafePerformIO $ newTVarIO ...  would cause that?
09:22:41 <Solonarv> it shouldn't
09:22:43 <dminuoso> Solonarv: Ohh right. `x = unsafePerformIO (atomically $ newTVar "foo")`
09:22:47 <dminuoso> this is bad. :-)
09:22:50 <Solonarv> yeah :D
09:22:57 <dminuoso> Unless you add some bangs.
09:23:00 <dminuoso> that is
09:23:07 <dminuoso> !x = unsafePerformIO (atomically $ newTVar "foo")
09:23:08 <dminuoso> Is fine
09:23:19 <dminuoso> But at that point you might as well just use newTVarIO
09:23:48 <Solonarv> top-level fooCell = unsafePerformIO (newWhateverMutableCell ...) is a reasonably safe pattern as long as you remember the {-# noinline fooCell #-} pragma
09:24:30 <larryba> Solonarv, even without the bang?
09:24:37 <larryba> I guess I'll test it
09:24:55 <Solonarv> I don't think bangs do anything on *top-level* bindings, if they're even allowed
09:31:22 <ski> what about unboxed value bindings ?
09:31:44 <ski> (like `(# a , b #) = ...')
09:31:51 <Solonarv> I have no idea!
09:34:11 <ski> hmm
09:34:17 <ski> > let (# a , b #) = undefined in ()
09:34:19 <lambdabot>  ()
09:34:23 <ski> > let (# a , b #) = undefined in a
09:34:25 <lambdabot>  mueval-core: GhcException "Error: bytecode compiler can't handle unboxed tup...
09:34:26 <lambdabot>  CallStack (from HasCallStack):
09:34:26 <lambdabot>    error, called at ./Mueval/Interpreter.hs:149:31 in main:Mueval.Interpreter
09:34:39 <ski> that's interesting, though
09:38:56 <Solonarv> %! echo -e '(# a, b #) = undefined\nmain = print 42' > slkfhl.hs
09:38:56 <yahb> Solonarv: 
09:39:24 <Solonarv> %! ghc -XUnboxedTuples slkfhl.hs -o slkfhl
09:39:24 <yahb> Solonarv: /var/lib/xsbot/sandbox/root/usr/lib/ghc-8.6.0.20180620/bin/ghc: error while loading shared libraries: libHShaskeline-0.7.4.2-ghc8.6.0.20180620.so: cannot open shared object file: No such file or directory
09:39:35 <Solonarv> aww :(
09:44:52 <hasker> Solonarv: I made it work by lifting the IO using 'lift' and the Maybe using 'MaybeT return', then used the <$><*> and finally 'runMaybeT' to get 'IO Maybe Int'. In the end I got 'IO (Maybe Int)'. Is this correct or am I off?
09:45:12 <Solonarv> no, that's correct
09:46:38 * hackage strongswan-sql 1.2.1.0 - Interface library for strongSwan SQL backend  https://hackage.haskell.org/package/strongswan-sql-1.2.1.0 (erick)
09:46:41 <hasker> Solonarv: So essentially, I lifted both monads into a common one, applied the function and then extracted the value back. Am I understanding correctly that the idea is to get all values into a common structure to operate on?
09:46:51 <Solonarv> exactly!
09:47:00 <hasker> Great, thank you!
09:50:30 <ski> hasker : good. yes
09:54:07 * hackage strongswan-sql 1.2.2.0 - Interface library for strongSwan SQL backend  https://hackage.haskell.org/package/strongswan-sql-1.2.2.0 (erick)
09:56:01 <ski> btw, there should be some class that relates a monad transformer `t' to its "untransformed variant" `m' (isomorphic to `t Identity'), via not the usual `lift :: Monad m => m a -> t m a', but via some isomorphism `climb :: 'Monad n => m a -> t n a' (being equivalent to `m a -> t Identity a', at least if `t' is an `MFunctor' (?)) & `deflate :: t Identity a -> m a' (being equivalent to `(forall n. Monad n => t n a) -> m a', same condition) ?
10:10:02 <Solonarv> well, most of the time the "untransformed variant" is *literally* just t Identity
10:10:13 <Solonarv> hm, perhaps not most
10:13:02 * ski . o O ( `MaybeT',`ExceptT e',.. )
10:59:46 <fendor> is TH on windows still broken with ghc 8.6.4? The release note suggest it
11:06:21 <Phyx-> fendor: no it's not, what makes you think it is? :)
11:06:35 <cocreature> iirc the release notes mention that this bug is fixed?
11:08:01 <Phyx-> to clarify, I meant, TH is no longer broken
11:08:32 <Phyx-> the bug that is now re-opened has to do with profiling libs when you have more than 16k of symbols
11:09:04 <Phyx-> err 65k* of symbols
11:10:25 <fendor> Phyx-, ah, then i misread the documentation
11:13:46 <LunarJetman> I wonder how long it will take me to implement Haskell.
11:17:00 <boj> one full cycle
11:37:49 <oo_miguel> I have a stack project inside some particular directory ~/foo that builds an executable.. I can run it with "stack exec" as long as I am inside this directory. How could I use this exe after I navigate somewhere else? It seems two foo-exe files have been generated (inisde ~/foo/.stack-work/install.. and ~/foo/.stack-work/dist..). Can I just run them directly or is this not recommended?
11:42:29 <Solonarv> that should work, use 'stack exec -- which your-exe' (from within your project) to get the path easily
11:45:08 * hackage wai-log 0.1.0.0 - A logging middleware for WAI applications  https://hackage.haskell.org/package/wai-log-0.1.0.0 (jonathanjouty_scrive)
11:51:21 <oo_miguel> Solonarv: ok thank you. It gave me the one inside the /install directory. Still curious what the other one is than.. 
11:54:07 <nefple[m]> Anyone recognize a law st: (a -> b) . id . (b -> c) == (a -> b) . (b -> c) in the context of category theory? basically identity transformations/mappings are necessarily reduceable/removeable? It's come up in this totally not really math-related thing and it's bugging me that it must be a concept from CT
11:56:57 <lyxia> that's part of the definition of a category     f . id = id . f = id
11:58:04 <day> im trying to find a function that does [Char] -> Maybe Float . But im not very successful
11:58:41 <delYsid> reads?
11:59:00 <Taneb> :t readMaybe
11:59:01 <lambdabot> error: Variable not in scope: readMaybe
11:59:03 <Taneb> :(
11:59:28 <day> oh that helped
12:00:17 <Solonarv> there are a few other variants of that in Text.Read
12:03:03 <ski> nefple[m] : hm, i suppose one way to view it is that the exponential functor applied to a pair of morphisms is a morphism between exponentials that sends the "name" of identity in the domain exponential to the name of the composition of the two morphisms :  `f0^f1  =  \g |-> f0 . g . f1'
12:03:17 <ski> not sure whether that's terribly useful/enlightening, though
12:08:45 <LunarJetman> I have no idea what that means.
12:09:47 <ski> (any suggestions for a better term than "name" here ?)
12:09:55 <Welkin> ski: thing
12:10:13 <LunarJetman> concept?
12:10:15 <ski> thank you, that's actually worse, i think
12:10:44 <Welkin> oh! I know
12:10:49 <Welkin> call it "bulbasaur"
12:10:55 <Welkin> send the bulbasaur
12:11:41 <Welkin> there's gotta be a pokemon language for use in math papers
12:11:47 <Welkin> and a programming language to go with it
12:12:08 <ski> category theory (or rather, any particular category, iow mathematical structure satisfying the categorical axioms. just like a group is any structure satisfying the group axioms) can be thought of as an *abstract* theory of *first-order* "functions". you work with abstract objects, which "behave like functions" in that you can compose them, associatively, and they have a (double-sided) identity
12:12:49 <ski> (unlike say lambda calculus, which inherently treats *higher-order* functions, but pointfully)
12:14:05 <ski> category theory does not (properly) speak about elements, such as inputs and outputs to these "functions". it just talks about how different compositions of them contrast and compare to each other. so it's "pointless" (aka "pointfree"), not "pointful" (which is what lambda calculus is)
12:15:02 <Welkin> so then what is a "pointy functor"?
12:15:06 <ski> to express / talk about higher-order functions, in CT, you have to talk about "exponential objects", which you can think of as types which has "functions" as "elements"
12:16:00 <LunarJetman> hopefully I can ignore most of this when implementing Haskell.
12:16:06 <Welkin> yes
12:16:13 <ski> in general CT, a morphism has a source/domain ("argument type", singular), and a target/domain ("result type"). but a set of (say all) morphisms between two such objects ("types") is not itself automatically an object ("type")
12:16:16 <Welkin> well mostly
12:16:25 <Welkin> just don't drink the koolaid
12:16:44 <ski> exponentials allow you you regard it as an object, and thus to express higher-order "functions"
12:18:36 <geekosaur> LunarJetman, CT gives you more ways to express things in Haskell, but isn't itself required to implement Haskell.
12:18:45 <ski> LunarJetman : yes, what i say here is mostly for the closest mourning people. don't bother about it, if you don't care. you don't need to know about this to use Haskell effectively. at some point, at least if you're a bit mathematically inclined, you might want to look up a *little* of it, if you're curious. or not. but it's not exactly suggested material
12:19:10 <ski> (well, what i say on this topic, right now, i mean)
12:19:47 <Welkin> you can safely treat haskell like a typed lambda calculus and leave it at that
12:20:53 <geekosaur> even Monad boils down to syntax and a couple of simple rules, and CT only comes into it if you want to understand where it came from and/or clever ways to make use of it.
12:21:07 <ski> in CT. one'd not say `null :: [a] -> Bool', but `null_a : [a] >---> Bool'. one can't say `filter_a : (a >---> Bool) >---> ([a] >---> [a])', though, that's nonsense. you can't nest the morphism arrow `>--->'
12:21:52 <ski> if one has exponentials (written with a double arrow `=>', say). one could say `filter_a : (a => Bool) >---> ([a] => [a])', though
12:22:28 <ski> or, a tupled (aka uncurried) version, `tupled-filter_a : (a => Bool) * [a] >---> [a]'
12:23:07 <day> http://dpaste.com/2SS2QBK how would one make this 'non explosive' ? The [String] comes from a file and could potentially be non conform to what the function expects (if the user were malicious)
12:24:11 <day> like in C i would check if there actually are 6 fields, then check if those fields actually translate to reasonable values etc.
12:24:15 <lyxia> day: pattern-match on a
12:24:30 <day> and then return a maybe [Card] ?
12:24:35 <ski> (also `A => B' would often be written like `B^A' in CT (or math in general), since the number of functions from a finite set `A' (with `m' elements, write `| A | = m') to a finite set `B' (with `n' elements, `| B | = n'), is `n^m', so that `| B^A |  =  |B| ^ |A|')
12:24:46 <lyxia> day: yes
12:24:59 <larryba> what is the difference between withMVar and withMVarMasked? documentation says "Like withMVar, but the IO action in the second argument is executed with asynchronous exceptions masked.", but I don't understand what "executed with asynchronous exception masked" means
12:25:30 <clever> larryba: things like throwTo cant be used to force an exception in that remote thread, i believe
12:26:12 <larryba> when would that be desirable?
12:26:13 <ski> larryba : asynchronous exception aren't allowed to interrupt the execution of the second action (unless if/when temporarily unmasked in the middle, iirc)
12:26:43 <sternmull> could someone could point me how to build with stack so i get stacktraces for unhandled exceptions? I remember there was a way to activate this for all toplevel functions... i think with profiling enabled.
12:28:57 <larryba> specifically, should I be using modifyMVar or modifyMVarMasked in here? (and are there any issues with this function when called in parallel?) https://bpaste.net/show/e9d8fabf9eeb
12:30:45 <ski> anyway .. i was thinking maybe nefple[m]'s question could be related to dinatural transformations between some particular difunctors (same concept as profunctors ??). thinking a little about it, you don't seem to get that kind of equation with ends/coends (or generally wedges/cowedges). i suppose the other generally interesting special case of difunctors would be from a covariant to contravariant functor, or vice versa ..
12:31:57 <LunarJetman> oh dibblego is here; I used to argue with dibblego about "state".
12:32:29 <cocreature> sternmull: compile with --profile and run with +RTS -xc
12:32:34 <LunarJetman> he used to say state doesn't exist and I argued the opposite; these were not constructuve arguments.
12:34:05 <sternmull> cocreature: I found out about the "build" section in stack.yaml and "library-profiling" and "executable-profiling". Is that the right way to activate it permanently? What does "library-profiling" apply to? Only my libs or all dependencies?
12:34:25 <cocreature> I wouldn’t recommend enabling it permanently
12:34:33 <ski> (.. consider e.g. the covariant powerset functor `P', and the contravariant powerset functor `Q' being `X |-> Omega^X', iow `X |-> (X => Omega)' (`Omega' being subobject classifier, "object of truth-values", `2' in `Set'). then a divariant transf. from `P' to `Q' amounts to `X * P X >---> Omega', iow the membership relation, while in the other direction would be `(X => Omega) >---> P X', which looks like comprehension to me)
12:34:36 <cocreature> it slows down compilation and slows down your code
12:34:51 <geekosaur> larryba, the point is that an exception at the wrong time can cause resource leaks including memory, filehandles, etc. You use masking to establish critical areas that can't be interrupted between allocating a resource and recording it so it can be cleaned up 
12:35:08 <sternmull> cocreature: Hm, i am very interested in useful stacktraces for unhandled exceptions. At least for my code. Performance is not so important.
12:35:56 <ski> LunarJetman : whether it exists or not can be thought of as a matter of POV (of which language "level" you currently reason at. "reason" being a key term. "what really happens", not so much)
12:36:32 <ski> (in categorical terms, you can pass from a category, with a monad on it, to the corresponding Kleisli category)
12:36:55 <Welkin> LunarJetman: on the separation of Church and state?
12:37:10 <cocreature> sternmull: I’d still stick to passing --profile personally but if you add both library-profiling and executable-profiling your own libs and your deps should be compiled with profiling info
12:37:35 <larryba> geekosaur, ok. I'm not doing any manual clean ups, so modifyMVar  should be good enough I guess
12:37:37 <ski> @quote separation
12:37:37 <lambdabot> GuySteele says: Some people prefer not to commingle the functional, lambda-calculus part of a language with the parts that do side effects. It seems they believe in the separation of Church and
12:37:37 <lambdabot> state.
12:37:41 <cocreature> you can’t just compile your own libs with profiling info. it requires recompiling everything
12:37:55 <ski> @quote is.no.state
12:37:55 <lambdabot> MonadState says: Do not try to change the state; that's impossible. Instead only try to realize the truth: There is no state.
12:38:25 <LunarJetman> Welkin: that is something different and as a militant atheist I am all for it
12:38:34 <Welkin> LunarJetman: I think you missed the joke
12:38:40 <LunarJetman> (and anti-theist)
12:38:41 <sternmull> cocreature: thanks. Not really satisfying but at least now i know what i can do.
12:39:04 <Welkin> (Alonzo) Church and (mutable) state
12:39:24 <LunarJetman> I do not know who Alonzo Church is hence why I didn't get the joke
12:39:43 <Welkin> LunarJetman: blasphemy! Heretic! You'll be burned at the stake!
12:39:51 <ski> Church invented the lambda calculus model of computation, on which functional languages, like Haskell, are based on
12:40:06 <Welkin> genuflect before our lord and master Church, father of the holy lambda calculus
12:40:41 <LunarJetman> hopefully not knowing who Alonzo Church is is not an impediment to me implementing Haskell
12:41:11 <Welkin> why do you keep saying "implementing"?
12:41:15 <Welkin> don't you mean "using"?
12:41:22 <LunarJetman> no I mean implementing
12:41:23 <Welkin> you aren't writing a haskell compiler after all
12:41:32 <Welkin> you are?
12:41:40 <Welkin> well, have fun for the next 10 years
12:41:47 <LunarJetman> I am writing a universal compiler that can compile any programming language including Haskell
12:41:55 <Welkin> that sounds like nonsense
12:41:57 <ski> (lambda calculus can be thought of (alongside, typically, Turing machines), as a prototypical, minimal, "full-power" programming language. and these things were invented before computers ! (not counting Babbage) in fact, i've heard it argued that computers partly came into be, because of these first mathematical/logical/philosophical steps)
12:42:01 <LunarJetman> well it isn't
12:42:16 <Welkin> you mean a collection of compilers bundled together with some scripts
12:42:20 <LunarJetman> no
12:42:25 <Welkin> like the gnu compiler collection
12:42:28 <LunarJetman> no
12:42:44 <Welkin> well that sounds absurd
12:42:49 <LunarJetman> well it isn't
12:42:54 <boj> kind of reminds me of young kids writing an MMO as their first game
12:43:03 <ski> Welkin : apparently <https://neos.dev/>
12:43:36 <Welkin> what is the point??
12:43:37 <Dr8128> why would anyone want a compiler for every language? i only want to use the best language
12:43:42 <Welkin> just use the compilers that exist
12:43:44 <Dr8128> because i deserve only the best
12:44:06 * ski . o O ( "Let's Build a Compiler" by Jack Crenshaw in 1988-1995 at <https://compilers.iecc.com/crenshaw/> )
12:44:07 <LunarJetman> Welkin: NIH.
12:44:18 <tdammers> so how is that going to work
12:44:32 <ski> you say that as if it's a badge of honor :)
12:44:38 <LunarJetman> it is.
12:44:41 <Welkin> if you are going to write a compiler, invent your own language
12:45:05 <LunarJetman> I already have that tee shirt
12:45:09 <LunarJetman> this is next level shit
12:46:11 <dashkal> Reinvent ALL the wheels!
12:46:30 <LunarJetman> you see the thing is lots of people already have their favourite languages and wouldn't want to use mine ergo my compiler must be able to compile all the things
12:46:38 <tdammers> seriously, how is a "universal compiler" going to work? what does the architecture look like? how does it know how to deal with a given language? do you plug in language definitions somehow?
12:47:22 <LunarJetman> tdammers: https://neos.dev
12:48:19 <Welkin> LunarJetman: no one will use your compiler anyway
12:48:35 <Welkin> so there isn't a difference
12:49:01 <LunarJetman> so? it is only a separate project because it makes sense to be one; it will primarily will be used by neoGFX https://neogfx.org
12:49:14 <tdammers> oh. so it's really more like a framework for building compilers, except that you call the compiler source code a "language schema"
12:50:11 <Welkin> instead of bolting something on to c++, why not write a language that isn't broken and suits the domain better?
12:50:29 <LunarJetman> the domain is all the things
12:50:40 <Welkin> you have a "universal compiler" for what is ultimately a c++ library?
12:50:57 <Welkin> I can't take this seriously
12:51:06 <Welkin> I can't tell if it's a joke, but it seems like it
12:51:25 <tdammers> https://github.com/i42output/neos/blob/master/languages/C.neos so this is the "language schema" for C?
12:51:34 <LunarJetman> think Unity but rather than just having one scripting language (C#) you can use your favourite
12:51:44 <LunarJetman> tdammers: the Ada scheme has more stuff in it
12:51:49 <tdammers> is that all of it, or are there additional schema files to define the C programming language?
12:51:55 <LunarJetman> I have only just started this project
12:52:07 <tdammers> because I don't see how this is anywhere near defining C's syntax, let alone semantics
12:52:27 * ski . o O ( "Languages and Machines" in 2011-03-22 at <https://web.archive.org/web/20110322154536/http://existentialtype.wordpress.com/2011/03/16/languages-and-machines>;"The Holy Trinity" in 2011-04-06 at <https://web.archive.org/web/20110406161551/http://existentialtype.wordpress.com/2011/03/27/the-holy-trinity>, both by Robert Harper (also cf. <https://ncatlab.org/nlab/show/computational+trinitarianism>) )
12:53:00 <LunarJetman> the C.neos I knocked up in a few minutes just to show someone how I would handle a particular ambiguity in C
12:53:02 <tdammers> I mean, this looks like a subset of a grammar for a C parser, written in a slightly awkward format, with a tiny bit of metadata added to it
12:53:09 <Welkin> if you said you were building something like this, it would make sense https://haxe.org/
12:53:17 <LunarJetman> it is nowhere near complete; as I said the Ada one has more stuff in it
12:53:31 <tdammers> OK, so the Ada one is complete?
12:53:38 <Welkin> but what you describe is totally backwards
12:53:39 <LunarJetman> no it is nowhere near complete
12:53:42 <tdammers> oh
12:53:47 <tdammers> so it doesn't actually work yet
12:53:50 <LunarJetman> as I said I have only just started this project
12:54:07 <spew> this whole thing is so patently ridiculous any more discussion of it is indistinguishable from troll feeding
12:54:14 <tdammers> oh right, that's why you have a fancy .dev domain registered and all
12:54:37 <tdammers> I must admit I was genuinely curious until I started looking at the actual code
12:55:01 <spew> tdammers: you just needed to wait to let your disappointment catch up to you
12:55:04 <MarcelineVQ> There's no need to be overly negative about this, it'll go somewhere or it won't.
12:55:10 <MarcelineVQ> LunarJetman: Be sure to ask questions here about the haskell part as you run into problems
12:55:12 <LunarJetman> thanks MarcelineVQ
12:55:19 <larryba> agreed, I'm not sure what is up with all the negativity
12:55:38 <tdammers> OK, let me rephrase my criticism in a less sarcastic way
12:55:49 <Welkin> sorry, I'm not trying to be negative, just realistic
12:56:07 <Welkin> I'm genuinely shocked at the proposition
12:56:10 <tdammers> so far, implementing a compiler for a programming language has always been a fairly intricate, complex, and tedious task
12:56:40 <LunarJetman> and I am making that task less tedious by using an easy to write schema language (in RJSON)
12:56:50 <tdammers> decades of research have been sunk into the topic, with mind-blowing results, but the bottom line is that it's still a pretty damn tedious thing
12:57:06 <tdammers> and the reason for that is not lack of a convenient schema language
12:57:09 <tdammers> we have plenty of those
12:57:37 <LunarJetman> ORLY? One that can represent both syntax AND semantic concepts?
12:57:43 <tdammers> we also have a fair amount of building blocks; Haskell itself is a pretty good toolbox for building compilers
12:57:54 <MarcelineVQ> ski: https://ncatlab.org/nlab/show/computational+trinitarianism that's a pretty neat page
12:58:08 <tdammers> so, trivially yes.
12:58:13 <MarcelineVQ> really lets you know what you need to know to know about the stuff you want to know to know
12:58:44 <tdammers> but let's suppose you come up with such a schema language, and it is expressive enough to capture all the nuances that are necessary to accurately implement all those language
12:59:15 <LunarJetman> the schema language is only part of the solution
12:59:16 <cocreature> LunarJetman: your examples seem to focus very heavily on syntax rather than semantics. I would recommend that you pick some very simple language and try to implement that fully before you start moving on to supporting 10 different, quite complex and large languages.
12:59:23 <LunarJetman> there are also semantic concept libraries
12:59:36 <tdammers> I propose the hypothesis that if and when you come up with such a schema language, and all the infrastructure to support it, it will be approximately as difficult to use as what is currently available
13:00:02 <LunarJetman> cocreature: I am starting with Ada precisely because it is a tricky language
13:00:37 <LunarJetman> I hope to have sufficient infrastructure in place this weekend to do an Ada Hello, world to stdout
13:00:38 <ski> MarcelineVQ : *nod*
13:00:50 <tdammers> or, in different words, the "schema language" you are planning to build is going to be just as complex as a typical general-purpose language as we know them today
13:01:04 <LunarJetman> not at all
13:01:08 <cocreature> looking forward to seeing it in action :)
13:01:24 <tdammers> it's a hypothesis. prove me wrong.
13:01:50 <LunarJetman> one does not prove a hypothesis nevermind a theory (modulo mathematical theories)
13:02:03 <cocreature> so far your examples seem to be half-finished parsers of C and Ada so people are understandably sceptical that you can pull this off.
13:02:18 <ski> MarcelineVQ : "Physics, Topology, Logic and Computation: A Rosetta Stone" by John Baez,Mike Stay in 2011 at <https://arxiv.org/abs/0903.0340> is also neat
13:02:25 <Welkin> regarding people who use the word "one" when they really mean "you"...
13:02:42 <dibblego> ski: that's definitely not what the argument was :)
13:02:57 <dibblego> (I have logs)
13:03:56 <LunarJetman> cocreature: the biggest task is not the languages themselves but their standard libraries
13:04:01 <ski> dibblego : hm, which argument ?
13:04:16 <LunarJetman> an argument from a decade ago on DALnet
13:04:22 <tdammers> I'll happily settle for just the languages
13:04:56 <tdammers> at least for Haskell, you could take most, if not all, of the standard libraries from the existing implementation
13:05:04 <dibblego> ski: the argument was the usual, "state is inherently mutable"
13:05:08 <MarcelineVQ> ski: I feel like things like that are only going to get more relevant as reversible computation gains traction. that is, tying ideas from physics and tolopology directly to computation
13:05:34 <Welkin> MarcelineVQ: joe armstrong talks about physics a lot when he talks about erlang and concurrency
13:06:20 <ski> dibblego : oh, you're saying it wasn't an accurate portrayal of your position
13:06:33 <dibblego> ski: correct, it's not even close :)
13:07:06 * ski doesn't even recall the argument, probably never saw it
13:07:16 <LunarJetman> it was a decade ago on DALnet
13:07:25 <ski> (ok, that too :)
13:07:30 <dibblego> ski: it occurred elsewhere
13:07:44 <Welkin> dibblego and LunarJetman had this argument 10 years ago on DALnet?
13:07:53 <ski> (i was around then, but not on DALnet)
13:07:58 <LunarJetman> I hope your health problems have been resolved dibblego
13:08:01 <Welkin> ski: you were on EFnet
13:08:04 <dibblego> LunarJetman: mostly, thanks
13:08:47 <ski> (Welkin : hm, possibly for some minor channel. mostly i was on Freenode (formerly OpenProjects), though)
13:09:48 <ski> MarcelineVQ : hm, interesting that you mention reversible computation. elaborate on that connection ?
13:12:31 <MarcelineVQ> Just that it's inherently something tied to the physical world, reversible computation allows (and/or requires depending on the angle you're approaching from) not losing the energy expended on a computation. Typically lost as heat.
13:13:08 <MarcelineVQ> So the more ideas you can tie in from physics the better position you're going to be in to reason and make connections in that direction
13:14:57 <ski> i recall reading about having to do work to forget information (cf. Garbage Collection)
13:15:52 <MarcelineVQ> I don't know much more about it than that but it's a subject that comes up every once in awhile in ##dependent
13:20:13 <ski> ("Thermodynamics and Garbage Collection" by Henry G. Baker in 1994-04 at <https://web.archive.org/web/20180704171416/http://home.pipeline.com/~hbaker1/ThermoGC.html>)
13:24:21 <ski> (also i recall seeing "Lively Linear Lisp -- 'Look Ma, No Garbage!'" by ibid in 199[12] at <https://web.archive.org/web/20190123062937/http://home.pipeline.com/%7Ehbaker1/LinearLisp.html>)
13:24:36 <larryba>  how can I avoid all this boilerplate and code repetition? https://bpaste.net/show/4b498fa8b48d
13:25:23 <zachk> zeroing bits in memory generates quite a bit of heat 
13:25:35 <ski> MarcelineVQ : and there was some other (more recent) reversible/symmetric combinator language paper (or draft, i think), with corresponding "string driagrams", that i can't find atm ..
13:26:08 <phadej> larryba: short answer, don't try if it write once, use a lot - code
13:26:14 <phadej> it's*
13:27:10 <Welkin> dryadgrams
13:27:46 <larryba> enumerator2 reusing enumerator3 (and so on), with properly placed undefined, comes to mind
13:27:53 * ski just found "Reversible and Quantum Computing" (Amr Sabry, mentioning Toffoli and Girard) at <https://www.cs.indiana.edu/~sabry/teaching/b629/s11/>
13:28:21 <larryba> or making something similar to <$> <*>, but I'm not sure how I'd do that (or if it is even possible)
13:31:09 <ski> (istr reading about cnot (controlled-not), and Toffoli gate somwhere, can't recall where. perhaps in relation to linear logic ?)
13:34:49 <larryba> phadej, I did not understand your suggestion, but I ended up with this. https://bpaste.net/show/1803bddf57a1
13:35:58 <ski> larryba : hm, not an answer, but i suppose i would pass in an explicit update function, to generalize away from `Integral'
13:36:33 <larryba> that's a good idea
13:36:36 <ski> i'm reminded of the "monad tunneling" discussion on the mailing list, years ago (i don't have a handy link atm)
13:37:16 <phadej> larryba: use (), no undefined
13:37:36 <phadej> there's really no need for undefined
13:38:10 <larryba> yes
13:41:55 <ski> hm, perhaps if you had a type class like `class (MonadTrans t,Monad m) => MonadTunnelBlah m t where tunnelBlah :: (m a -> m b) -> (t m a -> t m b)' (is this even reasonable ? i don't recall the verdict, or even the general formulation, in the discussion ?)
13:42:22 <Solonarv> MFunctor?
13:42:33 <Solonarv> @hackage mmorph
13:42:33 <lambdabot> http://hackage.haskell.org/package/mmorph
13:42:59 <ski> no, that'd be `(Monad m,Monad n) => (forall a. m a -> n a) -> (forall a. t m a -> t n a)', iirc ?
13:43:32 <ski> (though perhaps i'd still need higher-rank, not sure)
13:43:33 <Solonarv> hm, it's not *exactly* the same thing indeed
13:44:07 <ski> it's sortof somewhat "orthogonal", in the meaning "varying in an orthogonal direction"
13:44:39 <ski> (like cutting a rectangle either horizontally or vertically. or say vertical vs. horizontal composition in a 2-category. these are only very rough analogies)
13:45:07 <LunarJetman> analogy: (a)theism is orthogonal to (a)gnosticism 
13:45:40 <Solonarv> I'm wondering what instances of this MonadTunnel would look like
13:45:51 <ski> (not that i can ever recall which is vertical and which is horizontal composition .. ;)
13:46:22 <ski> the main idea is for `t' being `ReaderT rho' (in larryba's case), and `m' probably being an instance of `MonadIO'
13:46:56 <ski> so something like `instance MonadIO m => MonadTunnelBlah m (ReaderT rho) where ..', is what i had in mind
13:47:12 <ski> `ReaderT rho' would be used to add extra arguments
13:47:28 <ski> (or that's the idea, anyway. i dunno if it works out)
13:48:22 <larryba> should I give it a different name with Integral i => i  changed to i -> (i -> i)?
13:48:40 <ski> (hm, or maybe one'd not need `MonadIO' for this part ? i think this part wouldn't handle larryba's state `i', which was the motivation for the `IO' anyway)
13:48:41 <Aleksejs> hello, how can I write to a named pipe with 700 permissions via runhaskell?
13:49:28 <ski> larryba : what you're doing is keeping a count of how many times you've invoked the (parameterized) action
13:50:18 <larryba> ski, right. but with a more general type it could be used for other things
13:50:34 * ski . o O ( `tabulate :: (Array ar,Ix i) => (i,i) -> (i -> e) -> ar i e' )
13:50:53 <ski> yea, s/increment count/update state/
13:51:27 <larryba> silly example:  e <- makeEnumerator0 "hi" (++"!") (\i -> printf "%s\n" i)
13:51:33 <Solonarv> you don't actually need an MVar for this, btw
13:51:51 <ski> so you're "secretly" passing a local count around in the computation (cf. local state in stream processors, e.g. Fudgets)
13:51:56 <Solonarv> oh wait, you do
13:52:05 <ski> they need some kind of mutable state
13:52:07 <larryba> Solonarv, I wanted to make it thread safe. I'm not sure if I actually accomplished that, I have yet to test it concurrently
13:52:17 <Solonarv> yeah I had misunderstood what you were trying to do
13:52:54 <ski> perhaps the body of the `modifyMVar' calls ought to have some checks about reentrancy ?
13:53:28 <larryba> how would I do that? this is the first time I'm using MVar
13:54:51 <ski> (similar to comparable issues for caching of lazy thunk results, when forcing. see e.g. SRFI 45 : "Primitives for Expressing Iterative Lazy Algorithms" by André van Tonder in 2003-09-20 - 2004-08-04 at <https://srfi.schemers.org/srfi-45/srfi-45.html>)
13:55:13 <Solonarv> yeah, modifyMVar "is only atomic if there are no other producers for this MVar"
13:55:22 <Solonarv> note that modifyMVar is itself a "producer"
13:56:15 <Solonarv> ...ah, but I think you're still fine as long as you never use a standalone putMVar (which you don't)
13:57:24 <Welkin> Producer and Consumer sounds too capitalistic for me
13:57:46 <Welkin> also see the Streaming library
13:57:59 <larryba> seems to work. https://bpaste.net/show/ce777da6b4a2
13:58:09 <Solonarv> also, using your implementation you can only ever have one copy of the action running
13:58:21 <ski> larryba : well, i'm not sure whether this is what you want to do (or if you perhaps want to ignore/forget about the issue), but the idea would be something like (a) replace the `MVar' contents with a "black hole" marker just before invoking the action; (b0) afterwards, check (iirc ?) that it's still a black hole, before updating with the new value. or maybe instead (b1) check that it's not a black hole before (a). in any case, if these conditions are violat
13:58:23 <larryba> I tested it in ghci, so not really running in parallel, if that matters
13:58:41 <ski> (er, possible cut off near ".. in any case, if these conditions are violated, something weird may be happening, that you need to handle in some way, perhaps by an exception ?")
13:59:08 <Welkin> this is the problem with haskell concurrency: shared state
13:59:15 <Solonarv> I'm pretty sure this code actually works fine as is
13:59:50 <ski> larryba : the general question is : what, during the time the action is executed, the same action resulting from the current call to `enumerateN' is executed again ? which update is to win, in the end ?
14:00:17 <Solonarv> answer: the second one blocks until the first one is finished
14:00:41 <larryba> that was my understanding
14:00:46 <Solonarv> because each action is basically: do i <- takeMVar var; innerAction; putMVar (var+1)
14:00:49 <ski> (in this case, the second one occurs inside the call to the first)
14:01:09 <larryba> ski, you mean if multiple threads are executing the same enumerator?
14:01:13 <larryba> the same e
14:01:16 <ski> no, the same thread
14:01:32 <Solonarv> oh yeah, that'll deadlock
14:02:34 <larryba> not sure I understand. can you give an example?
14:02:34 <ski> i mean if you have a recursive action `weird = enumerate0 update start (\state -> ..weird..)', where the "body action" uses the same `weird' action that is currently being defined (and so will access the same `MVar')
14:02:53 <Solonarv> yeah this only happens if an enumerator calls itself
14:02:54 <Welkin> larryba: 2 threads both try to take the mvar and no one writes to it
14:02:57 <Solonarv> so dont't do that
14:03:00 <larryba> ski, oh
14:03:19 <Welkin> not only is mutable state evil, shared state is evil
14:03:49 <Solonarv> actually it's the same thread, not two threads
14:04:17 <Solonarv> if there are two threads there's no problem: the second one simply blocks until the first one is finished and puts (i+1) into the mvar
14:04:21 <ski> yea, "Don't do that" is a fine answer. i'm just saying that you should at least spend a minimal amount of thought to decide whether you want to figure out some kind of sanish behavior (or exception-raising) in this kind of situation, or if you just want to have as a precondition for the user "don't do that !"
14:04:21 <Welkin> on top of that, all operations on mvars are synchronous instead of asynchronous
14:05:46 <ski> (and your docs should say which decision you came up with, even the minimal conservative one "don't do that (perhaps it'll be supported in the future ?)")
14:06:11 <ski> (hm, or is that incomparable to "don't ever do that !")
14:07:02 <larryba> I did not imagine such a use case. but I think exception would be better than a deadlock
14:07:16 <Welkin> the only safeguard against catastrophe being a note that reads "don't do this" is just asking for trouble
14:07:17 * ski wonders whether the local state in stream processors (which is more sane), could somehow be used as inspiration here
14:07:21 <Welkin> an invitation to disaster
14:07:33 <Solonarv> another option is to modify the MVar and *then* run the inner action with the value you got
14:07:38 <ski> Welkin : well, sure
14:07:49 <Solonarv> i.e. do i <- takeMVar var; putMvar var (i+1); innerAction i
14:07:56 <Solonarv> Now there's no problem.
14:08:06 <Welkin> don't use takeMVar
14:08:09 <Welkin> use readMVar
14:08:10 <Welkin> anyway
14:08:15 <Welkin> it's take/put
14:08:21 <larryba> Solonarv couldn't that cause other issues? numbers not being incremented sequentially, repeated numbers, etc
14:09:01 <Solonarv> Welkin: readMVar var puts the value back, so readMVar var >> putMVar var foo will block forever
14:09:08 <ski> larryba : shouldn't be a problem, if you disregard reentrancy problems like i stated (or versions that'd execute in multiple threads)
14:09:22 <Welkin> what you should do instead is have a queue of actions (x -> x + 1) that get applied to some data that is wholly owned by a single thread
14:09:27 <Welkin> you push operations on the queue
14:09:32 <Welkin> but you don't directly modify this state
14:09:34 <Welkin> the thread owns it
14:09:37 <Welkin> don't store the state in the mvar
14:09:44 <Welkin> pass a "message" to the thread instead
14:09:49 <larryba> I plan to execute returned action in multiple threads
14:10:11 <Welkin> look into cloud haskell
14:10:27 <Welkin> if you want some semblance of sane concurrency
14:10:32 <ski> hmm .. would it help any to have a commutative monoid acting on the state ?
14:10:44 <Welkin> ski: CRDTs?
14:10:55 <ski> what's that, you say ?
14:10:59 <Welkin> there are many implementations of that
14:11:02 <Welkin> not sure about in haskell
14:11:09 <Welkin> conflict-free replicated datatypes
14:11:32 <ski> (i'm sure it doesn't stand for "Carucated Reglair Disbursable Towel" ..)
14:13:06 * ski was thinking of something reminiscent of (ordinary) commutative geometry, where addition of vectors in commutative
14:13:16 <ski> (as opposed to non-commutative geometry)
14:13:46 <Welkin> well yes, CRDTs are actualy commutative/convergent replicated data types
14:15:25 <ski> (points being states, and vectors being state updates. so given any two states, there'd, at least conceptually, be a vector from one to the other, that you can then apply ("add") to any other state, getting a fourth point (cf. familiar parallelogram diagram for vector addition). also cf. "transitive monoid/group action")
14:15:53 <Solonarv> amusingly enough, IORefs might be easier here: do ref <- newIORef start; pure $ atomicModifyIORef' ref (\i -> (i+1, i)) >>= innerAction
14:16:34 <Welkin> Solonarv: the worst of both worls, mutable *and* shared
14:16:50 <ski> Welkin : related to `LVar's ?
14:16:56 <ski> @hackage lvish
14:16:56 <lambdabot> http://hackage.haskell.org/package/lvish
14:16:58 <Welkin> what are those?
14:17:19 <Welkin> that looks like append-only data structures
14:17:46 <nshepperd1> Calling user supplied code under lock is kind of unavoidably dangerous
14:17:56 <Welkin> CRDTs are implemented in Riak and Redis, and there is a library for erlang
14:18:21 <ski> "LVars: lattice-based data structures for deterministic parallelism" by Lindsey Kuper (lkuper),Ryan R. Newton in 2013-09-23 at <https://dl.acm.org/citation.cfm?id=2502326>
14:18:25 <Welkin> pretty much, an append-only list, a set, map, and counter
14:18:27 <Solonarv> nshepperd1: hence my suggestion to do everything-involving-the-lock first, and only then run the user code
14:18:50 <nshepperd1> The magic of STM is it does what locks do but composable
14:19:09 <Welkin> even better, remove the need for locks
14:19:32 <ski> Solonarv : well. what if you (sometimes) execute the `weird' action more than once, in the body ?
14:19:48 * ski ponders
14:19:58 <ski> i suppose it'd work out as well
14:19:59 <Solonarv> I don't see a problem there, the counter will simply get incremented multiple times
14:20:06 <nshepperd1> Solonarv: yeah, if that works for your case it's good
14:20:13 <larryba> Solonarv, as I mentioned before, that won't ensure sequential enumeration if e is ran concurrently
14:20:26 <Solonarv> what does "sequential" even mean in that case?
14:20:48 <larryba> see https://bpaste.net/show/ce777da6b4a2
14:20:50 <ski> (yeah, you could always run `forkIO' (on an action involving `weird') inside the body, since you have access to full `IO')
14:21:33 <Solonarv> yes? that's still enforced (keep in mind that we're talking about an enumerator that calls itself)
14:21:53 <Solonarv> (which your example doesn't do)
14:22:15 <larryba> ah, ok. I'm not particularly worried about that user case (except maybe throwing an exception to prevent it, if I can figure out how)
14:22:31 <larryba> use case*
14:22:40 <Solonarv> does it *need* to be prevented?
14:22:52 <ski> larryba : btw, perhaps it could be called something like `withLocalState :: (s -> s) -> s -> (s -> IO a) -> IO (IO a)' (or perhaps `(s -> s) -> (s -> IO a) -> (s -> IO (IO a))' is sometimes a nicer ordering ?)
14:22:53 <larryba> I'd prefer an exception over a deadlock
14:23:08 <Solonarv> there won't be a deadlock either with the approach I mentioned
14:23:15 <Solonarv> update the counter and *then* run the action
14:23:22 <Solonarv> no deadlocks!
14:23:31 <larryba> of course, if it works properly, that would be even better. but it is more important that I get proper ordering if I run it concurrently
14:23:45 <Solonarv> Hm
14:24:45 <ski> (would it be any use to use `atomicModifyIORef_' here ?)
14:24:57 <Solonarv> I suggested that earlier, actually
14:25:04 <ski> ah, sorry. missed that
14:25:15 <Solonarv> well, atomicModifyIORef' 
14:25:27 <Solonarv> but that only works for the "increment first" approach
14:25:51 <ski> yea, naturally
14:26:11 <ski> @hoogle atomicModifyIORef'
14:26:12 <lambdabot> Data.IORef atomicModifyIORef' :: IORef a -> (a -> (a, b)) -> IO b
14:26:12 <lambdabot> Data.IORef.Lifted atomicModifyIORef' :: MonadBase IO m => IORef a -> (a -> (a, b)) -> m b
14:26:12 <lambdabot> Data.IORef.Compat atomicModifyIORef' :: IORef a -> (a -> (a, b)) -> IO b
14:30:39 * ski is also reminded of `mapIterate :: (a -> b) -> (a -> a) -> (a -> [a]); mapIterate f step start = map f (iterate step start)'
14:31:01 <ski> (er, s/[a]/[b]/, obviously)
14:32:38 <Welkin> if haskell didn't have so many escape hatches to mutate data and instead had a no-exceptions impleentation of immutability, the need for tracking IO in the type system would be gone
14:32:56 <ski> fun little observation, not all streams (= functions from `Nat') can be represented as `iterate step start' for some `step start', but if you use `mapIterate' instead, then it becomes true
14:33:57 <ski> (s/`step start'/`step',`start'/.) this observation seems possibly Coyoneda-ish, methinks
14:35:17 <ski> (there's also an argument that `foldr1' and `foldr1' would be better (FSVO "better") if they incorporated a `map' ..)
14:38:06 <ski> (hm, when i think about it, obviously `exists s. s * (s -> a) * (s -> s)' is a representation of `Stream a'. it's `nu s. f s  =  exists s. s * (s -> f s)' (is that a coend ?), for a (covariant) functor `f')
14:39:57 <ski> (cf. `mu r. f r  =  forall r. (f r -> r) -> r', Church representation. otoh Yoneda is `f a  =  forall b. (a -> f b) -> f b'. so the previous stream thing isn't quite Coyoneda, just a bit similar, afaict)
14:41:42 <Solonarv> larryba: this seems to work fine: https://gist.github.com/Solonarv/10fe6b58fbfbdb4b04c9a5992ebbbd22
14:42:01 <Solonarv> note that higher-arity versions aren't needed, you can just pack the arguments together into a tuple
14:43:48 <ski> (another investigation would be to try to characterize (differently) in some "nice" way *which* streams can be represented via `iterate' (is in the image of it). obviously if the stream is non-injective (has duplicates), it must have a suffix that's periodic, and whose prefix *is* injective, and doesn't overlap with the suffix. is that it ? and how to formulate it nicely ?)
14:45:21 * ski recalls pondering which functions in `M A -> M B' (`M' a monad) is in the image of `(=<<)', calling such functions Referentially Transparent
14:47:06 <ski> (.. also, the talk about prefix and suffix would require having a cutoff index, which is not computable in general. how to formulate it nicely, in a constructive way ?)
14:54:30 <ski> hm, just noticed Church representation of inductive types is dual to (internal) State representation of coinductive types. so perhaps it shouldn't be "separation of Church and State", but rather a duality ? (expressed via adjunction ? (cue Lawvere (and Lambek), dialectical (as in philosophy) interpretation of adjoints, <https://ncatlab.org/nlab/show/adjoint+modality>))
14:55:08 * ski is not sure "duality between Church and State" sounds as catchy, though
14:58:32 <benzrf> ski: oh hey that's a pretty legit use of "referentially transparent" :-D
14:58:34 * ski is waiting for someone, anyone, to say that this is crazy talk, though ;)
14:59:36 <ski> benzrf : yea, i thought it was a nice generalization of the philosophical/linguistic concept of `C[E]' being equivalent to `let v = E in C[v]'
15:00:14 <benzrf> i like it more than the abuse of terminology where it means "pure", anyway
15:01:07 <ski> here `C' is an expression context (corresponds to the function of type `M A -> M B' above, so `C[E]' becomes just `C E'. and `let v = E in C[v]' becomes `do v <- E; C (return v)')
15:01:37 <benzrf> indeed
15:01:52 <benzrf> dependence on the value of a computation rather than its nature
15:02:35 <benzrf> i guess it's not so much about "referential" transparency, though
15:02:40 <benzrf> perhaps "computationally transparent"
15:02:43 <benzrf> or something
15:03:14 <ski> see "Referential Transparency, Definiteness and Unfoldability" by Harald Søndergaard,Peter Sestoft in 1987-11-30 - 1990-01-04 at <http://www.cs.tufts.edu/~nr/cs257/archive/peter-sestoft/ref-trans.pdf>
15:05:30 <ski> (and perhaps Uday Reddy's answer at <https://stackoverflow.com/questions/210835/what-is-referential-transparency>. cf. <http://www.reddit.com/r/haskell/comments/xgq27/uday_reddy_sharpens_up_referential_transparency/>,<https://www.reddit.com/r/haskell/comments/xgq27/uday_reddy_sharpens_up_referential_transparency/>)
15:07:08 * hackage list-witnesses 0.1.1.0 - Witnesses for working with type-level lists  https://hackage.haskell.org/package/list-witnesses-0.1.1.0 (jle)
15:10:09 <larryba> Solonarv, you mean it works fine on your end when the returned action calls itself, or when running it concurrently?
15:10:13 <ski> it's interesting that if we take `M' to be `Reader Gamma', where `Gamma' is a variable environment, then we get `[| C[E] |]_rho  =  let v = [| E |]_rho in [| C[lift v0] |]_rho', which need not hold if `C[X]' is a context around `X' that binds a variable, like `C[X]  =  \x. X'
15:10:47 <ski> so, in this roundabout sense, variable capture/shadowing is not RT, is Referentially Opaque !?
15:10:55 <Solonarv> larryba: running concurrently
15:11:38 <Solonarv> replicateM_ 100 . forkIO =<< localState_ (+1) 0 print' -- prints numbers 0-99 in order
15:11:43 <larryba> not in here! not even in ghci (it is actually worse in ghci)
15:12:16 <Solonarv> (note: print' is a version of print that uses a lock to avoid interleaving output)
15:12:48 <ski> benzrf : well, wasn't the original formulation in terms of "frames of reference" (like in modal logic, possible worlds. e.g. states of knowledge (epistemic) or belief (doxastic) of a person (or law (deontic), as a codification of ethics) ?
15:13:11 <larryba> https://bpaste.net/show/cc6ab6a07021
15:13:50 <Solonarv> yeah, that's happening because the printfs are happening at the same time
15:14:25 <larryba> oh, so issue is writing to stdout concurrently
15:14:30 <Solonarv> yes
15:15:09 <larryba> how can it work fine though? you don't have any locks. what if you sleep randomly before each thread executes the action
15:15:28 <benzrf> ski: no idea :)
15:15:41 <ski> (a particular person's boss might be the wife of someone they know, but they might now be aware of that. so saying that they *know* their boss' phone number is ###### is not the same as saying that they know that their acquaintence's wife's phone number is ######, because stating knowledge of an agent is an RO context, you can't propagate (cotingent) formulae across it, willy-nilly)
15:16:07 <Solonarv> Hm. perhaps it worked out fine because the lock I used to avoid concurrent printing made things work nicely?
15:16:10 <larryba> I'd guess that it only appears to work fine by accident
15:16:36 <larryba> that seems likely
15:17:27 <ski> so, the idea would be that a context (such as a call to a particular function) around an action is RT iff you could lift out that action, and execute it in the outer context, instead substituting in the "result value" (the denotation) inside the context
15:17:54 <fen> > let x = "loop " ++ x in x
15:17:57 <lambdabot>  "loop loop loop loop loop loop loop loop loop loop loop loop loop loop loop ...
15:20:18 <zachk> > cycle "loop " 
15:20:20 <lambdabot>  "loop loop loop loop loop loop loop loop loop loop loop loop loop loop loop ...
15:22:37 <ski> in formulae, if `phi :: M A -> M B', then `phi' is RT iff `forall (ma :: M A).  phi ma  =  do a <- ma; phi (return a)' (or `forall (ma :: M A).  phi ma  =  phi . return =<< ma'), iow `phi = (phi . return =<<)', which is further equivalent to `exists (f :: A -> M B).  forall (ma :: M A).  phi ma  =  psi =<< ma', iow `exists (f :: A -> M A).  phi  =  (psi =<<)', that is, that `phi' is in the image of (curried) `(=<<)' (Kleisli extension)
15:23:40 <ski> in short, `phi' is RT (wrt a given monad) iff it is a Kleisli extension of a Kleisli arrow/morphism (for the monad in question)
15:27:06 <ski> (in some vague sense, think of executing an action / determining the denotation of a linguistic expression (with possible side-effects) as "entangling" yourself with the surrounding "context" (in the vague monad tutorial sense) / world. but perhaps it doesn't matter whether you embed a particular subsystem inside another system, or place it outside, and arrange for its denotation (but not its connotations ?) to be passed inside ??)
15:28:00 * ski realizes this quantum analogy might very well be on heavily shaky (earthquaky ?) ground ..
15:28:47 <fen> % let cycle' x = fmap (either id (lefts x !!)) x
15:28:48 <yahb> fen: 
15:28:59 <fen> % cycle' ([Left 'c',Right 1,Left 'y',Right 0,Left 'l',Left 'e',Right 3])
15:28:59 <yahb> fen: "cyyclee"
15:30:30 <fen> ski: for commuting monad transformers?
15:33:08 <Solonarv> larryba: actually you don't even need to do anything special for preventing self-calling enumerators
15:33:54 <Solonarv> at least I couldn't figure out how to write one that doesn't just hang anyway
15:34:01 <wroathe> In what sense is a GADT a generalization of a regular ADT?
15:34:22 <Solonarv> (you need to use mfix / fixIO to write one, so you can't actually use the argument)
15:34:50 <Solonarv> wroathe: in an ADT 'Foo a b', every constructor must have the same return type 'Foo a b'
15:35:08 <Solonarv> in a GADT the constructors' type signatures are allowed to differ from that
15:35:29 <Solonarv> namely, their return types are allowed to instantiate those type variables however you want
15:36:20 <ski> fen : hum ? not talking about monad transformers at all here, just monads
15:36:35 <ski> (unless you meant the talk about `MonadTunnelBlah' before ?)
15:37:16 <joehh> hello, when using ghcid with cabal new-repl, how can I set the context for expression evaluation
15:37:24 <joehh> Ie I am wanting to do something like:
15:37:28 <fen> oh, then what was the point about not being able to permute something through a monad?
15:37:40 <fen> commute*
15:38:08 <joehh> ghcid --command="cabal new-repl lib:myproject" -T "myTestFunc" -M "MyModule.MySubmodle.GoodModule"
15:38:35 <joehh> the --command part and the -T part should be fine, but don't know how to set the module
15:39:02 <joehh> so that myTestFunc is found in MyModule.MySubmodle.GoodModule
15:39:23 <ski> Solonarv : hm, why would you need `mfix'/`mdo'/`do'-`rec' ("monadic result recursion") for that ?
15:39:25 <fen> % let cycle'' = (\x -> fmap (either Left (x !!)) x)
15:39:25 <yahb> fen: 
15:39:38 <wroathe> Solonarv: You could implement a GADT just in terms of functions that return that type though, right?
15:39:43 <wroathe> Solonarv: Without enabling the extension, I mean
15:39:50 <fen> % take 4 map lefts $ iterate cycle'' ([Left 'c',Right 1,Left 'y',Right 0,Left 'l',Left 'e',Right 3])
15:39:51 <yahb> fen: ; <interactive>:223:1: error:; * Couldn't match expected type `([Either a2 b1] -> [a2]) -> [[Either Char Int]] -> t' with actual type `[a1]'; * The function `take' is applied to three arguments,; but its type `Int -> [a1] -> [a1]' has only two; In the expression: take 4 map lefts; In the expression: take 4 map lefts $ iterate cycle'' ([Left 'c', Right 1, Left 'y', Right 0, Left
15:40:11 <Solonarv> ski: you need something like: callsSelf <- localState succ 0 (\s a -> ... callsSelf ... )
15:40:22 <Solonarv> you can't write that without mfix!
15:40:37 <Solonarv> wroathe: well yes, but you can't pattern match on functions
15:40:41 * ski . o O ( "Value Recursion in Monadic Computations" (Ph.D. diss.) by Levent Erkök in 2002-10 at <http://leventerkok.github.io/papers/erkok-thesis.pdf>,<https://leventerkok.github.io/> ?
15:40:45 <ski> )
15:40:47 <Solonarv> and the function still needs to compute that result somehow!
15:40:53 <fen> % take 4 $ map lefts $ iterate cycle'' ([Left 'c',Right 1,Left 'y',Right 0,Left 'l',Left 'e',Right 3])
15:40:53 <yahb> fen: ["cyle","cycle","cyclec","cyclec"]
15:41:08 <ski> Solonarv : oh, right, of course. the nested `IO'. sorry
15:41:34 <wroathe> Solonarv: Oh, so in this sense it promotes functions to be value constructors that we can pattern match on
15:41:45 <Solonarv> well, not all functions
15:41:46 <Solonarv> one sec
15:42:08 * hackage shh-extras 0.1.0.0 - Utility functions for using shh  https://hackage.haskell.org/package/shh-extras-0.1.0.0 (lukec)
15:42:40 <wroathe> I'm trying to determine if GADT falls under the category of syntactic sugar, of if it's it's own thing, loosely speaking
15:43:05 <ski> fen : hm, "permute/commute through a monad" sounds like a rather inexact/vague rendering of what i was trying to express. i'd rather talk about it as a kind of substitution property, i think
15:44:07 <fen> how is that like unsafePerformIO being used safely?
15:44:08 * hackage shh 0.2.0.3 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.2.0.3 (lukec)
15:44:31 <Solonarv> wroathe: https://gist.github.com/Solonarv/03e0587a0ce14cb2ed3a96d01adb564a
15:45:07 <ski> (and it's not a property of the monad itself, but of a "context" (value) for that monad, so it couldn't be "(being | not being) able to permute something through a monad", but rather "through the given monadic context" (not in the monad tutorial sense))
15:45:30 <ski> fen : er .. it's not, at all ?!
15:46:01 <fen> oh because an IO interaction would entangle the value
15:46:28 <ski> (i didn't bring up, or even intended to imply, anything vaguely remotely related to `unsafePerformIO', i think)
15:47:05 <fen> well yeah, destroying the monadic wrapper on the value isnt the same as getting the value out, sure
15:47:09 <wroathe> Solonarv: Oh, so in a way it actually allows you to be more specific. "This doesn't just return a Foo a b, it returns a Foo a Int
15:47:09 <Solonarv> wroathe: check the gist again, I updated it
15:47:13 <Solonarv> yes
15:48:01 <Solonarv> the important thing is that pattern-matching on a GADT constructor makes these equalities available in the body of the function/case-alternative
15:48:16 <ski> (i suppose perhaps there's a crude relation in that `unsafePerformIO' is about "tangling" with the surrounding world (OS) via I/O, and `join' *looks* slightly similar ("remove a monadic layer", though it's rather "smach together two monadic layers"))
15:49:16 <ski> fen : yea, it's not "destroying the monadic wrapper" (in the `join' / `(=<<)' case), it's "merging" (or "entangling" ?) two (adjacent, nested) layers together into one
15:49:42 <fen> so if there are no "monadic effects" then the value can be lifted to the same scope as the monad was in?
15:50:17 <ski> (on that note, one question would be what the formulation for RTness would be, in terms of `join', instead of `(=<<)')
15:50:40 <ski> not if you're talking about RT (which i was talking about)
15:51:37 <wroathe> Solonarv: I'm actually not familiar with ~ yet, but thank you for taking the time to write up this gist. I'll mull it over.
15:51:46 <ski> RT is not about "computing/running a potentially effectful program phrase", it's about a *context* of such phrases. a phrase minus a subphrase, if you will
15:51:53 <Solonarv> wroathe: ~ is just equality
15:52:11 <Solonarv> i.e. 'a ~ b' means "a and b are the same type"
15:52:25 <fen> referential transparency like for use in equational reasoning?
15:52:31 * ski would have preferred (i'm almost sure) it if they had used `=' instead of `~' in type equality constraints
15:52:54 <Solonarv> yeah, but that would make the parser even more complicated
15:52:56 <ski> (but i suppose there were concrete syntactic considerations/complications)
15:52:58 * ski nods
15:53:15 <wroathe> Solonarv: So because we're constraining the type of one or more fields in one or more constructors, does this actually lower the cardinality for the type?
15:53:47 <Solonarv> we're not constraining the type of fields, we're constraining the GADT's type parameters
15:53:58 <ski> (almost sure, because i'm not quite sure whether the partiality of type families means that we have to be extra careful about non-denoting type expressions)
15:54:54 <ski> fen : referential transparency, as in the original analytical philosophy / linguistics sense, applied (and adapted appropriately) to a programming language context
15:55:21 <fen> the thing with cyclic pointers is something to do with the datatype that is a pointer having a cons like constructor making reference to the tail, but that this is not the same type as the pointer. like, a zipper over a list, cannot have a zipper as the tail
15:56:38 <Solonarv> wroathe: interestingly, it seems that one can write GADTs without enabling the GADTs extension, using the following set of extensions: GADTSyntax, ExistentialQuantification, TypeFamilies
15:57:03 <Solonarv> (well, you have to use the 'a ~ Int => GADT Int) form
15:58:09 <fen> the best you can do is have Pointer i f => f (Either a i), and then with the pointer function navigate :: i -> f a -> f a, this would be a cycle
15:58:56 <fen> but then its not like f a, its more like f (Either a (f a)), which is like, half comonad!
15:59:12 <fen> so it would be better to have i -> f a -> a
15:59:36 <fen> and then, this, over a duplicated pointer, would have the expected cyclic behaviour
16:00:19 <fen> ie containing values (which are pointers to each location)
16:00:47 <ski> fen : the sentence "I know that Phosphoros is Phosphoros." (Phosphoros is the morning star, which refers to (or is coextensive with) Venus) is not equivalent to "I know that Phosphoros is Hesperos." (Hesperos being the evening star, which is also Venus, although this identification of the two "stars" is an empirical fact that was at some point discovered, iow not known before)
16:00:54 <fen> seems strange how duplicate then seems necessary for cyclic pointers.. 
16:02:29 <fen> ski: wait, so even though the statements are equivalent, the fact they take different routs to the same result makes them distinguishable?
16:02:38 <ski> fen : this despite the ("de re") fact that "Phosphoros" is equal to (coextensive with) "Hesperos". so we express this phenomenon of statements about (e.g.) knowledge (or belief, &c. .. modal statements. or in my version, monadic ones :) by saying that the context "I know that [...]" is not RT
16:02:43 <ski> fen : <https://en.wikipedia.org/wiki/Frege%27s_Puzzle>
16:02:46 <fen> and that has something to do with referential transparency 
16:03:25 * ski isn't sure why fen is bringing pointers or zippers into this ..
16:04:23 <fen> might have misunderstood this idea of making reference to a value within a context
16:04:47 <fen> its the opposite of the monadic join?
16:04:53 <ski> fen : is whatever you're talking about related to Löb ?
16:08:16 <p0a> Hello, if I do ``take 2 $ words xs'' where xs is a long sentence, am I guaranteed that it won't "split" words it doesn't have to?
16:08:33 <ski> > let loeb :: Functor f => f (f a -> a) -> f a; loeb hungries = satisfieds where satisfieds = fmap (\hungry -> hungry satisfieds) hungries in loeb [product . tail,length,(2+) . (!! 1)]  -- this is like a spreadsheet, where cells can refer to any cells
16:08:35 <lambdabot>  [15,3,5]
16:08:38 <hpc> correct, take and words are both quite lazy
16:08:57 <p0a> hpc: who guarantees this though?
16:08:59 <hpc> well, maybe not guaranteed that it won't evaluate it
16:09:04 <hpc> but that it doesn't matter if it does or not
16:09:25 <hpc> p0a: the language specifies evaluation semantics
16:09:27 <Solonarv> > take 2 $ words $ "hello world " ++ undefined
16:09:29 <lambdabot>  ["hello","world"]
16:09:37 <fen> another thing is that factoring programs is nothing like factoring dynamical systems. mean field averaged ergodic spanning orbits have no well defined notion of energy conservation. maybe thats not actually a necessary invariant, maybe it just needs to be bounded 
16:09:38 <p0a> Well say you know all your words are less than 15 characters but the line is n characters. It's O(1) versus O(n)
16:09:53 <hpc> and i think also the definitions of take and words
16:10:09 <hpc> (ghc is free to give a different definition as long as it has the same semantics as the standard definition)
16:10:20 <ski> (a safe version would use a derivative (cf. zipper), like `F (DF a -> a) -> F a', to prevent a cell from referring to itself (though sometimes that can be useful, if a cell is not bulky, but lazily composed of multiple individual parts which can be individually accesses)
16:10:31 <dmwit> p0a: The language itself does not guarantee O(1) performance. Also, GHC will give you O(1) performance.
16:11:15 <p0a> dmwit: alright 
16:11:17 <ski> fen : the statements were not equivalent, but the corresponding differing subphrases where (in fact) equivalent (but not necessary in *knowledge* of some particular agent)
16:11:36 <p0a> dmwit: because it saves me a lot of trouble if I use that code, but I was not sure whether it's the right thing to do 
16:11:45 * ski has no idea what "opposite of the monadic join" is supposed to mean, here
16:11:47 <Solonarv> the language spec says roughly "programs must behave as if evaluation was lazy"; so if your program would successfully complete when lazily evaluated, it must also successfully complete when evaluated <however the implementation does it>
16:12:20 <p0a> Solonarv: doesn't that actually force O(1) here then?
16:12:32 <dmwit> No.
16:12:34 <Solonarv> well that part says nothing about performance
16:12:35 <hpc> there's a certain level of trusting the compiler to not be stupid involved
16:12:48 * ski has no idea about ergodic theory
16:13:01 <fen> ski: that was supposed to be like the opposite of unsafePerformIO, like, you can get at the value if it does not interact in the monadic context, and the opposite was supposed to be the let bound self reference of a cycle
16:13:07 <dmwit> The compiler is permitted to evaluate much more than necessary and backtrack if it discovers an exception, e.g.
16:13:11 <Solonarv> only about successfully completing (well, and computing the same value, which I forgot to specify)
16:13:11 <p0a> Solonarv: given that I can do  take 2 $ words $ cycle "a b "
16:13:44 <dmwit> (or runs out of time budget, or whatever)
16:13:49 <Solonarv> again, the *language spec* merely says that this must terminate and return ["a", "b"]
16:13:57 <p0a> dmwit: I see, you're saying the compiler is permitted to be entirely unreasonable
16:14:05 <Solonarv> it doesn't say anything about how the implementation is supposed to accomplish this
16:14:09 <dmwit> I do not agree to this rephrasing, no.
16:14:23 <Solonarv> this is a good thing, because it allows the implementation to start computing values earlier if it knows they'll be needed
16:14:27 <dmwit> It is often reasonable to evaluate more than is currently apparently needed.
16:14:33 <p0a> Well it would be entirely unreasonable to expect O(n) behavior in take 2 $ words s
16:14:42 <fen> ski: just that itterate f would span all values in some region with some weight upon averaging. its just supposed to give a stationary distribution, whereas an integrable system would loop and not span the region
16:15:01 <p0a> Maybe O(1) for a billion words, but not O(n). It's ... unreasonable. Because then it has to /decide/ to work differently when you provide cycle "a b ". No more O(n), now it's O(1).
16:15:13 <fen> normally some noise is added to help it escape the stability region
16:15:34 <dmwit> p0a: That depends. I bet I could cook up a setting where the reasonable thing that a compiler did involved evaluating extra stuff. e.g. maybe it's compiling to hardware, and it's easier to route things if you do a bit of extra work or whatever.
16:15:57 <Solonarv> what is the 'n' in O(n) ?
16:16:02 <p0a> the length of the string 
16:16:15 <Solonarv> of 'cycle "a b "' ? that's infinite
16:16:24 <fen> then you can treat function returns probabalistically, drawing them from the resulting stationary distribution
16:16:25 <p0a> that's why it's not O(oo)
16:16:32 <ski> fen : anyway, the `loeb' i gave above is formally similar to (as in "looks similar, in form, to"). see <https://en.wikipedia.org/wiki/L%C3%B6b%27s_theorem> (related to Gödel's incompleteness theorems), and compare with <https://en.wikipedia.org/wiki/L%C3%B6b%27s_paradox>
16:16:41 <p0a> In other words, it would switch from O(n) for finite strings to O(1) for infinite strings
16:17:10 <p0a> which is unreasonable to me, but permitted as you said. This explains my characterization of unreasonable, which dmwit did not agree with
16:17:18 <dmwit> Imagine a compiler which decides to fork a thread for evaluating the input string.
16:17:33 <dmwit> And then imagine the compiler finding itself on a single-threaded machine, and so implementing cooperative multitasking.
16:17:57 <dmwit> So now although take 2 . words returns in a finite time, it is causing the rest of the program to run a bit slower for the rest of the run.
16:18:00 <p0a> Look all I'm saying is that I'm *expecting* it to be O(1), based on Solonarv's comment. My justification is as above
16:18:00 <dmwit> I'd call that O(n).
16:18:03 <zachk> > take 2 . words . cycle $ "hello world " 
16:18:05 <lambdabot>  ["hello","world"]
16:18:06 <ski> fen : in my (fuzzy) view, "the opposite of unsafePerformIO" would maybe be something like `unsafeInspectEvaluation :: a -> Evaluation a', where `Evaluation' reifies how much has currently been forced, in a by-name (/ lazy) operational semantics ..
16:18:13 <dmwit> I expect it to be O(1), too.
16:18:15 <Solonarv> if 'take 2 $ words xs' were O(length xs), then it would take forever (i.e. never complete) when given an infinite input, while a fully-lazy evaluation strategy would complete after some time
16:18:21 <Solonarv> this would violate the spec!
16:18:28 <p0a> precisely!
16:18:32 <p0a> that's what I'm saying 
16:18:46 <zachk> > take 2 . words . cycle $ "hello world " 
16:18:48 <p0a> but it *can* be O(n) for finite strings and switch to O(1) for infinite
16:18:48 <lambdabot>  ["hello","world"]
16:18:51 <Solonarv> indeed I expect 'take 2 $ words xs' to be O( length-of-output )
16:19:07 <ski> (`Evaluation' ought to be a comonad ! .. it would be nice if we could instead use Dick Kieburz `OI' comonad, but that doesn't work, at least in a system without linear (or unique ?) types)
16:19:52 <p0a> dmwit: O(n) for some other n? Not sure I follow. I am not sure what cooperative multitasking even is 
16:20:25 <Solonarv> it's O(n) where n is the length of the *output*
16:20:48 <Solonarv> (I'm assuming that we're fully evaluating the output)
16:20:51 <p0a> like I said, it's reasonable to expect a word to be O(1) length 
16:21:01 <ski> p0a : there are/were implementations of Haskell, which used speculative evaluation, to evaluate something it thought would be needed soon, on an idle core, making sure to abort if it raises an exception (which is then ignored, or rather memoized in the thunk), or a time-out is signalled
16:21:29 <p0a> I see 
16:21:52 <Solonarv> well, if I pass an infinite input that doesn't have any spaces I expect to get back [the entire input, <<loop forever>>]
16:22:29 <Solonarv> because this is what would happen under lazy evaluation, and ghc must give back the same thing if it conforms to the spec
16:22:35 <dmwit> (the entire input : <<loop forever>>)
16:22:38 <p0a> and I'd expect you didn't have an english word
16:22:48 <p0a> in that infinite string
16:22:55 <tswett[m]> It can't give you a thunk for the second element because it doesn't know whether or not there's a second word.
16:23:01 <dmwit> Cooperative multitasking is like pre-emptive multitasking, except the tasks have to volunteer to give up control to other tasks.
16:23:02 <ski> p0a : this is one case of nonstrict semantics (a denotational (~= "meaning") semantics "*what* is the answer ?" property) not implying by-need / lazy semantics (an operational/procedural semantics "*how* do we arrive at the answer ?" property)
16:23:20 <Solonarv> well actually 'words' just splits on any whitespace, it doesn't care about english or whatever
16:23:39 <p0a> ski: I understand what the what does not imply the how
16:23:46 <dmwit> No, not O(n) for some other n. O(n) for n the length of the input.
16:24:00 <p0a> ski: but I'm suggesting that the how is strongly suggested by the what & Solonarv's comment on lazyness 
16:24:09 <fen> still cant understand why cycles would need comonads..
16:24:43 <Solonarv> p0a: oh yes indeed
16:24:55 <p0a> right :P
16:25:08 <ski> fen : hm, is that ergodic thing a (continuous) dynamical system thing ? perhaps related to (some) fractals and strange attractors ?
16:25:15 <fen> a list stores a value or a list. maybe its something to do with that...
16:25:26 <Solonarv> the spec is phrased like that to allow implementations which are smarter/faster than a naive lazy evaluator
16:25:40 <p0a> Solonarv: btw dmwit is right on the O(n) thing -- cycle "x" is evaluated instantly
16:25:47 <dmwit> ...or better some *other* way.
16:25:48 <fen> ski: basically its the opposite of deterministic.
16:25:57 <dmwit> e.g. perhaps being slower means it can run with less memory, or lower power.
16:26:12 <Solonarv> yes, true
16:26:14 <p0a> Solonarv: now, is it shown instantly? show $ cycle "x". Probably not. Maybe that takes infinte time 
16:26:23 <fen> we want the trajectories to spread out so we get even proportional sampling of the accessible values of some type
16:26:36 <dmwit> show (cycle "x") should be quite fast.
16:26:37 <ski> p0a : see monochrom's "Lazy Evaluation of Haskell" for some notion of "denotational semantics" vs. "operational semantics"
16:26:48 <dmwit> No slower than show on some other String.
16:26:55 <oo_miguel> How can I explain what seems to me, that most of the "debugging" time, when working with haskell I actually spend with getting ghc compile my code :P ? 
16:26:56 <p0a> dmwit: with "x"... as output?
16:27:06 <ski> (for that matter, how long as monochrom been "MIA" ?)
16:27:22 <p0a> dmwit: fair enough 
16:27:25 <dmwit> p0a: Why not try it? Experiments are a part of (computer) science!
16:27:35 <Solonarv> > show (cycle "x")
16:27:37 <lambdabot>  "\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx...
16:27:55 <p0a> dmwit: no thank you! :P 
16:28:06 <p0a> anyway, after this long chat, I'll try to finish this exercise 
16:28:07 <ski> fen : "why cycles would need comonads" ??
16:29:00 <bsima> TIL postgresql-simple is actually much better than persistent, especially when working with existing databases
16:29:39 <nshepperd1> In a nitpicky technical sense it's not really possible for the compiler to switch to O(1) for infinite lists, because being infinite is undecidable.
16:29:43 <fen> basically, if you want to refer to a pointer, then you have to carry and update a copy while traversing it, and the traversal does not include any pointer updating... so its a waste of time. but if you are doing duplicate, it evaluates a copy at every position, so then there is no extra cost in placing these at the cyclic references
16:30:06 <Solonarv> at least in the general case, anyway
16:30:06 <dmwit> ski: FWIW my logs last have content from monochrom on last Sunday.
16:30:23 <Solonarv> it's certainly possible to notice that e.g. cycle "x" is infinite
16:30:26 <nshepperd1> But you could totally have a compiler which converted lists into arrays whenever it could prove that the size is some particular number ahead of time
16:30:45 <nshepperd1> Like (replicate 3 'x') -> array
16:30:55 <fen> ski: yeah, these tail recursive datatypes mix up storing values and themselfs, so its like half comonad and confuses everything
16:31:03 <dmwit> But my claim is that take 2 . words can *both* return *and* be O(n).
16:31:22 <dmwit> Not that it can magically switch to O(1) for infinite lists.
16:31:46 <dmwit> You're attacking a strawman.
16:32:36 <fen> right, if you only decide later how much of a computation to run, you cant give its cost!
16:32:41 <ski> (note that the definition of `loeb' actually only needed `Functor' (but then it cheated and used general recursion), unlike Löb's theorem, which is expressed in Provability Logic (see "The Logic of Provability" by George Boolos). now `[]_F' ("it is provable, in formal system `F', that") is not quite a comonad, as would usually be the case with a "neccesary"-type modality in modal logic. `extract' fails (that's exactly what Löb's (or Gödel's, from this PO
16:32:58 <nshepperd1> I'm not attacking anything, lol
16:33:07 <ski> (hrm, probably cut off near ".. `extract' fails (that's exactly what Löb's (or Gödel's, from this POV) theorem is about), but you still have `scaffold'. also you have `(<*>)' (as is the norm, in modal logic (but not `pure')))")
16:33:35 <ski> dmwit : hopefully he's fine
16:33:52 <Solonarv> ski: you might want to configure your IRC client to break up long messages :>
16:34:23 <ski> eventually, when i get annoyed enough, i suppose :)
16:34:50 <Axman6> oo_miguel: "The type system got yo back" is how you explain it
16:35:00 <fen> basically, if traversing something, it should encounter values, not pointers to whole structures
16:35:43 <ski> @quote compiles.it.works
16:35:43 <lambdabot> chessai says: "'if it compiles it works' -brian kernighan"
16:36:05 <fen> Pointer i f => f (Either i a) + i -> f a -> a
16:36:39 <ski> fen : "tail recursive datatypes" being ?
16:36:48 <nshepperd1> dmwit: you're saying that the 'cost' can be O(n) in the case where it spins off evaluation in a thread? Because it just uses resources forever which is O(inf) for infinite lists
16:36:54 <fen> but then you cant keep traversing over the cyclic reference to the tail, but thats a good thing, since it should be refering to values already been traversed
16:37:23 <nshepperd1> That makes sense
16:37:38 * hackage pretty-ghci 0.1.0.0 - Functionality for beautifying GHCi  https://hackage.haskell.org/package/pretty-ghci-0.1.0.0 (harpocrates)
16:37:47 <fen> nshepperd1: no thats the point, its just referring to memory after some point, its not doing any extra work
16:38:38 <fen> cycle (... :: HList n a) costs O(n)
16:39:08 * hackage shh 0.2.0.4 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.2.0.4 (lukec)
16:39:10 <fen> > length "hello"
16:39:12 <oo_miguel> Axman6: thanks for answering. definitely the type system. Just wondered if I'm the only one experiencing this.
16:39:12 <lambdabot>  5
16:39:31 <fen> cycle "hello" costs 5
16:39:32 <Solonarv> oo_miguel: happens to me all the time
16:39:40 <nshepperd1> > deepseq (cycle "hello") ()
16:39:42 <lambdabot>  error:
16:39:42 <lambdabot>      Variable not in scope: deepseq :: [Char] -> () -> t
16:39:45 <oo_miguel> Solonarv: what a relief ;) thanks
16:39:47 <nshepperd1> Sad
16:40:10 <Solonarv> % rnf (cycle "hello")
16:40:10 <yahb> Solonarv: ; <interactive>:225:1: error: Variable not in scope: rnf :: [Char] -> t
16:40:14 <p0a> nshepperd1: what prevents the compiler from accomplishing undecidable tasks?
16:40:18 <Solonarv> % import Control.DeepSeq
16:40:19 <yahb> Solonarv: 
16:40:21 <Solonarv> % rnf (cycle "hello")
16:40:27 <yahb> Solonarv: [Timed out]
16:40:50 <nshepperd1> p0a: the ghost of alan turing
16:41:01 <p0a> nshepperd1: but the ghost is not part of the standard
16:41:14 <fen> \f -> fmap f . cycle (where f is O(n)) is O(n). [Int] is O(1) so cycle [Int] is O(1)
16:41:14 <Solonarv> p0a: the definition of "undecidable" is roughly "a computer cannot always figure this out in finite time"
16:41:51 <fen> ski: a tail recusive datatype like list, which takes itslef as an argument to one of its constructors
16:41:55 <fen> :t (:)
16:41:56 <lambdabot> a -> [a] -> [a]
16:42:18 <p0a> Solonarv: but it's a moot point, computers have finite resources 
16:42:19 <fen> [a] does not only appear as the return type
16:42:31 <fen> so its a recursive datatype
16:42:46 <Solonarv> p0a: really, "a hypothetical computer with infinite memory"
16:42:58 <hpc> a turing machine
16:43:13 <fen> and is causing confusion about cyclic references being like comonads, because they dont just store `a' they also store [a] sometimes
16:43:28 * ski idly wonders whether fen is familiar with `IVar's
16:43:38 <p0a> Okay when you have a turing machine at hand let me know
16:43:50 <dmwit> nshepperd1: right
16:44:00 <fen> ski: mutable datatypes are verbotern
16:44:10 <ski> ("I-structures: data structures for parallel computing" by Arvind,Rishiyur S. Nikhil,Keshav K. Pingali in 1989-10 at <https://dl.acm.org/citation.cfm?id=69562>. related to Haskell's `MVar's)
16:44:18 <Solonarv> p0a: it's a mathematical definition
16:44:20 <ski> fen : the `I' stands for "Immutable"
16:44:32 <p0a> Solonarv: it's applicability to reality is dubious
16:44:32 <ski> @hackage ivar-simple
16:44:32 <lambdabot> http://hackage.haskell.org/package/ivar-simple
16:44:47 <hpc> it's... math
16:44:50 <Solonarv> although, consider: if a computer with infinite memory can't answer a question in finite time, how could a computer with *finite* memory possibly answer that question?
16:44:56 <MarcelineVQ> write-once-vars
16:45:05 <ski> it has an identiy (like a graph node), so you can compare for that, but you can't change the contents
16:45:18 <inkbottle> I fail to populate the following type, which is a well known tautology, because I put 'r' where "empty type" should be: Either a (a -> r) -> ((a -> r) -> r) -> a, Is there a way to solve that?
16:45:32 <fen> ski: thats cheating
16:45:41 <dmwit> ?djinn Either a (a -> r) -> ((a -> r) -> r) -> a
16:45:42 <lambdabot> -- f cannot be realized.
16:45:46 <dmwit> inkbottle: no
16:45:53 <fen> how can you have concurrency in a pure environment?
16:46:04 <ski> (also dataflow / (declarative) concurrency variables, in concurrent logic programming (see Oz, CTM), is related)
16:46:09 <hpc> inkbottle: that looks like the law of the excluded middle
16:46:09 <ski> @where CTM
16:46:09 <lambdabot> "Concepts, Techniques, and Models of Computer Programming", by Peter Van Roy,Seif Haridi, at <http://www.info.ucl.ac.be/~pvr/book.html>
16:46:12 <Solonarv> inkbottle: Haskell's type system is closer to intuitonistic logic, where LEM (i.e. 'Either a (Not a)') doesn't hold
16:46:20 <inkbottle> dmwit: yes, I need an empty type
16:46:22 <ski> fen : is `lvish' also cheating ?
16:46:29 <ski> @hackage lvish
16:46:29 <lambdabot> http://hackage.haskell.org/package/lvish
16:46:39 <dmwit> inkbottle: Void is the traditional empty type in Haskell.
16:46:40 <inkbottle> Solonarv: it is EM -> contradiction principle
16:46:42 <dmwit> ?src Void
16:46:43 <lambdabot> Source not found. I don't think I can be your friend on Facebook anymore.
16:46:49 <dmwit> ah well. data Void
16:46:50 <ski> <ski> "LVars: lattice-based data structures for deterministic parallelism" by Lindsey Kuper (lkuper),Ryan R. Newton in 2013-09-23 at <https://dl.acm.org/citation.cfm?id=2502326>
16:46:57 <ski> @index Void
16:46:57 <lambdabot> Data.Void
16:47:13 <dmwit> https://hackage.haskell.org/package/base-4.12.0.0/docs/src/Data.Void.html#Void
16:47:33 <inkbottle> And I would need ex falso quod libet
16:47:37 <Solonarv> so: Either a (Not a) -> Not (Not a) -> a ? Hm.
16:47:41 <dmwit> :t absurd
16:47:42 <lambdabot> Void -> a
16:47:44 <ski> fen : why do you say ((single-)linked) lists is a *tail* recursive data type ?
16:47:52 <inkbottle> dmwit: nice
16:48:04 <inkbottle> that should do it
16:48:11 <Solonarv> % type Not a = a -> Void
16:48:12 <yahb> Solonarv: 
16:48:49 <dmwit> ?djinn Either a (a -> Void) -> ((a -> Void) -> Void) -> a
16:48:49 <lambdabot> f a b =
16:48:50 <lambdabot>     case a of
16:48:50 <lambdabot>     Left c -> c
16:48:50 <lambdabot>     Right d -> void (b d)
16:49:02 <Solonarv> (void = absurd)
16:49:34 <fen> ski: it seems safe as far as determinism is concerned, but its still concurrency, so it can still jam. its not pure enough
16:49:37 * ski . o O ( "Ceterum autem censeo `void'inem esse delendam" )
16:49:52 <hpc> ski: gesundheit
16:50:09 <fen> ski: tail recursive as its not making refference to the previous values, like a double linked list using CoFree would
16:50:29 <fen> Cofree (,)
16:50:29 <p0a> so I wrote a function parseMessage :: String -> LogMessage. It applies to a line. Now I'd like to have a function parse :: String -> [LogMessage] that goes through all lines in a String (separated by "\n")
16:50:43 <p0a> How can I do this? Should I split the string by "\n" ?
16:51:14 <ski> (or, rather that `void' ought to be *renamed* (not destroyed) to something else, at least in `Data.Functor' and `Control.Monad'. it can have the name `void' in the C modules under `Foreign'. but otherwise `void' by birthright belongs to `Data.Void' !. you can keep `absurd' if you wish)
16:51:28 <ski> hpc : tyvm
16:51:36 <dmwit> p0a: map parseMessage . lines -- ?
16:51:44 <Solonarv> p0a: there's a built-in function 'lines' which does just that
16:51:50 <p0a> oh that's nice 
16:51:51 <ski> fen : declarative concurrency has deterministic results
16:51:53 <MarcelineVQ> ski: hehe I already did that rant some days ago
16:52:14 <p0a> great, thank you 
16:52:30 <ski> MarcelineVQ : heh, i do it semi-regularly here, (mostly) whenever i've reminded :)
16:52:40 <fen> thats the problem about pointers not being ok with these tail traversals, as the copy that must be simultaneously navigated during traversal is of the whole thing, not just the tail. so you cant just refer to the previous stages of the traversal at the cyclic references
16:53:07 <ski> fen : "double linked list using CoFree" ?
16:53:41 <fen> ski: Cale's comment with DList https://wiki.haskell.org/Tying_the_Knot
16:53:49 <ski> @quote cofree.theorems
16:53:49 <lambdabot> djahandarie says: Category theorists are morphisms for turning cofree theorems into free theorems.
16:54:27 <LunarJetman> do you take milk with you cofree?
16:54:34 <LunarJetman> your*
16:54:42 <dmwit> mirk
16:54:53 <hpc> LunarJetman: and mix it with a http://hackage.haskell.org/package/spoon
16:55:07 <ski> fen : ah, ok, but you can't update tying-the-knot (and keep sharing). it's basically not a graph (or DAG), but a(n infinite) tree that *happen* to be represented more efficiently, but this representation is not stable under updates
16:55:10 <fen> ski: in that, the whole structure is contained at each location. like some sort of comonad thing. like, lists being half comonad (the stored tail as well as value), this stores the previously passed thing, the cotail or whatever
16:55:47 <ski> (and by updates, i mean "compute the same structure, except with this part replaced", not mutability / update-in-place)
16:56:01 <ski> (and perhaps this is something zippers might help with ??)
16:56:07 <fen> pointers
16:56:09 <fen> yeah
16:56:30 <fen> but only after they are duplicated can they refer to pointers at the cyclic references
16:56:31 <LunarJetman> comonad the barbarian
16:56:33 <ski> LunarJetman : it must be cowmilk
16:57:11 <ski> @quote coconut
16:57:11 <lambdabot> jle` says: coconuts are just nuts, aren't they
16:57:28 <ski> (perhaps coconut "milk" would also suffice ?)
16:57:30 <fen> that might have explained the question about comonads and cyclic datatypes
16:57:59 <LunarJetman> I think monoids are a thing too but I have no idea what they are.
16:58:21 * ski thinks they've'd at some point earlier mentioned zippers in relation to graph traversal, in a conversation with fen
16:58:29 <Solonarv> they are actually quite simple!
16:58:32 <hpc> monoids are super easy
16:58:45 <hpc> you have an empty element, []
16:58:50 <hpc> and an append operation, (++)
16:58:55 <hpc> [] ++ xs = xs
16:59:00 <hpc> xs ++ [] = xs
16:59:08 <LunarJetman> I understand that
16:59:13 <hpc> and (xs ++ ys) ++ zs = xs ++ (ys ++ zs)
16:59:16 <fen> ski: the kenco coffee co. has coconut coco
16:59:17 <Solonarv> they're just:
16:59:17 <Solonarv>  - a type
16:59:17 <Solonarv>  - a way of smashing together two values of that type
16:59:17 <Solonarv>  - an special element that doesn't do anything when you smash it together with something else
16:59:30 <p0a> that sounds like the algebraic monoid
16:59:32 <Solonarv> e.g. (Int, (+), 0)
16:59:33 <hpc> LunarJetman: and that's it
16:59:44 <Solonarv> p0a: that's because it *is* the algebraic monoid!
16:59:52 <hpc> now rename [] to mempty, and (++) to mappend
16:59:58 <p0a> lol
17:00:12 <fen> ski: sure, zippers are like storing the cotail, thats why they are pointers. well, that and they have i -> f a -> f a
17:00:27 <sicklorkin> > _ :: [a] -> Maybe (a,a).. 
17:00:30 <lambdabot>  <hint>:1:24: error: parse error on input ‘..’
17:00:45 <ski> LunarJetman : a monoid is a way to combine (or "smash together", for illustrative purposes) a bunch of items, ordered in a (finite) list (possibly empty), into a single item. such that if you "smash" a singleton list, you get back the sole item, and if you have a list of lists of items, it doesn't matter if you smach each individual list, then smashing the resulting list of items, or if you instead concatenate all the lists, and only smash once
17:00:45 <fen> and extract to give the required i -> f a -> a for the cyclic reference over the duplicate 
17:00:50 <sicklorkin> > _ :: [a] -> Maybe (a,a)
17:00:52 <lambdabot>  error:
17:00:52 <lambdabot>      • Found hole: _ :: [a1] -> Maybe (a1, a1)
17:00:52 <lambdabot>        Where: ‘a1’ is a rigid type variable bound by
17:01:06 <Solonarv> sicklorkin: what is that function supposed to do?
17:01:10 <dmwit> ?djinn [a] -> Maybe (a,a)
17:01:10 <lambdabot> Error: Undefined type []
17:01:11 <LunarJetman> what is [] ++ []
17:01:12 <ski> (perhaps that also got cut off, near ".., then smashing the resulting list of items, or if you instead concatenate all the lists, and only smash once")
17:01:14 <dmwit> Oh, too bad.
17:01:18 <hpc> > [] ++ []
17:01:20 <lambdabot>  []
17:01:28 * ski . o O ( "Me smash good." )
17:01:29 <inkbottle> :t \aav avv -> case aav of { Left a -> const a avv; Right av -> absurd (avv av) } -- -- A /\ B -> not B -> A, slightly more general than the tautology I was trying to prove
17:01:31 <lambdabot> Either p t -> (t -> Void) -> p
17:02:05 <dmwit> LunarJetman: It must be both [] (by letting xs = [] in [] ++ xs = xs) and [] (by letting xs = [] in xs ++ [] = xs).
17:02:22 <ski>   smash (singleton x) = x
17:02:27 <dmwit> (Luckily those are the same thing, so it's possible to be both at once!)
17:02:40 <LunarJetman> "empty element" sounds like a poor description; unconvincing choice of words?
17:02:46 <ski>   smash (concat xss) = smash (map smash xss)
17:02:57 <sicklorkin> Solonarv: It takes a list and if it can fit inside some fixed size tuple you get Just otherwise Nothing.. So [1,2] == Just (1,2); [1,3,4] == Just (1,2,3) 
17:03:01 <hpc> it's the zen kind of empty :P
17:03:12 <ski>   singleton :: a -> [a]
17:03:16 <ski>   singleton x = [x]
17:03:24 <sicklorkin> Solonarv: i'm not understanding how the continuation works for building the tuple
17:03:31 <ski>   concat :: [[a]] -> [a]
17:03:39 <ski>   smash :: [Item] -> Item
17:03:39 <dmwit> sicklorkin: Can't really reasonably be done in Haskell.
17:03:41 <LunarJetman> is there an ISO standard for Haskell?
17:03:45 <dmwit> sicklorkin: Make a plan that doesn't require that.
17:03:59 <Solonarv> sicklorkin: so this simultaneously has the types [a] -> Maybe (a, ..., a) for any number of a in that tuple?
17:04:00 <dmwit> LunarJetman: No, but there is the Report, the closest thing we've got to a standard.
17:04:03 <dmwit> ?where report
17:04:03 <lambdabot> http://www.haskell.org/onlinereport/haskell2010/ (more: http://www.haskell.org/haskellwiki/Definition)
17:04:13 <sicklorkin> dmwit: Right.. 
17:04:17 <LunarJetman> and [] is officially called "empty element"?
17:04:25 <ski> or "empty list"
17:04:26 <fen> > let x = []++x in x
17:04:29 <lambdabot>  *Exception: <<loop>>
17:04:43 <dmwit> LunarJetman: No, that was just a notational convenience for explaining monoids here in-channel.
17:04:47 <Solonarv> in the context of monoids it's usually called "empty element" or "identity element"
17:05:04 <ski> it plays the role of "neutral element" (sometimes "identity element" or "unit element") in relation to `(++)', just as `0' does for `(+)', and `1' does for `(*)'
17:05:07 <Solonarv> there are probably less common names I'm not thinking of
17:05:11 <ski> (and `id' does for `(.)')
17:05:35 <dmwit> LunarJetman: (And the standard mathematical jargon for its role in its monoid is "identity element".)
17:05:44 <Solonarv> right, sometimes it's also called 1 or 0 (in those cases the "smashing together" operation is usually called * resp. 0)
17:05:47 * ski frowns
17:05:56 <LunarJetman> I hope I don't get a stroke implementing Haskell.
17:06:01 <Solonarv> sometimes called "unit" as well
17:06:11 <ski> learning Haskell is fun ! :)
17:06:12 <sicklorkin> Solonarv: I was thinking back to sequenceA (_,Maybe a) == Maybe a and toListOf . traverse both [(1,3),(4,5)] and wondering why you can't go the other way
17:06:25 <ski> @quote is.the.solution
17:06:25 <lambdabot> quicksilver says: head-explosion is the solution, not the problem.
17:06:43 <fen> if the compiler knew about closed orbits it would reduce itterate id to repeat 
17:07:42 * ski has to appreciate how fen seemingly can relate almost anything to ergodic theory, or zippers/pointers ;)
17:08:09 <ski> (slight exaggeration, i know)
17:09:43 <dmwit> sicklorkin: flip (,) :: Maybe a -> (b, Maybe a) does one, and chunksOf 2 :: [a] -> [[a]] can be used for the other.
17:10:27 <dmwit> err
17:10:49 <dmwit> (,) :: b -> Maybe a -> (b, Maybe a) -- whoops
17:11:19 <sicklorkin> dmwit: I had this but really wanted to use traverse
17:13:33 <fen> ski: actually, there is more to the DList thing and zippers as pointers for cyclic references. the point is that traverse destroys extra structure of a more complex pointer such as Zipper (Free (Zipper f)). the "cotail" which could be stored in a dlist can be navigated any way other than forwards and backwards, while more general pointers can have orthogonal navigational directions
17:14:29 <jmcarthur> phadej: You're http://oleg.fi/ right? It seems to be down, in case you didn't know.
17:14:37 <dmwit> sicklorkin: I see. Well, keep traverse in your back pocket for now and pull it out again another time when it can really shine. =)
17:14:49 <sicklorkin> lol
17:15:06 <fen> so you cant just use cotail + value + tail at the cyclic reference. and so traversing zippers must explicity update a carried copy of the pointer, the cyclic reference cant just refer to a previous point in the traversal, even if a cotail was stored inthe datatype constructor
17:15:55 * ski for a moment thought jmcarthur was accusing phadej of being Oleg ..
17:16:25 <fen> then, as replacing values with the updated carried pointer is exactly duplicate, it makes sense to only have cyclic references using the duplicated pointer
17:16:53 <ski> @quote solves.NP-hard
17:16:53 <lambdabot> OlegFacts says: Oleg solves NP-hard problems in N log N time... in the type system
17:16:58 <p0a> should I align my ::'s with my ='s in functions?
17:17:00 <fen> and by that reasoning, only store a value at the cyclic reference, not something like tail which could be traversed over
17:17:19 <ski> @quote 100.milli-Olegs
17:17:19 <lambdabot> Pseudonym says: What was considered 100 milli-Olegs of type hackery five years ago is standard operating procedure these days
17:17:21 <p0a> this is what my indentation does automatically but it really stretches when the arguments have long names
17:18:13 <ski> p0a : no
17:18:25 <Solonarv> p0a: nah, I'd turn that off
17:18:35 <jmcarthur> ski: Well, I think phadej is Oleg Grenrus. Just a different Oleg.
17:18:36 <ski> p0a : you might, sometimes, align `::'s in related signatures, with each other
17:18:50 <p0a> okay 
17:19:01 <Solonarv> or in multi-line signatures, align :: with the subsequent => and ->
17:19:01 <ski> (this is one way in which Haskell formatting is really two-dimensional. aligning "parallel" patterns is another way)
17:19:04 <fen> Pointer i f => f (Either i a) + i -> f a -> a === f a 
17:19:35 <ski> Solonarv : yes ! :)
17:19:46 * ski . o O ( a monoid is just a monoid action, acted by the monoid object `List' in the monoidal category of monads, what's the problem ? )
17:19:48 <fen> not; Pointer i f => f (Either i a) + i -> f a -> f a === f (Either a (f a)) "half comonad"
17:20:03 <ski> (also see : monad algebras)
17:20:38 <dmwit> Solonarv: foo ::\n Ctx =>\n arg1 ->\n arg2 ->\n result is the one true way
17:20:47 <ski> fen : what are you claiming is equivalent to `f a' ?
17:21:07 <Solonarv> dmwit: yes! also makes haddock comments on the arguments nice and neat
17:21:34 <ski> fen : i'm don't follow "cotail", nor your `Zipper (Free (Zipper f))', what's `Zipper' here, e.g. in terms of derivative (say `D') ?
17:21:49 <Solonarv> Although I find that this gets a bit awkward when there is a 'forall' or a big context involved
17:22:00 <dmwit> Solonarv: Oh! Has that changed, or did you misread (I thought haddock didn't yet support this style)?
17:22:03 <ski> (nor do i know what `Pointer' expresses)
17:22:08 <Solonarv> (mostly because splitting it properly breaks my editor's syntax highlighter)
17:22:21 <Solonarv> oh no, I misread
17:22:26 <fen> right, it needs a Linear_r f constraint to say f is nonempty and has f a <-> (a,Maybe (f a))
17:22:47 <ski> dmwit : argh ! pretty please don't leave those `=>'s and `->' hanging around all lonely at the end of lines of code !
17:22:49 <p0a> how exactly do I change a binary tree ?
17:22:51 <Solonarv> I guess you could do haddock comments using -- | on the line *before* each argument
17:23:03 <dmwit> p0a: mu
17:23:05 <p0a> do I have to transverse all of it to recreate it?
17:23:06 <fen> then there is always a head, for the one hole context
17:23:14 <p0a> dmwit: is `mu' to do with mutability?
17:23:28 <dmwit> p0a: "mu" is the traditional Chinese answer to a wrong question.
17:23:42 <dmwit> Sort of like "no", but more like "unask the question".
17:23:45 <Solonarv> 'mu' means "your question is malformed and doesn't have an answer"
17:23:52 <fen> Free has a Linear_r r f instance with r a = Free f a
17:24:03 <dmwit> But with less mystery: you build a new tree with the right contents. Generally you don't need to traverse the whole thing, only the parts you plan to "change".
17:24:36 <ski> (have `=>'s and `->' as initial tokens, rather than final ones, in such multi-line signatures. cf. initial `,'s with multi-line tuple and list literals)
17:25:01 <dmwit> (I know. The mystery answer isn't fun or useful for you, it was only fun for me. But at least I followed it up with a useful answer, hey? Some places you wouldn't even get that.)
17:25:06 <p0a> dmwit: I see it now 
17:25:13 <p0a> dmwit: I can `point' to the unchanged part
17:25:29 <dmwit> ski: But then adding a new first argument requires a 2-line diff instead of just 1! How awful.
17:25:31 <ski> dmwit : aka "inadmissible", or "not even wrong" ("Ganz Falsch !") or "one of the presuppositions of that is wrong"
17:25:51 <p0a> dmwit: looks like any change in a binary tree requires to change at least *half* the tree though. right?
17:25:58 <p0a> dmwit: since every parent is affected
17:26:08 <desnudopenguino> i'm trying to get haskell installed on Alpine Linux with http://markbucciarelli.com/posts/2017-04-05_haskell_on_alpine_linux.html but i'm getting "No setup information found for 
17:26:13 <fen> ski: that is, extracting the `Linear_r r f => Free f a' at the head of the f, and passing all the rest of it into the reverse portion of the zipper, a vertically downwards navigation, the inverse of which is replacing the currently pointed to Free back into the head of the upper layer
17:26:28 <desnudopenguino> ...ghc-8.6.3 on your platform. This probably means a GHC bindset has not yet been added for OS key 'linux64-ncurses6'"
17:26:29 <ski> fen : is that iso an `uncons' operations, getting the "head/root" element ?
17:26:37 <ski> s/getting/detaching/
17:26:58 <fen> pattern matching on (::::) of FIFO_r
17:27:00 <ski> (fen : and is `f' a comonad ?)
17:27:10 <fen> https://gist.github.com/fen-hs/9772c2ce27a355984add2e5b7d352fbb
17:27:29 <p0a> so "half" of hte binary tree needs to be recreated on every insert 
17:27:31 <p0a> I think 
17:28:13 <Solonarv> well, not half exactly - everything on the path between the root and the changed node
17:28:24 <fen> f is a comonad but a "tail" comonad, while Zipper f => f a is a better comonad, with Zipper f (Zipper f a) as the duplicate
17:28:50 <ski> fen : lots of modules, types, classes i don't know there
17:29:11 <ski> (and why would you call that `Linear_r' ?)
17:29:17 <fen> https://gist.github.com/fen-hs/9772c2ce27a355984add2e5b7d352fbb#file-fifo_r-hs-L44
17:29:53 <fen> well its like linear, which is like nonempty list, as Stack is like list. but it has extra shape `r'
17:30:20 <ski> p0a : my comment for dmwit was also meant for you, fwiw
17:30:23 <p0a> Solonarv: aah, good point. thank you 
17:30:31 <p0a> Solonarv: I see that 
17:30:43 <fen> eg Linear_i === Linear_r but where r a = (i,a) so that it only contains one value a.
17:31:02 <fen> Free is thus Linear_r but not Linear_i
17:31:17 <fen> and zippers are over Linear_r things
17:31:53 <fen> including Linear === Linear_r Identity === Linear_i ()
17:32:32 <p0a> ski: which?
17:33:10 <p0a> ski: ganz falsch?
17:33:32 <fen> then we can navigate `Linear_r r f => Zipper (Free (Zipper f)) a' up, down,left and right
17:34:01 <fen> giving an example of a pointer with navigational directions other than just forwards and backwards like zipper
17:34:10 <larryba> exceptions from different thread (fired by functions in async package) are completely ignored. is there a way to let them propagate to the main thread, so that my program is killed?
17:34:40 <fen> and where the traversal flattening things to a list is not a good cyclic reference - to a previous location of the traversal
17:34:46 <larryba> do I have to do that manually? catch them in that thread, and then exit the program?
17:34:46 * ski would expect something like `class Functor f => Linear f where deflate :: f Void -> Void; separate :: f (Either a b) -> Either (f a) (f b); factor :: f (a,b) -> (a,f b)', perhaps
17:34:55 <fen> (Zippers = "partial traversals")
17:34:55 <ski> p0a : yea, that message
17:35:19 <p0a> ski: I don't know how that makes me feel 
17:35:28 <ski> (perhaps it's not quite the same nuanced thing, but it's in the same ballpark)
17:36:22 <fen> ski: Linear_r things are both MonadPlus and Comonad
17:37:34 <dmwit> p0a: In a balanced tree, modifying one leaf requires changing O(log n) of the total structure.
17:37:38 <fen> ski: separate wouldnt work except for stacks, linear + empty
17:37:47 <dmwit> (n being the size of the total structure, I mean)
17:37:58 <dmwit> Half is a vast overestimate of that.
17:37:59 <p0a> dmwit: aah, yeah. I think missed that too
17:38:00 <Solonarv> larryba: 'link' does that, IIRC
17:38:48 <fen> no idea how that factor function would work...
17:38:50 <ski> fen : i'm just following the vector/module notion of "linear" (except using the rig (of types) for the scalars, rather than a ring (or a field))
17:39:02 <Solonarv> larryba: https://hackage.haskell.org/package/async-2.2.1/docs/Control-Concurrent-Async.html#v:link
17:39:11 <ski> (you know the usual notion of that "linear" means, in math)
17:39:15 <fen> right ok
17:39:23 <fen> no, its not that at all
17:39:34 <fen> it means "its like in a line"
17:39:43 <ski> ok
17:40:25 <ski> fen : "are both MonadPlus and Comonad" -- with expected coherence conditions between those two structures ?
17:40:34 <fen> yeah
17:40:38 <fen> all da laws
17:40:56 <ski> (like `extract . return = id', e.g.)
17:41:00 <fen> Linear_r is not line like, it has extra shape `r'
17:41:47 <ski> hmm .. is that vaguely like the distinction of modules over `|Z', versus modules over an arbirary ring ?
17:41:53 <larryba> Solonarv, nice!
17:42:13 <fen> \a -> extract (Pure (a :| [])) = a
17:42:17 * ski . o O ( Erlang ftw ! )
17:42:23 <larryba> I'm really liking async package
17:42:30 <Solonarv> yeah, it's very nice :D
17:43:18 <fen> yeah, anyway, they are tail comonads, and its better to use Pointers over the corresponding zippers on the Linear_r types
17:43:40 <ski> what's a tail comonad ?
17:44:03 <fen> nonempty is a comonad on iterate tail
17:44:19 <ski> i dunno what that means
17:44:33 <fen> > iterate tail [1,2,3]
17:44:34 <ski> ("a comonad on blahblah" means what ?)
17:44:35 <lambdabot>  [[1,2,3],[2,3],[3],[],*Exception: Prelude.tail: empty list
17:45:03 <fen> "duplicate is implemented by"
17:45:04 <larryba> Solonarv, hmm, I think I can't use that. I am using mapConcurrently and concurrently, and they don't return async
17:45:30 <larryba> or, I guess, I can't use mapConcurrently and concurrently
17:45:34 <Solonarv> those already re-throw exceptions in the child thread
17:45:36 <ski> oh .. you mean that `duplicate'^W`scaffold' is just `tails' (or rather `init . tails')
17:45:42 <larryba> Solonarv, huh?
17:45:58 <Solonarv> larryba: at least the docs say so!
17:46:11 <fen> ski: no, the init isnt required as its linear, not stack
17:46:12 <Solonarv> mapConcurrently: "If any of the actions throw an exception, then all other actions are cancelled and the exception is re-thrown."
17:46:29 <ski> oh, i thought you were talking about nonempty
17:47:10 <larryba> Solonarv, ok, you're right. very odd! I was expecting my program to be failing every now and then. I guess it is a good thing that it hasn't so far :P
17:47:18 <fen> ski: https://gist.github.com/fen-hs/0e01cf44b066804433b24a64429f2400#file-unfoldable_r-hs-L18
17:47:22 <fen> instead of iterate
17:48:05 <fen> https://gist.github.com/fen-hs/a71ab735bf977d9b948a62416662fe57#file-church-hs-L69
17:48:14 <fen> that fuses
17:49:45 <ski> (fwiw, i've forgotten exactly what variations your `State0' and `State1' were)
17:51:12 <fen> https://gist.github.com/fen-hs/9772c2ce27a355984add2e5b7d352fbb#file-fifo_r-hs-L101
17:52:09 <fen> thats a deafult for Traversable_r
17:52:12 <fen> https://gist.github.com/fen-hs/6bb03486008a8a31b9edf95f8bd35f46#file-traversable_r-hs-L72
17:52:17 <fen> which also fuses
17:53:57 <fen> via: https://gist.github.com/fen-hs/0e01cf44b066804433b24a64429f2400#file-state-hs-L15
17:54:16 <fen> ski: States are there^
17:55:07 <p0a> are helper functions okay in haskell code?
17:55:19 <MarcelineVQ> p0a: absolutely
17:55:29 <p0a> is it f_aux or f_helper or ?
17:55:35 <slack1256> even encouraged
17:55:35 <p0a> good to know
17:55:56 <ski> p0a : depends
17:56:01 <slack1256> you can check on the prelude a lot of functions have a `go` helper function defined via let/in or where
17:56:01 <MarcelineVQ> whatever name conveys the most info in your opinion
17:56:33 <fen> basically, you can unfold the Linear variants, and traverse over them (and convert between them) using fusion. which is totally ruined by having to update a carried pointer to place at cyclic references. so, the solution is to just have cyclic references over the duplicate, since this would evaulate the pointer at every position anyway
17:56:33 <ski> if it's private (in `let' or `where') you can call it `go' or `loop', e.g. (or sometimes avoid naming it, using `fix' e.g.)
17:56:54 <p0a> ski: thanks
17:56:55 <maerwald> 'go' is used a lot for starting a recursion with additional parameters that are not part of the function API
17:57:04 <p0a> sounds rihgt for my case
17:57:34 <p0a> can you provide types for `where/let' functions?
17:57:38 <Solonarv> yes!
17:57:40 <ski> p0a : sometimes the helper can be of independent value, and then it can often be given a descriptive name like `reverseAppend' (where `reverseAppend xs ys = reverse xs ++ ys' holds, though that's not the implementation)
17:58:16 <Solonarv> but you might need the ScopedTypeVariables extension to write those type signatures sometimes
17:58:30 <p0a> ah
17:58:38 <p0a> sometimes?
17:59:07 <Solonarv> yes: you need it if you want to mention a type variable from the outer function's type
17:59:37 <fen> what in a where?
18:00:16 <Solonarv> type signatures 
18:00:26 <ski> (oh, so your `State s' is `StateT s Maybe', in normal terms. and i probably wouldn't call that `CoState'. also, you have redundant brackets !)
18:00:32 <fen> should be implicit in local scope?
18:01:06 <Solonarv> I never said that, and in fact I disagree with that statement
18:01:30 <p0a> well given that types can serve as documentation 
18:01:52 <maerwald> They barely do
18:01:59 <p0a> anyhow, I'll look into ScopedTypeVariables
18:02:00 <fen> why? a where bound type signature with the same type variables as appear in the type signature of the top level function should not throw an error
18:02:04 <maerwald> unless you already know the purpose of the function
18:02:18 <Solonarv> fen: it won't throw an error, it just won't refer to the same type variable
18:02:20 <p0a> maerwald: well, I agree. [a]->[a] is ... not very illuminating.
18:02:28 <fen> well it should
18:02:31 <p0a> maerwald: worse is a->b :P
18:02:31 <maerwald> p0a: even String -> String is not
18:02:41 <fen> pretty sure it used to
18:02:47 <p0a> maerwald: and the catch-all `a'.
18:02:52 <Solonarv> it does with ScopedTypeVariables
18:03:05 <fen> why shouldnt it without?
18:03:37 <Solonarv> because the standard says so
18:03:56 <Solonarv> at least I assume it does, can't be bothered to check
18:04:01 <fen> if you disagree with it because of reasons, those reasons are in the standard?
18:04:31 <fen> if not, what are these reasons!?
18:04:38 <Solonarv> I don't agree with that behavior! I would be perfectly happy with ScopedTypeVariables being enabled by default, in fact
18:04:51 <p0a> you're all a happy bunch aren't you
18:05:17 <p0a> :P I can just imagine a reenaction of this chatroom in a movie
18:05:23 <Solonarv> hah
18:05:25 <nshepperd1> On the contrary, 'f :: a->b' is very illuminating. It means the function is either some kind of bottom or something horribly unsafe
18:05:39 <fen> [02:00] <fen> should be implicit in local scope? [02:00] <Solonarv> I never said that, and in fact I disagree with that statement
18:06:10 <nshepperd1> The information a type seems to have, the more it actually has...
18:06:17 <nshepperd1> Or something like that
18:06:25 <Solonarv> Yes. I don't agree that "type signatures in a local scope should be implicit"
18:06:33 <fen> the only issue would be if it didnt used to, and old code was broken by making ScopedTypeVariables onby default
18:06:56 <fen> not sure what was the case before that extension existed
18:07:54 <fen> oh, no, meant that the reuse of type variables bound at the top of that scope should be implicitly the same as those appearing in type signatures within that scope
18:07:55 <Solonarv> imagine this function: map :: (a -> b) -> [a] -> [b]; map f = go where go [] = []; go (x:xs) = f x : go xs
18:08:08 <Solonarv> without STV it is impossible to give a type signature to 'go'
18:08:38 <fen> not sure that was always the case
18:08:52 <fen> didnt that break old libraries?
18:09:22 <Solonarv> I'm not familiar enough with the history of haskell to answer that
18:09:51 <fen> well, one thing that totally sucks is that you cant put rankN types in classes
18:09:59 <p0a> Thank you for all the help 
18:10:03 <inkbottle> ?djinn ((Void -> Void) -> Void) -> Void) -> (Either Void (Void -> Void)) -> Void
18:10:03 <lambdabot> Cannot parse command
18:10:10 <fen> so you cant give default signatures!
18:10:24 <Solonarv> what do you mean?
18:11:02 <fen> you cant use scoped type variables for implicit params in default signatures
18:11:31 <fen> because some of the variables are bound by the class head, and a forall would free them
18:12:24 <inkbottle> ?djinn (((Void -> Void) -> Void) -> Void) -> (Either Void (Void -> Void)) -> Void
18:12:24 <lambdabot> -- f cannot be realized.
18:19:08 * hackage primitive 0.6.1.2 - Primitive memory-related operations  https://hackage.haskell.org/package/primitive-0.6.1.2 (CarterSchonwald)
18:21:48 <benzrf> @let a -?> b = not a || b
18:21:49 <lambdabot>  Defined.
18:22:09 * ski is a bit sleepy
18:22:20 <benzrf> > (((False -?> False) -?> False) -?> False) -?> (False || (False -?> False)) -?> False
18:22:22 <lambdabot>  False
18:22:27 <benzrf> no need for djinn :]
18:22:50 <ski> fen : sorry not following along :/
18:25:56 <ski> inkbottle : congrats, a counter-model to .. something
18:26:34 <larryba> is there some sort of naming convention for similar IO functions, where one throws and the other returns a list of Eithers?
18:27:38 <Solonarv> foo & fooEither works
18:28:38 * hackage b9 0.5.66 - A tool and library for building virtual machine images.  https://hackage.haskell.org/package/b9-0.5.66 (SvenHeyll)
18:31:21 <larryba> I thought of that one as well, but it kind of suggests function returns Either a b, not [Either a b]
18:35:37 * hackage shh 0.2.0.5 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.2.0.5 (lukec)
18:37:26 <Solonarv> what does the other version return?
18:38:02 <larryba> [b]
18:38:55 <Solonarv> I might just not have the throwing version then
18:43:44 <larryba> it has different semantics, as it stops on the first error
18:45:56 <Solonarv> oh, just stops completely?
18:46:06 <Solonarv> right, of course it does
18:46:42 <Solonarv> that's not a problem, you recover it from the [Either e b] version using sequence
18:47:48 <ski> % :t sequence @[] @(Either IOError)
18:47:48 <yahb> ski: [Either IOError a] -> Either IOError [a]
18:49:47 <larryba> I'm probably not explaining my situation well. I have .. -> IO [Either String Value] function that doesn't throw, and ... -> IO [Value] function that does throw.
18:50:35 <Welkin> exceptions are evil
18:51:14 <larryba> they are inevitable when in IO
18:51:32 <Welkin> no they aren't
18:51:44 <Welkin> C doesn't have exceptions for example
18:52:24 <larryba> C is a great example why the alternative is even worse :)
18:52:25 <Welkin> your code is inherently unreliable in IO if it throws exceptions, meaing you can never write a safe program in IO
18:52:32 <Welkin> meaning none of your programs will ever be safe or reliable
18:53:32 <larryba> that makes no sense. even if you never throw an exception, other things do. every IO action can throw an exception, and should be treated as such
18:53:45 <Welkin> libraries that throw exceptions should be avoided
18:54:08 <Welkin> often you can catch all exceptions and wrap them in Either or Except
18:54:18 <Solonarv> larryba: no, I understood perfectly well. I wouldn't have that throwing version.
18:54:19 <Welkin> servant, for example, operates only with ExceptT
18:54:26 <Welkin> exceptions suck
18:54:43 <Solonarv> you can catch all exceptions, yes, but then you get a program that you can't kill
18:55:56 <dncr> isn't spans xs = zip (inits xs) (tails xs) useful enough to be in Data.List?
18:56:28 <Welkin> dncr: you wrote it in one line of code
18:56:40 <Clint> dncr: when would i ever use that?
18:56:43 <Welkin> I think that answers the question
18:57:14 <Solonarv> Welkin: yes, and? map f = foldr (f . (:)) [] is also a one-liner and yet it's in Data.List
18:57:20 <larryba> Welkin, does servant have IO actions?
18:57:28 <Welkin> larryba: of course
18:57:39 <Welkin> Solonarv: but map is a primitive
18:57:46 <Welkin> in terms of functional programming
18:57:50 <larryba> Welkin, they can crash due to exeption
18:58:04 <Welkin> you could bloat libraries with every variation under the sun to do very obscure and specific things if you wanted to
18:58:25 <Welkin> larryba: yes, which is why exceptions are evil
18:58:25 <larryba> Welkin, async exceptions. out of memory exceptions. and a bunch more I can't bother thinking of right now
18:58:40 <Welkin> and haskell doesn't handle them well
18:59:01 <Welkin> unless you use cloud haskell (I assume)
18:59:03 <larryba> in a way, Either is worse, because it gives you false sense of security. that the type covers all the possible errors. that is fine in pure code, but in IO it is a lie
18:59:10 <glguy> I think exceptions in IO work quite well. Things get hard when you want to use asynchronous exceptions
18:59:21 <larryba> Welkin, well you think how C is handling this is good.. so :)
18:59:29 <Welkin> larryba: I didn't say that
18:59:43 <Welkin> I only used C as an example why you don't need exceptions
18:59:51 <Welkin> they are not inherent
18:59:57 <Welkin> they are an abstraction over failure
19:00:05 <glguy> and I'd generally consider ExceptT e IO to be a mistake
19:00:12 <larryba> Welkin, what alternative do you suggest, then? encoding every possible error in the Either-like type? coding in such an environment would be miserable
19:00:54 <larryba> and if you don't encode every possible error in the type, then it is even worse. because 1) you give false sense of security. 2) you have to handle errors in two different ways
19:01:04 <Welkin> larryba: accepting that failure will happen and dealing with it like erlang. The process dies, the error gets handled by the supervising thread, and the dead thread is started up again to continue working
19:01:15 <Welkin> basically, cloud haskell, or really, erlang
19:09:58 <MarcelineVQ> so like, exceptions
19:10:56 <larryba> Welkin, I took a quick look, its focus seems to be distributed computing. I'm not too thrilled about using separate processes that communicate via messages unless I don't have a choice, having done that in other languages
19:11:21 <Welkin> the secret is that if you are running on more than one core, you are already doing distributed computing
19:11:40 <Welkin> which is why an erlang program is the same running on one core, multiple cores, or multiples machines
19:12:36 <larryba> depends on your definition. cloud's focus seems to be computer clusters
19:14:36 <larryba> you need processes that communicate with each other for that. but you don't when your program runs on a single machine. I'd much rather use SMT (at least compared to what I have used in other languages)
19:14:53 <dmwit> dncr: My preferred function of similar nature is this one: zippers = go [] where go _ [] = []; go b (h:e) = (b,h,e) : go (h:b) e
19:15:00 <larryba> STM*
19:15:43 <larryba> and MarcelineVQ made a good point, I don't see why that model couldn't be implemented with exceptions - without the pain of inter-process communication
19:16:02 <dmwit> dncr: One nice feature of this version is that observing the entire output is O(n), unlike yours, which is O(n^2).
19:16:07 <Welkin> you don't need to catch anything, because exceptions are not propagated between processes
19:16:10 <Welkin> they don't share state
19:17:05 <dncr> dmwit: I haven't grokked zippers yet but O(n) sounds worth it
19:17:30 <dmwit> ?let zippers = go [] where go _ [] = []; go b (h:e) = (b,h,e) : go (h:b) e
19:17:31 <lambdabot>  Defined.
19:17:36 <dmwit> > zippers "abcde"
19:17:38 <lambdabot>  [("",'a',"bcde"),("a",'b',"cde"),("ba",'c',"de"),("cba",'d',"e"),("dcba",'e'...
19:17:44 <dmwit> Congratulations, now you understand zippers!
19:17:44 <dncr> ah nice
19:18:30 <dmwit> (Well, list zippers, anyway.)
19:18:49 * dncr kicks their rusty internal universal turing machine
19:20:38 <Solonarv> oh, this is (almost) 'select'
19:21:45 <Cale> ah, yeah, this is another related thing :)
19:21:46 <dmwit> I don't know select.
19:21:46 <MarcelineVQ> "<Solonarv> oh, this is (almost) 'select'" It keeps happening :O
19:21:52 <Cale> That's just a little function that I wish was in Data.List from time to time, it's like this:
19:21:57 <Cale> select [] = []
19:22:13 <Cale> select (x:xs) = (x,xs) : [(y,x:ys) | (y,ys) <- select xs]
19:22:16 <MarcelineVQ> I warned you about select bro. I told you dog
19:22:27 <dmwit> Oh, yes. But this is better than select.
19:22:40 <Solonarv> hence "almost" ;)
19:22:41 <dmwit> (Because cheaper, and can be used to trivially implement select if that's what you need.)
19:22:58 <dmwit> (But in my experience it rarely is. The zipper version is almost always sufficient.)
19:23:28 <Cale> Well, a lot of the time if you're trying to pick a permutation or subset-permutation of some things, select is what you want.
19:23:46 <dmwit> select xs = [(h, reverse b ++ e) | (b,h,e) <- zippers xs] -- which shows exactly where the extra cost of select comes from, in fact
19:23:57 <dmwit> Cale: In that case, eliding the reverse is fine.
19:26:44 <dmwit> I guess the sharing is sadly lost whether you use zippers or select. So darn.
19:26:57 <MarcelineVQ> why does State tend to be s -> (a,s) instead of s -> (s,a)
19:27:06 <dmwit> MarcelineVQ: Ugh, why indeed.
19:27:28 <dmwit> There's no good reason that I've ever heard. It's just how the first person did it and then we've had it ever since.
19:28:40 <Cale> That's just a mistake that was made in MTL a long time ago, yeah
19:28:54 <Cale> People weren't thinking of (,) s as a functor back then
19:29:05 <MarcelineVQ> I'm looking at a fresh implementation where they define State's Functor instance, and use a helper in a where to map over the first tuple spot, and it's like, when you were writing that helper you didn't stop for a second and wonder hehe
19:29:29 <MarcelineVQ> 'What if I just swap these in the first place'
19:29:41 <MarcelineVQ> But I'm asking here just in case there was a good reason after all
19:31:32 <Solonarv> if it were s -> (s, a) GHC could even derive the functor instance all by itself!
19:32:44 <MarcelineVQ> why that's positively silly
19:33:00 <nshepperd> ghc can derive the functor instance either way
19:33:01 <Cale> Changing transformers/mtl would obviously be too disruptive at this point, but there doesn't appear to be any particularly good reason why someone couldn't just make a new monad library which gets these things right.
19:33:14 <Cale> But no, we must wallow in our tiny errors forever
19:33:39 <MarcelineVQ> Cale: are there other things that come to mind?
19:34:04 <Cale> Honestly, it's not a whole lot
19:34:11 <Cale> ListT is dumb
19:34:14 <nshepperd> (it uses the built in fact that (,) is a bifunctor, not the Functor instance for (,))
19:34:24 <Solonarv> nshepperd: oh, nice! what other bi-(tri-...)functors does that work for?
19:34:59 <nshepperd> probably just all of the tuples, since they're built into ghc
19:35:42 <nshepperd> maybe the new fancy unboxed sums
19:35:59 <Solonarv> uhh, https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ is a 404, what's up with that?
19:36:19 <Cale> it's not
19:36:34 <MarcelineVQ> itis
19:36:44 <Cale> wat
19:36:47 <Cale> I can load it...
19:36:52 <MarcelineVQ> probably just a hiccup along a specific route
19:37:07 <Welkin> Solonarv: you've been man-in-the-middled
19:37:08 <Cale> bad cache maybe, yeah
19:41:24 <Solonarv> checked the docs - indeed, only tuples and -> are treated specially
19:42:24 <glguy> That URL was 404 for me, too. I purged it from the cache; it should work for you now, Solonarv.
19:42:42 <glguy> (at least it started working for me)
19:43:13 <Solonarv> yup, that fixed it
19:53:06 <dmwit> :t uncurry
19:53:07 <lambdabot> (a -> b -> c) -> (a, b) -> c
19:53:17 <dmwit> the catamorphism for tuples :3
20:08:40 <Cale> glguy: now I'm getting a 404 for https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html
20:08:48 <Cale> glguy: but not for the main user's guide page
20:09:01 <glguy> Now?
20:09:04 <sicklorkin> dmwit: works here
20:09:07 <Welkin> who broke haskell.org, again?
20:09:10 <sicklorkin> Cale: works ehre
20:10:22 <Cale> now it's working
20:21:07 * hackage servant-auth-client 0.4.0.0 - servant-client/servant-auth compatibility  https://hackage.haskell.org/package/servant-auth-client-0.4.0.0 (domenkozar)
20:36:28 <olligobber> Is there anything of kind * -> * that isn't a functor? I can't think of any right now
20:36:43 <dibblego> not in the Data.Functor(Functor) sense
20:37:51 <glguy> olligobber: newtype Predicate a = P (a -> Bool)
20:38:34 <olligobber> glguy, thanks
20:39:02 <glguy> Or Data.Set's Set
20:39:22 <olligobber> oh yeah, I should remember that from all the times I tried to use it as a functor
20:57:14 <pomme> hello, I'm getting an error from stack build that I don't understand:
20:57:28 <pomme> --  While building custom Setup.hs for package xyz using:       /home/xxx/.stack/setup-exe-cache/x86_64-linux/Cabal-simple_mPHDZzAJ_2.2.0.1_ghc-8.4.3 --builddir=.stack-work/dist/x86_64-linux/Cabal-2.2.0.1 build lib:xyz exe:xyz-exe --ghc-options " -ddump-hi -ddump-to-file -fdiagnostics-color=always"     Process exited with code: ExitFailure 1
20:57:44 <pomme> I'm not sure why this is exiting with ExitFailure 1.  Has anyone seen this before?
20:58:37 <kadoban> pomme: Anything before that? What about with -v ?
20:58:56 <dibblego> oh sorry, I misread
20:59:11 <dibblego> olligobber: yes, there are also things like newtype Endo a = Endo (a -> a)
20:59:55 <olligobber> dibblego, ty
21:00:17 <dibblego> basically, anywhere that the type parameter appears in negative position
21:00:20 <pomme> kadoban: I don't see any errors before that when I try stack build -v.  I see a lot of green debug messages...
21:00:49 <pomme> Right before the -- While building custom Setup.hs, I see
21:01:00 <pomme> @(src/Stack/Build/Execute.hs:406:17)
21:01:00 <lambdabot> Unknown command, try @list
21:01:32 <pomme> src/Stack/Build/Execute.hs:406:17
21:11:23 <kadoban> Hm, not sure.
22:07:08 * hackage pandoc-citeproc 0.16.1.2 - Supports using pandoc with citeproc  https://hackage.haskell.org/package/pandoc-citeproc-0.16.1.2 (JohnMacFarlane)
22:10:07 * hackage texmath 0.11.2.2 - Conversion between formats used to represent mathematics.  https://hackage.haskell.org/package/texmath-0.11.2.2 (JohnMacFarlane)
22:32:20 <dmwit> data NotAFunctor a where It'sUnit :: NotAFunctor ()
23:07:13 <neoscapebamf9999> asdasd
23:08:04 <MarcelineVQ> fgsfds
