00:13:12 <hololeap> what's the best intuition for the use of the Store comonad?
00:13:33 <dminuoso> hololeap: It's a container with a current positoin
00:14:10 <hololeap> that part seems obvious, but why should i care?
00:14:23 <dminuoso> hololeap: What do you mean?
00:14:34 <dminuoso> hololeap: Oh do you mean the comonad instance?
00:14:37 <dminuoso> hololeap: It
00:15:00 <dminuoso> hololeap: The store comonad could be seen as a generalization of convolution.
00:15:32 <dminuoso> Think of it as an "fmap" where the function gets to not just see the point its mapping over, but the neighbourhood too.
00:18:21 <hololeap> right, so the `peeks` function, for instance, allows it to "see" given a relative position, specified by the function (f :: s -> s)
00:18:55 <hololeap> am i on the right track?
00:21:45 <hololeap> so i can create local calculations that take into account neighbors, and map those calculations everywhere using `extend`
00:22:33 <hololeap> does that basically sum it up, or is there more to it than that?
00:27:17 <sicklorkin> quit
00:34:59 <dminuoso> hololeap: pretty much, yes.
00:36:04 <dminuoso> hololeap: Note that there's some laws attached to it.
00:37:38 <dminuoso> hololeap: Essentially `extract` acts as a left and right identity wrt t =>=, and you get associativity `extend f . extend g = extend (f . extend g)`
00:37:48 <dminuoso> (Where =>= is just the cokleisi composition)
00:42:26 <dminuoso> hololeap: The two best examples of the store comonad is image filters (e.g. gaussian blur) and many (all?) cellular automata like Conways Game of Life.
00:43:17 <dminuoso> (If you look closer, lenses have a deep relationship with the store comonad too)
00:54:42 <merijn> ugh, the cpu package apparently only has endianness conversions for WordX. Anyone know where I'd find those for IntX?
00:59:57 <__monty__> merijn: data-endian has some.
01:06:14 <koz_> dminuoso: Could you elaborate on the image filter example?
01:10:33 <dminuoso> koz_: A gaussian blur is just convolving an image with the gaussian function.
01:15:22 <dminuoso> koz_: One way to implement is, is to calculate a kernel weighted by the gaussian function. This is just a matrix that may be clamped down to say 4x4 - image folks call this type of matrix a "kernel". For each pixel you put that matrix centered ontop, weigh each pixel/neighboring pixel and you sum them up.
01:15:46 <dminuoso> (Im just giving you a very rough sketch here)
01:15:50 <koz_> OK.
01:16:13 <dminuoso> Oh. 4x4 is a bad example since you want it centered. So 3x3 or maybe 5x5
01:16:15 <dminuoso> :P
01:17:34 <dminuoso> And it turns out, that by selecting different kernels and border behaviors you can do an awful lot of image filters.
01:18:18 <koz_> How is that a comonad though?
01:18:22 <tdammers> the "kernel" terminology comes from DSP, actually
01:18:29 <koz_> Like, what is extract and extend in this case?
01:18:40 <tdammers> you use the same trick for, say, audio filters (only it's just one axis instead of two)
01:18:49 <dminuoso> In Haskell you would encode this as some parametrized function that produces some `Store Coord (Maybe Pixel) -> Maybe Pixel
01:19:04 <dminuoso> tdammers: Ah cool I did not know this. :)
01:19:27 <dminuoso> koz_: ^- and this function you extend with.
01:19:41 <dminuoso> So you might have some:
01:20:05 <dminuoso> Kernel -> BorderBehavior -> Store Coord (Maybe Pixel) -> Maybe Pixel
01:20:17 <dminuoso> For a gaussian blur you would pick a suitable kernel (and a suitable border behavior)
01:20:29 <dminuoso> And then extend your (store encoded) image with the resulting cokleisli arrow.
01:20:54 <tdammers> specifically, filters like these are often called "Finite Impulse Response" filters, because the response to an impulse (a single-sample spike) is going to be of finite length: it is limited to the size of the filter kernel, i.e., a 100-sample kernel cannot produce any nonzero output from a spike beyond 100 samples
01:21:26 <tdammers> as opposed to IIR (Infinite Impulse Response) filters, which involve feedback / recursion, and are thus capable of infinite responses
01:21:54 <tdammers> (although you practically always want to select their parameters such that the response is finite, or at least converges)
01:26:24 <dminuoso> koz_: https://i.stack.imgur.com/bRN2c.jpg
01:26:39 <dminuoso> koz_: This is a visual representation of it. :)
01:26:52 <koz_> Ah, I think I see now.
01:27:15 <koz_> Thanks, that's actually a good motivating 'why the (extensible) eff we care about comonads' example.
01:28:11 <dminuoso> koz_: Careful though, this is not "comonads"
01:28:17 <dminuoso> This is just the "store comonad instance"
01:28:28 <dminuoso> Comonad is just an abstract interface.
01:29:15 <koz_> It's still an example of a use of that interface.
01:29:21 <koz_> (even if it's in a more specific context)
01:29:41 <dminuoso> koz_: Comonad wouldn't be useful if there was only one instance for it.
01:29:48 <koz_> Indeed.
01:29:58 * koz_ is still trying to grok the comonad.
01:31:36 <dminuoso> koz_: It's basically when you can compose arrows of the shape (f a -> b) -> (f b -> c) -> f a -> f c in some nice manner.
01:32:21 <dminuoso> Oh that last f there was wrong.
01:33:09 <koz_> It should be (f a -> b) -> (f b -> c) -> f a -> c?
01:33:11 <dminuoso> Yes.
01:33:28 <dminuoso> Just like you could think of monads as the set of functors `f` where you get to compose `(a -> f b) -> (b -> f c) -> a -> f c`
01:33:34 <koz_> Yeah.
01:33:37 <dminuoso> (Plus identity and associativity)
01:33:44 <koz_> :t (>=>)
01:33:46 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
01:33:51 <koz_> :t (=>=)
01:33:53 <lambdabot> error:
01:33:53 <lambdabot>     • Variable not in scope: =>=
01:33:53 <lambdabot>     • Perhaps you meant one of these:
01:33:57 <koz_> :(
01:34:06 <dminuoso> % import Control.Comonad
01:34:06 <yahb> dminuoso: 
01:34:11 <dminuoso> % :t (=>=)
01:34:12 <yahb> dminuoso: Comonad w => (w a -> b) -> (w b -> c) -> w a -> c
01:34:24 <koz_> If >=> is called 'fish', what do we call =>=?
01:34:39 <dminuoso> koz_: the first is called kleisli composition, the second is called cokleisli composition
01:34:51 <Taneb> koz_: cofish
01:34:51 <koz_> Oh yeah, I know those terms.
01:34:55 <koz_> LOL
01:34:58 <dminuoso> Taneb: haha :
01:35:00 <phadej> koz_: `lure`
01:35:01 <koz_> 'cofish' is the name I will now use.
01:35:16 <phadej> (not really)
01:35:22 <koz_> phadej: 'Lure' is good too, but cofish wins.
01:35:49 <dminuoso> koz_: I think in a general sense `w` represents context, where `m` represents effect.
01:36:10 <koz_> dminuoso: Yeah, I keep hearing that, but I guess it's just not in my brain in the same way monads are.
01:36:18 <koz_> I'll just give it a bit of time.
01:37:15 <koz_> Is there something that is both a monad and a comonad?
01:37:26 <dminuoso> koz_: NonEmpty, Tree
01:37:33 <dminuoso> Oh wait. NonEmpty at least.
01:37:40 <dminuoso> Yes, Tree too.
01:37:48 <koz_> NonEmpty is a monad the same way [] is, right?
01:38:01 <dminuoso> koz_: Yes.
01:38:05 <Zvpun> Out of curiosity, can (a+b, c+d) be written as something like `(,) (+) (a,b) (c,d)`?
01:38:23 <koz_> Zvpun: I think Biapplicative can help here.
01:38:51 <koz_> dminuoso: And comonad with head and diagonalization, right?
01:39:22 <dminuoso> koz_: what is diagonalization?
01:39:51 <dminuoso> koz_: By the way, have you ever heard that "all monads arise from an adjunction"
01:40:07 <koz_> dminuoso: I have, but as I don't understand what adjunctions are, this hasn't told me much.
01:40:34 <dminuoso> koz_: It's a relationship that is weaker than equivalence.
01:40:37 <dminuoso> Between functors.
01:40:53 <koz_> I hear there are also left and right adjunctions.
01:41:29 <koz_> Or am I getting my wires crossed?
01:42:21 <dminuoso> koz_: Adjunctions are asymmetric.
01:42:55 <dminuoso> koz_: Anyway, the details arent that important.
01:43:06 <koz_> One of these days, I will read enough category theory to actually understand all these terms folks here sling.
01:43:07 <dminuoso> koz_: What is cool is that Store and State are very deeply related.
01:43:14 <dminuoso> Store used to be called Costate.
01:43:25 <koz_> Yeah, I heard Edward mention this a few dozen times in his very unique way.
01:44:34 <dminuoso> koz_: The two functors in play here are: ((,) a) and ((->) a)
01:46:22 <dminuoso> koz_: There's an adjunction - and it turns out if you compose them one way you get a monad. If you compose them the other way, you get a comonad.
01:47:00 <koz_> Also, I recall that you can get both lenses and recursion schemes out of (certain) comonads.
01:47:35 <dminuoso> data State s _ = State (s -> (s, _))
01:47:51 <dminuoso> data Store s _ Store (s, (s -> _))
01:47:54 <dminuoso> data Store s _ = Store (s, (s -> _))
01:50:51 <merijn> shapr: So, after trying to use network-data to parse my own generated packets I've concluded that package is buggy anyway as it's parsing things wrong
01:50:55 <dminuoso> koz_: lenses are just coalgebras for Store.
01:51:56 <dminuoso> type Lens a b = Coalg (Store b) a
01:52:18 <koz_> Coalg is what again?
01:53:33 <dminuoso> type Coalg f a = a -> f a
01:54:13 <koz_> So Lens a b = a -> Store b a ?
01:54:22 <koz_> Sorry wait, wrong order.
01:54:36 <koz_> Lens a b = b -> Store b a ?
02:02:58 <delYsid> koz_: Lens a b = a -> Store b a
02:05:20 <dminuoso> koz_: Now if you look at lens you will see an odd looking type. It turns out that `data Store s a = Store { pos :: s, peek :: s -> a }` has an equivalent representation
02:07:05 <dminuoso> data Pretext s a = Pretext { runPretext :: forall f. (s -> f s) -> f t } -- The equivalent you can try and figure out if you like.
02:07:35 <Taneb> dminuoso: you need a Functor constraint on the f there
02:07:50 <dminuoso> Taneb: Gargh. Yes.
02:08:03 <dminuoso> data Pretext s a = Pretext { runPretext :: forall f. Functor f => (s -> f s) -> f t } 
02:08:09 <Taneb> And also t's came out of nowhere
02:08:15 * dminuoso gives up
02:08:44 <dminuoso> data Pretext s a = Pretext { runPretext :: forall f. Functor f => (s -> f s) -> f a } 
02:08:48 <dminuoso> There we go!
02:09:21 <dminuoso> If you then consider the Lens alias from the lens library: type Lens s t a b = forall f. Functor f => (a -> f b) -> s -> f t 
02:10:17 <dminuoso> I really do give up, Im not doing this right.
02:55:03 <Zvpun> How would one refactor `if test (f x) then Just (f x) else Nothing`?
02:56:14 <Zvpun> I have my own `toMaybe :: Bool -> a -> Maybe a` but wonder if it could be done with predefined functions.
02:56:37 <Taneb> let r = f x in r <$ guard (test r) 
02:57:08 <Ariakenom> ^ pure r
02:58:35 <Taneb> :t (<$)
02:58:37 <lambdabot> Functor f => a -> f b -> f a
02:58:46 <Taneb> Ariakenom: no??
02:59:02 <Taneb> :t guard
02:59:03 <lambdabot> Alternative f => Bool -> f ()
02:59:39 <Ariakenom> yeah you're right
03:02:14 <fen> data Free2 f a b = Free2 (f (Free2 f a b)) | Pure1 a | Pure2 b
03:02:44 <Zvpun> ty
03:03:55 <fen> type Cycle f a = Zipper ((\a -> Free2 (Zipper f) a (Cycle f a)) a)
03:04:43 <fen> type Cycle f a = Zipper (\a -> Free2 (Zipper f) a (Cycle f a)) a
03:05:38 <fen> can try to update the inner Cycle to be a navigated version of the whole thing
03:07:12 <fen> which makes a cyclic reference to itself. ie the cyclic nodes contain a version with these nodes inhabited
03:08:33 <fen> difficult to unfold
03:13:29 <fen> maybe the only way is to unfold a tree and then join the branches to make the cycles
03:17:02 <fen> also not sure if there is a way to ensure at type level that the `f' contains cyclic nodes corresponding to other cycles 
03:17:18 <fen> like, so they always appear in pairs
03:18:29 <fen> so this is something the unfolding process, or function over a tree would have to ensure
03:20:26 <fen> the problem with unfolding these cyclic trees is making reference to parts that have not yet been unfolded
03:22:18 <fen> both the state being used to do the unfolding, and the accumulating cyclic tree would be updated each time a cyclic node was made
03:23:02 <fen> so that the cyclic reference could be provided when it was available, possibly with a numeric index like a hashreference
03:23:23 <fen> no idea how to do this
03:24:17 <fen> to return a datatype that can be updated at a previous location
03:24:34 <fen> something like \a->[1,2,3,a,4,5,6, ...]
03:25:13 <fen> dont want to have to navigate back to the previous location if thats expensive
03:25:26 <fen> might all fusion up though..
03:30:20 <Henson> what's the name of the function that discards the first argument?  You use it in a map to ignore the item being passed in.  Like a lambda function with "\_ -> foo"
03:30:37 <lemmih> Henson: const
03:30:48 <Henson> lemmih: ahhh, that's it.  Thank you.
03:31:36 <lemmih> @pl \x _ -> x
03:31:36 <lambdabot> const
03:32:52 <fen> is that what shift/reset is for?
03:35:55 <Henson> lemmih: do you know where lambdabot gets its information?  Is there a resource a could ask a similar question without coming on here and asking lambdabot?  Also, is there a manpage for lambdabot's commands?
03:36:40 <__monty__> Henson: There's "pointfree" on hackage.
03:36:52 <Henson> resource a could ask -> resource I could query
03:36:54 <lemmih> Henson: http://pointfree.io/
03:37:50 <Henson> lemmih, monty: thank you!
03:38:48 <bwe> Has someone spotted small multi-build docker images for stack organised Haskell projects (along the lines of build on stack-build image, run on alpine linux) in the wild yet?
03:39:08 * Henson laughs at the lambda bot mascot's picture
03:40:06 <__monty__> What mascot?
03:41:12 <Henson> __monty__:  https://wiki.haskell.org/Lambdabot
03:41:31 <Henson> __monty__: a very tired-looking South-Park style angel
03:44:07 * hackage pairing 0.2 - Optimal ate pairing over Barreto-Naehrig curves  https://hackage.haskell.org/package/pairing-0.2 (sdiehl)
03:52:49 <fen> anyone can help give a simple example using http://hackage.haskell.org/package/transformers-0.5.6.2/docs/Control-Monad-Trans-Cont.html#g:2 
03:56:44 <fen> a simple example could be eg \s -> let (x,y) = (last y,unfold' x s)
03:56:54 <fen> in y
03:57:54 <fen> you want to unfold a list like \x -> [1,2,3,x,4,5,6,x,7,8 ...]
03:57:58 <julianleviston> there are examples in the package: http://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Cont.html#g:4
03:59:17 <fen> wasnt sure if they covered this case, like, if its even the correct thing to use
03:59:37 * hackage deque 0.3.1.1 - Double-ended queues  https://hackage.haskell.org/package/deque-0.3.1.1 (NikitaVolkov)
03:59:50 <fen> wasnt clear how to addapt to this example
06:43:52 <plakband> Can anyone explain why this Haskell code: https://pastebin.com/nJFSAjxM and this C code: https://pastebin.com/zMymWG1P behave differently when piped through `cat`? The Haskell code exits upon ^C, while the C continues filling stderr.
06:45:48 <merijn> plakband: You're not checking error conditions in the C code, thus noticing it's broken
06:46:04 <merijn> plakband: ^C in a pipeline sends the signal to every process in the pipeline (i.e. also to cat)
06:46:17 <merijn> plakband: cat dies, the pipe is closed and all writes to the pipe return an error
06:46:40 <merijn> plakband: You are not checking the return code of fprintf, thus silently ignoring the error and continuing the loop (filling up stderr)
06:46:58 <merijn> plakband: The Haskell code will trigger an exception upon writing to the broken pipe, exiting the processes
06:49:02 <plakband> merijn: I see, thanks! Do you know what kind of exception/where it's documented?
06:49:08 * hackage haskus-system-build 1.1 - Haskus system build tool  https://hackage.haskell.org/package/haskus-system-build-1.1 (SylvainHenry)
06:49:56 <merijn> plakband: I don't think things like hPuStrLn document all the IO exceptions (sadly). You want to look in System.IO.Error
06:50:51 <plakband> merijn: Alright, I'll give it a look. Thanks again.
06:51:03 <dminuoso> Shouldn't it be some ResourceVanished?
06:51:09 <merijn> Possibly
06:54:46 <geekosaur> its more complex than that here. the C program, unless told otherwise, will be aborted with SIGPIPE; you only get the write error if you explicitly ignore the signal
06:56:08 <merijn> geekosaur: But it does explicitly ignore it
06:56:11 <geekosaur> last I checked, haskell's runtime handles ^C and SIGPIPE the same way, and that way means they may not be processed until the next allocation
06:56:15 <merijn> geekosaur: As does the Haskell code
06:59:50 <merijn> There's no library for sliding window computations over vectors, is there?
07:07:37 <drninjabatman> hello, under what circumstances are monadic bind operators inlined and can I force it in specific do blocks?
07:08:49 <fr33domlover> Hi people! So, I looked into sending email over SMTP in pure Haskell. Some packages are deprecated, some don't support TLS, some have too limited constraints on dependency versions. The closest thing I found is HaskellNet, which has 1 issue: It sends HELO and not EHLO, and technically authentication and TLS only work for the latter, so some MTAs (such as Exim, idk about Postfix) reject those features unless
07:08:50 <fr33domlover> you use EHLO. I didn't find reports of bugs about this though hmmm
07:09:01 <fr33domlover> Just wanting to share with you what I found ^_^
07:09:47 <fr33domlover> 1 package does use EHLO, smtp-mail-ng, but its dependency version constraints are very strict, can't really use it without tweaking them
07:11:22 <Ariakenom> drninjabatman: I don't think there's a way to force it. Any particular reason you're looking into it?
07:16:13 <drninjabatman> Ariakenom: I am looking at the performace report and its more than 50% the ListT (from the list-t package) bind operator
07:19:30 <dminuoso> drninjabatman: Can you show the full profiler output (put it on some pastie/gist website?)
07:25:50 <drninjabatman> dminuoso: https://gist.github.com/39569a289f85c408b3f2fd489073b8c6
07:31:44 <merijn> I don't suppose there's a Bits instance for ByteString?
07:32:16 <Taneb> Nope
07:41:51 <dmwit> merijn: No, but UArray _ Bool is bit-packed.
07:42:24 <merijn> dmwit: So is bitvec, but it's bit-packed the wrong way, which is my problem :)
07:43:00 <merijn> I think the solution is just to use a mutable storable vector and manually setting all the bits
07:43:32 <Taneb> merijn: what are you trying to achieve here?
07:43:34 <merijn> Not the most efficient way to do things, but I can't patch everything to make it work
07:44:43 <merijn> Taneb: I'm generating data for several network protocols, but none of the existing serialisation libraries nicely support sub-byte serialisation which all those protocols need
07:45:35 <merijn> Taneb: So as a hack I'm just building the data by concatenating bit vectors. Sadly, however bitvec assumes bit 0 = least significant bit, but all the networking assumes bit 0 = most significant bit
07:47:07 <shapr> merijn: have you seen the oddword stuff in RTP? 
07:47:19 <shapr> merijn: https://code.xkrd.net/voip/rtp/blob/master/src/Data/RTP.hs#L185
07:47:54 <merijn> shapr: no?
07:48:35 <shapr> that RTP.hs shows how to do sub-byte de/serialization 
07:48:52 <merijn> shapr: That'd involve having to duplicate all that boilerplate, though
07:49:23 <merijn> At least, I dunno where Data.Word.Odd comes from
07:49:42 <shapr> http://hackage.haskell.org/package/OddWord
07:50:19 <merijn> shapr: Right, but that doesn't include any serialisation
07:50:29 <shapr> that's true
07:51:36 <merijn> Anyway, converting the stupid way is easy, just slow
07:51:42 <merijn> But I don't care about performance
07:52:17 <merijn> I just loop over the bit vector and for every index to quotRem 8, and set the bit at the right index of a mutable Word8 vector
07:54:05 <csaurus> I have a question about conduits if anyone is familiary with them. Is it possible to fold over elements of a stream while still yielding them downstream? Like a conduit that counts the number of items in the stream and yields each one. I tried using foldM, but the stream seems to stop whenever it goes through that section of the pipeline
07:54:07 <shapr> merijn: there's also http://hackage.haskell.org/package/bits-0.5.1/docs/Data-Bits-Coding.html#t:Coding
07:55:11 <merijn> csaurus: Sure
07:55:31 <merijn> csaurus: It's just that most of the default folds in conduit don't do that
07:56:00 <csaurus> merijn: ah, so should I try to implement a version using primitives?  
07:56:48 <reallymemorable> Does anyone have any thoughts on what the issue with my Quandl script might be?  I get that it is super basic, but I am very new to this and don't know how else to seek a solution.  I have even tried using the exact parameters given in the Hackage docs, but I still get `Nothing` back: https://stackoverflow.com/questions/54964875/cant-understand-why-my-haskell-api-call-script-returns-nothing
07:57:04 <merijn> csaurus: Have a look at things like mapAccumWhile
07:57:25 <merijn> csaurus: Also, note the type of conduit's foldM
07:57:56 <merijn> csaurus: "foldM :: Monad m => (a -> b -> m a) -> a -> ConduitT b o m a" <- note the 'o' output type. Since there is no 'o' anywhere you can conclude it never yields
07:58:45 <merijn> csaurus: But yes, worst case scenario you'll have to roll something yourself
07:59:11 <csaurus> merijn: Thank you, that's a good insight. I see what you're saying, there's nothing to produce an o anywhere
07:59:34 <csaurus> merijn: and thank you for the mapAccumWhile tip, I'll see what I can do with that
08:02:24 <merijn> mmm, what's the difference between new and unsafeNew with vector? unsafeNew says the memory is not initialised, but I don't see how "new" would initialise the memory?
08:02:28 <hololeap> reallymemorable: quandl-api hasn't been updated in ~4 years. it's possible that it no longer works correctly
08:02:38 * hackage haskus-utils-variant 2.6 - Variant and EADT  https://hackage.haskell.org/package/haskus-utils-variant-2.6 (SylvainHenry)
08:03:01 <dmwit> merijn: http://hackage.haskell.org/package/NumLazyByteString-0.0.0.1/docs/Data-ByteString-Lazy-Num.html has a Bits instance =P
08:04:42 <reallymemorable> hololeap: Ah ok.  
08:09:14 <shapr> reallymemorable: looks to me like even the free DataSets require an API key
08:09:30 <reallymemorable> shapr: I have an API key that I pay for
08:09:38 * hackage haskus-utils-types 1.4 - Haskus types utility modules  https://hackage.haskell.org/package/haskus-utils-types-1.4 (SylvainHenry)
08:09:38 <reallymemorable> I tried using that as well.
08:10:12 <shapr> reallymemorable: are you trying to learn Haskell? or do you have some specific quandl need? or what?
08:10:39 <reallymemorable> I am trying to learn haskell and trying to do this quandl script in the process as some friends need it
08:10:52 <Solonarv> merijn: perhaps 'new' fills the memory with zeroes?
08:11:36 <shapr> reallymemorable: if you want to learn Haskell, you probably want to start smaller with cis194 or a Haskell book
08:11:57 <merijn> Solonarv: Maybe, but it doesn't specify!
08:12:07 * Solonarv is browsing the source
08:12:44 <Solonarv> ah, I found this comment:   -- initialization is unnecessary for boxed vectors
08:12:54 <Solonarv> https://hackage.haskell.org/package/vector-0.12.0.2/docs/src/Data.Vector.Mutable.html#line-84
08:13:00 <Solonarv> so they are the same for boxed vectors
08:13:13 <shapr> reallymemorable: I tried the quandl package but even for datasets that do exist I get nothing
08:13:25 <merijn> Solonarv: Storable isn't boxed, though
08:13:49 <Solonarv> oh you were looking at storable vectors, nvm
08:15:12 <reallymemorable> hololeap: i think the Hackage was just out of date
08:15:19 <reallymemorable> I cloned from GitHub and it worked
08:16:37 <Solonarv> for storable vectors it looks like 'new' zeroes out the vector and unsafeNew doesn't
08:16:48 <jedai> reallymemorable: For sure, I looked ar the source in Hackage (it's really short in fact) and apparently it still used the v1 of the API, the example on Quandl site are with v3 of the API ...
08:17:54 <Solonarv> merijn: the 'new' and 'unsafeNew' functions exposed from each Data.Vector.*.Mutable module are aliases to the same functions from Data.Vector.Generic.Mutable
08:19:02 <Solonarv> where roughly: new sz = unsafeNew sz >>= \v -> basicInitialize v >> return v
08:19:43 <jedai> reallymemorable: though apparently even the github still use v1 but at least the last commit date back only to 2017, not 2015
08:19:56 <Solonarv> basicInitialize is a class method; for boxed vectors, it does nothing; for storable vectors, it zeroes out the vector
08:21:03 <Solonarv> if you unsafeNew a storable vector I think it's just filled with garbage
08:23:12 <Solonarv> merijn: ^ got all that?
08:23:17 <merijn> Yeah
08:23:35 <merijn> Solonarv: I was pretty much guessing that's what it does, it's just sloppy that it's not documented
08:23:46 <Solonarv> indeed
08:24:09 <Solonarv> and it takes quite some jumping around the source to find out, because there is a lot of indirection
08:25:34 <merijn> OTOH, vector is freaking amazing
08:25:51 <merijn> The more I use it, the more I realise I will never again need C :p
08:26:05 <Solonarv> yeeee vector is awesome
08:26:39 <unyu> Is Vector sufficient for your unsafe programming needs? :-p
08:27:03 <reallymemorable> jedai: I
08:27:04 <Solonarv> you can slosh raw pointers around in Haskell too if you really want to :p
08:27:09 <merijn> unyu: Not quite
08:27:18 <reallymemorable> I'm not experienced enough to know why, but I was able to run my script with GitHub
08:27:44 <merijn> unyu: But I just add more MagicHash and ForeignPtr to vector when I want it more unsafe: https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/src/Utils.hs
08:28:02 <unyu> :-)
08:28:29 <jedai> reallymemorable: As long as it works :) (Though I think updating this code so that it works with v3 would not be too hard a project for someone with a bit of time on his hands)
08:28:30 <merijn> I mean, if you're not using all the unsafe* functions possible from vector, what are you even doing?!
08:28:52 <reallymemorable> I opened an issue on github
08:30:12 <Solonarv> merijn: good one :D
08:32:16 <tdammers> I settle for nothing less than 'accursed and unutterable'
08:32:17 <unyu> merijn: I don't think I could program like that, mostly because I don't have a mental machine model of Haskell. (Where “machine” means “physical machine”, not “lambda calculus evaluator” or “graph reduction” or wahtever.)
08:33:08 <merijn> unyu: Why would you need one to code that, though?
08:34:10 <unyu> To figure out what the program does? Else, what exactly do “pointer” and “cast” mean in this case?
08:35:31 <merijn> unyu: Ptr is just a more sane version of C's pointer and machine model, though
08:36:09 <unyu> merijn: In what sense is it saner? How does this interact with garbage collection?
08:36:27 <merijn> Because where C's machine model introduces all sorts of abstract nonsense with regards to strict aliasing, etc. Ptr does not, it just models a straight up linear address space that you can grab bytes from and insert into
08:36:40 <unyu> Okay, that much is good.
08:37:05 <Solonarv> as for the interaction with garbage collection: you can't take the address of some existing value, so it's not particularly complicated.
08:37:24 <merijn> unyu: How it interacts with the GC depends on how you got the Ptr. ForeignPtr has an associated "free" that gets run when the last copy gets GCed
08:37:43 <merijn> unyu: Regular pointers don't interact with GC at all. If you allocated them, you better make sure you clean them up
08:37:48 <unyu> Ah, so it is like a pointer / finalizer pair?
08:37:58 <merijn> unyu: ForeignPtr is a pointer + finalizer, yes
08:38:13 <unyu> Okay, that is actually pretty sensible.
08:38:20 <Solonarv> Ptr is basically just a raw memory address
08:39:10 <merijn> unyu: So ForeignPtr is just gives you a sequence of bytes and doesn't care what's in there or what the bounds are (pretty much like C...), but since there's no strict aliasing or any limitations on type punning GHC will just let you do whatever
08:39:24 <unyu> That is nice.
08:39:51 <unyu> “Like C's machine model but without the complexity” is a good value proposition. :-)
08:40:09 <merijn> unyu: Storable defines a concrete memory layout of a datatype, so you can use it to grab stuff from a pointer, but if you cast the pointer to a different type and use that type's Storable instance to type-pun
08:40:20 <merijn> unyu: Yes
08:40:47 <merijn> unyu: Doing away with the pretense that we're not dealing with a huge linear address space you can arbitrarily fuck with makes things much easier :p
08:40:57 <unyu> Indeed.
08:41:15 <Solonarv> also, you're not actually forced to use Storable for your datatypes, you can just fiddle with bytes directly :>
08:41:20 <arjen-jonathan> Question; I have a data type that can contain STRefs. I parse it from string, after which it is pure. Then I want to use it in my stateful computation. 
08:41:45 <arjen-jonathan> How do I type this?
08:42:05 <Solonarv> You don't; you can't "leak" STRefs out of an ST computation
08:42:20 <Solonarv> (or rather, you can, but you can't do anything with them unless you use unsafe functions)
08:42:30 <merijn> unyu: So ByteString wrapping "ForeignPtr Word8" makes it pretty straightforward to rip the internals out and alias them into vectors as you please
08:42:31 * ski thinks it's not quite clear what arjen-jonathan wants to do
08:42:51 * dminuoso thinks ski may be correct
08:43:02 * Solonarv agrees with dminuoso
08:43:34 <arjen-jonathan> Right, we have a term with raw variables as a result from parsing. Then I want to traverse the term and replace raw variables with STRefs. 
08:43:38 <ski> what do you mean, you parse `STRef's from `String' ? do you mean that you have some kind of graph serialized, and you implement graph nodes (when parsing) by allocating `STRef's ?
08:44:11 <arjen-jonathan> Actually I 'd like the parsing to be pure. 
08:44:19 <Taneb> arjen-jonathan: there's nothing preventing you having something like "Map String (STRef s)"
08:44:19 <arjen-jonathan> And do the conversion afterwards.
08:44:20 <dminuoso> arjen-jonathan: pure with respect to what exactly?
08:44:28 <unyu> is this data structure a syntax tree of some sort?
08:44:30 <arjen-jonathan> As in not in ST.
08:44:40 <dminuoso> arjen-jonathan: You can't produce STRef outside of ST.
08:45:00 <arjen-jonathan> dminuoso: I don't want to. The parser just parses string names.
08:45:03 <ski> (and then, what does "after which it is pure" mean ? do you mean you only need mutability when constructing the data structure, but not later (so some kind of "freeze" might be desirable) ? but how would that then mesh with "Then I want to use it in my stateful computation." ?)
08:45:06 <arjen-jonathan> The conversion happens in ST.
08:46:06 <dminuoso> I think arjen-jonathan has undergone a complex thought process and doesn't let us in on the details. Either we need to know more, or you need to reduce your problem to a small testcase.
08:46:14 <arjen-jonathan> ski: quite the inverse. the initial construction should be pure. Then I want to take the data into ST and might start convert some nodes to ST refs.
08:46:39 <Taneb> arjen-jonathan: if I understand you correctly, that's absolutely possible, as long as you make sure you use the same ST monad for both the assignment of refs and the actual use
08:47:10 <ski> s/ST monad/ST thread/
08:47:21 <Taneb> ski: is that the terminology?
08:47:49 <ski> i think in the paper, they talk about "state threads", where each call to `runST' gives a distinct state thread
08:48:44 <dminuoso> arjen-jonathan: So have some `data FooWithoutST = ...` and some `data FooWithSTRef`, then you can have your `parse :: ... FooWithoutST`, and some `wobble :: FooWithoutST -> ST (FooWithSTRef)` and things?
08:48:44 <ski> (but on second thought, i suppose "ST monad" wouldn't be that bad either, since for each distinct `s', you get a distinct monad `ST s'. so i suppose what you said is also fine, sorry for interjecting)
08:49:08 <Taneb> (yeah, that was what I was trying to evoke. No worries :) )
08:49:30 <arjen-jonathan> dminuoso: That'd work, but I was hoping to reuse the same datatype
08:49:50 <dminuoso> Oh I see. So in essence you are asking to traverse some data structure and somehow modify some type in place?
08:50:03 <ski> arjen-jonathan : you could parameterize and pass in say `Identity' vs. `STRef s'
08:50:34 <arjen-jonathan> Right. Actually Empty vs STRef s I think.
08:50:35 <Taneb> I was imagining something like Expr String -> Expr (STRef s Int)
08:50:55 <ski> like `data Foo ref = ..ref..' and then `thaw :: Foo Identity -> ST s (Foo (STRef s))', and a similar `freeze'
08:51:18 <dminuoso> arjen-jonathan: `Const ()` vs `Identity`?
08:51:24 <ski> yea, one can imagine different things than `Identity'. perhaps `Const Int' in some cases (hashconsing)
08:51:54 <arjen-jonathan> If I use Empty, that would guarantee that the conversion doesn't require a traversal.
08:52:04 <ski> `Empty' here being ?
08:52:12 <arjen-jonathan> The empty type, no inhabitants.
08:52:17 <ski> oh, `Void' ?
08:52:18 <dminuoso> arjen-jonathan: That would be hard to construct.
08:52:24 <dminuoso> arjen-jonathan: You need () at least.
08:52:49 <Profpatsch> oi
08:52:54 <Profpatsch> https://downloads.haskell.org/~ghc/8.6.2/ghc-8.6.2-x86_64-deb8-linux.tar.xz returns 0 bytes
08:53:00 <Profpatsch> fastly?
08:53:06 <Profpatsch> Where to report?
08:53:06 <dminuoso> Profpatsch: It's gotten that small.
08:53:16 <dminuoso> Profpatsch: #haskell-infrastructure maybe?
08:53:16 <Profpatsch> It breaks our bindist CI :(
08:53:25 <Profpatsch> thx
08:53:35 <ski> ("CI" ?)
08:53:54 <Taneb> ski: (continuous integration)
08:54:00 <ski> (ty)
08:54:26 <arjen-jonathan> dminuoso: Right, but my after-conversion phase could be a mixed representation with both STReps and names (this happens if they where unbound to start with)
08:54:57 * dminuoso finds it curious that ski has meddled with all kinds of languages, type theory and other fun things but not heard of CI yet.
08:54:59 <arjen-jonathan> So I have two constructors. After parsing, one of those is known not to occur,
08:55:19 <dminuoso> ski: What do you do for a living, if you dont mind my asking?
08:55:22 <arjen-jonathan> Which I could signal using Void.
08:55:44 <arjen-jonathan> Thanks all for thinking along :)
08:55:49 <arjen-jonathan> Haskell is a fun language
08:56:59 <Solonarv> oh yeah, Void works for saying "this constructor is not allowed"
08:57:30 <dminuoso> Except, if his parser has to construct values of this, then you have to put in `error/undefined` in those places.
08:57:51 <Profpatsch> dminuoso: You don’t want to know how many companies don’t use best practices, like CI, code review, version control …
08:58:25 <arjen-jonathan> dminuoso: The whole point is that the surface language doesn't contain this constructor.
08:58:53 <arjen-jonathan> I guess I just need a coercion then to go from (Term Void) -> (Term (STRef s))
08:59:09 <kuribas> how hard is it to deploy a haskell binary?
08:59:17 <dminuoso> kuribas: depends on you entirely.
08:59:21 <Solonarv> arjen-jonathan: that doesn't kind-check
08:59:24 <kuribas> to a machine without haskell installed
08:59:33 <Solonarv> Void :: *, but STRef s :: * -> *
08:59:33 <dminuoso> kuribas: Ive been playing with nix lately, nix-copy-closure is amazing!
08:59:51 <maerwald> difficult, we have a minimal busybox image with some required libs in the image
09:00:01 <Taneb> dminuoso: I guess the average machine that doesn't have Haskell installed also doesn't have Nix installed
09:00:16 <kuribas> maerwald: isn't busybox too light for haskell ?
09:00:18 <maerwald> but really portable, GHC is not
09:00:22 <maerwald> no
09:00:40 <arjen-jonathan> Solonarv: Nah, I missed a parameter
09:00:41 <kuribas> dminuoso: does that require nix on the target?
09:00:51 <dminuoso> Taneb: The intersection of users between #haskell and #nixos is suprisingly large indeed.
09:01:04 <Solonarv> arjen-jonathan: so you want 'Term Void -> Term (STRef s Something)' ? that easy
09:01:13 <dminuoso> kuribas: Yes.
09:01:30 <maerwald> dminuoso: ?
09:01:38 <kuribas> one of the main problems of introducing haskell in my workspace is the size of the installation
09:01:42 <Solonarv> implement 'Functor Term' and throw a Data.Void.vacuous at it
09:01:45 <maerwald> ah, I misread
09:01:48 <Solonarv> :t vacuous
09:01:50 <lambdabot> Functor f => f Void -> f a
09:01:52 <kuribas> It requires 2 Gb for a basic install
09:02:08 <maerwald> kuribas: the main problem is not bus factor? :>
09:02:15 <kuribas> maerwald: that also
09:02:21 <maerwald> then don't
09:02:34 <kuribas> maerwald: but I think it's possible to find good haskellers.
09:02:36 <Taneb> kuribas: we've had some luck with getting static executables that could be just copied over
09:03:12 <maerwald> kuribas: it's not easy
09:03:22 <maerwald> And it may be a problem for a project
09:03:31 <kuribas> maerwald: and typing helps a lot in getting an new developper familiar with the code.
09:03:44 <maerwald> Or the opposite, if the types are very complicated
09:03:46 <kuribas> maerwald: it's somewhat of a problem, but not that much
09:03:57 <kuribas> maerwald: if the code is well writen.
09:03:57 <maerwald> kuribas: you've tried to hire haskellers before?
09:03:59 <dminuoso> kuribas: We have gotten a new recruit who knows no Haskell but has no problem learning it.
09:04:06 <kuribas> maerwald: no, but a friend of mine did
09:04:20 <kuribas> maerwald: one of my coworkers is learning it now :)
09:04:33 <maerwald> That sounds dangerous to start a project with total haskell newbies
09:04:33 <kuribas> And the other one comes from scala, he shouldn't have any problem with it
09:04:41 <kuribas> maerwald: I am not a newbee
09:04:47 <maerwald> I did not say that
09:04:54 <kuribas> then I agree
09:04:58 <maerwald> You said your coworker is learning it
09:05:22 <kuribas> dminuoso: yeah, I think the difficulty is often overstated
09:05:35 <dminuoso> kuribas: Anyway. Originally I shipped Haskell by using docker multi-stage builds, extracting build artifacts into the final docker stage and putting them on minideb containers. 
09:06:07 <dminuoso> kuribas: This gives us deterministic builds, can be easily integrated into gitlab-ci, and it makes running the applications easy.
09:06:20 <dminuoso> And they are relatively small
09:06:31 <kuribas> dminuoso: ah cool
09:06:59 <kuribas> dminuoso: would that work for something that needs to start fast?
09:07:02 <kuribas> like a CGI script
09:07:07 <dminuoso> kuribas: Yes. It's really fast to set up.
09:07:21 <kuribas> dminuoso: I mean binary startup time
09:07:26 <hololeap> i have two functions that seem equivalent to me, but one causes a compilation error: http://dpaste.com/3MTXP84
09:08:18 <kuribas> hololeap: you need RankN for f
09:08:34 <kuribas> hololeap: because f and g don't have the same type
09:10:06 <dminuoso> I feel like this is monomorphism restriction kicking in.
09:10:15 <kuribas> dminuoso: hmm, yeah
09:10:19 <dminuoso> kuribas: let polymorphism should allow this
09:10:21 <dminuoso> ;)
09:10:38 <dminuoso> hololeap: Explicitly annotate `f` with a type
09:11:02 <dminuoso> Though.. doesnt MMR only apply to top level bindings?
09:11:25 <Taneb> dminuoso: MMR absolutely applies to let bindings
09:14:15 <kuribas> I thought MMR was off in newer ghc's...
09:14:38 <hololeap> {-# LANGUAGE NoMonomorphismRestriction #-} seems to "fix" it
09:17:04 <unyu> Still, don't you generally want bounded polymorphic definitions to be specialized as early as possible? Otherwise, you risk having to fetch the same instance dictionaries over and over...
09:18:42 <nshepperd1> I would not set NoMonomorphismRestriction. Give f a type annotation, or write it in pointy form f x = ...
09:20:43 <hololeap> nshepperd1: i thought that there was some kind of consensus that the monomorphism restriction was unnecessary... what is the danger here?
09:21:16 <Taneb> kuribas: no, but it's off in GHCi by default
09:21:22 <Taneb> (and has been for a while)
09:23:01 <dminuoso> hololeap: It's definitely not unnecessary.
09:23:02 <glguy> hololeap: The monomorphism restriction avoid surprise code inefficiencies. It's a feature that just requires a bit of awareness
09:23:35 <hololeap> nshepperd1: also, thanks for the hint of making the function "pointy"
09:24:17 <hololeap> however, i don't understand why that allows me to omit the type annotation (or why the type annotation is necessary when it's pointfree)
09:25:34 <dminuoso> hololeap: The MMR has very specific rules when it kicks in.
09:26:06 <dminuoso> hololeap: The ways to avoid it is to a) disable MMR, b) specify a type signature, or c) change the binding into a form for which MMR does not apply.
09:26:53 <nshepperd1> The danger is that a function you write will be slow and memory hogging and you'll have no idea that it's because using fromIntegral made some subcalculation polymorphic and stopped it from being reused
09:26:57 <nshepperd1> Or similar
09:27:25 <hololeap> i just literally annotated it with what GHCi told me `:t packFinite . toInteger`, so why is this necessary? is this supposed to force the programmer to explicitly state that they mean it to be polymorphic?
09:27:30 <nshepperd1> Writing a function in pointy form makes it clear that you don't expect sharing
09:28:15 <glguy> hololeap: It's necessary because you're making it explicit in your code that that value definition will be recomputed each time it is needed
09:29:07 <glguy> This allows the common case where value definitions are only computed once to be assumed when readers see them
09:30:45 <hololeap> so do the options of b) specify a type signature and c) change the binding  end up having the same effect in GHC?
09:30:56 <dminuoso> hololeap: Yes.
09:31:07 <hololeap> ok, i'll just try to keep that in mind
09:34:01 <dminuoso> hololeap: Strictly speaking it's not correct though. There is an edge case in which adding a type signature is not eonugh.
09:45:40 <dminuoso> We say that a given declaration group is unrestricted [iff] a) every variable in the group is bound by a function binding or a simple pattern binding [...], and b) an explicit type signature is given for every variable in the group that is bound by simple pattern binding
09:47:00 <dminuoso> Curious, what exactly is a declaration group here?
09:49:50 <dminuoso> Or is "group" just an arbitrary grouping of declarations for the purpose of asking the question "are these declarations unrestricted"?
09:51:14 <geekosaur> where are you seeing this? (I can think of two contexts, and they have different notions of it)
09:52:09 <dminuoso> geekosaur: 4.5.5, p. 57
09:53:43 <dminuoso> geekosaur: Ah! I found the definition for it.
09:53:48 <fresheyeball> hey out there
09:53:49 <geekosaur> version? (and perhaps which document; ghc manual latest has no 4.5.5)
09:54:01 <dminuoso> geekosaur: Oh sorry, it was the Haskell report.
09:54:07 <geekosaur> ah
09:54:13 <fresheyeball> so I have a typeclass with like this
09:54:17 <dminuoso> geekosaur: But it seems to be: A declaration group is  a  minimal  set  of  mutually  dependent  bindings
09:54:25 <dminuoso> My PDF reader just refused to find it for whatever bizarre reason
09:54:34 <fresheyeball> class Foo f where foo :: Foldable g => (a -> g b) -> f a -> f b
09:54:46 <fresheyeball> and I want to write an instance of it for `[]`
09:54:53 <fresheyeball> which is just fine and easy enough to do
09:55:03 <fresheyeball> but IF `g ~ Maybe`
09:55:10 <fresheyeball> I can provide a higher performance implimentation 
09:55:16 <fresheyeball> is there a way I can do that?
09:56:00 <fresheyeball> do I need to add `g` to the class defintion? Is there a way to avoid that?
09:56:03 <geekosaur> I think g has to be exposed in some fashion (either directly in the class or as an associated type)?
09:56:21 <geekosaur> otherwise there's no way to pick a more specific implementation
09:56:31 <fresheyeball> geekosaur: the class specifically needs to demand that `foo` work with any `Foldable`
09:56:36 <dminuoso> Couldn't you bury a rewrite RULE in there?
09:56:47 <fresheyeball> if I put in as a multiparameter type class, it breaks that
09:56:50 <fresheyeball> ooo
09:56:54 <fresheyeball> I don't know about RULE
09:56:58 <fresheyeball> teach me about RULE
09:57:02 <geekosaur> yeh, I think that might be the only other option
09:58:08 <Solonarv> {-# RULE "maybe is faster" forall f xs. foo f xs = fooMaybeList f xs #-}
09:58:09 <geekosaur> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#rewrite-rules
09:58:12 <Solonarv> ^ something like that
09:58:21 <dminuoso> fresheyeball: https://wiki.haskell.org/GHC/Using_rules
09:58:35 <dminuoso> The GHC manual page is surprisingly short on the topic.
09:59:13 <geekosaur> hm, SPECIALISE might also be a possibility
09:59:51 <dminuoso> Isn't SPECIALISE just some sugar around RULES?
09:59:59 <geekosaur> one variant at least
10:00:00 <Solonarv> correct
10:00:36 <geekosaur> this said, if picking one requires the dictionary, it won't work because RULES are compile time
10:00:43 <geekosaur> but dicts are runtime
10:01:14 <dminuoso> Runtime rules, wouldn't that be fun?
10:01:52 <Solonarv> one could view the machinery evaluating STG as a bunch of runtime rewrite rules :P
10:02:09 <dminuoso> geekosaur: Anyway, Ive pondered about "declaration groups" and that definition (even though it's somewhat disconnect in a previous section) seems to fit for the definition of the MMR.
10:04:53 <dminuoso> fresheyeball: SPECIALIZE lets GHC create its specialized version. If you want to roll your own, you have to use RULES.
10:05:50 <fresheyeball> dminuoso: so long as its possible, I am going to get the thing written, and then maybe enlist help adding benchmarks and rules
10:07:02 <geekosaur> dminuoso, there's also a deprecated synta which amounts to a RULE plus a wrapper
10:07:21 <geekosaur> unless that finally got removed in some 8.x
10:08:10 <dminuoso> geekosaur: Yeah I saw it, didn't feel it was worth to mention since it was deprecated.
10:08:12 <geekosaur> but I think it didn't because there's some corner case that's difficult to do without it (most can be done with SPECIALISE + a RULE)
10:11:18 <dminuoso> "This feature has been removed, as it is now subsumed by the RULES pragma (see Specialisation)."
10:13:09 <diskie> hello #haskell, is there a way, how to print a float number with decimal delimiter specific to locales (e.g. '.' vs. ',')?
10:13:17 <dminuoso>  % {-# SPECIALIZE fun :: Int -> Int = just1 #-}
10:13:24 <dminuoso> % {-# SPECIALIZE fun :: Int -> Int = just1 #-}
10:13:25 <yahb> dminuoso: ; <interactive>:91:34: error:; parse error on input `='; Perhaps you need a 'let' in a 'do' block?; e.g. 'let x = 5' instead of 'x = 5'
10:13:29 <dminuoso> geekosaur: Seems it was removed for good.
10:13:59 <dminuoso> % {-# SPECIALIZE fun :: Int -> Int #-}
10:13:59 <yahb> dminuoso: 
10:14:14 --- mode: glguy set -o glguy
10:17:19 <geekosaur> diskie, I don't think so. locale stuff is kinda difficult because it would have to be in IO; even for the time locale stuff there are e.g. hacks to try to minimize its intrusiveness
10:24:01 <diskie> geekosaur: Thanks for answer. I was affraid that it is so. Actually I would be perfectly fine with determining locale only, but I don't think that checking LANG env variable is multi-platform approach, it has to work in Windows 10 too :(
10:24:30 <geekosaur> yep, that's one of the major complications
10:25:51 <geekosaur> plus on Windows the locale is part of a device context
10:26:42 <geekosaur> well, part of it is. there's also systemwide settings, but for some things you need to query screen or printer etc. context to find out what to do
10:27:35 <diskie> hmm, it sounds quite sophisticated, I'm going to solve my problem with configuration option :) I'm too lazy to research it 
10:28:56 <diskie> but it is small internal tool anyway, for tiny group of people, but located in different countries. 
11:05:53 <fresheyeball> phadej: you around?
11:24:03 <phadej> fresheyeball: always
11:28:07 * hackage haskus-utils-types 1.4.1 - Haskus types utility modules  https://hackage.haskell.org/package/haskus-utils-types-1.4.1 (SylvainHenry)
11:29:38 * hackage haskus-utils-variant 2.6.1 - Variant and EADT  https://hackage.haskell.org/package/haskus-utils-variant-2.6.1 (SylvainHenry)
11:36:00 <fresheyeball> phadej: I have news
11:36:10 <fresheyeball> Compactable potentially subsumes these
11:36:23 <fresheyeball> so I am interested in working with you to merge our libraries
11:36:36 <fresheyeball> I dont want to duplicate your work
11:36:47 <fresheyeball> or have people using conflicting These data types
11:37:27 <fresheyeball> I also don't want to just depend on your library, since I need to make big changes to Data.Align
11:38:17 <fen> % @let puncture' = fmap snd . (`runCont` \xs -> fmap (second ($ fmap fst xs)) xs) . traverse (\x -> callCC (\k -> pure (x, \xs y -> fmap fst $ (`runCont` id) $ k (y, \_ _ -> xs))))
11:38:17 <yahb> fen: ; <interactive>:93:1: error: parse error on input `@'
11:38:21 <fen> % let puncture' = fmap snd . (`runCont` \xs -> fmap (second ($ fmap fst xs)) xs) . traverse (\x -> callCC (\k -> pure (x, \xs y -> fmap fst $ (`runCont` id) $ k (y, \_ _ -> xs))))
11:38:21 <yahb> fen: 
11:38:42 <fen> % fmap ($ 0) $ puncture' [1, 2, 3, 4]
11:38:42 <yahb> fen: [[0,2,3,4],[1,0,3,4],[1,2,0,4],[1,2,3,0]]
11:39:36 <fen> can anyone explain how that works?
11:40:16 <fen> <mniip> effectively we "yield" the thread of execution mid-traverse, but we can "resume" back into it if we apply the function
11:40:35 <mniip> that's exactly how it works
11:40:53 <fen> or what it does
11:42:30 <fen> in amongst all the infix and unknown intermediate types its not clear how it does this
11:43:01 <fen> which would help give precise meaning to these terms...
11:43:59 <fen> confronted with illegible code and baffling terms...
11:44:25 <fen> its not exactly an explanation 
11:45:26 <fen> it all seems quite mysterious, which isnt good as it is not then clear how else to use this kind of thing 
11:46:12 <fen> there was an example earlier it *might* work for, but that might just be an illusion resulting from its total incomprehensibility 
11:47:54 <fen> <fen> data Free2 f a b = Free2 (f (Free2 f a b)) | Pure1 a | Pure2 b
11:48:04 <fen> type Cycle f a = Zipper (\a -> Free2 (Zipper f) a (Cycle f a)) a
11:49:05 <fen> the way pointer duplicate works is using mapAccumL and updating a carried pointer to match the current location in a traversal.
11:49:28 <fen> we can then build up a list of pointers pointing to values at specified locations
11:49:49 <fen> and use these as "cyclic" nodes
11:50:23 <dminuoso> % :t puncture' [1,2,3,4,5]
11:50:23 <yahb> dminuoso: Num a => [a -> [a]]
11:50:26 <fen> but that requires "rebuilding the links" each time, and maybe by the magic of callCC, this might be solved
11:52:43 <fen> instead of building a list of nodes visited and then getting the corresponding pointer on the other end of the link, there could be a magic teleportation via continuations
11:53:11 <fen> at least, thats wishful thinking on how this "puncture" example seems like it might help
11:53:13 <dminuoso> % :t  traverse (\x -> callCC (\k -> pure (x, \xs y -> fmap fst $ (`runCont` id) $ k (y, \_ _ -> xs))))
11:53:13 <yahb> dminuoso: (Traversable t, Functor f) => t p -> ContT (f (b1, b2)) Identity (t (p, f b1 -> p -> f b1))
11:53:29 <dminuoso> mniip: How much dark magic did you pour into this?
11:55:26 <fen> enough to warp the very nature of reality!
11:55:51 <fresheyeball> phadej: I really would like to talk to you about this please
11:56:09 <fresheyeball> phadej: It turns out that Maybe and Either are sort of red herrings
11:56:19 <fresheyeball> and that the real structure is Foldable and Bifoldable
11:56:33 <fresheyeball> where These is not the core structure 
11:57:38 <fresheyeball> cmap2 :: Bifoldable g => (a -> g l r) -> f a -> (f l, f r)
11:57:44 <fresheyeball> in my lib has a dual in yours
11:58:16 <fresheyeball> alignWith :: Bifoldable g => (g l r -> a) -> f l -> f r -> f a
11:58:27 <fresheyeball> I find this very exciting! 
11:59:01 <fen> that does not look like fold
11:59:21 <fen> :t unzipWith
11:59:22 <lambdabot> error:
11:59:22 <lambdabot>     • Variable not in scope: unzipWith
11:59:22 <lambdabot>     • Perhaps you meant one of these:
11:59:33 <fen> hmm...
11:59:37 <fen> :t zipWith
11:59:39 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
12:00:04 <fen> so thats just an arbitrary profunctor g?
12:01:07 <fen> anyway, wouldnt f be the foldable thing?
12:01:52 <fen> seems more like just trying to make g be a pair and a function at the same time, which seems impossible, are there instances?
12:02:58 <fen> oh well its a curried function so thats fine, so g is just a generalised pair? seems like a strange way to define pair...
12:03:43 <fen> fresheyeball: whats the idea here?
12:05:09 <fresheyeball> fen: what do you mean? I discovered that part of phadej's lib is dual to mine, and that we can be more general than either of us is doing today
12:05:19 <fresheyeball> so I want to work on this together
12:05:35 <Solonarv> fen: 'g' could be e.g. Either or These, so it's not just a generalised pair
12:06:00 <fresheyeball> Solonarv: it could be ANY bifoldable
12:06:09 <fen> if thats a thing
12:06:12 <fresheyeball> it could be (,) or some custom thing
12:06:19 <Solonarv> yeah, exactly; I was explaining for fen's sake
12:06:25 <fresheyeball> like data Foo a b = Foo a | Bar a b | Nope
12:06:27 <Solonarv> Bifoldable is already a thing
12:06:39 <Solonarv> % :m + Data.Bifoldable
12:06:39 <yahb> Solonarv: 
12:06:45 <Solonarv> % :i Bifoldable
12:06:45 <yahb> Solonarv: class Bifoldable (p :: * -> * -> *) where; bifold :: Monoid m => p m m -> m; bifoldMap :: Monoid m => (a -> m) -> (b -> m) -> p a b -> m; bifoldr :: (a -> c -> c) -> (b -> c -> c) -> c -> p a b -> c; bifoldl :: (c -> a -> c) -> (c -> b -> c) -> c -> p a b -> c; {-# MINIMAL bifoldr | bifoldMap #-}; -- Defined in `Data.Bifoldable'; instance [safe] Bifoldable Either -- Defined in `Data.Bifoldab
12:07:08 <fresheyeball> I think These is fundimental to bifoldable
12:07:20 <fresheyeball> was talking with selllout on this
12:07:36 <fresheyeball> toList :: Foldable f => f a -> [Identity a]
12:07:49 <fresheyeball> toList :: Bifoldable g => g l r -> [These l r]
12:07:56 <fresheyeball> are core structures
12:08:00 <fen> if the idea is to have a class capturing (,) Either and These, using the way they act over a container still seems to be a fairly roundabout way of going on
12:08:37 <fresheyeball> fen: that is not the goal of bifoldable, there are more things that are bifoldable than that list
12:08:57 <Cale> Do we have an example of where abstracting in this way is actually helpful?
12:09:12 <fresheyeball> sure
12:09:32 <Solonarv> % newtype Bicompose p f g a = Bicompose { getBicompose :: p (f a) (g a) }
12:09:32 <yahb> Solonarv: 
12:09:35 <Cale> Bifoldable is a class that I've almost never used.
12:09:50 <Solonarv> ^ this is Bifoldable whenever p is Bifoldable and f&g are both Foldable, for example
12:10:14 <Cale> sure...
12:10:21 <fresheyeball> http://hackage.haskell.org/package/compactable-0.1.2.3/docs/Control-Compactable.html#v:separateFold
12:10:25 <fresheyeball> this is from my lib
12:10:42 <fresheyeball> it's nice to have the intention of the bifoldable abstracted out
12:10:54 <dmwit> fresheyeball: But your modified type for alignWith doesn't make the promise that the existing one does.
12:11:11 <dmwit> fresheyeball: Namely that the callback need only be capable of combining exactly one `a` and one `b` when things are well-aligned.
12:11:14 <fen> Cale: there have been problems of code duplication resulting from very similar classes steaming from slightly different permutation of Maybe over (,) 
12:11:33 <dmwit> Yours demand that the callback be capable of combining multiple `a`s, which may not always make sense.
12:11:36 <fresheyeball> Cale: how many times to we see mapEither out there?
12:11:46 <fresheyeball> wouldn't it be nice to decide the seperation semantic later?
12:11:51 <Cale> What's mapEither?
12:12:06 <fen> % :t bimap
12:12:06 <yahb> fen: Bifunctor p => (a -> b) -> (c -> d) -> p a c -> p b d
12:12:22 <fresheyeball> http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Map-Lazy.html#v:mapEither
12:12:24 <fresheyeball> here is one
12:12:37 <fen> guess its an attempt to not require functor to define pair like things...
12:13:08 <Cale> Ah, so basically the "unalign" sort of thing.
12:13:45 <Cale> (though 'these' sort of screws that up a bit)
12:13:49 <fen> but still, that biZip thing seems strange, so are there "bifoldable" (still a bad name) things that are not bifunctors?
12:13:59 <dmwit> fresheyeball: I note with some interest that you do not have an instance of CompactFold for Maps...
12:14:28 <fresheyeball> Cale: sometimes we want both all the time (,), sometimes we want to split with no union Either, sometimes we want to both know the union, and the difference These, sometimes its not a common semantic `newtype Foo a b = Foo (Maybe (a,b))`
12:14:37 <dmwit> (I think for a related reason to the one I was discussing above. Either a b promises much more than Bifoldable f => f a b does.)
12:14:53 <fresheyeball> dmwit: I do now!
12:14:58 <dmwit> (Sorry, I mean Bifoldabel f *> f a b.)
12:15:16 <Cale> fresheyeball: Yeah, there are enough weird cases to deal with that it may be best just to write what we mean each time.
12:15:23 <fresheyeball> dmwit: are there no promises this makes that we can regain with specialization?
12:15:37 <Cale> (and make sure that data structures like Map can do everything we want in an efficient way)
12:15:45 <fresheyeball> Cale: why if I can have a principled library that does this well?
12:15:56 <dmwit> fresheyeball: What does separateFold (M.singleton () (Foo 3 4 5 "abc" "def")) do?
12:16:02 <Cale> Maybe if it can make the distinctions clear
12:16:03 <fresheyeball> I am also interested in exploring the space, and doing research for its own sake
12:16:08 <dmwit> (with data Foo a b = Foo a a a b b, say)
12:16:22 <fen> sometimes if its possible to enumerate all instances its good to do so, though the abstraction can still be helpful
12:17:15 <fresheyeball> dmwit: define Bifoldable and I will tell you :)
12:17:20 <fen> dmwit: thats going towards type level lists of types...
12:17:37 <fresheyeball> err I guess its unambigous actually
12:17:39 <fresheyeball> sec
12:18:08 <fresheyeball> (M.singleton () 3, M.singleton () "abc")
12:18:16 <fresheyeball> that is what I would expect
12:18:40 <Cale> I'm on a bit of a "use the least abstract thing that still works" bent lately, since there have been a rash of examples of where someone used Foldable or ITraversable or something to obtain a function of the right type with the wrong semantics
12:18:46 <dmwit> fresheyeball: instance Bifoldable Foo where bifold (Foo m1 m2 m3 m4 m5) = mconcat [m1, m2, m3, m4, m5]
12:19:03 <Cale> Trying to get the people on my team to write more explicit case expressions and use fewer fancy things
12:19:04 <fresheyeball> dmwit: type error
12:19:25 <fen> % let (x,y) = (last y,(fmap ($ x) $ puncture' [1, 2, 3, 4])) in y
12:19:25 <yahb> fen: ; <interactive>:103:22: error:; * Occurs check: cannot construct the infinite type: a1 ~ [a1]; Expected type: [a1]; Actual type: [[a1]]; * In the expression: (fmap ($ x) $ puncture' [1, 2, 3, 4]); In the expression: (last y, (fmap ($ x) $ puncture' [1, 2, 3, ....])); In a pattern binding: (x, y) = (last y, (fmap ($ x) $ puncture' [1, 2, ....])); * Relevant bindings in
12:19:28 <dmwit> fresheyeball: uh?
12:19:34 <fresheyeball> Cale: this is a pure abstract lib
12:19:49 <fresheyeball> dmwit: you cannot cannot Num n => n with IsString s => s
12:19:57 <fresheyeball> cannot concat with*
12:20:04 <dmwit> I didn't try to.
12:20:29 <fresheyeball> Foo :: (Num n, IsString s) => n -> n -> n -> s -> s
12:20:31 <fresheyeball> in your example
12:20:41 <fresheyeball> it would be this
12:20:58 <dmwit> No, Foo :: a -> a -> a -> b -> b -> Foo a b
12:21:09 <dmwit> GHC does not agree with you that it's a type error. =P
12:21:23 <fresheyeball> dmwit: it is because you did this
12:21:39 <dmwit> You are telling me you know better than GHC?
12:21:44 <dmwit> Type it into GHC and see for yourself.
12:21:49 <dmwit> I did.
12:21:52 <fen> % let (x,y) = ((head.last) y,(fmap ($ x) $ puncture' [1, 2, 3, 4])) in y
12:21:53 <yahb> fen: [[1,2,3,4],[1,1,3,4],[1,2,1,4],[1,2,3,1]]
12:22:02 <fresheyeball> bifold (Foo m1 m2 m3 m4 m5) = mconcat [m1,m2,m3,m4,m5]
12:22:07 <fresheyeball> and I am saying we can't do that for bifold
12:22:12 <fresheyeball> since a and b can differ
12:22:12 <dmwit> Why not?
12:22:16 <dmwit> Not in the argument to bifold.
12:22:45 <fresheyeball> oh wait I am wrong
12:22:47 <fresheyeball> bifold :: (Bifoldable p, Monoid m) => p m m -> m
12:22:51 <fresheyeball> they have to match
12:22:53 <fresheyeball> ok
12:22:53 <dmwit> You claim there's a Map instance, but I don't see one in https://gitlab.com/fresheyeball/Compactable/blob/master/src/Control/Compactable.hs
12:23:03 <fresheyeball> dmwit: I have not published
12:23:20 <fresheyeball> I only a day ago realized I could do this, and abstract Maybe to Foldable, and abstract Either to Bifoldable
12:23:29 <fresheyeball> and in the process become dual to Data.Align
12:23:44 <fresheyeball> I am working through this, you don't need to be hostile
12:23:46 <dmwit> Anyway I don't like this. It throws away most of the data provided. That seems... bad.
12:23:56 <fresheyeball> why?
12:23:58 <dmwit> Either seems more honest. At least none of the data is thrown away.
12:24:04 <fresheyeball> what gets thrown away?
12:24:10 <dmwit> 4, 5, and "def"
12:24:58 <fen> are you just trying to capture "datatypes with 2 parameters" ?
12:25:25 <fen> might be why it seems strange...
12:25:30 <fresheyeball> dmwit: then don't use it. I am not sure, but I think there might be other lawful versions
12:25:41 <fresheyeball> perhaps headMay style is not the best default
12:25:44 <dmwit> (`(Maybe a, Maybe b)` would be fine, too.)
12:25:59 <fresheyeball> dmwit: I could still use your bifoldable defintion
12:26:07 <fresheyeball> bifold is not minimal 
12:26:08 <fen> and Free Maybe that
12:26:33 <fresheyeball> dmwit: that would be `Maybe (These a b)`
12:26:38 <fresheyeball> in my semantic
12:26:44 <phadej> fresheyeball: compactable?
12:26:54 <fresheyeball> phadej: yes
12:27:02 <dmwit> Anything isomorphic is fine.
12:27:03 <fresheyeball> there is a relationship I think
12:27:20 <Cale> What's the other library we're talking about?
12:27:26 <Solonarv> @hackage these
12:27:27 <lambdabot> http://hackage.haskell.org/package/these
12:28:00 <fresheyeball> dmwit: can you do bifoldr or bifoldMap ?
12:28:08 <dmwit> sure, why not
12:28:17 <fresheyeball> I think we might be able to find a version that doesn't throw anything away
12:28:50 <dmwit> bifoldr fa fb c (Foo a1 a2 a3 b1 b2) = fa a1 (fa a2 (fa a3 (fb b1 (fb b2 c))))
12:28:54 <Cale> Are you referring to unalign specifically?
12:29:06 <fresheyeball> Cale: alignWith is the one I know of right now
12:29:12 <fen> you could quotient out the ordering of a and b and make them only appear at most once, then you have 2  one (<=1) valued skip list concatinated together
12:29:15 <Cale> ah, alignWith is fine
12:29:33 <Cale> What's missing from it?
12:29:42 <dmwit> bifoldMap fa fb (Foo a1 a2 a3 b1 b2) = mconcat [fa a1, fa a2, fa a3, fb b1, fb b2]
12:29:51 <fresheyeball> alignWith :: (These a b -> c) -> f a -> f b -> f c
12:30:11 <fen> basically its just encoding Int as nested maybes, along with the 2x2 table of Maybe a and b
12:30:17 <fresheyeball> fmapBifold :: (Functor f, Bifoldable g) => (a -> g l r) -> f a -> (f l, f r)
12:30:19 <dmwit> (You'll note that any one of these three can be derived from the others + bimap.)
12:30:52 <fresheyeball> dmwit: thank you that helps
12:30:54 <dmwit> (And bimap has exactly one lawful implementation.)
12:31:01 <fresheyeball> I agreed
12:31:20 <fresheyeball> dmwit: I am researching here, so please don't expect me to see everything at once
12:31:25 <phadej> fresheyeball: `these` is a practical library. I refuse to do anything before concrete thing is spelled out in a way that current `these` user can use different version
12:31:36 * dmwit nods agreeably
12:32:21 <Cale> Yeah, I rely on 'these' regularly... I'd rather its types remain comprehensible :D
12:32:23 <fresheyeball> phadej: can you rephrase that?
12:32:25 <fen> ok, so if its reasonable to try to abstract "datatypes of 2 parameters appearing any number of times", why is this "bifodable" surgestion the best way to phrase that abstraction?
12:32:41 <fresheyeball> Cale: I believe it would remain mostly the same
12:32:53 <phadej> fresheyeball: I believe in hard evidence ;)
12:33:07 <fresheyeball> phadej: I can't provide hard evidence as I am doing research here
12:33:27 <fresheyeball> The realization that part of your lib is dual to mine
12:33:43 <fen> colib
12:33:48 <fresheyeball> and that my library can be dramatically more general by abstracting to foldable and bifoldable 
12:33:54 <Cale> I will say that I did end up writing  unalignProperly :: (FunctorMaybe f) => f (These a b) -> (f a, f b)
12:34:03 <phadej> fresheyeball: I'm not forbidding you do to your research, I'm just refusing to do any changes to these before that research provides some tangible results
12:34:05 <dmwit> fresheyeball: But I think the point we're making is that it is not dramatically more general.
12:34:08 <fresheyeball> means I want to _talk_ with you about this
12:34:15 <fresheyeball> I am not asking you to make any changes right now
12:34:19 <phadej> I didn't need to do any changes in `these` in years
12:34:33 <phadej> so it can wait for general abstraction to emerge few more :)
12:34:40 <fresheyeball> I am informing you, because if we work together we can be more powerful
12:34:40 <Cale> But apart from unalign, I think the types in 'these' are fairly exact
12:34:46 <dmwit> (In fact, in the specific case of alignWith, you'd be making it *less* general in the sense that there could be fewer instances.)
12:35:14 <fresheyeball> dmwit: I have not lost any instances yet with this approach 
12:35:23 <fresheyeball> I have not written them all yet either
12:35:31 <fresheyeball> so I may still prove myself wrong here
12:35:33 <fen> can continuations shift/reset/yield/return to, be used to tie the knot to intermediate positions like the puncture example? 
12:36:04 <dmwit> Hm. Actually, I guess `bifoldMap (const Nothing) (First . Just)` and `bifoldMap (First . Just) (const Nothing)` converts any `Bifoldable` to a `These`.
12:36:06 <fen> i dont want to have to traverse a list of returned values its expensive
12:36:15 <fresheyeball> phadej: if you don't want to research this with me, that's ok. I will go do it anyway. But hey, what is the harm in reaching out? 
12:36:21 <dmwit> But that's kind of my point, I think: if that's what you're going to do every time, why not just use `These` in the first place...?
12:36:35 <dmwit> And if you forbid that because it throws away information, then you can't have your Map instance...
12:36:35 <fresheyeball> I believe a deeper abstraction has emerged here, and so, yes I want to chase it down
12:36:54 <phadej> fresheyeball: you are not alone, you could reach for viercc e.g. https://github.com/isomorphism/these/issues/96
12:37:13 <fresheyeball> dmwit: I really think your are being non-helpfully negative here
12:37:36 <fen> why is it the best way to phrase the abstraction?
12:37:47 <phadej> for the last few years I haven't seen good arguments to generalise `Align` to something with `mapMaybe` like function
12:37:50 <phadej> it just doesn't work out well
12:37:55 <fresheyeball> dmwit: These is fundemental, as we should be able to map a given bifunctor to [These a b]
12:38:02 <phadej> So i'm not enthustiastic about those.
12:38:25 <fresheyeball> in the same way we can map a given from a foldable to [Identity a]
12:38:41 <fresheyeball> phadej: is there being a shared abstract substrait a good reason?
12:39:15 <fresheyeball> mapMaybe and mapThese can define one another
12:39:30 <phadej> fresheyeball: a class with `mapMaybe` **is not** a super class of `Align`
12:39:36 <fresheyeball> align with is dual to mapThese
12:39:42 <phadej> Align preserves all the data
12:39:51 <fresheyeball> phadej: right, its dual
12:40:02 <fresheyeball> that is my point
12:40:13 <phadej> Distributive is dual of Traversable, and leaves in different package :)
12:40:25 <fresheyeball> sure
12:40:32 <fresheyeball> but I would think you would want the rest of it as well
12:40:48 <fresheyeball> just for completelness 
12:40:51 <fresheyeball> completeness*
12:41:09 <Cale> phadej: I'm curious where the existing unalign came about
12:41:22 <phadej> Cale: I think it's a brain-wart
12:41:59 <fresheyeball> phadej: nil becomes F.null
12:42:07 <phadej> I mean, it's practically useful, but probably? there aren't any theoretical justification for its existence
12:42:09 <Cale> okay, I've had need for  class Unalign f where unalign :: f (These a b) -> (f a, f b)
12:42:19 <Cale> But not the existing thing
12:42:24 <fresheyeball> Cale: you have that now in compactable
12:42:39 <phadej> Cale: yes, that version you ask is reasonable thing to have
12:42:54 <Cale> fredcy: *exactly* that, or some absurd generalisation of it? :)
12:42:56 <fresheyeball> but I see no reason it needs to be specialized on These
12:43:25 <Cale> I don't want to have to think about what Bifoldable instances do to check that my programs are doing the right thing
12:43:29 <fresheyeball> newtype Foo a b = Foo (Maybe (a,b)) deriving Bifoldable 
12:43:34 <fresheyeball> seems perfectly valid to use there
12:43:46 <phadej> Cale: but otoh, the implementations are indeed very similar to f (a,b) -> (f a, f b); or f (Either a b) -> (f a, f b)
12:44:07 <Cale> phadej: Sure
12:44:26 <Cale> phadej: But those factor through the one I mentioned
12:44:38 <fen> Stack f => on that last one
12:44:44 <fresheyeball> Cale: I think its unambiguous what they do
12:44:56 <fresheyeball> here some examples
12:45:00 <phadej> Cale: but there's a catch
12:45:08 <phadej> Cale: think [] instance
12:45:22 <fresheyeball> [This 1, That 2, These 3 4] = ([1,3], [2,3])
12:45:30 <phadej> uncurry align $ unalign [This a, That b] == These a b
12:45:33 <phadej> so _something_ is missing
12:45:39 <fresheyeball> [Left 1, Left 2, Right 3] = ([1,2],[3])
12:46:05 <fresheyeball> [(1,2),(3,4)] = ([1,3],[2,4])
12:46:38 <Cale> phadej: I'm not sure [] should be an instance of unalign
12:46:56 <fresheyeball> [Foo Nothing, Foo (Just (1,2)), Foo Nothing, Foo (Just (3,4))] = ([1,3],[2,4])
12:47:02 <Cale> because you can't have missing elements
12:47:15 <fen> [] . Maybe
12:47:24 <phadej> Cale: but "why"
12:47:30 <fresheyeball> Cale: what law in unalign prevents missing elements?
12:47:35 <phadej> why Map and [] are both Align, but only Map can be unaligh
12:47:47 <phadej> what's the "abstract non-sense" part is missing
12:48:05 <phadej> *which is missing
12:48:18 <phadej> "you cannot have missing elements" is imprecise statement]
12:48:22 <Cale> Well, from a practical perspective, it's because unalign produces depleted structures, which may be missing some of the positions that the original structure had
12:48:32 <arjen-jonathan> I don't understand how ST interacts with other monads in a stack. Anyone have examples of nesting ST in ErrorT? 
12:48:33 <fen> data Skip a = Skip (Skip a) | a :_: (Skip a) | EmptySkip
12:48:40 <fresheyeball> Cale: right
12:48:45 <vaibhavsagar> does using CApiFFI allow me to work around symbol clashes?
12:48:47 <fresheyeball> Align does not lose any days
12:48:51 <fresheyeball> lose any data
12:48:59 <fresheyeball> Unalign can lose data
12:49:13 <phadej> if it's dual it won't
12:49:25 <Cale> Unalign shouldn't lose data.
12:49:29 <phadej> if align is (,) than unalign would be projections
12:49:46 <fresheyeball> now that is an interesting point
12:49:49 <fen> phadej: it loses shape when it hits a Nothing, its not invertable, Skip a stores the [Maybe a] invertably 
12:49:52 <Cale> It's just that some instances of Align can't also be instances of Unalign because their align instance isn't surjective
12:50:01 <phadej> it fits CT; but it's not useful
12:50:33 <Cale> align for lists doesn't get you every possible element of [These a b]
12:50:46 <phadej> Cale: I like that explanation
12:50:58 <fen> so its not any good to use some arbitrary f.
12:50:58 <fresheyeball> I want to understand this but dont
12:50:58 <Cale> and so there will be some [These a b] which don't correspond to a pair of lists ([a],[b])
12:51:03 <fresheyeball> can you explain again?
12:51:26 <dmwit> Are there Unalign instances that are not surjective (and therefore have no corresponding align)? =)
12:51:40 <fen> AND if there is a particular choice of f for each type of pair like thing, then its not an abstraction at all, as you need to specify this
12:51:49 <fresheyeball> surjective where?
12:51:59 <Cale> fresheyeball: align itself
12:52:30 <fen> basically its assigning a container to a pairlike thing, and enumerating these containers then becomes the same as enumerating the pairlike things
12:52:38 <Cale> Given a list zs :: [These a b], it's not necessarily the case that we can find xs :: [a] and ys :: [b] such that align xs ys = zs
12:52:39 <fresheyeball> Cale: as in surjective as (f a, f b) -> f (These a b) ?
12:52:53 <Cale> so align is not surjective
12:53:07 <Cale> and so it's unreasonable to expect it to have an inverse
12:53:22 <fen> if you need a specialised f, then its just no good an abstraction.. unless some particular f represents several varients of the pairlike things
12:53:43 <Cale> hm?
12:53:45 <fresheyeball> now I am really lost
12:53:51 <dmwit> (In particular, align xs ys always starts with These-s, then switches to either a bunch of This-s or That-s. Anything that doesn't match that pattern is out.)
12:53:54 <fresheyeball> I think the info I need is in here though
12:54:08 <Cale> I don't understand fen's remarks, but I'm not sure fen is talking about the same thing as us
12:54:13 <dmwit> (So e.g. [This (), That ()] is not align xs ys for any xs and ys.)
12:54:21 <Cale> right
12:54:23 <Cale> exactly
12:54:27 <fen> well [Maybe a] <-> Skip a, or eg f (Either a b) -> (f a, f b) requires `f' has empty
12:54:56 <Cale> Oh I see, you're proposing another type for which there would be an unalign, sure
12:54:59 <fresheyeball> yes
12:55:04 <fresheyeball> f must be Alternative 
12:55:15 <Cale> Alternative, I'm not sure
12:55:26 <fresheyeball> or atleast that is how I have been modeling this
12:55:29 <fresheyeball> I got the idea for Scalaz
12:55:36 <fresheyeball> to use Alternative there
12:55:50 <fr33domlover> What's the recommended way to run an IO action and catch an exception that is of one of 2 given types? I was using 'try' with a single type (to catch HttpException) but now I also want to catch another type
12:56:37 <Cale> fr33domlover: It's possible to make an instance of Exception for Either... but probably just use another try
12:56:56 <fen> your trying to abstract the Either in "f (Either a b) -> (f a, f b)". ie f (g a b) -> (f a, f b), but this requires specialised f. so the abstraction over g depends on the constraint of f
12:57:47 <dminuoso> fen: catches?
12:57:52 <fen> different f correspond to different classes of pairlike things
12:58:04 <dminuoso> Sorry, I meant fr33domlover.
12:58:16 <Solonarv> yes, 'catches' is what you want
12:58:33 <Solonarv> nesting 'try's or 'catch's has slightly different semantics
13:00:08 <Cale> Well, nesting try won't have the issue with the outer exception handler catching exceptions thrown by the inner one
13:00:33 <Cale> It should be *vaguely* like catches
13:00:47 <Solonarv> true
13:04:10 <fen> there is an example with DList here https://wiki.haskell.org/Tying_the_Knot
13:04:46 <fen> but when traversing over it, the reference to the finished traversal must be passed 
13:05:02 <fen> so its not like a normal list traversal instance
13:05:04 <Cale> haha, some really ancient comments by me there
13:05:28 <Cale> this was migrated from the *original* Haskell wiki, before mediawiki existed
13:06:13 <fen> if this is extended to trees with many cyclic links, then if these are updated via a lookup table over the completed list, passed into the traversal
13:06:37 <fen> then this lookup is expensive. is there any way to get round this using callCC
13:07:33 <Cale> hmm
13:07:40 <fen> it would be good to fix the cyclic shape upon creation, like the shape given to the rest of the tree
13:07:42 <Cale> How would you use callCC to do it?
13:08:20 <fen> well, it doesnt seem possible to avoid having to somehow do this lookup
13:08:23 <Cale> If you need an unbounded number of references, then it's just going to be tricky
13:08:46 <Cale> You can define any fixed cyclic structure by just binding a bunch of variables in place
13:08:52 <Cale> You could use an Array
13:09:14 <Cale> (or lazy Vector)
13:09:15 <fen> its fine if the creation is expensive if it allows for the subsequent updates to reuse this specification
13:09:48 <Cale> The lookups only happen once, don't they?
13:10:04 <Cale> If I understand what you mean
13:10:04 <fen> Cale: yeah, any Store? but they all have finite cost, and the concept of fixing the cyclic references isnt realised
13:11:38 <fen> well if you start with a tree, and give a list of pairs of positions to link, and traverse the tree, adding the links (which are returned from the updated tree)
13:11:40 <Cale> Personally, I don't often find many occasions to use things like this, because it's quite common to want to be able to do an update to something.
13:12:09 <fen> then when you traverse, you have to repeat this process, so always needing to store the list of links and redo the lookup each time
13:12:16 <Cale> nonono
13:12:37 <fresheyeball>  fen I guess I am still missing it
13:12:48 <Cale> Well, yes, if you do that :)
13:12:56 <fresheyeball> what is wrong with abstracting f (Either a b) -> (f a, f b) with a Bifoldable g?
13:12:57 <Cale> You need to produce an array from your references directly back to the actual final tree at once.
13:13:04 <Cale> Or something along those lines
13:13:24 <Cale> Think of it as defining an array of pointers
13:13:31 <fen> ok
13:13:41 <Cale> That will be doable
13:14:04 <fen> so then when creating it, you just put the pointers in the corresponding places, ensuring links go both ways
13:14:05 <Cale> I was thinking you were using a Map or something, and not wanting to pay a one-time cost of doing a lookup in the Map
13:14:25 <fen> but the problem is then having to repeat this process when traversing theresulting cyclic tree
13:14:30 <Cale> yeah, you have the subtree be a lookup in the Array
13:14:57 <Cale> Traversing the resulting structure is going to be hairy, because it will be indistinguishable from an infinite one
13:15:16 <Cale> So you'll have to have some external stopping condition
13:15:17 <fen> that cost is ok upon creation, but only if it can be saved when doing subsequent traversals
13:15:23 <fr33domlover> Cale, dminuoso thanks :)
13:15:31 * fr33domlover catches ^_^
13:15:33 <Cale> On subsequent traversals, there won't be any lookup to do
13:16:00 <fen> ah, right, yes, its exactly because of that stopping condition which causes the reference pointers to be required during traversal
13:16:08 <Cale> because the "subtree" will have been evaluated, first to a lookup in the array, and then to some particular (infinite) tree which was sitting there
13:16:36 <Cale> and so you'll end up with a pointer in memory to exactly the right thing
13:16:47 <fen> hmm
13:17:08 <fen> wouldnt it refer to the previous version, before the traversal?
13:17:50 <fen> that was the pointer that was passed into it upon creation.
13:18:19 <Cale> I mean that you can build a Tree and Array by mutual recursion with each other
13:19:24 <fen> yeah, but that array of references to the completed thing is only the "already created" thing, not the altready traversed thing 
13:20:26 <fen> the array is returned by, and passed into, the creation process
13:20:49 <fen> and this would also need to be done for the traversal implementation
13:21:06 <fen> so it costs every time, and the cycles are not retained
13:23:22 <fen> data Free2 f a b = Free2 (f (Free2 f a b)) | Pure1 a | Pure2 b
13:23:32 <fen> type Cycle f a = Zipper (\a -> Free2 (Zipper f) a (Cycle f a)) a
13:23:47 <fen> it is the Pure2 which is the stopping condition
13:24:28 <Cale> https://gist.github.com/cgibbard/fc43dc03ced5ce2f873b888c90e4b40e -- have a look at this
13:24:51 <Cale> Admittedly, we're not actually doing the conversion you were talking about there
13:25:01 <Cale> But this is the sort of structure I'm thinking of
13:26:18 <fen> thats a confusing reuse of Array, but if thats how to do pointers thats fine
13:26:31 <fen> Zippers of Free Zippers is used in the Cycle type above
13:26:49 <Cale> Well, the Array in this case is unnecessary, we could have simply defined 6 variable Trees
13:27:09 <Cale> But the point is that you could hope to define such an Array in a generic fashion
13:27:21 <Cale> (when you didn't know the size up-front)
13:27:21 <fen> yeah, the tying the knot uses a let bound reference to the returned completed dlist to make the final link
13:28:19 <fen> well the good point of using zippers of nested zippers is they can be stored in memory in the exact location desired
13:28:21 <fen> anyway..
13:29:31 <fen> the kind of reference in the paste is not the same as the version using Free2, where the "infinite container" never happens, there is just a reference to the pointer at a another location, which is what fails to be retained between traversals
13:34:03 <fen> basically by using !n on the already finished tree passed into the creation of the tree in the paste, the !n fixes the references location. 
13:34:15 <fen> how would that be traversed? 
13:34:50 <fen> wouldnt ts!n refer to the original not the updated traversed version?
13:35:29 <fen> the traversable instance must follow the same pattern as the creation. and all those indexes would need to be respecified?
13:36:06 <Cale> ts ! n refers to the Tree in a particular place in the Array
13:36:23 <Cale> the first time that expression is evaluated, it will do an Array lookup
13:36:47 <Cale> thereafter, the thunk will be evaluated already
13:37:37 <fen> how could it be though? the traversed version is a different thing, how could that already be evaluated?
13:39:18 <fen> even its functor instance...
13:39:43 <Cale> Oh, a Functor instance can't be made to respect this loopiness
13:39:49 <fen> ts!n would reference a tree with a different contents type
13:40:23 <Cale> If you tie the knot, fmap will take something occupying constant space to something which uses unbounded space
13:40:34 <fen> thats what was meant above with "the cycles are not retained between updates"
13:40:47 <Cale> Unless you're doing something like reallyUnsafePtrEquality#
13:41:01 <Cale> (and even then, that's not always going to save you! :)
13:41:25 <Cale> If you want to be able to do updates, you don't tie the knot in the first place
13:41:27 <fen> if the original tree was made by providing some pointer indicies, then these will also need to be provided to fmap
13:41:40 <fen> and the cyclic references rebuilt each time
13:41:50 <Cale> Updates in immutable cyclic data structures are a nightmare
13:42:09 <Cale> They just fundamentally can't be efficient
13:42:35 <fen> well so far its only as costly as doing a lookup of returned pointer locations
13:42:45 <fen> but it shouldnt be costly at all
13:43:08 <fen> maybe callCC cant be of any help at all, but its ability to reference previous locations seemed good
13:44:29 <fen> tying the knot is essential for making eg a 2d grid pointer which the cost of navigating over is independent of the path taken
13:45:13 <fen> but as the links cant be made permanent this seems like its impossible
13:48:55 <fen> hmm, maybe with use of fusion the updates can be commuted into the creation process...
13:48:59 <fen> brarg!
13:49:01 <Cale> fen: What I'd usually do is just to use Map or something like that
13:49:33 <Cale> and sure, you pay lookup costs in the Map repeatedly
13:49:52 <Cale> but usually that doesn't become much of a problem
13:50:13 <Cale> Of course, if you're doing image processing, maybe it's immediately a problem
13:52:08 <fen> an example use is loopy belief propagation 
13:52:30 <fen> its for communicating information between adjacent nodes on a graph
13:52:48 <fen> via a pointer comonad stencil
13:55:11 <fen> https://pastebin.com/raw/sujLnydr
13:56:43 <fen> imports found here https://gist.github.com/fen-hs
14:01:05 <zachk> if I can define a valid (>=>) for a type, can I derive a join and (>>=) if I have pure/return and fmap as well?
14:04:10 <Solonarv> % bind' m k = const m >=> k $ ()
14:04:10 <yahb> Solonarv: 
14:04:14 <Solonarv> % :t bind'
14:04:14 <yahb> Solonarv: Monad m => m b -> (b -> m c) -> m c
14:04:21 <Solonarv> % :t (>>=)
14:04:21 <yahb> Solonarv: Monad m => m a -> (a -> m b) -> m b
14:04:25 <Solonarv> zachk: ^
14:05:20 <Solonarv> % :t id >=> id
14:05:21 <yahb> Solonarv: Monad m => m (m c) -> m c
14:05:26 <Solonarv> ^ there's join
14:06:42 <zachk> ty Solonarv :)
14:13:38 * hackage avro 0.4.3.0 - Avro serialization support for Haskell  https://hackage.haskell.org/package/avro-0.4.3.0 (haskellworks)
14:19:57 <dminuoso> zachk: (>=>, pure) is completely equivalent to (>>=, pure) - in fact fmap is even recoverable from it. :)
14:20:33 <zachk> oh, how do I recover fmap from it?
14:20:34 <dminuoso> zachk: In fact, the monad laws are much more pleasing in the (>=>, pure) interpretation of monads.
14:20:57 <dminuoso> Since you get associativity: (f >=> g) >=> h = f >=> (g >=> h)
14:21:02 <zachk> I didn't really comprehend the laws fully until I saw them in (>=>) form 
14:21:11 <dminuoso> And both identities: f >=> id = id >=> f = f
14:21:29 <zachk> very much like abstract algebra in that form 
14:23:21 <dminuoso> % :t \f -> (pure . f) <=< id
14:23:21 <yahb> dminuoso: Monad m => (a -> c) -> m a -> m c
14:24:35 <dminuoso> zachk: ^-
14:25:03 <zachk> ty dminuoso 
14:25:17 <slack1256> From RTS options, is it possible to know how many haskell threads are alive?
14:26:09 <jackdk> contemplating the equivalence of join, (>=>) and (>>=) (and their laws) is a great way to understand the essence of monad
14:26:53 <Solonarv> slack1256: not from RTS options, but there is a 'getNumCapabilities' somewhere
14:27:01 <Solonarv> % :i getNumCapabilities
14:27:01 <yahb> Solonarv: getNumCapabilities :: IO Int -- Defined in `GHC.Conc.Sync'
14:27:26 <dminuoso> slack1256: What is your goal?
14:27:46 <slack1256> Yeah but that gets me the number of capabilities (HEC) avalaible. I want to know how many threads produced by `async` or `forkIO` are still running at any given moment.
14:27:59 <Solonarv> oh, hm
14:28:08 <slack1256> To check if I am killing them correctly and don't have a leak.
14:28:13 <Solonarv> I think you can probably get that from the RTS stats somehow
14:30:19 <im0nde> Hi, just starting out with haskell. I got the basic ideas and some of the syntax down, but feel I should read some actual haskell code "that does something" and is not just an example. Can anyone recommend some good haskell github repos that a beginner can read (not too complex stuff, but good code) 
14:30:40 <im0nde> I feel it could help to wrap my head a bit around funcional programming
14:30:48 <dminuoso> im0nde: I recommend writing code, solving problems.
14:31:14 <dminuoso> im0nde: What resource are you using to learn Haskell?
14:31:31 <im0nde> dminuoso: learn youself a haskell
14:31:38 <im0nde> and some videos on youtube.
14:32:15 <im0nde> I have programmeed queite a bit in other languges, so I have to change some of my assumptions.
14:32:50 <koala_man> im0nde: check out Real World Haskell. It's a free like LYAH, but has more practically oriented examples
14:32:52 <im0nde> I feel when I try to write something I either don't know how to approach it in gereral or try to keep doing what I always do in other languages
14:33:03 <im0nde> koala_man: Cool thanks! will do
14:33:13 <gentauro> im0nde: try to solve a `real` problem and avoid `katas`. Only when you `push` yourself to actually write usefull code, you will notice the pros/cons of Haskell
14:33:32 <dminuoso> im0nde: CIS194 is a superb resource - it comes with high quality examples/homework assignments.
14:33:42 <dminuoso> @where cis194
14:33:43 <lambdabot> https://www.seas.upenn.edu/~cis194/spring13/lectures.html
14:34:12 <gentauro> im0nde: once you understand the language, try to push it to the limits (my snippets) -> http://blog.stermon.com/snippets/
14:34:20 <gentauro> both in engineering but also theoretical
14:34:34 <gentauro> and then you can decide if the language is better than what else is out there
14:34:51 <gentauro> (my opinion is that Haskell is pretty good at most stuff)
14:35:35 <zenjester> hi all why use haskell for teaching undergrads and not ocaml?
14:36:36 <gentauro> zenjester: at Copenhagen University they actually use F# (OCaml spawn) to teach three paradigsm: Functional, imperative and Object Oriented programming
14:37:03 <gentauro> I think it's a good balance to get `novice` people to understand what programming is all about (we are talking about Computer Science students)
14:37:11 <dminuoso> zenjester: You will have to ask your professor.
14:37:29 <gentauro> the next languages are C/Assembly and so on
14:37:40 <zenjester> I am the professor :-)
14:37:46 <gentauro> LEL
14:38:15 <dminuoso> zenjester: I take it you are more familiar with OCaml than with Haskell?
14:38:18 <gentauro> zenjester: contact Torben Mogensen with regard of F# -> http://hjemmesider.diku.dk/~torbenm/
14:38:33 <zenjester> teaching functional next year and trying to find a language used haskell 20 years ago
14:39:41 <gentauro> test?
14:39:49 <gentauro> did you read any of my messages?
14:40:56 <zenjester> gentauro yes - F# considered but we use fedora in our labs
14:41:35 <gentauro> zenjester: is it a first year course?
14:41:43 <zenjester> masters
14:42:00 <gentauro> but no previous FP courses?
14:42:13 <zenjester> in software engineering
14:42:26 <zenjester> no first time course
14:42:41 <gentauro> well then go all in with Haskell :D
14:43:02 <gentauro> http://blog.stermon.com/articles/2019/02/04/haskell-usage-of-malloc-free-is-safe.html
14:43:04 <zenjester> thanks easier to setup and run than ocaml
14:43:19 <gentauro> zenjester: xD
14:43:28 <gentauro> specially if you just use `stack` ;)
14:43:33 <gentauro> it just "works"
14:43:54 <zenjester> yes used stack impressed big improvement on cabal
14:44:39 <gentauro> zenjester: btw, did you see the Google intro to Haskell with all the Ponies?
14:45:09 <zenjester> no
14:45:18 <gentauro> can't find the slides :(
14:45:38 <gentauro> but they where kind of `okayish` with regard of a introduction to the language
14:45:59 <zenjester> found them on reddit
14:46:04 <gentauro> xD
14:46:14 <gentauro> could you please share the link? ;)
14:47:31 <zenjester> https://github.com/google/haskell-trainings/releases
14:48:11 <gentauro> if you want `academic` inspiration, you might talk to Athas as I think he has been involved with the following Copenhagen University (Advanced Programming) course -> https://kurser.ku.dk/course/ndaa09013u/
14:49:55 <zenjester> thanks for the help will be back
14:51:45 <gentauro> sure no probs. Btw, I don't think those are the slides with all the ponyes xD
14:58:52 <wuffie> does gi-cairo and gi-glib install on windows?
15:08:38 * hackage mmark 0.0.6.2 - Strict markdown processor for writers  https://hackage.haskell.org/package/mmark-0.0.6.2 (mrkkrp)
15:10:38 * hackage haskus-binary 1.4 - Haskus binary format manipulation  https://hackage.haskell.org/package/haskus-binary-1.4 (SylvainHenry)
15:24:34 <zachk> is an endofunctor (Functor F) => f a -> f b or is it (Functor F) => a -> f b ? 
15:25:45 <Solonarv> the endofunctor is 'F'
15:25:56 <Solonarv> (if there is a 'Functor F' instance)
15:27:34 <zachk> how is it endo ? that just in Hask(ell) right?
15:27:40 <zachk> cause of fmap?
15:27:44 <zachk> % :t fmap 
15:27:44 <yahb> zachk: Functor f => (a -> b) -> f a -> f b
15:28:41 <c_wraith> zachk, the endofunctor of fmap is that the objects are Haskell types.
15:29:12 <c_wraith> zachk, on both sides I'd the transform, that is.
15:29:24 <zachk> so how is a monad a monoid over an endofunctor, when the "actions" look like a -> m b instead of m a -> m b 
15:30:57 <c_wraith> it's a monoid on the *category* of endofunctors
15:31:28 <c_wraith> you can just leave out words and expect it to make sense. :)
15:31:56 <c_wraith> ... like the "not" I left out in that sentence...
15:32:05 <Solonarv> specifically, the category of endofunctors with composition as the product
15:32:16 <shachaf> It's a monoid object in the category endofunctors with -- right
15:32:37 <shachaf> With other monoidal structures you get other meanings for monoids.
15:33:07 <Solonarv> so an endofunctor M is a monad iff there exist natural transformations M . M ~> M and Id ~> M
15:33:46 <Solonarv> or in Haskell: (forall a. M (M a) -> M a) and (forall a. Identity a -> M a)
15:33:59 <Solonarv> these are 'join' and 'return'
15:34:04 <unyu> The one monoidal structure I'm fascinated with is the one that gives us applicatives as the monoid objects.
15:34:20 <unyu> Since the monoidal product is less trivial in this case.
15:34:27 <c_wraith> unyu, Day convolution?
15:34:29 <unyu> Yes.
15:34:31 <shachaf> Stating operations without laws is such a Haskell thing to do.
15:34:40 <shachaf> Day convolution is too good.
15:34:50 <Solonarv> bah, I didn't feel like specifying them
15:35:39 <Solonarv> there is an alternative (heh) formulation: class Functor f => Applicative f where unit :: f (); product :: f a -> f b -> f (a, b)
15:35:57 <Solonarv> or even: product :: (f a, f b) -> f (a, b)
15:36:07 <unyu> We need to be less afraid to call them “<foo> homomorphism” or “natural transformation” or whatever. Sometimes a function is just the non-runtime-erased part of the data.
15:36:48 <Solonarv> this formulation is equivalent to the standard Haskell one because Hask has some nice categorical properties whose names I forget
15:37:56 <unyu> Solonarv: If you turn a blind eye to bottom, it is supposed to be bi-Cartesian closed, at the very least, I think.
15:38:56 <Solonarv> yeah, something like that
15:38:58 <unyu> (Two bad you cannot really ignore bottom, and all your nice properties then go “poof!”)
15:39:30 <Solonarv> you can often just conflate all values with any sort of bottom in them and keep most of the nice properties, though :>
15:40:08 <unyu> Argh, did I say “two”?
15:40:16 <Solonarv> oh I hadn't even noticed
15:41:37 <MarcelineVQ> Know, doughnut warty
15:59:20 <MarcelineVQ> This is probably much too vague to ask but is stream fusion, or more vanilla deforestation, as useful in a strict language as it is in a lazy one?
16:00:29 <Solonarv> I want to say "yes, but it's harder to implement"
16:01:31 <Solonarv> for example, look at Java's Stream interface
16:04:01 <Solonarv> In fact I would expect stream-fusion to often look that explicit in non-Haskell languages
16:04:21 <unyu> MarcelineVQ: In a strict language, I don't think streams are all that useful. I haven't seen many languages do this (other than C++ and its ilk), but I think it's useful to represent directly the intermediate state of traversing a data structure, in a way that doesn't hide the fact that different data structures are, well, different.
16:04:41 <Solonarv> laziness is only part of why it's so awesome in Haskell - GHC's support for rewrite rules also helps make stream fusion transparent
16:04:52 * sicklork1n is confused by this bird `(t -> [t] -> a) -> [t] -> [a]`
16:06:44 <MarcelineVQ> sicklork1n: are you wonder how you could write it, or what it could do?
16:08:11 <unyu> sicklork1n: What are you trying to do? It is not like a type is a full specification of a program.
16:08:12 * unyu ducks.
16:08:25 <MarcelineVQ> soon(tm)
16:08:29 <Solonarv> well, sometimes it is, but not here
16:09:15 <MarcelineVQ> unyu: Could you elaborate on the above, about intermediate state and not hiding differences?
16:09:55 <unyu> MarcelineVQ: For example, one thing I think C++ and related languages do right is that iterators into different data structures have different types.
16:10:25 <unyu> And they do not even have to have a common base class or anything.
16:10:38 <unyu> (*cough cough* Java *cough cough*)
16:10:49 <__monty__> sicklork1n: At a guess, apply the function to every pair of an element in the [t] and the rest of the [t]?
16:11:20 <unyu> MarcelineVQ: Streams are the opposite extreme: you maximally hide the internal state of the process that produces the elements of the stream.
16:12:04 <Solonarv> % thisBird f = mapMaybe (fmap (uncurry f) . uncons) . tails
16:12:05 <yahb> Solonarv: 
16:12:16 <Solonarv> 5 :t thisBird
16:12:18 <MarcelineVQ> I see, that description fits with the paper I'm looking at, where the state is existential
16:12:20 <Solonarv> % :t thisBird
16:12:20 <yahb> Solonarv: (a -> [a] -> b) -> [a] -> [b]
16:12:55 <nfd> After I was in here a little while ago asking about Megaparsec, I decided to go parse the Dyck language
16:12:55 <unyu> MarcelineVQ: It's okay if the state is an existential (i.e. an abstract type), but it doesn't have to be a *first-class* existential.
16:13:14 <Solonarv> % thisBird (fmap . (*)) [1..5]
16:13:14 <yahb> Solonarv: [[2,3,4,5],[6,8,10],[12,15],[20],[]]
16:13:21 <nfd> The shape of the data I'm banging that into is hideous, though
16:13:34 <nfd> Wondered if anyone could take a peek and suggest a better structure
16:13:35 <nfd> https://paste.ubuntu.com/p/xbKypZVYDX/
16:14:04 <__monty__> Solonarv: I rather had in mind everything but the element than tails.
16:14:15 <Solonarv> yeah, that works too
16:15:03 <Solonarv> % select [] = []; select (x:xs) = (x,xs) : (second (x:) <$> select xs)
16:15:03 <yahb> Solonarv: 
16:15:10 <Solonarv> % select [1..5]
16:15:11 <yahb> Solonarv: [(1,[2,3,4,5]),(2,[1,3,4,5]),(3,[1,2,4,5]),(4,[1,2,3,5]),(5,[1,2,3,4])]
16:15:36 <Solonarv> % thisBird' f = fmap (uncurry f) . select
16:15:36 <yahb> Solonarv: 
16:15:52 <Solonarv> % thisBird' (fmap . (*)) [1..5]
16:15:52 <yahb> Solonarv: [[2,3,4,5],[2,6,8,10],[3,6,12,15],[4,8,12,20],[5,10,15,20]]
16:15:54 <MarcelineVQ> unyu: What is a first class existential?
16:17:16 <Solonarv> (select is a neat function :D)
16:17:21 <unyu> MarcelineVQ: Ordinary Haskell existentials are first-class. (Non-first class, as they usually are) ML modules with abstract type components are second-class.
16:18:18 <Cale> ah, I would have thought ordinary Haskell existentials are not quite first class
16:18:40 <Cale> First-class existentials would involve a notation like (exists a. ...)
16:18:52 <__monty__> Solonarv: Kudos, wouldn't have thought of select. Don't think I've used it ever.
16:18:55 <Cale> which could be used without defining a new datatype
16:19:13 <unyu> Cale: Ah, my idea of “first-classness” was that you could construct existential values at runtime.
16:19:22 <nfd> And store them, and pass tehm
16:19:22 <Solonarv> you don't need a new datatype, you can encode them using continuations
16:19:36 <unyu> nfd: Right.
16:20:11 <unyu> Cale: In ML, modules are normally not things you construct at runtime, a certain ugly OCaml extension notwithstanding.
16:21:35 <Solonarv> (∀ r. (∀ a. T a → r) → r) is an encoding of (∃ a. T a)
16:23:22 <shachaf> First-class existentials seem like they'd either not be very useful or make inference/reading code much trickier.
16:23:40 <Solonarv> well as I demonstrated we can already encode them in Haskell
16:23:42 <jjb1> hello everybody!
16:23:48 <shachaf> Yes, but not first-class.
16:23:56 <Solonarv> jjb1: hi!
16:24:30 <jjb1> i have a couple questions on matters of style that i am hoping people will opine upon
16:24:54 <Solonarv> ask away!
16:25:11 <jjb1> one is the use of single-use newtypes to do parameter range checking. is it frowned upon?
16:25:24 <dminuoso> jjb1: never not newtype.
16:25:32 <jjb1> i.e. i have a function which takes an int, but only values from (say) 0 to 5
16:25:45 <jjb1> my inclination is to use a newtype with a private constructor that does range checking
16:25:48 <nfd> i guess you could have some type Human Job = Human {food :: Food, job :: Job}
16:25:58 <Solonarv> yup, that's perfectly appropriate
16:26:00 <dminuoso> jjb1: In general I'd say it's good practice. 
16:26:03 <nfd> you don't need to know the job at compiletime to know the Human can eat Foods
16:26:23 <dminuoso> jjb1: All newtype is, is compile time information that is erased by the compiler.
16:26:24 <jjb1> and return the same (MonadError MyErrorType m)-restricted thing as the thing it will get passed on to
16:26:27 <jjb1> excellent!
16:26:38 <Solonarv> if there are only a few possibilities you might also want to use an enumeration instead, e.g. data Day = Monday | ... | Sunday
16:26:39 <dminuoso> jjb1: So using newtypes to constraint or guide the compiler is perfectly fine.
16:26:55 <jjb1> well, depends on how few you think 0x10000000 things are ;)
16:27:03 <jjb1> my fingers would get tired
16:27:09 <Solonarv> that's a bit much :P
16:27:20 <jjb1> on to question two then!
16:27:30 <Solonarv> Really big enumeration types will tank your compile times anyway so you don't want to do that
16:27:31 <shachaf> Newtypes are a big hassle unfortunately.
16:28:22 <jjb1> right now i have a few newtypes which are fielded objects with a single field, and some newtypes which are not fielded. i can sometimes not remember why i chose one or the other, but the real answer is probably because i'm still a newbie. is there a consensus on general preference?
16:28:39 <dminuoso> jjb1: what do you mean with "fielded"?
16:28:45 <Solonarv> record syntax, I assume
16:28:51 <MarcelineVQ> has projection
16:28:59 <jjb1> data Foo = Foo { myFoo :: Bar }
16:29:05 <jjb1> ah yes, sorry
16:29:17 <jjb1> er, i guess probably myBar ;)
16:29:22 <Solonarv> I usually write them that way
16:29:25 <dminuoso> jjb1: It depends a bit on how you intend to use it.
16:29:59 <dminuoso> jjb1: But it's bike shedding - it's fine if you add an accessor, it's fine if you don't.
16:30:19 <Solonarv> yeah, and you can easily change it later anyway
16:30:21 <dminuoso> Not much difference either way.
16:30:27 <jjb1> excellent. would you say it's something that should be consistent within a project? or not even that important?
16:30:32 <dminuoso> jjb1: nope
16:30:49 <jjb1> excellent.
16:30:59 <jjb1> thank you all very much for the capable and friendly assistance!
16:33:02 <nfd> gonna take one more shot at this in case it got lost in the other question: i'm parsing the Dyck language, and the only target structure (unit aside) I've gotten to typecheck is awful
16:33:27 <nfd> i'd appreciate it if someone could point out any really simple solution i'm overlooking
16:33:28 <nfd> https://paste.ubuntu.com/p/xbKypZVYDX/
16:33:47 <dminuoso> shachaf: Do you really think so?
16:34:02 <shachaf> Yes, they're so much overhead.
16:34:32 <dminuoso> In what sense?
16:34:44 <dminuoso> And what else do you propose we could have instead?
16:34:57 <Solonarv> nfd: you don't actually need the 'Empty' case, I think
16:35:05 <Solonarv> you can just represent it as 'Some []'
16:35:23 <nfd> even without a type in the list?
16:36:44 <Solonarv> 'newtype Dyck = Some [Dyck]' is the type
16:36:44 <Solonarv> the 'Some []' value replaces the 'Empty' constructor
16:36:46 <dminuoso> % :t []
16:36:46 <yahb> dminuoso: [a]
16:36:46 <dminuoso> nfd: [a] unifies with [Dyck] just fine
16:37:46 <unyu> nfd: Yes, the Empty constructor is unnecessary.
16:37:46 <unyu> You already have a way to represent the empty string with it.
16:37:46 <unyu> Err
16:37:46 <unyu> You already have a way to represent the empty string without it.
16:37:49 <unyu> Mmm, perhaps “Free [] Void”?
16:38:31 <nfd> :t Free
16:38:32 <lambdabot> error: Data constructor not in scope: Free
16:38:56 <nfd> i do want that idea of fixed-point of List
16:38:59 <Solonarv> Free f Void is the same as Fix f
16:39:18 <Solonarv> you can also use 'type Dyck = Fix []'
16:39:46 <Solonarv> 'newtype Dyck = Some [Dyck]' is the same thing, just specialized to [] already
16:40:01 <reallymemorable> I am reading through the Pipes.Concurrency tutorial as I learn Haskell and am trying to dissect this function: https://paste.ofcode.org/YTMprxq6Uy9NjRvu9Pe4Z9
16:40:19 <reallymemorable> Does this basically say that it takes "forever" as an Int
16:40:40 <reallymemorable> and the Int defines the time parameter for the Consumer function?
16:40:57 <slack1256> I don't think that (i :: Int) is used at all.
16:41:25 <slack1256> plus shouldn't be "worker" be named "startWorker", so it matches the signature?
16:41:39 <Solonarv> that's clearly not the entire function
16:41:40 <nfd> Solonarv: i was having a heck of a time getting the compiler to believe a [] was a Fix []
16:41:43 <reallymemorable> https://paste.ofcode.org/Eh5KyTpckKEdNFABVGLPv2
16:41:44 <nfd> same when I used Nu
16:41:45 <reallymemorable> yeah sorry
16:41:52 <reallymemorable> i thought i could truncate it and it would still make sense
16:41:54 <Solonarv> nfd: well, good, because [] isn't the same as Fix []!
16:41:54 <reallymemorable> but clearly not
16:42:03 <Solonarv> you still need to apply the constructor
16:42:21 <reallymemorable> the constructor = "forever"?
16:42:23 <nfd> yeah
16:42:33 <Solonarv> reallymemorable: no, that was aimed at nfd
16:42:37 <reallymemorable> ah
16:42:52 <slack1256> reallymemorable: what is the problem with that code?
16:42:56 <sicklorkin> Solonarv:  did you say there's already a `(t -> [t] -> a) -> [t] -> [a]` bird with a name? (Lost my irc history)
16:43:00 <reallymemorable> there is no problem
16:43:07 <Solonarv> sicklorkin: no, I have no idea if there's a name for it
16:43:07 <reallymemorable> i am just trying to understand all th emoving parts
16:43:14 <Solonarv> I just wrote two possible implementations of it
16:43:34 <jmcarthur> Solonarv: They can be the same if you are using OverloadedLists
16:43:37 <sicklorkin> Oh.. darn i missed 'em..
16:43:54 <reallymemorable> that function takes an Int as an argument, correct?  and gives you a Consumer function
16:44:03 <slack1256> reallymemorable: Yep
16:44:05 <Solonarv> jmcarthur: yeah, but does Fix have an IsList instance?
16:44:05 <sicklorkin> min was `bird (x:xs) = f x xs : bird xs
16:44:15 <reallymemorable> what is happening with `a <- await`?
16:44:18 <Solonarv> sicklorkin: that's one of the implementations I gave
16:44:23 <slack1256> but Consumer is a monad, on it you can `await`
16:44:28 <Solonarv> % select [] = []; select (x:xs) = (x,xs) : (second (x:) <$> select xs)
16:44:28 <yahb> Solonarv: 
16:44:39 <Solonarv> % thisBird' f = fmap (uncurry f) . select
16:44:39 <yahb> Solonarv: 
16:44:45 <Solonarv> that's the other one I came up with
16:44:59 <slack1256> reallymemorable: It is analogous how on a "Reader Int a` you can `ask` for a Int.
16:45:17 <sicklorkin> thisBird (thisBird const) ... has an interesting property 
16:45:35 <sicklorkin> you bed back the original list?
16:45:38 <reallymemorable> so its basically the part that defines that it is "listening" for an `a`?
16:45:39 <sicklorkin> s/bed/get
16:45:42 <shachaf> I know this is Haskell, but I'd say that Free is data and Cofree is codata, and it's worth paying attention to that distinction with your fixed points.
16:47:21 <slack1256> reallymemorable: So that `await :: (Show a) => Consumer a IO a` it's bind as `a <- await` meaning that `a :: Show a => a`
16:48:02 <slack1256> reallymemorable: yes, it defined the "listening"/"consumer" part of "Consumer a IO r"
16:48:19 <reallymemorable> "a" is what it is waiting to receive
16:48:25 <slack1256> yep
16:48:42 <reallymemorable> and somewhere else I will define where it will look for "a"
16:48:43 <nfd> well, with those changes, I still can't come up on a way to make everything after the \y -> work out nicely
16:49:22 <slack1256> reallymemorable: yes, you will have to compose that consumer via the operators the pipe library defines so that await can come up with something
16:50:06 <slack1256> I must be on one hand a `Show a => Producer a IO r` and on another this `worker`
16:50:13 <slack1256> *It must
16:50:42 <reallymemorable> so I have to create a complementary Producer function
16:50:53 <slack1256> Yep
16:51:10 <slack1256> This is covered on the Pipes.Tutorial modules on the base pipes library.
16:51:43 <reallymemorable> got it yes -- I have been going through that.  I just like to read docs, then ask questions as a way to learn
16:51:52 <nfd> wouldn't it be nice if we could use cyclic types
16:51:55 <reallymemorable> otherwise it all dissipates from my brain
16:52:43 <nfd> what i want here is a [[[...[]...]]]
16:52:55 <nfd> it'd be awfully nice if i could just use that type
16:53:02 <slack1256> we could say otherwise isn't "really memorable" for you brain ;-)
16:53:11 <reallymemorable> lol yes
16:53:16 <Solonarv> that's exactly what Fix [] is, you just need a newtype wrapper at each layer
16:53:22 <ludat> hi everyone, I've got some very simple script to parse some pdfs, turn them into json and send the to an API...
16:53:22 <reallymemorable> the fact that my username is that is a clue as to how bad my memory is
16:53:51 * slack1256 is a vivid example of its nickname
16:53:57 <unyu> nfd: Unfortunately, any fixed points you introduce must go through data constructors, otherwise the type inference algorithm (more precisely the so-called “occurs check”) won't take it kindly...
16:54:07 * Solonarv has a nonsense nickname and is made of nonsense
16:54:07 <ludat> it works pretty well but it looks like it's slower than it should be, after --profile I see that 86% of the execution time is getAddrInfo, any idea why is that?
16:54:27 <nfd> Solonarv: if you can elucidate how exactly to make that work here, i'd love to see it
16:54:38 <slack1256> Solonarv: I always read you nick as sobolev (PDE spaces guy)
16:54:41 <nfd> couldn't figure out how to make the type system happy myself
16:54:42 <unyu> nfd: But, you could define your own type that is isomorphic to Fix [], but doesn't have any unnecessary wrapper constructors.
16:55:09 <MarcelineVQ> solonarv is a singular narv
16:55:11 <Solonarv> unyu: no, you can't
16:57:12 * hackage esqueleto 2.6.1 - Type-safe EDSL for SQL queries on persistent backends.  https://hackage.haskell.org/package/esqueleto-2.6.1 (parsonsmatt)
17:00:35 <Solonarv> nfd: I have a Dyck parser now, it's actually a one-liner
17:00:49 <unyu> Solonarv: After you simplify everything, the syntax trees of the Dyck language are (isomorphic to) binary trees. Like, “data Tree = Leaf | Node Tree Tree”. Using the convention that the left child is a genuine child, whereas the right child is actually the right sibling.
17:01:00 <nfd> oooh, neat
17:01:33 <Solonarv> this doesn't really have *less* wrapping than Fix [], though
17:01:56 <nfd> can it really be much worse than what I had?
17:02:04 <nfd> mine just looked redundant
17:02:16 <Solonarv> here's mine: https://gist.github.com/Solonarv/a92ba49e29702cdb88c9c1e6a99d4944
17:03:16 <unyu> Solonarv: It has less wrapping than Fix, because the Fix constructor itself doesn't represent any choices.
17:03:25 <nfd> that's way better, yeah
17:04:31 <unyu> Solonarv: Whereas my representation only requires using data constructors for actual choices: Leaf and Node correspond to Fix [] and “\x xs -> Fix (x:xs)” in your representation.
17:04:51 <Solonarv> yeah, I guess
17:05:03 <Solonarv> my representation makes writing the parser almost trivial though :p
17:05:34 <unyu> Right, because parser combinator libraries provide combinators for parsing sequences.
17:06:42 <Solonarv> in fact you can read this parser straight off the second grammar on https://en.wikipedia.org/wiki/Dyck_language
17:07:00 <Solonarv> namely: S → ("[" S "]")*
17:07:42 <unyu> Given that, in practice, the effort spent on parsing is only a tiny fraction of the effort spent on subsequent semantic analyses (not in nfd's example, though!), I prefer using less pointless wrapper constructors if possible. :-)
17:08:31 <nfd> fair
17:08:36 <Solonarv> I mean really the result type is superfluous if you just want to recognize the language
17:08:51 <nfd> this example's pointless enough that the first time i just parsed it to ()
17:08:59 <nfd> ie. recognized the language
17:09:02 <Solonarv> ^- yeah, I was typing the same thing
17:09:29 <nfd> obviously i'm still super unfamiliar with actually applying all of these parser combinators
17:09:38 <nfd> i'll go get some more practice with that :D
17:10:11 <nfd> luckily my "endgame language" here isn't gonna be too too crazy
17:11:07 * hackage simple-get-opt 0.3 - A simple library for processing command-line options.  https://hackage.haskell.org/package/simple-get-opt-0.3 (IavorDiatchki)
17:11:43 <nfd> come to think of it, before megaparsec, i'm not totally sure I ever came across anything like (Token s ~ Char, Stream s)
17:11:48 <nfd> what's the ~ mean?
17:11:59 <Cale> It means "is equal to" for types
17:12:02 <slack1256> Type equality
17:12:08 <nfd> thank you
17:12:21 <Solonarv> I was just being more general because I didn't want to fix the parser to Text
17:12:54 <Solonarv> that way I could just feed it String in ghci
17:12:55 <slack1256> Does haskell have a stablished room on matrix ?
17:13:26 <nfd> i thought irc was the Cool Kids Club XD
17:13:36 <Cale> There are way too many chats now
17:13:36 <Solonarv> nfd: my showDyck was wrong btw, I fixed it now
17:14:19 <PapaDinkle> nfd: oh. i can certainly assure you that I am one of the Cool Kids so you must be right. 
17:15:59 <nfd> but i guess json's cool
17:16:03 <nfd> matrix can't be so bad
17:17:50 <unyu> I'm not sure if this is the right place to ask, but has it previously been noticed that LR parsing is zipperified LL parsing? Of course LR parsing is more flexible, because the zipper is an ordinary data structure that you can inspect at will, unlike the continuation of a function.
17:21:53 <hololeap> does anyone know of a typeclass that can generalize Functors that are similar to Maybe, in that they have at least one constructor that holds data of type `a`, and at least one that doesn't?
17:22:13 <slack1256> @info Foldable
17:22:14 <lambdabot> Foldable
17:22:32 <slack1256> hololeap: Probably Foldable is that typeclass
17:22:35 <unyu> hololeap: I guess Pointed generalizes “has a Just constructor”.
17:22:40 <hololeap> wait, Foldable, really?
17:22:46 <slack1256> Yep
17:22:50 <Solonarv> not really, functions have a Pointed instance
17:23:07 <slack1256> [] -> Nothing , x:xs has Just x
17:23:23 <slack1256> sure it has more, but it really related to Monoids via foldMap
17:23:25 <unyu> Solonarv: Functions from an arbitrary domain?
17:23:32 <Solonarv> yes
17:23:39 <unyu> What would that instance do?
17:23:41 <unyu> undefined?
17:23:48 <hololeap> i guess that makes sense... you could use toList and then check with `null`
17:23:48 <unyu> I'm not sure how that instance would be helpful.
17:23:51 <Solonarv> instance Pointed ((->) e) where point x = \_e -> x
17:24:01 <slack1256> @type traverse_
17:24:02 <unyu> Oh, right, duh.
17:24:03 <lambdabot> (Applicative f, Foldable t) => (a -> f b) -> t a -> f ()
17:24:11 <Solonarv> after all Pointed is half of Applicative, and functions have an Applicative instance!
17:24:16 <unyu> Yes, yes.
17:24:18 <slack1256> > traverse print Nothing
17:24:18 <unyu> My bad.
17:24:20 <lambdabot>  <IO (Maybe ())>
17:24:27 <slack1256> > traverse print (Just 5)
17:24:29 <lambdabot>  <IO (Maybe ())>
17:24:34 <slack1256> > traverse_ print (Just 5)
17:24:34 <Solonarv> % traverse print Nothing
17:24:35 <yahb> Solonarv: ; <interactive>:134:10: error:; * Ambiguous type variable `a0' arising from a use of `print'; prevents the constraint `(Show a0)' from being solved.; Probable fix: use a type annotation to specify what `a0' should be.; These potential instances exist:; instance [safe] (Show a, Show b) => Show (Q.Fun a b) -- Defined in `Test.QuickCheck.Function'; instance Show Q.ASCII
17:24:36 <lambdabot>  <IO ()>
17:24:39 <Solonarv> % traverse_ print Nothing
17:24:40 <yahb> Solonarv: ; <interactive>:135:1: error:; * Variable not in scope: traverse_ :: (a1 -> IO ()) -> Maybe a0 -> t; * Perhaps you meant one of these: `traverse' (imported from Prelude), `traversed' (imported from Control.Lens), `traverse1' (imported from Control.Lens)
17:24:48 <Solonarv> nani?
17:24:53 <Solonarv> anyway, yahb will actually run OP
17:24:55 <Solonarv> * IO
17:25:05 <Solonarv> % :set -XExtendedDefaultRules
17:25:05 <yahb> Solonarv: 
17:25:16 <Solonarv> % :m + Data.Foldable Data.Traversable
17:25:16 <yahb> Solonarv: 
17:25:23 <Solonarv> % traverse_ print Nothing
17:25:24 <yahb> Solonarv: 
17:25:25 <slack1256> You can think of "Maybe b" as a list with at most 1 element
17:25:31 <Solonarv> % traverse_ print (Just 5)
17:25:31 <yahb> Solonarv: 5
17:25:32 <slack1256> so yeah, Foldable
17:26:19 <slack1256> (well, this is just part of my agenda of trying to make people use Foldable's foldMap + coerce more, really awesome stuff)
17:26:32 <Solonarv> foldMap is awesome :D
17:27:07 <benzrf> :t coerce
17:27:08 <lambdabot> error:
17:27:08 <lambdabot>     • Variable not in scope: coerce
17:27:08 <lambdabot>     • Perhaps you meant ‘coerced’ (imported from Control.Lens)
17:27:17 <Solonarv> % :t coerce
17:27:17 <yahb> Solonarv: Coercible a b => a -> b
17:27:24 <slack1256> Recently I had to use foldMap + the Alt newtype on the STM monad. I implemented a epoll-like system for TMVar's on a single line.
17:27:29 <slack1256> That stuff is magic
17:27:31 <Solonarv> nice!
17:27:52 <Solonarv> (note: getAlt . foldMap Alt = asum)
17:28:23 <slack1256> Yeah, I discovered someone had already given that a name. Rediscovering that was good though
17:28:40 <Solonarv> yep :D
17:29:14 <Solonarv> I do prefer using the specialized foldMap's when they exist (e.g. traverse_, asum, length, sum &c)
17:30:07 <hololeap> this makes me think of something that people have asked here before, which is if it is possible to have a Foldable that isn't also a Functor
17:30:52 <Solonarv> yes, Set is my go-to example
17:31:47 <hololeap> oh, right, because of the constraint. but it is still a functor, it's just not possible to define a Functor instance for it
17:32:09 <Solonarv> indeed
17:32:12 * Solonarv thinks
17:32:47 <hololeap> it also seems like any Comonad would, by nature, have a valid Foldable instance as well
17:33:01 <Solonarv> oh? how?
17:33:33 <Solonarv> foldMap f = f . extract ?
17:33:44 <hololeap> yeah, basically
17:33:58 <Solonarv> that... somehow that just doesn't seem right
17:34:41 <hololeap> i don't think that's a good default definition, but the fact that you can always extract an element means you could always make a minimal definition for foldMap
17:35:15 <hololeap> not that it matters much...
17:35:52 <Solonarv> oh, here's a silly Foldable-not-Functor:
17:36:12 <slack1256> MonoFoldable?
17:36:14 <Solonarv> % data Silly a where MkSilly :: Int -> Silly Int
17:36:15 <yahb> Solonarv: 
17:36:24 <slack1256> @where MonoFoldable
17:36:24 <lambdabot> I know nothing about monofoldable.
17:36:41 <Solonarv> % instance Foldable Silly where foldMap f (MkSilly i) = f i
17:36:42 <yahb> Solonarv: 
18:10:38 <hololeap> something i've never understood is why it's called a cofree comonad, instead of just a free comonad. are the concepts of free and cofree really that different?
18:17:43 <shachaf> Yes.
18:18:03 <shachaf> The free functor is left adjoint to the forgetful functor, an the cofree functor is right adjoint.
18:18:44 <shachaf> (Of course, "forgetful" doesn't really have a precise meaning. When you start saying "cofree", you can't even get away with the usual meaning of "right adjoint".)
18:19:12 <shachaf> But anyway "free" doesn't mean you don't pay for it, it means that it's unconstrained, or something.
18:21:39 <hololeap> i understand conceptually what a free monoid, free monad, and cofree comonad are, and the overarching pattern seems to be "it satisfies the laws with the minimal amount of structure"
18:23:08 <shachaf> "free monad" means "monad homomorphism : Free f -> m are in natural correspondence with natural transformations : f -> m"
18:23:12 <shachaf> (For any monad m and any functor f.)
18:24:01 <hololeap> right, there is a unique homomorphism from the free * to any other * ... is that correct?
18:24:58 <hololeap> i made some drawings when i was learning about adjunctions from milweski's book. i'll have to dig those up
18:26:12 <unyu> hololeap: Let f be a functor. Every natural transformation f → m, with m a monad, can be uniquely decomposed as the natural transformation f → Free f, followed by a monad morphism Free f → m.
18:26:31 <hololeap> i didn't realize that a cofree functor was a right adjoint, but maybe it would be more obvious if i was looking at a diagram
18:27:30 <unyu> Conversely. Every natural transformation w → f, with w a comonad, can be uniquely decomposed as a comonad morphism w → Cofree f, followed by the natural transformation Cofree f → f.
18:28:38 <unyu> (But I still find it difficult to believe that people actually use these things when programming. To think that here I manipulate predicates on state variables the good old Hoare way.)
18:29:59 <hololeap> unyu: i don't think that anyone uses these things directly when programming. the closest attempt would probably be kmett's libraries. but it's still useful knowledge and can give some insights
18:30:23 <hololeap> at the very least, it's good to know the etymology of the terms
18:31:17 <unyu> I meant it as in “I see it and I still don't believe it”, rather than “I have no evidence that...”.
18:31:39 <Solonarv> yeah, clearly people do use these things
18:31:53 <Solonarv> (especially free monads, comonads seem to be a bit ignored)
18:32:25 <hololeap> i like cofree comonads. a trie is basically a cofree comonad
18:32:49 <hololeap> they have their uses and knowing the laws they satisfy gives you more confidence when coding
18:34:47 <hololeap> i went from ruby to haskell after a) biting myself with too much metaprogramming b) realizing that all programming is math
18:35:12 <unyu> a) Understandable. b) Errr, no?
18:35:57 <hololeap> it *is* math, though, and if you don't treat it as such you are going to run into issues
18:36:24 <unyu> No, I mean, I do both math and programming, and they're definitely not very alike.
18:36:27 <geekosaur> but taking that pov too far means you hit snobol or perl and confuse yourself
18:37:14 <hololeap> snobol?
18:37:44 <geekosaur> old IBM language. think of it as fortran for string processing
18:38:20 <geekosaur> it's something of a weird language
18:39:05 <unyu> hololeap: Maybe if your idea of “programming” is “designing algorithms and solving number theory puzzles all day long”, maybe then programming is math. :-p
18:39:46 <geekosaur> its original author tried again later with algol-style syntax instead of fortran-style, and the result was icon
18:40:05 <unyu> geekosaur: Still designed around string processing?
18:40:53 <geekosaur> icon has generalized some of the ideas, btu cset being a basic type still shows its string processing core. and string scanning, which is pretty fundamental
18:41:50 <geekosaur> (cset is what Haskell would call Set Char, but with specific syntax and language support)
18:42:03 <unyu> I find it difficult to trust languages that treat strings too seriously as a fundamental thing. These tend to be languages that don't have a good notion of alpha-equivalence.
18:43:15 <unyu> We can civilizedly disagree about strict vs. lazy or even typed vs. untyped, but “renaming a local variable preserves the program's meaning” is sacred.
18:43:51 <mniip> screw reflection then ;)
18:44:06 <hololeap> unyu: what kind of programming have you done that didn't involve algorithms, number theory, or, for that matter, any other branch of math? i feel like the point that programming == math is pretty obvious.
18:44:11 <geekosaur> icon does not confuse the map with the territory
18:44:25 <Solonarv> surely you mean "if said renaming doesn't cause it to now shadow/not shadow a variable from an outer scope"
18:44:47 <unyu> Solonarv: Ah, sure, sure.
18:45:11 <unyu> hololeap: Data entry and report generation systems.
18:45:13 <geekosaur> even haskell has that one, I've had to help people figure out why a program broke when they used the name of a Prelude function as a local binding (think head)
19:38:37 * hackage cachix 0.2.0 - Command line client for Nix binary cache hosting https://cachix.org  https://hackage.haskell.org/package/cachix-0.2.0 (domenkozar)
19:39:37 * hackage cachix-api 0.2.0 - Servant HTTP API specification for https://cachix.org  https://hackage.haskell.org/package/cachix-api-0.2.0 (domenkozar)
19:55:11 <manjaro-user_> Hello everyone, I'm beginning to learn Haskell and I have a strange problem. Anytime I call a recursive function, I get *** Exception: stack overflow. This is for small inputs for factorial and fibonacci. This just recently started happening. Can anyone please help?
19:55:48 <Cale> manjaro-user_: I can try
19:55:54 <Cale> manjaro-user_: What's your program?
19:56:10 <manjaro-user_> Hi Cale, I am just using ghci 
19:56:35 <manjaro-user_> f 1 = 1; f 2 = 2; f x = f (x-1) + f(x-2)
19:56:45 <Cale> Are you entering it with semicolons like that?
19:57:01 <manjaro-user_> No I entering it per-line
19:57:03 <Cale> If you type it on three lines into ghci, you'll be shadowing your previous definitions of f each time
19:57:11 <manjaro-user_> ^I am entering it per-line
19:57:17 <Cale> Right, that would be why
19:57:33 <Cale> It's probably more comfortable if you make a new .hs file and load that
19:57:41 <Cale> and just keep your editor open alongside ghci
19:57:54 <Cale> :r in ghci will reload the file
19:58:17 <Cale> Basically, you were ending up with only  f x = f (x-1) + f (x-2)
19:58:26 <Cale> and that was just recursing forever
19:58:46 <manjaro-user_> ah ok!
19:59:11 <manjaro-user_> yes, I wrote a script and it works when I load it in ghci
19:59:45 <manjaro-user_> Thank you Cale!
19:59:49 <Cale> no problem!
20:00:03 <Cale> Feel free to ask any questions you might have here
20:00:17 <manjaro-user_> p.s. how would I enter fibonacci into ghci without writing another script and loading it?
20:01:42 <manjaro-user_> perhaps setting multi-line input mode? :set +m
20:01:57 <Cale> Yeah, you can do that, or use :{ and :}
20:02:04 <Cale> or just put semicolons
20:02:15 <manjaro-user_> super, thanks a bunch Cale. Off to more learning!
20:59:38 * hackage servant-kotlin 0.1.1.7 - Automatically derive Kotlin class to query servant webservices  https://hackage.haskell.org/package/servant-kotlin-0.1.1.7 (matsubara0507)
21:01:22 <dinnu93> Hey guys, I'm trying to write a simple markdown parser using megaparsec , here is my [source code](https://github.com/dinnu93/MdParser) which takes only headings and paragraphs into consideration for now.
21:01:23 <dinnu93> The problem I'm facing is how to parse single newline in between lines in a paragraph which markdown totally ignores without screwing up the double newlines which mark the end of a paragraph ?
23:32:13 <kadoban> Look for a newline not followed by another newline?
