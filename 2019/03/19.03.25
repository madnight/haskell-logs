00:22:22 <Lears> koz_: Don't you want `Left j -> Left (decodeFinite j)`, and similarly for the `Right` case?
00:23:07 <koz_> Yeah, I do, thanks.
00:24:26 <koz_> Now I get a _different_ error.
00:26:39 <koz_> Namely: https://gist.github.com/kozross/cba8a5d4c55fb5dba87019fe55dd2632
00:26:57 <koz_> Why does it determine 'Cardinality k a
00:27:00 <koz_> ' of all things?
00:27:37 <koz_> Wait, never mind, type application was throwing it.
00:28:24 <koz_> Now it's failing to derive n <=? k from the context k ~ (n + m).
00:28:29 <koz_> Argh.
00:36:20 <koz_> The old two-punch of ghc-typelits-natnormalise and ghc-typelits-knownnat seem to have fixed that.
01:42:04 <mywen> hello
02:32:03 <mywen> hello everyone ,how can execute python code in haskell project
02:32:27 <mywen> python code in a file
02:33:31 <mywen> plz i need help
02:33:35 <dminuoso> mywen: What is your goal exactly?
02:34:11 <mywen> en i get a python file and i wanna run it to get the result
02:40:08 <dminuoso> mywen: You could use the `process` facilities.
02:41:43 <mywen> tks :) ......
03:12:22 <Unhammer> hey, I have a heap profile with some high but short spikes at the end: https://i.imgur.com/KuvYbCs.png and I'm trying to reduce max residency – how can I "zoom in" on that? can I munge the .hp to only have the last N seconds somehow?
03:13:37 * hackage generics-mrsop 2.0.0 - Generic Programming with Mutually Recursive Sums of Products.  https://hackage.haskell.org/package/generics-mrsop-2.0.0 (vcmiraldo)
03:23:33 <delYsid> I need a name for f a b = a .&. complement b
03:24:58 <c_wraith> clear?
03:26:23 <Ariakenom> clearMask?
03:29:57 <delYsid> Like, clearMask vs the existing clearBit, thats nice.
03:30:04 <Unhammer> actually, that was quite simple to do with a little awk :)
03:32:07 * hackage raaz 0.2.1 - The raaz cryptographic library.  https://hackage.haskell.org/package/raaz-0.2.1 (PiyushKurur)
03:48:37 * hackage publish 0.4.4 - Publishing tools for papers, books, and presentations  https://hackage.haskell.org/package/publish-0.4.4 (AndrewCowie)
04:44:07 * hackage ats-pkg 3.2.5.11 - A build tool for ATS  https://hackage.haskell.org/package/ats-pkg-3.2.5.11 (vmchale)
04:53:13 <siraben> Is there a more efficient way to write this? https://dpaste.de/DhaW
04:53:46 <siraben> I'm essentially trying to find the number of times characters change in a given string
04:54:33 <siraben> (zero "00011110001110") would return 4, because there's 4 times the characters change
04:54:42 <siraben> Maybe I'm missing some fold to make it simpler?
04:54:45 <phadej> > length $ group "00011110001110"
04:54:47 <lambdabot>  5
04:54:52 <phadej> > length $ group "0"
04:54:54 <lambdabot>  1
04:54:55 <phadej> > length $ group ""
04:54:57 <lambdabot>  0
04:57:32 <siraben> phadej:  but the input "01001001" doesn't work with (length . group)
04:57:41 <siraben> oops it does
04:57:49 <siraben> I mean passing "00011110001110" should return 4
04:58:57 <phadej> siraben: you can `pred' 0 = 0; pred' n = pred n` if you need to fix that one-by-maybe-not-an-error
04:59:32 <oleks> Hi, is it possible to use Parsec together with Text.PrettyPrint.GenericPretty?
04:59:57 <siraben> phadej:  What do you mean?
04:59:58 <oleks> In particular, is there a way to make Parsec's ParseError an instance of Out?
05:00:39 <Solonarv> > countFlips = length . filter (uncurry (/=)) . (zip`ap`tail)
05:00:42 <lambdabot>  <hint>:1:12: error:
05:00:42 <lambdabot>      parse error on input ‘=’
05:00:42 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
05:00:49 <Solonarv> @let countFlips = length . filter (uncurry (/=)) . (zip`ap`tail)
05:00:50 <lambdabot>  Defined.
05:01:01 <Solonarv> > countFlips "00011110001110"
05:01:03 <lambdabot>  4
05:01:23 <Solonarv> siraben: ^
05:01:39 <siraben> Solonarv:  thanks!
05:01:43 <Solonarv> > countFlips ""
05:01:45 <lambdabot>  0
05:01:47 <siraben> Ah, clever use of `ap`
05:01:55 <Solonarv> @where zip.ap.tail
05:01:55 <lambdabot> I know nothing about zip.ap.tail.
05:02:01 <Solonarv> @quote zip.ap.tail
05:02:02 <lambdabot> quicksilver says: zip`ap`tail - the Aztec god of consecutive numbers
05:02:05 <Solonarv> :D
05:02:17 <siraben> How does zip `ap` tail even work like that?
05:02:38 <phadej> > countFlips ""
05:02:40 <lambdabot>  0
05:02:47 <Solonarv> it use the Applicative (or rather, Monad) instance for functions
05:03:18 <Solonarv> (f `ap` g) x = f x (g x)
05:03:35 <Solonarv> so zip`ap`tail = \xs -> zip xs (tail xs)
05:05:57 <Solonarv> I could've used <*> instead of `ap` but then we wouldn't get the "Aztec god" joke :p
05:06:46 <Ariakenom> worth :D
05:07:01 <__monty__> Should define a local helper `tl = tail`
05:08:41 <Solonarv> also, 'zip' inspects its first argument before the second one, which is why zip`ap`tail doesn't crash on empty lists
05:09:13 <mniip> are we doing fibonacci
05:09:15 <Solonarv>   (zip`ap`tail) []
05:09:15 <Solonarv> = zip [] (tail [])
05:09:15 <Solonarv> = []
05:09:32 <Solonarv> mniip: no, counting spots in a list where the value changes
05:09:39 <mniip> I see
05:09:43 <Solonarv> > countFlips "00011110001110"
05:09:45 <lambdabot>  4
05:09:53 <mniip> length . group
05:10:01 <Solonarv> yes, that was brought up too
05:10:04 <Solonarv> off by one though
05:11:36 <Solonarv> my definition was: countFlips = length . filter (uncurry (/=)) . (zip`ap`tail)
05:11:47 <dminuoso> 13:08:19  Solonarv | also, 'zip' inspects its first argument before the second one, which is why zip`ap`tail doesn't crash on empty lists
05:11:57 <dminuoso> ^- Are you sure this is actually guaranteed by the report?
05:12:06 <dminuoso> Because I cant find anything about that behavior.
05:12:17 <Solonarv> I'm not, no
05:12:38 <Solonarv> I freely admit that this is post-hoc reasoning - "it didn't crash on empty list? oh, this must be the reason"
05:12:59 <phadej> zipWith          :: (a->b->c) -> [a]->[b]->[c]  
05:12:59 <phadej> zipWith z (a:as) (b:bs)   =  z a b : zipWith z as bs  
05:13:00 <phadej> zipWith _ _ _    =  []
05:13:03 <phadej> is report definition
05:13:25 <phadej> and yes, it inspects first argument first
05:14:25 <lyxia> does the report really constrain evaluation order
05:14:34 <phadej> lyxia: pattern matching, yes.
05:14:50 <dminuoso> phadej: Mmm, where is that from?
05:17:40 <phadej> "Pattern matching in
05:17:41 <phadej> Haskell works top-to-bottom, and left-to-right"
05:17:44 <phadej> in https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/gadtpm-acm.pdf
05:17:52 <phadej> I guess SPJ knows what he writes about
05:18:25 <phadej> also in report the "sub-patterns are matched left-to-right" is in case of con v1 ... vn
05:19:18 <__monty__> dminuoso: Zip isn't actually in the report afaik but that's irrelevant.
05:20:11 <lyxia> I'm pretty sure purity makes it so it doesn't matter
05:20:40 <Ariakenom> here's zip https://www.haskell.org/onlinereport/standard-prelude.html
05:20:42 <phadej> > zip (tail []) []
05:20:44 <lambdabot>  *Exception: Prelude.tail: empty list
05:20:56 <lyxia> oh
05:21:07 <lyxia> ok that makes sense now
05:22:46 <phadej> and there are translations like: let {p1=e1;  ... ; pn=en} in e0=let (~p1, ... ,~pn) = (e1, ... ,en) in e0
05:23:56 <phadej> but it's tricky to follow all the translation, so I won't do it now
05:26:15 <lyxia> you are forgiven
05:28:14 <__monty__> Ariakenom: Ah, I was wrong. Though it does say that the Prelude needn't be implemented the same way. So, how much is the implementation allowed to deviate? If semantics have to be identical that doesn't leave much room for performance improvement, right?
05:29:25 <phadej> __monty__: if you look at the `base` impl there is USE_REPORT_PRELUDE definitions
05:29:54 <phadej> e.g in https://github.com/ghc/ghc/blob/master/libraries/base/GHC/List.hs
05:30:01 <lyxia> Exceptions can still be imprecise
05:31:10 <lyxia> so if you know a function is strict in its second argument, and this argument happens to be undefined, you can throw the exception right there without looking at the first.
05:31:54 <phadej> makes sense, _|_ are indistiguishable in pure code
05:33:29 <Ariakenom> __monty__: i'd expect other implementations not to break code written of of the specification
05:35:18 <siraben> Solonarv:  I understand zip and tail, but not how it interacts with `ap` 
05:35:20 <siraben> @t ap
05:35:21 <lambdabot> Maybe you meant: tell thank you thanks thesaurus thx tic-tac-toe ticker time todo todo-add todo-delete type v @ ? .
05:35:31 <siraben> :t ap
05:35:32 <lambdabot> Monad m => m (a -> b) -> m a -> m b
05:36:18 <siraben> :t \x -> (x `ap` tail) "hello"
05:36:19 <lambdabot> ([Char] -> [Char] -> t) -> t
05:36:47 <Ariakenom> Solonarv said
05:36:50 <Ariakenom> (f `ap` g) x = f x (g x)
05:36:54 <Ariakenom> so zip`ap`tail = \xs -> zip xs (tail xs)
05:37:27 <siraben> > ((\x -> \y -> (x, y)) `ap` tail) "hello"
05:37:29 <lambdabot>  ("hello","ello")
05:37:34 <siraben> Ah this makes sense
05:37:46 <Solonarv> :D
05:37:52 <siraben> So you're zipping the string with its tail
05:38:03 <Solonarv> precisely
05:38:11 <siraben> And `ap` doesn't discard the argument?
05:38:14 <siraben> Because 
05:38:16 <siraben> > tail "hello"
05:38:18 <lambdabot>  "ello"
05:38:47 <Solonarv> what do you mean by "discard"?
05:38:59 <siraben> Oh never mind, I just read the source of ap
05:39:03 <siraben> https://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.Base.html#ap
05:39:06 <siraben> Very clear
05:39:42 <siraben> Huh I think I've seen that before
05:39:45 <Solonarv> there is also <*> which is exactly the same thing as ap but more general
05:39:45 <siraben> :t (<*>)
05:39:46 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
05:39:50 <siraben> :t (<$>)
05:39:51 <lambdabot> Functor f => (a -> b) -> f a -> f b
05:40:17 <siraben> Oops I'm conflating them
05:40:34 <siraben> Yeah it's like <*> but over monads instead
05:41:13 <Solonarv> yes
05:41:46 <Solonarv> to some extent, ap is historical baggage, but it's still useful for writing Applicative instances
05:42:05 <Solonarv> since you can just write (<*>) = ap, instead of implementing <*> yourself
05:42:16 <Solonarv> (when you also have a Monad instance, of course)
05:43:15 <Solonarv> and the existence of ap also makes it easy to state one of the laws relating Monad and Applicative
05:43:27 <Solonarv> that law is simply: (<*>) = ap
05:45:01 <siraben> how does the original "hello" still get passed
05:45:07 <siraben> The list monad simulates non-determinism?
05:45:10 <siraben> :t ap [(+3)] [1,2,3]
05:45:12 <lambdabot> Num b => [b]
05:45:16 <siraben> > ap [(+3)] [1,2,3]
05:45:18 <lambdabot>  [4,5,6]
05:45:25 <siraben> > ap [(+3), (+5)] [1,2,3]
05:45:27 <lambdabot>  [4,5,6,6,7,8]
05:45:42 <siraben> huh looks like some composition of map and concat
05:46:11 <__monty__> Ariakenom: Yeah but there's various levels of breakage.
05:46:46 <FSMnArmosta_> Does ByteString.putStr flush stdout?
05:46:49 <Solonarv> siraben: the list monad is not involved here
05:46:56 <phadej> FSMnArmosta_: no
05:47:05 <siraben> So ap can be thought of as taking an M (a -> b), an (M a) and mapping the function over it (M (M b)) and flattening it to yield (M b)?
05:47:07 <FSMnArmosta_> phadej: thanks
05:47:30 <Solonarv> siraben: that's one way to think about it
05:47:49 <siraben> Solonarv: , which monad then?
05:47:49 <Solonarv> but it doesn't generalize to Applicative, because "flattening" needs a Monad instance
05:48:06 <Solonarv> siraben: functions!
05:48:16 <siraben> The function monad?
05:48:19 <Solonarv> instance Applicative ((->) e) where ...
05:48:21 <siraben> Mm
05:48:30 <siraben> Ah the reader monad
05:48:33 <siraben> Of course!
05:48:38 <Solonarv> or using slightly nicer fake syntax: instance Applicative (e ->) where ...
05:48:40 <Solonarv> indeed
05:48:46 <siraben> And (->) is a profunctor right?
05:49:14 <Solonarv> it is, but that's not really relevant here :p
05:49:25 <siraben> Contravariant in the first argument, covariant in the second
05:49:26 <siraben> Right
05:49:31 <siraben> It's the applicative nature
05:49:52 <siraben> I should read up on applicatives, just reached there in category theory for programmers
05:50:20 <phadej> approaching applicatives through CT is very long detour
05:50:39 <phadej> but whatever works
05:51:18 <Solonarv> and there are actually two or three different category-theoretical things (which happen to be equivalent in Haskell) which you could use to define Applicative
05:52:58 <Solonarv> another possible definition would be:
05:52:58 <Solonarv> class Functor f => Monoidal f where
05:52:58 <Solonarv>   unit :: f ()
05:52:58 <Solonarv>   (><) :: f a -> f b -> f (a, b)
05:53:29 <Solonarv> it's fairly easy to see that this is equivalent to the usual Applicative
05:54:06 <Solonarv> but the corresponding category-theoretical things are not always equivalent
05:58:07 * hackage ordered-containers 0.2.1 - Set- and Map-like types that remember the order elements were inserted  https://hackage.haskell.org/package/ordered-containers-0.2.1 (DanielWagner)
06:23:46 <matheus23> Hi, I have a fairly large program and am running into a 'Prelude.init: empty list' error. Running it with profiling enabled, gives me a single call in the call stack: "GHC.List.CAF (<entire-module>)". I don't know how to figure out where the error comes from
06:24:44 <lyxia> matheus23: do you have -fprof-auto enabled and optimizations disabled
06:25:06 <matheus23> how do I set this? when I build?
06:27:23 <adamCS> Anyone have thoughts about working with types that may or may not be monadic, like Fold and FoldM from the folds library?  If there is just one, having two types is fine.  In my case (a map-reduce thing) I have three (an unpack step, an assign-to-group-step and a reduce step) and any or all may have a monadic return type.  Code here: https://github.com/adamConnerSax/Frames-utils/blob/master/map-reduce-folds/src/Control/MapReduc
06:27:23 <adamCS> e/Core.hs
06:27:25 <matheus23> Okay. I'm using 'stack install --profile --ghc-options=-fprof-auto', I get the same error, however :/
06:27:29 <adamCS> https://github.com/adamConnerSax/Frames-utils/blob/master/map-reduce-folds/src/Control/MapReduce/Core.hs
06:29:00 <adamCS> I've been able to handle some fo the obvious things polymorphically in that return type.  But it gets messy very quickly and I'm not sure if I should just abandon the effort to make all the possible combos work "under the hood" or if there is a better way.
06:29:47 <kish\> i am completely new to this.
06:29:51 <kish\> it seems complicated
06:30:59 <adamCS> My way involves a type-level Maybe parameter and a type-level "or" (sort of).  Which works...sort of.
06:31:15 <cocreature> matheus23: and you’re running with +RTS -xc?
06:31:28 <matheus23> cocreature: just tried that after googleing this second
06:31:39 <matheus23> this gives me way more information. I don't quite know what to do with it yet :D
06:33:53 <dmwit> adamCS: Identity is a monad ;-)
06:34:06 <matheus23> cocreature: Yeah, -xc gave me enough info! Thanks this fixed my issue :)
06:34:30 <dmwit> adamCS: And in case you need some of them to "line up", you can accept monad homomorphisms to connect them.
06:34:52 <dmwit> (...and Identity is initial in the category of Monads and Monad homomorphisms.)
06:35:10 <adamCS> dmwit:  Yeah.  I thought about that.  So I could drop the Maybe of it all.  But folds keeps the non-monadic version for better inference and error messages so I thought I would try to do the same
06:35:27 <dmwit> yeah... =P
06:35:28 <adamCS> promoting them all to Identity loses that.  Though maybe at this level of complication, that is worth it
06:37:52 <adamCS> dmwit: I also thought about having a separate m parameter--which would make the proofs about the "or" a possiility--and setting that to Identity in the "Nothing" case.  Then I could tale advantage of it being initial to get to whatever m lines them up.  But that's another parameter.  And makes the whole thing harder to use.  
06:38:07 <adamCS> *take
07:25:23 <Athas> Is there a tool that can find globally unused functions in a Haskell program?
07:25:44 <Athas> Oh, ndmitchell made something called weeder...
07:54:00 <sshine> Athas, I was just about to ask a question related to extending HLint, and it turns out ndmitchell also made HLint. :)
08:06:37 <sshine> when making a .hlint.yaml file, how does it know which parts of 'lhs' and 'rhs' are variables?
08:22:07 <delYsid> How do I avoid fizzling in a relatively simple recursive function that uses parList rdeepseq for depths > 2
08:24:31 <akersof> hi all, i have a little question about accessor functions on datatypes: https://gist.github.com/akersof/97371301cf55d64ca6ec3234846118b7
08:25:03 <c_wraith> akersof: what happened when you tried?
08:25:12 <akersof> in this snippet, i am curious to know how i can access "fields" from datatype "Character" 
08:25:25 <akersof> i mean with accessor functions
08:25:50 <akersof> c_wraith: i got i error, let me show you, but in reading a stackoverflow post: https://stackoverflow.com/questions/33273164/using-record-syntax-with-algebraic-data-types-with-multiple-constructors
08:26:12 <akersof> an answer says: Using accessor functions for datatypes with more than one constructor is widely discouraged, because these functions will be partial.
08:26:38 <delYsid> akersof: No.
08:26:41 <akersof> I would think you could probably do better using prisms and/or traversals from the lens package.. first time i read about lens package
08:26:47 <Ariakenom> delYsid: Oh sparks. I haven't read about those for a while. Do you have any usage story or know of some blog post?
08:26:55 <c_wraith> delYsid: that's not true.  You certainly can use accessors with multiple constructors.
08:27:01 <c_wraith> delYsid: it just is fragile.
08:27:35 <merijn> There's a GHC proposal that I wholly endorse on allowing the use of record syntax without accessors
08:27:58 <merijn> i.e. so you have to use NamedFieldPuns/RecordWildCards to use the field names, which would remove that brittleness
08:29:00 <Ariakenom> is it a good rule of thumb that if it's the first you hear about lens then you shouldn't use it? :p
08:29:06 <delYsid> Ariakenom: Hmm, I am using the parallel package.  I dont have any blog post to point at though.
08:29:31 <akersof> merijn: hum here what i tried, and doesnt works ofc
08:29:33 <akersof> https://gist.github.com/akersof/97371301cf55d64ca6ec3234846118b7
08:29:46 <akersof> merijn: you mean i have to use only what i have commented ?
08:29:49 <c_wraith> akersof: the fact is, you can do it.  If every constructor has a field with the same name, it doesn't even have cases where it can blow up.  But don't do it, because in general it has cases where it will blow up.
08:29:55 <delYsid> Ariakenom: Lens is the way to go if you want to overload record field accessors.  There is an extension for GHC as well, but I think it has some restrictions.  Read up on DuplicateFieldNames, IIRC.
08:30:12 <merijn> akersof: Define "doesn't work"?
08:30:49 <akersof> merijn:     Data constructor not in scope: Character :: Character    "name: " ++ name Character ++ "\n" ++
08:30:56 <Ariakenom> I know. Just reacted to "better using prisms and/or traversals from the lens package"  "first time i read about lens package"
08:31:09 <merijn> akersof: Well, yes, Character is not a constructor, I'm not sure what you expect it to do there?
08:31:25 <akersof> omg typo error
08:31:35 <akersof> merijn: sorry
08:32:40 <Ariakenom> I only know sparks in theory but haven't really looked into any practical usage
08:33:15 <delYsid> Ariakenom: I find the parallel package pretty useful for quick and dirty speedups.  However, I wonder if I can reduce the fizzling I get.
08:33:32 <delYsid> SPARKS: 7600094(1217577 converted, 0 overflowed, 0 dud, 786224 GC'd, 5596293 fizzled)
08:34:06 <akersof> ok so no error... and it works perfectly, so my showCharacter function in https://gist.github.com/akersof/97371301cf55d64ca6ec3234846118b7 can handle both constructors
08:34:11 <merijn> akersof: You'd apply "name", etc. to the "monster" you bound on line 44
08:34:20 <delYsid> The speedup is pretty linear, however, I am not sure if part of the speedup doesnt come from parallel GC.
08:34:34 <Ariakenom> delYsid: that ratio does look unfortunate
08:34:38 <merijn> delYsid: I'd be surprised, parallel GC usually slows things down :p
08:34:41 <Ariakenom> ok. interesting
08:35:03 <delYsid> merijn: Yes, but I produce *a lot* of garbage.
08:35:17 <merijn> delYsid: GHC's GC is not linear in size of garbage
08:35:36 <akersof> ok.. so if i want to write decent code, i should pattern match the constructor in my showCharacter function ?
08:35:37 <merijn> delYsid: Cost of GHC's GC scales with "amount of data that is *not* garbage"
08:35:46 <akersof> i mean it is more "solid"
08:35:52 <merijn> delYsid: Having LOTS of garbage is actually the best possible case for GHC's GC :)
08:37:10 <delYsid> 3,448,458,498,064 bytes allocated in the heap in a run on 20 cores with 84s elapsed time
08:37:14 <dminuoso> delYsid: The GHC GC is implemented as a two-space moving garbage collector, so it moves things found from root references which is everything not considered garbage.
08:37:44 <dminuoso> So the more non-garbage you have, the more needs to be moved. The amount of garbage is irrelevant.
08:38:25 <dminuoso> (You could call it a "non-garbage collector" if you wanted)
08:39:25 <merijn> dminuoso: "copy and compact" is the name for this GC style :)
08:39:42 <delYsid> 10,390,915,104 bytes copied during GC
08:39:57 <dminuoso> merijn: I blame Ryan.
08:40:38 <dminuoso> merijn: I thought it was called a tracing GC though.
08:41:27 <delYsid> I mean, the speedup is actually pretty linear, I am just wondering about the high fizzling count
08:41:49 <merijn> dminuoso: It's also a tracing compiler, yes
08:42:07 <merijn> dminuoso: tracing is an orthogonal axis
08:42:16 <Solonarv> (also, you can reduce the impact of long-lived non-garbage by shoving it into compact regions)
08:42:31 <dminuoso> merijn: Ah I see. Apparently compacting and moving are two synonyms in that domain.
08:42:37 <merijn> dminuoso: "copy and compact" is what you do, tracing (as opposed to reference counting) is about how you determine what is garbage)
08:43:30 <merijn> dminuoso: Well, they're not quite synonyms, but having compact heaps is generally considered good. So if you're gonna bother moving *anyway*, you might as well compact :p
08:43:59 <dminuoso> *shrugs*
08:52:07 <dmwit> akersof: I'd be tempted to write `data CharacterType = Monster | Hero Job; data Character = Character { name :: Name, race :: Race, hp :: Hp, mp :: Mp, ty :: CharacterType }`
08:53:03 <akersof> dmwit: indeed this is a good trick
08:54:34 <akersof> dmwit: sound good :) thx !
09:06:14 <akersof> dmwit: it is just hard to have good FP reflex after 15 years of OOP brainwashing
09:06:22 <akersof> reflexes*
09:07:20 <tdammers> hard, but ever so rewarding
09:07:36 <tdammers> and also nothing 10 years of FP brainwashing couldn't reverse
09:08:14 <tdammers> I just tried my hand at my former go-to language, C++, the other day, and I was just outright paralyzed, trying to find a reasonable structure for what I wanted to write
09:08:34 <merijn> tdammers: Lambda all the things!
09:08:51 <nisstyre> tdammers: you just gotta RAII harder man
09:08:51 <tdammers> merijn: been there, done that, ended up in pain cave
09:09:01 <nisstyre> needs more RAII
09:09:09 <tdammers> "RAII-ing intensifies"
09:09:10 <akersof> tdammers: but, not enough, C++ now is pushing FP style all the way
09:09:20 <dminuoso> akersof: well... hardly "all the way"
09:09:25 <dminuoso> Just incorporating some ideas.
09:10:00 <dminuoso> tdammers: The only thing C++ has going for itself is.. its better than C.. somewhat.. not much..
09:10:14 <dminuoso> (On the basis of having a bit more type system than C)
09:11:19 <gentauro> how do you reach out to https://haskellweekly.news/ if you don't have a Twitter account?
09:11:30 <nisstyre> dminuoso: some languages don't even have unions, C has unions!
09:11:34 <nisstyre> they're untagged mind you
09:11:44 <akersof> dminuoso: yes it is sad,
09:11:54 <gentauro> we have made a nice setup in Sweden (Charlmers Uni) https://www.meetup.com/got-lambda/events/259965014/ and we would like a bit of awareness ;)
09:12:11 <tdammers> you can tag them yourself
09:12:19 <nisstyre> yes, just like your grandparents had to do
09:18:08 <Solonarv> gentauro: email probably works?
09:19:37 * hackage symantic-http 0.0.0.20190324 - Symantic combinators for deriving clients or a server from an HTTP API  https://hackage.haskell.org/package/symantic-http-0.0.0.20190324 (julm)
09:20:37 * hackage symantic-http-demo 0.0.0.0, symantic-http-test 0.0.0.20190324, symantic-http-pipes 0.0.0.20190324, symantic-http-client 0.0.0.20190324, symantic-http-server 0.0.0.20190324 (julm)
09:23:44 <ph88^> hey guys, i wrote this algorithm in imperative style and it's really starting to get complicated and i was wondering if i would try a more functional style maybe it would help me. Description: https://bpaste.net/show/8563352af269 Code: https://bpaste.net/show/4b38fdd2428a
09:24:09 <ph88^> Sorry if it's not about haskell directly, but i thought it would be ok to ask because i want to know about functional programming
09:25:23 <ph88^> i already rewrote it a couple of times and put debug texts all over the place .. but even so it's really a pain in the ass to modify it or fix bugs in it
09:32:18 <gentauro> ph88^: Sorry, I stopped at `1 - <?php`. My eyes begin to bleed :-)
09:32:32 <ph88^> :*(
09:32:34 <ph88^> i know right :P
09:33:10 <ph88^> anyway i don't think reading the code helps that much anyway, i hoped the description would have been enough. I just put the code there to be complete
09:35:04 <avn> gentauro: write php parser in haskell should be not very complicated task
09:35:33 <tdammers> avn: say what
09:35:40 <tdammers> php is super terrible that way
09:36:16 <tdammers> it may be a little better now that people are trying to formalize things a bit, but still
09:36:25 <tdammers> so many quirks, so much contextual nonsense
09:36:27 <avn> tdammers: I do it once in python ;) depend of "fullness". JSON grade is possible ;)
09:37:50 <avn> I wrote something enough stable to read/write wordpress and mediawiki configs (and resource files).
09:43:40 <ski> ph88^ : shouldn't the two latter lines align the initial `Dash's with the ones on the former two lines ?
09:46:15 <ph88^> ski, that's how it works now, but it's not what i want
09:46:56 <ski> what do you want ?
09:47:26 <ski> are you mainly interested in finding commonalities between all the rules ?
09:47:36 <ph88^>  /RelationshipDetail?  " "  Dash  " "/  as second commonality
09:48:10 <tdammers> "JSON grade"?
09:48:13 <ph88^> one observation is that it's longer than  /Dash  " "/
09:48:19 <ph88^> ski, just find common items
09:48:43 <ski> hmm
09:49:35 <ph88^> but as long as possible, not just 1 by 1   /RelationshipDetail?  " "  Dash  " "/  is _one_ commonality 
09:49:45 * ski nods
09:49:57 <ski> but a commonality must be contiguous, yes ?
09:50:25 <ski> or would you count it as a single commonality, even if not ?
09:50:40 <ph88^> yes
09:51:13 <ph88^> if i input [1,2,3,4] [1,2,999,3,4]  then  [1,2] and [3,4]  are the common parts
09:51:19 <ski> hmm .. in general, we have non-determinism
09:51:36 <ph88^> and the differences would be   [void, 999]  (whatever symbol to denote that there is nothing there)
09:51:53 <ski> i'm reminded of string matching. but here you want to match multiple rules, not just two
09:52:03 <ski>  [[],[999]]
09:52:07 <ph88^> yes
09:53:04 <ski> a first step could be to try to find what's common inbetween all the rules
09:53:30 <ski> and perhaps to associate with each such a value or cost, in order to rank them
09:53:51 <ph88^> value based on ?
09:56:21 <ski> consider `[0,1,2,1,0]' and `[0,1,2]'. we could get dissimilarities `([[1,0]],[[]])', or `([[0,1,2],[0]],[[0],[2]])', or `([[0,1,2,1],[]],[[],[1,2]])'
09:56:46 <ski> clearly the first of these three would be considered best
09:57:53 <ski> (in the first case, the common parts are `[[0,1,2]]', in the second case, `[[1]]', in the last case, `[[0]]')
09:57:54 <ph88^> [0,1,2,1,0] and [0,1,2] should give:   common [[0,1,2]] diff [[[0,1], []]]
09:58:07 * hackage asap 0.0.3 - Atlassian Service Authentication Protocol  https://hackage.haskell.org/package/asap-0.0.3 (puffnfresh)
09:58:20 <ph88^> common search should take as much as possible
09:58:45 <ski> yes .. i was just attempting to avoid being greedy
09:58:55 <ph88^> oh
09:59:43 <ski> i'm not sure the algorithm really needs to know that there's two different kinds of items in a rule
09:59:56 <ski> it only needs to be able to compare items for equality, right ?
09:59:56 <ph88^> there is a small benefit from reading left to read, because natural language is also from left to read and optional parts appear more often after a common part
10:00:14 <ski> perhaps so
10:00:25 <ph88^> yes i check for equality .. it's all that is needed
10:00:36 <ph88^> don't know what you mean by different kinds by the way
10:00:50 <ski> literals and non-literals
10:01:54 <ph88^> at the moment i don't do anything with that distinguin
10:02:04 <ski> if we can find a list of parts that's common to all rules, the next step would be to consider parts that are only common to some rules
10:02:13 <ph88^> distinction *
10:02:38 <ski> here it seems to be trickier, because probably we don't get a total ordering
10:03:36 <ski> iow, perhaps there's some commonality between rules A and B, some between rules B and C, and some between rules C and A .. and perhaps we can't align according to all of these, at the same time (?)
10:04:04 <ph88^> it needs to be common between all the rules A, B and C
10:04:17 <ski> oh, you're only interested in finding those ?
10:04:20 <ph88^> yes
10:05:03 <ski> i thought what you said above meant that you were also interested in such second-order commonalities
10:05:43 <ph88^> i didnt mean to say that
10:05:51 <ski> roughly how long rules, and how many of them at the same time, do you think you'll consider ?
10:06:09 <ph88^> what is there is pretty much the longest: 4 rules of about 11 items
10:06:28 <ph88^> and the program doesn't need to run fast anyway
10:06:33 <ski> perhaps one could do some kind of dynamic programming algorithm, with a multi-dimensional array
10:06:48 <ski> > 11^4
10:06:50 <lambdabot>  14641
10:07:01 <ski> doesn't look too big, perhaps
10:07:36 <ph88^> sounds good
10:07:52 <ski> do you know about string matching ?
10:07:56 <ph88^> didn't know dynamic programming was a thing in haskell
10:08:15 <ph88^> i've read about it but not sure what it is .. maybe i've done it sometime without knowing
10:08:19 <ph88^> what about string matching ?
10:08:36 <ski> well, consider trying to find a word, or a phrase, in some text
10:08:52 <ski> however, the search is meant to be approximate
10:09:02 <ph88^> i just use functions for that .. don't do it will indexes myself 
10:10:27 <ski> to make it fit, we allow the text to have an extra character where the search phrase had none, or vice versa. or a different character. but each such edit has a cost of `1', and we want to find a match with the lower cost (obviously we're allowed to disregard the prefix before and the suffix after the part of the text matching the phrase, with no cost)
10:11:18 <ski> s/lower/lowest/
10:11:30 <ph88^> ski, something came up, i have to go. I will think about your suggestion about doing something cost-based
10:11:34 <ski> ok
10:11:39 <ph88^> i'll leave my computer on, back in about 2 hours
10:12:42 <dmwit> ph88^: You may like https://en.wikipedia.org/wiki/Longest_common_subsequence_problem
10:14:25 <ph88^> dmwit, funny that you mention that, i just did a mini-study one some lcs algos https://gist.github.com/flip111/775dedf39c46f84325ce58c2c6475ea8 
10:15:20 <[exa]> ph88^: what kind of "rules" are the rules in your algorithm input?
10:15:53 <dmwit> ph88^: Okay. So how does your problem differ from an LCS problem?
10:18:25 <[exa]> do I get it correctly that it's a multiway LCS?
10:30:52 <hhefesto> good morning from México :)
10:44:46 <codedmart_> I have a situation where I am calling an api which has a 15 requests per second limit. I was thinking of adding all my requests to a pool/list and every second pull 15 out and run them? Is there something for this already? Or any ideas/suggestions?
10:45:37 <Rembane> codedmart_: There's the async library which will let you run things concurrently without you having to think too much about it. 
10:45:45 <Rembane> codedmart_: https://hackage.haskell.org/package/async
10:46:11 <Rembane> codedmart_: So every second you can run the 15 first requests in the list, then wait a second and so on. 
10:51:30 <codedmart_> Rembane: So once the requests are ran the original caller gets the result? How do I add to the list? I was thinking I would have to use an MVar or something.
10:51:43 <dmwit> codedmart_: I think glirc has some flood protection mechanism that you might check out. I don't know exactly where in the codebase to point you; glguy might have some more targeted advice there.
10:52:43 <merijn> codedmart_: I'd gate every access to the AI behind a Semaphore, then have a thread that adds 15 to the semaphore every second
10:53:02 <cocreature> merijn: I love how you mistyped API as AI :)
10:53:16 <merijn> cocreature: I blame the cat on my lap :p
10:53:43 <merijn> cats > IRC
10:57:39 <Rembane> codedmart_: I'
10:58:28 <Rembane> codedmart_: I'd use a queue and append the results to it, and then the thread that's interested in the results can read the queue
11:07:07 * hackage clang-pure 0.2.0.4 - Pure C++ code analysis with libclang  https://hackage.haskell.org/package/clang-pure-0.2.0.4 (PatrickChilton)
11:17:37 * hackage base-orphans 0.8.1 - Backwards-compatible orphan instances for base  https://hackage.haskell.org/package/base-orphans-0.8.1 (ryanglscott)
11:30:03 <Nevoic> Does anyone have an example of some short code that is done in Haskell (or any functional language) that is hard to replicate in say Kotlin or Swift? Or are modern languages static OOP languages pretty much there in terms of conciseness because of their declarative functions?
11:36:12 <dmwit> Nevoic: Perhaps the standard "quicksort" example would be a nice one.
11:36:21 <dmwit> (It's not really quicksort, but it's halfway decent anyway.)
11:38:01 <Logio> http://rosettacode.org/wiki/Sorting_algorithms/Quicksort#Haskell seems to make a nice case for conciseness
11:40:27 <shapr> Nevoic: I'd argue that higher level patterns like Applicative make parsing super-easy, but I've not done parsing in kotlin or swift. https://gist.github.com/shapr/f4c9f2a1d6d269f404277ae3bd89afdd
11:43:50 <kadoban> That "quicksort" doesn't seem like a particularly good example to me. The only reason anyone uses quicksort is because it's in-place, and that isn't. Also, how would one add randomized pivot selection? Also also, it doesn't do anything for equal elements, so [1,1,1,1,1,1...] is already a terrible case for it.
11:44:41 <[exa]> kadoban: who would sort a list of 1's ?
11:44:59 <shapr> Nevoic: have you done the advent of code problems in kotlin and/or swift?
11:45:41 <kadoban> [exa]: Anyone who doesn't know or care what the list contains, because it came from elsewhere.
11:45:44 <shapr> There are lots of public solutions to advent of code in various languages, that might make it easier to answer your question.
11:45:45 <Nevoic> I have not, I'll take a look though. I was able to make a pretty short quicksort in Kotlin.
11:46:29 <Nevoic> I'm not sure it's less characters than the Haskell version, but that's because Kotlin is overly verbose when handling nulls and new list definitions (listOf instead of [] and firstOrNull instead of [0])
11:46:39 <Nevoic> val List<Int>.qs: List<Int> get() = firstOrNull()?.let { n -> filter { it < n }.qs + listOf(n) + filter { it > n }.qs } ?: listOf()
11:47:13 <Nevoic> That's a Kotlin quicksort. You could change `List<Int> to List<T> where T is <T: Comparable<T>>` if you wanted to expand it generically.
11:48:52 <Nevoic> I will say I like the idea of pattern matching more than the way I handled it in Kotlin though, so I actually prefer the Haskell code over that Kotlin code, although I think it is a bit longer.
11:49:09 <kadoban> Nevoic: A sort that only works on all distinct elements is a bit not great.
11:49:20 <shapr> In my opinion, the parts that make Haskell concise could be (and should be!) done in other languages with a bit more trouble.
11:50:16 <slack1256> So haskell remains special?
11:50:46 <Nevoic> I think back in 2008 or whenever, Haskell had a lot of advantages over traditionally imperative languages. Now in Kotlin (an imperative OOP language), functions are first class, you can map/filter/reduce/fold with ease, and generally write concise code.
11:51:00 <Nevoic> I think solid pattern matching is still missing from most non-functional languages.
11:51:24 <Athas> Haskell's unique selling point is laziness, and I don't see that cropping up a lot.
11:51:44 <shapr> I think Haskell's unique selling point is parsing.
11:51:47 <kadoban> Nevoic: First class functions and map/filter/fold/reduce existing are *super* old
11:51:51 <MarcelineVQ> specifically lazyness-by-default
11:51:51 <shapr> no wait, maybe it's software transactional memory
11:51:56 <kadoban> Definitely not special to haskell
11:52:01 <slack1256> shapr: clojure also has that
11:52:01 <shapr> wait, maybe it's equational reasoning
11:52:20 <kadoban> Haskell's type system, equational reasoning and pattern matching are what sells it for me.
11:52:23 <Nevoic> kadoban I know they're old, but not for imperative languages. They were introduced into Java 4 years ago, and are still overly verbose.
11:52:25 <shapr> slack1256: good point, is stm popular in clojure?
11:52:36 <Nevoic> C# was on a similar time span, and Kotlin and Swift are like not even a decade old IIRC.
11:52:58 <slack1256> shapr: there always seems to be a fanboy of clojure stm on HN, so I guess so (bad metric I know)
11:53:02 <Athas> The MLs have pretty much all that Haskell does, except for enforced purity, the fanciest type extensions, and laziness-by-default.
11:53:07 <Athas> Also, Haskell has a much nicer syntax.
11:53:24 <shapr> wait! I've got it!
11:53:34 <shapr> Haskell's unique seling point in Simon Peyton-Jones
11:53:35 <kadoban> python is like 30 years old if you want imperative with first class functions and the basics of well known higher-order function stuff.
11:53:40 <Nevoic> I do like Haskell's syntax, but I really don't like their runtime pattern matching. I've found cool warnings that can be enabled by the compiler, but the fact that you can run a program with incomplete pattern matching is no fun.
11:53:59 <c_wraith> shapr, all of great Britain gets spj now.
11:54:08 <Nevoic> Meh even today I wouldn't say Python has that great higher order function stuff. You can't even make multiline blocks.
11:54:13 <shapr> c_wraith: yeah, I'm happy about that
11:54:19 <cocreature> Athas: is there an ML with a similar RTS, i.e., one with a decently fast IO manager and lightweight threading?
11:54:36 <Nevoic> Which means you have to resort to like comprehensions for everything. It's still declarative, but not nearly as customizable.
11:54:37 <slack1256> green threads on the RTS are a big point missing on other languages
11:54:47 <Athas> cocreature: doubt it.  If so, it would have to be OCaml or F#.  There is no doubt that more engineering has gone into GHC than the MLs nowadays.
11:54:58 <shapr> yeah, Haskell's concurrency is really nice
11:55:00 <Nevoic> What's an RTS?
11:55:03 <shapr> runtime system
11:55:18 <cocreature> the RTS is one of the reason’s why I don’t see myself switching to idris in the foreseable future
11:55:26 <Nevoic> Does that term also encompass compile-time optimizations for the runtime?
11:55:38 <cocreature> no
11:55:41 <shapr> I do like that I can start an unreasonably large number of "threads" and they get matched with OS threads for the cores I have available.
11:55:57 <cocreature> the RTS is things like IO, GC, threading, …
11:56:10 <Nevoic> How do you guys feel about unsafe pattern matching being allowed?
11:56:22 <shapr> unsafe?
11:56:23 <Athas> Nevoic: unsafe in what sense?  Partial?
11:56:28 <Nevoic> Yeah, partial.
11:56:38 <Athas> It should be an error or an unconditional warning.
11:56:48 <Nevoic> That's my view too, I'd prefer it to be an error.
11:57:00 <shapr> isn't that a ghc option?
11:57:01 <Nevoic> That's something that bugs me about Haskell, I really don't like runtime errors.
11:57:07 <Nevoic> It is, I have it enabled, but I believe it's just a warning.
11:57:23 <Nevoic> And plus that requires code level enforcement. Was still super happy to see it as an option, but would prefer it as a default.
11:57:33 <shapr> I thought you could turn any warning into an error?
11:57:34 <cocreature> -Wall -Werror and now it’s an error :)
11:57:34 <Nevoic> Also that kind of leads me into a related question, is there any way to enable a ghc-option for an entire project?
11:57:35 <yushyin> -Werror
11:57:35 <slack1256> Being completely fair, sometimes I don't handle a pattern match case because I know I handle it higher on the call stack and it is impossible
11:57:52 <cocreature> you can specify ghc-options in your cabal file
11:57:53 <shapr> Nevoic: ghc-options in your cabal file?
11:58:08 <Nevoic> I I have it in my cabal file, but only under `library` or `executable`.
11:58:13 <shapr> why not both?
11:58:13 <Nevoic> Can I like put it top level and have it apply everywhere?
11:58:15 <cocreature> slack1256: if you handle it higher in your call stack don’t pass the same type donwards
11:58:31 <Athas> slack1256: I would argue that your code would be better if you were forced to add a catchall case with an 'error' call explaining why it's impossible.
11:58:34 <Nevoic> Well yeah I have it under both, but I don't like the idea of making a new module and having to remember to add the ghc-options in the cabal.
11:58:50 <Nevoic> It'd be cool to just have global ghc-options defined one time instead of like 17.
11:58:52 <slack1256> cocreature: define a new ADT for each refinement is overly verbose and obscure the meaning of the different ADT that some simple comments
11:58:53 <Nevoic> more DRY.
11:59:25 <slack1256> Athas: if you add "error" as a catch-all, you don't have anymore safety as if it were an unhandled case
11:59:27 <shapr> is it possible to change the defaults for cabal init?
11:59:37 <cocreature> slack1256: I’ll happily take verbosity over having to figure out which cases are possible at a given point in a program
11:59:57 <Athas> slack1256: no, but it's more clear why the case is not handled sensibly.
12:00:00 <Nevoic> slack1256 I'm not a fan of having to reason about a program as a person to know what is possible and what isn't, when the compiler can easily enforce safety.
12:00:09 <Nevoic> slack just got hit with 3 @s lol
12:00:09 <MarcelineVQ> https://cabal.readthedocs.io/en/latest/developing-packages.html#common-stanzas
12:00:13 <Athas> It forces the writer to at least think, and ensures the reader that it's not an oversight.
12:00:18 <slack1256> Hahahah
12:00:31 <slack1256> The main way I found to solve this problem is with "tree that grow" 
12:00:53 <slack1256> https://gitlab.haskell.org/ghc/ghc/wikis/implementing-trees-that-grow
12:01:16 <slack1256> Basically you decorate your "main ADT" with type families that are set to Void when they are impossible
12:01:36 <slack1256> certainly is easier than defining 3+ ADT refinement which are basically the same minus some constructors
12:01:46 <Athas> I'm using something similar to Trees that Grow in my compiler, and it really is a nice solution.
12:02:11 <slack1256> yeah, but people has to accept "there is a problem with defining almost equal ADTs that obscure the meaning"
12:03:10 <shapr> Nevoic: did you see MarcelineVQ's link about cabal common stanzas?
12:03:16 <cocreature> I accept that. What I don’t accept is that defining similar ADTs necessarily obscures the meaning
12:03:28 <slack1256> Alternative, you can use Vynil and remove "cases" changing the HList
12:03:40 <Nevoic> Oh no I didn't, I didn't know that was directed at me. Thanks shapr & MarcelineVQ.
12:03:45 <Nevoic> That's awesome!
12:03:47 <cocreature> it can certainly happen but ime Haskellers are often way too focused on avoiding verbosity and duplication as a goal in itself rather than a means to an end
12:04:21 <Nevoic> How do I know my cabal version?
12:04:30 <Nevoic> In my haskell.cabal file it was version 0.1.0.0
12:04:45 <Nevoic> I'm guessing that's my project version though.
12:04:47 <Nevoic> Not my cabal version
12:05:15 <slack1256> There is certainly an economic argument to be done, how important is that part of the code to justify 3+ ADT versions that are basically the same? If it done on a one-off deal then maybe comments suffice
12:05:49 <cocreature> sure as always most decisions are a tradeoff between different things :)
12:05:55 <slack1256> Yep :-D
12:05:58 <MarcelineVQ> does anyone know if trees that grow is akin to the universe pattern?
12:05:58 <ddellacosta> Nevoic: can you do `cabal --version` ? Should tell you
12:06:13 <Nevoic> 1.24.2.0
12:06:22 <cocreature> that’s fairly old
12:06:25 <ddellacosta> yah
12:06:25 <Nevoic> I need to be using stack lts 8.24 because I need ghc-mod.
12:06:39 <Nevoic> And all the other things resolved on their own.
12:06:44 <shapr> break free and try cabal new-awesome!
12:06:48 <slack1256> Is ghc-mod still around? I though kazu was working on HIW now
12:06:50 <slack1256> HIE*
12:06:52 <Nevoic> It was the only way I could get decent Haskell tooling, but I have like autocomplete and inline errors etc.
12:07:05 <Nevoic> At least the only way that worked for me. I tried for hours to get it setup.
12:07:26 <shapr> emacs' haskell-mode does that for me with a stock setup
12:07:42 <Nevoic> Is it real autocomplete or the kind of autocomplete people pretend is real from like Ruby/Python etc?
12:07:48 <Nevoic> i.e is it supported by compile-time knowledge or text-based?
12:08:10 <shapr> oh wait, you mean intellisense style completion?
12:08:15 <Nevoic> Yeah.
12:08:31 <shapr> no, I don't get that from emacs, only text based name completion
12:08:37 <Nevoic> Yeah, I don't care for that.
12:08:38 <shapr> but inline errors, yes
12:08:41 <shapr> ok, fair enough
12:09:55 <Nevoic> I get inline errors, inline warnings, on hover types, and intelligent autocomplete. It's still not as in depth as I'd like from say Intellij + Kotlin or Swift + XCode, but it's solid.
12:10:47 <Nevoic> Because this only knows about everything I have in scope, either imported or not. Those tools explore the entire possible scope and allow me to auto import names (with a keybinding) without even knowing what package it's from.
12:11:45 <shapr> Nevoic: I do like that I can import a module and cabal+emacs say "that's in package foo, want to add that to your cabal file?"
12:12:01 <shapr> I think the heavy lifting there is cabal, from what I've heard
12:12:28 <Nevoic> That's a cool feature. I don't have that hooked up in my environment.
12:12:44 <MarcelineVQ> Nevoic: what editor do you use?
12:13:04 <gbd_628> Hi, quick question about type-level programming with singletons: is there any way to promote GADTs? E.g., can I promote `Fin :: Nat -> Type`, the types of finite sets? I keep getting type errors.
12:14:01 <cocreature> gbd_628: you need to enable TypeInType to promote GADTs iirc
12:16:23 <gbd_628> cocreature: I do have TypeInType enabled. But I'm getting "Expected kind ‘ℕ’, but ‘n_aK7p’ has kind ‘Type’" when I wrap "Fin"'s definition in the singletons template thing
12:16:59 <cocreature> ah not sure if singletons supports it
12:19:09 <Nevoic> MarcelineVQ Atom.
12:19:21 <gbd_628> okay, thanks. do you happen to know why it isn't done, or where I could read about it? Is it actually impossible for type-theoretic reasons, or is it just really hard to implement?
12:21:29 <cocreature> gbd_628: I would try to get it to work without the singletons package first. that might give you some idea whether it’s possible or not
12:22:23 <ddellacosta> MarcelineVQ: btw what is the universe pattern?
12:31:56 <merijn> shapr: Did tree-diff help?
12:32:07 <shapr> ah, I gave up and did real work
12:32:10 <shapr> but I should try it
12:32:15 <MarcelineVQ> ddellacosta: actually that question was part of my problem as well. it appears to be generics based on the idea of capturing the essence of many disparate data structures into a few or one datatype(s), called a universe, and performing your operation on those. exemplified in haskell via GHC.Generics
12:32:21 <shapr> not sure how to hook it into hedgehog's tests though
12:32:51 <merijn> shapr: hedgehog takes care of the output in an inextensible way?
12:33:17 <shapr> it does the diff itself at the moment, but I don't see anything different
12:34:44 <ddellacosta> MarcelineVQ: oh thanks! Is it related to comonads in any sense...? Reminds me of a Dan Piponi blog post which I'm forgetting now...
12:36:18 <MarcelineVQ> Not in a way that comes to mind, but I just learned what I wrote above so there's salt grains involved
12:36:58 <ddellacosta> MarcelineVQ: this may only be coming to mind because he uses the same word "universes," but here it is... http://blog.sigfpe.com/2006/12/evaluating-cellular-automata-is.html
12:37:41 <ddellacosta> anyways, thanks, that's neat
12:37:41 <MacSlow> Greetings everybody!
12:38:22 * ddellacosta waves
12:53:55 <ph88^> ski, i'm back
12:54:14 <ph88^> [exa], grammar
12:55:29 <ph88^> dmwit, currently i wasn't looking for the longest sequence, but just taking the common sequence as i encountered them. But starting with the longest is a good idea for the next version
13:02:05 <[exa]> ph88^: oh so, I didn't see the nonterminals before the arrow, so got confused
13:02:12 <[exa]> anyway
13:02:52 <[exa]> dynamic programming will work, but if you just expand Levenshtein to generalized `n` words you'll end up with an algorithm that's exponential in `n`
13:04:49 <[exa]> so instead I'd go with getting "sequences of length 1 that appear in all rules" and then expanding it to "sequences of length n+1 that appear in all rules that have previous sequences of length `n` as prefixes", which is efficient and very fast, given some quick multi-prefix matching algorithm (aho-corasick?)
13:07:12 <[exa]> even without Aho-Corasick this will probably be somewhere between O(n^2) and O(n^3)
13:11:32 <abbe> hi!
13:12:10 <NinjaTrappeur> Hey, not sure if it's the right place to report that but hoogle seems broken ATM https://hoogle.haskell.org/
13:15:11 <__monty__> NinjaTrappeur: What about it's broken? Seems to work for me.
13:15:46 <koz_> [exa]: What's the goal here?
13:16:04 <MarcelineVQ> __monty__: bad gateway 502 error
13:17:12 <__monty__> Hmm, not for me. You both in the same general geographic area?
13:17:50 <MarcelineVQ> probably not, doesn't matter too much at least :>
13:17:53 <NinjaTrappeur> Western europe here
13:18:11 <__monty__> Huh, weu here too.
13:20:16 <abbe> I'm using 'httpJSON' (Network.HTTP.Simple), and in processing the result "(FromJSON a) => Response a". In my function, I'm trying to return value of ErrorResponse type if HTTP status code is not 200, else a LoginResponse type's value, but seems like type system doesn't like what I'm trying to do.
13:20:24 <abbe> I'm wondering if anyone has any suggestions on how to resolve this: https://pastebin.com/gVDpK1WV
13:25:44 <ph88^> [exa], ye that's a good idea. My code doesn't need to be fast though
13:30:05 <MarcelineVQ> abbe: what's the definition of lrUser?
13:30:39 <abbe> data LoginResponse = LoginResponse { lrUser :: Text, ... }
13:31:00 <abbe> data ErrorResponse = ErrorResponse { errMsg :: Text, ... }
13:31:27 <abbe> I've also implemented instances of "FromJSON a"
13:31:59 <ddellacosta> abbe: it looks like you're using yesod (or your own ad-hoc)Response types with those used by Network.HTTP.Simple, is that right?
13:32:08 <abbe> right
13:32:38 <abbe> my own ad-hoc types, and not yesod
13:34:27 <ddellacosta> abbe: ah okay. so I'm assuming that type sig was different when you got that error, and what you pasted is what you have now for debugging, but if you are returning an IO a of some type where a needs to be a Response, I guess you need a type class that will let you do that.
13:35:28 <MarcelineVQ> in "getResponseBody resp >>= \x -> print (lrUser x)" x is of the type "FromJSON a => a" Its type is not LoginResponse, you'll need to convert the "FromJSON a => a" to LoginResponse yourself before using lrUser on it
13:36:55 <ddellacosta> or, I'm confused, based on MarcelineVQ's response...lol
13:36:55 <abbe> ddellacosta: if I don't do if/then/else, and just do "errOrSomething resp = (getResponseBody resp) >>= (print . lrUser)" then it works, but not with the conditional
13:37:37 <ddellacosta> oh okay, so I was making wrong assumptions I guess
13:39:13 <slack1256> Has anyone used a `vty`-using app over a ssh connection?
13:39:14 <abbe> https://pastebin.com/1Y31zMbe << FromJSON implementations
13:39:28 <abbe> MarcelineVQ: ^
13:39:52 <slack1256> I am getting worse than expected interactivity that say for example vim.
13:44:37 <MarcelineVQ> no "errOrSomething resp = (getResponseBody resp) >>= (print . lrUser)" shouldn't work either with the signature "errOrSomething :: (FromJSON a) => Response a -> IO ()"
13:46:08 <MarcelineVQ> "errOrSomething :: (FromJSON a) => Response a -> IO ()" says that this function works for any choice of 'a', which is why it's an error to treat the 'a' as a specific type like LoginResponse or ErrorResponse, because that means this function only works when 'a' is one of those, not _any_ 'a'.
13:46:53 <MarcelineVQ> "errOrSomething resp = (getResponseBody resp) >>= (print . lrUser)" by itself is of type "errOrSomething :: Response (IO LoginResponse) -> IO ()"
13:48:40 <gentauro> does anybody know if this is Haskell (it seems like it, at least like a DSL + REPL) -> https://youtu.be/c2I_v44ndUc?t=60
13:48:52 <gentauro> all those `$` and `const` here and there
13:49:01 <gentauro> if it is Haskell, do anybody know the name of the library?
13:49:04 <slack1256> That seems tidal
13:49:15 <slack1256> https://hackage.haskell.org/package/tidal
13:49:32 <slack1256> It a music generation DSL IIRC
13:49:35 <slack1256> *it's
13:49:57 <gentauro> slack1256: yeah, I think we have a winner
13:50:14 <gentauro> also her files are named `.tidal` (I thought it was a music service)
13:51:18 <slack1256> Jay-Z has/had a music service called Tidal too. It has no relation to the DSL (and I think the DSL is older).
13:52:12 <abbe> MarcelineVQ: sorry, it seems like i messed up in copy-pasting for IRC, this is better: https://pastebin.com/KGn6dhWH (thanks for looking, btw)
13:53:23 <gentauro> slack1256: thx for explaining. I would really like to see a live concert with that :)
13:53:41 <gentauro> I will have to ask around CPH to see/hear if anybody actually does anything with that tool :)
13:53:56 <slack1256> Mee too, me too...
13:53:57 <abbe> I think I understand what the problem is, but I don't know how to properly resolve it.
13:56:21 <heebo> what approach should i use if, instead of ```forever $ ``` i wanted something to run on a time interval
13:56:41 <Solonarv> heebo: I actually wrote a library for that, though it's very bare-bones
13:56:44 <Solonarv> @hackage fixed-timestep
13:56:44 <lambdabot> http://hackage.haskell.org/package/fixed-timestep
13:57:32 <heebo> thanks Solonarv
13:57:45 <slack1256> Solonarv: Don't sell it as "bare-bones", say it's "easy to understand" :-)
13:57:46 <Solonarv> let me know if there's anything you would like to see improved!
13:58:01 <Solonarv> slack1256: hah, I should remember that
13:58:06 <gentauro> Solonarv: you mispelled `second` -> http://hackage.haskell.org/package/fixed-timestep-0.1.0.0/docs/Time-Flick.html#v:secnd
13:58:58 <Solonarv> gentauro: that's intentional, I don't want to conflict with the function from Control.Arrow or Data.Bifunctor
13:59:35 <Solonarv> might rename it to something more sensible, I just couldn't think of anything that was nice and short
14:01:26 <MarcelineVQ> abbe: your first branch (return $ getResponseBody resp) >>= (print . lrUser) treats resp as a LoginResponse, so your second branch is also expecting resp to be a LoginResponse since it's the same resp, which is an error to give to errMsg which expects an ErrorResponse
14:01:46 <abbe> right
14:02:53 <heebo> Solonarv: threadDelay doesnt guarantee prompt scheduling. I'm trying to poll prices so time is of the essence
14:03:40 <Solonarv> oh yeah if you need to be that precise then my library might not be right
14:03:51 <MarcelineVQ> I don't do web programming so I'm not sure what the right route is here but I'd be inclined to use the old signature "errOrSomething :: (FromJSON a) => Response a -> IO ()" and see if I can use what FromJSON provides me to determine whether I the 'a' I have should result in a LoginResponse or ErrorResponse
14:06:07 <abbe> Okay, I'll keep looking. thanks for your time.
14:06:08 <MarcelineVQ> could start by writing a helper like "isLoginOrError :: FromJSON a => a -> Either ErrorResponse LoginResponse" maybe, not sure really, never used FromJSON myself so idk what all it can provide you to make that decision
14:06:11 <Ariakenom> heebo: prompt scheduling is never guaranteed
14:07:31 <Ariakenom> unless running on real time OS
14:08:15 <gentauro> Solonarv: I prefer people to use `import qualified Data.Foo as F` and then `F.second` instead of seeing something that hurts my `OCD` :(
14:09:00 <abbe> MarcelineVQ: I think have to use some function that checks for error status, and then throws the result as exception, if there is error situation
14:09:21 <gentauro> Ariakenom: can you do that with `FFI`? (real time OS)?
14:10:09 <Ariakenom> gentauro: depends on how you structure it I would think. I don't think you could use GHC's scheduler at all
14:10:25 <Ariakenom> that said it's probably good enough heebo 
14:10:54 <slack1256> gentauro: you can always do `second = F.secnd` at top level and be happy with the OCD. XMonad used to do `io = liftIO` on their code base and all went well.
14:11:50 <gentauro> Ariakenom: good point
14:12:29 <gentauro> slack1256: I would rather write a library myself than allowing that on my code base xD
14:12:35 <gentauro> (I'm not even kiding) :P
14:20:49 <[exa]> koz_: sorry I was afk -- basically finding the longest _continuous_ subsequence common to all `n` strings.
14:22:47 <Solonarv> actually 'oneSecond' might be a good name
14:26:24 <Solonarv> gentauro: thoughts?
14:28:30 <delYsid> Another naming question.  Is there a version of fold{l,r} with the starting value and input list arguments swapped, such that they could be easily composed?  I have a function foldBits :: Bits bits => (a -> Int -> a) -> a -> bits -> a; which I actually would like to compose, so I am looking for a better name for the version with swapped final arguments.
14:28:45 <gentauro> Solonarv: I'm sold :)
14:31:16 <delYsid> fooBits :: (a -> Int -> a) -> bits -> a -> a
14:34:36 <delYsid> Actually, fooBits :: (Bits b, Num b) => (a -> Int -> a) -> b -> a -> a
14:35:52 <Solonarv> gentauro: any further suggested improvements while I'm changing the API anyway?
14:39:50 <gentauro> I was looking around and I you use a lot of `prime` naming convention. Why didn't you name it `second'`?
14:39:57 <gentauro> that would give sense and consistency
14:40:50 <gentauro> (this is from `TimeStep`). But I really like your new name `oneSecond` as it actually states what happens. Just like `map`
14:40:57 <Solonarv> :D
14:41:24 <Solonarv> I don't think second' would be a very good name - that suggests that it's something sort of like a second but not exactly
14:42:32 <gentauro> btw, with regard of `TimeStep`. Would it give sense to call it `Time.Step`, so it's under the main `Time` and besides `Flick`? Just a thought
14:43:00 <gentauro> otherwise I might would call Flick as `TimeFlick`
14:43:26 <Solonarv> hm, perhaps
14:43:39 <Solonarv> could even change the module name to e.g. 'Time.Repeatedly'
14:44:43 <heebo>  Ariakenom, Solonarv: I have been looking at tiny-scheduler although it makes no claims for promptness
14:45:09 <heebo> just needed to patch it though because its Monoid instance was dated
14:46:13 <gentauro> Solonarv: could be :)
14:54:27 * Younder is trying to understand how you get from laplace transforms in control theory to Z-transforms in my FPGA which is digital
15:02:44 <heebo>  i think i prefer fixed-timestep whats a missed flick here and there...
15:13:21 <sicklorkin> listToMaybe ("" :: Text) `shouldMagicallyBe` Nothing 
15:17:59 <haskellnoob> Hi. I noticed when I try to purposefully overflow the stack in ghci with a call to something like "foldl (+) 0 [0..]" it will error and tell me there was a stack overflow, but then my system becomes incredibly unstable and locks up. Is this normal behavior??
15:18:07 * hackage fixed-timestep 0.2.0.0 - Pure Haskell library to repeat an action at a specific frequency.  https://hackage.haskell.org/package/fixed-timestep-0.2.0.0 (Solonarv)
15:18:26 <Solonarv> heebo: :D
15:18:35 <glguy> haskellnoob: You're on Linux?
15:18:58 <haskellnoob> Yes, debian. 
15:19:19 <heebo> i noticed the change from 8 minutes ago
15:19:29 <Solonarv> the package also tries to catch up if it sleeps for too long, so as long as threadDelay doesn't have too much extra delay it Should Work™
15:19:38 <glguy> Linux is (apparently) designed to fail once you hit swap, and I don't think GHCi is great about freeing up memory in that situation
15:19:39 <haskellnoob> happens with ghci 8.6.4 and 8.6.3
15:19:48 <Solonarv> a new version fresh off the presses, no new functionality though
15:20:13 <Solonarv> just better names for things
15:20:26 <haskellnoob> Yes, there's usually alot of hard drive activity at that point
15:21:36 <heebo> Solonarv: thank you , im intending to use it with pipes 
15:22:35 <glguy> haskellnoob: Try running GHCi with a memory limit like: ghci +RTS -M100m
15:22:44 <heebo> Solonarv: just to be clear ```repeatedly 1 ``` means repeat every 1 flick or millisecond?
15:22:54 <Solonarv> heebo: it means "once per second"
15:22:55 <glguy> ghc:   -M<size>  Sets the maximum heap size (default unlimited)  Egs: -M256k -M1G
15:23:09 <heebo> ah 1 second
15:23:10 <Solonarv> the parameter is a frequency (in Hertz)
15:24:56 <Solonarv> heebo: so, 'repeatedly 20' would run 20 times per second
15:28:13 <heebo> ah 
15:28:42 <heebo> oh i like that
15:29:06 <haskellnoob> glguy: what's +RTS?
15:30:07 * hackage fixed-timestep 0.2.0.1 - Pure Haskell library to repeat an action at a specific frequency.  https://hackage.haskell.org/package/fixed-timestep-0.2.0.1 (Solonarv)
15:30:31 <Solonarv> heebo: new version, slightly clearer docs :D
15:34:58 <hpc> only slightly
15:35:03 <hpc> wouldn't want it to be too clear :D
15:39:16 <AfC> Swap on Linux isn't a problem at all, but if something huge is eating memory  the system has to start paging to create room, that takes time and effort. When OOM killer finally comes into action there are all kinds of unhappy paths that result. It's not that your system has become "unstable" so much as it's suddenly doing tons of work you don't normally experience and (probably) getting it wrong (relative to user expectation).
15:39:57 <slack1256> remember to press SysRq-f to launch the OOM killer at will and don't let it reach the end of the swap! 
15:40:03 <MarcelineVQ> it's a proble when your swap is full
15:41:52 <hpc> slack1256: i had no idea that was a thing
15:41:59 <hpc> https://en.wikipedia.org/wiki/Magic_SysRq_key
15:42:40 <MarcelineVQ> hpc: magic keys aren't always enabled, it'll depend on your distro setup
15:42:58 <slack1256> I only knew the "REISUB" combo as a way to safely reboot when your system is wreck, but it has extra niceties as well as the OOM killer launcher
15:47:32 <glguy> haskellnoob: +RTS tells the runtime system that the next flags are for it. -RTS ends that
15:48:02 <glguy> haskellnoob: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#setting-rts-options
15:48:37 * hackage ghc-syntax-highlighter 0.0.3.1 - Syntax highlighter for Haskell using lexer of GHC itself  https://hackage.haskell.org/package/ghc-syntax-highlighter-0.0.3.1 (mrkkrp)
15:52:49 <haskellnoob> glguy: thanks for the info 
16:08:10 <glguy> AfC: It's a probably because it doesn't prioritize what it swaps out well and you get situations where you can't kill the process that's using all the memory
16:08:14 <glguy> a problem*
16:08:37 * hackage QuickCheck 2.13 - Automatic testing of Haskell programs  https://hackage.haskell.org/package/QuickCheck-2.13 (NickSmallbone)
16:09:37 * hackage arbor-datadog 0.1.0.0 - Datadog client for Haskell.  https://hackage.haskell.org/package/arbor-datadog-0.1.0.0 (arbornetworks)
16:10:37 * hackage quickcheck-with-counterexamples 1.2 - Get counterexamples from QuickCheck as Haskell values  https://hackage.haskell.org/package/quickcheck-with-counterexamples-1.2 (NickSmallbone)
16:16:14 <Nevoic> How does $ know when to end?
16:16:30 <Clint> end what
16:16:54 <hpc> same way + knows when to end :P
16:17:03 <hpc> it's just an operator
16:17:12 <Nevoic> For example:
16:17:12 <Nevoic> f = []
16:17:12 <Nevoic> f (x:xs) = f $ filter (< x) xs ++ [x]
16:17:12 <Nevoic> I believe that's equivalent to
16:17:12 <Nevoic> f (x:xs) = f (filter (<x) xs) ++ [x]
16:17:13 <Nevoic> why is it not
16:17:13 <Nevoic> f (x:xs) = f (filter (<x) xs ++ [x])
16:17:30 <glguy> It's the latter, not the former
16:17:46 <Nevoic> Ah. My question still remains, I'm obviously not clear on the functionality xd
16:17:57 <hpc> operator precedence determines it
16:18:16 <hpc> in ghci, do :i ($) and :i (++)
16:18:34 <hpc> ($) has precedence 0, (++) has precedence 5
16:19:04 <Nevoic> I don't see how `:i` told me about precendence. It just displayed a bunch of type information.
16:19:19 <hpc> last line
16:19:19 <glguy> Nevoic: The parser sees an alternating: subexpr operator subexpr operator subexpr
16:19:25 <hpc> infixr $ 0
16:19:30 <hpc> infixr ++ 5
16:19:45 <hpc> the "r" means right associativity as well
16:19:50 <Nevoic> Oh okay, I see it. So why is precedence important?
16:20:04 <glguy> to decide which operators are combined with their neighboring subexpressions we start with the highest precedence first
16:20:10 <glguy> and then work down to lowest
16:20:29 <hpc> it determines how the expression is grouped
16:20:35 <hpc> > 2 * 5 + 3
16:20:37 <lambdabot>  13
16:20:41 <hpc> > 2 * (5 + 3)
16:20:42 <lambdabot>  16
16:20:43 <Solonarv> precedence says "how tightly does this operator bind?"
16:20:58 <Nevoic> Does the newline have any sort of operator precedence?
16:21:12 <glguy> Your example had: 04f 03$ 04 filter (< x) xs 03++ 04[x]
16:21:13 <Nevoic> i.e can I use a newline to make $ interpret the expression differently?
16:21:37 <hpc> no, it would be the same kind of whitespace as function application
16:21:37 <glguy> Yes, but in a nother case with layout rules that doesn't apply here
16:22:37 <Solonarv> glguy: whoa, colors!
16:22:39 <Nevoic> Erhm, no and yes?
16:23:03 <hpc> yes and no
16:23:04 <glguy> Nevoic: Yeah, that's what the text after the yes/no is for
16:23:14 <Solonarv> you got one "no" and one "sometimes, but not here"
16:23:56 <hpc> i don't know how a newline would make a single expression parse differently, except to turn it into an expression plus the beginning of some other syntactic element
16:24:00 <jle`> Nevoic: remember that $ here isn't any special built-in syntax, it's just a normal operator as relevant here
16:24:11 <jle`> so any question about $ would also apply to +, for example
16:24:17 <glguy> hpc: do notation is one case
16:24:21 <jle`> "can i use a newline to make + interpret the expression differently?"
16:24:51 <glguy> hpc: you can indent at different levels to pull something outside of the do-notation block
16:24:53 <jle`> Nevoic: these are also defined "within Haskell", as in it's exported from the standard libraries
16:24:54 <Nevoic> And the answer to that question, I assume, is also yes and no?
16:25:35 <hpc> glguy: ah, i figured this was just about expressions and operator precedence, so that wouldn't have been a useful nuance here ;)
16:25:42 <jle`> Nevoic: well, + and other operators don't really interpret expressions
16:26:04 <jle`> Nevoic: expressions are parsed before operators are consulted
16:26:10 <hpc> oh i guess if you're using do-blocks inside the expression
16:26:15 <hpc> bleh
16:26:27 <jle`> operators do not affect parsing of expressions, because expressions are parsed before operators are considered 
16:26:59 <jle`> once we tokenize and lex everything, the operator fixities are then consulted to make the right expression tree
16:27:08 <jle`> this happens after everything is already sequentially aggregated
16:27:28 <jle`> i suppose i am being a bit fast and loose when i'm talking about "expressions"
16:27:49 <glguy> Nevoic: You're probably used to this from other languages where:  x + y * z   means   x + (y * z)   because * has higher "precedence"
16:28:00 <jle`> but essentially haskell lexes things that could potentially be expressions into something like [2, *, 5, +, 3]
16:28:10 <slack1256> test
16:28:11 <gentauro> I'm giving `diagrams` a try, but it seems that it doesn't really work (http://dpaste.com/2E1ZH37 mimicing this example https://archives.haskell.org/projects.haskell.org/diagrams/gallery/Sunburst.html)
16:28:15 <gentauro> :(
16:28:15 <jle`> or [f, $, filter, (< 3), xs, ++, [x]]
16:28:29 <Nevoic> Sure, I'm just having trouble going through all this detail. I'm trying to absorb it all to understand the answer to my question, because I assume it's necessary to understand it.
16:28:30 <jle`> after it does that, it consults the fixities of $ and ++ to determine how to "parenthesize" things
16:28:53 <jle`> so, $ and ++ themselves do not play an active role, w.r.t. how newlines are handled
16:29:11 <jle`> where they come into play is long after the tokening and lexing, where whitespace doesn't matter anymore
16:30:22 <Nevoic> I've never written a language, so when you jump into tokenizing and lexing, I need to like jump into a separate browser tab and start looking things up about how languages parse syntax.
16:30:49 <jle`> ah, okay
16:31:05 <glguy> Nevoic: Do you already understand how + and * interact in other languages?
16:31:24 <remexre> is there a thing for computing and caching an IO'd value?
16:31:36 <Nevoic> I understand the concept of addition and multiplication. I also understand order of operations, and how * takes precedence over +.
16:31:46 <jle`> remexre: there might be some libraries, but i often re-implement it myself, heh
16:31:53 <jle`> that's the nice thing about first-class IO
16:31:58 <glguy> OK, the only thing that's new here is that you can define more operators than + and * and what their precedences are
16:32:09 <remexre> jle`: Should I build it over MVar? or IORef? or what primitive :P
16:32:13 <Nevoic> I don't understand the lexical analysis that goes into parsing various expressions to make that determination, though.
16:32:58 <glguy> Is your question about how it's implemented or how to know what bits of code like you pasted earlier mean?
16:32:59 <Nevoic> Okay, cool. So I now have a new operator `$`, with a certain precedence that is below +, so * and + both happen before $.
16:33:03 <hpc> remexre: i usually use MVar because it's more explicitly "about" concurrency
16:33:05 <nisstyre> Nevoic: look up the precedence climbing algorithm
16:33:12 <remexre> hpc: Alright, thanks!
16:33:16 <nisstyre> that's what I always use to do precedence parsing
16:33:23 <nisstyre> https://eli.thegreenplace.net/2012/08/02/parsing-expressions-by-precedence-climbing
16:33:29 <nisstyre> example is in Python but easy to write in Haskell
16:33:38 <hpc> remexre: IORef has a number of concurrency-safe operations you could use to implement it, but not all of them
16:33:42 <glguy> Nevoic: yes
16:34:00 <hpc> it's really easy to keep the whole model of MVar in your head at once
16:34:12 <Nevoic> Yeah, I understand that. I don't know why we're going into lexigraphical parsing to answer my question though. A newline operator normally doesn't affect operator precedence.
16:34:19 <glguy> Nevoic: $ is precedence 0 (the lowest) + has 6,   * has 7
16:34:21 <Solonarv> if you're just writing once and only ever reading after that it hardly even matters what you use
16:34:21 <Nevoic> But a couple people needed to clarify some details, because apparently that's not always true.
16:34:33 <nisstyre> Nevoic: you can imagine that the Prelude simply defines a bunch of operators, their precedence, and their association, and maps them to an internal function that the runtime system knows about
16:34:44 <haskellnoob> A question on evaluation: say I have a function like "testing = x + x where x = sum [1,2,3]" does x get evaluated once and then substituted or is x evaluated for each use of x in the function??
16:34:47 <glguy> Nevoic: Haskell has layout-sensitive parsing. In cases other than the one you're looking at that can matter
16:34:49 <nisstyre> Nevoic: then GHC takes those definitons in the Prelude and is able to parse code with them
16:34:54 <nisstyre> I don't know if that's *exactly* how it works
16:34:58 <nisstyre> but that is a good approximation
16:35:04 <jle`> remexre: i recently wrote my own cacher for a library, https://github.com/mstksg/advent-of-code-api
16:35:17 <jle`> remexre: idk, cacheing is a pretty complex topic and there is a lot of variability that depends on your situation
16:35:18 <glguy> Nevoic: so if we say "no, newlines never matter" you'll find a surprise later. So the answer is "no, they don't matter here"
16:35:34 <jle`> i find it a lot easier to just write an ad-hoc cacheing that is specific for my situation than to try to learn how to use some general purpose library
16:35:36 <Nevoic> Cool, that makes sense.
16:35:37 * hackage quickcheck-instances 0.3.20 - Common quickcheck instances  https://hackage.haskell.org/package/quickcheck-instances-0.3.20 (phadej)
16:35:40 <Nevoic> Thanks!
16:35:44 <glguy> Nevoic: Have you seen do-notation yet?
16:35:48 <Solonarv> if you just want "laziness but with IO" that is quite simple
16:35:54 <lyxia> haskellnoob: there's nothing in the language that dictates either but in practice x is computed once.
16:35:54 <Nevoic> Yeah, I don't understand it's purpose though glguy
16:35:57 <remexre> jle`: okay, thanks
16:36:09 <nisstyre> Nevoic: your original question was about associativity I think right?
16:36:09 <jle`> actually that link might be a bad example, since i cached on disk, heh
16:36:11 <glguy> Nevoic: OK, but if you're seen some examples you can probably imagine that newlines and indentation levels start to matter
16:36:11 <haskellnoob> lyxia: ok, thanks
16:36:17 <jle`> but actually it might be a good example...it's very situational :)
16:36:44 <Nevoic> I mean I come from other languages where newlines matter syntactically. I've done development in Kotlin, Ruby, and Python, all which use newlines to denote the start of a new expression.
16:36:56 <nisstyre> Nevoic: Haskell uses the "offside rule"
16:37:01 <jle`> haskellnoob: if you are using a thunk-based implementation, then x will be a thunk that is evaluated once
16:37:15 <jle`> Nevoic: be careful :)  newlines in python, etc. actually denote the start of a new statement
16:37:30 <jle`> i only mention this distinction because statements and expressions are very blurred in languages like python, ruby
16:37:34 <nisstyre> jle`: not technically always true
16:37:35 <jle`> but in Haskell, the difference is very explicit
16:38:02 <nisstyre> jle`: (2\n+\n3\) is valid Python
16:38:07 * hackage arbor-monad-metric-datadog 1.1.0 - Metric library backend for datadog.  https://hackage.haskell.org/package/arbor-monad-metric-datadog-1.1.0 (arbornetworks)
16:38:14 <nisstyre> * (2\n+\n3\n)
16:38:21 <jle`> ah yes, not always true.  but the "new thing" that is probably being referred to in the message probably is more closely related to statements than expressions 
16:38:24 <Solonarv> % newtype CacheMe a = CacheMe (MVar (Either (IO a) a))
16:38:25 <yahb> Solonarv: 
16:38:31 <jle`> nisstyre: well, python has expression statements
16:38:36 <nisstyre> yeah, it's weird
16:38:44 <Solonarv> % newCached act = CacheMe <$> newMVar (Left act)
16:38:44 <yahb> Solonarv: 
16:38:47 <jle`> so it's a statement, but of the form [expression]
16:38:48 <nisstyre> but that is a multiline expression, which is allowed if you bracket it
16:38:55 <jle`> nisstyre: oh, i see your point
16:39:11 <nisstyre> you can also put semicolons in some places
16:39:17 <jle`> fun stuff :)
16:39:18 <nisstyre> Python syntax is very strange
16:39:22 <Nevoic> jle yee that's a good point, I mispoke. I know about the differences between statements and expressions.
16:39:44 <nisstyre> they have a huge BNF grammar for it
16:39:49 <nisstyre> and that's basically the defacto spec
16:40:24 <Solonarv> % runCached (CacheMe var) = takeMVar var >>= \case { Left act -> do { x <-act; x <$ putMVar var (Right x) }; Right x -> x <$ putMVar var (Right x) }
16:40:25 <yahb> Solonarv: 
16:40:57 <Solonarv> % myCached = newCached (42 <$ putStrLn "computing...")
16:40:57 <yahb> Solonarv: 
16:41:03 <Solonarv> % runCached myCached
16:41:03 <yahb> Solonarv: ; <interactive>:81:11: error:; * Couldn't match expected type `CacheMe b' with actual type `IO (CacheMe Integer)'; * In the first argument of `runCached', namely `myCached'; In the expression: runCached myCached; In an equation for `it': it = runCached myCached; * Relevant bindings include it :: IO b (bound at <interactive>:81:1)
16:41:30 <Solonarv> % myCached <- newCached (42 <$ putStrLn "computing...")
16:41:30 <yahb> Solonarv: 
16:41:32 <Solonarv> % runCached myCached
16:41:32 <yahb> Solonarv: computing...; 42
16:41:40 <Solonarv> % runCached myCached
16:41:40 <yahb> Solonarv: 42
16:42:00 <jle`> alternatively if you don't ever dynamically generate cached things, you can use the 'global mutable variable' trick
16:42:01 <Solonarv> remexre: there's a super simple implementation
16:42:45 <slack1256> % 5 take 5 $ fix (1:)
16:42:45 <yahb> slack1256: ; <interactive>:85:1: error: lexical error at character '\ETX'
16:43:17 <Solonarv> less than 10 loc :D
16:44:24 <Solonarv> slack1256: it doesn't like the color :/
16:45:22 <slack1256> It seems so, oh well.
16:45:26 <remexre> jle`, Solonarv: Yeah, global would work
16:48:36 <jle`> s/alternatively/and/
17:13:37 * hackage arbor-monad-logger 0.1.1.0 - Simple logging library  https://hackage.haskell.org/package/arbor-monad-logger-0.1.1.0 (arbornetworks)
17:32:41 <dmwit> % :t mfix
17:32:41 <yahb> dmwit: MonadFix m => (a -> m a) -> m a
17:35:51 <dmwit> % :t \act -> mfix $ \ref -> newIORef (do { v <- act; writeIORef ref (return v); return v })
17:35:51 <yahb> dmwit: IO b -> IO (IORef (IO b))
17:36:03 <dmwit> oops
17:36:03 <codedmart_> OK so had to step away for a while. Now looking at this Queue idea again for requests. I know how to setup a Queue and and/remove to it, etc. The part I am not sure about is how do I keep the same return type for my web requests if I am adding them to a Queue to be processed now.
17:37:13 <dmwit> % dmwitCached act = mfix (\ref -> newIORef (do { v <- act; writeIORef ref (return v); return v })) >>= readIORef
17:37:13 <yahb> dmwit: 
17:37:18 <bwright> Can anyone point me in a direction for fixing the ghc error: "Warning: Coulnd't figure out linker information" ?  I believe I do have the GNU ld.
17:37:27 <codedmart_> Say addToQueue is `a -> IO ()` and my request returned `IO Foo`. If I add it to Queue now that returns `IO ()`
17:37:30 <dmwit> % myCached <- dmwitCached (42 <$ putStrLn "computing...")
17:37:30 <yahb> dmwit: 
17:37:56 <dmwit> % myCached >>= print >> myCached >>= print
17:37:56 <yahb> dmwit: computing...; 42; computing...; 42
17:38:00 <dmwit> oh no!
17:40:37 * hackage asif 5.0.0 - Library for creating and querying segmented feeds  https://hackage.haskell.org/package/asif-5.0.0 (arbornetworks)
17:40:55 <dmwit> % dmwitCached act = join . readIORef <$> mfix (\ref -> newIORef (do { v <- act; writeIORef ref (return v); return v }))
17:40:55 <yahb> dmwit: 
17:41:10 <dmwit> % myCached <- dmwitCached (42 <$ putStrLn "computing...")
17:41:10 <yahb> dmwit: 
17:41:12 <dmwit> % myCached >>= print >> myCached >>= print
17:41:12 <yahb> dmwit: computing...; 42; 42
17:41:15 <dmwit> yay!
17:43:01 <dmwit> codedmart_: Unless you plan to wait for the queue to get around to your request, it will simply have to return some info on whether the thing got added to the queue only, and not the result of executing the thing on the queue.
17:43:05 <dmwit> So of course the type has to change.
17:43:24 <codedmart_> dmwit: Right I understand that.
17:43:31 <dmwit> bwright: Is that the whole error? What's the smallest code I could use to try to reproduce that problem?
17:43:52 <codedmart_> But since I use servant and my types expect a specific return not sure how this will fit together.
17:46:13 <codedmart_> All I want is to make sure that only 15 requests happen per second. But I would like the types to return the same thing they do now. Now sure if that is possible with how I am thinking about it.
17:46:53 <bwright> dmwit: I'm just doing a hello world to get ghc going.  I'm using the ghc package on OpenBSD, but I'm sure it will take some fiddling.
17:47:28 <dmwit> I... don't think you can control how many requests other people send you.
17:48:05 <dmwit> bwright: Hello world like `main = putStrLn "hello world"`?
17:48:13 <bwright> dmwit: yes
17:48:15 <slack1256> He can return HTTP 503 after 15 request for the rest of the second
17:48:23 <codedmart_> dmwit: That is my point. I can't on how many they send me. But I want to pool them and only run 15 per second. Because the api I am hitting only allows 15 per second.
17:49:05 <dmwit> bwright: Yikes, if even that doesn't work that seems pretty rough.
17:49:25 <dmwit> bwright: You could try adding some verbosity flags to see if GHC will disgorge info about how it's trying to get that linker information.
17:50:37 * hackage arbor-monad-logger 0.1.1.1 - Simple logging library  https://hackage.haskell.org/package/arbor-monad-logger-0.1.1.1 (arbornetworks)
17:50:39 <bwright> dmwit: Thanks.  I'll mess with it and check back when I have something more specific.  
18:07:51 <Solonarv> dmwit: cool use of mfix, by the way!
18:08:14 <bwright> dmwit: Would there be something other than the /usr/local/lib/ghc/settings file that ghc would be using to get info about C compiler, linker, etc. ?
18:16:02 <byorgey> gentauro: I think you just have to add --package diagrams-lib to your flags
18:37:08 <jpg> In this code: https://pastebin.com/zQ1wNg7F
18:37:37 * hackage influxdb 1.6.1.3 - Haskell client library for InfluxDB  https://hackage.haskell.org/package/influxdb-1.6.1.3 (MitsutoshiAoe)
18:37:55 <jpg> If I call :kind! Rem (S Z) (S ( S Z)), the interpreter stucks
18:38:08 <jpg> and eats my memory
18:38:30 <jpg> why?
18:55:58 <ph88^> can i safely use stack build  in two different projects at the same time ?
19:28:52 <lyxia> jpg: there is no defined evaluation order for type families and often they behave strictly
19:35:07 * hackage ats-pkg 3.2.5.12 - A build tool for ATS  https://hackage.haskell.org/package/ats-pkg-3.2.5.12 (vmchale)
19:45:18 <jpg> So the problem can be fixed encoding the type level If in another way, now possibly the compiler is evaluating both branches every time
19:50:00 <jpg> isn't it?
19:51:14 <jpg> In Data.Type.Bool If is definded this way, so probably it is ok. Should I change Rem?
19:53:10 <jpg> Yes, I fixed it putting  the equation Rem Z n = Z on the Rem Type family
19:57:23 <jpg> interesting
20:37:46 <average> hi
20:38:02 <average> how come you guys weren't the first to implement a major CAS, and a major theorem-prover?
20:39:46 <average> every time I hear about Haskell, type safety and how Haskell is great for math.. I am wondering "why isn't the #1 CAS and theorem prover written in Haskell?"
20:39:59 <average> it might just be a case of "the emperor has no clothes" ..
20:45:28 <mjrosenb> Is there anything like find, but operates on monads?
20:45:42 <glguy> :t mfilter
20:45:43 <lambdabot> MonadPlus m => (a -> Bool) -> m a -> m a
20:46:06 <mjrosenb> I could use head <$> filterM f l
20:46:53 <mjrosenb> but that will still evaluate the whole list, rather than stopping when it finds the first element.
20:48:37 <mjrosenb> hrm, actually what I've written a function for is more like head <$> mapMaybeM f l; I want thing :: Monad m => a -> m (Maybe b) -> [a] -> Maybe b
21:21:37 * hackage asap 0.0.4 - Atlassian Service Authentication Protocol  https://hackage.haskell.org/package/asap-0.0.4 (puffnfresh)
21:46:37 <dmwit> mjrosenb: http://hackage.haskell.org/package/monad-loops-0.4.3/docs/Control-Monad-Loops.html#v:firstM
21:48:30 <mjrosenb> ahh, yup, that looks almost like what I want.
21:48:35 <mjrosenb> I ended up writing my won.
21:50:01 <mjrosenb> *own
21:53:55 <dmwit> :t \f -> foldr (\x k -> f x >>= maybe k (pure.pure)) (pure Nothing)
21:53:56 <lambdabot> (Monad m, Foldable t1) => (t2 -> m (Maybe a)) -> t1 t2 -> m (Maybe a)
21:54:32 <mjrosenb> ahh, (pure.pure)
21:54:38 <mjrosenb> true purity.
21:54:52 <dmwit> pure Nothing -- v. zen
21:57:46 <dmwit> % import qualified Control.Monad.Trans.Maybe as MT
21:57:47 <yahb> dmwit: 
21:58:05 <dmwit> % :t \f -> MT.runMaybeT . asum . map (MT.MaybeT . f)
21:58:05 <yahb> dmwit: Monad m => (a1 -> m (Maybe a2)) -> [a1] -> m (Maybe a2)
21:58:17 <dmwit> % :t \f -> MT.runMaybeT . asum . fmap (MT.MaybeT . f)
21:58:18 <yahb> dmwit: (Foldable t, Monad m, Functor t) => (a1 -> m (Maybe a2)) -> t a1 -> m (Maybe a2)
21:58:21 <dmwit> much better
21:59:03 <dmwit> traverse : sequence :: _ : asum -- ?
22:00:10 <dmwit> mjrosenb: Anyway, asum+MaybeT seems like the way to go to me.
22:45:14 <c_wraith> I just wrote a non-trivial search that both compiled and worked correctly on the first try.  what the heck?
22:53:31 <benzrf> :]
22:59:45 <koz_> :[
23:26:33 <mjrosenb> how can I use zoom to zoom in on an individual element of an array within the state? it looks related to the fact that ix when used as a getter returns a Maybe.
23:53:07 * hackage funspection 0.1.0.0 - Type-level function utilities  https://hackage.haskell.org/package/funspection-0.1.0.0 (ThomasEding)
23:55:58 <Nevoic> Can you parse [IO] in main?
23:56:06 <Nevoic> I can't see to figure out how to loop through a list of IOs.
23:56:57 <mjrosenb> sequence
23:57:00 <mjrosenb> or sequence_
23:57:25 <dminuoso> Nevoic: Or just use traverse/traverse_ to begin with.
23:58:40 <Nevoic> Thanks!
