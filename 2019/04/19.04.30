00:16:17 * hackage clock 0.8 - High-resolution clock functions: monotonic, realtime, cputime.  https://hackage.haskell.org/package/clock-0.8 (CetinSert)
00:20:38 <c50a326> Axman6: hey these are awesome... I'm stuck on exercise 6 though :\
00:22:19 <c50a326> `f banana` would be like: m (a -> n b) -> m (n a -> n b)   I think?   which doesn't seem/look helpful...
00:24:47 <tsahyt> I'm currently running flatpak-builder to flatpak a haskell GTK app. it's compiling all dependencies (some 120 or so) sequentially. You don't know how much package level parallelism helps your compile times until you miss it...
00:28:11 <Solonarv> yikes
00:28:14 <dminuoso> jle`: If a blog post does not come from this, Id still be very interested what usage Day would have.
00:28:57 <tsahyt> anyhow, flatpak strikes me as a reasonable way to distribute such apps. it's unreasonable to expect your users to pull in 120 libraries in an ecosystem they're not using, etc.
00:29:11 <Solonarv> it's already used in lens (because of *course* it is)
00:29:40 <dminuoso> Solonarv: I wouldn't count `lens` as the "this is a day-to-day problem"
00:29:44 <dminuoso> Pun fully intended.
00:29:48 <tsahyt> especially considering that most operating systems don't just provide these packages
00:30:09 <Solonarv> and also, "Applicative is a monoid in the category of endofunctors with Day as the tensor product"
00:30:28 <jle`> dminuoso: after some reflection, it looks like it came up out of the need to have a "deferred" parser that i can break down and inspect
00:30:32 <dminuoso> Solonarv: It should be *monoindal category :|
00:30:44 <dminuoso> jle`: Ah, so essentially same reason you'd use Free
00:30:46 <jle`> so it's acting as an EDSL for deferred evaluation
00:30:50 <Solonarv> fair enough, I was talking off the cuff
00:31:10 <jle`> yeah, except Free/free Applicative/etc. is for using the "same" language with itself
00:31:23 <jle`> but Day is useful for combining two different languages maybe.
00:31:44 <dminuoso> jle`: I'd so love to read a detailed blog post on this, should you find the time.
00:31:45 <jle`> type ParserPieces = Day Lang1 Lang2
00:31:48 <Solonarv> you could define Applicative as:
00:31:48 <Solonarv> class Applicative f where pure :: Id ~> f; ap :: Day f f ~> f
00:31:58 <dminuoso> Solonarv: Oh yeah Im aware.
00:32:26 <dminuoso> Solonarv: Amusingly I didn't get it until I considered using Day in infix notation, then everything clicked.
00:32:32 <jle`> hm. but i wonder if that's any different than just using FreeApplicative (Product Lang1 Lang2)
00:32:32 <Solonarv> so it's not used directly super often but it lies at the base of an abstraction we use fairly often
00:32:44 <jle`> ah, it is.
00:33:00 <jle`> using free applicative over (Lang1 :*: Lang2) lets you mix layers of lang1 and lang2 together
00:33:06 <Lears> c50a326: `furry'` has a very similar type sig to `banana`; you just want to tweak the argument `furry'` takes so you can apply `banana` to it and get the result. Don't forget you have `unicorn` too.
00:33:15 <jle`> but Day Lang1 Lang2 ensures that the two languages remain strictly separate until you finally interpret them
00:34:06 <jle`> dminuoso: funnily enough i was actually using Free but was unsatisfied with it (because the target context isn't nicely monadic) when i realized Day would work
00:37:35 <dminuoso> jle`: What about Ap then?
00:40:05 <c50a326> Lears: I ended up looking up how to define fmap in terms of bind :\ 
00:40:54 <c50a326> Lears: one thing that's bothersome is that I don't seem to be able to verify types like I usually do in this case, e.g. if I do this:
00:40:57 <c50a326> furry' f ma = let something = unicorn . f in undefined
00:41:18 <c50a326> I get an error about "could not deduce" somethingorother
00:41:33 <c50a326> which is annoying because in vscode/intero I can't hover the type of "something" to see what the type is... 
00:41:50 <c50a326> (this approach sometimes helps me write haskell piece by piece)
00:43:21 <jle`> dminuoso: Ap is FreeApplicative
00:44:01 <dminuoso> jle`: Ohh wait, so you are using Day with `f !~ g`?
00:44:06 <jle`> and the difference is that if you use Ap over a sum or product if Lang1/Lang2, you get intermixed layers of Lang1/Lang2 
00:44:09 <jle`> dminuoso: yes, exactly :)
00:44:13 <dminuoso> Okay I see.
00:44:24 <dminuoso> Pretty cool then.
00:44:25 <jle`> so it's like using (a,b) instead of [Either a b]
00:44:30 <jle`> re: Day vs. Ap
00:45:09 <Ariakenom> c50a326: do you know typed holes?
00:48:01 <c50a326> Ariakenom: ah yeah I used them before, will do that again, cheers
00:48:31 <Ariakenom> great
01:23:11 <dminuoso> jle`: There's still something I don't like about Day. It's that it doesn't compute anything, and it does not seem to be isomorphic to an existing construction.
01:23:42 <jle`> i think the not-computing something is the "point" of why i'm using it
01:24:03 <Solonarv> sure, much in the same way that (,) doesn't compute anything and isn't isomorphic to an existing construction
01:24:14 <Solonarv> that is precisely the point
01:24:56 <jle`> and yeah, that too ;) the fact that it isn't isomorphic to an existing construction is the reason i'm using it ...
01:25:09 <jle`> if it was isomorphic to an existing construction, i'd be using the existing construction itself
01:26:58 <dminuoso> Mmm I guess the same could be said for Free too or [] too, and I dont have any issues with those..
01:27:23 <jle`> right, the fact that they do'nt compute anything is a part of the point
01:27:55 <jle`> maybe it might be interesting to compare all the different 'tensors'/functor combiners
01:27:57 <Solonarv> although Free f a is actually isomorphic to Fix (Compose (Either a) f)
01:28:32 <jle`> in this conversation we've already talked about :*:, :+:, Day, and we can throw in Compose too
01:28:43 <jle`> things of kind (* -> *) -> (* -> *) -> (* -> *)
01:29:05 <dminuoso> So I guess those things are useful because of the operations defined on them.
01:29:28 <jle`> in this case they are useful because of how they 'combine' the structures, i think
01:30:48 <jle`> if we go along the 'language edsl' route, `Lang1 :+: Lang2` is a union of languages that never combine. it's all one or the other
01:31:03 <Solonarv> % class Functor f => Monoidal tensor id f where unit :: id ~> f; join :: f `tensor` f ~> f
01:31:03 <yahb> Solonarv: 
01:31:23 <jle`> `Lang1 :*: Lang2` is now, the two languages process things separately, and both languages create a full picture of the result
01:31:31 <Solonarv> now we have: Applicative = Monoidal Day Identity; Monad = Monoidal Compose Identity
01:31:46 <jle`> `Day Lang1 Lang2` is the two languages process in parallel, but both produce a *part* of the result
01:32:05 <Solonarv> or also: Applicative = Monoidal Product Proxy
01:32:06 <jle`> but you can't produce the final result without running both languages
01:32:42 <jle`> but whereas Lang1 :*: Lang2, you can produce the final result from either language and choose whichever one you want.
01:32:52 <jle`> maybe :*: is like fork, and Day is like diamond
01:32:54 <Solonarv> so yeah, picking different tensor products for the monoidal category of endofunctors gets us interesting things
01:34:42 <jle`> and `Lang1 :.: Lang2` is, you have to do one, then the other.  it imposes a strict sequence, i suppose
01:34:47 * hackage yesod-test 1.6.6.1 - integration testing for WAI/Yesod Applications  https://hackage.haskell.org/package/yesod-test-1.6.6.1 (MichaelSnoyman)
01:35:30 <jle`> in both :.: (Compose) and Day, each Lang generates one half of the puzzle. but Day lets them work in parallel and you can put together the pieces after. but Compose forces an ordering in dependency
01:35:36 <jle`> just rambling :)
01:35:45 <jle`> now how to fit Ran/Lan/Curried/etc. into this picture ...
01:37:04 <dminuoso> jle`: How would one compute (IO `Day` STM) a
01:37:28 <jle`> well it depends on the 'target' interpretation
01:37:59 <jle`> in this case it's not super interesting, because probably the only meaningful interpreter is IO, or any other MonadIO
01:38:18 <dminuoso> Ah, I guess my question is silly.
01:38:23 <jle`> but you could interpret it using interpret (Day iox stmx f) = f <$> iox <*> atomically stmx
01:38:31 <jle`> (IO `Day` STM) a -> IO a
01:38:41 <dminuoso> It's equivalent to: how does one compute `a` from `M a` for some choice of M
01:39:01 <dminuoso> jle`: Your ramble about fork/diamond makes quite a lot of sense.
01:39:20 <jle`> it's more interesting when you have some sort of carrier functor that you can interpret in some useful context
01:39:25 <lavalike> what's Day for?
01:39:26 <jle`> yeah, compare that to (IO :*: STM) a
01:39:47 * hackage wai-extra 3.0.26 - Provides some basic WAI handlers and middleware.  https://hackage.haskell.org/package/wai-extra-3.0.26 (MichaelSnoyman)
01:39:47 <jle`> interpreting (IO :*: STM) a -> IO a, you could choose one or the other
01:39:53 <dminuoso> Right
01:39:57 <jle`> you can use only the IO side, or only the STM side.
01:40:06 <jle`> but using Day forces you to use both of them
01:40:27 <jle`> lavalike: it's not a super common data type, but this discussion came up because i ran into a usage for it earlier today, heh
01:40:36 <lavalike> fancy! what for?
01:41:29 <jle`> well i wanted to make a structure that defined a parser, so i could inspect the structure before interpreting it into a parser
01:42:06 <jle`> i use Day to allow me to create a more fully featured structure out of simpler structure pieces
01:42:14 <Solonarv> lavalike: definition just for context: data Day f g a where Day :: f x -> g y -> (x -> y -> a) -> Day f g a
01:42:42 <jle`> usually i do something like this using :*:, :+:, Free, Ap, etc.; but this was the first time Day was the thing I needed, heh
01:42:51 <jle`> that combined the pieces in the right way
01:43:19 <jle`> * add Compose/:.:, Sum/:+: to that list too
01:43:33 <Solonarv> :+: was already in the list ;)
01:43:51 <dminuoso> We could call Day just :^: for symmetry
01:43:56 <lavalike> I guess f and g are the "simpler structure pieces"
01:44:07 <dminuoso> (Since :*: is taken already)
01:44:21 <jle`> yes, exactly :)
01:44:33 <Solonarv> call it :->: :D
01:44:40 <Solonarv> or :<*>:
01:44:48 <jle`> the main point is something i can pattern match on and manipulate as an ADT
01:44:59 <jle`> instead of just an opaque (String -> (Maybe a, String)) parser type
01:45:20 <dminuoso> Solonarv: The star would be wonderful to keep as an indicator of convolution.
01:45:45 <dminuoso> I wonder, is :x: valid?
01:45:47 <Solonarv> it isn't called "Day convolution" for nothing!
01:45:49 <Solonarv> it is not
01:46:05 <dminuoso> % data f :x: g
01:46:05 <yahb> dminuoso: ; <interactive>:137:6: error: Malformed head of type or class declaration: f : x : g
01:46:24 <dminuoso> Solonarv: I just have absolutely no clue how that correlates to convolution.
01:46:37 <dminuoso> But I feel comforted in the fact that people with far more category theory brains have figured that out already.
01:46:39 <Solonarv> an identifier has to be either all-alphanumeric or all-punctuation
01:46:43 <jle`> there was a discussion on this channel maybe a year or so ago that helped me see why it is a convolution
01:47:00 <jle`> basically you just symbolically replace all of the ->/,/etc. curry-howard isomporphism style
01:47:09 <jle`> and you get literally the mathematical convolution of a time series
01:47:12 <dminuoso> jle`: I think if I understand coends I might be ablt o see it
01:47:26 <Solonarv> something something (co)ends are integrals?
01:47:29 <jle`> i don't really grasp it on an intuitive level
01:47:31 <dminuoso> Solonarv: Yeah.
01:47:33 <jle`> just from a symbolic level :)
01:47:36 <jle`> but that's the first step, i suppose
01:48:13 <dminuoso> "We observe now that Day convolution is equivalently a left Kan extension. This will be key for understanding monoids and modules with respect to Day convolution."
01:48:29 <dminuoso> I should really step back into category theory and crack kan extensions. Soon.
01:50:36 <dminuoso> Regarding the bit about "does not compute anything", I also just realized how products are defined in category theory.
01:50:49 <jle`> ah, nice connection :)
01:50:52 <Solonarv> I'm only just getting into (sort of) proper math again
01:51:36 <Solonarv> my theoretical physics class requires calculus that I theoretically know but it has rusted and most everyone else has taken "calc for physicists" last semester - I haven't
01:52:36 <c50a326> dang it, what do I do about this? https://gist.github.com/m1574b34r/eecba75df7afd5ed3dd9e7b1fc2c8d05 (error in comment)
01:53:19 <c50a326> I'm trying to use typed holes to get this done... maybe I should just stop arsing about the overly general Parser typage with the existential extension and whatnot and just use String...
01:54:07 <Solonarv> you can have an existential but that isn't the right place to put it
01:54:12 <c50a326> before, it was telling me I couldn't use the `runParser` function because of suchandsuch... now it won't even let me pattern match >.>
01:54:45 <Solonarv> (note: to see the problem it's enough to look at how one would write the Applicative instance)
01:54:47 * hackage kind-apply 0.3.1.0 - Utilities to work with lists of types  https://hackage.haskell.org/package/kind-apply-0.3.1.0 (AlejandroSerrano)
01:55:32 <Solonarv> you have a (exists c1. [c1] -> (a, [c1])) and a (exists c2. [c2] -> (a, [c2]))
01:55:37 <Solonarv> and you need to combine those
01:55:55 <Solonarv> but you can't do that, because you have no idea what c1 and c2 are, but actually they need to be the same
01:56:17 * hackage kind-generics-th 0.1.1.0 - Template Haskell support for generating `GenericK` instances  https://hackage.haskell.org/package/kind-generics-th-0.1.1.0 (AlejandroSerrano)
01:56:50 <Solonarv> there's no way around this: that's a natural consequence of hiding the token type behind an existential
01:57:46 <dminuoso> c50a326: Semantically what you are trying to do is equivalent to the following value level concept: Imagine a function `f : Int -> Double`, and someone hands you a Double resulting from `f` applied to some Int, and you are trying to refer to the Int. It's gone, you cant know anything about it.
01:58:09 <Solonarv> instead you can make the token type a plain old type parameter:
01:58:09 <Solonarv> newtype Parser tok a = Parser { runParser :: [tok] -> (a, [tok]) }
01:58:28 <dminuoso> Or better: you are trying to refer to the variable representing the Int inside `f` when you are given the Double. It just does not work.
01:58:52 <c50a326> oh right
02:01:10 <c50a326> okay that makes some sense to me, thanks
02:01:28 <dminuoso> c50a326: I really like to think of `forall q. ...` as a kind of lambda-abstraction over a type. For me at least this helps to see who can/must apply a construction to a type, and who has no access to it
02:02:09 <Solonarv> (this is also a theoretically sound way of looking at foralls, so it really is quite helpful!)
02:11:17 * hackage mmark 0.0.7.0 - Strict markdown processor for writers  https://hackage.haskell.org/package/mmark-0.0.7.0 (mrkkrp)
02:14:11 <dminuoso> % data Parser a = forall c. Parser { runParser :: [c] -> [(a, [c])] }
02:14:11 <yahb> dminuoso: 
02:14:14 <dminuoso> % :t Parser
02:14:14 <yahb> dminuoso: ([c] -> [(a, [c])]) -> Parser a
02:14:30 <dminuoso> % :set -fprint-explicit-foralls
02:14:30 <yahb> dminuoso: 
02:14:33 <dminuoso> % :t Parser
02:14:33 <yahb> dminuoso: forall {c} {a}. ([c] -> [(a, [c])]) -> Parser a
02:18:09 <dminuoso> c50a326: If we replace `forall c. ...` with the ascii notation `/\ c. ...` to make it similar to the value level `\x -> ...` where dot . takes the same role as the arrow in lambda syntax.
02:18:22 <dminuoso> Then you might be able to see it even better
02:19:27 <Solonarv> note that you can constructor whatever parsers you want:
02:19:27 <Solonarv> % let foo = Parser (\xs -> (sum xs, xs)); bar = Parser (\xs -> map (flip splitAt xs) [1..]) in ()
02:19:28 <yahb> Solonarv: ; <interactive>:142:26: error:; * Couldn't match expected type `[(a, [Integer])]' with actual type `(Integer, [Integer])'; * In the expression: (sum xs, xs); In the first argument of `Parser', namely `(\ xs -> (sum xs, xs))'; In the expression: Parser (\ xs -> (sum xs, xs)); * Relevant bindings include foo :: Parser a (bound at <interactive>:142:5)
02:19:29 <dminuoso> Solonarv: Its not even theoretically sound, even practically since GHC implements it exactly as such - optimizations aside :P
02:19:52 <Solonarv> % let foo = Parser (\xs -> [(sum xs, xs)]); bar = Parser (\xs -> map (flip splitAt xs) [1..]) in ()
02:19:52 <yahb> Solonarv: ()
02:19:58 <dminuoso> % :t foo
02:19:58 <yahb> dminuoso: ; <interactive>:1:1: error:; * Variable not in scope: foo; * Perhaps you meant `for' (imported from Data.Traversable)
02:20:11 <Solonarv> ...but we can't ever run a parser on anything other than an empty list
02:20:40 <Solonarv> (we don't know what type of token the parser wants, so how could we give it anything butan empty list?)
02:21:02 <dminuoso> Solonarv: can you even give it an empty lis?
02:21:04 <dminuoso> Id expect not
02:21:18 <dminuoso> % foo = Parser (\xs -> [(sum xs, xs)]); 
02:21:19 <yahb> dminuoso: 
02:21:23 <dminuoso> % runParser foo []
02:21:23 <yahb> dminuoso: ; <interactive>:146:1: error:; * Cannot use record selector `runParser' as a function due to escaped type variables; Probable fix: use pattern-matching syntax instead; * In the expression: runParser foo []; In an equation for `it': it = runParser foo []
02:21:45 <dminuoso> The problem is more fundamental than that
02:21:55 <Solonarv> % case foo of Parser f -> case f [] of (result, _) -> result
02:21:55 <yahb> Solonarv: ; <interactive>:147:38: error:; * Couldn't match expected type `[(Integer, [c])]' with actual type `(p, b0)'; * In the pattern: (result, _); In a case alternative: (result, _) -> result; In the expression: case f [] of { (result, _) -> result }; * Relevant bindings include; f :: [c] -> [(Integer, [c])] (bound at <interactive>:147:20); it :: p (bound at <interactive>
02:22:22 <Solonarv> % case foo of Parser f -> case f [] of (result, _):_ -> result
02:22:22 <yahb> Solonarv: 0
02:22:26 <dminuoso> Oh interesting
02:22:27 <Solonarv> see? works fine
02:22:47 <dminuoso> Solonarv: Ah I guess it makes sense actually
02:23:01 <Solonarv> in fact this is the only thing you can do with a parser
02:23:33 <Solonarv> % parseEps :: Parser a -> [a]; parseEps (Parser f) = map fst (f [])
02:23:33 <yahb> Solonarv: 
02:25:35 <dminuoso> Solonarv: What's the type of `f` inside that pattern match?
02:27:11 <dminuoso> It seems as if it should be f :: (forall a. [a] -> (c, [a]) where c is some monomorphized type variable
02:27:26 <Solonarv> dminuoso: [c] -> (a, [c]) with a bound in the signature of parseEps, and c a skolem type variable brought into scope by the pattern match
02:27:44 <dminuoso> Solonarv: Huh, you can bring skolems back into scope?
02:28:00 <Solonarv> yes, you just can't do a whole lot with them
02:29:05 <dminuoso> Solonarv: Are skolems used in GADTs?
02:29:21 <Solonarv> indeed
02:29:38 <Solonarv> and in fact I prefer GADT syntax for writing existentials
02:30:33 <dminuoso> Solonarv: Do you have a concrete example that fits?
02:30:36 <Solonarv> newtype Parser :: Type -> Type where Parser :: { runParser :: [c] -> (a, [c]) } -> Parser a
02:31:00 <dminuoso> Oh oh! I have seen this in a discussion about coends!
02:31:01 <Solonarv> yes, you can use record syntax together with GADT syntax :>
02:31:21 <dminuoso> No wait, it was Procompose actually
02:31:38 <dminuoso> data Procompose q p a b where Procompose :: q a c -> p c b -> Procompose q p a b
02:31:47 <dminuoso> That's the existential with `c`
02:31:49 <Solonarv> or for another example:
02:31:49 <Solonarv> data Day f g a where Day :: f x -> g y -> (x -> y -> a) -> Day f g a
02:32:08 <Solonarv> here x, y are existentials
02:32:19 <Solonarv> in your example it's c
02:32:26 <dminuoso> exists c. (q a c, p c b)
02:32:35 <dminuoso> Okay. I can see the relation (pun intended)
02:32:51 <Solonarv> yeah!
02:33:19 <dminuoso> data Coend p = forall a. Coend (p a a)
02:33:34 <dminuoso> Existentials everywhere
02:33:37 <Solonarv> and of course we have: (exists x. F x) -> T ~ forall x. F x -> T
02:33:50 <Solonarv> which is why we use 'forall' to write existentials in Haskell
02:34:03 <Solonarv> I like GADT syntax better because it makes this explicit
02:35:06 <Solonarv> compare: data T where MkT ::  forall x. F x  -> T
02:35:06 <Solonarv>          data T where MkT :: (exists x. F x) -> t
04:31:16 <Akii> Hi I need to parse a date as LocalTime so that it includes a timezone which I know and is static
04:31:25 <Akii> cannot use parseTimeM because that just assumes UTC
04:31:26 <Akii> obviously
04:32:21 <opqdonut> Akii: are you sure? there seems to be a ParsedTime instance for ZonedTime
04:32:24 <Akii> so let's say "2019-12-12T12:12:00" should yield (probably) "2019-12-12T11:12:00" for Berlin TZ
04:32:36 <opqdonut> oh right, but it parses the TZ out of the timestring
04:32:36 <Akii> ah okay but how do I tell it the TZ then
04:32:43 <opqdonut> you can't inject it (as such)
04:33:04 <Akii> I could encode the TZ but afaik I'd have to say +1 or +2 and that changes based on daylight savings
04:33:31 <opqdonut> so you need to parse a LocalTime
04:33:39 <opqdonut> and bundle it with a TimeZone into a ZonedTime
04:33:45 <opqdonut> that will get you the right behaviour I think
04:34:23 <opqdonut> (and then convert the ZonedTime into UTCTime if needed)
04:35:33 <Akii> yeah so how do I inject the timezone?
04:35:43 <opqdonut> just use the ZonedTime constructor
04:36:05 <opqdonut> you don't inject it into the parsing, you parse a time-zone-less LocalTime and then combine
04:36:11 <Akii> oh
04:36:40 <opqdonut> (caveat: I've never actually worked with timezones in haskell, I'm just reading the docs for you :D)
04:37:21 <Akii> yeah sorry I'm reading them as well but just not seeing the relationship
04:37:26 <Akii> you're completely right
04:42:38 <Akii> opqdonut thank you! I had to use the package Data.Time.Zones which can convert LocalTime to UTCTime given a TZ
04:42:45 <Akii> works perfectly
04:43:05 <opqdonut> great
04:43:20 <Akii> those can be so hardcore nasty bugs
04:43:33 <Akii> my alarm goes off every time I see a date
04:43:37 <merijn> Akii: :)
04:43:41 <Akii> time zone senses are tingling
04:44:01 <Akii> man haskell has been an absolute pleasure to work with in this private project
04:44:12 <opqdonut> yeah my reaction when seeing dates anywhere is "stop. think."
04:44:20 <merijn> In my experience the time modules aren't always super convenient, but they at least are very explicit and deliberate making it less likely you screw it up
04:44:45 <Akii> yes and that's absolutely ok
04:45:09 <Akii> I'd go as far and say they should have the TZ in the type as whatisitcalled
04:45:16 <Akii> this 'Foo thingies
04:47:35 <merijn> Akii: honestly, that probably makes 90% of things more hassle than they should be
04:47:47 <merijn> It also would make it impossible to have zone free times
04:47:55 <Akii> well that'd be LocalTime
04:48:03 <Akii> as soon as it's zoned it's in the type
04:48:16 <Akii> but yeah I agree, this is getting tedious fast
04:48:24 <merijn> Akii: Then it becomes impossible to do things like having times in different zones in a list/container
04:48:40 <Akii> I'd argue that maybe you don't want that lol
04:48:51 <merijn> Akii: Why? It's perfectly reasonable to want
04:49:02 <Akii> I'm just scared of times
04:49:06 <merijn> Akii: Like...literally every calendar application I know of has to support that
04:50:49 <Akii> fking Haskell just works every freaking time
04:50:56 <Akii> just wrote my first XML parser
04:51:00 <Akii> first try just works
04:51:07 <kernel-sanders> woa
04:51:21 <Akii> like just getting stuff out of XML not writing the actual parser
04:51:23 <merijn> Akii: Including the weird ass binary escape thing?
04:51:34 <merijn> Akii: Ah, that's easier, yes :p
04:51:36 <Akii> :P
04:51:47 <Ariakenom> merijn: where in the calendar? and can't you be polymorphic enough?
04:51:50 <kernel-sanders> lol yeah that's more like it
04:52:00 <merijn> Ariakenom: Not all appointments in my calendar are in the same timezone
04:52:09 <dminuoso> Akii: Its wonderful to experience "it type checks and it works (almost) right" every time.
04:52:16 <merijn> Ariakenom: So the "list of upcoming appointments" contains elements in multiple timezones
04:52:37 <Akii> dminuoso yeah but also if I have only IO functions or in this case one gigantic Maybe monad
04:52:54 <Akii> just few days ago I did some heavy IO stuff and email parsing
04:52:58 <Akii> worked first try
04:53:02 <Akii> just blows my mind
04:53:38 <Ariakenom> Akii: what are you used to writing?
04:53:50 <Akii> all the things, been doing Haskell for years now though
04:53:52 <merijn> Ariakenom: Concrete example, the end of my internship I was already back home working remote, so all my work appointments/conference call meetings where scheduled in PST, while all my other appointments were in CEST
04:54:01 <Akii> never had this much awesomeness with it though
04:54:27 <Ariakenom> merijn: makes sense
04:55:00 * Ariakenom is writing python with 30 min feedback cycle
04:55:05 <Akii> sorry for this but I need the exact equivalent for Haskell of what this Python (again, sorry) code does `random.getrandbits(64)`, one example being 14023583288163714864
04:55:19 <Akii> I'm integrating with an undocumented API and I just know this works 
04:55:34 <merijn> Akii: randomIO :: IO Int64? ;)
04:55:41 <Akii> okay, fair enough
04:55:44 <merijn> Akii: How random does it have to be?
04:55:45 <Akii> thank you!
04:55:50 <Akii> I don't think it matters
04:55:54 <Akii> it's more about the format
04:56:07 <Solonarv> or if you want it unsigned, use Word64 instead of Int64
04:56:09 <dminuoso> Akii: The format?
04:56:15 <merijn> Akii: It's just that randomIO isn't cryptographically secure :)
04:56:21 <Akii> merijn that's ok
04:56:26 <Akii> nothing serious here
04:56:33 <Akii> dminuoso yea the length of the number I guess
04:56:59 <dminuoso> merijn: Realistically, what is short of QRNG done on some PCI/USB device running quantum experiments?
04:57:50 <Solonarv> you can incorporate things like keystroke timings or noise in audio input pretty easily
04:58:00 <Solonarv> if the system you're running on has those, of course
04:58:08 <merijn> dminuoso: You don't need that level of randomness, but you want your PRNG to follow certain properties (i.e. a CSPRNG) rather than any random PRNG
04:58:28 <tsahyt> merijn: and sometimes you don't care at all, as long as it looks random
04:58:45 <dminuoso> tsahyt: "it looks random" is very subjective.
04:58:45 <tsahyt> random-ish number generation
04:58:51 <merijn> tsahyt: Sure, but it's important to know what you need :)
04:58:58 <dminuoso> tsahyt: MT for example looks very random until you start graphing large amounts of it.
04:59:12 <dminuoso> And then it looks very non-random suddenly.
04:59:17 <tsahyt> agreed. my gripe with StdGen for example is usually the opposite. it does more than I need and ends up being too slow as a result
04:59:23 <merijn> dminuoso: There are many PRNGs that are good for simulations/monte carlo, etc. that are "too predictable" to be used in crypto applications
04:59:25 <tsahyt> then again I always find myself in strange usecases
04:59:33 <merijn> tdammers: mwc-random is pretty damn fast
05:00:02 <merijn> eh
05:00:04 <tsahyt> merijn: usually I resorted to a xorshift implementation in that case, which is crazy fast
05:00:07 <merijn> s/tdammers/tsahyt
05:01:31 <tsahyt> it's hard to beat 3 xors and 3 shifts, but it's of course not suited for cryptographical applications.
05:01:47 <tsahyt> my usecases for it are generally some type of monte carlo algorithm where I just need to spit out samples as quickly as possible
05:02:08 <merijn> tsahyt: mwc-random uses a multiply with carry, which should be about as fast as you can get
05:02:34 <tsahyt> hm.. I believe I tried it once and had some issue
05:02:50 <tsahyt> I'll keep it in mind for when I need a fast PRNG again
05:06:47 * hackage accelerate-examples 1.2.0.1 - Examples using the Accelerate library  https://hackage.haskell.org/package/accelerate-examples-1.2.0.1 (TrevorMcDonell)
05:10:50 <Ariakenom> dminuoso: realistically /dev/random is cryptographically secure
05:12:08 <Solonarv> on a desktop system, certainly
05:12:31 <Solonarv> perhaps not so much on a peripheral-starved server or something
05:13:59 <vamsi> Why does template haskell's lookupTypeName function fails for tuples. lookupTypeName "(,)" returns a Nothing.
05:14:29 <tsahyt> Solonarv: at least on linux, the intent of /dev/random is to be cryptographically secure afaik. you might just run out of randomness if you can't gather enough entropy
05:14:34 <Solonarv> tuples are handled a bit weirdly/specially
05:14:59 <Solonarv> tsahyt: I get it confused with /dev/urandom tbh
05:15:26 <tsahyt> Solonarv: /dev/random may block, /dev/urandom doesn't
05:15:40 <Solonarv> if it simply blocks when you run out of entropy that's secure, but not necessarily usable if you need more randomness than /dev/ provides
05:15:48 <tsahyt> yep
05:16:11 <tsahyt> hence why some applications will ask the user to erratically move the mouse around while they generate keypairs
05:16:22 <Solonarv> ah yeah, I remember that
05:17:05 <tsahyt> also if you have a hardware RNG in your server, /dev/random uses it as an entropy source afaik
05:17:19 <tsahyt> again, on Linux. implementations differ across operating systems.
05:31:47 * hackage accelerate-blas 0.2.0.1 - Numeric Linear Algebra in Accelerate  https://hackage.haskell.org/package/accelerate-blas-0.2.0.1 (TrevorMcDonell)
05:35:54 <fen> there is a Singletons version of Free?
05:36:29 <fen> https://pastebin.com/raw/QuXqQHTK
05:36:46 <fen> F f a = F (F a) | f a
05:37:37 <fen> then you make `f' a Singleton and give F (or Free) a type level list to specify the case of `f' at each level
05:37:54 <fen> which stops F f a being isomorphic to simply (Nat,f a)
05:38:40 <fen> so if we first write this Singletons version of Free, then it should be easy to convert it to revcover the Singletons F implementation desired
05:48:00 <Ariakenom> Solonarv, tsahyt: I like https://www.2uo.de/myths-about-urandom
05:50:21 <Ariakenom> the "quality" of urandom v random only matters if you're using "true encryption", ex one time pads, instead of the usual "cryptographically secure"
05:50:32 <merijn> There is no quality difference
05:50:42 <merijn> It's also not cryptographically relevant
05:50:47 * hackage purebred-email 0.1.0.1 - types and parser for email messages (including MIME)  https://hackage.haskell.org/package/purebred-email-0.1.0.1 (frasertweedale)
05:51:03 <merijn> Ariakenom: https://www.2uo.de/myths-about-urandom
05:51:18 <Ariakenom> oh wait i got them confused :D
05:51:33 <Ariakenom> but I didn't say either way so nevermind
05:52:10 <Ariakenom> merijn: I linked that 1 minute ago :)
05:53:06 <merijn> Ariakenom: Ah, I was DCed for a bit :)
05:53:23 <Ariakenom> oh right sry. missed that
05:54:20 <Ariakenom> the one pitfall is that urandom should block on startup but doesn't
05:54:35 <merijn> Ariakenom: *on linux*
05:55:13 <Ariakenom> yes
06:02:47 * hackage alarmclock 0.7.0.1 - Wake up and perform an action at a certain time.  https://hackage.haskell.org/package/alarmclock-0.7.0.1 (dcturner)
06:12:47 * hackage hpqtypes-extras 1.8.0.0 - Extra utilities for hpqtypes library  https://hackage.haskell.org/package/hpqtypes-extras-1.8.0.0 (MikhailGlushenkov)
06:30:17 * hackage http-conduit 2.3.7.1 - HTTP client package with conduit interface and HTTPS support.  https://hackage.haskell.org/package/http-conduit-2.3.7.1 (MichaelSnoyman)
06:35:06 <spion_> Can two type classes have overlapping function names in their definitions and still end up working?
06:37:06 <c_wraith> if they're defined in different modules and you make sure to import them in ways that keep them unambiguous at their use sites
06:37:47 <spion_> i see, so a qualified import ought to do the trick
06:37:51 <Solonarv> indeed
06:38:50 <Solonarv> note that you don't need to qualify names of identifiers you're defining in an instance
06:39:37 <Solonarv> meaning there is no need to write 'instance Qualified.Class where Qualified.member = ...'; instead you can write 'instance Qualified.Class where member = ...'
06:39:53 <spion_> ah yeah.
06:40:04 <spion_> I was thinking, thats another cool way that typeclasses are nicer than OOP interfaces
06:41:36 <spion_> (if two interfaces happen to have a method with the same name that would often cause a problem in most languages)
06:42:47 <Solonarv> yup
06:43:07 <Solonarv> not in Rust, though (then again its traits are kinda close to Haskell's type classes already)
06:43:14 <c_wraith> There are advantages to name resolution not being dependent on values.
06:43:27 <c_wraith> or even types
06:47:07 <Cale> Solonarv: Not only *can* you write that, but it is a syntax error to qualify names in instance declarations.
06:47:25 <Solonarv> oh, didn't know that
06:47:28 <Solonarv> makes sense though
06:48:17 <Cale> I found it slightly surprising at one point, but yeah.
06:48:47 * hackage th-lift-instances 0.1.13 - Lift instances for template-haskell for common data types.  https://hackage.haskell.org/package/th-lift-instances-0.1.13 (BennoFuenfstueck)
06:58:11 <c50a326> https://gist.github.com/m1574b34r/e0c5d8c410cb1b27e13fd3fe38e8ae89 the testFunc at the bottom of this gist seems to go into some infinite loop or something?
06:59:01 <c50a326> ah do I need to account for EOF or \0 or something?!
07:05:53 <Putonlalla> It appears your parser may accept multiple lines that are not separated by `\n`, c50a326.
07:06:34 <Putonlalla> It also appears that your parser may accept an empty line.
07:06:51 <Solonarv> yes
07:06:59 <Putonlalla> These two together mean you can parse an infinite number of empty lines from `""`.
07:07:11 <Solonarv> in fact your parser is just many (many whatever)
07:07:55 <Solonarv> you need to make the parser actually require line endings somewhere
07:08:27 <c_wraith> this is why I like parser libraries that don't require me to think so much :)
07:08:31 <delYsid`> yeah, looks like this is missing a sepBy or something
07:11:04 <delYsid`> c50a326: I think what you might be missing is that notChar doesn't *consume* the newline.  You need match the separator somehow, otherwise the many (which accepts an empty list as well) will never stop trying to  match empty lines
07:11:29 <Putonlalla> It's important that we repeat the same answer multiple times.
07:12:07 <delYsid`> oh, didnt read scrollback.
07:13:03 <lyxia> The Applicative docs say "as a consequence of [the Applicative] laws, the Functor instance for f will satisfy: fmap f x = pure f <*> x", that seems to rely on parametricity, or am I missing some other way of deducing that fact? https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Applicative.html#t:Applicative
07:14:44 <c_wraith> lyxia: didn't someone ask this on reddit in the last couple weeks?
07:14:46 <Putonlalla> That was the conclusion of the previous discussion on this, lyxia.
07:14:51 <Solonarv> lyxia: looks like it
07:16:25 <Solonarv> handwavy sketch of the proof:
07:16:25 <Solonarv> 'f = \f v -> pure f <*> v' has the same type as fmap
07:16:25 <Solonarv> f id = id, because pure id <*> v = v
07:16:25 <Solonarv> therefore f is a valid implementation of fmap
07:16:25 <Solonarv> therefore f = fmap because fmap is unique
07:16:49 <Putonlalla> I do think that the laws in the documentation are stated in a really confusing way. Trying to teach from them has shown this too.
07:17:47 <Solonarv> paramatricity is why we only need to prove fmap id = id and not also fmap (f . g) = fmap f . fmap g
07:19:34 <Solonarv> lyxia: so parametricity is involved but (AIUI) not directly
07:20:03 <Cale> Applicative is fundamentally a little bit weird, because we're not all that used to dealing with things of type f (a -> b) individually. Even when you *are* using Applicative, it's more typical to use a pattern like f <$> x <*> y <*> z without thinking about (f <$> x) individually.
07:20:39 <stepcut> I'd like to test my app against various error conditions like running out of disk space, etc. And I'd like the tests to work on linux/os x/windows -- so I can't just mount a tmpfs and call it a day. Is there some sort of library on hackage that implements a fake Handle or something to simulate these errors?
07:21:05 <Putonlalla> On this note, proving `fmap id m = id m` and `(fmap g . fmap h) m = fmap (g . h) m` from `Traversable` laws without using parametricity is quite a tricky exercise.
07:21:37 <Putonlalla> (It takes about 200 lines in natural deduction style.)
07:23:05 <Solonarv> Cale: earlier we were talking about how "an Applicative is just a monoid in the category of endofunctors with Day convolution as the tensor product"
07:23:47 * hackage stm-lifted 2.5.0.0 - Software Transactional Memory lifted to MonadIO  https://hackage.haskell.org/package/stm-lifted-2.5.0.0 (MaksymilianOwsianny)
07:24:06 <dmwit> fmap id = runIdentity . traverse (Identity . id) = runIdentity . traverse Identity = runIdentity . Identity = id -- first one seems easy enough
07:26:44 <Cale> Solonarv: I prefer just thinking of it as a monoidal functor (with respect to the (,)/() monoid structure)
07:26:46 <lyxia> c_wraith, Putonlalla: it was certainly in previous discussions, but I don't remember them at all :)
07:27:01 <Cale> (monoidal category structure, I should say)
07:27:02 <Solonarv> Cale: yes, it's that too :>
07:27:32 <Cale> In that description, you don't need to work with functors applied to exponentials
07:28:11 <Solonarv> it's also a monoid in the category of endofunctors with Data.Functor.Product.Product as the tensor product (the identity is Const (), not Identity)
07:28:21 <lyxia> Solonarv: Thanks, that's also what I was thinking :)
07:28:32 <Solonarv> again no exponentials needed
07:29:00 <Solonarv> I don't think Applicative really clicked me until I stopped staring at <*> so hard and turned to liftA2 instead
07:32:41 <dmwit> The composition one seems harder. =P
07:32:50 <Putonlalla> Do you want a hint, dmwit?
07:33:09 <dmwit> Nah. I've seen the parametricity argument that fmap id = id is enough, presumably it can be reused directly.
07:34:15 <dmwit> I guess I want a hint if that's not true. =)
07:35:23 <Putonlalla> You need to rewrite with the "applicative transformation" hypothesis applied to `Compose . Identity`.
07:37:00 <Putonlalla> The hypothesis should be `forall {f :: Type -> Type} {tf :: Traversable f} {g :: Type -> Type} {ag :: Applicative g} {h :: Type -> Type} {ah :: Applicative h} (t :: forall {a :: Type}, g a -> h a), (forall {a :: Type} (x :: a), t (pure x) = pure x) -> (forall {a b :: Type} (m :: g (a -> b)) (n :: g a), t (m <*> n) = t m <*> t n) -> forall (m :: a -> g b) (n :: f a), (t . traverse m) n = traverse (t . m) n` if I'm not mistaken.
07:58:18 * hackage byteslice 0.1.0.0 - Slicing ByteArray and MutableByteArray  https://hackage.haskell.org/package/byteslice-0.1.0.0 (andrewthad)
08:06:50 <adamCS> PVP question:  What level of version change is required if I remove a required constraint (backward compatible! The extra constraint won't do any harm!) but also remove the export of the constraint type, so now I've broken any code that relied on my export to add the constraint when using my code?
08:09:50 <lyxia> adamCS: removing an export is breaking. Changing the version of your dependencies is not (if upgrading a dependency is breaking, then that should be reflected in the version of the dependency)
08:10:56 <adamCS> Right.  So a package that removes an export should bump at least "B" of A.B.C.D ?
08:12:02 <lyxia> yeah
08:13:39 <adamCS> I'm new to adding packages and I want to get dependencies right.  So I've been upper bounding at < A.(B+1).0.0 where my current version is A.B.*.*.  But that just bit me.  Because something just removed an export but only bumped C. 
08:15:00 <adamCS> Anyway, thanks for clarifying.
08:15:56 <lyxia> :)
08:46:25 <Boarders> does anyone know any good resources if one wants to better learn the internals of GHC
08:46:32 <Boarders> like is there a reading list of papers or something similar?
08:46:51 <sclv> the ghc dev wiki has a listing
08:48:06 <sclv> looking for it now, sec
08:48:25 <Boarders> looks like: https://gitlab.haskell.org/ghc/ghc/wikis/reading-list
08:48:28 <Boarders> thanks for the tip
08:49:04 <sclv> yeah, beat me to it :-)
08:49:30 <tsahyt> what was the extension that let you write do blocks without () again
08:49:34 <tsahyt> I think it landed rather recently
08:52:44 <Taneb> tsahyt: BlockArguments?
08:53:00 <tsahyt> yes that was it, thanks!
08:56:45 <Taneb> :)
08:58:12 <cdupont> Hi guys
08:58:27 <cdupont> been scratching my head on a small problem :)
08:58:33 <cdupont> I run:
08:58:35 <cdupont> foo <- C.try $ throwError err404
08:58:35 <cdupont> case foo of 
08:58:35 <cdupont>   Left (e :: ServantErr) -> liftIO $ putStrLn "errored"
08:58:35 <cdupont>   Right ds -> liftIO $ putStrLn "not errored"
08:58:51 <cdupont> My monad is ExceptT ServantErr IO a
08:59:05 <cdupont> However I see none of the two messages
08:59:12 <cdupont> despite the try
08:59:47 <cdupont> It seems the try doesn't catch the exception??
09:00:00 <lyxia> C.try doesn't catch exceptions thrown with throwError
09:00:29 <cdupont> It's Control.Monad.Catch.try
09:01:49 <cdupont> lyxia: which one should I use?
09:02:44 <lyxia> throwError is paired with catchError, and there is no tryError though you can define it. But now I'm being puzzled at the fact that you get neither of the messages.
09:04:02 <cdupont> Yeah I use "try" everywhere in my code with this monad, so I'm surprised it doesn't work now
09:04:10 <cdupont> probably some stupid mistake!!
09:05:22 <cdupont> BTW, if I use try or throwError in the wrong monad stack, it should just not compile??
09:06:08 <lyxia> The problem is they're both fine to use here.
09:06:13 <Cale> Sure, though those things are polymorphic, so using them in a differen monad might mean that they mean something different.
09:07:27 <Cale> I don't know which module C is, but assuming it's Control.Monad.Except
09:07:41 <Cale> there's an instance MonadError IOException IO
09:07:55 <cdupont> No C is Control.Monad.Catch
09:08:08 <Cale> as well as Monad m => MonadError e (ExceptT e m)
09:08:10 <Cale> ah, okay
09:09:58 <Cale> In that case, it catches exceptions proper as available from the IO monad, not the fake exceptions that ExceptT provides
09:10:02 <cdupont> I see ExceptT has instances for both MonadCatch and MonadThrow
09:10:55 <cdupont> try :: (MonadCatch m, Exception e) => m a -> m (Either e a) 
09:11:19 <Cale> The terminology is somewhat unfortunate here.
09:11:47 * hackage cryptol 2.7.0 - Cryptol: The Language of Cryptography  https://hackage.haskell.org/package/cryptol-2.7.0 (AaronTomb)
09:12:11 <Cale> ExceptT provides an arbitrary monad with something that behaves like exceptions, but are not properly the sort of exceptions that MonadCatch is trying to deal with
09:12:31 <Cale> You can detect this in the type signature because  catch :: Exception e => m a -> (e -> m a) -> m a
09:12:45 <Cale> is too polymorphic to deal with anything too particular to m
09:13:22 <Cale> It catches something arbitrary of some type e which is an instance of Exception, which makes it at least somewhat apparent that this is IO's exception mechanism at work
09:13:52 <Cale> (or, well, the exception mechanism that's shared by IO and STM)
09:14:19 <Cale> instance MonadCatch m => MonadCatch (ExceptT e m) where
09:14:19 <Cale>   catch (ExceptT m) f = ExceptT $ catch m (runExceptT . f)
09:14:36 <cdupont> So, how to throw something in ExceptT, and catch it (with try)?
09:16:19 <Cale> ExceptT provides catchError, you could write a try in terms of that, but I don't know if there's one in the library anywhere
09:17:33 <Cale> It would just be  try x = catchError (fmap Right x) (\e -> return (Left e))
09:19:12 <Cale> Alternately, depending on whether your monad was already an instance of MonadThrow/MonadCatch, you might not need to use ExceptT at all
09:19:55 <Cale> You could use MonadCatch's try, and use throwM to throw your exceptions
09:20:35 <Cale> (which is just throwIO, lifted to whichever monad)
09:27:07 <zincy_> Cale: "Remind me to tell you about folds of trees sometime"
09:27:31 <zincy_> So tree folds
09:29:59 <Cale> zincy_: ah, sure, though I have a meeting I need to attend in about one minute :)
09:30:06 <Cale> (Should be short)
09:30:09 <zincy_> :) no problem
09:30:15 <zincy_> just ping me when free
09:32:17 * hackage knit-haskell 0.2.0.0 - a minimal Rmarkdown sort-of-thing for haskell, by way of Pandoc  https://hackage.haskell.org/package/knit-haskell-0.2.0.0 (adamCS)
09:45:02 <Cale> zincy_: Seems like it's delayed, so I'll try to explain...
09:45:18 <zincy> Sure
09:45:49 <Cale> zincy_: The basic idea is that the key thing which foldr f z is doing is replacing each of the (:) constructors in a list with f, and the [] at the end (if any) with z
09:46:29 <Cale> So, we can do this with arbitrary data types as well, defining a function which will substitute all the data constructors in our type for other functions or values as appropriate
09:46:55 <Cale> For example, if we have a binary tree datatype like:
09:47:03 <Cale> data Tree a = Tip | Branch a (Tree a) (Tree a)
09:47:13 <Cale> We might want a function:
09:47:23 <Cale> foldTree tip branch = f
09:47:25 <Cale>   where
09:47:30 <Cale>     f Tip = tip
09:47:41 <Cale>     f (Branch x l r) = branch x (f l) (f r)
09:49:14 <Cale> Once we have that, we can define many useful functions on trees, such as functions that compute the depth or size of a tree, or enumerate its elements into a list in various ways
09:49:50 <zincy> Is tip the empty node?
09:49:58 <Cale> The empty tree, yeah
09:50:27 <zincy> The function (+1) applied to foldTree is depth right?
09:50:48 <zincy> Is there a way of getting height apart from using max depth
09:50:58 <Cale> depth = foldTree 0 (\x l r -> 1 + max l r)
09:52:06 <Cale> size = foldTree 0 (\x l r -> 1 + l + r)
09:52:10 <zincy> The algo for checking if a tree is balanced confuses me
09:52:28 <zincy> it is basically the depth between subtrees of each node cannot differ by 1 right?
09:52:33 <zincy> sorry more than 1
09:52:50 <Cale> Usually if you care about balance, you need to include additional data in the branches to help compute it
09:53:45 <zincy> What do you mean by care about balance?
09:54:08 <zincy> If you have the definition of balanced according to the height balanced definition you don't need any extra info no?
09:54:28 <Cale> I mean, if you're going to be trying to maintain balance as you're adding and removing things from the tree
09:54:50 <Cale> But you can determine if the tree *is* balanced without needing to do that, sure
10:06:42 <zincy> Yeah the essential property of AVL trees is that they self-balance right
10:07:53 <[exa]> zincy: yeah, or at least that's the direct outcome of their essential subtree height property
10:16:15 <Cale> zincy: (had that meeting)
10:16:32 <Cale> zincy: So, one thing we could also do is to write an in-order traversal of the tree:
10:16:47 <Cale> inorder = foldTree [] (\x l r -> l ++ [x] ++ r)
10:17:15 <Cale> But this has the downside that computing xs ++ ys takes O(length xs) steps
10:18:28 <phadej> foldTree id (\x l r -> l . (x : ) . r) []
10:18:49 <Cale> So yeah, we can write
10:19:17 <Cale> well, what phadej wrote, except that it needs the tree argument :)
10:19:37 <phadej> true, my bad
10:19:59 <Cale> The idea being that instead of concatenating lists, we'll compose functions that add elements to the beginning of any list they receive
10:20:21 <Cale> Since function composition is O(1), this turns a quadratic worst case into a linear one
10:20:58 <Cale> We can then apply the resulting function to an empty list to recover the list we wanted originally
10:21:19 <Solonarv> What a tangent ;)
10:21:38 <Cale> I like this tangent :)
10:22:00 <Cale> It's a nice (and important) trick to learn about
10:22:59 <Solonarv> personally I'd prefer writing foldMapTree / traverseTree which let us skip the list entirely if we want to
10:23:48 * hackage vector 0.12.0.3 - Efficient Arrays  https://hackage.haskell.org/package/vector-0.12.0.3 (CarterSchonwald)
10:24:44 <Cale> zincy: Is that all clear? The idea is that we can replace lists of type [a] with functions of type [a] -> [a] which add whatever elements our list would have had to any list they're given.
10:24:46 <Cale> So the empty list [] becomes the identity function id
10:24:59 <Cale> The singleton list [x] becomes the function (x:)
10:25:17 <Cale> and concatenation (++) becomes composition (.)
10:25:44 <zincy> Oh just reading up 
10:26:00 <zincy> I have a meeting now for a bit but will respond soon
10:27:07 <zincy> So your inorder traversal takes O(N) steps for each node>
10:27:18 <zincy> so for a 5 node tree 5N?
10:27:55 <Cale> Sort of -- it costs the size of the left subtrees
10:28:07 <Cale> So add up the sizes of all the left subtrees throughout the tree
10:29:07 <Cale> right? Because xs ++ ys takes O(length xs) steps:
10:29:11 <Cale> [] ++ ys = ys
10:29:19 <Cale> (x:xs) ++ ys = x : (xs ++ ys)
10:31:15 <zincy> meeting cancelled
10:31:19 <zincy> so ...
10:35:01 <zincy> Cale: yeah that makes sense
10:38:17 * hackage cyclotomic 1.0 - A subfield of the complex numbers for exact calculation.  https://hackage.haskell.org/package/cyclotomic-1.0 (ScottWalck)
10:46:15 <cdupont> Cale: sorry I had to go out
10:46:19 <cdupont> let me try that
10:50:00 <w1n5t0n> does anyone know what package I need to add to my dependencies in order to be able to use the Data.Global package? 
10:50:24 <w1n5t0n> I tried searching for it on hoogle but it doesn't come up, it just says "not on stackage"
10:50:44 <alp> googling "hackage Data.Global" does the trick: https://hackage.haskell.org/package/safe-globals-0.1.1/docs/Data-Global.html
10:51:04 <phadej> google is your friend: https://www.google.com/search?q=Data.Global+hackage&oq=Data.Global+hackage
10:51:08 <phadej> alp: +1
10:51:29 <w1n5t0n> thanks both, learned a lesson today!
10:57:41 <w1n5t0n> another question: say I have a top-level variable of type `a` that contains a series/list of `b`s, and I have multiple threads each reading their respective `b` at fixed intervals and doing some IO. Occassionally I replace the top-level `a` with a new version, but I don't want to interrupt or otherwise mess with a thread that's otherwise running. Is an MVar the right way to store the `a`?
10:58:39 <merijn> w1n5t0n: Do you care about updates blocking?
10:59:10 <w1n5t0n> I care about the threads never being blocked, as their regular and timely execution is important
10:59:23 <merijn> w1n5t0n: Then MVar's are probably out anyway
10:59:55 <merijn> w1n5t0n: And you just wanna replace the current list with a new one that another thread will pick up later?
11:00:26 <ClaudiusMaximus> if it's acceptable to fail to read an update (in which case the thread has its own logic to use an older value) then tryReadMVar may be an option?
11:00:43 <merijn> Or just an IORef if you just wanna swap a value occasionally
11:02:18 <w1n5t0n> merijn: I'm using an IORef at the moment, but I'm getting some glitches (this is in an audio context) when I replace an old `a` with a new one, so I was thinking that the function that does the updating should use an MVar to block until all threads have finished doing their thing with the old version
11:02:29 <catern> super basic question: what exactly is the right term for a type-level function that can accept type-level functions as an argument?
11:02:53 <catern> is that a... rank-N type? higher-kinded types? higher-order kind? something?
11:03:39 <ClaudiusMaximus> w1n5t0n: my guess is too much lazyness? the IORef stores a computation (thunk) that calculates an `a` instead of a fully evaluated `a`?  or GC pauses?
11:04:47 <w1n5t0n> ClaudiusMaximus: perhaps, but I'm using modifyIORef' which I thought was the strict version
11:05:29 <w1n5t0n> either way, these glitches happen some times and not others, which makes me think that it's something to do with the timing between me updating the stored list and threads being in the middle of using the old one
11:05:50 <ClaudiusMaximus> it's strict to WHNF (weak head normal form), basically the outermost constructor only
11:06:06 <[exa]> catern: I'd go with higher-kinded type constructor (function) or something, but AFAIK the thing isn't really that special (eg all transformers are like that)
11:06:44 <ClaudiusMaximus> w1n5t0n: https://hackage.haskell.org/package/deepseq may help, or using a stricter data type
11:07:24 <ClaudiusMaximus> w1n5t0n: particularly the bit about "ensure pending work does not migrate to the wrong thread"
11:07:45 <catern> [exa]: well, I'm trying to contrast it to the generics that are in a lot of languages, which are type-level functions that can only accept, uh, atomic types or something I guess?
11:07:51 <catern> I guess I also don't know what to call those
11:08:55 <w1n5t0n> ClaudiusMaximus: thanks, that looks like the right direction
11:08:58 <Cale> catern: "Higher kinded type"
11:09:31 <monochrom> Sapir-Worf-Orwell scores again.
11:10:13 <Cale> Oh, sorry, I was replying to your first question
11:11:27 <w1n5t0n> and one last question: does forking a function by `forkIO` introduce any chance that its execution may be delayed? So if I press a button and have it execute `f::IO ()` and `void . forkIO f`, will the latter execute just as promptly as the former?
11:11:43 <Cale> You mean types of kind * or * -> * or * -> * -> *, etc? I suppose we could call those "first-order kinds"
11:11:57 <Cale> and so, "types of first order kind"
11:12:06 <c_wraith> no guarantees about timeliness of execution of *any* thread once concurrency is involved.
11:13:19 <Cale> Practically speaking, it's not typically going to take very long to start running the threads forked with forkIO, but yeah, hard to specify any actual guarantee.
11:13:24 <monochrom> 1. Clearly forkIO involves more overhead, even if the new thread is giving utmost priority.
11:13:46 <monochrom> 2. Clearly if a human pressing a button and waiting for a response is involved, the human will not notice.
11:14:02 <catern> Cale: The thing I'm confused about is I sometimes see people say languages with generics, like e.g. Java, don't have higher-kinded types. but such language do have both * and * -> * types
11:14:05 <[exa]> catern: there's no problem with eg. templates in C++ accepting other templates, if you put it that way
11:14:40 <Cale> [exa]: Oh, in which C++ did that start to become the case?
11:15:09 <catern> [exa]: wow, I had no idea, but I guess then I don't include C++ when I'm talking about "languages with generics"
11:15:23 <c_wraith> catern, yes, that'd poor phrasing. I don't know why people say things like that. accurate phrasing would be "don't allow abstracting over higher-kinded types"
11:15:28 <w1n5t0n> monochrom: thanks, that helps exclude the `forkIO` as the source of the substantial, human-perceptible delay
11:15:35 <monochrom> Don't worry, people don't speak of "C++ generics" anyway :)
11:16:13 <[exa]> catern: well you don't want generic stuff when programming assembly :]
11:16:21 <Cale> w1n5t0n: Yeah, if you're doing a single forkIO, it would be weird to have a noticeable delay
11:16:34 <catern> c_wraith: I see, but someone would still be able to pick up from context what I mean if I say "Java doesn't have higher-kinded types"? or would it still be better to say "Java doesn't have abstraction over higher-kinded types"?
11:16:39 <Cale> w1n5t0n: If you already have hundreds of thousands of threads, then... maybe?
11:17:13 <catern> I think I get it now though, it's just people being approximate
11:17:18 <monochrom> It has always been "template" because it was a blind macro expansion system.  Java generics is actually Phil Wadler adding "forall a of kind *" very consciously, not a blind macro expansion.
11:17:30 <Cale> catern: * -> * -> * isn't a higher-kinded type
11:17:43 <c_wraith> catern, most people would understand from context. I tend to use the phrasing "doesn't have higher-kinded abstraction"
11:18:05 <catern> Cale: I mean (* -> *) -> * - that's a higher-kinded type right?
11:18:10 <Cale> that is, yes
11:18:20 <Cale> or, that's a higher-order kind
11:18:35 <Cale> I misspoke before as well :)
11:18:48 <monochrom> It is both :)
11:19:36 <[exa]> Cale: you anyway about c++, you can do something awful like template<template<typename> typename T>, so that T is expacted to be a template
11:20:49 <[exa]> ...which is a really ugly way to put (*->*)->*, right.
11:21:44 <Cale> [exa]: I'm not sure whether that sort of thing was possible back when I did some C++, but that was a very long time ago now, and templates were still fairly new.
11:21:50 <catern> monochrom: would it be also correct to say it's a higher-order type?
11:22:06 <catern> uh, guess I mean to address that to Cale
11:22:16 <monochrom> But it is a kind, not a type.
11:22:30 <catern> ah I see, okay, makes sense
11:22:34 <Cale> catern: Yeah, it wasn't meant to be a type in the first place. :)
11:22:51 <[exa]> Cale: I thought it's there even before c++11 but not sure, gonna search for it
11:23:40 <catern> ok, so "higher-kinded type" is just confusing shorthand for "higher-order kind"?
11:23:56 <catern> "higher-kinded type" doesn't really make sense, right, since type-level functions aren't types?
11:23:56 <Cale> [exa]: Yeah, I was using like C++98 and... whatever the previous version was
11:24:11 <Cale> Type level functions are types
11:24:13 <monochrom> No.  "Maybe" is a higher-kinded type, because its kind is * -> * not simply *
11:24:35 <Cale> Though sometimes when we say "type" we mean "type of kind *"
11:24:50 <Cale> It's a bit of a difficult terminological issue
11:24:58 <[exa]> works even with -std=c++98 in gcc but not sure whether it's strict enough
11:25:04 <monochrom> So it is still true that Java has higher-kinded types, for example List is an example because you use it like List<T>.
11:25:06 <Cale> [exa]: cool
11:25:39 <catern> ok, so is it that a "higher-kinded type" is an instance of a "higher-order kind"?
11:25:48 <[exa]> (the test example, just for completeness: https://pastebin.com/6c5Un86S )
11:25:51 <Cale> catern: yes
11:26:00 <monochrom> But Java doesn't have abstraction over higher-kinded types.  There is no "class Functor f", in which f's kind is * -> *
11:26:08 <Cale> :k Fix
11:26:09 <lambdabot> error:
11:26:10 <lambdabot>     Not in scope: type constructor or class Fix
11:26:13 <Cale> :k Mu
11:26:14 <lambdabot> (* -> *) -> *
11:26:15 <catern> and then, for example, value level functions are higher-order types?
11:26:29 <catern> (if we're being really uniform about the terminology)
11:26:36 <monochrom> I would avoid the word "instance". It's too broad and too bland.
11:26:44 <Cale> value level functions have types of kind *
11:26:46 <monochrom> The kind of Maybe is * -> *
11:26:54 * [exa] feels urge to implement Mu in C++ and laugh.
11:27:00 <Cale> Everything at the value level has a type of kind *
11:27:24 <catern> Cale: sure, but the type of a value-level function is T -> U; which is a higher-order type right?
11:27:33 <Cale> [exa]: and then you can run the compiler and wait forever
11:27:48 <[exa]> yeah, sufficient time for the laugh
11:27:58 <catern> (i'm just trying to drop the terminology of higher-order kind down from the type: kind setting to the value: type setting, to make sure I understand)
11:28:06 <Cale> catern: only if T is a function type
11:28:30 <[exa]> Cale: anyway I remember that I found it in docs quite a lot time ago when I was searching for something for the nested typename qualifier, so it's in c++ at least as long as the typename nesting.
11:29:06 <catern> oh, sorry, yeah, I see now, yes, a value-level function has first-order type, but if it's a function that takes another function, then it has higher-order type. okay, I think I understand all this terminology now :)
11:29:29 <catern> Cale: monochrom: thanks!
11:30:23 <monochrom> At some point I recommend growing out of drawing a line between "higher foo" and "not higher foo".  The dichotomy denies the rich multitude of possible levels and mixtures.  I recommend simply writing down the exact term, or type, or kind, or whatever it is.
11:31:53 <catern> Yeah, like with my original question, I'm just trying to find terminology for referring to what Haskell etc has and Java generics don't
11:32:00 <monochrom> Even in highschool algebra, no one draws a line between "shallow expressions are for example 3 and 3+4", "deep expressions are for example (3+4)*5, ((3+4)*5)+7, etc."
11:32:14 <catern> since the terminology that I'd heard from people was confusing to me
11:33:05 <monochrom> Therefore I just write A->B, (A->B)->C, ((A->B)->C)->D.  I don't draw an arbitrary line and call one side "low"/"shallow", the other side "high"/"deep".
11:33:22 <[exa]> second-higher-level-kinded-type-function!
11:33:51 <monochrom> Especially since the word "high" still fails to recognize the big difference between (A->B)->C and ((A->B)->C)->D.
11:33:56 <gentauro> anybody know how I can get slides for this? -> https://conf.researchr.org/event/icfp-2016/hiw-2016-papers-ghc-determinism
11:34:12 <Cale> There are a bunch of definitions of roughly this form...
11:34:17 <gentauro> it's not on the videos for ICFP 2016 :( -> https://www.youtube.com/watch?v=EpifLmPM1L0&list=PLnqUlCo055hV-Yb_88YYUC2ucaBKCWCsa
11:37:48 <Cale> The order of some basic type is 0, and then order(s -> t) = max(1 + order(s), order(t))
11:39:42 <monochrom> I confess that I'm somewhat hypocritic on this matter, because when it comes to computability, I just draw a couple of lines between decidable, undecidable but enumerable, not even enumerable.  As opposed to embracing the whole arithmetic hierarchy. :)
11:40:48 <monochrom> OTOH the whole arithmetic hierarchy hypothesizes imaginary oracles so meh.  But Haskell's rich types and kinds are realizable and realized, not imaginary oracles.
11:41:12 <monochrom> (And furthermore Agda's, Coq's, ...)
11:41:33 <Cale> At some point the restriction becomes an arbitrary one
11:41:52 <Cale> It's like 0, 1, many or something
11:41:58 <monochrom> Yes.
11:42:22 <Cale> For rank, it's interesting that rank-2 types are sometimes singled out
11:42:33 <Cale> because they have better type inference than arbitrary rank types
11:43:55 <Cale> Rank has a very similar definition to order, except that it only cares about how many arrows the foralls are on the left of, rather than how many arrows anything is on the left of :D
11:44:05 <monochrom> But within the computable, my supervisor would point out that there is a rich hierarchy of different time complexities...
11:45:38 <Cale> I've probably mentioned this before, but I don't feel that we really understand the polynomial class very well. Specifically, it is infinitely deep, and all our comprehensible mechanisms for producing polynomial time algorithms seem to result in algorithms with fairly low degree polynomials involved.
11:46:23 <catern> (trolls can count 1-kind, 2-kind, many-kind, lots-kind)
11:47:12 <monochrom> Is the AKS primality algorithm like degree 12?
11:48:07 <Cale> O(log(n)^12) I think
11:48:31 <Cale> well, if n is the number of bits then O(n^12) :)
11:49:04 <Cale> There is a conjecture which would improve the analysis to O(n^6)
11:50:37 <monochrom> Yeah 12 seems to be the highest we've hit so far.
11:50:51 <Cale> and it's all incremental
11:51:29 <Cale> There isn't so much in the way of sensible things one can do which would square the degree
11:51:45 <monochrom> And previously it was 5 for "here is a cute way to check graph planarity: recall that a graph is planar iff it does not contain this subgraph of 5 vertices or that subgraph of 3 vertices..."
11:51:55 <Cale> or go from O(n^a) to O(n^(2^a))
11:53:40 <Cale> P = NP, but the best reduction of an NP-complete problem takes O(n^G) time, where G is Graham's number. ;)
11:53:46 <dmwit> (s/subgraph/graph minor/g)
11:57:11 <Cale> Or O(n^TREE(3)) or pick your favourite fast-growing function :)
11:57:36 <Psybur> @hoogle (a,b) -> c -> (a,b,c)
11:57:36 <lambdabot> Control.Concurrent.Async.Lifted concurrently :: MonadBaseControl IO m => m a -> m b -> m (a, b)
11:57:36 <lambdabot> Control.Concurrent.Async.Lifted.Safe concurrently :: forall m a b . (MonadBaseControl IO m, Forall (Pure m)) => m a -> m b -> m (a, b)
11:57:36 <lambdabot> Yesod.WebSockets concurrently :: MonadBaseControl IO m => m a -> m b -> m (a, b)
11:59:47 <Cale> DigitalKiwi: So, ordinary types with values in them like Integer and such have kind *, and then we have types that take ordinary types as parameters and produce other types, like Maybe which has kind * -> *
12:00:16 <Cale> (also, IO, the type constructor for lists [], and many others)
12:01:01 <Cale> DigitalKiwi: Then we have types such as monad transformers, which take such type-level functions as arguments
12:01:18 <Cale> ReaderT :: * -> (* -> *) -> *
12:01:24 <Cale> :k ReaderT
12:01:25 <lambdabot> * -> (k -> *) -> k -> *
12:01:29 <Cale> oops
12:01:30 <Cale> lol
12:01:38 <Cale> ReaderT :: * -> (* -> *) -> (* -> *)
12:01:42 <Cale> I should have written
12:01:53 <Cale> but then ghci gives me an even more general kind
12:01:54 <Cale> haha
12:02:45 <Cale> It takes a plain type (the type of environment that you're adding), and a monad, and produces another monad, and monads always have kind * -> *
12:02:52 <zincy> What is computable decidability?
12:03:10 <Cale> DigitalKiwi: Does that make sense?
12:03:25 <zincy> Sorry for the distraction :)
12:04:00 <hyperisco> zincy, means you can compute whether something is or is not true
12:04:07 <zincy> Is it fair to say that * -> * is a type level function?
12:04:18 <zincy> Well the kind of one
12:04:32 <zincy> hyperisco: Ah thanks
12:04:32 <Cale> yes
12:04:40 <Welkin> * is Type
12:04:47 <Welkin> * -> * is Type -> Type
12:04:48 <Cale> anything with kind k -> k' for some kinds k and k' is a type level function.
12:04:56 <Welkin> -> is a function constructor
12:05:02 <Cale> Well, you're just renaming * there ;)
12:05:16 <zincy> What does it mean to promote a data constructor to a type constructor?
12:05:16 <Cale> But yeah, we probably could have written it as Type
12:05:23 <hyperisco> zincy, there are some things you can ask which are either true or *shrug*, and others which are just *shrug*
12:05:53 <Cale> (but then that's also a bit confusing, because not all the things which are types, are things of kind Type)
12:06:15 <zincy> Right you could get a kind Bool
12:06:19 <Welkin> BOX?
12:06:41 <Cale> zincy: and you have things of kind * -> * which are types, but not types of kind *
12:06:46 <Cale> Like Maybe
12:07:01 <Welkin> Maybe is a type constructor, not a type
12:07:11 <Solonarv> Welkin: no, BOX is gone since TypeInType
12:07:18 <Solonarv> (approximately)
12:08:24 <wdanilo> Hi guys! I've discovered in stack release notes that stack will drop support for GHCJS. Weve got a pretty big project standing on this technology. Is there any info if GHCJS would stop work completely with new stack?
12:08:50 <[exa]> wdanilo: time to fork!
12:09:09 <Welkin> time to use cabal new-*
12:09:14 <[exa]> +1
12:09:20 <Welkin> potentially with nix if necessary
12:09:26 <Welkin> which is probab;y necessary because ghcjs
12:10:02 <hyperisco> zincy, for example, determining which of two infinite lists is longer is *shrug*
12:10:25 <DigitalKiwi> Cale: kind of :3
12:10:52 <hyperisco> zincy, whereas an element either does occur in an infinite list or *shrug*
12:10:55 <wdanilo> [exa], Welkin, our whole "stack" is on stack now. Using LTSes works amzing for us. I'm talking about a production system where a lot of developers involve into the system developing  in such case, LTSes work like a dream. Of course forking is not a good option for us, switching to cabal without LTS seems risky as well
12:11:11 <hyperisco> zincy, and these questions about finite lists are decidable
12:11:25 <Welkin> wdanilo: new cabal uses nix-style builds
12:11:32 <Welkin> there is no problem whatsoever with dependencies
12:11:35 <Welkin> and no risk
12:11:36 <zincy> hyperisco: So how do you prove that?
12:11:42 <hyperisco> zincy, prove what?
12:11:45 <Welkin> if you need a specific set of dependencies, just use cabal freeze
12:12:13 <zincy> Well generally speaking in the abstract whether a problem is decidable?
12:12:15 <Cale> DigitalKiwi: One practical use for types that are parameterised by something of kind (* -> *) is so that we can plug in something like Const () or Proxy when we'd rather leave parts of the structure blank, or plug in Identity when we want to insist that it be filled in, or Maybe/[] for some other options
12:12:27 <Psybur> @hoogle (a -> b -> (a, b)) -> c -> (a, b, c)
12:12:27 <lambdabot> Data.Text.Internal firstf :: (a -> c) -> Maybe (a, b) -> Maybe (c, b)
12:12:27 <lambdabot> Data.List.Split chop :: ([a] -> (b, [a])) -> [a] -> [b]
12:12:28 <lambdabot> Data.List.Split.Internals chop :: ([a] -> (b, [a])) -> [a] -> [b]
12:12:39 <hyperisco> zincy, you can prove that your decider terminates
12:13:10 <Welkin> Psybur: do that in a private message
12:13:11 <zincy> ah right
12:13:27 <Psybur> Welkin, gotcha
12:13:41 <zincy> Does anyone think compiling to webassembly is preferable to compiling to JS for Haskell front ends?
12:13:43 <Solonarv> wdanilo: cabal new- uses nix-style builds, as already mentioned (no cabal hell); cabal supports freeze files; nix supports all that and more, and IIRC its package sets are largely equivalent to LTS stackage snapshots anyway
12:14:16 <hyperisco> not a good idea for compatibility, but probably a good idea for powah
12:14:16 <Welkin> zincy: absolutely, even if only because ghcjs is a huge pain in the ass
12:14:19 <Solonarv> zincy: certainly, but last I heard there was no production-ready WASM target for GHC
12:14:22 <zincy> Or would the resulting binary be too large to download in a browser since it would include the garbage collector
12:14:32 <zincy> Asterius?
12:14:37 <Welkin> I gave up on haskell in the browser a long time ago. Elm has far surpassed anything available in haskell, so I use that
12:14:38 <Solonarv> yes, that's one of them
12:14:40 <wdanilo> Welkin, Solonarv, ok, so if cabal new- provides such functionality (tbh I was not aware of it), what stack gives above that in terms of 'build security and maintanability" ?
12:14:40 <zincy> Well not production ready
12:14:45 <hyperisco> I doubt the GC would tip it over the edge
12:14:51 <wdanilo> Or there is right now a "motion" to switch to cabal back ?
12:14:53 <Welkin> wdanilo: nothing
12:15:08 <Solonarv> there's another ghc-wasm project but I don't remember what it's called
12:15:10 <sphalerite> Hi folks. I have a newtype that wraps (Map String (Maybe Float)), and want to define a Monoid instance for it. My mappend is essentially `Map.unionWith (liftA2 (+))`, but since I'm working with a newtype I also need to remove the constructor from the two variables and add it back onto the result. Is there a handy way to have that code generated automatically?
12:15:25 <Welkin> stack was always a third party tool
12:15:26 <Solonarv> wdanilo: there seems to be a slow trickle of stack users switching (back) to cabal, yes
12:15:32 <Welkin> cabal is the only offical build tool
12:15:36 <Solonarv> sphalerite: coerce
12:15:38 <Welkin> and cabal new- is now also a package manager
12:15:44 <zincy> I am thinking it would be a cool project to write a front end framework with a virtual dom in Haskell that targets webassembly
12:15:53 <wdanilo> interesting, ill give it a shot, thank you!
12:16:08 <boj> zincy: there are already two i believe
12:16:11 <Solonarv> zincy: everything except the "targets webassembly" part is already provided by reflex
12:16:18 <Cale> sphalerite: Use MonoidalMap (whose name kinda sucks, but eventually it will become Map hopefully)
12:16:39 <sphalerite> Solonarv: that sounds like a bad thing.
12:16:47 <Solonarv> sphalerite: it's safe
12:16:56 <hyperisco> zincy, if small binary is of interest then you might have better results using an EDSL to generate code, rather than translating the Haskell program itself
12:17:09 <Solonarv> it only lets you change between types that are "the same after throwing away newtype wrappers and phantom types", roughly
12:17:22 <Welkin> compile core to wasm, not haskell
12:17:43 <Solonarv> Cale: I don't think the Monoid (Maybe Float) instance does the right thing, if it even exists
12:17:43 <zincy> boj: Do you have names?
12:18:31 <Solonarv> Welkin: most GHC-based Haskell-to-<other backend> compilers leave the frontend largely unchanged already
12:18:35 <zincy> So what are the benefits to targeting WASM over JS for browser apps?
12:18:38 <Cale> Solonarv: Yeah, you'll also want Sum
12:18:48 <hyperisco> you're just never going to get rid of the overhead from porting the entire runtime to wasm, or js
12:18:53 <boj> zincy: https://github.com/tweag/asterius and https://webghc.github.io/ for WASM at least
12:19:05 <zincy> Ah Thanks
12:19:10 <hyperisco> though! if, say, haskell.org hosted the runtime script, browsers could cache this :)
12:19:19 <Cale> sphalerite: you can use coerce from GHC.Coerce to add and remove newtypes
12:19:20 <Solonarv> zincy: smaller binaries, faster binaries, less overhead, and so on
12:19:37 <Cale> er, sorry, Data.Coerce
12:19:44 <Cale> https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.12.0.0/Data-Coerce.html
12:19:50 <zincy> So would it be a worthwhile project a front end which uses say Asterius?
12:20:13 <Welkin> you can translate directly from a low-level AST to another low-level AST instead of trying to emulate a low-level AST in javascript, which gives you no control over anything
12:20:19 <boj> zincy: hard to say, everything is alpha quality right now
12:20:40 <zincy> Is it usable?
12:20:57 <Solonarv> Welkin: GHCJS, webghc and Asterius already keep the "Haskell -> low level AST" translation from GHC
12:21:01 <Welkin> does it blend?
12:21:20 <Solonarv> that's mostly just copied over verbatim (with some tweaks to allow for FFI and the like)
12:21:25 <hyperisco> just keep in mind wasm is bleeding edge stuff, and so you're going to alienate users
12:21:33 <Welkin> no it isn't
12:21:35 <sphalerite> Cale: ah, or to just coerce the whole thing :)
12:21:51 <sphalerite> as in coerce the function
12:21:57 <Welkin> wasm is supported is every major browser
12:21:57 <Welkin> https://caniuse.com/#feat=wasm
12:21:58 <sphalerite> Cale: perfect, thanks!
12:22:02 <Cale> sphalerite: cool
12:22:02 <hyperisco> well instead of playing semantics with "bleeding edge" lets just look at how many browsers support it
12:22:17 <Welkin> hyperisco: all of them
12:22:22 <Solonarv> with ghc 8.6 you can even write:
12:22:22 <Solonarv> deriving (Semigroup, Monoid) via MonoidalMap String (Ap Maybe (Sum Float))
12:22:27 <Welkin> note: IE has been deprecated since 2013
12:22:35 <hyperisco>  yeah, like the world runs on latest versions
12:22:58 <Cale> hyperisco: It's largely true now that the world runs on latest versions
12:23:09 <Welkin> all major browsers have supported wasm for over 2 years now
12:23:10 <Cale> The switchover is *very* short, like the course of a week or 2
12:23:36 <sphalerite> hm, although it does need a type annotation to work
12:23:44 <Solonarv> yeah, it usually does
12:24:19 <Cale> It used to take forever, but now all the major browsers do automatic updates
12:24:20 <Solonarv> sphalerite: the snippet I posted above (starts with 'deriving via') will basically write that instance with the appropriate 'coerce' calls for you
12:24:44 <sphalerite> which leaves the code being bigger and a bit harder to read than just pattern matching and wrapping it myself >.<
12:25:09 <sphalerite> Solonarv: hm, is MonoidalMap included with GHC?
12:25:28 <Solonarv> sphalerite: no, Cale mentioned it earlier
12:25:45 <Solonarv> I don't remember the name of the package its in
12:26:28 <sphalerite> eeh, I'd rather just get on with my program than add dependencies so I can no longer just build it in `nix-shell -p ghc` :)
12:26:38 <sphalerite> thanks for the help though!
12:26:40 <hyperisco> well hope it works out for ya, graphs look alright now in 2019
12:26:50 <hyperisco> I wouldn't be able to use it still
12:27:06 <Solonarv> I think I'd write something like:
12:27:06 <Solonarv> instance Semigroup YourFancyMapType where
12:27:06 <Solonarv>   (<>) = coerce (Map.unionWith @_ @(Maybe Float) (liftA2 (+)))
12:27:46 <Solonarv> sphalerite: ^
12:28:00 <Welkin> I use only the latest features for my browser applications
12:28:04 <Cale> https://caniuse.com/usage-table
12:28:13 <Welkin> if your browser is so old that it doesn't support css grid, sorry, you can't use my app
12:28:17 <Solonarv> need a modern-ish GHC for TypeApplications, without those you'll have to write a full type annotation and that's rather more annoying
12:28:18 <Welkin> upgrade your damn software
12:28:42 <hyperisco> my perspective is slanted because I specifically have to deal with old, old stuff
12:28:47 <sphalerite> Solonarv: ok, I'm unfamiliar with @ as well Is that for making the implicitly passed arguments to the Map type explicit?
12:28:58 <hyperisco> and my thoughts and prayers go out to those still relying on it
12:29:02 <Solonarv> sphalerite: pretty much
12:29:11 <sphalerite> I'm on 8.6.4 or something so that's fine
12:29:26 <hyperisco> like, NaCl is the latest and greatest thing
12:29:27 <sphalerite> Thanks very much for the help! :)
12:29:39 <hyperisco> yes, the deprecated native web thing
12:29:53 <zincy> At what point do you cut off the people on an abacus from using your app?
12:30:25 <hyperisco> that's not how the problem is structured
12:30:36 <hyperisco> but my general sentiment seems to be dated by at least a year, so my bad
12:30:46 <Solonarv> sphalerite: see ghc manual: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-TypeApplications
12:31:05 <zincy> How is the problem structured?
12:31:09 <zincy> And what is the problem?
12:32:10 <Cale> Well, to be fair, 85% of all users isn't *that* high compared to most things
12:32:43 <Cale> (that's how many users are using webassembly-supporting browsers)
12:33:13 <hyperisco> zincy, no problem telling clients you need to meet requirement X. The problem is I have to program for old hardware / software which is then given to the client to use.
12:34:44 <hyperisco> because in some organisations they like to battle test and security vet things, not just update willy-nilly
12:35:29 <Welkin> if you are using unsupported or deprecated software, it's your problem
12:35:39 <Welkin> don't make it everyone elses
12:35:42 <hyperisco> thanks for informing me
12:35:49 <Welkin> I mean that in general
12:35:52 <Welkin> for companies that do it
12:37:03 <hyperisco> there are some game-changers like wasm which make me want updates
12:37:12 <zincy> I would just say no to those clients :P
12:37:23 <hyperisco> but by and large I am also grouchy and prefer not trying to fix things which are not broken
12:37:43 <hyperisco> that isn't how it is structured, there is no one to say that to but ourselves, lol
12:38:21 <zincy> Are the clients forced upon you?
12:38:31 <hyperisco> no
12:38:31 <zincy> This is beginning to sound abusive
12:38:38 <zincy> So why can't you say no?
12:38:47 * hackage esqueleto 3.0.0 - Type-safe EDSL for SQL queries on persistent backends.  https://hackage.haskell.org/package/esqueleto-3.0.0 (parsonsmatt)
12:38:50 <hyperisco> the clients are not choosing the versions of things to run, WE are
12:39:08 <zincy> So you are giving them old things?
12:39:14 <hyperisco> yes
12:39:35 <zincy> Do you have any examples?
12:39:54 <zincy> Like what industry are your clients in, medical devices, avionics?
12:40:15 <hyperisco> digital signage
12:40:28 <Welkin> remember when people used to actually write in that untyped low-level language directly?
12:40:34 <Welkin> Oh yeah, you mean javascript
12:40:50 <Welkin> I hope that doesn't happen
12:40:54 <Welkin> javascript needs to go the way of the dodo
12:41:05 <zincy> Wasm might help Welkin
12:41:07 <Welkin> it will be like cobol
12:41:17 <Welkin> kids will say "what's javascript?"
12:41:24 <hyperisco> yes please I think every majour org has a not-javascript layer on javascript lol
12:41:31 <zincy> Digital signage, as in screens which display things like restaurant names and menus?
12:41:52 <hyperisco> "Back in my day, young grasshopper, we had to deal with both null and undefined!"
12:41:54 <Welkin> zincy: unfortunately, the goal is wasm is not to replace javascript, but to live alongside it
12:42:00 <hyperisco> zincy, yup
12:42:11 <zincy> Yes I know but might there be an accident
12:42:17 <yushyin> https://ro-che.info/ccc/images/language.png
12:42:25 <zincy> hyperisco: So why would you give them old things?
12:42:34 <Welkin> yushyin: yes I was referencing that
12:42:50 <yushyin> Welkin: :D I thougt so.
12:42:57 <yushyin> ht
12:43:47 <hyperisco> zincy, because there are way more important factors, and optimising for those gives us dated software support
12:44:27 <hyperisco> like, I wish every case of JavaScript was just a person and their browser, I really do, but it isn't, not even close
12:44:47 <hyperisco> there is, for example, NodeJS, which isn't showing up in browser stats
12:45:10 <hyperisco> and there are apps built on top of Chrome or some other browser, to deliver a desktop app
12:45:27 <koala_man> and similarly, React Native for mobile
12:46:36 <hyperisco> Not telling you not to go for wasm, please do. I am just sharing the possibility that some devs won't be able to use it :)
12:47:23 <zincy> sure :)
12:47:44 <zincy> So datakinds.
12:47:48 <DigitalKiwi> "just get a different job/pick different clients lol" isn't really helpful even if it's true sometimes
12:47:49 <koala_man> JS is a fascinating language. Like how English is weird with tons of corner cases based on what Latin had, JS is weird with tons of corner cases based on what V8 had
12:47:54 <zincy> What does it mean to have a kind of Bool
12:48:48 <Solonarv> zincy: it means you have a type which equal to 'False or equal to 'True
12:48:49 <zincy> DigitalKiwi: Right because if they could they would right
12:48:55 <hyperisco> Also worth noting, I think, that tech 2-3 years old feels ancient nowadays
12:50:01 <hyperisco> the tech you start a 5 year project with is deprecated by the time you release lol
12:50:04 <DigitalKiwi> windows xp will probably be around forever
12:50:38 <JappleAck> DigitalKiwi: i think not, but ReactOS may be
12:50:51 <JappleAck> i see ReactOS as a replacement for windows xp
12:51:00 <Welkin> that is only true with flavor-of-the-week javascript libraries
12:51:12 <zincy> Solonarv: So is the point of the promotion to make relations between types?
12:51:22 <Welkin> there is erlang software built decades ago still running today
12:51:23 <Welkin> no change
12:51:27 <zincy> So they can be exploited for things like type families
12:51:39 <JappleAck> koala_man: js is just a piece of garbage
12:51:40 <Welkin> you can even update the compiler used with very minor changes to the codebase, if any
12:52:02 <Solonarv> zincy: the point is to create more types which are in smaller "groups"
12:52:26 <zincy> Id prefer JS to Golang
12:52:26 <Solonarv> instead of everything being one big pool of * and ->
12:52:38 <JappleAck> koala_man: and its ecosystem. just run this for a minute (until it fail, and monitor memory usage): node -e 'while (1) {console.log("foo")}'
12:52:42 <Welkin> zincy: you'd prefer green crap instead of brown crap?
12:53:21 <koala_man> JappleAck: preaching to the choir
12:53:54 <hyperisco> JappleAck, I am worried is that going to leak memory =\
12:54:07 <Welkin> if it does your OS will recover it when you kill the process
12:54:13 <JappleAck> hyperisco: exactly, about 2GiB of ram
12:54:16 <Welkin> unless you are on windows, maybe
12:54:20 <JappleAck> hyperisco: and then it fails
12:54:37 <Solonarv> zincy: the benefit to using DataKinds over plain old types for your type-level computation, is the same as the benefit of using types at all for your value-level computation
12:54:47 <JappleAck> with some some error like "heap out of memory"
12:54:50 <hyperisco> let me guess it has to reach the end of the event loop before it can flush the buffer
12:55:13 <Solonarv> with DataKinds you can make your type-level computation total and still remain sensible
12:55:31 <JappleAck> some kiddies told that js can be used for shell-scripting, what the retards
12:55:50 <Welkin> there is a terminal emulator written in javascript running in electron
12:55:51 <hyperisco> so great story there is a memory leak in V8 related to the Error object if you instantiate it in the wrong spot then it is never freed
12:55:53 <sphalerite> so I've implemented a wonderful monoid for my data item, now I want to play around with parallelising folding a bunch of them. Are there any nice pre-made parallel fold functions?
12:56:10 <Solonarv> sphalerite: check out the 'parallel' package
12:56:13 <hyperisco> which I have yet to fully characterise, but it is wholly evident in a heap snapshot so that's great
12:56:32 <zincy> Solonarv: Is total in relation to open vs closed type families
12:56:36 <sphalerite> Solonarv: what a well-chosen name! ;)
12:56:42 <Solonarv> zincy: sort of
12:57:07 <zincy> Solonarv: As in total function vs partial function
12:57:13 <Welkin> as in the cereal
12:57:20 <Welkin> or the multivitamin
12:57:41 <zincy> Welkin: ?
12:57:46 <Solonarv> imagine that we have somehow defined type-level peano numbers, using S and Z for successor and zero
12:57:55 <Solonarv> and now we want to define addition
12:58:17 <zincy> Ok
12:58:40 <Solonarv> we can write:
12:58:40 <Solonarv> type family Add p q where Add Z q = q; Add (S p) q = Add p (S q)
12:59:36 <Solonarv> if we defined S and Z as plain old data types like so: data Z; data S a; then Add :: * -> * -> *
13:00:02 <Solonarv> which means the kind of Add doesn't tell us that we should pass it a peano natural, or that it returns a peano natural
13:00:43 <Solonarv> so you can write silly things like 'Add Int (Maybe String)' and instead of a proper error you just get a stuck type family
13:00:49 <Solonarv> (stuck = can't be reduced further)
13:01:11 <hyperisco> the rewriter's version of type error
13:01:13 <zincy> Oh I see
13:01:26 <Solonarv> if instead we turn on DataKinds and define our numbers using: data Nat = Z | S Nat; then we get Add :: Nat -> Nat -> Nat
13:01:35 <Solonarv> now 'Add Int (Maybe String)' is a kind error
13:01:56 <Solonarv> and GHC will helpfully tell you "hey, you need to pass a Nat to this type family"
13:02:09 <Welkin> why do you even need datakinds for that?
13:02:19 <Welkin> a normal sum type could work too
13:02:40 <Solonarv> Nat is a normal sum type
13:02:47 * hackage generic-env 0.1.0.0 - Generic Environment Generator  https://hackage.haskell.org/package/generic-env-0.1.0.0 (yigitozkavci)
13:02:57 <zincy> So Add is a type level function which takes types and the types of types are kinds. So we group these kinds using promoted data constructors since they are more expressive than can encapsulate multiple types?
13:03:05 <hyperisco> interjection be aware that GADTs don't promote so well
13:03:21 <Solonarv> you need DataKinds in order for Nat's definition to create the 'Z and 'S type constructors
13:03:26 <hyperisco> particularly, constraints do not promote
13:03:29 <Solonarv> zincy: more or less, yes
13:03:48 <hyperisco> is anyone working on kind constraints? would enjoy it
13:03:55 <JappleAck> you need DataKinds to be able to shift value/term-level constructors to type-level
13:04:17 <Solonarv> it brings the capabilities of type-level Haskell closer to the capabilities of term-/value-level Haskell
13:04:42 <Solonarv> JappleAck: no; if you have a Z at runtime there's no way to turn that back into the promoted 'Z constructor
13:05:05 <Solonarv> it doesn't let you move information from the value level to the type level
13:05:26 <JappleAck> Solonarv: unless you use 'singletons'?
13:05:41 <Solonarv> yes, singletons works around this
13:06:22 <Solonarv> there is a way to extract type information from values: namely, if that type information was already hidden away in these values
13:06:54 <Solonarv> singletons just uses that technique and lays on some template haskell and other stuff to make it a teensy bit less cumbersome
13:07:22 <hyperisco> well there is "singletons" as in "singleton type", and then there is "singletons" as in the Haskell package / paper
13:07:50 <Solonarv> (I assumed from the quotes that JappleAck was referring to the package)
13:08:14 <hyperisco> probably but I'd like to note that from personal experience the package isn't worth it
13:08:36 <iqubic> How does this work?
13:08:57 <iqubic> @let powerset = filterM (const [True, False])
13:08:59 <lambdabot>  Defined.
13:09:01 <hyperisco> as a demonstration it is interesting, but as a platform for learning it is really, really complicated compared to the essential concept, which is singleton types
13:09:10 <iqubic> > powerset [1..3]
13:09:12 <lambdabot>  [[1,2,3],[1,2],[1,3],[1],[2,3],[2],[3],[]]
13:09:19 <iqubic> How does that work?
13:09:37 <hyperisco> but if someone has built something substantial off the singletons package, I'd love to be proven wrong
13:10:20 * hackage hoauth2 1.8.5 - Haskell OAuth2 authentication client  https://hackage.haskell.org/package/hoauth2-1.8.5 (HaishengWu)
13:10:24 <iqubic> I really want to know how that powerset function works.
13:10:56 <hyperisco> it destroys all universes with the wrong answer prove me wrong
13:11:17 * hackage multi-containers 0.1.0.1 - A few multimap variants.  https://hackage.haskell.org/package/multi-containers-0.1.0.1 (zliu41)
13:11:41 <iqubic> hyperisco: I'm not sure that's right. In fact, I'm sure that's not.
13:11:58 <yushyin> https://stackoverflow.com/questions/28872396/understanding-filterm
13:12:17 <turion> I'm having some trouble with Scrap Your Boilerplate. It doesn't define `dataCast3`. There is an old question on stackoverflow (https://stackoverflow.com/questions/14447050/how-to-define-syb-functions-for-type-extension-for-tertiary-type-constructors-e/14529377#comment96884273_14529377), but its answer doesn't compile on newer GHCs (>=8.4). How would I go around defining this nowadays?
13:13:04 <hyperisco> iqubic, well, I don't know how that function works specifically, but consider the Cartesian product of [1..3] and [True,False]
13:13:47 * hackage comic 0.0.1 - A format for describing comics.  https://hackage.haskell.org/package/comic-0.0.1 (davean)
13:14:03 <hyperisco> > [(x,y)|x<-[1..3],y<-[True,False]]
13:14:05 <lambdabot>  [(1,True),(1,False),(2,True),(2,False),(3,True),(3,False)]
13:14:14 <hyperisco> that didn't go how I wished
13:14:18 <iqubic> 6 elements, just as I thought.
13:14:39 <turion> Even this simple code doesn't compile:
13:14:39 <turion> > thing :: (Typeable t) => (forall b c d . (Data b, Data c, Data d) => f (t b c d)) -> TypeRep
13:14:39 <turion> > thing = typeRep
13:14:39 <turion> It says something about "Could not deduce (Data b0)" and "The type variable `b0' is ambiguous"... what is it even referring to?
13:14:41 <lambdabot>  error: Variable not in scope: thing
13:14:41 <lambdabot>  <hint>:1:7: error:
13:14:41 <lambdabot>      parse error on input =
13:14:42 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
13:15:01 <turion> Ah sorry :)
13:15:15 <turion> > typeRep :: (Typeable t) => (forall b c d . (Data b, Data c, Data d) => f (t b c d)) -> TypeRep
13:15:17 <lambdabot>  error:
13:15:17 <lambdabot>       Could not deduce (Data b0)
13:15:17 <lambdabot>        from the context: Typeable t
13:15:29 <turion> Thank you
13:15:49 <iqubic> Not sue how to make sense of this powerset function at all.
13:16:21 <turion> iqubic: What powerset function?
13:16:40 <iqubic> "powerset = filterM (const [True, False])"
13:16:42 <iqubic> That one.
13:16:47 <iqubic> turion: ^^^
13:16:52 <hyperisco> > let b = [True,False] in [(x,y,z)|x<-b,y<-b,z<-b]
13:16:54 <lambdabot>  [(True,True,True),(True,True,False),(True,False,True),(True,False,False),(Fa...
13:17:16 <zincy> That beautiful moment in an interview when you get an anagrams question in an interview and chose Haskell
13:17:33 <iqubic> zincy: How would you do that in haskell?
13:17:35 <zincy> I can't type
13:17:43 <hyperisco> so that has 2^3 elements, and we can interpret each as whether to keep the respective element of [1..3]
13:17:44 <iqubic> :t permutations
13:17:45 <lambdabot> [a] -> [[a]]
13:17:49 <zincy> yes
13:18:22 <iqubic> let anagrams = filter isRealWord $ permutations
13:18:33 <zincy> So if a given [a] is in your [[a]] it is an anagram
13:18:56 <iqubic> with isRealWord :: String -> Bool
13:19:01 <iqubic> Yeah, that's nice.
13:19:05 <iqubic> Now do it yourself.
13:19:08 <Solonarv> iqubic: . not $
13:19:18 <iqubic> Really?
13:19:19 <sphalerite> hm, I don't really see anything useful for parallelising a fold in Control.Parallel.Strategies..? Or am I missing something?
13:19:22 <Welkin> or just sort and pairwise compare
13:19:27 <Welkin> which is the best solution
13:19:37 <zincy> iqubic: But you just did it for me?
13:19:42 <hyperisco> iqubic, does that make some sense?
13:19:45 <Welkin> n log n instead of n^2
13:19:56 <Solonarv> sphalerite: 'parallel' has stuff for generally evaluating values in parallel
13:19:58 <iqubic> Hyperisco, yes.
13:20:05 <Solonarv> I admit I haven't used it
13:20:29 <sphalerite> right, I've managed to make my program run faster by evaluating the list that fold operates on in parallel
13:21:31 <sphalerite> but I think the fold is still happening sequentially
13:21:41 <sphalerite> then again, I don't actually have any evidence for that :^)
13:23:34 <hyperisco> iqubic, can also think of it as a fold
13:23:43 <iqubic> How so?
13:23:53 <turion> sphalerite: Put in a lot of traces and see whether they come out in order?
13:24:15 <turion> What are you folding over? A list? Or a sequence?
13:24:18 <Welkin> sphalerite: learn about the Par monad
13:24:26 <hyperisco> iqubic, so if we start with [[]], the powerlist of the empty list
13:24:36 <sphalerite> turion: a list
13:24:40 <hyperisco> iqubic, then what do we do with one more element?
13:25:15 <turion> So you should try and split your list in the middle, and launch the two halves parallely
13:25:17 * hackage generic-env 0.1.1.0 - Generic Environment Generator  https://hackage.haskell.org/package/generic-env-0.1.1.0 (yigitozkavci)
13:25:44 <iqubic> hyperisco: You either add it to the list, or you don't.
13:25:52 <Solonarv> that doesn't seem obvious to me - splitting a list in the middle is not cheap
13:26:16 <iqubic> But I'm not sure how that helps us get to a fold.
13:26:20 <Solonarv> (perhaps you should work on alternating elements instead?)
13:26:26 <hyperisco> so the powerlist of [x] is [x:[],[]], the powerlist of [y,x] is [y:x:[], y:[], x:[], []]
13:26:49 <iqubic> Correct.
13:26:58 <iqubic> that makes the most sense.
13:27:04 <hyperisco> do you see the pattern?
13:27:48 <iqubic> Not yet.
13:28:00 <iqubic> Or wait, yes I do.
13:28:32 <iqubic> Not sure how that patter helps me.
13:28:49 <sphalerite> turion: hmm, ok although the monoid I'm working with is commutative as well so splitting down the middle isn't any better than going from beginning to end? I think?
13:28:57 <hyperisco> because once you have a base case and the inductive case for one more element, you have a fold
13:29:03 <turion> Solornarv: No it's not so cheap to split it in the middle, Sequences would be better for that
13:29:30 <iqubic> so the powerlist of [x] is [x:[],[]], the powerlist of [y,x] is the exactsame as before, but then you can have each of those cases with a y in the list.
13:29:34 <iqubic> How do you write this fold?
13:29:43 <yushyin> filterM is implemented as a fold and the base-case is pure []
13:29:50 <iqubic> Oh???
13:30:08 <hyperisco> iqubic, foldr (\nextElement lastStep -> ...) baseCase
13:30:15 <iqubic> I see.
13:30:16 <turion> sphalerite: Maybe commutativity makes things even easier. I just thought that you probably don't want to parallelise the whole list, just split it into as many parts as you have cores
13:32:47 <iqubic> foldr (\nextElement lastStep -> lastStep ++ map (a:) lastStep) [[]]
13:32:52 <iqubic> How does that look?
13:33:12 <iqubic> Not quite that.
13:33:34 <iqubic> But something similar I think
13:33:47 <iqubic> @let powerfold = foldr (\nextElement lastStep -> lastStep ++ map (a:) lastStep) [[]]
13:33:48 <lambdabot>  Defined.
13:34:00 <iqubic> > powerfold [1..3]
13:34:02 <lambdabot>  [[],[a],[a],[a,a],[a],[a,a],[a,a],[a,a,a]]
13:34:04 <hyperisco> this is going to be interesting
13:34:13 <iqubic> That didn't work.
13:34:17 <iqubic> What the heck???
13:34:25 <hyperisco> :t a
13:34:27 <lambdabot> Expr
13:34:42 <hyperisco> see, in principle is a great idea, and in practice it is a great idea, but in practice it is also a bad idea :P
13:34:42 <iqubic> @let powerfold = foldr (\nextElem lastStep -> lastStep ++ map (nextElem:) lastStep) [[]]
13:34:44 <lambdabot>  .L.hs:162:1: error:
13:34:44 <lambdabot>      Multiple declarations of powerfold
13:34:44 <lambdabot>      Declared at: .L.hs:159:1
13:34:57 <iqubic> @undefine
13:34:57 <lambdabot> Undefined.
13:35:05 <iqubic> @let powerfold = foldr (\nextElem lastStep -> lastStep ++ map (nextElem:) lastStep) [[]]
13:35:07 <lambdabot>  Defined.
13:35:18 <iqubic> > powerfold [1..3]
13:35:20 <lambdabot>  [[],[3],[2],[2,3],[1],[1,3],[1,2],[1,2,3]]
13:35:27 <iqubic> That seems to work.
13:35:45 <iqubic> > powerfold [1]
13:35:47 <lambdabot>  [[],[1]]
13:35:57 <iqubic> I'm going to claim that my thing works.
13:36:36 <Welkin> prove it
13:36:48 <hyperisco> first is the complicated question of what "working" means
13:36:49 <iqubic> I'm not sure how to prove it.
13:36:58 <hyperisco> after that, proving it might not be so hard :P
13:37:14 <iqubic> Now you guys are just diving into the semantics of the matter.
13:37:24 <hyperisco> see I started calling it powerlist because it isn't really a set
13:37:38 <iqubic> Why isn't it a set?
13:37:39 <Welkin> tails [1,2,3]
13:37:42 <Welkin> > tails [1,2,3]
13:37:42 <hyperisco> > powerfold [1,2,1]
13:37:44 <lambdabot>  [[1,2,3],[2,3],[3],[]]
13:37:45 <lambdabot>  [[],[1],[2],[2,1],[1],[1,1],[1,2],[1,2,1]]
13:38:11 <iqubic> alright... It's not a set.
13:38:15 <hyperisco> actually, lets do it this way
13:38:25 <hyperisco> > powerfold [1,1] == powerfold [1]
13:38:27 <Solonarv> iqubic: I can tell you that it works
13:38:27 <lambdabot>  False
13:38:32 <hyperisco> QED
13:38:41 <iqubic> I called it the powerfold function because it uses a fold, and resembles the powerset/powerlist function
13:38:43 <Solonarv> but I'm too lazy to formulate the argument
13:39:03 <iqubic> Solonarv: I don't need a formal argument.
13:39:33 <iqubic> A formal argument that proves my thing works would require a formal definition of powerset.
13:39:43 <hyperisco> we need to characterise what elements need to be in the powerlist, together with what elements cannot be seen in the powerlist
13:39:57 <Solonarv> I didn't say anything about a formal argument, just about any argument at all :>
13:40:07 <hyperisco> and that will characterise a powerlist :P well, we might care about order too, so that's another bother
13:40:16 <iqubic> Yeah...
13:40:33 <iqubic> @let powerset = filterM (const [True, False])
13:40:35 <lambdabot>  Defined.
13:40:44 <iqubic> > powerset [1..3]
13:40:47 <lambdabot>  [[1,2,3],[1,2],[1,3],[1],[2,3],[2],[3],[]]
13:41:06 <iqubic> > powerfold [1..3]
13:41:08 <lambdabot>  [[],[3],[2],[2,3],[1],[1,3],[1,2],[1,2,3]]
13:41:20 <iqubic> they both have the same elements, just not in the same order.
13:41:50 <hyperisco> if we're using list equality, that means they are different
13:42:00 <iqubic> generateSubset (x:xs) = let p = generateSubset xs in p ++ map (x:) p
13:42:09 <iqubic> generateSubset [] = [[]]
13:42:28 <iqubic> I basically wrote that function, but I used a fold instead of a pattern match.
13:42:42 <iqubic> Are there any cases where folds work better than pattern matching?
13:42:46 <Welkin> what?
13:42:50 <hyperisco> there is no difference
13:42:57 <Welkin> you mean explicit recursion vs a fold?
13:43:04 <iqubic> Yeah. 
13:43:05 <Welkin> your question makes no sense
13:43:15 <Welkin> a fold is explicit recursion
13:43:18 <Welkin> everything is recursion
13:43:21 <hyperisco> well, if your intent with pattern matching is to recurse, there is no difference
13:43:37 <Welkin> a fold is just a generic cursive function
13:43:43 <Welkin> recursive
13:43:49 <iqubic> Welkin: That sounds like the age old linux saying: "Everything is a file"
13:44:07 <Welkin> one downside of folds is you cannot short circuit/exit early
13:44:25 <iqubic> I see.
13:44:32 <Welkin> only a right fold can, and only under specific conditions of laziness
13:44:43 <Solonarv> That's wrong, foldr can exit early
13:44:43 <iqubic> Yeah. That's an issue.
13:45:16 <Solonarv> And more generally any catamorphism can exit early
13:45:16 <Welkin> Solonarv: sure, but does to make that happen is very convoluted
13:45:17 <JappleAck> Solonarv: early than what? and in which case?
13:45:17 <hyperisco> > foldr const 0 [1..]
13:45:19 <lambdabot>  1
13:45:52 <Welkin> if you pass around a counter or sentinel value, how do you do that with a right fold without some horrible unreadable code?
13:46:16 <Welkin> you may as well write the recursion yourself
13:46:40 <Welkin> early exit by laziness is another story
13:47:14 <wdanilo> Hi! As cabal new- commands are here, are there also some utils for sandboxed ghc installation? This is one of the most useful utils in stack, that you can point it with information about an lts for a project and it will automatically download and install proper GHC compiler for that project
13:47:34 <sclv> ghcup manages ghc installs
13:47:45 <sclv> it won't pick the compiler magically
13:47:49 <sclv> but can place them all side by side
13:48:10 <sclv> and then you can pass the compiler choice to ghc using the appropriate cmd line flag
13:49:12 <Solonarv> there is also a tool called 'vabal' which will do this automatically based on the version constraint for base (IIRC)
13:50:31 <wdanilo> sclv: it does not work on Windows  im rather looking for a fully cross platform solution
13:51:18 <sclv> wdanilo: for windows chocolatey will do the job
13:51:21 <turion> sclv: Hi :) Do you know how to define dataCast3 (which is missing from syb) nowadays?
13:51:40 <iqubic> I don't use Stack any more.
13:51:48 <iqubic> I use pure Nix. Because I run Nixos.
13:52:03 <Welkin> not GuixSD?
13:52:13 <wdanilo> sclv: thanks, Il check it out
13:52:16 <sclv> turion: oh in reference to https://stackoverflow.com/questions/14447050/how-to-define-syb-functions-for-type-extension-for-tertiary-type-constructors-e
13:52:29 <sclv> the difference is that let does not generalize its arguments anymore i think
13:52:37 <sclv> or in this case, where
13:52:59 <iqubic> Welkin: I would use GuixSD, but my drivers are non-free, so I literally can't use that.
13:53:00 <sclv> so you just need to bind all the type parameters with explicit foralls in the top level
13:53:04 <sclv> use scoped type variables
13:53:09 <sclv> and then give signatures to the bits of the where clause
13:54:02 <turion> Does getArg and typeOf3' need to be in the where clause?
13:54:46 <sclv> you could probably float 'em out
13:55:01 <sclv> haven't looked at that code since i wrote it, so just working from my gut here
13:55:17 * hackage multi-containers 0.1.0.2 - A few multimap variants.  https://hackage.haskell.org/package/multi-containers-0.1.0.2 (zliu41)
13:55:33 <turion> ... which is a long time ago.
13:55:53 <sclv> yeah, time flies when you're hacking haskell!
13:56:16 <turion> Also, typeof3 doesn't really check for all the type arguments, right? So if a :: t Int and b :: t Bool then typeof a == typeof b, right?
13:56:20 <sclv> i'm not sure why anyone would still use syb these days tbh given the existence of new-generics
13:56:57 <turion> I use it because I can't get generics to work well with multi parameter type classes
13:57:25 <turion> I'm writing a function (Data a, Data b) => a -> b -> foo
13:57:52 <turion> But I couldn't make a generic class such that I can have MyClass a b => a -> b -> foo
13:58:47 <trcc> so just a simple design consideration. I load some data concerning some entities from a file. Several functions that operate on the entities do not need all of the data, whereas other functions that operate on the entities do need all the data. Should I just go ahead and pass all the entity data to every function, or only what is relevant for the function in question?
13:58:55 <sclv> hm
13:59:14 <turion> Either way I have to check for constructors and record fields, and this is very easy in syb. What exactly do you mean by new-generics?
13:59:28 <turion> Just, like, GHC.Generics and so on?
13:59:32 <sclv> yeah
13:59:58 <sclv> these days i either use that or template haskell
14:00:42 <turion> So imagine you want a function that takes two values and then tells you whether the types have a record field of the same name
14:00:47 <turion> How would you do that in Generics?
14:01:51 <turion> trcc: Ideally only what is relevant. Makes unit testing of your functions easier. But also depends on how well you can separate the data
14:02:20 <trcc> turion: I noticed that. But turning the data into what the functions need is also expensive 
14:03:02 <trcc> and I enjoyed it very much when writing tests
14:07:38 <dmwit> turion: I guess you'd call `from` and then look for the `C1` constructor and its metadata on field names.
14:07:52 <dmwit> % import GHC.Generics
14:07:52 <yahb> dmwit: 
14:07:57 <dmwit> % :set -XTypeApplications
14:07:57 <yahb> dmwit: 
14:08:02 <dmwit> % :t from @(Product _)
14:08:02 <yahb> dmwit: ; <interactive>:1:1: error:; Ambiguous occurrence `from'; It could refer to either `GHC.Generics.from', imported from `GHC.Generics'; or `Control.Lens.from', imported from `Control.Lens' (and originally defined in `Control.Lens.Iso'); <interactive>:1:8: error:; Ambiguous occurrence `Product'; It could refer to either `FP.Product', imported from `Data.Functor.Pro
14:08:12 <dmwit> % :t GHC.Generics.from @(Product _)
14:08:12 <yahb> dmwit: ; <interactive>:1:21: error:; Ambiguous occurrence `Product'; It could refer to either `FP.Product', imported from `Data.Functor.Product'; or `Data.Monoid.Product', imported from `Data.Monoid' (and originally defined in `base-4.12.0.0:Data.Semigroup.Internal')
14:08:19 <dmwit> are you kidding me
14:08:27 <dmwit> % :t GHC.Generics.from @(Data.Monoid.Product _)
14:08:27 <yahb> dmwit: forall {w} {x}. Data.Monoid.Product w -> D1 ('MetaData "Product" "Data.Semigroup.Internal" "base" 'True) (C1 ('MetaCons "Product" 'PrefixI 'True) (S1 ('MetaSel ('Just "getProduct") 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 w))) x
14:09:10 <dmwit> Oops, the "getProduct" occurs in the metadata for S1, not C1. Sorry.
14:09:51 <turion> dmwit: I had trouble getting stuff like this to work with two type variables
14:09:53 <manek> Hi! How can I install "happy" globally when using the cabal new-install? I see it's installed in a store in my home, can I ask cabal to make a binary link for me in such a case?
14:10:27 <dmwit> manek: Yes, I think the relevant flag is --symlink-bindir
14:10:56 <dmwit> There should be a sensible default if you have a reasonably recent cabal.
14:11:05 <dmwit> Like ~/.cabal/bin or something.
14:11:35 <dmwit> % :t GHC.Generics.from @(Control.Monad.State.StateT _)
14:11:35 <yahb> dmwit: ; <interactive>:1:21: error:; * Expecting two more arguments to `StateT _'; Expected a type, but `StateT _' has kind `(* -> *) -> * -> *'; * In the type `(StateT _)'; In the expression: GHC.Generics.from @(StateT _)
14:11:46 <dmwit> That'll teach me to try it in-channel first.
14:12:02 <manek> dmwit: interesting, accorrding to docs t should be done witout a flag: https://www.haskell.org/cabal/users-guide/nix-local-build.html#cabal-new-install
14:12:48 <dmwit> manek: I think so. --symlink-bindir just says where it should go, not whether it should go there.
14:13:25 <turion> If I have just one type variable and I want a function hasField :: MyClass a => String -> a -> Bool, that's easy. But I couldn't get this to work for a function sameField :: MyClass a b => a -> b -> Bool
14:14:26 <turion> Hmmm what I said doesn't make much sense...
14:14:40 <dmwit> % :t GHC.Generics.from @(Data.Monoid.Alt _ _)
14:14:40 <yahb> dmwit: forall {k} {w1 :: k -> *} {w2 :: k} {x}. Alt w1 w2 -> D1 ('MetaData "Alt" "Data.Semigroup.Internal" "base" 'True) (C1 ('MetaCons "Alt" 'PrefixI 'True) (S1 ('MetaSel ('Just "getAlt") 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 (w1 w2)))) x
14:14:51 <dmwit> turion: The info still seems to be there in the S1 to me?
14:14:54 <manek> dmwit: actually when using without manual providign the path I got info "cabal: symlink-bindir is not defined. Set it in your cabal config file or use" Ok, Ill check it out where to set it as a defaut location globally, but imo cabal should default to something "by default"
14:14:59 <turion> Ah! The issue was that I _needed_ a single parameter type class!
14:15:40 <dmwit> manek: Yes, as I said, I think newer cabals have a sensible default. Like you, the cabal devs considered it a bug that the older ones didn't.
14:15:49 <lyxia> turion: what do you mean
14:16:12 <turion> lyxia: Long ago, I'm trying to remember...
14:16:48 <turion> What I needed was a type class such that I can write a function e.g. sameField :: (MyClass a, MyClass b) => a -> b -> Bool
14:17:14 <dmwit> type MyClass = Generic -- ;-)
14:17:35 <manek> dmwit: Actually Im using the newest one (2.4.1.0)
14:17:37 <turion> Ok, and how do I implement the function then?
14:17:58 <manek> dmwit: anyway, thank you so much for the help!
14:18:00 <manek> :)
14:18:03 <lyxia> you need a bit more than Generic
14:18:07 <turion> dmwit: It's really easy with syb, but with Generic I basically need to rewrite syb from scratch
14:18:13 <turion> (using syb)
14:18:28 <turion> I mean one could define all the stuff in syb by using GHC.Generics
14:18:55 <turion> But it seemed less effort to me to just use syb instead ;)
14:19:08 <Boarders> say I have a library that I want to upload to cabal, how does it work with testing?
14:19:16 <Boarders> like I have a test suite but I don't want that to be a library dep
14:19:49 <dmwit> You make a test-suite stanza in your cabal ifle.
14:20:20 <Boarders> oh ok, and that will not be exposed in the library?
14:20:27 <Boarders> sorry haven't done it before
14:20:49 <Solonarv> <pedant> you can't upload libraries to cabal, only to hackage or some other package repository </pedant>
14:20:58 <dmwit> I don't know what "that" means. But you can specify different dependencies in your library and test-suite stanzas.
14:21:30 <Solonarv> and it is indeed possible to build the library without using test-suite-only dependencues
14:21:45 <Solonarv> (that is why the dependencies are listed separately in the first place!)
14:26:41 <dmwit> % let f :: D1 a (C1 b (S1 ('MetaSel ('Just fieldName) c d e) f)) g -> Proxy fieldName; f _ = Proxy
14:26:41 <yahb> dmwit: 
14:26:52 <dmwit> % symbolVal . f . GHC.Generics.from $ Data.Monoid.Alt undefined
14:26:52 <yahb> dmwit: "getAlt"
14:26:56 <dmwit> turion: ^
14:26:57 * hackage expressions 0.5 - Expressions and Formulae a la carte  https://hackage.haskell.org/package/expressions-0.5 (jakubdaniel)
14:27:16 <dmwit> I don't know Generics, so there's probably library support for writing that more simply. But it seems like a proof-of-concept that it's not too difficult.
14:28:08 <dmwit> (And maybe more robustly, too. Like to support constructors with more than one field.)
14:29:34 <dmwit> Probably to be really clean you'd want to write a tiny class with `getFieldNames` as the method and make instances for `D1`, `C1`, `S1`, and so on.
14:29:56 <lyxia> turion: https://gist.github.com/Lysxia/59d7391e7d656e9e9e3c06951eb7238a
14:30:03 <dmwit> And that might even already exist, I don't know. Like I said, I'm just staring at the basic haddocks, I'm no expert.
14:30:33 <lyxia> I don't think that exists yet
14:31:09 <Boarders> Solonarv: sorry I meant to write hackage and my mind just slipped o_0
14:31:18 <dmwit> lyxia++ for being an expert!
14:34:18 <lyxia> Ah generics-sop has that stuff nicely packaged up.
14:36:17 * hackage logict 0.6.0.3 - A backtracking logic-programming monad.  https://hackage.haskell.org/package/logict-0.6.0.3 (Bodigrim)
14:48:17 * hackage expressions-z3 0.5 - Encode and Decode expressions from Z3 ASTs  https://hackage.haskell.org/package/expressions-z3-0.5 (jakubdaniel)
14:48:17 <koz_> Solonarv: Do you use Stack or cabal new-* on Windows?
14:48:31 <koz_> (by which I mean WSL)
14:48:57 <Solonarv> I don't have WSL, actually (and consequently I don't use it :P)
14:49:04 <koz_> Solonarv: So what do you use?
14:49:52 <Solonarv> I use chocolatey to install ghc + cabal, cabal-head (i.e. 3.0) with v2-* commands, and MSYS2 when I need a C dependency
14:50:07 <koz_> Ah, OK.
14:50:17 <koz_> So I guess you just pick one GHC version and stick with it?
14:50:43 <Solonarv> yes, but mostly because I haven't needed to use an older version since switching to that system
14:50:52 <koz_> So you're on 8.6?
14:50:54 <koz_> Or 8.4?
14:50:58 <Solonarv> chocolatey supports installing multiple versions of a package side by side
14:51:05 <Solonarv> and yes 8.6.5
14:51:27 <Solonarv> oh, 8.6.4 apparently, I must have forgotten to grab the new one
14:51:32 <koz_> OK, thanks. I will try that once work replaces my machine.
14:51:37 <koz_> (which will be next week)
14:52:14 <koz_> So what do you use for a shell?
14:52:16 <Solonarv> koz_: I documented my setup here: https://gist.github.com/Solonarv/3c023fa7de9b0ca38781bd96943a11ee
14:53:09 <Solonarv> the shell is msys2 mingw64 (running bash)
14:53:18 <koz_> Solonarv: Oh, neat. I might just do that then, thanks.
14:53:22 <Solonarv> no idea what the terminal emulator is called, I just use the one that came with msys2
14:53:47 <koz_> As a complete aside, is the go-to thing for working with XML still HXT?
14:54:09 <koz_> I need XSLT/XPATH capabilities ideally, as well as the ability to verify by schema (RelaxNG preferred).
14:54:33 <koz_> If it's of any consequence, I'll be working with SVGs programmatically.
14:58:25 <Solonarv> hm, perhaps one of the SVG libraries might be a better fit then?
15:00:27 <koz_> Looking at the existing ones, they are all about rendering (which I will need eventually) or construction, not manipulation.
15:06:23 <koz_> (also I'm not sure what library to use if I wanna render SVG into PDF)
15:13:16 <jle`> hm, is there a data type `newtype Many :: (* -> *) -> * -> * where Many :: f a -> Many f [a]`
15:13:20 <koz_> Seems Rasterrific is what I want.
15:18:08 <trcc> Is map (\x -> show x) $ map (\x -> x+1) [1,2,3] as efficient as map (\x -> show (x+1)) [1,2,3]?
15:19:00 <lyxia> that looks like it should fuse but I haven't checked.
15:19:18 <koz_> Yeah, I think fmap fusion is a RULE somewhere in the guts of GHC, but I too am unsure.
15:19:18 <jle`> they're both O(n) on the length of the list that you eventually use, but without fusion the first would should have twice as high a constant factor
15:20:13 <trcc> okay. Thank you. So it has nothing to do with lazy evaluation in this context?
15:22:43 <lyxia> I don't think so.
15:23:45 <trcc> hm ok. Because I was thinking, in context of the first one, each variable within the list would have attached x+1 and show, and therefore it would not matter, that it was separated into two mapping functions instead of one
15:26:41 <lyxia> every map produces a list, which has a nonzero cost in addition to the stored elements.
15:27:10 <trcc> ah I see. Thank you.
15:27:22 <trcc> so in general, package as much as possible within each map function
15:27:34 <koz_> trcc: If you wanna be _absolutely 100% certain_ yes.
15:27:39 <koz_> (HLint even suggests this I think)
15:28:11 <trcc> ok thank you all
15:30:50 <jle`> trcc: the laziness here comes to play in that you can start evaluating the "show" part before you finish mapping the list
15:31:16 <trcc> I understand. I just thought, hoped, that it had an impact on the other thing as well
15:31:18 <jle`> trcc: so if you got the first item, you'd get "2", without ever having to compute 2+1, 3+1, etc.
15:31:30 <trcc> so it has an impact, but still a cost
15:31:42 <jle`> so the laziness essentially gives the linear-time O(n) on the items retrieved
15:31:51 <jle`> if we weren't lazy then we'd get linear-time on items in the original list
15:31:59 <jle`> so it's more 'efficient' in that algorithmic sense
15:32:04 <trcc> so n becomes 6 or 3 in the example?
15:32:25 <jle`> hm, to be clear, it's O(items retrieved), instead of O(items in list)
15:32:46 <trcc> so if we extract all 3
15:33:11 <jle`> yeah, if we extract all the items in the original list, then laziness doesn't help us too much in terms of time-efficiency
15:33:16 <trcc> then it performs two mapping functions in the first one, and thereby we get O(6), whereas in the second one, it is packaged into one mapping function, and therefore O(3)
15:33:20 <jle`> but it can help us in temrs of space-efficiency
15:33:25 <trcc> okay I see
15:33:26 <jle`> i guess there's a big deal here, it's O(1) space
15:33:39 <jle`> laziness gives us O(1) space instead of O(n) space
15:33:43 <jle`> (depending on how you consume the list)
15:34:41 <jle`> trcc: no, it still performs two operations in both cases.  so if we evaluate the entire lists, there is no benefit or drawback for laziness in terms of time-efficiency
15:35:06 <jle`> but *if* we have fusion, then yes, the fused version is 'twice as fast'
15:35:29 <jle`> if we're taking memory access and allocation as the main cost.
15:35:44 <trcc> I was mainly thinking of time
15:36:10 <trcc> and in time, the single mapping is fastest (if we do not consider fusing), correct?
15:37:28 <jle`> if we have no fusion, then  if we use the entire list, laziness is the same as non-lazy
15:37:47 * hackage entwine 0.0.4 - entwine - Concurrency tools  https://hackage.haskell.org/package/entwine-0.0.4 (lambda_foo)
15:37:48 <jle`> you get an extra traversal cost for every subsequent map, just like for the non-lazy situation
15:38:43 <trcc> damn :) But good to know
15:38:47 <jle`> the main thing laziness helps us here for the multi-chained-map is in space efficiency
15:39:24 <trcc> Makes for a cleaner structure to split it up into several map functions sometimes
15:39:34 <trcc> but I guess that is what the fusion is therefore
15:39:52 <jle`> indeed. but also adding a constant cost factor is likely not going to be a bottleneck in most situations
15:40:04 <jle`> single-map and multi-map are both O(n)
15:40:12 <jle`> just with different constant factors
15:40:21 <trcc> Yes
15:41:38 <jle`> if you wanted to control fusion explicitly, and not rely on compiler magic, iteratee-based libraries are a good tool, i think
15:41:46 <jle`> like pipes and conduit
15:41:54 <jle`> but it's going to be overkill for something like chained maps
15:42:32 <jle`> it's mostly for situations where "get the next item" is the expensive operation.  and for lists, 'get the next item' is a pattern match on :/[], so it's usually not the bottleneck
15:43:16 <jle`> i mean the retrieval of the next item, to be clear. not the evaluation/computation of it.
15:43:42 <trcc> ah ok
15:44:04 <trcc> Lots of small pieces falling into place
15:44:58 <jle`> (the point of bringing up iteratees is that your distrust of compiler magic in fusion is not uncommon, and there are solutions that can make it explicit, but with some overhead :) )
15:45:21 <jle`> for the most part in haskell we just trust in list fusion without thinking about it
15:45:26 <Boarders> is there an easier way to sort vectors than converting to a list and then sorting (performance is no big deal)?
15:45:36 <jle`> Boarders: check out vector-algorithms
15:46:10 <jle`> although, now that i think about it, sorting by converting to list then sorting is probably the "easiest" way
15:46:22 <jle`> albeit pretty inefficient for large vectors
15:46:44 <jle`> vector-algorithms implements those in-place sorts that are famous in comp sci classes.
15:48:15 <Boarders> thanks
15:48:28 <Boarders> it is just for a test suite so I went with the low-fi approach
16:45:20 <wdanilo> Guys, I'm trying to use the new cabal functionality and Im wondering if this is by design or this is a bug that running `cabal new-install alex  --symlink-bindir="~/.cabal/bin"` the provided path is glued with my current path so its `/home/me/test/~/.cabal/bin`. I understand this is kind of a bug ?
16:47:10 <jle`> wdanilo: usually the expansion of tildes and stuff is handled by the console, not the application
16:47:21 <jle`> so maybe try --symlink-bindir ~/.cabal/bin ?
16:47:31 <jle`> s/console/shell
16:48:13 <jle`> usually manually 'expanding' things like that is out of the scope for a big multiplatform application like cabal
16:48:27 <jle`> but if you pass in ~/.cabal/bin then the shell should expand it before giving it to cabal i believe
16:49:23 <wdanilo> jle`: oh damn, Im tired. Of course it should be expanded by shell. Thank you
16:49:40 <jle`> np :) but i'm not 100% sure, you should test it out before trusting me heh
16:50:04 <jle`> fwiw it's not an obvious thing i think
16:50:43 <wdanilo> jle`: wait, nope! it doesnt work
16:50:50 <wdanilo> jle`: it still does not expand properly
16:50:55 <jle`> :'(
16:51:11 <jle`> hm, then that's all i got
16:51:45 <jle`> sorry! :(
16:52:13 <wdanilo> no need to be sorry, thanks for help!
16:52:24 <wdanilo> anyway, its broken
16:53:21 <JappleAck> wdanilo: have you tried `--symlink-bindir="$HOME/.cabal/bin"`?
16:54:31 <wdanilo> JappleAck: yeah, it works! And yes, I tried it just when you typed your question :P
16:56:06 <JappleAck> wdanilo: i think replacing `=` with space would also work: `--symlink-bindir ~/.cabal/bin`
16:56:34 <JappleAck> i believe bash deosn't expand tilde if it's not placed at beginning of a word
16:58:48 <Mortir> Hi
17:07:47 * hackage reflex-dom-svg 0.3.2.0 - Reflex functions for SVG elements.  https://hackage.haskell.org/package/reflex-dom-svg-0.3.2.0 (schalmers)
17:22:37 <c50a326> is it just me or is it slightly sad that, considering one of the main things that Haskell is apparently great at is parsing, and that one of the most prolific softwares written in Haskell is Pandoc, for CommonMark, Pandoc is actually just wrapping the cmark C ref impl http://hackage.haskell.org/package/cmark-gfm-0.2.0/docs/src/CMarkGFM.html#commonmarkToNode
17:25:05 <boj> c50a326: i suppose one could argue that since Haskell has a great FFI, may as well save developer time and wrap C libraries if they already do a decent job
17:38:01 <DigitalKiwi> boj: that's not very nih of them
17:41:23 <DigitalKiwi> (if you pretend for a moment that nih and nice remotely sound alike that joke is hilarious)
19:07:47 * hackage stopwatch 0.1.0.6 - A simple stopwatch utility  https://hackage.haskell.org/package/stopwatch-0.1.0.6 (debugito)
19:20:08 <c50a326> is there a way to pass a function name to ghci (so that it evals the function on loading)?
19:20:35 <c50a326> oh nvm I figured it out
19:49:24 <pavonia> Has anyone here ever used the pictikz package by chance? I'm testing it on quite simple graphics but I either get "read: no parse" errors or just a quasi-empty output
19:51:11 <iqubic> How are my haskell folks doing at this late hour.
19:51:13 <iqubic> ??
19:51:37 <cloudy2> do haskell wannabes count?
19:54:56 <koz_> Awww, Solonarv isn't around. :(
19:57:09 <koz_> I'm getting some really weird behaviour from MSYS2 and a binary GHC (https://www.haskell.org/ghc/download_ghc_8_6_5.html#windows64). I have a cabal.project.local which aims at /home/em162098/ghc-8.6.5/bin/ghc.exe. However, when I try 'cabal new-build', it explodes, claiming that doesn't refer to an executable.
19:57:20 <koz_> I've tried running ghc.exe 'by hand' and it seems to work OK.
19:57:25 <koz_> Could someone tell me what I'm missing here?
20:02:17 * hackage persistent-documentation 0.1.0.0 - Documentation DSL for persistent entities  https://hackage.haskell.org/package/persistent-documentation-0.1.0.0 (parsonsmatt)
20:37:10 <LordBrain> is there a way to tell cabal to download the most resent version of each package on hackage, to have it ready for offline usage?
20:41:22 <Cale> LordBrain: Sounds doubtful... and a bit wasteful
20:41:42 <LordBrain> i've done it manually before
20:41:46 <LordBrain> wasn't so bad
20:42:26 <LordBrain> i only got the most recent versions, and i maintained a set of patches to make things work for offline
20:43:01 <LordBrain> it's not as space consuming as you might imagine if that's your concern
20:43:24 <Cale> I suppose not -- most packages probably never get used though
20:43:29 <LordBrain> i copied them all to a live cd i used to boot from quite often
20:45:30 <LordBrain> i just tried cabal fetch acme-everything --max-backjumps=-1
20:45:46 <LordBrain> didn't work, got hung up on ztail
20:46:42 <LordBrain> btw Cale, do you work on cabal?  I found a bug earlier
20:46:59 <LordBrain> it still tries to download, even when i give it the --offline switch
20:47:28 <LordBrain> i dont know if thats a bug, but it is contrary to my expectation
20:47:55 <Cale> I don't work on it, but you could perhaps report the bug here: https://github.com/haskell/cabal/issues
20:48:49 <Cale> What command accepts that flag?
20:49:02 <LordBrain> build
20:49:04 <LordBrain> v2-build
20:50:25 <Cale> Interesting, it doesn't show up in the help for me.
20:50:32 <LordBrain> what version?
20:50:48 <LordBrain> i have 2.4.1.0 
20:50:51 <Cale> 2.4.1.0
20:51:02 <LordBrain> cabal v2-build --help shows it
20:51:23 <LordBrain> use grep offline
20:51:24 <Cale> oh, it is there, I just missed it
20:51:51 <Cale> "Don't download packages from the Internet." sounds pretty clear
20:53:24 <LordBrain> it should be a little more documented tho actually, as when the preferred dependencies can't be satisified, does it try to make use of whatever you have in your package folder, or does it just quit with an error?
20:54:43 <LordBrain> in effect it actually wrote "Downloading ..." and gave me an error, which seems wrong
20:56:16 <LordBrain> maybe those two behaviors should be different switches really, --offline-or-quit  --offline-or-cope
20:57:10 <LordBrain> as they both seem useful to me
21:00:51 <LordBrain> offline-or-cope seems more useful tho, so if we're only to have one, i vote that
21:05:43 <LordBrain> index.tar seems 200M larger since october... 
21:27:02 <zincy> What is a good solution for offline docs for packages such as containers
21:32:14 <benzrf> zincy: you can configure cabal to build the haddocks locally
21:32:19 <benzrf> in fact i think that might be default? not sure
21:38:43 <AJTJ> I DO
22:03:33 <Squarism> if one wants a 30 type "domain model" to use different instances of the same class in different parts of your program. What would you see is the best approach? newtype or GeneralizedNewtypeDeriving?
22:04:44 <Squarism> writing newtype 30 times feels a bit id be doing the computers work.
22:05:07 <adino> @pl
22:05:07 <lambdabot> (line 1, column 1):
22:05:07 <lambdabot> unexpected end of input
22:05:07 <lambdabot> expecting white space, "()", natural, identifier, lambda abstraction or expression
22:05:27 <adino> @pl \f g x y -> f (x ++ g x) (g y)
22:05:27 <lambdabot> join . ((flip . ((.) .)) .) . (. ap (++)) . (.)
22:05:46 <c_wraith> totally an improvement. :P
22:05:49 <Squarism> thats human readable =D
22:06:24 <adino> quite so
22:21:57 <suzu> lol
22:22:12 <suzu> looks like somebody spilled marbles
22:39:04 <olligobber> @type ap
22:39:05 <lambdabot> Monad m => m (a -> b) -> m a -> m b
22:41:03 <Squarism> So no general advice on how to make 30 types use 2 different instances of same class in different parts of my program? newype or GeneralizedNewtypeDeriving?
22:41:36 <Cale> I guess newtype
22:41:44 <Cale> But what's the class? Should it be a class?
22:42:29 <zen_monk> can someone help me with a weechat error really quick ?
22:43:21 <Squarism> Cale, its aeson To/From-JSON
22:43:41 <Cale> ah, okay
22:44:01 <zen_monk> NickServ (NickServ@services.): Invalid password for zen_monk.
22:44:16 <Cale> Yeah, it's silly, but aeson is kind of obnoxious to use without its classes.
22:44:22 <zen_monk> how do i fix this ?
22:44:25 <Cale> So newtype is basically it.
22:44:33 <Squarism> Ok, ill run with that
22:44:53 <Cale> zen_monk: Maybe there's a way to recover your password? Maybe ask in #freenode
22:45:18 <zen_monk> Cale: ok
23:01:39 <MarcelineVQ> how come you goofs never told me about tagless final intepreters? :>
23:10:42 <suzu> ??
23:11:21 <suzu> is that when you use MonadMyEffect constraints
23:16:38 <MarcelineVQ> more general than just effects, and pretty darn neat http://okmij.org/ftp/tagless-final/course/lecture.pdf
23:31:48 * hackage validation 1.1 - A data-type like Either but with an accumulating Applicative  https://hackage.haskell.org/package/validation-1.1 (qfpl)
23:55:55 <trcc> jle`: thank you for your answers yesterday. Sorry for the sudden leave, my kids woke up
