00:35:47 * hackage category 0.2.3.0 - Categorical types and classes  https://hackage.haskell.org/package/category-0.2.3.0 (MatthewFarkasDyck)
01:21:17 * hackage category 0.2.4.0 - Categorical types and classes  https://hackage.haskell.org/package/category-0.2.4.0 (MatthewFarkasDyck)
01:59:14 <butterthebuddha> Does anybody know why the "init" function (returns everything but the last element from a linked list) is called init?
02:00:19 <Axman6> it's the initial part of the list
02:02:58 <butterthebuddha> Makes sense, ty
02:15:47 * hackage persistent 2.9.2 - Type-safe, multi-backend data serialization.  https://hackage.haskell.org/package/persistent-2.9.2 (MichaelSnoyman)
02:16:47 * hackage persistent-sqlite 2.9.3 - Backend for the persistent library using sqlite3.  https://hackage.haskell.org/package/persistent-sqlite-2.9.3 (MichaelSnoyman)
02:26:34 <geekosaur> or if you prefer, init and last are related the same way head and tail are, but from the opposite end as it were
02:42:46 <bonz060> Hi. I'm reading "Thinking Functionally with Haskell". What does 'Functional application in Haskell associates to the left in expressions and also has the highest binding power' mean?
02:43:18 <Cale> So when you write an expression like
02:43:20 <Cale> f x y z
02:43:21 <cocreature> bonz060: "f x y z" is equivalent to ((f x) y) z
02:43:23 <Cale> it means
02:43:26 <Cale> yeah
02:44:01 <cocreature> and highest binding bower means that f x + y will parse as (f x) + y since the precedence of (+) will always be lower
02:44:08 <cocreature> instead of f (x  + y)
02:45:13 <bonz060> Thanks alot! That is so much clearer!
02:45:24 <geekosaur> and f sin 3 means passing the two parameters sin and 3 to f, not the result of sin 3
02:46:09 <ItalianGentleman> Hi everyone
02:46:22 <ItalianGentleman> I'm trying to implement a kind of "for each"in haskell. I explain myself, I have a : `map (fn a b c d) mylist` and what I want is to have something like this in pseudo code : a = 0; foreach child in mylist do {value = fn a b c d;    a = max(a, value);}
02:46:27 <ItalianGentleman> How can I do that ?
02:47:05 <Cale> foldr max 0
02:47:34 <Cale> or wait, did you mean to reuse the same a though?
02:48:01 <Cale> I guess we can just write that recursively
02:48:34 <cocreature> where do b c d come from?
02:48:38 <cocreature> and whild seems to be unused?
02:48:42 <cocreature> *child
02:48:47 <Cale> yeah, it's weird
02:49:33 <Cale> ItalianGentleman: What are you actually trying to compute?
02:51:04 <ItalianGentleman> Cale: computing a sort of minimax 
02:51:25 <ItalianGentleman> and I'm trying to improve it
02:52:38 <ItalianGentleman> So i'm going to do an alphabeta pruning and need to break into the "for each"
02:52:52 <ItalianGentleman> and to pass alpha beta to the next "for each"
02:56:48 <Ariakenom> ItalianGentleman: you can always translate a for loop directly. loop state = ... loop newState ...
02:59:21 <ItalianGentleman> Ariakenom: can you give me an example ?
03:07:07 <Ariakenom> ItalianGentleman: https://gist.github.com/Ariakenom/b8b5d81024638facec2e806bb90db8d7
03:07:46 <ItalianGentleman> Okay, thanks !
03:18:56 <Ariakenom> oh I forgot that python has parenthesis in function calls ha
03:26:17 * hackage registry 0.1.3.3 - data structure for assembling components  https://hackage.haskell.org/package/registry-0.1.3.3 (etorreborre)
03:48:59 <orzo> I'm trying to use a Gtk.GLArea with gi-gtk-declarative, and the "create-context" signal is associated with a handler of type IO GLContext, but UserEventHandler is not defined for that type so I cannot use the onM function.  How do I attach to this signal?
03:55:36 <orzo> the overloaded label #createContext is a recognized name for that signal, but I can't seem to figure a way to attach a handler
04:21:21 <orzo> Actually, i'm attaching to the "realize" signal, and that compiles, but for some reason it is never triggered.
05:16:43 <gehmehgeh> hmm, why's there no "lookAhead" function in Trifecta --- or am I missing something?
05:38:47 * hackage sbv 8.2 - SMT Based Verification: Symbolic Haskell theorem prover using SMT solving.  https://hackage.haskell.org/package/sbv-8.2 (LeventErkok)
05:47:58 <HenryCH> i don't understand liftA2, if liftA2 :: (a -> b -> c) -> f a -> f b -> f c, how come (<*>) = liftA2 id? how can you apply liftA2 to a -> a?
05:51:47 * hackage yiyd 1.0.1 -   https://hackage.haskell.org/package/yiyd-1.0.1 (vonfry)
05:56:45 <__monty__> HenryCH: It's possible if c = a -> b
05:58:18 <Lears> Rather, if a is b -> c.
05:59:56 <Lears> > (+1) 2
05:59:58 <lambdabot>  3
06:00:03 <Lears> > id (+1) 2
06:00:05 <lambdabot>  3
06:00:45 <Lears> Hence `id` plays the role of an application function.
06:06:19 <Lears> (you could also write (<*>) = liftA2 ($), and indeed ($) = id)
06:06:30 <dmwit> They're gone.
06:06:40 <dmwit> Been gone since before __monty__ even answered.
06:06:53 <Lears> Oh, I should have tried to use their nick...
06:07:16 <MarcelineVQ> but was Crash even real all along
06:14:25 <__monty__> Their nick still completed for me but I do ignore parts.
07:22:28 <dmwit> HenryCH: Since `id :: a -> a`, and we can choose any `a` we like, we can in particular choose `id :: (b -> c) -> b -> c`.
07:23:09 <dmwit> HenryCH: Similarly, since `liftA2 :: (a -> b -> c) -> f a -> f b -> f c`, and we can choose any `a` we like, we can in particular choose `liftA2 :: ((b -> c) -> b -> c) -> f (b -> c) -> f b -> f c`.
07:23:35 <dmwit> HenryCH: This argument shows how the types can be made to line up, but doesn't explain how the implementations can be made to line up.
07:23:40 <dmwit> For that, check out:
07:23:41 <dmwit> ?src liftA2
07:23:41 <lambdabot> liftA2 f a b = f <$> a <*> b
07:24:10 <dmwit> One of the Applicative laws is `id <$> x = x`, and so `liftA2 id a b = id <$> a <*> b = a <*> b`.
07:26:26 <dmwit> __monty__: Their nick completed for you when you typed your message because they had left, but the server hadn't noticed because IRC's ping timeout is more than four minutes.
07:27:18 <dmwit> You wrote your message between the time they almost certainly stopped receiving messages and the time the server finally admitted this.
07:28:18 <CelestialLake> Around 250s
07:30:16 <infinity0> i'm a bit late to the party but is there any way i can "take over" the trac-infinity0 auto-created account on gitlab
07:30:27 <infinity0> and/or rename it to just "infinity0"
07:32:11 <CelestialLake> Grapple it, board it, yarrr
07:32:11 <kaizoku> YAARRRR
07:40:57 <infinity0> ah looks like "forgot password" works, then you can just change your own username
07:46:16 <HenryCH> dmwit: thanks!
07:53:01 <jusss> what are those Functor Applicative and Monad things?
07:53:42 <jusss> do I really need to learn category theory?
08:00:43 <lyxia> no
08:01:15 <lyxia> they're interfaces
08:06:41 <jusss> so what exactly they are?
08:16:23 <lyxia> jusss: https://en.wikibooks.org/wiki/Haskell/The_Functor_class
08:18:17 * hackage line-bot-sdk 0.5.0.0 - Haskell SDK for LINE Messaging API  https://hackage.haskell.org/package/line-bot-sdk-0.5.0.0 (moleike)
08:35:12 <dmwit> jusss: You might like: Typeclassopedia, You Could Have Invented Monads (And Maybe You Already Have)
08:35:36 <dmwit> , All About Monads
08:35:49 <dmwit> ?where typeclassopedia
08:35:49 <lambdabot> http://www.haskell.org/haskellwiki/Typeclassopedia
08:35:52 <dmwit> ?where ychim
08:35:52 <lambdabot> http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html
08:35:55 <dmwit> ?where aam
08:35:55 <lambdabot> http://www.haskell.org/haskellwiki/All_About_Monads
08:36:14 <jusss> dmwit: type constructor is functor, and now I even don't know what is functor
08:37:23 <dmwit> Functors are parameterized types that offer a way to modify all the contained values of the parameter type.
08:37:26 <dmwit> :t fmap
08:37:27 <lambdabot> Functor f => (a -> b) -> f a -> f b
08:37:43 <dmwit> They make a few promises: if you pass it a function that doesn't change anything, then the whole transformation doesn't change anything.
08:37:55 <dmwit> (Formally, `fmap id = id`.)
08:38:12 <dmwit> The second promise is that if you do two transformations in a row, that's the same as doing one big transformation that combines the two steps.
08:38:18 <dmwit> (Formally, `fmap f . fmap g = fmap (f . g)`.)
08:38:27 <dmwit> In terms of "what they are", that is all there is to it.
08:38:35 <dmwit> But to get a feeling for them, you'll need to play with a couple instances.
08:38:55 <dmwit> The resources I linked do that, and it is why I linked them, so definitely take a look.
08:39:03 <jusss> I know function composition
08:39:59 <jusss> but those type things, did fmap have a function definition?
08:40:16 <dmwit> fmap has many function definitions; a different one for each Functor.
08:40:36 <dmwit> Check here: https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#t:Functor
08:40:54 <dmwit> You can click the "Source" links in the list of instances to see implementations of fmap for a bunch of different types.
08:42:31 <jusss> a list is a container for values, I can understand, but functions? no
08:42:46 <dmwit> Would you like me to convince you that a function is a container? =)
08:43:05 <jusss> is it?
08:43:44 <jusss> http://learnyouahaskell.com/functors-applicative-functors-and-monoids
08:43:45 <roland> is there a name for the operator „$“?
08:44:07 <dmwit> roland: Not really. "function application" if you need to refer to it, or "applied to" if you are reading it alound as part of a code snippet
08:44:34 <jusss> those articles always use wrappers to descripe that functor monad things, but what are that wrappers
08:45:13 <dmwit> jusss: Well, if you define what you mean by container, then we can answer for sure whether functions are containers. But I have a pretty good track record of giving people a "container-like" way of intuiting functions' Functor instance.
08:45:38 <roland> ok thx
08:45:53 <dmwit> This last question "what are that wrappers?" I find too vague to meaningfully answer.
08:46:38 <rfold> I prefer to think of "fmap" not as mapping a to b using given function, but as mapping functions (a -> b) into functions (f a -> f b).
08:47:11 <rfold> This completely does away with the confusion surrounding the container metaphore when considering things that "aren't really containers".
08:47:53 <jusss> dmwit: a list is a container, I can get the value from it and the value won't change before and after
08:48:27 <dmwit> Which value?
08:48:48 <dmwit> Surely you admit there may be more than one.
08:48:50 <jusss> dmwit: those values in the list
08:49:18 <dmwit> Okay. So, rephrasing slightly: a list is a container, I can get the value at a particular index and the value won't change before and after.
08:49:27 <dmwit> You are okay with this modification?
08:49:32 <jusss> yeah
08:49:45 <dmwit> A function is a container, I can get the value at a particular input and the value won't change before and after.
08:50:06 <dmwit> (This isn't my preferred usual route to giving this intuition, but you sound like you prefer an argument to an exposition, so let's go! =)
08:50:20 <jusss> I don't think so
08:50:30 <dmwit> Which part don't you believe?
08:50:56 <jusss> how you can get the value at a particular input?
08:51:03 <dmwit> Apply the function to the input.
08:51:06 <dmwit> Compare:
08:51:17 <dmwit> > "abcde" !! 2
08:51:19 <lambdabot>  'c'
08:51:38 <dmwit> > chr $ 98
08:51:40 <lambdabot>  'b'
08:51:51 <dmwit> So we call the indexing operator ($) instead of (!!), but that's not *so* different.
08:52:13 <jusss> ok
08:52:35 <jusss> get the value at a particular input, ok,
08:52:49 <jusss> and your input is a list
08:52:57 <dmwit> Nope.
08:53:01 <dmwit> My input is a number.
08:53:06 <dmwit> Just like with lists, the index is a number.
08:53:21 <dmwit> (Picking `chr` as my function of interest for now, to give something concrete to talk about.)
08:53:29 <jusss> ok
08:54:30 <dmwit> Now if I wanted to muck about with all the letters in a list, making them uppercase or something, I could use map to do it.
08:54:35 <dmwit> > map toUpper "abcde"
08:54:38 <lambdabot>  "ABCDE"
08:54:47 <dmwit> I can do something similar with functions.
08:55:04 <jusss> like?
08:55:07 <dmwit> I can take a function that returns characters, and create a new function that does almost the same thing except it returns upper-case versions if the original returned a lower-case one.
08:55:19 <dmwit> But instead of map, we use (.) for that transformation.
08:55:27 <dmwit> > (.) toUpper chr $ 98
08:55:29 <lambdabot>  'B'
08:55:59 <dmwit> This is something like "mucking about with all the letters in the function chr", see?
08:56:23 <dmwit> Imagine we have a bunch of boxes with characters in them.
08:56:33 <dmwit> Maybe some of the boxes have the same character, maybe not. No promises.
08:56:55 <dmwit> And now I'm going to label each box somehow; say, with a number.
08:57:39 <dmwit> The interface to this collection of boxes is that if you give me a label, I'll give you the character inside the box with that label.
08:57:48 <dmwit> This is a bit like a container that contains characters, right?
08:58:08 <jusss> ok
08:58:19 <dmwit> But this is exactly what functions (of type `Int -> Char`) are: they are a bunch of `Char`s in boxes, each labeled with an `Int`.
08:58:34 <dmwit> If you give me an `Int`, I can look up the `Char` in the box with that label.
08:58:58 <jusss> "a type is just a set of values."
08:59:22 <dmwit> And you can easily imagine taking that big collection of boxes, together with a transformation on their contents, and making up a new collection of boxes where each labeled box in the new collection corresponds to applying the given transformation to the contents of the labeled box in the old container.
09:00:22 <dmwit> We name that operation (.): you give it a transformation on contained values, and a container (function), and it produces a new container (function) with all the same labels and the transformation applied to each labeled value.
09:00:32 <dmwit> :t (.)
09:00:33 <lambdabot> (b -> c) -> (a -> b) -> a -> c
09:01:11 <dmwit> (An aside: "a type is just a set of values" is an okay first approximation to the truth, but it turns out set theory isn't enough for the rich universe of types that Haskell offers.)
09:05:22 <dmwit> (...but I'm happy to run with the "a type is a set of values" intuition for now. It takes you a pretty good long way.)
09:05:24 <monochrom> Actually you will need that richness for function types for every non-total language.
09:05:34 <srnty> What should I read to get started with Haskell?
09:06:10 <dmwit> monochrom: Really? If it's merely bottoms you're thinking of, sets are enough to capture bottoms -- just add an extra element. It's polymorphism that kills the set theory approach.
09:06:46 <monochrom> Oh, that.
09:07:05 <monochrom> I thought you were going for "set plus partial order".
09:07:19 <jusss> dmwit: I can catch up with your "If you give me an `Int`, I can look up the `Char` in the box with that label." but I don't know what those boxes are related with functor? sorry I'm not every smart 
09:07:20 <dmwit> ?wiki tutorial
09:07:20 <lambdabot> https://wiki.haskell.org/tutorial
09:07:30 <dmwit> ?wiki tutorials
09:07:30 <lambdabot> https://wiki.haskell.org/tutorials
09:07:35 <dmwit> srnty: ^
09:07:41 <srnty> thank you
09:08:04 <dmwit> jusss: Mmm, the boxes analogy is to give you a way of conceptualizing functions that feels "container"-like.
09:08:19 <dmwit> jusss: It's easy to imagine applying some function to the value inside each box, right?
09:08:53 <dmwit> That is the fundamental operation of Functor: it gives you a way to apply a function to each contained value.
09:09:14 <jusss> dmwit: ok
09:09:22 <dmwit> (*If* you want to understand functors as containers. I don't, really; it was you that brought that analogy up.)
09:10:20 * rfold wonders if Functor would be easier to explain if it was a newtype rather than a class
09:10:40 <jusss> they all have they own version story about those functor monad stuff on the internet
09:10:45 <jusss> their
09:11:06 <dmwit> newtype Functor f = Functor (forall a b. (a -> b) -> f a -> f b) -- ? doesn't seem easier to explain to me
09:11:36 <dmwit> It's all the same concepts, plus now you have to understand/explain `forall` in more detail.
09:12:25 <dmwit> And maybe also have to explain some other tangential oddities (like why is this a newtype instead of a simple type alias).
09:12:34 <jusss> so the functor is the box or a function?
09:12:53 <dmwit> A functor is a parameterized data type plus the fmap operation.
09:12:53 <jusss> or neither?
09:13:09 <dmwit> So, e.g., `[]` and `map` make a functor.
09:13:19 <dmwit> But it would be wrong to say "`"abcde"` is a functor".
09:13:35 <jusss> aha
09:14:05 <jusss> list and function are not functor, but they make functor?
09:14:35 <dmwit> Yes. Although most people are sloppy about the distinction, and just say "lists are functors" as a shorthand.
09:14:43 <dmwit> (Because it's so obvious what the operation must be.)
09:14:47 * hackage webshow 0.0.0 - Show programming language printed values in a web UI  https://hackage.haskell.org/package/webshow-0.0.0 (ChrisDone)
09:15:25 <dmwit> On functions, people are sloppy in a different way, actually, that MJD brought to my attention. =)
09:15:51 <dmwit> But anyway the careful phrasing is something like this: for any type X, (->) X and (.) is a functor.
09:17:35 <jusss> fmap (+1) is a functor?
09:21:49 <fen> whats it called when you have a standalone API layer?
09:21:54 <fen> like a standard or something
09:22:29 <fen> eg for AI we could have an implementation of a standardised interface
09:22:43 <fen> then whatever tools this actually used could be swapped around and stuff
09:24:33 <fen> idk if these exist or if they do are they normally several layers deep? like one for standard use cases, eg for AI it might be like, a classification of images or something, and then internal api layers that would allow swapping around of internal components, like, different approaches to satisfying the upper standerd
09:24:44 <fen> is this a thing or did I just dream it up?
09:27:46 <utonx[m]> does the law of assiociativity basically mean that the result is of the same type?
09:28:33 <deathcap> question haskell gang: I'm running through the 99 haskell problems and had a performance related issue. If I'm looking to define my own "elementAt" function, which would be more performant:
09:28:40 <deathcap> (\(_,a) -> a) . head . filter (\(i,x) -> i==n) $ zip [1..] xs
09:28:42 <deathcap> or 
09:28:48 <deathcap> (\(_,a) -> a) $ head $ filter (\(i,x) -> i==n) $ zip [1..] xs
09:31:09 <Solonarv_> should not matter at all
09:31:36 <Solonarv_> is there a reason you're using (\(_,a) -> a) instead of snd ?
09:32:12 <deathcap> Because I'm a n00b.
09:32:27 <Solonarv_> oh, also: I'd prefer 'head . drop n'
09:33:24 <deathcap> Actually it's cause i was trying to get it done fairly quickly and lambdas are just what came to mind haha, i figured there was an obvious function for that, just didn't bother looking it up.
09:33:38 <Solonarv_> @check \xs n -> (n <= length xs) ==> (xs !! n :: Int) == (head . drop n) xs
09:33:40 <lambdabot>  error:
09:33:40 <lambdabot>  • Couldn't match expected type ‘Test.QuickCheck.Safe.SProperty’ with actual ...
09:33:46 <Solonarv_> bleh
09:34:04 <Solonarv_> @check \xs n -> (n >= length xs) || (xs !! n :: Int) == (head . drop n) xs
09:34:06 <lambdabot>  *** Failed! Exception: 'Prelude.!!: negative index' (after 2 tests and 1 shr...
09:34:06 <lambdabot>  [1] -1
09:34:20 <Solonarv_> @check \xs n -> (n >= length xs) || (n<0) || (xs !! n :: Int) == (head . drop n) xs
09:34:22 <lambdabot>  +++ OK, passed 100 tests.
09:34:26 <Solonarv_> there we go!
09:34:35 <cocreature> deathcap: more performant than (!!)? I don’t see why that should be the case
09:35:04 <Solonarv_> so yeah, I'd most prefer 'head . drop n', which should be equivalent to !!
09:37:48 <dmwit> utonx[m]: Generally no, associativity says more than just that the types match.
09:37:55 <dmwit> utonx[m]: The values are required to match as well.
09:38:24 <dmwit> utonx[m]: However, there's many different structures that have some variant of an associativity law, so without further information about what you're talking about it will be difficult to be more clear than this...
09:39:18 <raek> utonx[m]: no, that would be a law of closure. associativity is about that the way you put the parentheses for the same operation does not matter. (a + b) + c = a + (b + c) = a + b + c
09:40:28 <deathcap> cocreature noooo, obviously !! would be the most performant.
09:40:44 <deathcap> i'm talking about problem #3 on wiki.haskell.org/99_questions
09:43:02 <Solonarv_> aaah, I see
09:43:42 <deathcap> Just trying to make sense of this weird and wonderful world.
09:44:17 <utonx[m]> dmwit raek : oh alright, because I'm going through a book and it say such thing
09:44:17 <utonx[m]> >Commutative means you can reorder the arguments and still get the same result. Addition and multiplication are commutative, but (++) for the list type is only associative
09:44:18 <utonx[m]> Does that mean it's wrong?
09:45:10 <Solonarv_> no, that's correct
09:45:39 <Solonarv_> we have x + y = y + x (commutativity) and also x+(y+z)=(x+y)+z (assoc.)
09:46:05 <Solonarv_> we also have xs++(ys++zs)=(xs++ys)++zs, but not xs++ys=ys++xs
09:47:07 <utonx[m]> Solonarv_: Ah I see now, thanks
09:55:44 <energizer> Is there a name for functions like map, filter, reduce,  that take a function and a sequence of values, and somehow apply the function to the values
09:57:16 <lyxia> optics
09:57:41 <Lears> Higher order functions
09:58:05 <Solonarv_> folds, traversals
09:59:05 <Lears> If it's specifically things that traverse a list, I would go with traversals.
09:59:42 <dmwit> "Higher order function" means any function which takes a function as an argument.
10:00:45 <Solonarv_> "list traversals" is nice and specific
10:00:51 <dmwit> If you specifically want to narrow it down to only those that also take a sequence as an argument, Solonarv's suggestions are better.
10:01:12 <Lears> I interpreted "sequence" pretty broadly.
10:01:30 <dmwit> I ignored it entirely on my first pass through the question, and was ready to also suggest HOF. =)
10:02:53 <blankhart> i think the specific examples energizer mentions are all discussed in graham hutton's article tutorial on the universality and expressiveness of fold
10:04:03 <blankhart> the question can be answered several ways depending on what you focus on when you generalize the common features of those examples
10:05:31 <dmwit> energizer: clear as mud? =)
10:05:58 <energizer> looks like i have some reading to do, thanks :D
10:07:05 <mud> <.< >.>
10:09:17 <HugoDaniel> hello
10:09:23 <spoonm> greetings
10:22:17 * hackage parsix 0.2.0.0 - Parser combinators with slicing, error recovery, and syntax highlighting  https://hackage.haskell.org/package/parsix-0.2.0.0 (OlleFredriksson)
10:46:57 <energizer> is fold a generalization of traversal or vice versa?
10:48:06 <energizer> or these not in the same category of thingy
10:48:14 <energizer> or are*
10:48:27 <hpc> they're related similarly to (<*>) and (>>=)
10:48:39 <hpc> an instance of Traversible requires an instance of Foldable
10:48:39 <hpc> https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#t:Traversable
10:48:43 <Solonarv_> for [] specifically they are equally powerful (you can implement 'traverse' and 'foldr' in terms of each other)
10:48:52 <Solonarv_> in general a fold is "weaker" than a traversal
10:49:34 <monochrom> fold consumes only. traverse has to produce too.
10:50:24 <energizer> ok
10:51:12 <Solonarv_> demonstration of the first claim:
10:51:12 <Solonarv_> traverse f = foldr (liftA2 (:) . f) (pure [])
10:51:13 <Solonarv_> foldr k = appEndo . getConst . traverse (Const . Endo . k)
10:51:31 <Bish> i want to crack sha1 hashes with haskell, how would i go with the threading (having 4 green threads that calculate one hash at time?)
10:52:06 <hpc> look at Contorl.Concurrent
10:52:09 <Solonarv_> the "foldr from traverse" direction works for any Traversable thing, and is why Foldable is a superclass of Traversable
10:52:23 <Solonarv_> the "traverse from foldr" direction is specific to []
10:53:16 <geekosaur> @where parconc
10:53:16 <lambdabot> https://www.safaribooksonline.com/library/view/parallel-and-concurrent/9781449335939/
10:53:50 <sclv> Solonarv_: well specific to anything with a `fromList` :-)
10:54:20 <Solonarv_> yeah, sure - it'll work for things with an (unconstrained) fromList
10:54:50 <Solonarv_> (e.g. not Set, because Set's fromList has a constraint on the element type)
10:55:36 <Zer000> linux
11:11:37 <Bish> hpc: yeah i have, but how do i give that forkIO parameters..
11:11:44 <Bish> i mean i have to give the greenthreads inputs dont i
11:22:20 <blankhart> as to the original question from energizer though my thought would have been that the answer was a fold on a list because filter and reduce are not structure-preserving and therefore are not good traversals
11:24:35 <blankhart> based on the discussion in this thread (which also may explain lyxia reference to optics) https://www.reddit.com/r/haskell/comments/1dpk2b/haskell_for_all_program_imperatively_using/
11:25:06 <hpc> Bish: there are ways to pass information between threads in the modules under Control.Concurrent
11:25:09 <moll> Hey! Does anyone know of a lib that has total and IO exceptionless file system functions? Thinking of System.Diretory.listDirectory, for example, that returns an IO (Either SomeError [FilePath]), for example.
11:25:28 <Bish> hpc: that would mean the threads would be persistent
11:25:33 <Bish> i was rather looking for something
11:25:55 <Bish> doAtTheSameTime {  4 things } 
11:26:03 <dmwit> blankhart: Solonarv shows the standard trick above for squirreling away the non-structure-preserving computation in an Applicative that doesn't actually contain anything.
11:27:50 <blankhart> yes i am glad i asked because Solonarv_ is well ahead of me in all things. i will study it.  but if i understand this is limited to []?
11:28:54 <dmwit> No, that trick is not limited to [].
11:29:20 <dmwit> However it's not clear to me just how general filter can be made. Probably more general than just working on [], but certainly not general enough to work on all Applicatives.
11:30:02 <dmwit> Bish: Depending on how complicated those things are, and how complicated you want the processing on their results to be, that can be as simple as mapM_ forkIO [thing1, thing2, thing3, thing4]
11:30:27 <blankhart> okay.  i suspect investigating this is going to destroy my intuition temporarily but maybe broaden my mind.
11:35:09 <nshepperd> 'traverse from foldr' doesn't quite work for everything with unconstrained fromList
11:35:21 <nshepperd> it needs to be a surjective fromList too
11:35:32 <blankhart> dmwit: you are referring specifically to the Applicative instance for Const?
11:36:17 * hackage lsp-test 0.5.1.0 - Functional test framework for LSP servers.  https://hackage.haskell.org/package/lsp-test-0.5.1.0 (luke_)
11:38:36 <Bish> yeah thats what i meant, but how do i tell haskell what thing1 is (compute that single hash)
11:45:47 <blankhart> nvm dmwit i think i understand now thanks
11:46:15 <dmwit> blankhart: yep
11:46:50 <dmwit> Bish: Same way you would tell it if you weren't doing things in parallel, I guess.
11:47:56 <dmwit> Bish: Like you were going to write `main = computeHash1 >> computeHash2 >> computeHash3 >> computeHash4`. Now write `main = forkIO computeHash1 >> forkIO computeHash2 >> forkIO computeHash3 >> forkIO computeHash4`. Except not quite, see below.
11:48:21 <dmwit> Bish: The "not quite" is because the program exits as soon as `main` does, and it's on you to make sure `main` runs as long as whatever threads you want to run.
11:48:43 <cocreature> note that there are high-level combinatories for this, e.g., mapConcurrently or parMap
11:48:51 <dmwit> Bish: You can make an MVar () to write to once for each thread, and takeMVar the appropriate number of times at the end of `main`.
11:49:18 <dmwit> And yes, there are libraries for this. But I think it's worth doing yourself at least once, so the libraries don't feel magical.
11:49:54 <dmwit> (And for simple stuff it's not that hard to do by hand. The libraries are big and complicated mostly because they are built to handle complicated situations that you are probably not currently facing.)
11:50:15 <dmwit> (Like complicated exception-based control flow and stuff.)
11:50:55 <cocreature> I’d say do it once yourself and then use the libraries even for simple stuff. it’s fairly easy to screw things up in subtle ways when exceptions come into play
11:51:15 <dmwit> Yes, I agree with everything said there.
11:57:55 <jpg> when you write a function the compiler can infer a type with
11:57:55 <jpg> complicated constraints, when you write a class you put the type
11:57:55 <fresheyeball> hamishmack: you around?
11:57:55 <jpg> on each method signature.
11:57:56 <jpg> Suppose I want to write an instance where a method needs additional
11:57:56 <jpg> restrictions, inferable by the compiler, but I do not want to annotate them,
11:57:56 <jpg> Is this possible?
11:58:09 <fresheyeball> I need some quick advice on how to serve static assets along side jsaddle-warp
11:58:45 <merijn> jpg: You can constrain the entire instance
11:58:58 <fresheyeball> anyone here done that?
11:59:09 <jpg> for example, if I want to implement a Show instance using a function foo:: Blah a => a -> String
11:59:15 <merijn> jpg: If you have a function "Foo a => Bar -> a -> Quux" you can't magically add any constraints inside your class implementation
11:59:37 <merijn> jpg: For some specific type 'a', you mean?
11:59:42 <jpg> yes
11:59:56 <jpg> a is not a variable
12:00:12 <merijn> jpg: then the "Blah" constraint is redundant :p
12:00:52 <merijn> jpg: If you're trying to, e.g. implement Show for "Foo" using a function from class 'Blah' you can "just use it" if "Foo" is an instance of Blah
12:02:11 <dmwit> jpg: Can you give a small example of something you wished work but doesn't?
12:02:18 <jpg> correct, I was confused, a is actually polymorphic
12:02:20 <dmwit> jpg: Use an online pastebin and send us a link.
12:02:50 <dmwit> (Bonus points for including the error message.)
12:05:22 <merijn> jpg: If 'a' is polymorphic you can constrain the instance
12:06:01 <merijn> jpg: So suppose I wanna make a "Show" instance for "Foo a" that uses the fact that 'a' is an instance of "Blah" you can write the following: "instance Blah a => Show (Foo a) where..."
12:06:14 <jpg> I'm trying to make a smaller example than my code 
12:06:21 <merijn> jpg: Which basically says "Foo a" has a show instance IFF 'a' has a Blah instance
12:07:11 <jpg> yes, constraining the instance is the way to go, but the problem is that I have to annotate all the constraints, constraints are actually HUGE
12:08:47 <merijn> jpg: ConstraintKinds extension lets you define a constraint alias using type aliases
12:09:16 <merijn> jpg: So you can write "type Foo a = (Show a, Read a, Eq a, ...)" and then use "Foo a" as constraint on functions/classes
12:10:01 <Bish> dmwit: that mvar approach is vor not letting main "exit"?
12:13:25 <Cale> You can also, without the need for ConstraintKinds, just invent a class that has all your constraints as a superclass, and then a totally general instance of it.
12:13:47 <Cale> This is something that I often forget about, but it actually has better properties than a type synonym in some cases.
12:13:47 <jpg> merijin: I was thinking that a solution was to write a type level computation to compute the constraints (using constraintkinds), this will be ok since the user of the library can define new instances without taking care of the constraints.
12:13:51 <jpg> The problem is
12:14:48 <Solonarv_> Bish: yes, you can use MVars to make 'main' wait until all the subcomputations are finished
12:15:30 <Solonarv_> dmwit: there are a few libraries generalizing 'filter' (or 'mapMaybe')
12:16:13 <jpg> Constraints here are not actually fixed, they depend on the thing you are defining, I can encode them with a type family, but now the compiler can infer the constraints silently (with no typeclass, defining the function each time)
12:17:31 <Cale> jpg: Can you perhaps provide a concrete example of the sort of case you're dealing with?
12:17:45 <jpg> http://www.cs.ru.nl/~W.Swierstra/Publications/AttributeGrammarsFly.pdf
12:17:59 <jpg> I'm working with a modern implementation of that library
12:18:32 <Cale> I have some nice things for working with constraints that arise from wanting to constrain all the possible index types on a GADT
12:18:54 <Cale> https://github.com/obsidiansystems/constraints-extras
12:19:35 <jpg> Now I want to use EADTs, because the way we actually use to add new productions is not as good
12:19:50 <Cale> You can say things like "Given a value of type f a, we can show that there is an instance of c (g a)"
12:20:22 <jpg> to define semantic functions over an EADT I want a class like, suppose
12:20:33 <isn> hi
12:20:38 <Cale> hello!
12:20:50 <isn> someone here who is good with math and want to help me with understanding fibonacci in Haskell?
12:20:53 <jpg> class Sem f where sem :: Record r -> f -> Attribution ip -> Attribution sp
12:21:08 <Bish> how do i get "chunks" out of a list?
12:21:08 <Cale> isn: I'm sure many of us would be happy to answer questions about it :)
12:21:16 <Bish> like, every 4?
12:21:31 <isn> nice Cale :), here it goes:
12:21:42 <Cale> Bish: With just the base library, you can write  map (take 4) . takeWhile (not . null) . iterate (drop 4)
12:21:52 <Cale> Bish: There's also a nice library called 'split'
12:22:08 <Cale> jpg: Okay...
12:22:13 <isn> I'm following seven languages in seven weeks and I'm stuck with understanding very basic fibonacci function. The book instructed me to type out this:
12:22:14 <jpg> where f is an EADT constructor. The problem is that the semantic functions have a huge number of constraints about the grammar shape, that now the compiler infers
12:22:15 <isn> module MainModule where
12:22:15 <isn>     fib :: Integer -> Integer
12:22:15 <isn>     fib 0 = 1
12:22:17 <isn>     fib 1 = 1
12:22:19 <isn>     fib x = fib (x - 1) + fib (x - 2)
12:22:50 <isn> I'm not sure what I have to do with the answer I get from calling the function. If I do fib 5, I only get 8
12:23:09 <Cale> isn: A little note: it's extremely weird to indent an entire module like that, most people avoid that initial bit of indentation
12:23:12 <isn> does this mean that I only get the next number in the fibonacci sequence?
12:23:29 <Cale> isn: It's calculating whichever element of the sequence you ask for
12:23:32 <isn> Cale: oh, could you give an example of the indentation?
12:23:46 <Cale> isn: I mean that initial 4 spaces on each of the lines there
12:23:54 <Cale> It's unnecessary
12:24:21 <isn> ah, visual studio code does that automatically for me. i've installed a haskell plugin :p
12:24:25 <Cale> ah
12:24:30 <Cale> weird :P
12:24:31 <Solonarv_> oh yeah that annoys me too
12:24:49 <isn> I probably could turn that off tho 
12:24:49 <Cale> I guess it's because we're theoretically inside a 'where' clause
12:24:54 <isn> yeah I guess
12:24:54 <Cale> but everyone ignores that where clause
12:25:23 <Cale> But yeah, that's just a minor syntactic thing. It doesn't harm anything :)
12:25:37 <monochrom> fib n give the nth Fibonacci number.
12:25:38 <isn> but anyway, would you want to break down how the function works when calculating?
12:26:09 <Cale> So, if you apply fib 5, it's going to reduce to fib 4 + fib 3
12:26:24 <Cale> and then fib 4 will reduce to fib 3 + fib 2
12:26:35 <isn> oh, the number we give to the function is actually the "index" or something in the sequence right?
12:26:40 <Cale> yeah
12:26:48 <isn> aah lol, that makes sense :p
12:27:02 <isn> got a tunnel vision for some reason lol
12:27:18 <Cale> This is a very inefficient algorithm for computing the Fibonacci sequence
12:27:47 <Cale> because it's producing an expression which does O(fib n) additions
12:27:55 <monochrom> I believe that these days everyone suffers tunnel vision because they're addicted to their phones 16 hours a day.
12:28:01 <Cale> haha
12:28:08 <Cale> GLOWING RECTANGLES
12:28:32 <isn> *_*
12:29:39 <Cale> The pinnacle of human goals is to experience as many glowing rectangles for as much of the time as possible.
12:29:47 <isn> Cale: it's inefficient because it called the function recursively twice?
12:29:55 <Cale> isn: Pretty much.
12:30:20 <isn> ok nice, thanks!
12:30:47 <Cale> isn: But really, it's that in the end, you're adding up a bunch of 0's and 1's, and not really getting to share any of the work of computing earlier fib's
12:30:57 <Cale> Like, if we look at that fib 5 example
12:31:15 <Cale> We get fib 4 + fib 3 on the initial reduction step
12:31:32 <Cale> and then while we're in the process of evaluating fib 4, we're going to end up evaluating fib 3
12:31:46 <Cale> but by the time we've computed fib 4, we'll have forgotten that result
12:31:54 <Cale> and will end up recomputing fib 3 again
12:32:33 <isn> uhm, not sure if I understand that correctly. isn't it calculating it both at the same time?
12:33:10 <Bish> if i have "passwordsOfLength" with "map passwordsOfLength [1..2]"
12:33:10 <monochrom> No, that code isn't parallelized.
12:33:15 <Bish> how can i concat those resulting list?
12:33:17 <Bish> reduce with ++?
12:33:22 <Bish> pardon, fold?
12:33:40 <Cale> For a simpler example, if we were to write:
12:33:46 <isn> hmm, how would I make it paralel?
12:33:47 <Cale> double x = x + x
12:33:48 <Cale> and then
12:33:48 <monochrom> Not that parallelization would magically help. You would need exponentially many cores to parallelize.
12:34:01 <Cale> quadruple x = double x + double x
12:34:18 <Cale> This would do the work of computing double x, twice, every time
12:34:41 <Cale> It would be more efficient if we wrote  quadruple x = y + y where y = double x
12:35:09 <Cale> Bish: There's a function 'concat'
12:35:12 <Cale> :t concat
12:35:13 <lambdabot> Foldable t => t [a] -> [a]
12:35:20 <Cale> lol, of course :)
12:35:35 <Cale> You can think of that as [[a]] -> [a]
12:35:43 <monochrom> There is also concatMap. There is also list comprehension.
12:35:47 <Cale> yep
12:36:27 <Cale> isn: In the case of fib, if we want to avoid redoing work, it helps to keep track of the last couple of results as we go
12:37:27 <isn> alright, thanks for the explanation. I don't really understand this yet: You can think of that as [[a]] -> [a] - but that's maybe because I'm still early in the book
12:37:29 <Cale> isn: We can do this by writing a function which takes the "initial" elements of the sequence (in the case of the Fibonacci sequence, 1 and 1), and does the following sort of thing:
12:37:39 <Cale> isn: Sorry, that was aimed at Bish's question
12:37:49 <isn> ah ok, nvm :)
12:37:57 <Cale> lucas a b 0 = a
12:38:10 <Cale> lucas a b n = lucas b (a+b) (n-1)
12:38:25 <Cale> fib = lucas 1 1
12:38:31 <isn> those are tuples right?
12:38:36 <Cale> no tuples
12:38:43 <Cale> just parenthetical expressions
12:38:50 <Cale> and multiple parameters to the lucas function
12:39:30 <Cale> lucas takes three arguments: the two initial elements of our sequence, and which element of the sequence we're interested in obtaining
12:39:55 <Cale> A Lucas sequence is like the Fibonacci sequence, except that instead of starting with 1 and 1, it might start with another two elements
12:40:34 <Cale> and here we're taking advantage of the fact that the nth element of the Lucas sequence that starts with a and b is the same as the (n-1)th element of the Lucas sequence that starts with b and (a+b)
12:41:13 <Cale> lucas a b n = lucas b (a+b) (n-1) -- that's what this equation says
12:41:27 <Cale> lucas a b 0 = a -- this special case lets us stop recursing
12:42:12 <Cale> (The equations are tried in order, and we take the first one which matches, as in your previous definition of fib)
12:43:12 <isn> oh nice, this is a bit more advanced than what I had. I'll have to read it over a couple of times lol. Thanks
12:43:18 <isn> Now I got another question 
12:43:29 <Bish> is there a nice function for hash to bytestring :o
12:43:37 <Bish> hex*
12:43:50 <isn> fib = lucas 1 1 - would the fib function need more params?
12:44:15 <Cale> isn: We are defining a function there because there aren't quite enough params :)
12:44:41 <Cale> isn: In Haskell, whenever we write
12:44:43 <Cale> f x y z
12:44:52 <Cale> It really means ((f x) y) z
12:45:20 <Cale> Functions all secretly have exactly one argument, and those which appear to take more are just producing another function
12:45:52 <Cale> So, when I wrote lucas 1 1, that's the function which will take another argument, say n, and give us lucas 1 1 n
12:46:02 <Cale> and I can just define fib to be that function
12:46:16 <Cale> We could also be more explicit about it if we want, and write
12:46:20 <Cale> fib n = lucas 1 1 n
12:46:37 <isn> ahh lol
12:46:43 <Cale> (but then I wouldn't have had the opportunity to point that out ;)
12:47:03 <isn> yeah, thank you very much this really helps :)
12:47:43 <isn> i would however think that when I call the fib function I would have to do something like this: fib = lucas 1 1 a
12:47:56 <Cale> When you apply the fib function to a number
12:48:02 <Cale> like say  fib 5
12:48:09 <Cale> that will evaluate to  lucas 1 1 5
12:48:16 <isn> so it put it at the end
12:48:30 <Cale> Well, let's put in the parens:  (lucas 1 1) 5
12:48:45 <isn> would this work? fib x = lucas 1 1 x
12:48:49 <Cale> yes
12:49:17 <isn> hm
12:49:35 <Cale> Let's do a simpler example
12:49:46 <Cale> Suppose we have  add a b = a + b
12:49:52 <isn> what is the reason that you created that function without defining a new variable?
12:49:53 <isn> ok :)
12:49:55 <Cale> I can then define
12:49:59 <Cale> addFive = add 5
12:50:05 <Cale> Let's use the bot :)
12:50:09 <Cale> @let add a b = a + b
12:50:11 <lambdabot>  Defined.
12:50:16 <isn> oh wwo
12:50:16 <isn> wow
12:50:19 <Cale> @let addFive = add 5
12:50:20 <lambdabot>  Defined.
12:50:27 <Cale> > addFive 10
12:50:30 <lambdabot>  15
12:51:22 <Cale> So it goes  addFive 10 -> (add 5) 10 -> 5 + 10 -> 15
12:51:56 <Cale> and remember that when we write add 5 10, that means exactly the same thing as (add 5) 10
12:52:06 <Cale> function application associates to the left
12:52:29 <isn> alright, I get it thanks. but what's the point of doing it like this?
12:52:36 <Cale> This is really convenient when you start using higher order functions -- ones which accept other functions as parameters
12:52:37 <isn> It's much more readable when we define the var next to it
12:52:56 <Cale> For example, perhaps I want to add 1 to a whole list of numbers, using the map function
12:52:56 <__monty__> isn: It's not once you get used to it.
12:53:03 <Cale> > map (add 1) [10,20,30]
12:53:04 <__monty__> The name just becomes noise.
12:53:06 <lambdabot>  [11,21,31]
12:53:30 <Cale> It's really because we're constantly using higher order functions that this "currying" is helpful
12:53:56 <Cale> (Currying being the process of taking a function of multiple parameters and turning it into one which has a single parameter and produces another function)
12:55:06 <isn> alright, thanks :)
12:55:06 <Cale> Functions in Haskell are just automatically already in their curried form by default. Functions which accept tuples of arguments are comparatively rare.
12:55:16 <isn> btw, how did map work?
12:55:31 <isn> I mean the add fucntion, that's the one you defined earlier right?
12:55:36 <Cale> yeah
12:55:44 <Cale> map is a standard function which takes a function and a list, and applies that function to each of the elements of the list
12:55:47 <isn> then it does add 1 10
12:55:48 <isn> add 1 20
12:55:49 <isn> add 1 30
12:55:50 <Cale> yeah
12:55:53 <Cale> exactly
12:56:01 <Cale> map :: (a -> b) -> [a] -> [b]
12:56:04 <Cale> map f [] = []
12:56:11 <Cale> map f (x:xs) = f x : map f xs
12:56:17 <Cale> [] is the empty list
12:56:34 <Bish> how does one profile haskell? i mean.. how do i add counters to a function, so i know how often it gets called
12:56:35 <Cale> (x:xs) is the list which starts with some element x and continues with another list of elements xs
12:56:51 <Cale> Bish: You can compile with -prof -fprof-auto
12:57:08 <Cale> Bish: and then run your program with the commandline arguments +RTS -p
12:57:42 <Cale> Bish: and that will produce a .prof file that shows how many times every definition was entered, and how much time and allocation was done
12:58:10 <isn> starts and continues?
12:58:15 <Bish> cool
12:58:18 <Cale> Bish: There's a lot more profiling you can do, I highly recommend checking out the GHC User's Guide for more details as well
12:58:34 <Bish> ByteString.pack (map (fromIntegral.ord) "nY")
12:58:39 <Cale> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#profiling
12:58:39 <Bish> http://dpaste.com/2FV8298
12:58:49 <Bish> this is my approach to sha1 cracking... critism is welcome
12:59:02 <Bish> my next stap will be MVars & green threads and wait for them to finish
12:59:10 <Bish> then i will filter them and only print results
13:00:09 <Cale> Just a tiny thing, you have parens around hash there which don't do anything
13:00:23 <Bish> yeah i get that :)
13:01:25 <isn> brb
13:01:28 <Cale> You might also want to try pure parallelism
13:01:49 <Bish> Cale: like "par"?
13:02:14 <Cale> http://hackage.haskell.org/package/parallel-3.2.2.0/docs/Control-Parallel-Strategies.html#v:parListChunk
13:02:15 <Cale> yeah
13:04:22 <fen> https://pastebin.com/raw/A4qyHP2J
13:04:33 <Cale> print $ withStrategy (parListChunk 1000 rseq) result
13:04:52 <fen> does this need data families?
13:05:13 <Cale> fen: What's the definition of S1?
13:05:25 <Cale> oh, that type family
13:05:38 <Cale> Well, you have that parameter to the type family there
13:05:57 <Cale> type families, like type synonyms, must be fully applied
13:06:14 <fen> type family S1 (n :: Nat1) :: Nat1 where  S1 n = '() : n
13:06:27 <Bish> Cale: do i have to import that?
13:06:43 <Cale> Bish: yeah,  import Control.Parallel.Strategies
13:06:55 <fen> Cale: right, so it requires refunctionalising right? so should it just use datatype families directly
13:06:56 <fen> ?
13:06:57 <Bish> not a base package as it seems
13:07:03 <Cale> oh, interesting
13:07:43 <Cale> They must have moved it out of the set of packages that come with ghc
13:07:51 <fen> defunctionalising* 
13:07:59 <Cale> fen: Possibly? I'm not sure what you're trying to do
13:08:13 <isn> i've gotta go, thank you for all the help you guys. I feel a bit smarter ;)
13:08:13 <Cale> fen: Type lambda is impossible though :)
13:08:31 <Cale> isn: Yeah, feel free to hang around and ask questions any time :)
13:08:31 <fen> provide a defunctionalised associated type family
13:08:37 <isn> thanks! :)
13:08:40 <isn> cyaa
13:09:36 <Cale> fen: Well, to what end?
13:09:44 <fen> like, there has to be a datatype somewhere
13:09:58 <fen> but does it go at the type family or some other place
13:10:25 <fen> that seems like the last possible point to defer it to
13:10:45 <Cale> I'm not sure I get it
13:11:20 <Cale> I don't know, I usually start with programs that do something useful, and then figure out the abstractions I'll need to make them nicer after the fact
13:11:35 <fen> well data Nat = S Nat | Z has a type level incrament function `S'
13:11:42 <Cale> This all feels a bit premature to be able to shape what it is that we're trying to do
13:11:45 <fen> but [()] does not
13:12:04 <Cale> ah, okay
13:12:13 <fen> to use S in a type signature for type Nat = [()] it should be a data family? 
13:12:29 <Cale> Well, it clearly can't be a data family
13:12:46 <fen> or a type family
13:12:59 <fen> there is seemingly no way to make a synonym for ()' :
13:13:12 <fen> ('() :)
13:13:33 <Cale> Perhaps (:) ()
13:13:55 <Cale> @undefine
13:13:55 <lambdabot> Undefined.
13:13:59 <fen> :t (':) '()
13:14:00 <lambdabot> error: parse error on input ‘:’
13:14:02 <Cale> @let type S = (:) ()
13:14:03 <lambdabot>  Defined.
13:14:18 <Cale> @let type Z = []
13:14:19 <lambdabot>  Defined.
13:14:24 <Cale> oh, oops
13:14:26 <Cale> hahaha
13:14:35 <Cale> @undefine
13:14:35 <lambdabot> Undefined.
13:14:41 <Cale> @let type S = (:) ()
13:14:42 <lambdabot>  Defined.
13:14:47 <Cale> @let type Z = '[]
13:14:48 <lambdabot>  Defined.
13:15:00 <Cale> :k S (S (S Z))
13:15:01 <lambdabot> [*]
13:15:40 <Cale> So we could do that as a type family, if you like
13:16:32 <Cale> Where we have a  type family S k :: k -> k
13:17:11 <Cale> and then have a  type instance S [*] = (:) ()
13:17:31 <Cale> or perhaps that was meant to be ['()] or something
13:17:34 <d34df00d> Hi!
13:17:34 <Cale> but yeah
13:17:43 <Cale> Hello!
13:18:11 <d34df00d> I'm going through Okasaki's "Purely functional data structures", and as part of that I'm curious about relative benchmarking different algorithms/modifications he suggests in the exercises/etc.
13:18:26 <fen> https://pastebin.com/raw/kwRTFDMv
13:18:31 <d34df00d> What's the best way to generate arbitrary data QuickCheck-style and feed it to some benchmarking framework (I only know of criterion, but maybe there are better ones)?
13:18:42 <Cale> fen: ah, yeah, might need to '()
13:18:57 <fen> yay!
13:19:17 <fen> how did that work!?
13:19:29 <fen> it is defunctionalised but as a type synonym somehow?
13:20:09 <fen> ohhh, it uses the list as the datatype... like (:) as a data-constructor can be partially applied
13:20:17 <fen> nice thanks
13:20:22 <nshepperd> it's ('() :) but not a section
13:20:23 <Cale> fen: Yeah, that (:) is lifted
13:20:33 <Cale> and yeah, partially applied
13:20:41 <nshepperd> because sections aren't a thing for type operators i guess
13:21:31 <fen> type lambdas are break haskell apparently
13:22:32 <merijn> fen: They make type checking Turing complete, as opposed to the current total/finite evaluation
13:22:55 <merijn> fen: Then again, UndecidableInstances also breaks the decidability of type checking
13:24:44 <Cale> But there's also a lot of ugly questions to be answered about how type lambdas should interact with all the other features of Haskell's type system
13:25:02 <merijn> that too
13:25:04 <Cale> Like, are they allowed in instance heads? How do they interact with type inference?
13:25:28 <Bish> stupid questions can you have thread "accellerated" lists?
13:25:30 <fen> but are these questions without a solution, or is it just difficult?
13:25:33 <Cale> It's difficult to answer either of those with anything close to "yes"
13:25:35 <Bish> while the code working on that list is single threaded?
13:26:09 <Cale> Bish: That's not a stupid question
13:26:30 <Cale> Bish: People have worked very hard in the past to try to create a data parallel Haskell.
13:26:52 <Cale> Bish: It turns out to be *very* tricky to do it in full generality
13:27:15 <Cale> But I still highly recommend looking up the talks on it, because they're very interesting and tantalising
13:27:33 <Cale> https://www.youtube.com/watch?v=kZkO3k9g1ps
13:28:14 <Bish> so is that a yes :D?
13:29:13 <Cale> Well, it never really fully materialised, sadly
13:29:21 <jacker[m]> Anyone uses nextcloud with fediverse or federation stuffs?
13:29:25 <Cale> But it did get part of the way
13:29:36 <Bish> yay, my code found a match
13:29:39 <Cale> I don't know how much of it is still in a maintained form
13:29:44 <Cale> haha, nice
13:29:53 <Bish> [("nY","\a\159\129\145\254/\196\176\ESC\182AP\131\219.\212\129\183\236\&2")
13:30:08 <Cale> Lucky break on the 2 character password
13:30:14 <Cale> LOL
13:30:21 <Bish> :D
13:30:26 <Cale> Did the parallelism seem to help?
13:30:31 <Bish> its the homework of my girlfriend
13:30:35 <Cale> ahh, cool
13:30:35 <Bish> and i was like " i got this"
13:30:48 <Bish> and i was surprised to see, that i cannot get a sha1 cracker without:
13:30:52 <Bish> using existing tools
13:30:54 <Bish> writing c
13:31:04 <Bish> so i figured, could try haskell
13:31:21 <Bish> still frustrated, though
13:31:53 <fen> whats that the output of some kind of lexer?
13:32:05 <fen> romantic! 
13:32:09 <nshepperd> if you just want to parallelize list evaluation thats pretty straightforward
13:32:14 <Cale> fen: It's a password and its hash
13:32:31 <Bish> why is my code eating so much ram?
13:32:32 <Cale> fen: a hash that apparently matches the one being searched for
13:33:15 <Cale> Bish: Well, you do have a lot of lists... and is this the parallelised version?
13:33:22 <Bish> no, not yet
13:33:46 <Bish> but its slower than my ruby version, and eats my ram
13:34:35 <Cale> Oh, btw, there's Data.ByteString.Char8
13:34:43 <monochrom> What do you use for "strings"? That can matter.
13:34:46 <Cale> which you can use to pack strings in the way you're doing
13:34:58 <monochrom> It matters for eating RAM.
13:35:13 <Cale> It might be worthwhile however, to generate ByteStrings somewhat more directly somehow.
13:36:20 <remexre> is there a Prism' a b -> Getter a (Maybe b) function, and is there a good way to search for things like these in general? Hoogle isn't incredibly helpful (I think because of all the aliases)
13:36:35 <Cale> Bish: It's also important to be careful about what might be retaining stuff in memory longer than needed.
13:37:13 <Cale> remexre: uhhh... are you sure you can't just use a Prism as a Getter like that?
13:37:43 <remexre> ...you're right, I can
13:37:51 <Cale> > view _Just (Just 5)
13:37:53 <lambdabot>  error:
13:37:53 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M379253615342...
13:37:53 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
13:37:54 <remexre> I'm also having a hard time with all the aliases :P
13:37:55 <Cale> oops :)
13:37:58 <Cale> yeah
13:38:12 <Bish> even crashed it :(
13:38:33 <Bish> my machine, that is
13:38:38 <monochrom> It takes a huge UML diagram to chart all those types in lens.
13:38:48 <Solonarv_> you can only use a Prism as a getter directly if the target is a monoid
13:38:54 <Solonarv_> (if it isn't there, you get back mempty)
13:38:58 <Bish> http://dpaste.com/2WH4CDR
13:39:00 <Bish> that sucks.
13:39:20 <Bish> i mean shouldnt haskell know that it can throw away the list?
13:39:47 <Cale> Bish: It might, but you need to be careful :)
13:39:49 <nshepperd> > Just 5 ^? _Just
13:39:50 <lambdabot>  Just 5
13:39:54 <nshepperd> gasp
13:39:57 <monochrom> That can depend on tiny details of your code.
13:40:10 <Cale> nshepperd: Right, it's review, I think
13:40:12 <Bish> well, thats what haskell gets advertised with.. often :/
13:40:17 <Bish> being memory efficient like, by default
13:40:22 <Solonarv_> it's preview
13:40:32 <Cale> preview, that's right
13:40:40 <Solonarv_> > preview _Left (Right 43)
13:40:42 <lambdabot>  Nothing
13:40:42 <monochrom> Sorry but I've never heard of that kind of advertisement.
13:40:57 <Solonarv_> review is for using a prism as a constructor
13:41:02 <Solonarv_> > review _Right 3
13:41:03 <monochrom> In fact the advertisement I've always heard is that [Char] takes too much space.
13:41:04 <lambdabot>  Right 3
13:41:18 <shapr> monochrom: lenses will solve all your problems!
13:41:21 * shapr advertises to monochrom
13:41:24 <Bish> so how can i tell what part of that is eating allmymem.jpg?
13:41:48 <Cale> Bish: On the contrary, one of the major negative points about Haskell that always comes up (and which I think is actually somewhat unfair) is that it's hard to understand the space usage of programs.
13:42:22 <Cale> It is hard, when you're starting out, because the machine model is strange, so most of your intuitions will be wrong.
13:42:38 <Bish> yeah i get that, i expected similiar things somewhere
13:42:40 <nshepperd> the haskell GC is very efficient and ruthlessly throws away things that aren't needed any more
13:42:43 <Bish> but not in this example
13:42:57 <monochrom> How long is a password?
13:42:57 <Bish> nshepperd: doesn't look to me like it does :p
13:43:03 <nshepperd> the problem is that sometimes things are still needed because something involving them hasn't been evaluated yet
13:43:09 <Bish> monochrom: that one has.. 4 chars? i think
13:43:13 <Cale> Bish: btw, how are you compiling this?
13:43:14 <remexre> Solonarv_: is there a way around that Monoid bound?
13:43:22 <Bish> Cale: no, i mean yes, runhaskell
13:43:22 <Cale> Bish: Make sure to compile with -O or -O2
13:43:32 <monochrom> Actually if you're parallelizing... How many passwords are there to try?
13:43:46 <Bish> no parallelization yet
13:43:49 <Solonarv_> yes: use preview / (^?), or toListOf / (^..), or something similar
13:43:56 <Cale> Bish: The performance of interpreted Haskell is all over the place and fairly meaningless
13:44:16 <monochrom> Wait you are not compiling?!
13:44:21 <nshepperd> is runhaskell interpreted?
13:44:24 <Cale> yes
13:44:25 <monochrom> Yes.
13:44:31 <Bish> lul.. yeah the compiled version
13:44:32 <nshepperd> that's annoying
13:44:35 <Bish> takes no ram at all
13:44:38 <Cale> haha, right
13:44:45 <Solonarv_> but to answer your original question:
13:44:45 <Solonarv_> :t to . preview :: Prism s t a b -> Getter s a
13:44:46 <lambdabot> error:
13:44:46 <lambdabot>     No instance for (Contravariant f)
13:44:46 <lambdabot>       arising from an expression type signature
13:44:46 <Cale> That problem is solved then :D
13:44:51 <fen> Cale: hows about this: https://pastebin.com/raw/3gT0nzrR
13:44:53 <monochrom> Ticket closed.
13:44:54 <Bish> well, now it does, i might be wrong, but its certainly less
13:44:56 <fen> "bounded nats"
13:45:07 <Solonarv_> :t to . preview :: Prism s t a b -> Getter s (Maybe a)
13:45:08 <lambdabot> error:
13:45:08 <lambdabot>     • Couldn't match type ‘b1’ with ‘a1’
13:45:08 <lambdabot>       ‘b1’ is a rigid type variable bound by
13:45:13 <Bish> hm.. but it's rather slow, also
13:45:15 <Solonarv_> bah
13:45:36 <fen> does it have the same kind of problem as if you used LList for defining Nat, like a dounble redundant nat...
13:45:40 <Solonarv_> > Right 43 ^. (to . preview) _Right
13:45:42 <lambdabot>  Just 43
13:45:42 <mud> Stack's script interpreter mode thing can compile and optimize and still be easy to run
13:45:51 <Solonarv_> haha, victory!
13:45:54 <remexre> lol
13:46:01 <remexre> alright, thanks!
13:46:02 <Bish> nope, still eating my ram :(
13:46:12 <Cale> ah, okay
13:46:16 <monochrom> Where is "combo" defined?
13:46:20 <Cale> Let's try some stuff
13:46:26 <Cale> monochrom: it's right there
13:46:27 <Bish> combo n m = replicateM n m
13:46:28 <Cale> It's replicateM
13:46:31 <Solonarv_> cabal's script interpreter thingy also compiles & optimizes, by the way
13:46:37 <Bish> lol.. yeah right it is
13:46:39 <monochrom> Darn tunnel vision.
13:46:41 <Bish> didnt even notice
13:47:12 <Bish> hm.. i think i know what the problem is
13:47:27 <Bish> all_passwords.. is concatinating all the passwords.. in order to be able to do that
13:47:29 <fen> wait maybe thats not the right BoundedList...
13:47:40 <Bish> he has to keep the passwords of length 1,2,3,4,
13:48:00 <Bish> while not even needed any longer?
13:48:45 <Cale> Not necessarily, but I'd be tempted to rewrite the program in a way that made it more obvious that these big lists are only consumed in one place
13:49:23 <Cale> We should also do a bit of space profiling
13:49:26 <monochrom> How much space is it using?
13:49:40 <Bish> as far as i can tell limitless
13:49:54 <Bish> 16G+
13:50:48 <monochrom> Yeah I'm a bit surprised too, this code looks like O(1)-space.
13:50:50 <Bish> but if it was atleast quick.. i'd be happy
13:50:59 <Bish> but it's not even that
13:53:06 <Bish> okay, so i can go to sleep well
13:53:20 <Bish> how would you guys create all passwords of an alphabet between length of 1..8
13:53:44 <Cale> It seems to complete some initial phase of the computation, and then begin to use lots of memory in the form of lists, very quickly
13:54:14 <glguy> do n <- [1..8]; replicateM n ['a'..'c'] -- example
13:54:19 <Bish> the filter expression will only get evaluated once, right?
13:54:22 <glguy> > do n <- [1..8]; replicateM n ['a'..'c'] -- example
13:54:23 <lambdabot>  ["a","b","c","aa","ab","ac","ba","bb","bc","ca","cb","cc","aaa","aab","aac",...
13:54:34 <Bish> glguy: shit thats clever.
13:54:45 <Cale> It's essentially the same thing you're doing
13:54:50 <Bish> i know that
13:55:03 <Bish> i spent a lot of weeks into understanding monadic bind
13:55:06 <Cale> you have a concatMap which is the same thing as (>>=) for the list monad
13:55:29 <Cale> I could possibly help explain that, but let's debug this performance issue first
13:55:41 <Bish> it was a really happy day, when understanding why filterM (const [True,False]) [1,2,3] works
13:55:42 <Cale> Compile your program with -prof -fprof-auto
13:55:46 <glguy> I hadn't read far enough back to see the whole conversaion
13:55:49 <glguy> I only saw the question
13:56:03 <Cale> and then run it with +RTS -p -hy
13:56:54 <Bish>     Failed to load interface for ‘Crypto.Hash.SHA1’
13:57:03 <Bish> when trying to compile with those flags
13:57:21 <Cale> Ah, perhaps you don't have the cryptohash package built with profiling support
13:57:22 <Bish> fuck i need to compile those packages with -profile
13:57:43 <Cale> I don't suppose you have nix? :)
13:57:50 <Bish> gentoo
13:57:59 <Bish>     Failed to load interface for ‘Data.List.Split’
13:58:04 <Bish> i never installed that though
13:58:07 <Cale> Well, I'm running Linux Mint, and have the nix package manager anyway
13:58:12 <Bish> but i have installed ghc with profile
13:58:18 <Cale> because it's so useful for dealing with Haskell builds
13:58:44 <nshepperd_> That reminds me, how do i get profiling with cabal new-install --lib
13:59:23 <Cale> For example, I was able to use:
13:59:25 <Cale> nix-shell -p 'haskellPackages.ghcWithPackages (pkgs: with pkgs; [ cryptohash split ])'
13:59:40 <Cale> to get into a shell with ghc installed, and the requirements for building your program :)
14:00:01 <Bish> glguy: but when saying that, you mean inside a list syntax way, right?
14:00:12 <Bish> [ y | x <- [1..8], y <- replicateM x ['a'..'z'] ]
14:00:14 <Bish> this right?
14:00:26 <Cale> (The nixpkgs library leaves a lot to be desired in terms of ease of understanding, but it is quite handy once you know how to do particular things)
14:04:03 <monochrom> It is possible that this is exactly what Oleg complained about several years ago how full laziness retains unnecessary data.  (This "full laziness" means too much memoization.)
14:05:43 <Bish> after removing the filter it seems not to have that much ram
14:05:53 <Bish> could it be the GC does not walk over a not yet filtered list?
14:06:03 <monochrom> No.
14:06:47 <monochrom> Because I'm doing a much simpler experiment.  main = mapM_ putStrLn [ y | x <- [1..8], y <- replicateM x alphabet ]
14:06:54 <monochrom> And it still grows memory.
14:07:00 <Bish> also not becaus ei am showing it?
14:08:23 <monochrom> Oh wait I was not even running that simpler program.
14:08:40 <fen> % @let type Z = '[]
14:08:40 <yahb> fen: ; <interactive>:63:1: error: parse error on input `@'
14:08:44 <fen> % let type Z = '[]
14:08:45 <yahb> fen: ; <interactive>:64:5: error: parse error on input `type'
14:08:50 <fen> !!
14:10:14 <fen> @let type Z = (True ~ True) => '[]
14:10:15 <lambdabot>  .L.hs:158:27: error:
14:10:15 <lambdabot>      • Expected a type, but ‘'[]’ has kind ‘[k0]’
14:10:15 <lambdabot>      • In the type ‘(True ~ True) => '[]’
14:10:25 <fen> @let type Z = '[]
14:10:27 <lambdabot>  Defined.
14:10:53 <fen> thats the error
14:11:37 <fen> the constraint needs the type synonym to be of kind * ?
14:11:48 <Bish> well thanks either way, im heading to bed!
14:11:53 <Bish> gn folks
14:12:02 <HenryCH> i have two Ints x and y, i'd like to make a range [x, x+0.1..y] but that doesnt compile, what's the cleanest way to do this?
14:12:03 <Cale> Bish: I'll see if I can figure it out
14:12:17 <Bish> Cale: i would be grateful, this nick is idling :)
14:12:22 <Cale> okay, cool
14:12:33 <fen> HenryCH: use Doubles instead of Ints?
14:12:35 <Bish> maybe its just a huge list in ram and i demand too much of haskell :p
14:12:48 <Solonarv_> fen: yes; you can think of => as an operator (=>) :: Constraint -> Type -> Type, similar to (->) :: Type -> Type -> Type
14:13:19 <Cale> Bish: But yeah, at first blush, it does appear that all the space is used by CAFs (i.e. top level constants)
14:13:34 <Solonarv_> (it isn't actually an operator, but it behaves like one in some ways)
14:13:43 <HenryCH> the function must take 2 ints
14:13:44 <Cale> So it's probably the compiler lifting that list of passwords up and out of the computation.
14:14:14 <Solonarv_> HenryCH: you can convert them to doules (or floats, or whatever) using fromIntegral
14:14:20 <benzrf> % :k (=>)
14:14:20 <yahb> benzrf: ; <interactive>:1:2: error: parse error on input `=>'
14:14:22 <benzrf> :[
14:14:30 <monochrom> Cale, a simple "main = mapM_ putStrLn (replicateM 8 ['a'..'z' ])" already grows.
14:14:35 <Cale> yes
14:14:49 <fen> HenryCH: then you need to cast from Int to be able to do (+0.1)
14:14:49 <Cale> What if we compile with -fno-full-laziness ?
14:14:56 <monochrom> No difference.
14:14:59 <Cale> hmm
14:15:06 <HenryCH> so [fromIntegral x, (fromIntegral x + 0.1).. fromIntegral y] ?
14:15:12 <fen> yeah
14:15:21 <fen> well, not on the Double
14:15:25 <HenryCH> thought there might be a simpler way
14:15:32 <fen> no
14:15:36 <Cale> ohhh... hmm... I wonder
14:16:27 <fen> Solonarv: then how can the constraint thing be used on the Nats?
14:16:56 <fen> does it need to have some other way to check the lengths not using a constraint?
14:17:57 <fen> :t \x y -> let (x',y') = (fromIntegral x,fromIntegral y) in [x,x+0.1 ..y]
14:17:59 <lambdabot> (Fractional a, Integral a) => a -> a -> [a]
14:18:00 <Solonarv_> you can perfectly well have a Nat (or whatever) somewhere in one of =>'s "arguments" 
14:18:12 <fen> :t \x y -> let (x',y') = (fromIntegral x,fromIntegral y) in [x',x' +0.1 ..y']
14:18:13 <lambdabot> (Enum a3, Fractional a3, Integral a2, Integral a1) => a1 -> a2 -> [a3]
14:19:11 <Cale> okay, rewriting the function which produces the combinations did a great deal to help
14:19:18 <fen> Solonarv: what, just have a phantom type to store the nat?
14:19:30 <Cale> apparently replicateM is not a good way to generate such a large number of combinations
14:19:39 <fen> wouldnt be able to write S then...
14:19:45 <Cale> which seems a bit sad, honestly
14:20:15 <fen> type Sn b n = ((S n <=? b) ~ True) => S n
14:21:27 <fen> seems like a partially applied function with a | guard at type level
14:22:23 <Cale> I think I'd have to look at the core to try to work out why the memory is being retained though, that's still pretty mysterious
14:22:26 <fen> s b n | n+1 < b = n+1; |otherwise = error "denied" 
14:25:59 <Solonarv_> what's wrong with 'type Sn b n = If (n <=? b) (S n) (TypeError ...)'  ?
14:27:36 <fen> that should work
14:27:57 <fen> the constraint is then inside If
14:28:22 <fen> oh, there are no constraints?
14:28:43 <lyxia> type families are not non-strict
14:28:57 <fen> wait if there is a Constraint on the bools in the definition of If then how could it return something other than Type?
14:29:19 <nshepperd_> The problem with replicateM is *probably* that fs <*> xs for lists holds onto xs reusing it for each element of fs instead of recomputing it
14:29:31 <Cale> @let repM 0 xs = return []; repM n xs = do vs <- repM (n-1) xs; v <- xs; return (v:vs)
14:29:32 <lambdabot>  Defined.
14:29:41 <Cale> ^^ this version seems to use far less space
14:29:56 <nshepperd_> Or at least, that is what I'd suspect
14:30:25 <Cale> I haven't quite puzzled out why yet though
14:30:39 <Cale> Bish: ^^
14:30:58 <nshepperd_> But in this case you don't want to reuse it. You don't care if "abcd" and "zbcd" share the "bcd"
14:31:07 <Solonarv_> there are no constraints in the version I gave, indeed
14:31:12 <Cale> right...
14:31:52 <Solonarv_> the only potential issue with this is that you'll also get a type error when GHC can't figure out whether n <=? b is True or False
14:32:09 <Solonarv_> but that doesn't actually seem like a problem here
14:32:33 <Solonarv_> and constraints have the same problem anyway
14:33:33 <Cale> ahhhhh of course
14:34:01 <Cale> nshepperd: You're basically right, it's all about the order in which the selections are being made
14:35:12 <Cale> There's still something mildly upsetting though
14:37:08 <fen> yeah, it just gives the type error every time
14:37:12 <Cale> I think that GHC is seeing  xs >>= (\v -> replicateM (n-1) xs >>= (\vs -> return (v:vs))) and lifting the replicateM (n-1) xs out of that lambda body
14:37:21 <nshepperd_> I guess your one with the order reversed is basically bigList <*> smallList, where the small list is the input and hence shared anyways
14:37:22 <Cale> because it doesn't depend on v
14:37:49 <nshepperd_> So it doesn't matter if <*> holds onto the small list
14:37:59 <Cale> yeah
14:38:19 <Cale> It'll only go through the big list once that way
14:38:45 <Cale> But I feel like it shouldn't have retained the big list in the first place
14:39:07 <fen> https://pastebin.com/raw/w1vpaTts
14:39:14 <nshepperd_> :t replicateM
14:39:15 <lambdabot> Applicative m => Int -> m a -> m [a]
14:41:09 <nshepperd_> It's Applicative now, which is probably why
14:42:06 <fen> Solonarv: why cant it use that type family? why does it always fail?
14:43:10 <Cale> nshepperd: Oh, is that all it is? :)
14:43:17 <Cale> Oh jeez
14:43:23 <Cale> That's so bad
14:43:27 <Cale> hahaha
14:43:40 <Cale> Applicative was a mistake, lol
14:43:52 <nshepperd_> Haha
14:44:27 <Cale> I thought I tried rewriting replicateM by hand the normal way, but must not have recompiled
14:44:28 <nshepperd_> I wish they'd have made replicateA instead of changing replicateM
14:44:35 <Cale> Yeah, that's really dumb
14:45:23 <Cale> Welp
14:45:38 <Cale> One more thing to be annoyed about :D
14:45:41 <nshepperd_> It probably introduced a bunch of performance regressions in old apps
14:45:48 <Cale> yep
14:47:39 <nshepperd_> > replicateM 3 (ZipList "abc")
14:47:41 <lambdabot>  ZipList {getZipList = ["aaa","bbb","ccc"]}
14:48:33 <nshepperd_> Should have to use replicateA for that
14:54:07 <fen> If (n <=? b) (S n) (S n) works, but both;
14:54:11 <fen> If (n <=? b) (S n)  (TypeError (Text "denied")) 
14:54:15 <fen> and 
14:54:16 <fen> If (n <=? b)  (TypeError (Text "denied")) (S n) 
14:54:27 <fen> return "denied" at compile time
14:54:34 <fen> type Sn (b :: Nat) (n :: Nat) =  ...
14:55:09 <fen> shouldnt it only reach the type error if it can prove the first argument True or False respectivly
14:56:28 <fen> hmmm, could use a type level Maybe perhaps, but still, this isnt behaving in an expected way
15:00:35 <Solonarv_> if you have a stuck type family and there is a TypeError in its arguments that TypeError gets thrown
15:02:14 <Solonarv_> so what's happening here is:
15:02:14 <Solonarv_>  - n and/or b aren't sufficiently known, so 'n <=? b' is stuck
15:02:14 <Solonarv_>  - therefore, 'If (n <=? b) foo bar' is stuck
15:02:14 <Solonarv_>  - 'bar' is 'TypeError ...', so GHC reports the error
15:02:34 <Solonarv_> (the last one is a quirk/bug, and certainly a bit surprising)
15:07:08 <fen>  right
15:07:35 <fen> so how can we right this kind of partially applied if b then a else error ""
15:08:08 <fen> where b is not "knowable" because its yet to be created, as it appears in a partially applied thinh
15:08:13 <fen> maybe thats not right...
15:08:47 <fen> well, its "stuck" as you put it
15:08:51 <MarcelineVQ> Solonarv_: What is a stuck type family?
15:09:16 <fen> it cant yet access the arguments it needs to evaluate 
15:09:32 <fen> as it appears in something which takes arguments... 
15:09:35 <fen> not quite...
15:09:41 <fen> *sigh*
15:10:16 <fen> not in weak head normal form?
15:10:42 <Solonarv_> MarcelineVQ: it's a type family where the arguments aren't sufficiently known to figure out which equation to use
15:11:18 <fen> ohhh
15:11:24 <fen> its because it was a type synonym
15:11:28 <Solonarv_> (or also a type family where no equation applies)
15:11:29 <fen> instead of a type family
15:11:41 <fen> type family Sn (b :: Nat) (n :: Nat) where  Sn b n = If (n <=? b) (S n)  (TypeError (Text "denied"))
15:11:44 <fen> that compiles
15:11:53 <Solonarv_> oh yeah, that should delat things long enough to actually get work donw
15:13:06 <fen> not known / unidentifiable ?
15:13:11 <MarcelineVQ> why does " type family Cawnst a b where Cawnst x y = x " report a TypeError if b is a TypeError
15:14:01 <hpc> the type level isn't lazy, iirc
15:14:14 <Solonarv_> indeed it isn't
15:14:20 <Solonarv_> it's not quite strict either
15:14:28 <Solonarv_> iirc
15:14:33 <MarcelineVQ> But then how does If (n <=? b) (S n) (TypeError (Text "denied")) ever work?
15:14:54 <lyxia> it's a nondeterministic rewriting system, TypeError was bolted on top.
15:15:03 <Solonarv_> % type family Cawnst a b where Cawnst x y = x
15:15:03 <yahb> Solonarv_: 
15:15:22 <Solonarv_> % :k! Cawnst Int (TypeError (Text "boom"))
15:15:22 <yahb> Solonarv_: unknown command ':k!'; use :? for help.
15:15:28 <Solonarv_> % :kind! Cawnst Int (TypeError (Text "boom"))
15:15:28 <yahb> Solonarv_: ; <interactive>:1:24: error: Not in scope: type constructor or class `Text'
15:15:35 <Solonarv_> % :kind! Cawnst Int (TypeError ('Text "boom"))
15:15:35 <yahb> Solonarv_: ; <interactive>:1:24: error:; Not in scope: data constructor `Text'; Perhaps you meant one of these: variable `text' (imported from Text.PrettyPrint.HughesPJ), variable `next' (imported from System.Random)
15:15:47 <Solonarv_> % :kind! Cawnst Int (TypeError ('Text "boom"))
15:15:47 <yahb> Solonarv_: ; <interactive>:1:13: error:; Ambiguous occurrence `TypeError'; It could refer to either `GHC.TypeLits.TypeError', imported from `GHC.TypeLits'; or `Control.Exception.TypeError', imported from `Control.Exception' (and originally defined in `Control.Exception.Base')
15:15:56 <Solonarv_> % :kind! Cawnst Int ('TypeError ('Text "boom"))
15:15:56 <yahb> Solonarv_: ; <interactive>:1:25: error:; * Expected kind `String', but ` 'Text "boom"' has kind `ErrorMessage'; * In the first argument of ` 'TypeError', namely `( 'Text "boom")'; In the second argument of `Cawnst', namely `( 'TypeError ( 'Text "boom"))'; In the type `Cawnst Int ( 'TypeError ( 'Text "boom"))'
15:15:59 <MarcelineVQ> import
15:16:13 <hpc> just get rid of 'Text, i think you have it
15:16:22 <Solonarv_> % :kind! Cawnst Int ('TypeError "boom")
15:16:22 <yahb> Solonarv_: ; <interactive>:1:24: error:; * Expected kind `String', but `"boom"' has kind `Symbol'; * In the first argument of ` 'TypeError', namely `"boom"'; In the second argument of `Cawnst', namely `( 'TypeError "boom")'; In the type `Cawnst Int ( 'TypeError "boom")'
15:16:30 <Solonarv_> sigh
15:16:37 <Solonarv_> I'll fix it in PMs
15:17:56 <Solonarv_> % :kind! Cawnst Int (Ty.TypeError (Ty.Text "boom"))
15:17:56 <yahb> Solonarv_: Cawnst Int (Ty.TypeError (Ty.Text "boom")) :: *; = Int
15:18:05 <Solonarv_> MarcelineVQ: no error message!
15:18:10 <Solonarv_> what did you do?
15:18:48 <MarcelineVQ> % foo :: Cawnst Int (Ty.TypeError (Ty.ShowType Int :<>: Ty.ShowType String)); foo = 3
15:18:49 <yahb> MarcelineVQ: ; <interactive>:96:8: error:; * IntString; * In the type signature: foo :: Cawnst Int (GHC.TypeLits.TypeError (ShowType Int :<>: ShowType String))
15:20:09 <fen> MarcelineVQ: it works because its a tpye family
15:20:14 <fen> yours was a tpye
15:20:19 <fen> !?
15:20:22 <fen> type
15:20:38 <fen> like, a type synonym basically
15:20:42 <MarcelineVQ> I'd have used Text but I didn't understand the error at first and thought Symbol it wasn't working
15:20:47 <Solonarv_> hmm... might be something to do with numeric literals being polymorphic
15:20:55 <Solonarv_> foo :: Cawnst Int (Ty.TypeError (Ty.ShowType Int :<>: Ty.ShowType String)); foo = 3 :: Int
15:20:59 <fen> it needs to be able to defer evaluation, which apparently requires it to be explicitly a type family
15:21:01 <Solonarv_> 5 foo :: Cawnst Int (Ty.TypeError (Ty.ShowType Int :<>: Ty.ShowType String)); foo = 3 :: Int
15:21:07 <Solonarv_> % foo :: Cawnst Int (Ty.TypeError (Ty.ShowType Int :<>: Ty.ShowType String)); foo = 3 :: Int
15:21:07 <yahb> Solonarv_: ; <interactive>:97:8: error:; * IntString; * In the type signature: foo :: Cawnst Int (GHC.TypeLits.TypeError (ShowType Int :<>: ShowType String))
15:21:11 <Solonarv_> hm, noe
15:21:31 <Cale> So yeah, that space issue also provides another reason to be very wary of ApplicativeDo
15:22:24 <fen> eh?
15:22:47 <Solonarv_> MarcelineVQ: okay, I have no idea what's going on there
15:23:16 <fen> clearly we are not doing enough type level programming 
15:23:21 <MarcelineVQ> Cale: Most places people are using replicateM are on things that are already Monads, you should make an issue about it since it'd be a minimal change to existing bases to swap replicateM back to Monad and have replicateA typeof things
15:23:41 <Cale> Yeah, I think I will
15:23:46 <Cale> The only question is where
15:24:12 <MarcelineVQ> yeah ehe, gitlab I guess, I've not signed in there so idk the setup
15:24:30 <MarcelineVQ> if you ask in #ghc people will have a good idea
15:25:34 <fen> is there a minimal version of haskell the haskell specification can be expressed in terms of?
15:25:51 <fen> like, so you can write a compiler for the specification without needing a full GHC?
15:26:07 <Solonarv_> what do you mean? are you asking about a precisely spec-conformant Haskell implementation?
15:26:47 <fen> well just like, systemF is fine, shouldnt be hard to implement, but all the language extensions are daunting and are not written in a way thats easy to implement
15:27:08 <fen> if they were written in some kind of meta language - or even a sub-haskell dialect, then we could compile them
15:27:35 <fen> as in, to produce a ghc from some thing other than the source
15:27:44 <MarcelineVQ> You'd like a literate-haskell, haskell specification? :>
15:27:51 <fen> just a minimal implementation in some language specifically designed for that
15:27:52 <Solonarv_> ooh, that's what you mean
15:28:16 <Solonarv_> I don't think there's any Haskell implementation other than GHC itself that can compile/run modern GHC
15:28:24 <fen> yeah thats the point
15:28:35 <fen> if you want to write a GHC... 
15:29:06 <fen> like, I would like to be able to implement a custom compiler to compile the GHC meta-source
15:29:27 <fen> we dont need the full haskell implementaion to compile GHC?
15:29:32 <fen> thats the point
15:29:32 <Solonarv_> I vaguely recall a (series of) articles about bootstrapping GHC but I don't think it managed got donw
15:30:16 <fen> for example, how many language extensions dont we need, to compile all the other language extensions
15:30:18 <Solonarv_> iirc GHC x.y.z is supposed to be compilable with ghc x.(y-2) or newer
15:30:31 <fen> oh nice
15:30:40 <Solonarv_> might be a different number than 2 but you get the idea
15:30:46 <fen> yeah
15:31:16 <monochrom> y-2? y+2?
15:31:18 <fen> so there is at least some upper bound on the least sufficent ammount of haskell needed to compile GHC
15:31:40 <fen> but we have System F
15:31:56 <fen> so why not a special GHC specification language
15:32:35 <fen> it would be great to be able to write a compiler capable of compiling GHC
15:32:50 <fen> maybe even a specification for this written in terms of itself
15:33:31 <fen> the advantage being that it would standardise the syntax for describing language extensions
15:33:38 <Solonarv_> yeah, it'd be nice if there were another compiler capable of accepting (recent) GHC
15:34:28 <fen> and give a kind of, not constantly expanding - almost constant - compiler that we could actually write by hand
15:35:13 <fen> probably compiled using GHC or itself anyway, but at least it would be some readable amount of code
15:35:36 <fen> like System F, which is legible comprehensable and easy to write a compiler for
15:35:41 <fen> probably...
15:35:51 <fen> easier than a full GHC anyway
15:36:22 <fen> wow, maybe SystemF is actuall enough...
15:36:36 <fen> so you could maybe write GHC in systemF?
15:36:54 <fen> and all the language extensions?
15:36:59 <fen> actually thats a crappy idea
15:37:00 <Solonarv_> in theory yes
15:37:08 <fen> its not *more* legible
15:37:12 <fen> that was the whole idea
15:37:28 <fen> it would be imposible to read a language extension specification written in SystemD
15:37:30 <fen> F*
15:37:31 <Solonarv_> but it would take a lot of effort - more than rewriting GHC, quite possibly
15:37:56 <fen> yeah but it would be extra awesome
15:40:36 <fen> ok, what if you relaxed the requirement that it wasnt supposed to use GHC
15:40:47 <fen> you could just say it wasnt allowed to use any language extensions
15:40:53 <fen> actually that might totally suck
15:41:25 <fen> it might be much easier to write the language extension source code in haskell including the language extensions
15:41:47 <fen> well anyway at least that gives a notion of "i can write this language extension without needing these other ones"
15:41:58 <fen> so maybe giving an order to them
15:42:15 <fen> and maybe most can be written in haskell98
15:42:26 <fen> but yeah, maybe its more legible if they are not...
15:43:05 <fen> but can you continue this process of reduced nesacary component parts of GHC below haskell98? or pure haskell or whatever its called
15:43:24 <Solonarv_> all of GHC's current features could in principle be implemented using only Haskell98 (or whatever), it'd just be more verbose / less readable / harder to maintain
15:43:26 <fen> gradually removing parts you dont need to write the other parts
15:44:00 <fen> oh right, so its better to use the most advanced recent GHC to compile the next version
15:44:03 <fen> ok that makes sense
15:44:17 <fen> but it does not help trying to start that process from scratch
15:44:40 <fen> which would be enabled by the procedure described
15:45:04 <fen> which is obviously lacking or we wouldnt be only ever using GHC to compile GHC
15:45:25 <fen> we have no ability to write a compiler capable of compiling GHC other than itself
15:45:36 <Solonarv_> oh no, we have the ability
15:45:42 <fen> i can see how this wouldnt be nesacary, but it could be useful somehow
15:45:48 <Solonarv_> it would just take a ton ofeffort, so nobody has done it
15:46:02 <fen> could it be obtained algorthmically
15:46:19 <fen> just by randomly removing parts and seeing if it still compiled or something
15:46:40 <monochrom> The problem with ignoring economics.
15:46:59 <Solonarv_> considering how big GHC is I doubt that'd finish in a reasonable time frame
15:47:18 <monochrom> What's wrong with naïve interpretations of and expectations from FOSS.
15:47:19 <fen> well if you had something that you could read as a result you could figure out what it had done, and get this order of construction or whatever
15:47:54 <Solonarv_> perhaps it'd be good enough to simply compile GHC to JS or JVM-bytecode or whatever, and use that to bootstrap a regular GHC without needing a native GHC binary
15:48:01 <dmwit> You can write a compiler for untyped LC in H98 in a weekend. Probably you could, with some tears, write a compiler for untyped LC in untyped LC in a week or less.
15:48:05 <monochrom> The reason why I like to ask this upsetting question: How much money will you pay for it?
15:48:11 <dmwit> But why would you do that?
15:48:24 <MarcelineVQ> 20
15:48:47 <fen> but probably what is more in keeping with the desired goal of "more readable language extension source" is actually make something more than what we have currently, probably not, but similar too, a new language extension
15:49:00 <dmwit> (I know the joke is that you haven't given units. But even so I'm willing to bet you won't even pay 20 for it.)
15:49:09 <Solonarv_> it might help porting GHC to a new system, or making GHC available on a bootstrap-everything-no-binaries-allowed system
15:49:20 <MarcelineVQ> That is the joke; you know, we make a great team.
15:49:28 <hpc> dmwit: if you want units, make a typed LC
15:49:50 <fen> worst deal ever!
15:50:15 <joserele> any good reads about parallel programming with haskell??
15:50:20 <hpc> @where parconc
15:50:20 <lambdabot> https://www.safaribooksonline.com/library/view/parallel-and-concurrent/9781449335939/
15:50:21 <dmwit> (In fact, I suspect it goes the other way -- you might demand somebody give you money to use it!)
15:50:50 <MarcelineVQ> joserele: that's the definitive read on the subject btw
15:51:04 <hpc> tremendous read, the best read :P
15:51:12 <MarcelineVQ> it's yuge
15:51:22 <dmwit> Let's not.
15:51:28 <fen> yeah, whats being required is just a metalanguage for writing GHC source, which is probably no good since we read haskell best anyway
15:52:03 <joserele> I did a quick seach on the matter and thats the only "recommended" book I came up with
15:52:07 <joserele> Anything else?
15:52:08 <fen> damn recursively specified language
15:52:24 <monochrom> It took like ten years between the first time someone wished for :doc and today it's finally in beta.
15:52:28 <hpc> joserele: there's reading the haddock, i guess
15:52:39 <hpc> https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent.html
15:52:50 <hpc> and probably http://hackage.haskell.org/package/async too
15:53:06 <dmwit> joserele: Not really. You could go right to the horse's mouth and read the original paper about GHC's implementations of concurrency and parallelism.
15:53:09 <Solonarv_> also
15:53:09 <Solonarv_> @hackage parallel
15:53:09 <lambdabot> http://hackage.haskell.org/package/parallel
15:53:20 <hpc> oh wait, parallel
15:53:21 <dmwit> joserele: Oops, I mean papers.
15:53:29 <Solonarv_> which is the 'par' half or 'parconc' ;)
15:53:49 <dmwit> joserele: What don't you like about the one recommended thing?
15:54:00 <monochrom> You will want to learn both anyway. par and conc are not completely separate either.
15:54:17 <MarcelineVQ> monochrom: just more evidence that haskell cribbed everything it has from idris :>
15:54:47 <joserele> Just checking different options before I head on :)
15:54:48 <monochrom> You mean regarding :doc?
15:54:51 <MarcelineVQ> ye hehe
15:54:56 <Solonarv_> steal all of idris!
15:55:02 <joserele> I guess I'll just go with the recommended one
15:55:06 <joserele> Thxs people
15:55:07 <Solonarv_> well, not strictness-everywhere I guess ;)
15:55:10 <hpc> never mind that idris came after, haskell used http://hackage.haskell.org/package/tardis
15:55:25 <monochrom> Well, ten years ago the person wishing for :doc came from Python, and Idris didn't exist.
15:55:33 <MarcelineVQ> I wouldn't mind if haskell stole idiom syntax and !do as well tho
15:55:38 <Solonarv_> oh wait - we have -XStrict or the alternative "vomit ! everywhere"
15:56:04 <monochrom> To be fair, that still doesn't contradict the idea that maybe because Idris has it, this gives enough pressure on GHC to finally get to it.
15:56:28 <Solonarv_> what are those? idiom syntax is something to nicely generalize liftAn, right?
15:56:35 <monochrom> Yeah
15:56:36 <MarcelineVQ> Solonarv_: yes
15:56:43 <Solonarv_> and what's !do ?
15:57:42 <MarcelineVQ> !do is binding to a name and using it immediately do beh <- foo; booble beh; bo; do booble !foo; bo
15:58:02 <MarcelineVQ> erm, that's not so redable, darn plugin
15:58:58 <MarcelineVQ> http://docs.idris-lang.org/en/latest/tutorial/interfaces.html#notation
15:59:03 <Solonarv_> ah, I think I saw a ghc proposal forsomething similar
15:59:34 <MarcelineVQ> http://docs.idris-lang.org/en/latest/tutorial/interfaces.html#idiom-brackets re the other
15:59:59 <monochrom> Interesting.
16:00:45 <Solonarv_> !do seems like a generalization of idiom brackets in some sense
16:01:04 <Solonarv_> (it's like an idiom bracket that also inserts 'join' where needed)
16:01:37 <dmwit> ...and now we just need a type-directed way of inferring where !'s go... ;-)
16:01:42 <fen> hpc: that just looks like pipes
16:01:58 <fen> whats wrong with regular traversal :(
16:02:02 <MarcelineVQ> while we're at it I'm pretty okay with http://docs.idris-lang.org/en/latest/tutorial/interfaces.html#pattern-matching-bind too
16:02:57 <Solonarv_> oh yeah, that seems useful too
16:03:21 <fen> like, its a nice API which traversals could implement, and conduits etc, but why is that API better than the Lens API which offers the same functionality, by giving traverse in terms of a getter and setter?
16:03:36 <Solonarv_> '>>= \case' covers some of its use cases, though
16:03:39 <fen> hpc: am i missing something?
16:04:00 <monochrom> I think I prefer ">>= \case" for better symmetry.
16:04:29 <Solonarv_> '>>= \case' is more awkward when the ordering of pattern matches matters
16:04:50 <dmwit> MaybeT covers the specific case used to motivate the special syntax.
16:04:56 <monochrom> Oh wait this is not symmetric in the first place. Nevermind.
16:05:13 <dmwit> (And >>= \case doesn't seem to cover that specific case.)
16:05:44 <hpc> it reads like the case-of version of "t if p else f"
16:05:46 <monochrom> This is instead doing MaybeT IO without formally introducing and eliminating MaybeT.
16:06:15 <fen> probably what you really want is a branched version of a double linked list to get cyclic graphs, then you can have branching "future" directions and mu references
16:06:20 <remexre> is there a Getter a b -> Getter a c -> Getter a (b, c) combinator? (for lens)
16:06:23 <monochrom> Now I am all for it. :)
16:06:26 <Solonarv_> e.g. compare
16:06:26 <Solonarv_>   [stuff] <- foo | _ => some_fallback
16:06:26 <Solonarv_>   <rest of the do block, very large>
16:06:26 <Solonarv_> vs.
16:06:26 <Solonarv_>   foo >>= \case
16:06:28 <Solonarv_>     [stuff] -> <rest of the do block, very large>
16:06:30 <Solonarv_>     _ -> some_fallback
16:07:21 <Solonarv_> remexre: yes, I don't remember what it's called though
16:07:34 <fen> and thats just a datatype, no class interface nesacary, thought it is a store...
16:07:56 <Solonarv_> the >>= \case approach is more awkward here because the fallback ends up being far away from the thing being bound
16:08:24 <Solonarv_> (this is assuming that the fallback is small, and the rest of the do block is large; but that seems like a fairly common situation)
16:08:31 <monochrom> Yes.
16:09:00 <monochrom> This is "error handling where 'error' means Maybe, oh but we're also inside IO".
16:09:20 <fen> so its just pointers on a cyclic graph comonad stencil. where the "bridge" between past and future computations is created by carring cyclic updates of a future reference into the traversal that creates the cyclic linked tree from the acyclic tree
16:09:30 <monochrom> This is really an alternative to MaybeT.
16:09:51 <Solonarv_> well, it doesn't have to be Maybe, that's just the example chosen
16:10:16 <fen> so that then "crossing over this bridge" / wormhole or whatever, is just navigating the pointer onto a cyclic reference
16:10:34 <monochrom> I know
16:10:56 <Solonarv_> I too am in favor of it
16:11:10 <monochrom> In general this is an alternative to ExceptT.
16:11:16 <dmwit> I am ambivelant about it.
16:11:29 <dmwit> ambivalent. spelling is hard
16:15:47 * hackage purescript 0.12.4 - PureScript Programming Language Compiler  https://hackage.haskell.org/package/purescript-0.12.4 (hdgarrood)
17:03:53 <fen> https://pastebin.com/raw/N9g1x2Pa
18:46:17 * hackage backprop 0.2.6.2 - Heterogeneous automatic differentation  https://hackage.haskell.org/package/backprop-0.2.6.2 (jle)
19:09:12 <remexre> if I have a type like Foo a = Foo (a, a) [a], is there a way to get a Traversal' (Foo a) a over all the fields?
19:13:32 <shachaf> deriving (Functor, Foldable, Traversable)
19:14:05 <Cale> Yeah, it'd look something like  traverseFoo f (Foo p zs) = Foo <$> both f p <*> traverse f zs
19:14:12 <Cale> But you can also just derive it
19:14:14 <shachaf> I mean, it's just traverse.
19:14:27 <remexre> oh
19:14:29 <remexre> huh
19:14:37 <Cale> It's worth knowing how to write it yourself though
19:14:46 <shachaf> Sure.
19:14:57 <remexre> I'm having a hard time internalizing all the lens stuff past Lens' :P
19:15:28 <remexre> tbh might try reimplementing the whole thing after finals to see if that helps...
19:16:08 <Cale> I found it to be quite helpful to really think about what some of these type synonyms unfold to, and what functions of that sort mean
19:17:02 <Cale> So, in the case of a Lens, we have a function of type  Functor f => (part -> f part') -> whole -> f whole'
19:18:31 <Cale> So it's a function for transforming actions on some focused part to actions on the whole type.
19:18:42 <remexre> ok, that makes sense
19:19:07 <blankhart> this also may help with intuition. https://blog.jle.im/entry/lenses-products-prisms-sums.html
19:19:08 <Cale> They're almost always going to take that whole thing, and split it into two pieces: a function which takes the missing part and replaces it
19:19:19 <Cale> and the part to which we apply our arbitrary transformation
19:19:58 <remexre> my problems start when Conjoined and such start appearing
19:19:58 <Cale> It'll then apply the transformation to the piece, and then fmap the function for building up the rest of the structure around it over the result
19:20:12 <Cale> Now Traversals generalise that
19:20:40 <Cale> Let's just write the lens for the first part of a pair for a moment:
19:21:06 <remexre> lensFst f (x, y) = (,y) <$> f x ?
19:21:07 <Cale> firstPart f (x,y) = (\x' -> (x',y)) <$> f y
19:21:15 <Cale> er, sorry, f x, yes :D
19:21:35 <Cale> Okay, so what does adding Applicative buy us here?
19:21:44 <remexre> multiarg functions
19:21:48 <Cale> Well, it lets us do more than one substitution at once, yeah
19:21:57 <Cale> So we can write stuff like
19:22:11 <Cale> both f (x,y) = (,) <$> f x <*> f y
19:22:37 <Cale> the (,) being like the original data structure but with two holes punched in it
19:22:45 <Cale> and then we have the substitutions filling those in
19:23:19 <remexre> alright
19:23:28 <remexre> that one makes sense too
19:26:16 <Cale> The further generalisations are a bit farther out, but the idea is basically that instead of manipulating functions of type a -> f b
19:28:35 <Cale> oh, hah, didn't finish that line
19:29:09 <Cale> instead of the function arrow, we'll manipulate things of type  p a (f b)
19:29:27 <Cale> where the p can typically specialise to the usual function arrow
19:31:15 <Cale> but can also specialise to other function-like things
19:32:36 <Cale> (Especially the "Market" type, whose name I don't really get, except that it bears some sort of relationship to Bazaar)
19:34:49 <Cale> Also Indexed
19:34:57 <Cale> and a handful of other ones
19:38:37 <remexre> okay
19:38:58 <remexre> it's mostly the various... is "subclasses" the right word? of profunctor I have trouble with
19:40:06 <Cale> Honestly, I've gotten by perfectly fine without taking the trouble to understand how they relate to the rest of the library very well, but yeah, there are a lot of interesting sorts of profunctor that different kinds of operations are restricted to.
19:41:51 <Cale> Conjoined p means roughly "something very very very much like an ordinary function -- maybe it's got some additional arguments"
19:42:07 <Cale> after all that constraining, I don't think you're left with much
19:42:34 <remexre> huh, okay
19:45:15 <Cale> Like, the instances are ReifiedGetter s a, which is morally the same thing as a function of type s -> a, but encoded as a function of type (Contravariant f, Functor f) => (a -> f a) -> s -> f s (i.e. a Getter) -- there aren't so many things which are both contravariant and covariant functors, apart from Const
19:45:24 <Cale> and then you have ordinary (->)
19:45:28 <Cale> and then you have Indexed i
19:46:50 <Cale> and if you track down what it means for the thing to be Representable and Corepresentable, it implies that there's a way to encode the thing with functions of particular sorts to an extent that it's pretty hard to imagine too many more instances
19:47:18 <Cale> (I don't have a hard proof characterising them though, maybe Ed would)
19:47:51 <remexre> I think I'll dig more into this after I learn more category theory :P
19:48:06 <Cale> Yeah, it's both helpful and not
19:48:44 <Cale> These are things from category theory, but sometimes they're a little hard to recognise after they've been stomped on a bunch to specialise everything to Haskell.
19:48:45 <maerwald> and all you wanted was simple Java-style foo.bar ;)
19:49:48 <Cale> Also, tbh, in my day-to-day work, most uses of lens I run across are going to get replaced with much more mundane code 
19:50:52 <remexre> yeah, I'm largely using lens to learn it
19:51:28 <remexre> I'm taking a compilers course and writing an unrelated compiler, both in Haskell, so I'm using this opportunity to use every library I've seen mentioned more than 5 times :P
19:52:49 <remexre> though I still don't grok recursion-schemes... but I'm not using it anymore anyway
19:52:56 <Cale> The thing about Foldable/Traversable and then lens even moreso is that it's really easy for someone to type-tetris their way to something which looks convincing but does the wrong thing.
19:53:29 <Cale> oh, and recursion-schemes is entirely impractical to use directly -- those are programs for your head, not for your code imo :)
19:53:56 <Cale> Like, it hurts not to know what a catamorphism is
19:54:03 <Cale> but you pretty much never want 'cata'
19:54:24 <Cale> you want something with better ergonomics written for a specific type
19:54:53 <remexre> yeah, my non-class language is actually going to try to do that
19:55:22 <Cale> (e.g. foldr)
19:55:35 <remexre> it's intended to be total, so general recursion is right out, and I like the idea of eliminators better than more complex termination checking
19:56:50 <Cale> Have you looked at what Coq and Agda do?
19:57:08 <remexre> Not Agda, but Coq's check is syntactic, no?
19:57:54 <Cale> I'm actually not certain which is the more fundamental, but Coq also gives you general induction/recursion principles
19:58:07 <c_wraith> Cale: cata isn't so bad with LambdaCase
19:58:20 <Cale> c_wraith: I suppose that'd be true
19:58:22 <remexre> I _think_ it should be possible to mechanically translate the recursion into eliminators (which Coq calls recursion principles)
19:58:37 <Cale> c_wraith: But working with explicit fixpoints isn't terribly fun
19:58:41 <remexre> but in Coq, the recursion is the primitive, as I understand it
19:59:14 <Cale> remexre: Yeah, I suppose it lets you print the code for the things
20:11:17 * hackage yam-datasource 0.5.17 - Yam DataSource Middleware  https://hackage.haskell.org/package/yam-datasource-0.5.17 (leptonyu)
20:12:17 * hackage yam 0.5.17 - Yam Web  https://hackage.haskell.org/package/yam-0.5.17 (leptonyu)
20:16:47 * hackage salak-yaml 0.2.9 - Configuration Loader for yaml  https://hackage.haskell.org/package/salak-yaml-0.2.9 (leptonyu)
20:17:47 * hackage salak-toml 0.2.9 - Configuration Loader for toml  https://hackage.haskell.org/package/salak-toml-0.2.9 (leptonyu)
20:18:47 * hackage salak 0.2.9 - Configuration Loader  https://hackage.haskell.org/package/salak-0.2.9 (leptonyu)
20:53:02 <xpika> is there a sum type for a 3 way Either? like data Either3 a b c = Either3a a | Either3b b | Either3c c  
21:08:25 <slack1256> xpika: you just defined it yourself, if you mean a standard 3 way sum type on base at least there isn't
21:09:31 <slack1256> you could always `Either (Either a b) c`, you would have `Left (Left a)` or `Left (Right b)` and `Right c`
21:19:45 <benzrf> Either a (Either b c)
21:19:57 <benzrf> good thing Either is monoidal!!!
21:20:17 <benzrf> well, can be equipped as such
21:25:20 <slack1256> I think people ask this because they want an operator like (*) on python
21:25:45 <slack1256> There you can make (*(a,b),c) = (a, b, c) and think maybe this can be done for sum-types
21:29:46 <jle`> xpika: like with 3-tuples... at that point you might be better off making a custom data type
21:30:08 <MarcelineVQ> there's anonymous sums if you've got beer in the house (# a | b |​ c #)
21:30:10 <jle`> tuples and either are "anonymous" products and sums
21:30:19 <jle`> (ah, and that unboxed one too)
21:30:29 <jle`> but at a certain point, it's better to be non-anonymous
21:30:57 <slack1256> I didn't know about "anonymous sums"
21:31:39 <slack1256> MarcelineVQ: care to point to a link?
21:31:45 <MarcelineVQ> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#unboxed-sums
21:31:56 <slack1256> thanks!
21:32:04 <MarcelineVQ> Not something a person needs to stick their nose in too often but it's neat
21:32:36 <jle`> but yeah, i wouldn't use a 3-either any more than i'd use a 3-tuple
21:32:47 <jle`> which is ideally not at all :)
21:32:51 <slack1256> That looks... unboxed
21:34:41 <jle`> it's unboxed in the sense that there is not an extra layer of indirection
21:34:45 <jle`> but the values inside can be boxed
21:35:45 <slack1256> I see
21:35:56 <jle`> % type IntOrBool = (# Int | Bool #)
21:35:56 <yahb> jle`: 
21:36:22 <slack1256> % :k (# Int | Bool #)
21:36:22 <yahb> slack1256: (# Int | Bool #) :: TYPE ('SumRep '[ 'LiftedRep, 'LiftedRep])
21:37:12 <jle`> % :k Maybe IntOrBool
21:37:12 <yahb> jle`: ; <interactive>:1:7: error:; * Expecting a lifted type, but `IntOrBool' is unlifted; * In the first argument of `Maybe', namely `IntOrBool'; In the type `Maybe IntOrBool'
21:37:35 <jle`> so they don't have the layer of indirection necessary to be applied to Maybe and things like that
21:37:55 <jle`> the only reason Maybe and functions like map work polymorphically is because of that extra layer
21:38:04 <slack1256> This forces an strict evaluation of them too right?
21:38:26 <jle`> strict in that it is no thunk layer
21:38:42 <slack1256> yes strict in that sense, no extra undefined added
21:38:51 <slack1256> % :k (# Int | Bool #)
21:38:52 <yahb> slack1256: (# Int | Bool #) :: TYPE ('SumRep '[ 'LiftedRep, 'LiftedRep])
21:39:20 <slack1256> Isn't that TYPE a different one of the new type sinonym Type = * ?
21:39:38 * slack1256 needs ispell on his irc client, sorry
21:41:01 <jle`> the underlying story is type Type = TYPE 'LiftedRep
21:41:18 <jle`> so the real kind of Maybe is Maybe :: Type 'LiftedRep -> Type 'LiftedRep
21:41:35 <jle`> er, TYPE 'LiftedRep -> TYPE 'LiftedRep
21:41:42 <jle`> which is why it can't be given a TYPE ('SumRep ...)
21:42:02 <jle`> at this point we're talking about how these things are represented at runtime
21:42:14 <jle`> but it has always been kind of weird to me that we conflate this into the kind system
21:43:22 <slack1256> I see, that makes sense
21:43:44 <slack1256> I wonder how many kinds do we have now. Before you only had (*) as the one with terms
21:43:58 <slack1256> err boxed terms
21:44:35 <slack1256> anything higher than that, was BOX
21:48:36 <slack1256> anyways that's all for me today, see you guys
21:50:17 * hackage reflex-backend-wai 0.1.0.0 - Reflex interface to `wai`  https://hackage.haskell.org/package/reflex-backend-wai-0.1.0.0 (qfpl)
22:30:47 * hackage feed 1.1.0.0 - Interfacing with RSS (v 0.9x, 2.x, 1.0) + Atom feeds.  https://hackage.haskell.org/package/feed-1.1.0.0 (AdamBergmark)
22:54:47 * hackage simple-cmd 0.1.4 - Simple String-based process commands  https://hackage.haskell.org/package/simple-cmd-0.1.4 (JensPetersen)
23:06:47 <orzo> hi
23:09:10 <orzo> I've adapted LambdaCube3D's Hello.hs example, which uses glfw, to use glut, and I have that working.  I really would like to use gtk with a GLArea widget.  The same code shows no errors but renderFrame is leaving the widget blank.  My own direct GL rendering works, but not lambdacube's renderFrame.
23:09:44 <orzo> I'm out of ideas debugging this
23:16:17 * hackage simple-cmd-args 0.1.1 - Simple command args parsing and execution  https://hackage.haskell.org/package/simple-cmd-args-0.1.1 (JensPetersen)
23:38:26 <siraben> What are some recommended readings fro learning about arrows?
23:41:20 <therealwaphire[m> does anyone here use Emacs' org mode for embedding haskell source code blocks?
