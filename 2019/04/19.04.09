00:09:10 <merijn> hmm, why are versions 0.9 and 0.10 of binary deprecated if they're the newest ones?
00:12:53 <merijn> ...
00:13:04 <merijn> I should just never look at issue trackers for libraries...
00:20:01 <yushyin> :)
00:20:49 <merijn> Here I was, thinking binary was remotely sane, only to find out their Float and Double serialisation is completely broken and they have no intention of fixing it, because "backwards compatibility"
00:21:44 <opqdonut> broken how?
00:21:57 <merijn> opqdonut: It doesn't cleanly round trip and wastes tons of space
00:22:18 <opqdonut> oh
00:23:04 <nshepperd> doesn't it serialise as Rational?
00:23:05 <merijn> opqdonut: It's serialised as (Integer, Int) for some weird ass reason, instead of using IEEE-754 serialisation. As a result (for example) NaN values decode to -Infinity, instead of NaN
00:24:00 <merijn> nshepperd: That's insane, though...Float and Double have perfectly reasonable and well-defined serialisations...why would you ever do that?!
00:24:03 <nshepperd> it's also incredibly slow iirc
00:24:09 <opqdonut> merijn: yeah I found the issues
00:24:23 <opqdonut> https://github.com/kolmodin/binary/issues/69
00:27:51 <merijn> I'm sad now :\
00:27:59 * nshepperd wonders where that CBOR thing is at now
00:30:12 <merijn> nshepperd: It looks fairly done, but I'm not sure
00:32:09 <nshepperd> @hackage serialise -- based on cbor, looks pretty nice
00:32:09 <lambdabot> http://hackage.haskell.org/package/serialise -- based on cbor, looks pretty nice
00:32:41 <nshepperd> maybe i should try using it next time i need something like it to see if it actually cuts the mustard
00:41:30 <Ariakenom> you can tell that it's haskell documentation "the standard bijection between CBOR and JSON" :D
00:47:08 <phadej> merijn: 0.9 and 0.10 are deprecated because they are the same as 0.8.5.0 and 0.8.6.0
00:47:13 <phadej> i.e. major bump was not required
00:47:25 <merijn> ah
00:47:32 <phadej> it's in the changelog https://hackage.haskell.org/package/binary-0.8.6.0/changelog
00:47:39 <phadej> at least for 0.8.5.0
01:18:14 <merijn> I don't suppose anyone knows which of the GHC bindists I need for CentOS 7? I tries the Fedora 27 bindist, but that complains about a missing libtinfo.so.6
01:38:29 <phadej> 8.6.3 had centos bindists
01:39:01 <phadej> which is maybe the only version which had them
01:39:40 <maerwald> I am confused why that is, seems like people build stuff manually and upload it and there is no CI for bindists?
01:39:42 <phadej> according to https://github.com/haskell/ghcup/blob/master/.download-urls
01:39:56 <maerwald> https://downloads.haskell.org/~ghc/8.6.4/ doesn't have centos
01:39:57 <phadej> maerwald: that was the case a year ago
01:40:16 <maerwald> also lacks freebsd, which is why 8.6.3 is still marked recommended
01:40:53 <phadej> maerwald: have you read https://www.haskell.org/ghc/blog/20190403-infra-status.html
01:41:50 <phadej> based on https://gitlab.haskell.org/ghc/ci-images there are CI Images for centos7 and freebsd
01:42:39 <phadej> So if one is interested, one should ask (in reply to https://mail.haskell.org/pipermail/ghc-devs/2019-April/017481.html) why there aren't centos nor freebsd builds
01:42:53 <phadej> that's what RCs are for
01:43:17 * hackage syntactic 3.8.1 - Generic representation and manipulation of abstract syntax  https://hackage.haskell.org/package/syntactic-3.8.1 (EmilAxelsson)
01:57:32 <merijn> phadej: The debian 8 bindist appears to work
01:57:41 <merijn> phadej: at least, ghci runs and loads :p
01:58:27 <phadej> I'd still reply to the thread, asking about the real bindists
01:58:47 <phadej> if you care about improvement
01:59:09 <phadej> but I don't care about centos neither freebsd, so I won't do it for you
02:29:02 <Arina> https://2no.co/2GBcf5.jpeg
02:30:17 * hackage base32-z-bytestring 1.0.0.0 - Fast z-base32 and z-base32hex codec for ByteStrings  https://hackage.haskell.org/package/base32-z-bytestring-1.0.0.0 (AlfredoDiNapoli)
03:01:10 <HenryCH> I was trying to understand Functor's (<$). the implementation is fmap . const, but i thought you could only compose one param functions, is this looking at fmap as (a -> b) -> (f a -> f b), and const as (f a -> f b) -> f a? but then the type of <$ doesn't line up with that
03:01:35 <merijn> :t (.)
03:01:36 <lambdabot> (b -> c) -> (a -> b) -> a -> c
03:01:46 <merijn> HenryCH: 'c' is allowed to be a function type :)
03:02:31 <merijn> HenryCH: Also, const isn't "f a -> f b"
03:02:41 <merijn> HenryCH: const applied to one argument is the input to fmap
03:02:56 <merijn> "fmap . const" = "\x -> fmap (const x)"
03:03:25 <merijn> :t const True
03:03:26 <lambdabot> b -> Bool
03:03:51 <merijn> :t fmap (const True)
03:03:52 <lambdabot> Functor f => f b -> f Bool
03:04:15 <HenryCH> got it, thanks!
03:48:26 <fr33domlover> o/ I have 2 lists of type [(a, b)], both of them sorted by fst, and I'd like to merge the 2 lists, applying some function f :: b -> b -> b when both lists have some given fst value. It's easy to write one, I'm just wondering if there's an existing thing on hackage
03:48:54 <fr33domlover> Does anyone know a package/module that does this sort of thing? ^_^
03:50:07 <fr33domlover> There's unionBy but it doesn't assume sorting
03:50:11 <fr33domlover> :t unionBy
03:50:12 <lambdabot> (a -> a -> Bool) -> [a] -> [a] -> [a]
03:50:37 <fr33domlover> And I guess it's not enough by itself :P
03:55:49 <Lears> % :t \f l1 l2 -> M.toList $ (M.unionWith f `on` M.fromDistinctAscList) l1 l2
03:55:50 <yahb> Lears: Ord k => (a -> a -> a) -> [(k, a)] -> [(k, a)] -> [(k, a)]
03:56:11 <Lears> Don't know how fast it is compared to the basic way.
03:57:17 <Lears> Assuming sorted alists with unique keys you basically have a May anyway. I'd just use one of those in the first place?
03:57:21 <Lears> Map*
04:07:27 <fr33domlover> Lears, the sorted lists come from a database, I could put them in a Map but there's no need
04:07:43 <fr33domlover> :t merge
04:07:44 <lambdabot> error: Variable not in scope: merge
04:07:59 <fr33domlover> Well anyway there's merge and mergeBy in a few places
04:08:14 <fr33domlover> And then you can apply groupBy to the merge result ^_^
04:37:17 * hackage summoner 1.3.0 - Tool for scaffolding fully configured batteries-included production-level Haskell projects.  https://hackage.haskell.org/package/summoner-1.3.0 (shersh)
04:45:17 * hackage registry 0.1.3.4 - data structure for assembling components  https://hackage.haskell.org/package/registry-0.1.3.4 (etorreborre)
04:46:48 <epane> I am encountering the error https://github.com/yamadapc/stack-run/issues/17 on Kubuntu 18.10. What's the recommended way to fix this?
05:24:45 <zincy> Is it correct to describe Haskell as a "pure language for constructing impure expressions"?
05:26:02 <merijn> zincy: The expressions are pure too, though
05:26:28 <zincy> That is what someone told me.
05:26:38 <merijn> zincy: Maybe you meant "pure language for constructing impure executables" (or "impure IO actions", although also dubious naming)
05:26:47 <zincy> They didn't like the delegation of impurity to the GHC runtime mental model.
05:26:54 <merijn> zincy: In which case the answer is: Yes, no, maybe, it depends ;)
05:27:03 <zincy> And that was how they characterised Haskell's purity which didn't make sense to me.
05:27:03 <merijn> zincy: Then they were wrong :p
05:27:41 <zincy> It is someone who I admire but I don't think they spend enough time talking to other people about ideas.l
05:27:55 <zincy> Therefore the don't reap the benefits of being challenged by peers.
05:28:53 <zincy> I see Haskell compiles to a language called "core" and then to LLVM bytecode.
05:29:01 <zincy> What are the high level steps?
05:29:14 <merijn> zincy: The distinction between "evaluating expressions" and "executing actions" is "correct", but it's a statement about language semantics (i.e. "what does a piece of code mean")
05:29:45 <merijn> zincy: Pedantic sidenote: *GHC* compiles to Core ;) Haskell the language doesn't specify how to compile or implement it
05:30:24 <merijn> zincy: GHC compiles: Haskell -> Core -> STG -> Cmm -> (machine code || (LLVM assembly -> machine code))
05:30:42 <zincy> Yeah Haskell does't actual execute an IO action right? As in Haskell the language.
05:31:04 <merijn> zincy: Languages don't do anything in general, they just are. Implementations do something ;)
05:31:24 <merijn> zincy: But yes, the Haskell report doesn't specify what it means to execute an IO action or how it should be done
05:31:44 <zincy> :)
05:31:53 <zincy> That is a crucial insight.
05:32:05 <zincy> It is like asking whether a language is interpreted or compiled.
05:32:11 <merijn> zincy: *Conceptually* you have a pure Haskell expression that values to an IO action that gets executed. Operationally, GHC interleaves those two steps
05:32:17 <zincy> Is blue a prime number?
05:32:56 <merijn> zincy: The important realisation, of course, is that what happens operationally isn't important, as long as it's impossible to distinguish from the described semantics
05:33:37 <zincy> The counterargument would be that any IO in any language is pure by that rationale?
05:33:52 <merijn> zincy: No, because you can trivially observe it :)
05:33:54 <zincy> Because a language doesn't do IO an implementation oes?
05:34:28 <merijn> zincy: If I have "int foo = 0; void increment() { foo++; }" I can trivially notice that increment isn't pure, because foo changed across invocations
05:34:31 <zincy> Right so the trivial observation implies that they are coupled
05:34:59 <zincy> The meaning and execution of IO needs to be separate.
05:35:15 <merijn> zincy: The evaluation of a Haskell expression isn't affected by what runs before or after it (ignoring unsafePerformIO, obviously)
05:35:16 <zincy> In what sense though is it more trivial?
05:37:33 <merijn> zincy: The thing is that only IO can affect the environment, but Haskell code can never observe the result of IO. The only way to observe side-effects is via >>= in IO. But >>= doesn't actually trigger the left hand side to happen. It just describes "after this happens, we do this thing on the right"
05:38:33 <zincy> So IO actions can be composed without any effect on each value?
05:38:55 <merijn> zincy: Yes. You can compose IO values with >>= without executing them
05:39:24 <zincy> Whereas in an impure language the operation and the meaning of IO are bound together so composition would not work
05:39:46 <merijn> zincy: Right, in impure languages you can't compose IO operations without also running them right then and there
05:40:32 <merijn> :t map (\x -> print x >> getLine >>= putStrLn) [0..10]
05:40:33 <lambdabot> [IO ()]
05:40:35 <zincy> Ah ok each time I revisit this I deepen my understanding.
05:40:53 <merijn> zincy: That function returns a pretty complex compound IO action, but it's never run
05:41:13 <zincy> So is laziness integral to purity here?
05:41:25 <merijn> zincy: Try running: "map (\x -> print x >> getLine >>= putStrLn) [0..10] !! 4" in ghci for example :)
05:41:58 <merijn> zincy: I would say the reverse. Purity is pretty much a hard requirement to be able to program sanely in a lazy language, because laziness would make the order of IO side-effects unpredictable
05:42:33 <zincy> Ah
05:43:12 <merijn> zincy: The main goal for Haskell at the start was to experiment with lazy languages. The purity was more of a necessity because it would be impossible to write code sanely in a lazy setting otherwise. It's only in hindsight (and after monadic IO was introduced) that people realised that first-class IO itself is valuable even without laziness
05:43:53 <merijn> zincy: Because the very first Haskell versions didn't even have (monadic) IO :)
05:44:40 <zincy> Interesting!
05:45:20 <zincy> So first class IO values mean we can use them without running any IO
05:45:24 <merijn> I think monadic IO wasn't added until Haskell 1.4
05:45:39 <zincy> Since they are then just values.
05:45:43 <merijn> zincy: Right. First class functions is "I can pass around and manipulate functions like any other data"
05:45:57 <zincy> That will be operations on another lower layer of abstraction
05:46:04 <merijn> zincy: First class IO is "I can pass around and manipulate IO actions like any other data", which you can
05:46:11 <zincy> :)
05:46:23 <Taneb> > length [print 1, print 2, print 3]
05:46:25 <lambdabot>  3
05:46:32 <zincy> Thanks for the awesome explanation.
05:46:36 <Taneb> Note that that didn't print anything other than the length
05:46:44 <merijn> zincy: Imagine a socket protocol in an OO language. You'll have some "interface" that has a "getLine" operation that you need to implement
05:47:12 <merijn> zincy: In Haskell you can just write a function that takes "IO String -> IO Foo" and can internally run/use the "IO String" action as many times as you like
05:47:32 <merijn> zincy: It doesn't matter if "IO String" happens to read from a file, or a socket, or anything
05:47:46 <Axman6> One way to think about this is, what if IO is just a data type:c data IO a = Return a | GetChar (Char -> IO a) | ReadLine (String -> IO a) | ReadFile (String -> IO a) | PutString String (IO a) | SendToNetwork ByteString (IO a); you can write echo pretty easily: fix (\loop -> GetLine (\line -> PutString line loop
05:47:47 <Axman6> ))
05:48:18 <merijn> Axman6: Probably easier with explicit recursive binding, fix can be confusing for people :)
05:48:29 <Axman6> yeah...
05:48:42 <zincy> fix is lazy infinite recursion right?
05:48:47 <Axman6> yes
05:48:53 <zincy> from fixpoint
05:48:53 <Axman6> @src fix
05:48:53 <lambdabot> fix f = let x = f x in x
05:49:09 <Axman6> which evaluates to...
05:49:13 <Axman6> > fix f :: Expr
05:49:15 <lambdabot>  f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f...
05:50:28 <zincy> So in an OO lang you couldn't abstract out the function that operates on the results of IO ops?
05:50:39 <zincy> Because IO isn;t first class
05:50:40 <Axman6> anyway, the point is that IO can be defined like this, and your programs become a data structure which can be interpreted in any number of ways - this could be happen using RPC, on a microkernel, or over the internet using IPFS, the source and destination of the strings could be anything
05:52:11 <tdammers> zincy: "OO" and "first-class IO" are orthogonal
05:53:21 <zincy> Ah ok so let me rephrase by question from OO to langs with no first class IO
05:54:17 * hackage telega 0.1.5 - Telegram Bot API binding  https://hackage.haskell.org/package/telega-0.1.5 (iokasimovmt)
06:04:12 <dmwit> Yes, it's true, in languages with no first class IO, IO is not first class.
06:04:19 <monochrom> haha
06:05:13 <Cale> @tell fen Ah, looks like that's a difference between the master and develop branches of Obelisk. I'm actually not certain what's meant to be done, if anything, on master.
06:05:13 <lambdabot> Consider it noted.
06:11:21 <Cale> zincy: But yeah, it's true that it's really convenient that IO is a data type with lots of perfectly effect-free combining functions. People do invent mechanisms that are somewhat analogous to this in OO languages -- where you have objects with an execute method and ways of composing them -- but it's so much more awkward to use them of course that most code isn't written that way.
06:11:47 * hackage copilot 3.0.1 - A stream DSL for writing embedded C programs.  https://hackage.haskell.org/package/copilot-3.0.1 (frankdedden)
06:12:42 <Cale> In Haskell, we get the benefit of being able to write our own control structures as needed, and having them be immediately useful in ordinary code.
06:12:47 * hackage copilot-language 3.0.1, copilot-core 3.0.1, copilot-c99 3.0.1 (frankdedden)
06:15:29 <monochrom> It may not require an explicit IO type. What we call "X -> IO Y", other languages have simply "X -> Y". The only oddball is: what we call "IO Y", other languages call it "() -> Y".
06:16:06 <monochrom> So basically any language that supports first-class functions or first-class objects already have first-class IO.
06:17:32 <Cale> Yeah, that's fair -- I was thinking of languages without first class procedures/"functions".
06:19:18 <tdammers> the "pure combinators for first-class IO actions" is kind of unique though
06:19:32 <tdammers> at least in the sense that we enforce the purity of those combinators
06:19:35 <monochrom> Awkwardness and clumsiness are only because of the syntactic restriction that most OO languages disallow user-designed infix operators. To wit, Scheme is equally terrible at chains of "f . g . h" and "m >>= f >>= g".
06:19:35 <Cale> @tell fen Ah, it seems you can just ignore that step on the master branch of Obelisk.
06:19:36 <lambdabot> Consider it noted.
06:21:21 <Cale> monochrom: haha, I often feel like trolling that the real sign of a functional programming language is how quiet and usable function *composition* is.
06:22:08 <monochrom> Yeah but the debate can swing the other way with the FUD that says "APL is line noise".
06:23:06 <monochrom> I think a decade ago some detractor actually said "yes x.plus(y.plus(z)) is more readable than x+y+z".
06:25:55 <fen> Cale: what do you mean about these branches? that the system is not working for the public, just the in house devs?
06:25:58 <Cale> monochrom: Yeah, since that way you know which plus you're getting, it's the one from x ;)
06:26:04 <monochrom> Backus's definition of functional programming is also around function composition and related combinators as day-to-day business.
06:26:19 <fen> or that there is some other build proceadure that is to be followed to get this working?
06:26:39 <Cale> fen: Just that it changed recently on the development branch.
06:27:12 <Cale> fen: Try just omitting that step, and if it fails, we'll just update you.
06:27:26 <Cale> (since I don't want to sort out how it was meant to be done before)
06:27:56 <tdammers> clearly, you want BinaryOperator<Int> add = IntAdditionFactory.getInstance().create(); add(x, add(y, z));
06:28:04 <Cale> At least, the readme on the master branch doesn't have that step: https://github.com/obsidiansystems/obelisk/blob/master/README.md
06:28:22 <tdammers> or maybe x.addTo(y); y.addTo(z);
06:28:35 <fen> well if you dont have the option to accespt the android dev liscence you wouldnt be able to publish
06:28:52 <fen> and you wouldnt be able to do that on behalf of the user
06:29:01 <fen> seems like an essential step either way
06:29:20 <Cale> fen: Yeah, the thing I'm confused about is whether we were auto-accepting or what.
06:29:29 <ph88> don't really get this comment https://softwareengineering.stackexchange.com/a/9022/120648 
06:29:30 <fen> uncommenting a line is about as least as you can require of the user
06:30:10 <fen> Cale: well as devs you would have signed at some point so it wouldnt really matter, but yeah, that kind of shows you dont have a stable deployment
06:30:55 <Cale> fen: All this stuff is still changing somewhat rapidly, but we are using it in our actual client projects.
06:31:26 <fen> no you cant be signing on their behalf 
06:31:55 <Cale> fen: I mean, it's a boolean flag, I'm sure we could have been setting it.
06:33:22 <fen> well, if its communicated to the user that by using your distribution they are signing the licence thats essentially no different a process of accepting that getting them to uncomment a line
06:33:36 <fen> but it would seem like a form of small print if it wasnt made clear enough
06:36:51 <fen> as much small print as actually the whole contents of the licence being signed is! 
06:38:06 <fen> hope it doesnt wave all my rights as a citizen :o
06:39:30 <Cale> haha
06:39:30 <tdammers> fen: you can't actually do that. waive your citizen's rights, that is.
06:39:49 <fen> what if it prevented me from being able to sign any other licence. that would suck
06:40:18 <fen> tdammers: surely that is one of my citizens rights
06:40:27 <Cale> tbh, I'm not sure what it does -- I haven't worked on that part of the code so much.
06:40:50 <fen> nobody does probably 
06:41:14 <fen> it disallows any lawyers from reading the licence 
06:41:44 <Solonarv> people can write whatever they want in a license but that doesn't mean it'll actually be enforcable
06:42:03 <tdammers> fen: you cannot legally allow someone to kill you (except for euthanasia, which is bound to very strict rules and procedures in countries that allow it). just because I told you to kill me doesn't mean you cannot be charged with manslaughter
06:42:30 <tdammers> fen: and the same goes for most other civil rights. some of them you can choose to not enforce, but you cannot actually waive them.
06:45:11 <fen> "by using this software you agree to use this licence in any software developed which uses this software in any way, including having been inspired by this liscence" 
06:47:09 <fen> Cale: no, if you comment out that like it throws an "error: sign the licence" 
06:47:48 <Cale> fen: ah, okay
06:48:14 <Cale> fen: In that case, I wouldn't be sure about what to do, so just update to develop: cd to the .obelisk directory
06:48:27 <Cale> and run  "ob thunk unpack impl"
06:48:41 <Cale> and then cd impl  and  git checkout develop
06:48:53 <fen> by setting nixpkgs option 'android_sdk.accept_licence = true; 
06:49:44 <Cale> Yeah, I suspect we just didn't have a handy way to set that flag, and you'd have to mess around with options elsewhere.
06:50:10 <Cale> (given that)
06:50:14 <fen> is this really a product you deploy to users!? or do you make them all sign up as devs... 
06:50:30 <Cale> We use this internally, and it's also open source.
06:50:34 <fen> that some form of wierd licence of your own devising "you now work for us!"
06:50:41 <Cale> huh?
06:50:47 <fen> jk
06:51:42 <fen> oh right, so the company just makes money by doing what exactly? porting software to android via haskell?
06:52:31 <Cale> Mostly, building web and mobile applications on behalf of other clients.
06:53:21 <fen> well it sais, fetched thunk impl, but then the nix-build -A still throws the licence error
06:53:22 <Cale> Usually from the ground up, though we have a number of different arrangements.
06:53:32 <fen> oh nice
06:53:49 <Cale> okay, so you unpacked the thunk, and then did you go into that directory and check out develop?
06:54:13 <fen> oh no... dont fire me!
06:54:41 <Cale> After checking out develop, you should be able to set that config option in your default.nix (the instructions you were reading were actually those for the develop branch, sorry)
07:00:15 <Cale> fen: In any case, feel free to complain at us about things that you find annoying, since there are people assigned full time now to improving our open source stuff and making it more approachable and usable -- we're hoping to make everything a good deal better in the coming weeks and months.
07:00:32 <Cale> (I'm spending about 50% of my time on it as well)
07:04:35 <fen> thats a really positive business model, but how does the management justify that? publicity? or are they just really nice people trying to build a better open source community? seems like the kind of thing you wouldnt get through the board of shareholders or whatever it is
07:05:45 <fen> and is it part of welltyped or whatever entity it is that maintains the core functionality of the haskell ecosystem?
07:08:00 <fen> ok! now it says its on branch develop and the build proceeds having accepted the licence! woot! 
07:11:38 <Cale> fen: Well, at least some of our clients end up being other companies who are using our open source stuff and want additional development support. But also, we'd like to generally advance the usage of Haskell in industry a bit, and make it not quite so difficult a sell when talking to new clients.
07:12:00 <fen> right
07:12:01 <Cale> fen: Also, the company is not public.
07:12:16 <fen> idk what that means
07:12:34 <Cale> I mean, there aren't public shareholders
07:12:39 <fen> ah
07:13:10 <fen> so you have nothing to answer to except your commitments to the licence you signed when joining as a dev!?
07:13:30 <Cale> haha
07:32:48 <kirne> does the $ operator only work because all other operators are prioritized?
07:33:23 <kirne> eg : show $ 1 + 1
07:33:23 <jle`> prioritized above it, yes
07:33:31 <jle`> well, it depends on what you mean by "work"
07:33:48 <Boarders> does anyone know if there is a standard way to do a zipWith like: (Monoid m) => (a -> b -> m) ->  [a] -> [b] -> m
07:33:55 <Boarders> (though for a more general zippable structure)
07:34:37 <jle`> what other structure are you talking about
07:34:47 <Boarders> in my case it is a newtype around a vector
07:34:50 <Solonarv> :t \f x y -> fold (zipWith f x y)
07:34:51 <lambdabot> Monoid m => (a -> b -> m) -> [a] -> [b] -> m
07:34:53 <Boarders>  can write the recursion by hand
07:35:00 <Boarders> but I wondered if there is a different move
07:35:02 <jle`> a vectpr, or a list?
07:35:11 <Boarders> does laziness ensure that it will do the sensible thing if I write it like that?
07:35:20 <Boarders> a vector
07:35:27 <Boarders> I just wrote list for simplicity
07:35:27 <jle`> list, it will work.  vector, no, it'll allocate a new intermediate vector
07:35:33 <Boarders> hmm ok
07:35:50 <jle`> but you should be able to V.toList both vectors, and do the same thing with that
07:36:05 <jle`> the weird thing is that vector doesn't have `zipWithA`.  if you did, you can zipWithA using Const
07:36:16 <jle`> i think this might just be a historical thing.
07:36:18 <fen> Boarders: how are you producing the vector?
07:36:19 <Boarders> and because I am consuming it it won't allocate a list
07:36:35 <Boarders> the vector is produced after parsing some data
07:36:45 <fen> like, an unfold?
07:37:01 <Boarders> I don't think so
07:37:11 <fen> a fold?
07:37:20 <jle`> you can use zipWithM_ with Writer, maybe
07:37:26 <Boarders> :)
07:37:45 <jle`> > zipWithM_ (\x y -> tell (Sum (x + 1))) [1..10] [10..20]
07:37:47 <lambdabot>  error:
07:37:47 <lambdabot>      • Ambiguous type variable ‘m0’ arising from a use of ‘show_M226160111760...
07:37:47 <lambdabot>        prevents the constraint ‘(Show (m0 ()))’ from being solved.
07:37:53 <Solonarv> though ISTR Writer being prone to space leaks
07:37:57 <jle`> > zipWithM_ (\x y -> tell (Sum (x + 1))) [1..10] [10..20] :: Writer (Sum Int) ()
07:37:58 <fen> well when your speaking of lazyness and zipping, you want to not have to build the intermidiate structure right?
07:37:59 <lambdabot>  WriterT (Identity ((),Sum {getSum = 65}))
07:38:10 <Boarders> yeah
07:38:14 <jle`> > execWriter $ zipWithM_ (\x y -> tell (Sum (x + 1))) [1..10] [10..20]
07:38:15 <fen> so you want to get down to the thing that produced the vector in the first place
07:38:16 <lambdabot>  Sum {getSum = 65}
07:38:24 <Boarders> jle': neat, though I will avoid it
07:38:43 <jle`> yeah, the most efficient way might be if zipWithA existed.  but doing fromList for both vectors is probably fine enough
07:38:53 <fen> and if this can be phrased as a state, then you can just then unfold the 2 states from the 2 things being zipped
07:39:15 <Boarders> fen: I would ideally do that but the way it is produced is complicated
07:39:28 <Boarders> also the vector is going to be used throughout the application 
07:39:34 <Boarders> so it is ok for it to be allocated
07:39:39 <fen> maybe the difficulty is then viewing a "parser" which is some kind of "consuming" pattern, as actually a "producing" pattern
07:40:15 <fen> Boarders: yeah but fusion allows you to happily use the vector, its just never actually produced under the hood
07:40:48 <fen> it saves you the trouble, but what you want is to be reassured that such a fusion can occur
07:40:49 <jle`> the thing is that it is used in multiple places in different ways, so fusion won't be able to help
07:41:17 <fen> which if your working with lists is more clear, since there may be opperations that you can do to a vector which you cant "fuse through"
07:41:22 <fen> idk about that
07:42:22 <fen> jle` : yeah but there might still be some cases where because you only use certain opperations, like traversals or something, where you can reatain fusability
07:42:29 <jle`> fusion doesn't help if you ever do multiple traversals
07:42:38 <fen> no we can fuse those
07:42:39 <Solonarv> if it gets "fused" into every use site you just end up duplicating work
07:42:45 <Solonarv> potentially a lot of work, even
07:42:54 <fen> what?
07:43:15 <Solonarv> if there is no intermediate structure (because it fused away) you can't share the intermediate structure
07:43:17 * hackage cabal-rpm 0.13.2 - RPM packaging tool for Haskell Cabal-based packages  https://hackage.haskell.org/package/cabal-rpm-0.13.2 (JensPetersen)
07:43:21 <Solonarv> s/structure/result/
07:43:24 <fen> you mean it should store the intermidiate representaion of the unfolded thing and not re-unfold it
07:43:27 <fen> ?
07:43:52 <Solonarv> if you're going to traverse it multiple times, yes, you might not want to fuse it away
07:44:19 <fen> but if your doing multiple traversals on one version, and multiple traversals on another...
07:44:35 <fen> oh no, this is going to want to get to the place where the traversals started being different...
07:44:44 <fen> :'(
07:45:23 <adamCS> Solonarv: huh.  I hadn't thought about that! Like if you have an aggregated data set and you want to do multiple things on the aggregated groups, you have to be careful to fuse in the right order.  You can still fuse but only after you make all the reductions of the aggregated data into one operation on the aggregated data.
07:46:40 <fen> you want to cache the unfolding through the common traversals, so there may be many caches if the traversals have common paths up to some branching point in a tree from the original state at the top of the tree to the multiple references to the structure traversed over in defferent ways at the nodes
07:47:03 <jle`> yeah. and that cache here is the vector.
07:47:20 <fen> huh?
07:47:30 <fen> no you can still fuse down to the state
07:47:32 <jle`> cacheing the state of the unfold so you can branch and process it in different ways
07:47:37 <fen> but just run through a bunch of functions
07:47:41 <jle`> that point of divergence is the vector
07:48:16 <fen> im not sure if there are advantages of storing it in any particular representation
07:48:29 <jle`> it's situational
07:48:34 <jle`> in this situation it's a vector
07:48:37 <fen> maybe by definition, if there were, it would be because it would ruin this traversal unfold fusion branching thing
07:48:41 <jle`> in another situation it might be something else
07:48:52 <fen> jle` it need not be if its just an intermidiate representation
07:49:07 <fen> and if there is any reason for it to be, then it must be because it cant be fused like this
07:49:32 <jle`> if you ever generate a vector and traverse it more than once, fusion is only going to make you duplicate work
07:49:38 <fen> and the idea was to phrase all the opperations using traversals so that it could fuse like this
07:50:01 <fen> no, the fusion can combine multiple traversals
07:50:19 <fen> maybe the point where it branches is where it actually has to complete a traversal
07:51:29 <jle`> you can often merge traversals into a single traversals. but in many situations you can't
07:52:57 <fen> you always can
07:53:12 <fen> oh
07:53:24 <fen> for traversals defined using get/set
07:54:27 <fen> and, if this traversal thing is making a new state by passing the values from the original state through the traversal functions, then the point where it branches is still a state in the fused piture
07:54:49 <fen> so no, it does not need to re-traverse or actually complete a traversal
07:56:49 <tabaqui> hmm, vim highlight the "unit" term
07:56:54 <fen> not sure if get/set is the best implementation for traverse for vectors, but if it allows them to never be produced, then it would be?
07:56:56 <tabaqui> but I don't know such keyword
07:56:59 <tabaqui> any ideas?
07:57:06 <tabaqui> *highlights
07:57:28 <c_wraith> definitely not a keyword.
07:57:29 <tabaqui> just "unit" not "Unit"
07:58:00 <FliiFe> doesn't highlight it for me, strange...
07:58:33 <FliiFe> it's a keyword in ocaml though
07:58:44 <tabaqui> neovim + haskell-vim plugin
07:59:05 <FliiFe> Same setup
07:59:15 <yyt16384> Well I don't know this plugin but the one I'm using have "unit" as a keyword
07:59:29 <yyt16384> when g:haskell_backpack is 1
07:59:34 <yyt16384> so this is probably where it's from
08:00:00 <tabaqui> probably
08:00:11 <tabaqui> dunno, I copied this string from github page
08:00:16 <tabaqui> what is backpack?
08:00:24 <fen> jle` the point is that vectors have things its faster not to do via traverse?
08:00:50 <FliiFe> > Backpack is a system for retrofitting Haskell with an applicative, mix-in module system. It has been implemented in GHC 8.2 and cabal-install 2.0, but it is not supported by Stack.
08:00:52 <lambdabot>  <hint>:1:66: error: parse error on input ‘,’
08:01:37 <tabaqui> https://ghc.haskell.org/trac/ghc/wiki/Backpack
08:01:39 <tabaqui> I see...
08:02:28 <tabaqui> see no point for me
08:02:34 <fen> is it that by using an internal representation as a tree, they have faster navigations to values than via traversal, and that makes things which dont act on every value faster?
08:02:34 <tabaqui> ok, thanks, I'll disable it
08:03:40 <fen> so that except for "lookup table" things (hash-map?) then they all have a tree structure, and its only ever a case of branch balancing? 
08:05:10 <Cale> fen: Vector uses a flat array representation (or a lazy list of such)
08:05:19 <fen> whats that?
08:05:27 <fen> "flat array"
08:05:31 <Cale> fen: So indexing into a strict Vector is "O(1)" -- it's just a memory lookup
08:05:46 <fen> oh the boxing unlifted stuff?
08:06:02 <fen> (or a lazy list of such) like a tree?
08:06:07 <Cale> oh, there's no lazy Vector, right
08:06:17 <Cale> So they're all just arrays :)
08:06:25 <fen> what is this!?
08:06:40 <Cale> The unboxed vs. boxed thing is whether they support laziness and polymorphism in the elements
08:06:58 <fen> well its not just a strict list!?
08:07:16 <Cale> Unboxed vectors pack the elements directly into the array, so they use less space and are faster, but only work for certain element types and you lose out on polymorphism.
08:07:44 <Cale> Boxed vectors are contiguous arrays of pointers to code for the elements
08:08:10 <fen> in a tree shape?
08:08:13 <Cale> no
08:08:20 <fen> well that would be slower?
08:08:24 <Cale> in a contiguous segment of memory shape
08:08:38 <Solonarv> indeed, a tree shape would be slower (for some operations)
08:08:40 <fen> could have a tree shape then would only need to follow fewer branches to get to the values
08:08:48 <fen> pointer chasing branches or whatever
08:08:53 <Cale> You don't follow any branches
08:08:55 <Solonarv> for example you cannot have O(1) indexing with a tree shape
08:08:55 <fen> or they are strictly a linked list?
08:08:59 <c_wraith> a vector is just pointer arithmetic
08:08:59 <Solonarv> no!
08:09:02 <Cale> They're not a linked list at all
08:09:13 <fen> :-/
08:09:21 <Cale> You just do some pointer arithmetic and follow a single pointer to your element
08:09:29 <Cale> even in the boxed case
08:09:38 <fen> oh ok
08:09:43 <Solonarv> imagine:
08:09:43 <Solonarv> data Vector a = Vector0 | Vector1 a | Vector2 a a | ... -- imagine this going on forever
08:09:45 <Cale> In the unboxed case, you do the pointer arithmetic and your element is at that location
08:09:50 <fen> thats what this contiuguousness means?
08:10:00 <Solonarv> this is not the actual implementation but gets you mostly the right intuitions
08:10:20 <Cale> Yeah, I mean there is some chunk of memory which is all allocated at once, and the entire array is inside that.
08:11:06 <fen> but didnt we establish its sometimes faster to not do integer aritmatic ?
08:11:11 <Cale> no
08:11:48 <fen> well how could you ensure the calculations were done effeciently if there were several and they could share some work?
08:11:50 <Cale> Doing integer arithmetic is one of the fastest things that modern processors can do
08:12:01 <Solonarv> you claimed that and then refused to provide any reason for why it should be the case, other than waving your hands and mumbling about fusion
08:12:18 <Cale> (and never gave us a demo of it actually working)
08:12:29 <fen> regardless, if they brute force something that could be done cheaper just because they are apparently inexpensive, then they could become the most intensive part of a program needlessly 
08:12:48 <fen> Solonarv: not using the unitary stuff
08:13:16 <Cale> Pointer arithmetic that gets you to the element that you want in one step is always going to beat following a bunch of pointers
08:13:20 <fen> just eg (n,m) = (2*3*5*(7-1)*11,2*3*5*(7+1)*11)
08:13:24 <Cale> Pretty much all the time
08:13:58 <fen> if my values are there, and i embed by aritmatic into the shape of the tree, then i can share common computation
08:14:07 <Cale> Ideally, you're doing a single add followed by a load
08:14:27 <fen> well no, not if we have a high dimensional cartesian domain
08:14:32 <Cale> vs. doing several loads as you follow the pointers in this tree
08:14:38 <fen> and eg, want 2 points in a low dimensional submanifold
08:14:46 <Cale> A vector doesn't have multiple dimensions
08:14:48 <fen> which is very common in modern computation
08:14:55 <fen> Cale: thats the point!
08:15:13 <Cale> I don't know what the point is any more
08:15:26 <fen> it would correspond to faster ways to calculate the adresses of ellements in some common substructure
08:15:32 <fen> like, a section
08:16:14 <zachk> if you add or subtract one from a number, as far as I know you need to totally refactor the number in the general case 
08:16:28 <Cale> It's still generally going to be *way* better to calculate an offset like that in registers than it is to do a whole bunch of pointer indirections
08:16:46 <Cale> A single load takes hundreds of times longer than a single arithmetic operation
08:17:23 <Cale> Of course, in Haskell, things get a little weird, since your numbers are themselves lazy
08:17:26 <fen> the point is that random access memory means random access containers can be imporoved on. unless their randomly access locations are created in a structured way, and the handling of the most effecient utilisation of this structured computation can be abstracted away on the behalf of the user through judicious branch balancing 
08:17:50 <Cale> Don't get me wrong, there are plenty of uses for Data.Map and such
08:17:59 <Cale> and other balanced tree structures
08:18:09 <Cale> But performance isn't the reason to prefer it
08:18:31 <fen> Cale: right, so we just need a structure that is 100s of times more structured for it to start to be more noticably more effecinet
08:18:43 <Cale> "more structured"?
08:18:44 <fen> big data uses millions of dimensions!
08:19:30 <fen> the space of posseble molecular structures is rediculously large, exploring these phase spaces needs really careful structure  
08:19:38 <Cale> In cases where there are millions of dimensions, usually you use sparse vector representations
08:20:37 <Cale> Also, it's not millions of dimensions in terms of the layout of memory
08:20:50 <Cale> It's just millions of individual indices.
08:21:16 <Cale> Heh, that could be taken the wrong way as well. What I mean is that the tensor rank is generally not that high.
08:21:20 <fen> you can have some kind of blured path, so that if you stray from the optimal path you still have training data to navigate with, is that the kind of sparsity you mean? not quite dirac sections, just pdfs that are mostly over some low volume region
08:21:36 <Cale> People are still working with matrices and vectors, just very large ones.
08:22:17 <Cale> and ones which are mostly filled with 0's
08:22:19 <fen> so if you are navigating along some structured submanifold, it would be great if this structure was utilised by the memory access to make faster computations
08:22:29 <Cale> so it becomes more efficient just to store tables of the nonzero entries
08:22:34 <fen> that is, to exploit the sparsity of the data
08:22:51 <Cale> "submanifold" seems like the wrong term
08:22:52 <fen> a lookup table is way less effecient 
08:23:02 <fen> hypersurface?
08:23:12 <adamCS> MarcelineVQ: This github issue thread (https://github.com/composewell/streamly/issues/187) has a brief discussion of my "effect" problem in Streamly and the suggested solution is along your lines, to use the fact that (IsStream t, Monad m) always means (Monad (t m)) and then do things in that monad. Thanks again!
08:23:24 <Cale> But I don't really know what you're referring to now
08:23:49 <fen> a low demensional subsection of the total data, its very simple
08:24:11 <Cale> Data structures are usually discrete because computers have a finite amount of memory
08:24:29 <Cale> Unless we're talking about function types.
08:24:37 * fr33domlover wonders whether fen and Cale have benchmarks that can help them resolve this thing by looking at the actual data
08:24:45 <MarcelineVQ> adamCS: neato
08:24:56 <fen> eg, a stochastic fluid simulation where the exact solution at some advanced time is not sought, but instead as sharply a peaked pdf around the most likely solution among a noisy evolution
08:25:46 <fen> we dont care about most of the possible configurations of the fluid, just along some tangle, or whatever its called
08:27:02 <fen> like if we have addaptive resolution, we only increase the acuracy if we get too close to a bifurcation point
08:27:11 <Cale> fen: Well, you're talking about a very abstract problem now. You'd have to specify how everything is stored to get back to a question about data structures.
08:27:34 <fen> so we increase the sparsity, or decrease the volume of the subsection of total space that we are interested in
08:28:02 <fen> Cale: you were asking about what was meant by submanifold or hypersurface section
08:28:10 <Cale> Sure, for such problems space partition trees are often natural
08:28:30 <fen> no, just use a vector
08:28:43 <fen> is in a flat box and its as fast as possible
08:29:29 <Cale> Possibly. It depends on what we're storing, and how that's changing as our algorithm operates.
08:29:41 <fen> it uses a lookup table and no knoledge of the shape of the underlying data could help make repeated quiries to close by locations faster
08:30:21 <Cale> I don't understand what we're talking about any longer or how this is at all relevant to what came before though.
08:30:26 <fen> (ok, the idea of this "low volume" "sharply peaked pdf" is to give some meaningfull idea to the notion that all our data is "close" to all the other data) 
08:30:45 <fen> (all the other data we are interested in / access)
08:31:05 <zachk> if it's a vector and you only want some of it's dimensions, it might be able to be called a subspace 
08:32:15 <fen> Cale: we want to use the intrinsic "shape" of our problem - the nearby positions of the solution space we access, to increase the effeicy of our search
08:32:35 <fen> not to just index everything by a number and use a lookup table
08:34:51 <fen> if i know that 2 locations are "close" in some sense, then this notion can lead to a faster way to calculate both addresses together than seperatly
08:36:30 <fen> the sense of orthogonality is lost when you index everything by integers
08:37:10 <fen> unless you build the structure into how those integers are calculated
08:37:42 <fen> so the idea is to have some control over that process and abstract it from the user for them by using nifty datastructures
08:45:47 * hackage snmp 0.3.1.0 - SNMP protocol library  https://hackage.haskell.org/package/snmp-0.3.1.0 (andrewthad)
08:50:06 <fen> basically, the vector should just go at the lowest possible level, and its indexing should be taken care of by a data-structure above it
08:52:08 <fen> unless your emulating your memory on a fpga!!
08:52:16 <fen> then you can use the structure directly
08:53:06 <fen> "structured access memory" 
08:59:17 * hackage birch-beer 0.1.1.0 - Plot a colorful tree.  https://hackage.haskell.org/package/birch-beer-0.1.1.0 (GregorySchwartz)
09:03:02 <weebull[m]> Is there any guidance on choosing things like mconcat vs sconcat vs concat? Seems like it's only the type classes which differ, and some are more general than others.
09:04:17 * hackage aeson-quick 0.1.3 - Quick JSON extractions with Aeson  https://hackage.haskell.org/package/aeson-quick-0.1.3 (ssadler)
09:12:47 * hackage language-asn 0.1.1.0 - ASN.1 encoding and decoding  https://hackage.haskell.org/package/language-asn-0.1.1.0 (andrewthad)
09:19:47 * hackage birch-beer 0.1.1.1 - Plot a colorful tree.  https://hackage.haskell.org/package/birch-beer-0.1.1.1 (GregorySchwartz)
09:22:46 <jle`> weebull[m]: generally i pick the least polymorphic/general applicable function
09:23:13 <jle`> hm. maybe that's a bad way of puting it
09:23:18 <jle`> generally i pick the least powerful abstraction
09:24:03 <jle`> for example, i'll use traverse instead of mapM
09:24:20 <jle`> but i guess i'll use also map instead of fmap, so i'm not sure what i'm saying anymore :)
09:26:17 * hackage log-base 0.8.0.0 - Structured logging solution (base package)  https://hackage.haskell.org/package/log-base-0.8.0.0 (MikhailGlushenkov)
09:27:52 <adamCS> weebull[m]: I guess it depends what you're trying to accomplish?  The most specific/least polymorphic might be the easiest to understand for you now, or you later, or someone else.  It might also be the most performant, though not always.  But sometimes the most general can be a nice clue to a useful generalization of your function and that might lead in a fun/productive direction.
09:30:46 <adamCS> Like, if you write a function that does something on lists, maybe you want to be very clear that it's lists.  So use list specific things.  But maybe you're only using list as a foldable, adding all the elements or doing something to each and then combining them somehow, and then maybe it's worth re-writing in terms of Foldable and Functor?  But it depends on your use-case, style, etc.
09:45:47 * hackage too-many-cells 0.1.5.0 - Cluster single cells and analyze cell clade relationships.  https://hackage.haskell.org/package/too-many-cells-0.1.5.0 (GregorySchwartz)
10:10:03 <pezubi> Hey guys
10:10:20 <pezubi> is there anyone who could me with this? https://pastebin.com/4UfUtjf2
10:10:50 <glguy> pezubi: Please use almost any pastebin but pastebin.com. What's your question about that code?
10:11:16 <pezubi> i don't know why this isn't working :D
10:11:45 <glguy> In C you call a function with:    f(x,y,z)    but in Haskell you write    f x y z
10:14:28 <pezubi> That's not the solution :[
10:15:29 <glguy> Yes, that's the only thing that's preventing the code you pasted from working
10:19:01 <pezubi> no absolutely not
10:19:56 <Solonarv> well then, what code do you have now and what error are you getting?
10:31:35 <dkurilo> pezubi: https://pastebin.com/a2fhEphD
10:32:40 <cocreature> anzahl a = length . filter (a==)
10:42:02 <adamCS> If I have  "f :: Foldable g=> g x -> a", I can always make it into a foldl style fold with 'fmap f (Control.Foldl.list)" but that use of "list" feels arbitrary. Will that always get fused away since f must be a fold?  What I am hoping for is a cost-free way to transform any "Foldable g => g x -> a" to Control.Foldl.Fold x a. 
10:46:12 <dmwit> That doesn't make `f` magically behave as a left fold. It seems from your question that you were imagining it would; were you?
10:46:18 <MarcelineVQ> adamCS: doing more streamly stuff?
10:48:29 <adamCS> MarcelineVQ: I'm working on some map-reduce stuff. Very simple, just trying to make using some very typical data-science type aggregations a little more straightforward.  The Streamly bit was/is using streamly as an engine for the intermediate steps (mapping, filtering, assigning keys, grouping, and then reducing the groups).  This question has to do with the reducing but.
10:48:35 <adamCS> s/but/bit
10:49:16 <adamCS> dmwit:  I guess.  Can you explain that more?  I don't understand exactly what you mean but I think if I did I would understand my own question better as well.
10:50:01 <MarcelineVQ> aha just wondering as streamly has foldl compliant combintors, https://hackage.haskell.org/package/streamly-0.6.1/docs/Streamly-Prelude.html#v:foldx https://hackage.haskell.org/package/foldl-1.4.5/docs/Control-Foldl.html#g:6
10:50:15 <MarcelineVQ> Don't know anything about foldl (package) myself though
10:52:46 <MarcelineVQ> Would be interested to see how/where you're intending to use "f :: Foldable g=> g x -> a" though
10:54:44 <adamCS> MarcelineVQ: yeah. This is a more general issue.  I could require the reduce step to be a Control.Foldl style fold.  That would simplify things.  But I would like to not force that choice on users.  So I have two constructors for "Reduce x a",  one for "Control.Foldl.Fold x a" and one that holds a "(forall h. (Foldable h, Functor h) => h x -> a)" and, well, that second one is a pain to use.  My options are to convert
10:54:44 <adamCS>  everything to folds or have the Reduce type also have a parameter for the "h".  But that's annoying a different way. 
11:16:49 <nshepperd> has anyone managed to use 'cabal new-foo' for package management in anything that calls ghc directly?
11:17:06 <nshepperd> it's completely broken for me
11:18:03 <cocreature> nshepperd: sounds like a case where environment files might actually be helpful? what exactly do you mean by “completely broken”
11:23:45 <nshepperd> so, i've tried invoking my build tool under new-exec, but ghc complains that it can't find various modules even though they're listed in build-depends
11:24:37 <Solonarv> looks like environment files might indeed help, then
11:25:24 <Solonarv> there should be an incantation to build dependencies and create the env file without trying to build the actual package; once you've done that ghc should be able to see the dependencies
11:27:23 <nshepperd> 'should be' or 'is'?
11:29:08 <nshepperd> (nonfatal annoyances: new-exec has no -b option so i have to make a whole cabal file just to list the dependencies, and new-exec fails completely with some 'no such directory' error about ./dist-newstyle if I don't run new-build first)
11:29:29 <Solonarv> I'm fairly confident that there is such an incantation but haven't checked
11:34:40 <nshepperd> ok, after running new-exec bash so that it doesn't delete the ephemeral environment file it creates, it seems like it's just making it wrong
11:34:48 <nshepperd> some of my deps are just not in the list
11:36:56 <jle`> what's that word for a recursive data type where the recursion is with a different type variable than originally 
11:37:22 <jle`> data Blah a = Mk (Blah (Int -> a)) or something
11:38:09 <Solonarv> I've heard "non-regular recursion", or "polymorphic recursion"
11:38:30 <jle`> ah, i was searching for 'irregular'
11:38:36 <jle`> curse this english language
11:39:06 <nshepperd> it's also called irregular
11:40:05 <jle`> Solonarv: thanks!
11:40:16 <jle`> nshepperd: nothing showed up when i googled irregular, for some reason
11:44:05 <Solonarv> nshepperd: looks like v2-build still takes a --only-dependencies flag:
11:44:05 <Solonarv> $ cabal v2-build --only-dependencies --write-ghc-environment-files=always $TARGET
11:45:06 <Solonarv> that'll create a .ghc.environment.ARCH-GHCVER file in the project directory, which GHC will pick up automatically
11:50:55 <cjay-> is there a way to use pattern synonyms on the type level?
11:51:16 <nshepperd> hm, ok, so i make a dummy directory with a cabal file with the requisite dependencies, call v2-build there and take the environment file it makes
11:55:45 <Solonarv> I was actually suggesting running this in your actual project directory (where you presumably have a cabal file), but I suppose that'd work too
11:57:46 <nshepperd> wait what the heck?? i was sitting here wondering "why isn't cabal new-build rebuilding anything when i delete ./dist-newstyle", tried deleting ./garbage (a backup directory where i moved a bunch of cabal stuff: .cabal file, Setup.hs, dist-newstyle from last time I was trying to get this to work) and suddenly it starts actually builidng stuff >_>
12:04:32 <nshepperd> Solonarv: ok, that seems to work
12:04:54 <nshepperd> now for hard mode: how do i get cabal to build profiling versions of all these libraries and include those as well
12:06:48 <slack1256> cabal new-build --enable-profiling?
12:07:59 <nshepperd> ...of course
12:08:02 <Solonarv> should be as simple as passing that flag, yes :D
12:08:13 <nshepperd> (it's not cabal new-build --profiling, naturally)
12:10:18 <nshepperd> (which turns out to be automatically expanded to --profiling-detail, which has no effect if profiling isn't enabled)
12:25:04 <nshepperd> awesome, i think it works. thanks Solonarv, slack1256 
12:25:14 <isn> rev :: [Int] -> [Int]
12:25:14 <isn> rev [] = []
12:25:14 <isn> rev (h:t) = rev t ++ [h]
12:25:16 <isn> Hey guys, I've created a function that reverses list: 
12:25:29 <isn> however, I'm having trouble with understanding the logic
12:25:35 <isn> of this: rev (h:t) = rev t ++ [h]
12:25:56 <isn> in my head I thought I did: rev (h:t) = rev (t ++ [h]), but when I do that the program crashes
12:26:22 <isn> can someone explain the thought pattern here or break down how it gets calculated from rev t ++ [h]?
12:28:00 <Solonarv> function application binds the tightest, so 'rev t ++ [h]' is '(rev t) ++ [h]'
12:28:03 <Solonarv> does that help?
12:28:14 <Solonarv> s/the tightest/tighter than any operator/
12:29:10 <isn> hm, I'll have to process that, thanks :P
12:29:18 <isn> I'm not sure what you mean by "tightest" though
12:41:03 <Solonarv> example: * binds tighter than +
12:41:03 <Solonarv> this means that 'x + y * z' is actually 'x + (y * z)'
12:43:28 <MarcelineVQ> iow has higher operator precedence
12:43:45 <MarcelineVQ> just in case that is a familiar term
12:45:24 <fen> Cale: so how do you use obelsik to interface with an android project in android studio?
12:45:35 <__monty__> Haskell's precedence levels go from 0 (least) to 9 (most) tightly bound. Function application has a precedence of 10 : >
12:46:05 <freusque> what operator or function can I use to make this nicer: ma >>= ( \x -> ( mb x >> return x) ) ? I'm looking for something of type m a -> (a -> m b) -> (a-> m c) -> m b . Tried hoogling.
12:46:12 <fen> so its easy it seems to bypass it alltogether, but what about when some android-side stuff needs to be done, like giving access to specific hardware IO
12:46:38 <freusque> I just essentially want to plug some monadic 'tee' in a list of monad chains
12:46:56 <fen> how can a haskell library like openGL or SDL be made to work with android hardware commands using obelsik?
12:47:04 <freusque> and I don't like that lamba too much
12:47:38 <fen> freusque: isnt that what applicative is for?
12:48:09 <Solonarv> ma >>= ( \x -> ( mb x >> return x) )
12:48:09 <Solonarv> ma >>= (\x -> x <$ mb x)
12:48:09 <Solonarv> ma >>= ap (<$) mb
12:48:13 <fen> or is this some kind of sequencing of liftA2?
12:48:19 <fen> composing*
12:48:33 <fen> :t ma >>= ap (<$) mb
12:48:34 <lambdabot> error:
12:48:34 <lambdabot>     • Variable not in scope: ma :: m a
12:48:34 <lambdabot>     • Perhaps you meant one of these:
12:48:46 <fen> :t \ma ap mb -> ma >>= ap (<$) mb
12:48:47 <lambdabot> (Functor f, Monad m) => m a1 -> ((a2 -> f b1 -> f a2) -> t -> a1 -> m b2) -> t -> m b2
12:48:54 <rfold> How do the free variables of mutually recursive thunks get initialized in an STG letrec? Are the thunks first all allocated, and then their free variables reassigned? I can't reproduce GHC generating any STG letrecs.
12:49:06 <freusque> ohh ^_^
12:50:01 <benzrf> rfold: you could look at the cmm output
12:50:06 <benzrf> there's -ddump-cmm
12:50:07 <Solonarv> you could also just define: tee k x = x <$ k x
12:50:18 <Solonarv> (well, tee isn't quite the right name)
12:50:32 <benzrf> ruby calls this "tap" iirc
12:50:36 <freusque> thanks so much.. 
12:50:37 <Solonarv> then your original function becomes: ma >>= tee k
12:50:37 <rfold> benzrf: I first need to get GHC to generate letrecs, which turns out to be rather difficult.
12:50:41 <benzrf> oh, hah
12:50:57 <freusque> yep. so cool.
12:51:08 <benzrf> https://benzrf.com/uploads/cec37970f6149936.png
12:52:22 <rfold> benzrf: For example, I expect this to generate a letrec, but it doesn't: https://glot.io/snippets/fb57eni9p6
12:52:37 <freusque> Solonarv:  `btw` is a better alias I guess :)
12:53:12 <Solonarv> oh, I like that :D
12:53:43 <Solonarv> 'tee' suggests we'd get both results, with a signature like '(a -> m b) -> a -> m (a, b)'
12:53:45 <MarcelineVQ> how to reconcile the desired type sig: m a -> (a -> m b) -> (a-> m c) -> m b
12:54:12 <MarcelineVQ> given that the op example doesn't have that sig itself
12:55:57 <benzrf> rfold: oof
12:56:15 <benzrf> rfold: how about sth like "let as = 1:bs; bs = 2:as"
12:56:18 <freusque> x <- readFile fn >>= btw print 
12:56:20 <freusque> so cool.
12:57:38 <rfold> benzrf: Even that doesn't seem to do it. Adding NOINLINE g and NOINLINE h however seems to do the trick.
12:57:55 <benzrf> oh nice
12:58:02 <benzrf> wait so then what *does* it generate for as bs
12:58:35 <rfold> Oh nevermind, yes it does generate a letrec for your example. :)
12:58:44 <rfold> I read it incorreclty and picked x instead of 1 and 2.
12:58:50 <benzrf> heh
13:01:32 <reallyme1orable> Has anyone here had issues adding typerep-map to their build depends?
13:01:45 <reallyme1orable> It won't work for me
13:02:20 <reallyme1orable> I get this error: https://gist.github.com/reallymemorable/b48b711f585f6c3c4bcdb9f9c4a847dc
13:02:48 <freusque> next question, how to make mapM_ (>>= amb) [ma1, ma2] nicer? where amb :: a -> mb, and ma1 and ma2 are of type m a
13:03:15 <benzrf> freusque: (ma1 >>= amb) >> (ma2 >>= amb)
13:03:30 <freusque> you think the duplication makes it more readable?
13:03:35 <benzrf> kinda :p
13:03:39 <MarcelineVQ> nicer isn't well defined :>
13:03:58 <freusque> yes I agree, just taste
13:04:04 <rfold> benzrf: Thanks, this is helpful. What it seems to do is allocate all the thunks on the heap in a single pointer-bump, and then update all their free variables after that. The compiler can already precalculate their offets from the heap pointer at compile-time, since it knows the sizes of all the thunks.
13:05:29 <benzrf> 👍
13:06:16 <rfold> Now I wonder how GHCJS does it; without pointer bump allocation. :D
13:07:21 * nshepperd sprinkles irrefutable pattern markers everywhere to slake ghc's new hunger for MonadFail instances~
13:13:48 <reallyme1orable> no one else has had trouble with typerep-map?
13:15:38 <glguy> reallyme1orable: This is what I get: https://gist.github.com/reallymemorable/b48b711f585f6c3c4bcdb9f9c4a847dc#gistcomment-2884914
13:16:51 <glguy> reallyme1orable: You've got some other constraints but a bit of nix mess adding additional fun
13:17:54 <reallyme1orable> glguy: i added a comment to your gist
13:17:57 <reallyme1orable> with my error
13:18:44 <glguy> reallyme1orable: I have no idea why that command is cloning things from git
13:19:02 <glguy> what version of the cabal command are you using?
13:19:46 <reallyme1orable> ok i changed directories and ran it again
13:19:51 <reallyme1orable> and got a very different result
13:19:53 <reallyme1orable> which I pasted
13:20:21 <glguy> reallyme1orable: Also this means you have the wrong GHC version: [__1] rejecting: base-4.12.0.0/installed-4.1..., base-4.12.0.0 (constraint from project config TODO requires ==4.11.1.0)
13:20:53 <reallyme1orable> is that a separate issue or the cause of this
13:22:34 <glguy> probably just a different issue. In the case of missing "primitive >=0.6.4" I'd look at your nix file and see what version of primitive it is trying to use, if any
13:24:20 <reallyme1orable> hmm ok
13:24:32 <reallyme1orable> but what does it mean that typerep-map builds with that cabal command
13:24:41 <reallyme1orable> but wont build in my program
13:29:28 <glguy> It means your nix file is probably somehow too restrictive
13:33:31 <reallyme1orable> hmmm
13:33:32 <reallyme1orable> ok
13:33:33 <reallyme1orable> thank you
13:53:12 <reallyme1orable> ok so something is pinning primitive to a version that is < 0.6.4, but I need it to be greater than or equal to that
13:53:28 <reallyme1orable> does anyone know how to find out what is pinning a dependency version
14:12:19 <tabaqui> can I disable monomorphic restriction for specific function without writing its annotation?
14:12:39 <monochrom> I think no. Either whole module or hand-write type.
14:12:49 <tabaqui> okay
14:12:54 <monochrom> Or add a fictional parameter.
14:13:01 <tabaqui> proxy?
14:13:08 <tabaqui> hmm, it is interesting
14:13:09 <monochrom> f () = 5
14:14:23 <tabaqui> err, don't get how it works, but I'll try
14:15:12 <tabaqui> dunno, in my case it doesn't work
14:15:18 <tabaqui> I will add a proxy then
14:15:24 <tabaqui> thx, anyway
14:15:27 <cjay-> is there a generic way to convert a promoted type value to a normal value?
14:15:29 <monochrom> What error message?
14:16:02 <monochrom> Because if the error message is "ambiguous type variable" then it works.
14:16:40 <monochrom> For the monomorphic restriction actually has the benefit of circumventing a ton of those ambiguous type variables.
14:16:57 <tabaqui> > Couldn't match expected type ‘CPU’ with actual type ‘RAM’
14:16:59 <lambdabot>  <hint>:1:25: error: parse error on input ‘type’
14:17:11 <tabaqui> (CPU and RAM are different newtypes ahead of Int)
14:17:17 <matthewbauer> is there anyone designated as a maintainer for haskell-mode? It looks like there are quite a few good prs that have been waiting for a long time
14:17:29 <tabaqui> and I let binding of some "f" with (f cpu, f ram)
14:17:36 <tabaqui> *I use let...
14:18:00 <tabaqui> matthewbauer: try haskell-ide-engine
14:18:15 <tabaqui> haskell-mode is somewhat abandoned
14:18:33 <monochrom> OK, too many other moving parts then.
14:18:34 <tabaqui> oh, sorry
14:18:42 <tabaqui> I confused with ghc-mode
14:18:50 <monochrom> ghc-mod?
14:19:12 <tabaqui> yeah, it was not well supported, when I looked it last time
14:19:17 <tabaqui> about an year ago
14:19:28 <monochrom> haskell-mode hasn't updated for a while either.
14:19:29 <tabaqui> I migrated on hie
14:19:44 <matthewbauer> i want closer integration than lsp provides
14:19:57 <matthewbauer> it's nice to have a managed ghci buffer for instance
14:22:04 <matthewbauer> another question: is there a way to get ghci to send out haddocks documentation for a specific value? 
14:23:00 <monochrom> HIE and haskell-mode (and everything else really) suffers the same fundamental problem. However, only haskell-mode (maybe also dante) allows you to work around it.  And ironically the reason is that haskell-mode is not a close integration.
14:23:49 <saml> IDE is hard
14:23:57 <matthewbauer> monochrom: close integration to emacs that is as opposed to haskell
14:24:01 <monochrom> The problem is this. If your file contains errors, and you load/reload, the error causes the ghc/ghci backend to lose all information, e.g., imports, types, autocompletion.
14:24:50 <monochrom> Now, with HIE or anything that brags about "close" integration, the moment you hit "save" you also get an automatic do-gooder reload. You lose.
14:25:45 <monochrom> With haskell-emacs, "save" does not imply reload. That is an advantage. You don't lose.
14:26:16 <monochrom> So my workflow is this. I have emacs and haskell-mode. In another window, I have ghcid.
14:26:40 <monochrom> I hit "save". If there is an error, ghcid will warn me. So I don't "reload" until I fix that error.
14:26:47 <monochrom> This is two-phase commit.
14:26:51 <Solonarv> matthewbauer: :doc
14:26:56 <Solonarv> (in ghci)
14:26:59 <monochrom> HIE does not allow you to do this.
14:27:09 <Solonarv> it's very recent and still experimental, but it's there
14:27:18 <monochrom> "close" integration is a curse.
14:27:41 <matthewbauer> Solonarv: that's a hoogle thing right?
14:27:51 <monochrom> This is very well known and everyone who use HIE or ghc-mod or intero suffers this on a daily basis.
14:28:08 <monochrom> Why they still evangelize them, I don't understand.
14:28:23 <monochrom> This is when I chalk it up to "programmers are religious people".
14:28:38 <Solonarv> nope, :doc is built into ghci
14:28:51 <geekosaur> recent enough ghci
14:29:01 <Solonarv> Not sure when it got added, I think 8.6
14:29:19 <saml> so, just use ghci + any editor?
14:29:36 <matthewbauer> Solonarv: ok thanks! that's exactly what i was looking for
14:30:20 <saml> coding in haskell doesn't help in coding interviews at all, right?
14:30:36 <saml> for non-haskell job
14:30:53 <monochrom> I don't think anyone has data on that.
14:31:23 <matthewbauer> monochrom: that sounds like a good workflow. i have a similar setup, just using flycheck instead of ghcid
14:31:29 <monochrom> But my hunch is the most helpful thing is to demand a computer during coding interviews. Refuse "just write code on whiteboard".
14:31:48 <c_wraith> I have anecdata. it certainly got attention and curiosity when I mentioned Haskell in interviews.
14:34:01 <monochrom> I suddenly have this great idea that I should put up a bot that can detect opinion questions (perhaps backed by machine learning whatever) and automatically reply "I don't think anyone has data on that".
14:34:07 <c_wraith> but I suspect I'd have got the same set of offers without it.
14:35:14 <monochrom> Its effect is to frame the conversation and suddenly people don't feel like giving opinions.
14:35:47 <c_wraith> wait, it inspired me to provide an opinion!
14:36:47 <monochrom> like "data Opinion = Yes | No deriving (Eq, Ord, Enum, Bounded)"?
14:37:08 <monochrom> What is your opinion on the resulting Yes < No? >:)
14:37:32 <MarcelineVQ> forgot to derive Generic
14:37:41 <monochrom> haha
14:37:46 <c_wraith> and Show!
14:44:56 <nshepperd> my opinions are Generic, let me Show them to you
14:45:19 <saml> big data backed troll detection can be useful
14:58:10 <Solonarv> yeah, it got us at least one GHC language extension!
15:17:05 <dmwit> adamCS: Well, what I meant is that `list` will use a left fold to convert your Foldable thing to a list. But then the `fmap myFold` part will do whatever direction of folding `myFold` does on the list that produced, which might be a right fold or a left fold or something more bizarre.
15:52:47 * hackage hasql-transaction 0.7.1 - A composable abstraction over the retryable transactions for Hasql  https://hackage.haskell.org/package/hasql-transaction-0.7.1 (NikitaVolkov)
17:06:28 <reallymemorable> if im compiling a program and i interrupt it, does that mess anything up?
17:06:33 <reallymemorable> can i just rebuild it later?
17:06:44 <reallymemorable> this has been compiling forever and i need to go
17:07:19 <Solonarv> should be fine to interrupt
17:07:32 <Solonarv> or you can just send your computer to sleep
17:07:36 <Solonarv> instead of shutting it down
17:07:45 <slack1256> at least the already compiled dependencies are save on store
17:08:27 <reallymemorable> ok cool
17:08:32 <reallymemorable> thank you
17:08:42 <reallymemorable> i cant sit in this office much longer...
17:09:50 <jle`> on rare occasions you might run into bugs in your package manager/build system, but i think those are mostly edge cases.  and it's easy enough to reset
17:09:53 <slack1256> reallymemorable: do you have a job that uses haskell?, nice
17:10:24 <reallymemorable> I have been on the business side, but I wanted to learn haskell so I kind of bulldozed my way into coding stuff
17:10:29 <jle`> :D
17:10:36 <reallymemorable> I only do relatively simple projects
17:10:57 <reallymemorable> I have some art projects i want to do in haskell later on as well, but my skills are lagging
17:13:23 <jle`> haskell art seems to always be really great :)
17:14:09 <reallymemorable> are there examples out there
17:14:25 <reallymemorable> basically i want to visualize really utilitarian data in completely non-useful ways
17:14:30 <jle`> ah, i just see that haskell art pops up every once a while in the haskell reddit
17:14:35 <reallymemorable> so  like,  temperature time-series
17:15:01 <reallymemorable> it seems that I need to  learn reflex to make  this happen
17:15:25 <slack1256> I am learning reflex now too
17:15:32 <reallymemorable> how are you going about it
17:16:22 <slack1256> let me find that link
17:17:23 <slack1256> https://qfpl.io/projects/reflex/
17:18:02 <slack1256> I like the presentation on Behaviours, Dynamics, and Events
17:18:59 <reallymemorable> thanks so much
17:19:02 <reallymemorable> this looks great
17:29:43 <MarcelineVQ> check out lunalang as well if you like visual data stuff
17:35:45 <slack1256> On reflex, what does obelisk actually add that justify now using just cabal?
17:36:00 <slack1256> s/now/not/
17:38:17 * hackage persistent-postgresql 2.9.1 - Backend for the persistent library using postgresql.  https://hackage.haskell.org/package/persistent-postgresql-2.9.1 (parsonsmatt)
17:39:03 <jackdk> I don't have an answer but if you don't get one maybe #reflex-frp can help you
17:40:06 <slack1256> Yeah, I don't know why I didn't ask there first. Thanks jackdk
17:42:57 <MarcelineVQ> deployment, including mobile platforms
17:46:06 <fen> must be something to do with IO streaming hardware interactions
17:46:57 <fen> you mean *not* just using cabal?
17:47:41 <slack1256> fen: yeah, s/now/not/
17:48:09 <fen> whats that got to do with frp?
17:48:30 <MarcelineVQ> reflex is an frp library
17:48:35 <fen> like, why would that be better for #reflex-frp
17:48:39 <MarcelineVQ> obelisk is touted for reflex based projects
17:48:46 <fen> hmm
17:49:01 <fen> so the cross platform hardware IO stuff then?
17:49:13 <slack1256> yeah, I already asked there but MarcelineVQ said that obelisk also deals with deployment
17:49:32 <fen> no but why 
17:49:35 <fen> wait
17:49:45 <fen> what has cross platform got to do with frp?
17:49:59 <slack1256> Also seems to provide a cache via nix-build, maybe they avoid some quirky pitfall on nix with it
17:50:29 <slack1256> fen: nothing but it is a nice addon if you want to deploy to the cloud
17:50:50 <slack1256> they are marketing this library for people that want to do single page applications, and those people need deployment
17:52:21 <MarcelineVQ> It has about as much to do with frp as the conversation preceding it shows it to.
17:52:23 <fen> there are a few different issues here so its getting confused. nix as a build tool used by obelisk, obelisk as a build tool vs cabal for cross compiling. reflex as a tool used by obelisk, and if that has any intersection with the specific requirements of various hardware / target platforms
17:53:10 <slack1256> fen: I am not sure cross compiling is provided
17:53:21 <fen> MarcelineVQ: but we are just guessing that frp is helpful for hardware IO?
17:53:23 <slack1256> I don't know how that got involved
17:53:53 <MarcelineVQ> Which we?
17:54:29 <MarcelineVQ> And what is hardware IO as you're using it?
17:54:38 <fen> oh, well, just presuming you want to compile for ARM from Intel or AMD if your targeting mobile platforms from linux 
17:55:03 <slack1256> web apps don't run natively
17:55:17 <slack1256> they ship a browser that load the web app
17:55:31 <fen> MarcelineVQ: web, mouse, keyboard, camera, gyroscope.
17:55:42 <fen> sound
17:55:48 <fen> screen
17:55:52 <fen> thats all?
17:56:39 <fen> slack1256: oh right! that explains the ghcjs stuff
17:56:58 <fen> why not webgl?
17:57:18 <slack1256> nobody has put the effort
17:57:34 <fen> hang on thats confusing, how does SDL end up in a web app!? isnt it like OS things?
17:58:32 <fen> seems strange to think that opengl apps would compile to js... dont they have custom drivers? do those get compiled too?
17:59:14 <slack1256> maybe they get pulled not because they use them, but because they provide instances to ADT that live on those packages
17:59:41 <fen> like, a graphics card shader interfaced via opengl ends up working as a web app via js on android!? is that right?
18:00:00 <MarcelineVQ> pulled in by what?
18:00:15 <slack1256> as dependencies
18:00:21 <MarcelineVQ> from?
18:00:33 <slack1256> what ever fen is installing :-)
18:00:38 <fen> what!?
18:00:58 <fen> i get to choose!? hmm, ok... er... 
18:01:26 <fen> autofocus
18:01:36 <fen> then can do fast edge detection
18:01:58 <fen> and have to access the most difficult hardware io
18:02:18 <MarcelineVQ> slack1256: thus my disconnect, no words being said are connecting to things said before them :o
18:02:58 <fen> thats the wrong way to have a discussion!
18:03:03 <MarcelineVQ> I agree
18:03:45 <fen> none of the thing i say are relevant? 
18:04:58 <fen> i just cant understand how your supposed to compile shaders to web apps and keep up to date with various hardware interface specs 
18:05:19 <hpc> shaders are written in a standard language
18:05:30 <MarcelineVQ> check out shadertoy for how to compile shaders to web apps, in a limited fashion
18:05:41 <hpc> you don't concern yourself with hardware except in terms of how much computational resources are available
18:05:48 <fen> there is https://www.codota.com/code/java/methods/android.hardware.Camera/autoFocus
18:06:04 <fen> but it seems pretty much impossible to find an easy how to on writing manual focus
18:06:15 <fen> and thats on the android side!
18:06:33 <fen> how we on the haskell side are supposed to interact with this is just going to be difficult 
18:07:07 <fen> hence the questions about how obelisk manages to do anything at all from the vantage point of a web app
18:07:16 <fen> seems far removed is all
18:07:59 <MarcelineVQ> lunalang uses too much memory to build :(
18:08:15 <fen> and without any ability to wrangle android java, they are denying the user the ability to ability to interface with things they have not ported? or is that the libraries responsibility? 
18:08:18 <MarcelineVQ> this is the first time that's happened to me in haskell, finally I can join the clubhouse
18:08:59 <fen> like would we have to have some special android camera library on haskell that just presumes that its compiled crosscompiled and run on a phone... 
18:09:37 <hpc> MarcelineVQ: just give yourself 100 gigs of swap
18:09:40 <hpc> EZ
18:09:43 <MarcelineVQ> ;_:
18:10:21 <fen> graphical programming for finance!? give me a break...
18:11:13 <fen> why just use a fuzzy compiler instead
18:11:51 <fen> if peoples learning to think is shaped by there language then that looks like a recipe for a financial crisis 
18:12:48 <MarcelineVQ> Are you alright? You've been more random than usual lately.
18:13:39 <fen> "we have a new system in place allowing our quants to communicate program specifications using traditional trading floor semaphore, as it more in keeping with the intuitions of our fine institution!" 
18:13:57 <slack1256> MarcelineVQ: if lunalang uses too much memory and the program that does it is GC based, you can run it on a cgroup. Most GC based programs collect often when reaching the limit and seem more interactive
18:14:09 <slack1256> I use that trick to evaluate stuff with nix-build that leaks
18:14:18 <fen> MarcelineVQ: i cant write my function :'-(
18:14:19 <hpc> ooh sneaky'
18:14:41 <fen> or build a phone app with tilt capabilities
18:17:43 <fen> "buy! sell! monad!"
18:18:21 <slack1256> moreover, it's really simple if you have systemd: `systemd-run --user -p MemoryHigh=2000G --scope nix-build -argstr "compiler" ghc864`
18:18:38 <slack1256> s/2000G/2000M/
18:25:52 <MarcelineVQ> hmm, didn't seem to limit the child processes, does this look right? systemd-run --user -p MemoryHigh=3G --scope -- stack build --ghc-options="-fno-omit-interface-pragmas"
18:26:57 <MarcelineVQ> with the intent that the ghc stack calls up is limited by the 3G total
18:27:05 <monochrom> Would it be affected by how Linux defaults to overcommitting memory on every request i.e. it simply says "yes"?
18:27:36 <slack1256> check what memory controller do you have active on your distro, for example I am using cgroups v2 (no v1 stuff) and my /sys/fs/cgroup/cgroup.subtree_control says "pid memory"
18:28:45 <slack1256> monochrom: it works correctly with overcommitting, the OOM isn't usually triggered because if the program usually has a GC as they detect low memory conditions (I guess checking malloc)
18:28:59 <slack1256> what I don't know is how ghc reacts as it declares 1Tb of virtual memory at startup
18:31:00 <slack1256> IIRC when I've builded haskell programs they stay at the limit without being killed
18:31:07 <MarcelineVQ> I don't have "cgroup.subtree_control" which based on the man page makes me think I've cgroups v1
18:31:10 <slack1256> s/builded/built/
18:31:56 <monochrom> Yeah GHC tries a GC before asking for more memory.
18:32:34 <monochrom> Sometimes it even releases memory.
18:32:51 <p0a> Hello I want to have a vector with components x,y which are real numbers (like 2.3)
18:33:04 <p0a> The class 'Fractional' is complaining that I didn't provide a type so I'm confused on what to use
18:33:07 <MarcelineVQ> oh, no, I have cgroups 2..
18:33:10 <p0a> I used 'Float' but is that the right thing to do?
18:33:17 <slack1256> MarcelineVQ:  If you have a memory controller on the cgroups v1 systemd-run ought to respect the limits (in my view, I never used it knowingly)
18:33:46 <slack1256> MarcelineVQ: you can have cgroups v1 *and* cgroups v2 at the same time. It's a mess
18:33:57 <slack1256> that's is why I ban cgroups v1 at boot time
18:34:21 <jle`> p0a: so something of type (Double, Double) ?
18:34:32 <jle`> or (Float, Float), too
18:34:51 <jle`> it's common to define a custom data type, data Point = P { px :: Double, py :: Double }
18:35:25 <p0a> jle`: sure that's what I did with Float instead 
18:35:29 <p0a> jle`: so I'll just use double 
18:35:44 <p0a> jle`: not familiar with your notation though.\
18:35:55 <p0a> jle`: I thought `data' defines a type so what is {px,py} doing there?
18:35:56 <jle`> hm, it comes up pretty early in most haskell courses
18:36:01 <slack1256> But Fractional out of the box only provides instances for Float and Double, not for `Point`
18:36:01 <jle`> it's record syntax
18:36:08 <p0a> what is it recording?
18:36:28 <p0a> slack1256, sure, Point shouldn't be Fractional 
18:36:33 <jle`> it's basically the same as data Point = P Double Double
18:36:49 <jle`> except you get some auto-defined accessor functions, px :: Point -> Double, py :: Point -> Double 
18:36:52 <p0a> jle`: I thought px, py where accessors
18:36:53 <codebam> is there a channel where I can ask about pandoc? (I know this isn't really the place, but since pandoc is written in haskell I thought maybe some of you might know)
18:36:58 <jle`> p0a: yes, exactly
18:36:59 <p0a> oh so they're auto-defined. cool!
18:37:12 <jle`> yeah. you can also use them in update and creation syntax, too
18:37:18 <p0a> codebam: not sure about a channel but there are communities out there afaik
18:37:19 <jle`> like myPoint = P { px = 2, py = 3 }
18:37:32 <jle`> or just `P 2 3` if you want to not use record syntax
18:37:36 <p0a> I see, got it
18:37:52 <jle`> or setYToZero p = p { py = 0 }, where you can update a single field
18:38:00 <jle`> it's mostly just sugar :)
18:38:01 <codebam> p0a: hmm, I just was having trouble figuring out why \\ newline inside $$ $$ display math isn't working
18:38:06 <p0a> jle`: but why use Double over 'Fractional;' ?
18:38:15 <jle`> do you mean, why use Double over Float ?
18:38:25 <p0a> codebam: you mean \\ isn't working inside $$ $$?
18:38:32 <jle`> remember, Fractional is not a type, it's a typeclass
18:38:34 <codebam> p0a: exactly
18:38:41 <slack1256> codebam: even on LaTeX, newlines aren't useful inside $$ $$
18:38:44 <p0a> jle`: so why shouldn't I write it for the typeclass instead of a specific type?
18:39:02 <codebam> oh, how would I put a text above my aligned equation then?
18:39:04 <slack1256> you usually use \begin{align} or \begin{gather} to get newlines
18:39:07 <codebam> oh, okay
18:39:12 <p0a> codebam: pandoc --wrap=preserve 
18:39:16 <jle`> p0a: what would it even mean to "write it for the typeclass"
18:39:17 <p0a> codebam: does that work?
18:39:23 <codebam> p0a: will try
18:39:40 <p0a> jle`: Well, Point would be a typeclass that expects `a' to be Fractional?
18:39:48 <codebam> p0a: nope doesn't work
18:39:54 <monochrom> Point is a type, not a typeclass.
18:39:56 <jle`> you want Point to be a typeclass, and not a data type?
18:40:02 <jle`> and what is 'a' here?
18:40:02 <codebam> slack1256: I'll check out gather, thank you
18:40:18 <slack1256> codebam: no prob :-)
18:40:35 <p0a> jle`: nvm I'll go with what I already understand 
18:40:41 <jle`> what do you expect to gain out of making Point a typeclass?
18:40:51 <p0a> jle`: I was just wondering if there's any merit in doing it a different way but judging from your reaction it's unnatural
18:40:56 <slack1256> codebam: $$ \begin{gather} a + b = c \\ f + g = y + x \end{gather} $$
18:41:00 <p0a> not really thinking right now :P
18:41:05 <slack1256> ought to work
18:41:16 <jle`> p0a: one popular thing to do though is to make Point a parameterized data type
18:41:24 <jle`> like data Point a = P { px :: a, py :: a }
18:41:30 <codebam> slack1256: what if I want to have this text above my aligned equation and another one to the right?
18:41:45 <jle`> then you can derive nice instances for it, like Functor, Foldable, Traversable
18:41:54 <p0a> jle`: hm. not familiar with tose 
18:41:55 <p0a> those 
18:42:03 <slack1256> codebam: you then need to replace gather for "align", check out examples on stackoverflow
18:42:07 <p0a> jle`: oooh, got you
18:42:14 <jle`> ah. if you're not familiar with those typeclasses then you probably won't ge tmuch use out of it
18:42:34 <p0a> jle`: at this point I might as well just use tuples though hu
18:42:36 <jle`> but Foldable is a useful typeclass here because you get "sum" for free
18:42:38 <p0a> huh ? 
18:42:54 <jle`> hm, i think using an actual data type would be better than using tuples
18:43:00 <jle`> that way your fields have meaning
18:43:02 <p0a> alright 
18:43:22 <jle`> tuples are just what you use when you are too lazy to make your own data type :)
18:43:38 <jle`> or if you want some tupling with no inherent meaning
18:43:56 <p0a> nice 
18:44:18 <p0a> I think parametrized data type is what I was looking for I just forgot about it 
18:45:13 <jle`> yeah, the parameterized data type is useful :)  if even just for getting access to functor/traversable/foldable instances
18:45:19 <jle`> and it also has a cute Applicative instance as well.
18:45:25 <jle`> but that one can't be auto-derived
18:46:02 <jle`> but if you don't plan on using any of those then you might as well not parameterize it :)
18:47:01 <jle`> hm, there are still some other useful properties of the parmaeterized version
18:47:19 <jle`> it can help you make more descriptive type signatures that help you see what's going on
18:47:48 <jle`> for example, if you write a function `myFunction :: Num a => Point a -> a`, then you know that your fields might be being added togehter, subtracted, multiplied, etc.
18:47:54 <p0a> jle`: I also want to overload * and +, how can I do that?
18:47:57 <jle`> but they won't be square rooted, inverted, or anything silly like that
18:48:15 <jle`> p0a: ah, you can overload * and + by providing Num instance
18:48:29 <p0a> jle`: instance ... ? 
18:48:34 <p0a> jle`: okay, thank you
18:48:45 <jle`> instance Num Point where P x1 y1 + P x2 y2 = P (x1 + x2) (y1 + y2)
18:49:02 <jle`> but be aware that * has to follow the shape Point -> Point -> Point  (assuming you're using the unparameterized version)
18:49:17 <jle`> so you can't use it to define, say, a dot product
18:49:26 <jle`> it would have to be something like a component-wise product
18:49:30 <p0a> jle`: but * should be Double * Point 
18:49:36 <jle`> right, that is not possible
18:49:41 <p0a> alright 
18:49:43 <jle`> not with (*) :: Num a => a -> a -> a
18:49:57 <p0a> well, + will do for now :P 
18:50:01 <jle`> you would have to define your own function under a different name, or shadow (*) (which is probably highly unrecommended)
18:50:14 <p0a> no we're creatures of the light
18:50:27 <p0a> shadow spells are forbidden 
18:50:28 <p0a> :P 
18:50:38 <slack1256> monochrom: above you said GHC tries a GC before asking for more memory
18:51:29 <slack1256> but on linux the RTS allocates 1Tb at startup, so that "asking for memory" isn't done via malloc/mmap. How does it check the system is running low on memory?
18:51:59 <p0a> jle`: how can I tell it what the identity is in my instance of num? 
18:52:31 <p0a> slack1256, sounds like a very linux specific quesiton 
18:53:05 <slack1256> yeah, but I am curious
18:54:31 <p0a> so you're asking, how does GHC know that it's running out of memory?
18:54:54 <p0a> or the system is?
18:56:19 <amir_> exit
18:57:36 <Solonarv> p0a: the additive identity is assumed to be 'fromInteger (0 :: Integer)'
18:58:13 <slack1256> p0a: how does the RTS the GHC provides knows it's running out of memory on linux 
18:58:58 <p0a> Solonarv: which is nto defined either 
18:59:08 <p0a> slack1256, RTS stands for ? 
18:59:19 <Solonarv> you have to define 'fromInteger' as part of your Num instance
18:59:42 <p0a> Solonarv: apparently just providing (+) and (-) works to have -object by itself
18:59:51 <p0a> Solonarv: I'd assume -object is 0 - object...
19:00:15 <Solonarv> you won't get a compiler error if you're missing instance methods
19:00:20 <Solonarv> but things will blow up at runtime
19:00:44 <Solonarv> (you can get a warning; I forget what it's called, but it's included in -Wall )
19:00:49 <p0a> if they'r ecalled, right?
19:00:54 <p0a> Wno-missing-methods is what I added 
19:01:13 <slack1256> p0a: RunTime System, it's the program attached by ghc at compilation time that actually runs the haskell programs
19:01:17 <p0a> anyway, you're telling me the standard doesn't allow it?
19:01:22 <slack1256> it includes the Garbage collector for example
19:01:30 <Solonarv> yes, if they're used
19:01:40 <p0a> slack1256, it probably decides its own limits if they're not provided by the OS 
19:01:59 <p0a> slack1256, allocates 1TB?
19:02:03 <Solonarv> if you write -object to negate 'object', that does indeed turn into '0 - object'
19:02:27 <p0a> Solonarv: which is why I don't get how this works without me telling it what the identity is (or fromInteger)
19:02:31 <p0a> but neverhteless
19:02:36 <Solonarv> which tries to use 'fromInteger (0 :: Integer)', which will blow up at runtime
19:02:38 <Solonarv> try it!
19:02:47 <p0a> it doesn't blow up in my interpreter 
19:02:58 <Solonarv> % data Point = Point Double Double deriving Show
19:02:58 <yahb> Solonarv: 
19:03:07 <p0a> you just want my project to fail 
19:03:23 <p0a> :P
19:03:30 <Solonarv> % instance Num Point where P x1 y1 + P x2 y2 = P (x1+x2) (y1+y2); P 
19:03:30 <yahb> Solonarv: ; <interactive>:5:67: error: parse error (possibly incorrect indentation or mismatched brackets)
19:03:54 <Solonarv> % instance Num Point where P x1 y1 + P x2 y2 = P (x1+x2) (y1+y2); P x1 y1 - P x2 y2 = P (x1-x2) (y1-y2);
19:03:55 <yahb> Solonarv: ; <interactive>:6:26: error: Not in scope: data constructor `P'; <interactive>:6:36: error: Not in scope: data constructor `P'; <interactive>:6:65: error: Not in scope: data constructor `P'; <interactive>:6:75: error: Not in scope: data constructor `P'
19:04:16 <slack1256> p0a: allocates 1TB of "virtual memory", that by the overcommitting strategy linux uses isn't actually allocated at malloc() time, but at use time
19:04:18 <Solonarv> % instance Num Point where Point x1 y1 + Point x2 y2 = Point (x1+x2) (y1+y2); Point x1 y1 - Point x2 y2 = Point (x1-x2) (y1-y2);
19:04:18 <yahb> Solonarv: ; <interactive>:7:10: warning: [-Wmissing-methods]; * No explicit implementation for; `*', `abs', `signum', and `fromInteger'; * In the instance declaration for `Num Point'
19:04:26 <Solonarv> ^ see, here we get the warning
19:04:35 <p0a> yeah but a warning isn't blowing up 
19:04:36 <Solonarv> % Point 1 1
19:04:36 <yahb> Solonarv: Point 1.0 1.0
19:04:39 <p0a> it's much milder 
19:04:43 <Solonarv> % -(Point 1 1)
19:04:44 <yahb> Solonarv: *** Exception: <interactive>:7:10-18: No instance nor default method for class operation fromInteger
19:04:52 <Solonarv> oh look, an exception!
19:04:59 <p0a> well I don't get one so I'm not sure what' sup 
19:05:02 <p0a> maybe a compiler extension 
19:05:02 <Solonarv> that's what I mean by "blow up at runtime"
19:05:14 <p0a> unless by runtime you mean something other than what I'm doing n the interpreter 
19:05:17 <Solonarv> what's your actual code?
19:05:25 <p0a> slack1256, if it allocates 1TB probably it's not actually expecting to have it 
19:05:29 <p0a> Solonarv: just a second 
19:06:01 <p0a> Solonarv: https://pastebin.com/Vw6f8CFM
19:06:36 <Solonarv> p0a: that's just a bunch of declarations, nothing is getting evaluated there
19:06:55 <Solonarv> exceptions like the above happen when you try to *evaluate* a "bad" value
19:07:09 <slack1256> p0a: most programs don't actually use that memory, so everything works correctly. But what happens when you're running low on memory on linux?
19:07:13 <Solonarv> observe:
19:07:13 <Solonarv> % let containsBoom = -(Point 1 1)
19:07:13 <yahb> Solonarv: 
19:07:35 <slack1256> p0a: the usual response is that the OOM kills them, but that isn't what I am seeing
19:07:49 <Solonarv> % containsBoom `seq` () -- evaluate containsBoom
19:07:49 <yahb> Solonarv: *** Exception: <interactive>:7:10-18: No instance nor default method for class operation fromInteger
19:08:45 <p0a> slack1256, what I'm saying is that it probably doesn't expect to have 1TB of memory
19:09:00 <p0a> Solonarv: well, - (P 1 2) works fine here 
19:09:11 <p0a> Solonarv: unless it's not actually evaluated due to laziness. 
19:09:22 <p0a> Solonarv: probably what's wrong. I didn't derive Show :P Thanks for letting me know 
19:09:22 <Solonarv> could be, what did you enter into ghci exactly?
19:09:30 <p0a> Solonarv: exactly what I said 
19:09:37 <p0a> Solonarv: I'll just define fromInteger n = P n n
19:10:00 <Solonarv> actually that doesn't typecheck - n :: Integer, but the fields are Double
19:10:13 <slack1256> p0a: obviously
19:10:22 <Solonarv> you want fromInteger n = P n' where n' = fromInteger n
19:10:36 <p0a> slack1256, so it allocating 1TB is irrelevant to your question of how does it know about running out of memory 
19:10:42 <p0a> Solonarv: thanks
19:10:49 <Solonarv> and yeah, show is an easy way to force something to be evaluated in ghci
19:11:17 <p0a> I'm intelligent enough to get it right at some point
19:11:23 <p0a> not to get it right at the first time :P 
19:11:38 <p0a> so if I Get type mismatches, eventually... it'll work
19:11:54 <Solonarv> if you enter '-(P 1 2)' into ghci, that turns into 'print (-P 1 2)'; this fails to typecheck (due to the missing Show instance), so no evaluation happens
19:12:21 <p0a> ah 
19:12:45 <p0a> ok, so Haskell has its own bag of pitfalls for newbies :P
19:13:07 <Solonarv> yeah
19:13:40 <slack1256> p0a: not true. On other unix the way to check if it running out of memory is to check the return values of malloc(). On linux, there is a single big malloc at the beginning of the program (1Tb) and the error code is not that useful also
19:13:42 <Solonarv> for now keep this in mind: if you're defining a typeclass instance, fill in all the required methods, unless you like things blowing up at runtime
19:14:07 <p0a> slack1256, man mmap if you want details
19:14:57 <slack1256> p0a: it's not a linux question, is a question of what does the ghc's rts does on linux
19:14:58 <p0a> Solonarv: got it, thanks 
19:15:24 <p0a> slack1256, why would it be specific to ghc? most programs do what ghc does, no?
19:15:36 <p0a> most software with GC
19:17:35 <geekosaur> p0a, actually no. page table-based 2-stage allocation is quite a lot of work, and there are only a few memory managers that do so
19:17:55 <geekosaur> all of them fairly tightly tied to the systems that implement them, as with ghc or a few lisp implementations
19:18:14 <monochrom> slack1256: GHC keeps its own count of how much of its heap and stack are used.
19:18:27 <slack1256> p0a: not really, the rts does allocate 1Tb of memory at the beginning, so it cannot react well to low memory conditions as imposed by say cgroup
19:18:38 <geekosaur> various malloc implementations do use mmap instead of sbrk to allocate memory, but they still manage the result as traditonal chunks
19:18:57 <slack1256> p0a: the nix interpret (a much simpler interpreter), does restrict itself when knowing there is no memory left.
19:19:26 <monochrom> And yeah even malloc-free does its own free lists and/or heap data structure on top of sbrk or mmap.
19:19:35 <p0a> that's for efficiency
19:19:49 <slack1256> monochrom: yeah, but how does it know there is low free memory remaining on the system?
19:19:56 <p0a> because a lot of people malloc 1 byte 
19:20:12 <monochrom> I don't think it does?
19:20:41 <p0a> slack is saying that the return value is not useful so it has to know somehow 
19:20:45 <p0a> or otherwise it'd crash 
19:20:51 <p0a> or that's what they say I think
19:21:05 <slack1256> yeah but the answer was given by monochrom before and I didn't notice
19:21:08 <monochrom> GHC triggers GC when its own lawn is full, not when the other pasture is full.
19:21:30 <monochrom> And, if -threaded, when idle.
19:21:35 <geekosaur> because it can't do that, because the only thing in the system that knows for certain is the kernel
19:21:56 <p0a> and that's not certain either 
19:22:00 <slack1256> before allocating an extra block on the heap, it does a GC right?
19:22:22 <geekosaur> not guaranteed
19:22:34 <monochrom> I would rephrase that as: before asking the OS to give it more space so it can enlarge its heap.
19:22:55 <slack1256> It never asks the OS to give it more space on the linux case though
19:23:24 <monochrom> The reliable way to space-bound GHC is +RTS -M500M (this example for 500MB)
19:23:24 <geekosaur> it allocates some number of pools (you can specify this, and whether they're shared between threads or not in some ghc versions, via rts options). if a pool is getting full, it will gc it. if it's still too full, it'll allocate a new pool
19:23:53 <geekosaur> there's also a total heap size limit that it will try to not exceed (i.e. won't allocate a new heap area)
19:24:12 <monochrom> Ah OK yeah it has a 1TB virtual space it can just start using the next page.
19:24:12 <slack1256> right, good RTS options to know!
19:24:27 <monochrom> But it tries a GC before starting a new page.
19:24:39 <slack1256> ^ this is so important
19:24:48 <slack1256> for low memory conditions
19:25:07 <monochrom> And +RTS -M500M will stop it from starting a new page, instead it terminates.
19:25:31 <slack1256> the only sensible thing to do on a low memory condition is to start the GC. If you do it before starting to use a new page, you cover that case
19:26:02 <geekosaur> there is a key difference here in how this works: ghc allocates 1TB *address space*, not 1TB *mmeory*, up front.
19:26:29 <geekosaur> this tells the OS to map a new page for it the first time it writes to an address that desn't have actual memory assigned to it
19:26:56 <geekosaur> (this can fail, and ghc will catch a segfault instead of it "just working")
19:28:00 <slack1256> so using memory the OS cannot provide results in a segfault?
19:28:23 <geekosaur> that, or memory that was never requested to be part of the active address space
19:28:56 <geekosaur> C-style memory management usually only marks parts of the address space as active when needed; ghc marks a big chunk as active immediatelt
19:29:38 <geekosaur> (some malloc implementations may also do so, but then they have to be able to deal with segfaults as above, as opposed to those that come from pointers to addresses that aren't in the process's memory map)
19:32:58 <p0a> slack1256, are you worried about mission critical stuff?
19:33:47 <p0a> because haskell probably shouldn't be used in environments with little memory and no room for failure
19:34:13 <slack1256> p0a: not really, I like compiling stuff without hitting swap
19:34:45 <p0a> ok so you're worried about the compilation stage 
19:35:02 <slack1256> on nix I can constraint the interpreter (via cgroups) to say 1GB and the GC will reach the 1GB and collect to make space and keep running
19:35:12 <p0a> isn't hitting swap faster?
19:35:22 <slack1256> nop
19:35:24 <p0a> why do you not want to do that? or you just want to limit how many resources ghc grabs?
19:36:11 <p0a> how do you know? if your statement is generally true, you can just request a patch from the devs
19:36:32 <slack1256> that swap is not faster than main memory?
19:36:41 <slack1256> that is pretty well established
19:37:25 <geekosaur> but confused by tmpfs and by unified kernel page management
19:37:39 <p0a> the whole process may not be faster though (GC kicking in too often etc)
19:38:16 <p0a> If I have an IO [a] and a function that returns Maybe [a] why can't I combine things 
19:38:21 <slack1256> yeah I don't care if the process is faster or slower, I care it terminates correctly and doesn't make my system crawl
19:38:21 <geekosaur> also, de facto swap is slower only if there's thrashing going on such that the system is having to move pages in and out of memory a lot
19:38:28 <p0a> I can have print $ fromList [...] but I can't have f <- fromList[...] print ?
19:38:39 <slack1256> geekosaur: exactly my case ;_;
19:38:55 <slack1256> On go I got this tiny netbook from 2011, sooo
19:39:01 <p0a> slack1256, so you want to limit resources then 
19:39:13 <p0a> slack1256, i.e. you want to compile things and also use your netbook 
19:39:29 <geekosaur> if it just has to swap stuff out of the way once, that can be done lazily (in particular, I/O can take place while computation is occurring because the I/O doesn't necessarily need the CPU to be involved)
19:39:46 <geekosaur> heh. been there, mine is urrently in storage (and rather older than 2011)
19:40:11 <slack1256> hehe
19:41:00 <geekosaur> but also most recently used as a network file server because networks are even slower :)
19:41:25 <Ariakenom> does ghc have max memory flags? +RTS -M 1g or something?
19:41:33 <slack1256> Yep
19:41:49 <slack1256> well ghc doesn't have that flag, the RTS does
19:49:40 <monochrom> Oh, instant halving your memory need: Use 32-bit GHC.
19:50:31 <monochrom> Plus, 32-bit GHC doesn't even do the "declare 1TB virtual space thing". Honest-to-God memory requests instead.
19:50:53 <geekosaur> p0a, <- is desugred into (>>=)
19:50:57 <geekosaur> :t (>>=)
19:50:58 <lambdabot> Monad m => m a -> (a -> m b) -> m b
19:51:03 <geekosaur> same m everywhere
19:51:47 <monochrom> Yeah, for this reason I don't understand what does "combine IO and Maybe" mean
19:51:52 <geekosaur> and underneath this is fmap and join, and join can't combine arbitrary monads
19:52:08 <geekosaur> :t join
19:52:09 <lambdabot> Monad m => m (m a) -> m a
19:53:15 <geekosaur> this can't know how to collapse arbitrary monads together, and for some it's impossible (e.g. Maybe (IO a) can't be turned into Maybe a, it would have to somehow make the IO "go away")
19:54:07 <geekosaur> and in the other direction (making the Maybe "go away"), the only thing it could do is throw an exception on Nothing
19:55:29 <p0a> so if you have Maybe stuff, then forget about IO ? 
19:56:04 <geekosaur> I did not say that
19:56:17 <p0a> Okay, good 
19:56:20 <geekosaur> you have to approach it differently than thinking every box is like every other and it doesn't matter what shape the box has
19:56:30 <p0a> :(
19:57:01 <geekosaur> (because IO is not a "box", and Maybe is only a "box" if it's Just somethingOrOther)
19:57:33 <p0a> Basically I have this function that turns a list of doubles into points; but obviously if the list is of odd length you can't do that 
19:57:34 <p0a> that's all 
19:57:55 <geekosaur> there is MaybeT IO *if* you actually need the two interleaved. usually if Im working in IO, I ignore the Monad instance for Maybe and just treat it as a pure value and pattern match
19:58:16 <p0a> I see what you're saying 
19:58:16 <jusss``> why there're unit join return bind lift those at least five functions is related with monad?
19:58:36 <p0a> geekosaur: got it, thank you
19:58:48 <geekosaur> lift isn't part of Monad per se, it's MonadTrans which is a mechanism for combining Monad-s in particular ways
19:58:53 <p0a> geekosaur: so something like myPrint that pattern matches the MAybe stuff ? 
19:58:54 <slack1256> jusss``: lift if for MonadTrans though
19:59:15 <slack1256> unit I don't know it, but I guess it the same as return
19:59:28 <jusss``> and bind?
19:59:35 <geekosaur> the mathematical definition of Monad involves pure, join and fmap. Haskell's normal implementation is pure (return) and bind, because that's usually more convenient for how they're used in Haskell
19:59:36 <vaibhavsagar> jusss``: I'm not sure what unit is in this context
19:59:39 <jusss``> is monad a pattern?
19:59:39 <slack1256> bind is the real mean of monad :-)
19:59:41 <geekosaur> but they're pretty much the same thing
19:59:52 <geekosaur> bind is join . fmap, more or less
20:00:03 <slack1256> jusss``: the instances can use pattern matching
20:00:03 <geekosaur> and unit is another name for pure / return
20:00:11 <slack1256> in the case of Maybe this is clear as day
20:01:01 <geekosaur> jusss``, you could say it's a "command pattern" in Design Patterns terminology.
20:01:37 <jusss``> geekosaur: I still don't know what those Functor Applicative and Monad are
20:01:55 <geekosaur> @where typeclassopedia
20:01:55 <lambdabot> http://www.haskell.org/haskellwiki/Typeclassopedia
20:02:24 <jusss``> https://stackoverflow.com/questions/44965/what-is-a-monad
20:02:36 <jusss``> there're too much version about it
20:03:47 <p0a> How can I have Data.List.Unique in my haskell setup?
20:03:49 <p0a> It fails to import 
20:04:19 <slack1256> That module isn't on base
20:04:56 <slack1256> you have to include the unique package on the .cabal file, then you will be able to import it
20:05:03 <p0a> okay I know what I'll do I'll just write my own 
20:05:42 <slack1256> yeah, it is not that difficult
20:07:53 <p0a> error: ... 
20:07:57 <p0a> very informative ghc, thank you :)
20:12:46 <p0a> okay, this is enough haskell for today 
20:12:48 <p0a> thank you all 
20:21:34 <monochrom> I thought the Command pattern was just higher-order function (with effectful function).
20:56:17 * hackage multipool 0.2.0.0 - Generalized system for reading and writing to distributed systems that have primary/replica topologies.  https://hackage.haskell.org/package/multipool-0.2.0.0 (IanDuncan)
20:57:18 * hackage multipool-postgresql-simple 0.2.0.0, multipool-persistent-postgresql 0.2.0.0, multipool-persistent 0.2.0.0 (IanDuncan): https://qbin.io/great-patrol-qb6r
21:15:20 <mjrosenb> oh wonderful, flycheck mode isn't working in emacs anymore.
21:31:31 <codebam> hey, just tinkering with haskell a bit I guess. could someone help me understand how I'd define a function that does the same as python's range(x)?
21:32:06 <codebam> range(5) == [0, 1, 2, 3, 4]
21:33:10 <mjrosenb> there's some built in syntax for that
21:33:16 <mjrosenb> > [0..5]
21:33:18 <lambdabot>  [0,1,2,3,4,5]
21:33:33 <codebam> mjrosenb: oh, cool. but like if I wanted to do it using a function and with :
21:33:44 <codebam> I'm just trying to understand the language
21:35:36 <mjrosenb> like most functions, you'd want a recursive function.
21:35:53 <mjrosenb> it'll probably be easier to first write a function that generates it backwards
21:36:14 <codebam> I just started typing my response to that in ghci, maybe it's time I got some rest
21:36:15 <mjrosenb> so range 5 -> [5,4,3,2,1,0]
21:36:52 <codebam> mjrosenb: oh yeah I don't mind which way it goes, just trying to understand how I would do it
21:36:52 <mjrosenb> > let range 0 = [0] in range 0
21:36:54 <lambdabot>  [0]
21:38:03 <mjrosenb> then for the recursive case: let range 0 = [0]; range n = ... in range 4
21:39:03 <mjrosenb> and as you noted, : is the constructor for adding an element onto a list
21:39:29 <mjrosenb> range 0 = [0]; range n = n : ...
21:39:32 <jle`> i don't think it's accurate to say "like most functions" => a recursive functions
21:39:55 <jle`> most functions you write in haskell in the long run, you actually try to avoid explicit recursion
21:40:01 <codebam> so that just piecewises 0 to [0] and then n to... n : range?
21:40:03 <jle`> but definitely when learning haskell recursion can be useful to learn
21:42:20 <codebam> oh I got it
21:42:32 <codebam> > let range 0 = [0]; range n = n : range (n-1)
21:42:34 <lambdabot>  <no location info>: error:
21:42:35 <lambdabot>      not an expression: ‘let range 0 = [0]; range n = n : range (n-1)’
21:42:38 <codebam> that makes sense
21:47:16 <codebam> or I guess the python equivalent (backwards) would be let range 0 = []; range n = n - 1 : range (n - 1)
21:47:20 <codebam> because it's non-inclusive
21:49:07 <codebam> how would I do that forwards instead of backwards?
21:49:38 <mjrosenb> you'll need an extra argument
21:50:13 <codebam> oh, okay
21:58:43 <kaol> > let range = enumFromTo 0 in range 5
21:58:45 <lambdabot>  [0,1,2,3,4,5]
21:59:13 <codebam> I mean I could just do [0..5], I wanted to do it using recursion for learning purposes
21:59:42 <codebam> but I'm having fun
21:59:46 <codebam> with lists and map
22:00:04 <codebam> I like the simplistic syntax for map
22:00:05 <codebam> map (/ 2) [0, 10..1000]
22:00:08 <codebam> > map (/ 2) [0, 10..1000]
22:00:10 <lambdabot>  [0.0,5.0,10.0,15.0,20.0,25.0,30.0,35.0,40.0,45.0,50.0,55.0,60.0,65.0,70.0,75...
22:02:59 <kaol> > let range = unfoldr (\x -> guard (x > 0) >> let x' = x-1 in Just (x', x')) in range 5
22:03:00 <lambdabot>  [4,3,2,1,0]
22:11:47 * hackage shh 0.3.1.2 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.3.1.2 (lukec)
22:23:47 * hackage summoner 1.3.0.1 - Tool for scaffolding fully configured batteries-included production-level Haskell projects.  https://hackage.haskell.org/package/summoner-1.3.0.1 (shersh)
22:32:17 * hackage asif 6.0.0 - Library for creating and querying segmented feeds  https://hackage.haskell.org/package/asif-6.0.0 (arbornetworks)
22:41:17 * hackage shh 0.3.1.3 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.3.1.3 (lukec)
22:44:17 * hackage fast-logger 2.4.14 - A fast logging system  https://hackage.haskell.org/package/fast-logger-2.4.14 (KazuYamamoto)
22:45:10 <c50a326> why isn't there an ADT equivalent of JSON?
22:45:40 <c50a326> I mean why isn't there some data structure specification that is very popular that you can stick in files like blah.adt... so like JSON in that way...?
22:49:03 <c50a326> ah, found this https://stackoverflow.com/a/18316847/3461506
22:52:05 <jle`> c50a326: dhall tries to be something like that
22:52:09 <jle`> but also adds functions too
22:52:23 <jle`> but you can work with a subset of dhall that is just ADT
