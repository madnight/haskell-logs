00:22:42 <Axman6> siraben: don't =)
00:25:46 <siraben> Axman6: Hm?
00:43:44 <dminuoso> siraben: What exactly do you want to learn about arrows, and what do you hope to accomplish?
00:45:38 <Bish> Cale: like, the SHA thingie?
00:45:46 <Bish> or what does top level constants mean
00:48:35 <Bish> too bad, i like writing code this declarative way
01:03:24 <siraben> dminuoso:  I just saw (>>>) being used in Haskell code
01:03:29 <siraben> But it just seems like (.) but flipped
01:04:29 <geekosaur> some ways it is, especially as an Arrow
01:05:22 <geekosaur> (there's also Control.Category. in fact, Arrows turn out to be a somewhat unfortunate (less general than one could hope) conflation of Category, Profunctor, and Applicative.)
01:06:19 <geekosaur> so Arrow as such is of limited interest unles syou're into history or involved with one of their few practical use cases (some forms of FRP like them)
01:10:15 <jle`> siraben: that's not really using arrows, that's just using the (->) instance
01:10:30 <jle`> so you don't really need to "learn about arrows", it's just using a particular instance
01:10:39 <jle`> arrows as an abstraction ... not too useful
01:10:46 <jle`> using a specific instance can be useful.
01:18:22 <akr> out of curiosity, why does Data.Function define a flipped ($) (i.e. (&)), but not flipped (.)
01:18:32 <akr> seems like a little bit of an oversight
01:18:50 <phadej>  well, there is >>>
01:18:51 <phadej> :)
01:19:24 <akr> well, yeah, the discussion above about (>>>) gave rise to my question :)
01:19:52 <jle`> akr: sometimes the typeclass instance is the 'canonical' way to exposes the functionality of a type
01:20:15 <jle`> for example, if you want to 'map' a Maybe, with (a -> b) -> Maybe a -> Maybe b
01:20:21 <jle`> Data.Maybe doesn't provide one explicitly named
01:20:28 <jle`> but instead offers this functionality through its Functor instance
01:20:53 <akr> so (&) is in Data.Function only because there is (currently) no typeclass that could implement this functionality
01:20:54 <jle`> another common example is + for Int
01:21:05 <jle`> or well, that might be a bad example, since there might be an Int-specific +
01:21:21 <jle`> akr: yeah, that can be one way of looking at it
01:21:40 <jle`> the reason why this is done is usually to keep the namespace cleaner
01:22:01 <jle`> and also another major reason is, if you have a typeclass with laws, the context of the laws makes the functions more useful to think about
01:22:14 <phadej> or no other type such that b -> a b c -> c would make sense
01:22:33 <jle`> i think in this case it's probably more reason #1 than #2, since nobody cares about arrow laws hehe
01:23:53 <akr> okay, I see. Thanks for the explnato
01:23:58 <akr> explanations* :)
01:24:31 <jle`> note that in some cases, the specific version is ubiquitous enough, or is useful without the context of the laws enough, that it is given its own (redundant) name
01:24:57 <jle`> like map, (.) (which is a stand-in for both (<<<) and fmap), concatMap, etc.
01:25:04 <phadej> ... or maybe have better type
01:25:15 <jle`> oh, another reason why (.) exists apart from (<<<) is that it has a fixity more suited for its normal usage
01:25:52 <jle`> er, apart from `fmap`, too
01:26:01 <phadej> better type: e.g. `Set.empty :: Set a` vs `mempty :: Ord a => Set a`
01:27:03 <akr> I see, that's interesting
01:28:52 <akr> oh, I have one more question: can someone recommend me resources on learning about being more space-complexity aware in haskell? Especially on writing programs that run in constant memory
01:29:05 <akr> ideally with exercises
01:29:13 <akr> is there a book?
01:31:18 <siraben> akr:  I'm not sure of a specific book on that, but reading about strictness and various packages like Data.Bytestring might help
01:32:29 <siraben> There's various blog posts here and there
01:32:30 <siraben> https://github.com/bitemyapp/learnhaskell/blob/master/write_haskell_as_fast_as_c.md
01:40:13 <siraben> Anyone able to find a shorter program to check if a string contains non-overlapping substrings "AB" and "BA"?  
01:40:16 <akr> siraben: thanks, that is useful
01:40:18 <siraben> Here's mine: http://ix.io/1FBG
01:40:47 <siraben> It's a solution to https://codeforces.com/problemset/problem/550/A
01:41:15 <siraben> I can't do the usual foldr on the string because I might need to consume 1 or 2 characters each time
01:42:20 <siraben> It's "almost" a fold of sorts
01:43:41 <akr> I think you should be able to solve it in one pass, if you want to
01:43:50 <akr> though this is probably more readable (and shorter)
01:44:57 <akr> you'd have to add one line I think
01:47:56 <phadej> *Kleene Algebra.Lattice> let re x y = top <> x <> top <> y <> top in match (re "ab" "ba" \/ re "ba" "ab" :: RE Char) "abba"
01:47:59 <phadej> True
01:48:01 <phadej> *Kleene Algebra.Lattice> let re x y = top <> x <> top <> y <> top in match (re "ab" "ba" \/ re "ba" "ab" :: RE Char) "aba"
01:48:04 <phadej> False
01:48:05 <phadej> nothing regular expressions can't solve!
01:50:46 <siraben> phadej:  what are the imports for that?
01:51:06 <phadej> siraben: :m +Kleene, and +M Algebra.Lattice :)
01:51:17 <phadej> kleene and lattices packages
01:52:54 <phadej> fwiw, ^([^]*ab[^]*ba[^]*|[^]*ba[^]*ab[^]*)$ seems to be the JS-compatible regexp generated
01:53:07 <siraben> I see.
01:54:26 <siraben> Unfortunately I don't think those packages can be used in my solution :( 
01:55:52 <akr> phadej: that kleene package is really cute
01:56:47 <phadej> akr: thanks
01:57:04 <akr> oh, did you write it?
01:57:18 <phadej> akr: I did :)
01:57:18 <akr> I was looking at the info on hackage and it's a bit confusing
01:57:28 <akr> oh, neat :)
01:58:13 <siraben> By the way, does GHC do some evaluation at compile time?
01:58:25 <siraben> e.g. if I have (reverse "this is a string") in my program, will it be evaluated at compile time?
01:58:29 <siraben> As a form of program optimization
01:58:50 <siraben> Or will a call to reverse actually happen at runtime?
01:59:41 <geekosaur> ghc does not in general implement constant-folding optimizations at present
02:00:04 <geekosaur> (gcc and clang do, and demonstrate why nobody's in a hurry to do so in ghc: they're remarkably fragile)
02:01:07 <siraben> What about expressions like 3+5?
02:01:08 <siraben> Surely some sort of constant folding happens
02:01:09 <phadej> reverse ['t','h','i','s'] might be evaluated at compile time
02:01:42 <phadej> but it's heuristics driven, so you cannot know for sure
02:02:19 <siraben> I see.
02:02:30 <siraben> Maybe it doesn't know that "reverse" is a total function
02:02:49 <siraben> total and terminating
02:03:01 <tdammers> might also mess up strictness semantics
02:03:28 <siraben> At least inlining happens
02:06:24 <phadej> GHC is bad at optimising recursive functions
02:07:32 <phadej> that's one thing
02:07:46 <siraben> Any TCO?
02:07:48 <phadej> the other thing, is that string literal internals are tricky
02:08:11 <tdammers> siraben: TCO is kind of a meaningless concept in a language that doesn't have actual "calls"
02:08:11 <phadej> siraben: optimising as in rewriting them to simpler stuff
02:08:37 <tdammers> siraben: depending how you look at it, Haskell automatically has TCO on everything, or Haskell doesn't need TCO
02:09:45 <siraben> Hm.
02:23:55 <tdammers> do you understand why that is?
02:24:56 <siraben> Is it because of the compiler stages?
02:25:06 <siraben> IIRC haskell desugars to an 8-op "bytecode"
02:25:13 <siraben> Or a language with 8 constructors
02:27:01 <tdammers> no, not really
02:27:08 <tdammers> it's due to Haskell's evaluation model
02:27:27 <siraben> Ah the laziness
02:27:32 <siraben> everything is delayed
02:28:33 <tdammers> so suppose you're applying a function; well, that's just a matter of pattern-matching on the argument, selecting the right function body, and thunking that up, basically
02:28:54 <tdammers> it's not until the return value is demanded that you need to actually evaluate the body
02:29:13 <tdammers> but by that time, your function "call" has already "returned"
02:29:45 <tdammers> that is, you can replace the function application with a thunk that closes over the pattern-matched variables from the argument and contains the body
02:30:03 <tdammers> so the "call graph", if you want to call it that, naturally flattens
02:42:46 <Ariakenom> tdammers: weren't you a bit eager with the argument there?
02:44:52 <tdammers> Ariakenom: yes, that's entirely possible
02:45:09 <tdammers> the argument obviously doesn't get scrutinized any further than is necessary to find a match
02:45:47 <tdammers> and equally obviously, the implied first step is just thunking up the entire function application until its result is scrutinized in a pattern match on the consumer end
02:46:51 <akr> I think the problem is in your last line
02:46:58 <akr> it's a bit of a jump
02:47:40 <tdammers> well, what I'm trying to say here is that there are no "function calls" that stack up in a "call stack" in the strict sense
02:50:55 <akr> so there's just the thunk being evaluated, which can be completely replaced with a different thunk?
03:04:33 <siraben> phadej:  Looks like the language is regular, just wrote a DFA for it
03:06:49 <siraben> Can't really do anything clever, apart from a regex I guess.
03:40:54 <isn> hi
03:41:29 <isn> could somebody explain me how this function works and maybe break it down in steps?: map :: (a -> b) -> [a] -> [b]
03:44:30 <tdammers> isn: have you tried implementing it yourself?
03:44:43 <tdammers> isn: do you understand what the type signature means?
03:46:02 <isn> yesterday a user here helped me with some stuff and he explained the this function. The implementation is working and I understand the implementation. Just not the signature. This is the implementation:
03:46:05 <isn> map :: (a -> b) -> [a] -> [b]
03:46:05 <isn>     map f [] = []
03:46:05 <isn>     map f (x:xs) = f x : map f xs
03:46:50 <isn> I understand: test :: Integer -> Integer, since it expects and int and returns an int.
03:46:57 <hc> a -> b  means one function that takes one a and returns one b
03:47:16 <hc> [a] -> [b] means take one list of as and return list of bs
03:47:40 <isn> ah, I see
03:48:02 <isn> I got confused by the two ->'s
03:48:05 <isn> Thank you :)
03:48:06 <hc> so map takes a function that transforms one a to one b, and a list of [a]s and returns a list of [b]s
03:48:06 <tdammers> (a -> b) -> [a] -> b -- "a function that takes a function that takes an a and returns a b, and returns a function that takes a list of a's and returns a list of b's"
03:48:36 <tdammers> generally, a -> b -> c means a -> (b -> c), but we informally say that it "takes two arguments", because that's how it's often used
03:49:19 <dminuoso> gabiruh: The signature of your map looks a bit off.. but perhaps its just me.
03:50:36 <isn> a -> (b -> c) means function takes argument a and eventually returns c?
03:51:02 <hc> not exactly, it means takes a and returns a function that takes one b and returns one c
03:51:02 <akr> it means, function which takes argument `a` and returns a function `b -> c`
03:51:12 <Ariakenom> f :: a -> (b -> c); f x :: (b -> c); f x y :: c
03:51:13 <akr> (or at least that's one way to look at it)
03:51:43 <tdammers> Haskell doesn't really support multi-argument functions; all Haskell functions are unary
03:51:44 <hc> strictly speaking, in haskell functions only ever take one argument
03:51:56 <hc> \a b -> a + b     is equivalent to \a -> \b -> a + b
03:52:09 <tdammers> so if we want to pass more than one argument, we have two choices: tuple them up, or take the first argument and return a function that takes the second argument
03:52:14 <akr> isn: if you already know about pairs, it might be helpful to know that two functions `f : a -> (b -> c)` and `g : (a, b) -> c` are "essentially the same"
03:52:22 <akr> two function ypes*
03:52:22 <tdammers> the former would be (a, b) -> c; the latter is a -> (b -> c)
03:52:27 <dminuoso> isn: It may be helpful to understand that application to multiple arguments can be thought of as applying as one at a time. so `f x y z` is actually `((f x) y) z)`, each "layer" returns a subsequent function which can (or not) be applied to another argument.
03:52:46 <tdammers> but due to the fixity of the -> type operator, a -> (b -> c) can be written as a -> b -> c
03:52:53 <akr> ok folks I think we overwhelmed them :D
03:53:05 <tdammers> that's #haskell by the book
03:53:21 <Rembane> Brain-DOS
03:53:33 <dminuoso> akr: We are trying to do learning by force. With enough pressure *some* information will bypass the mental barriers put by years of Python programming.
03:53:38 <Athas> Clearly the best way to explain what's happening is by a Reynolds-style defunctionalisation.
03:53:45 <akr> dminuoso: :D
03:54:04 <tdammers> https://www.softantenna.com/wp/wp-content/uploads/2014/12/INewImage118.png
03:54:13 <isn> akr: almost, but I follow you guys. It's very helpful
03:54:16 <isn> :p
03:54:25 <akr> cool :)
03:54:33 <isn> I just have to get my thinking/thought pattern right
03:54:42 <Ariakenom> I think a concurrent monad tutorial is the way forward here
03:55:03 <dminuoso> Ariakenom: Perhaps an elementary course in homotopy type theory might be in order first.
03:55:07 <tdammers> don't forget to mention boolean blindness
03:55:21 <isn> boolean blindness?
03:55:28 <Ariakenom> dminuoso: excellent, but not first. concurrently :p
03:56:03 <akr> I would like to see a course in HoTT being elementary :P
03:56:20 <akr> anyway why don't we move to Agda...
03:56:29 <tdammers> isn: don't worry about that. at least not for now.
03:56:46 <isn> tdammers: alright :)
03:57:01 <isn> anyway, my question is answered for now. thank you very much for your help you guys!
03:57:09 <akr> you're welcome :)
03:57:13 <dminuoso> isn: This channel has just went into a self-irony mode. Don't pay too much attention if there's terms being flung around right now that don't make sense to you. Do not look them up, it won't help since we are just having fun. :-)
03:57:16 <tdammers> isn: if you're interested, there's this notion that using booleans is often a code smell, and that you should be using domain-specific custom types instead, most of the time - that is, instead of True | False, you should be using something like ConnectionSucceeded | ConnectionFailed, or some such
03:57:28 <tdammers> isn: but again, don't worry about it for now
03:58:01 <isn> kind of like enums right?
03:58:01 <dminuoso> tdammers: And in reality we should be using continuations do avoid needlessly discriminating on such sum types to discover what we already know!
03:58:04 <isn> haha alright :)
03:58:13 <dminuoso> To *rediscover in fact.
03:59:08 <tdammers> isn: yes, exactly enums actually - except that this kind of enum can then be extended, in subsequent iterations of the coding process, with additional information
03:59:26 <tdammers> isn: e.g., ConnectionSucceeded | ConnectionFailed Reason -- to indicate *why* the connection failed
03:59:51 <akr> tdammers: I'm not sure if that's what boolean blindness is... isn't it more about forgetting how we got to a result (i.e., the proof), and instead focusing only on whether the proof proved (True) or disproved (False) a proposition?
04:00:05 <isn> alright, ty :)
04:01:13 <dminuoso> akr: As Conor put it, to know what a Bool means you have to know its provenance.
04:01:32 * akr looks up provenance
04:01:55 <akr> interesting word
04:02:13 <akr> almost like a type theorist traveled back in time to invent it :D
04:04:09 <dminuoso> akr: What can you do with a Bool without knowing its provenance? 
04:04:38 <akr> anything a boolean algebra allows you :P
04:05:59 <akr> but you're right, I confused the term with a different concept
04:12:12 <tdammers> akr: it ends up being the same thing though, doesn't it
04:12:34 <tdammers> you want the "boolean" to be linked to the proof at the type level
04:13:06 <akr> sure :)
04:15:46 <tdammers> as much as people have called me a hopeless theorist in the dynamic world (PHP, Python, Clojure), and accused me of lacking pragmatism, my approach to Haskell is probably one of the most practically oriented ones out there
04:23:36 <dminuoso> tdammers: Very often when I hear the word "pragmaticsm" being used, it usually refers to being very ignorant and just hoping that your technique achieves the goal.
04:36:04 <d34df00d> But why do you _always_ care where the proof came from, instead of what it proved?
04:36:59 <d34df00d> I find myself not caring about that at all quite frequently (though I'm writing much toy code, closer to proving 1 + n = n + 1).
05:03:50 <ziman> proofs are fine, bools need provenance
05:04:50 <ziman> because "true" does not have a meaning if you don't know the question
05:04:54 <ziman> a bit like 42 ;)
05:06:35 <isn> I'm trying to create a function to add a number to a list. It's not working like I hoped, I have this:
05:06:38 <isn> addToList :: a [b] -> [b]
05:06:38 <isn> addToList a [b] = a:[b]
05:06:47 * hackage telega 0.1.4 - Telegram Bot API binding  https://hackage.haskell.org/package/telega-0.1.4 (iokasimovmt)
05:07:00 <isn> I want to achieve 1:[2,3,4,5] with addToList 1 [2,3,4,5]
05:07:20 <isn> Can someone help me out with this?
05:07:51 <opqdonut> isn: your type signature is wrong
05:08:03 <opqdonut> isn: it should be something like `a -> [a] -> [a]`
05:08:19 <opqdonut> you take two arguments, the first of type a, the second of type [a] and return something of type [a]
05:09:00 <isn> oh
05:09:24 <opqdonut> or you can use `Int -> [Int] -> [Int]` if you want to restrict the function to just numbers (Ints)
05:10:13 <isn> oh nice, thanks
05:10:25 <isn> I get Non-exhaustive patterns in function addToList
05:11:11 <opqdonut> ok the next problem is that in `addToList a [b] = a:[b]`, [b] is a list of length one
05:11:32 <opqdonut> you're destructuring (pattern matching) the second argument to addToList
05:11:49 <opqdonut> you should probably just use `b` instead of `[b]`
05:12:11 <mathlover2> addtoList :: Int -> [Int] -> [Int]
05:12:11 <opqdonut> the idiomatic name for the variable would be `bs`, variables of list type are usually in plural
05:12:22 <mathlover2> addtoList = (a :)
05:13:14 <isn> nice, its working :)
05:13:15 <isn> thanks!
05:13:36 <opqdonut> mathlover2: you probably mean `addtoList a = (a:)` or `addtoList = (:)` :)
05:13:51 <isn> :mathlover2 is that complete because I get an error
05:13:54 <mathlover2> opqdonut, yes.
05:14:16 <mathlover2> That's what I meant.
05:14:22 <mathlover2> Sorry, isn.
05:14:35 <isn> okay nice, works :)
05:14:38 <isn> np
05:27:58 <delYsid`> Hmm, how would I read a binary file of n 16 byte records, where n is determined by the filesize / 16?
05:28:59 <delYsid`> The binary package seems a bit restricted when it comes to reading a specific amount of records.
05:30:28 <ziman> using sequence and replicateM?
05:31:12 <ziman> erm, replicateM alone
05:33:17 * hackage HDBC-odbc 2.6.0.0 - ODBC driver for HDBC  https://hackage.haskell.org/package/HDBC-odbc-2.6.0.0 (anton_dessiatov)
05:38:47 * hackage tzdata 0.1.20190325.0 - Time zone database (as files and as a module)  https://hackage.haskell.org/package/tzdata-0.1.20190325.0 (MihalyBarasz)
05:47:20 <dmwit> delYsid`: many getWord16le -- ?
05:50:04 <dmwit> If you're paranoid, you might consider `many getWord16le <* (isEmpty >>= guard)`.
05:58:26 <delYsid`> So I gotta read manually, not using the Binary instance at all?
06:10:23 <delYsid`> hmm, binary-strict isnt ghc 8.6 compatible... :(
06:16:00 <delYsid`> dmwit: Any alternatives to binary-strict?
06:26:35 <ngirard> Hi all ! I'm requesting your assistance to solve a bug in the pp preprocessor ( https://github.com/CDSoft/pp/ ) related to parsing Json.
06:27:50 <ngirard> I'm affected by this bug and concerned PP's author may not reply soon, since he hasn't replied in months to a similar bug report concerning reading Yaml
06:28:22 <ngirard> And unfortunately I'm not currently proficient enough to solve it myself, although I've tried before joining you
06:28:39 <ngirard> So, my bug report is here: https://github.com/CDSoft/pp/issues/70
06:29:26 <ngirard> The problem is related to this line: https://github.com/CDSoft/pp/issues/70
06:29:34 <ngirard> readJSON s = eitherDecode (BL8.pack s)
06:29:57 <ngirard> where BL8 was defined as:
06:29:58 <ngirard> import qualified Data.ByteString.Lazy.Char8 as BL8
06:30:48 <ngirard> Apparently it's a common issue, which has already been discussed on Stack Overflow here: https://stackoverflow.com/questions/27669418/
06:31:12 <c_wraith> yeah, that's not a quick fix.
06:31:20 <ngirard> where two people advised using encodeUtf8 :: Text -> ByteString from Data.Text.Encoding instead of pack from Data.ByteString.Lazy.Char8
06:32:07 <ngirard> Which advice I've try to follow, but failed -- and there I am as this point
06:32:14 <ngirard> tried *
06:32:26 <c_wraith> oh, I see, you're reading it as a string?
06:33:50 <c_wraith> ngirard, do you have a paste of the code that is failing to convert + a description of how its failing? (compile error, runtime error?)
06:34:06 <ngirard> c_wraith: I think so yes -- a String is a list of Char8, right ?
06:34:14 <ngirard> c_wraith: sure, in a minute
06:35:05 <c_wraith> no, a String is a list of Char. char8 isn't a thing that really exists, except as the name of some really hack modules that die the first time they meet non-ascii data
06:37:57 <ngirard> c_wraith: oh, alright
06:38:08 <ngirard> c_wraith: here's the relevant part of the code: https://pastecode.xyz/view/a6aa5ea7
06:38:10 <dmwit> delYsid`: What Binary instance are you talking about?
06:38:32 <ngirard> c_wraith: problem occurs at line 58
06:38:53 <ngirard> c_wraith: with this error message:
06:38:54 <ngirard> pp: Mustache (test.json): Error in $: Failed reading: Cannot decode input: Data.Text.Internal.Encoding.decodeUtf8: Invalid UTF-8 stream
06:39:11 <tdammers> Char8 is something you should only use if 1) you understand the implications, and 2) you are forced to interface with something that doesn't
06:40:01 <ngirard> tdammers: thanks for your explanation
06:40:25 <c_wraith> ngirard, so what happens when you replace the pack with encodeUTF8?
06:42:40 <ngirard> c_wraith: well, I tried but probably got it wrong... I started to learned Haskell long ago but forgot about everything
06:42:48 <ngirard> So what I did is:
06:42:49 <ngirard> import qualified Data.ByteString.Lazy.Char8 as BL8
06:42:59 <ngirard> and at line 58:
06:43:24 <ngirard> No, my bad:
06:43:25 <ngirard> import Data.Text.Lazy.Encoding as TLE
06:43:31 <ngirard> and at line 58: 
06:43:43 <ngirard> readJSON s = eitherDecode (TLE.encodeUtf8 s)
06:45:07 <ngirard> And I got this output from the compiler:
06:45:07 <ngirard> https://pastecode.xyz/view/f3317302
06:45:12 <delYsid`> dmwit: I originally wrote an instance for Binary for my datatype, and later discovered that BitGet (the thing you pointed me to) doesnt work like that.  However, binary-strict doesn't look like it is very activel maintained, no ghc 8.6 yet.
06:47:15 <ngirard> (the line numbers match the actual file rather than the snippet I pasted)
06:50:26 <ngirard> I realize I didn't paste the url to the code properly, here it is:      https://github.com/CDSoft/pp/blob/master/src/Preprocessor.hs#L758
06:57:17 * hackage ping 0.1.0.2 - icmp echo requests  https://hackage.haskell.org/package/ping-0.1.0.2 (andrewthad)
07:05:59 <remexre> I'm trying to define a Traversal for an (extensible) expression type: https://p.acm.umn.edu/Wn9Q5zE5wAA=
07:06:15 <remexre> This works fine for leaves, but I want to be able to traverse over non-leaf nodes
07:06:44 <remexre> I'm thinking this is impossible (i.e. I need a Monad bound instead of an Applicative one), since order matterns (pre-order vs post-order traversal)
07:06:56 <remexre> is my intuition correct, and is there a workaround if so?
07:10:25 <dmwit> delYsid`: I'm pretty lost by now. I didn't point you to BitGet.
07:10:46 <dmwit> And if you're willing to write a Binary instance anyway, then I've given you the combinators you need to implement it by hand, I think.
07:10:48 <Solonarv> Applicative is ordered - 'f <*> x' does not have to equal 'flip ($) <$> x <*> f'
07:11:08 <dmwit> As for binary-strict, probably whatever is holding it back should be easy enough to fix up yourself if you really really need it...?
07:11:26 <Solonarv> so if you want a different ordering of effects you can do that pretty easily
07:12:00 <codedmart_> Does `stack install` use bash `install` under the hood?
07:12:12 <Solonarv> codedmart_: no
07:12:35 <remexre> Solonarv: wait, so is this possible to do? I found myself needing to put (f =<<) on the front of each case of traverseExpr, which of course isn't possible
07:13:09 <Solonarv> 'stack install' is a shortcut for 'stack build --copy-bins', which is roughly: 'stack build' and then 'cp' the binaries to ~/.local/bin
07:13:41 <codedmart_> Solonarv: hmm... when I tried to cp myself I got a `text file busy` error.
07:13:49 <codedmart_> But stack install works fine.
07:14:00 <Solonarv> codedmart_: uh, what did you 'cp' ?
07:15:02 <codedmart_> The binary produced from stack. We are building on one machine and copying to other machines of the same distro.
07:15:25 <Solonarv> no, what is the actual command you ran?
07:16:21 <codedmart_> `cp ./deploy/* ./.bin`
07:16:34 <Solonarv> remexre: I'm a bit confused - what is traverseExpr supposed to "target", exactly?
07:16:52 <Solonarv> codedmart_: and where do the files in ./deploy come from? stack doesn't put anything there normally
07:16:57 <remexre> Solonarv: every expression in the tree
07:17:21 <codedmart_> I am scp them on the machine. Built with stack from another machine.
07:18:34 <remexre> so if I ran it on (the parsed form of) (f x (g y)), it'd target [f x (g y), f x, f, x, g y, g, y]
07:18:59 <Solonarv> remexre: ah, *all* subexpressions? I don't think that can be made a lawful traversal - a traversal's targets should not overlap
07:19:08 <remexre> oh, hm
07:19:37 <Solonarv> your thing sounds sort of like everywhere / everywhere' / everywhereM from SYB
07:19:44 <Solonarv> @hackage syb
07:19:44 <lambdabot> http://hackage.haskell.org/package/syb
07:20:29 <remexre> yeah, looks like it
07:20:35 <remexre> except I think I want top-down instead of bottom up
07:20:53 <Solonarv> hm, dunno if syb has a combinator for that
07:21:18 <remexre> yeah; I think I can get away with it being pure though, so everywhere' should work
07:21:43 <Solonarv> in any case, since it's just for the one data type and there doesn't seem to be any mutual recursion it shouldn't be too hard to hand-write either
07:22:36 <remexre> yeah, I might do that anyway for ease of reading
07:23:25 <codedmart_> Solonarv: any other thoughts/advice?
07:29:32 <akr> does enabling profiling disable inlining automatically?
07:35:01 <akr> I don't really understand profiling builds
07:35:32 <akr> do they just print any exception you encounter w/ the call stack that led to it to stdout, regardless if whether you've caught the exception or not?
07:36:19 <Solonarv> codedmart_: well, I'm not entirely sure what you're doing or what the problem is, so no
07:37:03 <tdammers> akr: that's not what profiling is about. profiling allows you to gather stats on individual code paths: how often they are hit, and from where they are reached
07:37:47 * hackage hedis 0.12.1 - Client library for the Redis datastore: supports full command set,pipelining.  https://hackage.haskell.org/package/hedis-0.12.1 (k_bx)
07:38:00 <akr> tdammers: well, sure, but compiling with profiling enabled is also supposed to give you usable "call stacks", see https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Stack.html
07:38:12 <tdammers> oh, that. yeahh.
07:38:58 <tdammers> I don't use that a lot myself, but IIRC the idea is that when you let an exception bubble all the way to the top, you get a call stack with your crash
07:40:03 <akr> it's behaving pretty oddly for me https://gist.github.com/osense/90a9eb7f8be52668abc7490b68d9f382
07:40:15 <akr> it doesn't print the full stack trace, for starters
07:40:16 <codedmart_> Solonarv: I am running `stack build` on one vm of ubuntu xenial. Then downloading that and scp'ing it onto another vm of ubuntu xenial where that executable is running already and using the cp command.
07:40:26 <akr> and it prints a stack trace for exception I've caught, tdammers
07:40:35 <codedmart_> Then I get that error `text file busy`.
07:40:47 <codedmart_> Thanks for your help though.
07:40:50 <Solonarv> codedmart_: okay, that's a bit clearer.
07:41:27 <Solonarv> you're getting the 'text file' busy error after you've already successfully copied over the binary that stack built
07:41:30 <Solonarv> is that right?
07:42:18 <codedmart_> When I tried to copy it to the same place that the current executable is in. So I scp it onto the machine in a diff dir. Then run cp. That is when I get the error.
07:42:31 <codedmart_> During the cp step.
07:43:06 <codedmart_> I tried bash `install` and it seemed to do what I intended, but I am not a bash pro so I don't know if that is the right thing to do.
07:46:10 <saml> codedmart_, target directory might not exist
07:46:19 <saml> and install creates the directory if it does not exist
07:47:05 <codedmart_> saml: Target dir already exists. I am trying to copy a new exec to the same place of an existing running one.
07:50:05 <akr> also, I seem to have hit a bug in Stack that causes `stack build --profile` to fail if you're using TH and haven't previously run `stack build`
07:50:14 <akr> but nevermind that
07:50:20 <geekosaur> codedmart_, sounds expected to me. if you write over an existing file that is mapped into a process's memory space, you get that error. if you remove or rename that file first, no error but you may find you're using more swap space
07:51:00 <codedmart_> geekosaur: But why does stack install work on a running file?
07:51:13 <saml> oh you're doing hot swapping?  is application already running and you're copying over?
07:51:40 <codedmart_> I agree it sounds expected. I was trying to determine if I should use bash `install` in this case.
07:51:45 <geekosaur> because it's not literally overwriting the existing  file, it removes the existing one first
07:52:15 <geekosaur> which generally causes the running / mapped image to be loaded into memory / swap so it continues to exist until final unmap
07:52:32 <codedmart_> Oh ok
07:52:46 <codedmart_> Does bash `install` do something different then that?
07:53:04 <geekosaur> either removes or renames the original
07:53:08 <geekosaur> depending on options
07:53:20 <codedmart_> Oh ok great. Thanks for the info.
07:54:44 <saml> stack isn't packeger, unlike cabal, right?
08:17:31 <hackeryarn[m]> Stack is largely a convenience tool. It smoothens out the process of working with cabal.
08:17:35 <tabaqui> oh, gcc knows how optimize tail recursion
08:17:58 <tabaqui> moreover, it can optimize naive factorial "return n * f(n - 1)", while ghc cannot
08:18:13 <zincy> If you get interview feedback saying you spent too long looking things up vs implementation then what should I be memorising to appease them?
08:18:20 <zincy> Prelude, List an Map?
08:18:23 <zincy> *and
08:19:04 <tabaqui> *how to
08:25:27 <akr> zincy: kinda seems like a bullshit reason, but maybe just learn how to use hoogle in your IDE or something like that
08:25:43 <kadoban> zincy: I don't think getting familiar with a language, enough to not need to look much up, is a matter of explicit memorization. Mostly just practice if anything. Sounds like a fairly goofy complaint though.
08:26:19 <zincy> The interview question was "Write a class that ..."
08:26:21 <tdammers> zincy: I'd memorise to avoid that employer in the future
08:26:31 <zincy> I had picked Haskell already as my language of choice 
08:26:39 <zincy> tdammers: haha
08:26:49 <tdammers> I'm serious though
08:27:12 <zincy> Surely it is the correctness and suitability of the solution vs how fast you built it?
08:27:12 <tdammers> "pick a language of your choice" and "write a class that..." doesn't really match, does it
08:27:31 <zincy> Clueless.
08:27:50 <tdammers> and also - you're in an interview situation, surely you cannot be expected to expose anything resembling realistic on-the-job behavior
08:27:59 <zincy> I don't hire a plumber to fix my pipes and grade them on speed.
08:28:18 <tdammers> you actually do, but not on that scale
08:28:51 <tdammers> that is, you don't care whether it takes them 5 seconds or 30 to find a hammer in their toolbox, but you do want them to finish the job in a reasonable amount of time
08:28:51 <zincy> On your call, _ felt you had some good thoughts and seemed deliberate, but spent a long time looking up vs implementation. As you seem to be comfortable with technical design, we would be happy for you to have a second technical phone call. So, you can see why I ask if JS if your stronger language, because if you were to go forward and there is a similar pattern i.e. < implementation the team will not progress this forward.
08:28:53 <zincy> "
08:29:10 <tdammers> like, you want the kitchen sink to stop leaking *today*, not by September
08:29:20 <zincy> Exactly
08:29:42 <zincy> It is a weird thing for a recruiter to ask.
08:29:57 <tdammers> recruiters tend to ask lots of weird things
08:30:03 <zincy> Maybe they are trying to scare me into a lang that has classes.
08:30:08 <zincy> So they can follow.
08:30:23 <MarcelineVQ> sounds like they'd like you to write JS
08:30:33 <zincy> Yeah that was my gut feeling.
08:31:49 <amx> 'i.e. lower-than implementation'?
08:31:56 <zincy> Thanks for the advice. I was kinda frustrated.
08:32:31 <tdammers> maybe the fact that the "thinking / typing" ratio tends to be different in Haskell than in most other languages
08:32:43 <MarcelineVQ> amx:pattern being: time it takes doing any particular thing < time it takes to implement
08:32:54 <tdammers> it pays off IME, but to someone who has never written any Haskell, it'll come across as strange and somehow not productive
08:33:15 <MarcelineVQ> But you can't implement something you can't know/learn about, these are not that seperatable uses of time
08:33:19 <tdammers> I'm kind of allergic to the word "implementing", used in this context
08:33:28 <zincy> Haskell takes longer to implement than other languages. Because the compiler is forcing to consider things you otherwise wouldn't.
08:33:41 <zincy> Get this... during the coding interview , the guy said don't think about edge cases.
08:34:04 <zincy> I kept asking what if this edge case occurred? Then he would give that response.
08:34:10 <tdammers> it suggests that somehow "figuring out how to solve the problem" and "implementing" are two separate things
08:34:10 <Saito> Hi. How can I setup  proxy for stack?
08:34:20 <tdammers> and that the "thinking" part isn't productive, but the "implementing" part is
08:34:31 <zincy> :D
08:34:52 <amx> MarcelineVQ: thank you for deciphering that particular stylistic crime for me
08:35:12 <tdammers> zincy: seriously, it sounds like it's a deep cultural mismatch. they ask you to ignore the "edge cases", so that hints at a "dynamic" / "embrace failure" development culture
08:35:25 <zincy> Yep exactly.
08:35:29 <MarcelineVQ> I'm not sure I did ehe, it does read somewhat backwards to me
08:35:30 <tdammers> which is at odds with a "static" / "embrace certainty" culture
08:37:02 <siraben> If I have a (\x -> (length x, length x)) will length x be evaluated twice?
08:37:08 <siraben> Or if I have (length x) multiple times in my function
08:37:25 <siraben> Should I use a let expression to compute it once?
08:37:44 <dmwit> Use let.
08:37:47 * hackage fedora-img-dl 0.1 - Fedora image download tool  https://hackage.haskell.org/package/fedora-img-dl-0.1 (JensPetersen)
08:38:27 <dmwit> CSE is mostly not done in GHC, because it makes a time-space tradeoff that's very hard to get right 100% of the time via automation.
08:39:00 <siraben> CSE = ?
08:39:01 <siraben> Call _ elimination?
08:39:07 <dmwit> common subexpression elimination
08:39:14 <siraben> Ah right
08:39:20 <dmwit> It is the transformation that would turn `(length x, length x)` into `let y = length x in (y, y)`.
08:39:26 <siraben> Huh I thought it would be easy to automate, considering functions are pure in Haskell.
08:39:26 <dmwit> `length x` being the common subexpression
08:39:39 <dmwit> Oh, it's easy to discover opportunities for it and do it.
08:39:52 <siraben> IIRC Standard ML does this
08:40:07 <dmwit> But the thing is that when you eliminate a common subexpression, you trade using more space to save computation time.
08:40:12 <dmwit> Sometimes that's the right trade, and sometimes it ain't.
08:40:28 <benzrf> dmwit: but laziness means that youre using space anyway, dont it
08:40:57 <dmwit> Generally no? The computed result can be garbage collected as you go if you don't share that result with anything.
08:41:11 <benzrf> oh wait
08:41:13 <benzrf> hmm
08:41:37 <dmwit> It's introducing sharing via CSE that prevents it from becoming garbage.
08:41:47 <benzrf> ok im not sure im following, can u give a concrete example where this ends up being a problem
08:41:47 <siraben> Space leaks can be subtle in Haskell
08:42:00 <siraben> Ah right
08:42:38 <dmwit> benzrf: Sure, `sum [1..] / length [1..]` uses almost no space, but `let x = [1..] in sum x / length x` must keep all of `x` in memory while it's computing the sum.
08:43:40 <benzrf> dmwit: er, do you mean [1..n]?
08:43:43 <benzrf> :)
08:43:48 <dmwit> (Please assume the sane `sum = foldl' (+) 0` rather than what we actually have in Haskell for historical reasons.)
08:43:58 <dmwit> benzrf: I don't. But the discussion is the same for that, too.
08:44:03 <benzrf> oh wait i see
08:44:06 * benzrf thinks
08:45:16 <benzrf> oooooooookay i see
08:45:33 <dmwit> (I'm not trying to pull any punches with polymorphic numbers here. Please add as many type annotations as you like, and my point will be the same.)
08:45:38 <benzrf> no yeah i get it
08:46:13 <benzrf> so the issue arises when the consumers of the common subexpressions do not individually need a lot of the structure at once, then
08:46:34 <dmwit> That sounds about right.
08:46:48 <dmwit> If they do, there's nothing you can do anyway.
08:46:51 <benzrf> would it be safe to say that this problem could theoretically be solved by interleaving the consumers, even if that's not necessarily practical?
08:46:58 <dmwit> Oh, definitely.
08:47:02 <benzrf> ok cool
08:47:32 <benzrf> hmm ok but then it seems that CSE should be totally safe for fixed-size types, right?
08:47:41 <dmwit> See the "beautiful folding" blog post (I'll find it for you if you're into it), which eventually lead to our current modern Renaissance of using foldMap and Monoid's tuple instances to do all folds in one go.
08:47:53 <benzrf> thats ok
08:48:51 <dmwit> Well, "totally safe" is tricky.
08:49:12 <dmwit> If you want to temporarily let go of the space and re-allocate it later, because it's very big and you want to do some intermediate calculation that also needs a lot of space...
08:49:32 <benzrf> er, well, i was mostly visualizing things like enums and ints :)
08:49:48 <dmwit> Like, "allocate this array 2/3 of memory long; fold it; allocate this other array 2/3 of memory long and fold it; then rebuild the original array and fold it a different way".
08:50:16 <dmwit> (Yes, I know I just finished saying that folds can be coalesced. We can make the example more realistic, but simpler is easier to talk about.)
08:50:41 <benzrf> perhaps i mean something more like "atomic" than just "fixed-size"
08:50:53 <dmwit> Well, and now you're seeing the problem.
08:50:54 <benzrf> something where you can't go any deeper than WHNF
08:51:01 <dmwit> You have to decide how small is small enough.
08:51:16 <dmwit> That's a hard decision to make on a program-agnostic basis.
08:51:23 <dmwit> So GHC leaves it to the programmer to make that decision.
08:51:37 <benzrf> well, that's fine, but it seems like things like Int or enum-y ADTs should be an easy win
08:51:54 <benzrf> like, that seems like a lower bound on the cutoff
08:52:01 <benzrf> and those are common types!
08:52:09 <dmwit> Sure. And maybe `data Foo = Foo {-# UNPACK #-} !Int {-# UNPACK #-} !Int` while we're at it?
08:52:45 <benzrf> if your point is that it becomes complicated to deduce, that's irrelevant to my claim that this is a sane lower bound
08:52:54 <dmwit> What if the function we're doing CSE in is recursive, so we don't know how many such subexpressions will be shared over the course of the whole recursion...?
08:54:09 <benzrf> okay, but that still doesnt change the fact that we have an easy, and potentially quite performance-enhancing, lower bound!
08:54:16 <dmwit> Yes, it does.
08:54:23 <benzrf> ?
08:54:26 <dmwit> Because you've just said "okay, CSE all Ints and nothing else".
08:54:45 <dmwit> And I've said "okay, but if you CSE all Ints, you may use arbitrarily much space on shared subexpressions, which was the goal we were trying to avoid".
08:55:36 <benzrf> wait, let me think properly about what you said abt recursion
08:55:54 <dmwit> (Because we may do one Int's worth of CSE on each recursive step, and we can't sanely compute ahead of time how many recursive steps there will be in general.)
08:56:23 <zincy> tdammers: To add weight to the cultural mismatch slant. Their backend language is Golang.
08:57:13 <dmwit> gotta run
08:57:18 <benzrf> agh
08:57:23 <benzrf> can u give a quick example first?
08:57:28 <hpyCdr> currently stuck: If a function requires another function of type (a -> IO b), how can I pass a (a -> b) function?
08:57:34 <benzrf> im having trouble picturing how this cld be a problem
08:57:55 <benzrf> hpyCdr: requiringFunction (return . thingYouWannaPass)
08:58:17 <hpyCdr> I was as far as (pure $ ...) :D
08:58:19 <hpyCdr> thanks
08:58:28 <benzrf> you can use pure instead of return :)
08:59:32 <hpyCdr> ah I also passed the parameter, effectively passing just a b beforehand
08:59:37 <hpyCdr> well, now it's working
09:02:27 <benzrf> aha -> countTo :: Int -> [Int] -> [Int]; countTo 0 acc = acc; countTo n acc = countTo (n - 1) ((n - 1):acc); sumTo :: Int -> Int; sumTo n = sum (countTo n)
09:02:57 <benzrf> actually wait no that would be fine wouldnt it
09:03:34 <benzrf> er, i mean, in terms of CSE not doing harm
09:18:59 <siraben> How do I use functions like integerLog2# from GHC.Integer.Logarithms?
09:19:00 <siraben> I get a parse error
09:19:15 <siraben> The # seems to be causing trouble
09:19:19 <benzrf> siraben: you need to use -XMagicHash
09:19:39 <Cale> Add {-# LANGUAGE MagicHash #-} to the top of your file
09:19:40 <benzrf> that's an extension which does nothing except make # legal in non-operator identifiers
09:19:57 <benzrf> siraben: are you sure this is what you need, though?
09:20:26 <Cale> It's basically a bit of syntactic security for low-level primitives.
09:21:35 <siraben> benzrf:  I wanted to compute log base 2 of a integer
09:23:21 <benzrf> this seems like overkill .-.
09:24:18 <benzrf> siraben: it would probably be better to use operations from http://hackage.haskell.org/package/base/docs/Data-Bits.html
09:25:15 <Ariakenom> siraben: just use the function without the #
09:25:52 <benzrf> Ariakenom: i looked up the package and it doesnt look like that exists
09:26:28 <Ariakenom> benzrf: https://hackage.haskell.org/package/integer-logarithms-1.0.2.2/docs/Math-NumberTheory-Logarithms.html#v:integerLog2
09:26:41 <benzrf> oh
09:26:51 <benzrf> thats a different package from the one that has the version with the hash, fwiw :V
09:27:11 <Ariakenom> aha
09:36:11 <Ariakenom> benzrf: interestingly I don't think Bits help too much
09:36:42 <benzrf> http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Bits.html#v:countLeadingZeros
09:36:45 <benzrf> :)
09:37:02 <Ariakenom> benzrf: FiniteBits b
09:37:07 <Ariakenom> Integer not so finite
09:37:19 <benzrf> .......fuck
09:37:21 <benzrf> haha
09:38:09 <Ariakenom> I've run into it before. It's strange because the functionality is very close to log2. except log2 doesn't depend on maxsize
09:38:19 <Ariakenom> log2 just seems better
09:41:22 <Ariakenom> as in, even for finite sizes, the result for 100::Word8 and 100::Int doesn't change with log2 but does with leadingZeroes
09:41:26 <Ariakenom> which seems more useful
09:41:48 <tdammers> zincy_: ah yes. that sounds bad.
10:15:35 <HenryCH> why is Maybe an instance of Foldable?
10:15:58 <adamCS> HenryCH: Because life is good.
10:16:10 <adamCS> HenryCH:  It's useful and sensible. Why not?
10:16:14 <jhrcek> Because you can define lawful instances for it which make sense :)
10:16:47 <adamCS> HenryCH: It filters, basically.
10:16:58 <HenryCH> it can't define fold right, just foldr and foldl
10:17:33 <c_wraith> HenryCH, do you know how many times people asked for whenJust in the libraries back in the olden days?
10:17:47 <HenryCH> looking at the implementation the folds are just map with a default value, i struggle to think of it as folding anything
10:18:07 <HenryCH> wait let me look up whenJust :D
10:18:24 <c_wraith> HenryCH, something with a type like (Monad m) => (a -> m b) -> m a -> m ()
10:18:30 <c_wraith> it doesn't exist.
10:18:38 <c_wraith> err. replace m with Maybe
10:18:47 <c_wraith> but it turns out it existed all along.
10:18:54 <Cale> HenryCH: wait, what's wrong with fold?
10:18:57 <c_wraith> it's traverse_ from Foldable
10:19:03 <HenryCH> isn't that forM_?
10:19:09 <Solonarv> same thing
10:19:13 <ggole> It's just a one-element list, fold is perfectly sensible.
10:19:13 <Cale> HenryCH: A Maybe is just like a list of length at most 1
10:19:34 <Solonarv> up to somewhat irrelevant quibbles like swapping argument order and weakening the Monad constraint to Applicative
10:19:51 <c_wraith> HenryCH, so it turns out people wanted what the Foldable instance gives them. they just didn't realize they already had it.
10:19:59 <c_wraith> because Foldable is good
10:20:09 <adamCS> c_wraith: yeah
10:20:37 <dmwit> benzrf: Hm. Haven't thought super carefully about how to make it painful. But try this for an illustration: double 0 = 0; double n = 1 + double (n-1) + 1
10:20:51 <dmwit> benzrf: It would cost a bit of extra memory to CSE the 1 in the second clause.
10:21:09 <dmwit> (...I think.)
10:21:36 <dmwit> (Not super sure. It may cost the same to make the thunk that closes over 1 in the first place.)
10:21:59 <HenryCH> adamCS: what do you mean "it filters"?
10:22:22 <c_wraith> dmwit, that case also depends on the optimizer not reassociating if 1 is an Int...
10:22:30 <c_wraith> (and commuting)
10:22:38 <dmwit> Sure. But let's discuss one optimization at a time.
10:22:56 <adamCS> HenryCH: I ran into it by accident and then it was joyful.  Writing a map-reduce sort of thing.  Mapping over a list with a (Foldable g => x -> g y), then using the foldable to make that a list of lists, then concat.  Now you have a list of y.  And then you group and reduce and whatever.  
10:22:58 <dmwit> We can make it complicated enough to ensure that other optimizations don't kick in, I feel confident.
10:23:52 <c_wraith> dmwit, the standard example is like [1..10000] ++ x ++ [1..10000]
10:23:54 <adamCS> HenryCH:  That (x -> g y) can be lots of things, just a transformation (g ~ Identity), a "melt" making one item into many and then g might be [].  Or a filter and then g ~ Maybe. 
10:24:15 <dmwit> c_wraith: The claim I am replying to is this: "We can safely CSE all Ints and only Ints."
10:24:16 <adamCS> But it makes that all work with one function.  Since Identity is also foldable.
10:25:06 <dmwit> c_wraith: I proposed that a recursive function which CSE'd an Int at each step of the recursion would still lead to unbounded memory usage, the thing we're trying to avoid by not doing automatic CSE.
10:25:31 <dmwit> c_wraith: ...and then benzrf challenged me to show an example, and now you have most of the important context I think. =P
10:25:32 <adamCS> HenryCH:  We could, of course, also filter with g ~ [] and just return the empty list when we want to skip something. But it's nice to unify it all.
10:26:12 <c_wraith> dmwit, ah, sorry. shouldnt have intruded. carry on!
10:26:29 <HenryCH> adamCS: i see
10:26:41 <dmwit> I think all contributions are welcome on this discussion. I'm by no means the last word in why optimizations are or aren't available in GHC. =)
10:26:53 <adamCS> HenryCH: (That point about list is another way of saying what Cale did.  Maybe is just a list with length 0 or 1)
10:28:25 <HenryCH> you mentioned Identity, i've not seen this anywhere, what's the purpose of it? looking at the source lots of stuff is defined as just coerce, what's coerce?
10:29:03 <HenryCH> i get the concept, but as a beginner i've not seen it in code yet, when is it useful?
10:29:24 <dmwit> coerce changes a thing's type without changing its implementation. It first asks GHC to prove that the two types have compatible runtime representations (e.g. are different only by newtype wrappers).
10:30:10 <dmwit> The canonical example of why it's useful is this: suppose you have built an `[Identity Int]`. Actually you want to use it as an `[Int]` because you have a  function that accepts `[Int]`s.
10:30:34 <dmwit> Since under the hood, `Identity Int` and `Int` are really the same thing, it would be nice if there were a zero-runtime-cost conversion.
10:30:59 <HenryCH> how/why would I have built an [Identity Int]?
10:31:01 <dmwit> The obvious thing is to use `map runIdentity :: [Identity Int] -> [Int]`, but this is forced to make a copy of the list's spine at runtime.
10:31:04 <dmwit> That's unfortunate.
10:31:14 <dmwit> Enter `coerce :: [Identity Int] -> [Int]`.
10:31:48 <dmwit> HenryCH: You might have built an `[Identity Int]` because you had a handy monadic combinator that returned an `[m Int]` for an `m` of your choosing. You decided you didn't need the monadic-ness, and so chose the pure monad `Identity`.
10:32:33 <dmwit> You got to reuse the combinator that did the algorithm you needed, but had a slight type mismatch at the end vs. what you wanted it to have.
10:32:41 <HenryCH> dmwit: i see, havent gotten that far yet but i think i understand what you mean
10:32:47 <HenryCH> thanks
10:33:49 <dmwit> I mean, we can do an example that doesn't involve Monad. We've got a ton of newtypes made for specific Monoid instances, e.g.
10:53:45 <Ariakenom> I just spent an hour looking for a <<loop>> bug. Apparently I shadowed a useful variable with "x=x" in an unused where clause
10:57:13 <Cale> Ariakenom: One thing that can often (but not always) help with such things is to compile the program with profiling (-prof -fprof-auto) and then run the program with +RTS -xc
10:57:38 <Cale> I don't think that where clause was really unused though, because otherwise you wouldn't have hit the loop
10:57:58 <Ariakenom> unused except for the x=x redefinition
10:58:33 <Ariakenom> ya at least I got some practice using stack traces
10:58:45 <MarcelineVQ> alternatively -Werror name-shadowing, can you -Werror=specificwarning yet?
10:59:42 <MarcelineVQ> ah you can
11:30:16 <HenryCH> learn you a haskell recommends against using floats in ranges but doesnt explain why the issue is specific to ranges, and what's the alternative?
11:31:47 <Solonarv> the issue is that the Enum instance for Float and Double is weird
11:31:56 <Solonarv> > [1,3..20] :: Int
11:31:58 <lambdabot>  error:
11:31:58 <lambdabot>       Couldn't match expected type Int with actual type [Integer]
11:31:58 <lambdabot>       In the expression: [1, 3 .. 20] :: Int
11:32:00 <Solonarv> > [1,3..20] :: [Int]
11:32:02 <lambdabot>  [1,3,5,7,9,11,13,15,17,19]
11:32:09 <Solonarv> > [1,3..20] :: [Double]
11:32:11 <lambdabot>  [1.0,3.0,5.0,7.0,9.0,11.0,13.0,15.0,17.0,19.0,21.0]
11:33:00 <HenryCH> then it's a problem regardless how you create the list?
11:33:55 <tdammers> no, if you write the list manually, you're just limited by what floats can represent
11:34:47 <tdammers> > [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] :: [Double] -- no weirdness
11:34:49 <lambdabot>  [1.0,3.0,5.0,7.0,9.0,11.0,13.0,15.0,17.0,19.0]
11:39:32 <isn> hey. I think I broke the zip function in Haskell
11:39:47 <isn> When I did zip "kirk" "spock" I used to get [('kirk','spock')]
11:39:53 <isn> Now I just get [('k','s'),('i','p'),('r','o'),('k','c')]
11:40:10 <isn> does anyone know what I'm doing wrong? :')
11:40:13 <Akii> how do I compile https://github.com/mkawalec/emailparse ? it says something something * Missing (or bad) C libraries: icuuc, icui18n, icudata
11:40:24 <tdammers> you cannot possibly have gotten [('kirk', 'spock')]
11:40:36 <tdammers> > zip "kirk" "spock"
11:40:38 <lambdabot>  [('k','s'),('i','p'),('r','o'),('k','c')]
11:40:42 <tdammers> but maybe you did this:
11:40:48 <tdammers> > zip ["kirk"] ["spock"]
11:40:50 <lambdabot>  [("kirk","spock")]
11:40:59 <tdammers> remember that strings are lists of Char
11:41:04 <tdammers> :info String
11:41:07 <Akii> tdammers  maybe if it's text not [char]? 
11:41:17 <tdammers> Akii: no, then it simply doesn't typecheck
11:41:23 <tdammers> @let import qualified Data.Text as Text
11:41:25 <lambdabot>  Defined.
11:42:14 <isn> tdammers: hmm, I am following a book and I remember I just did "kirk" and "spock" and get [("kirk"),("spock")]. It's also like this in the Seven Langauges in Seven Weeks book
11:42:50 <isn> But maybe I've done ["kirk] ["spock"] without reminding
11:43:41 <dkurilo> "kirk" is the same as ['k','i','r','k']. The same is for spock. Everything is OK. Use zip ["kirk"] ["spock"]
11:44:01 <isn> thanks :)
11:44:11 <cocreature> isn: that just looks like a mistake in that book
11:45:12 <isn> yeah probably, I guess i've unconsciously did it better than in the book :p
11:45:52 <HenryCH> tdammers: so besides creating the list manually, you'll have the floating point problem equally regardless of the method you use?
11:49:07 <HenryCH> is there a difference between f.e. creating with replicate and then mapping vs creating the equivalent with range directly? not talking efficiency just the float issue
11:52:32 <dmwit> replicate won't do. But you can use ranges of Ints (or Integers) and convert, which usually has the behavior you want.
11:52:43 <dmwit> > map (fromIntegral :: Int -> Double) [1,3..19]
11:52:45 <lambdabot>  [1.0,3.0,5.0,7.0,9.0,11.0,13.0,15.0,17.0,19.0]
11:52:57 <HenryCH> what's the function that creates a list with a generator and state? like an unfold where the generator returns Maybe?
11:53:04 <dmwit> :t unfoldr
11:53:05 <lambdabot> (b -> Maybe (a, b)) -> b -> [a]
11:53:33 <dmwit> If you're thinking of maybe doing iterated addition on Doubles, I recommend against that, too. You'll get compounding rounding errors.
11:53:42 <HenryCH> damnit.. i searched for unfold, sorry about that :D
11:53:48 <dmwit> Again make a range of Ints and convert. Compare:
11:53:54 <dmwit> > iterate (0.1+) 0
11:53:56 <lambdabot>  [0.0,0.1,0.2,0.30000000000000004,0.4,0.5,0.6,0.7,0.7999999999999999,0.899999...
11:54:05 <dmwit> > map (\x -> fromIntegral x / 10) [0..]
11:54:08 <lambdabot>  [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8...
11:54:56 <HenryCH> no just wanted to know the recommended way to create a list of floats if I shouldn't use range
11:54:59 <Akii> any idea what I need to install on mac? https://gist.github.com/Akii/e16a1768581e2847dfab8cfa4e8932df
11:56:05 <honungsburk> Trying to use the tasty-golden module but can't for the life of me figure out how to send it the option "--accept" I've tried "stack test --ta --accept"
11:56:12 <HenryCH> dmwit: ok, understood thanks
11:56:34 <cocreature> Akii: maybe try the suggestions in https://stackoverflow.com/questions/7420514/using-text-icu-library-in-haskell-on-mac-os
11:56:50 <cocreature> honungsburk: --test-arguments=--accept
11:58:14 <Akii> magic thanks cocreature 
11:58:30 <__monty__> Yep, I have icu4c too.
11:59:31 <Akii> probably need to configure stack a bit
12:02:37 <boj> 124
12:03:39 <boj> sorry
12:08:39 <arjen-jonathan> What does one do if one finds themselve wishing for multiple MonadReader instances on a type to read different parts of the state?
12:09:08 <adamCS> arjen-jonathan: lenses ?
12:09:23 <arjen-jonathan> Is there a way that does not involve explicit focusing?
12:09:29 <adamCS> and zoom or view (I can never remember which is which)
12:09:31 <geekosaur> if they're part of the same state value, there's asks instead of ask? if they're not, you might want to reconsider
12:09:48 <adamCS> I mean, yeah, you could write the getters yourself.
12:10:15 <arjen-jonathan> Right, so in both cases I have to explicitly decompose my larger reader context into smaller parts to run the subcomputation on.
12:10:24 <geekosaur> I think effects-based systems instead of monad transformers handle this "better", but at the price of more complex types
12:11:30 <adamCS> arjen-jonathan, geekosaur: Yes. freer-simple, etc. allow that.  And are nice to work with once you get used to it.  But are, if it matters, slower.  So if binds are your bottleneck, maybe not a good idea.
12:11:31 <Solonarv> and more annoyingly, worse type inference
12:12:24 <arjen-jonathan> Right, thanks.
12:12:44 <adamCS> Solonarv: you mean because the fundeps in mtl make the inference simpler?  Doesn't TypeApplications sort of fix that?
12:13:01 <geekosaur> by removing the "inference" part
12:13:04 <honungsburk> stack test --test-arguments:--accept give me "Invalid option '--accept'"
12:13:10 <Solonarv> TypeApplications lets you more easily specify the types when they can't be inferred, yes
12:13:13 <geekosaur> equal sign, not colon
12:13:35 <adamCS> I mean, if you are "ask"ing and you have multiple readers, it's not a suprise that you need to "ask @SomeType"
12:13:55 <adamCS> It's actually more sort of amazing that sometimes you don't need to
12:14:49 <honungsburk> Sorry, that was a misstype in chat i did use "stack test --test-arguments=--accept"
12:15:10 <cocreature> honungsburk: do you have more than one test suite?
12:16:12 <honungsburk> yes
12:16:42 <Solonarv> something fairly nice you can do with generic-lens:
12:16:42 <Solonarv> do ...; something <- uses (typed @Something) :: MonadReader e m, HasTyped e Something => m Foo
12:16:47 <cocreature> honungsburk: then one of them probably doesnt accept that argument
12:16:55 <cocreature> honungsburk: try specifying the test suite explicitely
12:17:04 <Solonarv> (I may have gotten the names of some things in there wrong)
12:17:15 <honungsburk> I try that
12:26:01 <dmwit> arjen-jonathan: Make a custom monad with a custom API that isn't MonadReader.
12:26:50 <dmwit> (Okay, so maybe you use ReaderT and MonadReader-polymorphic things in the implementation! That's okay. The users of the API don't have to (shouldn't be able to) know that.)
12:29:44 <Solonarv> yep, I often do this
12:37:47 <arjen-jonathan> dmwit: i prefer the lenses solution
12:47:06 <fen>     * Expected kind `[*]', but `S Z' has kind `[()]'     * In the first argument of `Length', namely `(S Z)'
12:47:41 <fen> why is it not accepting that [()] is contained within [*] ?
12:50:59 <dmwit> There is no subtyping (or subkinding).
12:51:28 <dmwit> So 1. the kind [()] is not a subkind of [*] and 2. the type [()] has kind *, not [*].
12:52:47 <fen> well, S Z was used at type level, so thats a type level [()] so it has sort *... as it says in the error, S Z has kind [*]
12:52:53 <fen> [()] sorry
12:53:21 <fen> so how do we have polymorphism?
12:53:40 <fen> type family Fmap (f :: k1 ~> k2) (xs :: m k1) :: m k2 
12:54:06 <fen> type family Const (x :: a) (y :: b) = (c :: a) where  Const x y = x
12:54:15 <fen> type family Length (xs :: [*]) = (ys :: Nat) where  Length xs = Fmap (ConstSym1 '()) xs
12:55:11 <fen> hmm
12:55:16 <fen> setting (xs :: m a) works
12:55:33 <fen> i must mearly understand it to be able to make that guess, but not really convinced
12:55:38 <fen> nearly*
12:56:18 <fen> xs :: [a] works too
12:56:31 <fen> so * does not mean forall a. a
12:56:34 <fen> at type level?
12:56:52 <fen> ie [a] /~ [*]
12:57:22 <fen> argh thats wierd
12:57:36 <fen> ok nvm its just confusing
13:00:01 <Solonarv> * has never meant forall a. a
13:05:36 <adamCS> Anyone use streamly?  I'm trying to figure out the best way to do ((Monad m, IsStream t) => m (t m b) -> t m b), basically like Streaming's "effect" and the best I can come up with is "S.concatMap (const x) (S.yield ())" which is fine but it seems like there ought to be a more direct way to do this...
13:08:00 <tabaqui> proposal: add some "export spaces", like "module Data.Map.Strict where (@Types(Map), @SafeAPI(empty, singleton,...), @Unsafe(mapKeysMonotonic...)"
13:08:17 <tabaqui> so we can import a bunch of api methods without write explicit import for each of them
13:08:37 <tabaqui> like import Data.Map.Strict (@Types, @Construction)
13:08:44 <tabaqui> groups can intersect each other
13:11:11 <fen> hey check this out! data MaybeN n a = NothingN (BoundedNat n) | JustN a
13:11:24 <fen> how awesome is that!?
13:11:37 <tabaqui> 5/7
13:11:39 <tabaqui> what is it for?
13:11:50 <fen> MaybeN!
13:12:12 <tabaqui> BoundedNat a => Either a n?
13:12:23 <fen> yeah
13:12:35 <fen> wait, not BoundedNat is a type cont a constraint
13:12:47 <tabaqui> oh, (BoundedNat a ~ n) => Either a b
13:13:02 <tabaqui> dunno, somewhat
13:13:07 <fen> type StateN n a s = Either (a,Either s (BoundedNat n)) (BoundedNat n)
13:13:26 <fen> Either a (BoundedNat n) = MaybeN n a
13:14:29 <fen> type StateN n a s = MaybeN n (MaybeN n a)
13:15:18 <fen> hmm, maybe it needs one of the maybes to be less than the other...
13:15:46 <AWizzArd> Haskell microservices. How do they communicate? Currently my candidate would be ZMQ. Opinions?
13:16:16 <tabaqui> RabbitMQ, plain tcp with custom transport
13:16:20 <Rembane> AWizzArd: Do they only communicate to each other? 
13:16:50 <AWizzArd> Rembane: yes, bidirectional communication
13:16:55 <tabaqui> (cereal, or json with prepended 4 bytes size)
13:17:08 <AWizzArd> tabaqui: which lib for RabbitMQ?
13:17:53 <tabaqui> AWizzArd: amqp
13:18:13 <fen> type StateN n a s = MaybeN n (a,(MaybeN n s))
13:18:26 <tabaqui> brokers has two significant flaws for me
13:18:38 <tabaqui> you cannot know if other side is dead
13:18:51 <tabaqui> and you cannot know if other side even received a message
13:18:53 <johnw> if I'm running tests with ./Setup test, is there a way to run them concurrently?
13:19:11 <tabaqui> johnw: try HUnit for your test suits
13:19:15 <tabaqui> it is really great library
13:19:17 <AWizzArd> tabaqui: then why not ZeroMQ?
13:19:26 <fen> isnt Haxl for that?
13:19:36 <tabaqui> AWizzArd: I dunno, is is a legacy component
13:19:43 * tabaqui is out
13:19:47 * hackage comprehensions-ghc 0.1.0.0 - Plugin to generalize comprehensions  https://hackage.haskell.org/package/comprehensions-ghc-0.1.0.0 (MatthewFarkasDyck)
13:19:53 <johnw> tabaqui: I'm using tasty, but for some reason using via ./Setup test doesn't give me access to its wonderful array of options
13:20:18 <johnw> ./Setup test -j4 says "unrecognized test option"
13:20:27 <tabaqui> johnw: well, I've tried test-framework before, but HUnit is much better
13:20:31 <johnw> oh, hmmmmmm
13:20:34 <johnw> actually, n/m
13:20:40 <johnw> I'm not using tasty thanks
13:20:42 <tabaqui> and it works pretty well with QuickCheck and HUnit
13:20:49 <tabaqui> *oh not hunit but hspec
13:20:50 <johnw> switching now.
13:20:52 <__monty__> Tasty's great.
13:20:57 <tabaqui> s/hunit/hspec
13:21:11 <tabaqui> HSpec is a great framework
13:21:17 * tabaqui is really really out
13:21:17 <__monty__> What's legacy about ZeroMQ?
13:21:46 <fen> what if you want to use memoisation logging to record the dataypes generated by Quickcheck for reproducability using Haxl?
13:21:50 <AWizzArd> __monty__: have you worked with zmq? I found it to be working pretty well.
13:22:30 <fen> then you could have concurrent IO too
13:23:28 <fen> concurrent-by-default using applicative-do or whatever it is
13:23:35 <__monty__> AWizzArd: I haven't no. But Saltstack switched from their custom RAET to ZeroMQ when I followed the development. Because it performed better. So I doubt it's legacy.
13:23:59 <AWizzArd> __monty__: what is RAET?
13:25:20 <__monty__> Reliable Asynchronous Event Transport
13:25:35 <__monty__> It was designed specifically with Saltstack in mind.
13:26:13 <__monty__> I'm not sure about the current status though. It seemed like they were gonna abandon it back then but apparently they're still developing it.
13:26:58 <__monty__> Or not, last commit in 2017.
13:30:21 <fen> states can be unfolded... so the StateN above seems to be able to be "unfoldedN" or, if the unfold n is less than the StateN n, then there is a way to change a StateN n into a StateN m via unfoldN (n-m)
13:30:42 <fen> this gives a really difficult to understand version of an unfold typeclass
13:31:20 <delYsid`> dmwit: Sorry, I was confused.  I just googled for getWord16be, and ended up on the binary-strict page.  By now, I understand you were just pointing me to the many combinator.  It all works now, thanks
13:35:21 <fen> where the value the state is over is the return of the unfold, ie a (n-m) nested thing
13:36:13 <fen> maybe its just the lowest levels that can be unfolded? those closest to the stored value `a'
13:36:42 <fen> not sure how it would be othersise like a state of states and unfolded containers all interspersed
13:36:52 <fen> cant even understand how to express that
13:37:43 <dmwit> delYsid`: cheers!
13:40:02 <delYsid`> uhhh, defining a Unbox instance for a newtype looks pretty scary.
13:40:51 <delYsid`> s/newtype/record type/
13:41:08 <dmwit> It's not that bad, really.
13:41:19 <dmwit> Depending on exactly which Unbox you're talking about, I guess.
13:41:35 <dmwit> One common trick is to just use n arrays (when there are n fields).
13:41:45 <delYsid`> I guess, however, I have zero experience with type families.
13:41:49 <dmwit> Refer to the Unbox instance for tuples for direction.
13:42:08 <fen> :t \f s -> let go fs fa (b,ms) = maybe (b,ms) (go fs fa) (ms >>= \s -> fmap (\(a,s') -> (fa a b,s')) (fs s)) in go  f (:) ([],Just s)
13:42:10 <lambdabot> (t -> Maybe (a, Maybe t)) -> t -> ([a], Maybe t)
13:42:20 <fen> thats the lowest level version
13:42:38 <delYsid`> dmwit: Yeah, I gotta fetch the source.  the #include of the tuple instances somehow breaks webreadability.
13:42:55 <dmwit> Oh yeah, I forgot about that.
13:43:05 <delYsid`> It would also help if the example at the beginning of the module didn't elide essential instance method definitions.
13:43:09 <fen> see how it takes a higher nested version of State and returns a regular State of an unfolded [a]
13:43:57 <dmwit> :t \f t -> unfoldr (>>= f) (Just t)
13:43:58 <lambdabot> (a1 -> Maybe (a2, Maybe a1)) -> a1 -> [a2]
13:44:00 <delYsid`> what is a newtype instance?
13:44:51 <dmwit> delYsid`: It's like a data instance, but a newtype instead. =P
13:45:04 <fen> dmwit: woah whats that?
13:45:04 <dmwit> delYsid`: You know what (associated) data families are?
13:45:32 <dmwit> fen: What's what?
13:45:52 <fen> looks like you managed to simplify it a whole lot
13:46:12 <dmwit> Maybe. I didn't read your implementation, only your type, so maybe it doesn't do the same thing.
13:46:18 <fen> oh, but only by making it an unfold instead of a hylo
13:46:29 <fen> thats fine though, the fold unfold fusion should recover that
13:47:03 <fen> oh, unless this is actually the thing that rule is written in terms of
13:47:10 <fen> oh no this is terrible
13:48:07 <fen> there might even be some similar form of fold...
13:48:29 <dmwit> :t \f s -> let go (b, ms) = maybe (b, ms) go (ms >>= \s -> fmap (\(a,s') -> a:b,s')) (f s)) in go ([], Just s)
13:48:30 <lambdabot> error: parse error on input )
13:48:46 <dmwit> :t \f s -> let go (b, ms) = maybe (b, ms) go (ms >>= \s -> fmap (\(a,s') -> a:b,s') (f s)) in go ([], Just s)
13:48:47 <lambdabot> error:
13:48:47 <lambdabot>      Couldn't match expected type a -> ([a1], Maybe t)
13:48:47 <lambdabot>                   with actual type ((a1, b0) -> [a1], b1)
13:48:59 <dmwit> Okay, I'll stop doing that in-channel. Sorry.
13:50:31 <fen> if this nested state hylo unfold turns a higher nested state into a lower nested state of unfolded things, then there must be the opposite of returning StateN with an increased n from a lower StateN of linear containers that could be hylo/folded
13:52:23 <fen> so creating an equvalence between the extreem opposites of a bunch of nested containers to some depth, and a stateN of that dpeth, and with all the various stages inbetween by proceeding one level at a time
13:52:40 <fen> still not sure if there is choice over the order of which layers to do first
13:53:10 <flebron_> Hi. I wrote this and I'd like my eyes to stop bleeding. How can I make this clearer/prettier? fold . fmap (fold . fmap fold) $ xs
13:53:33 <fen> in either direction, converting to stateN n from n-depth nested containers or the other way round
13:53:41 <jle`> hm, if your type is a Functor, you can use foldMap instead of folding and mapping
13:54:00 <jle`> (foldMap . foldMap) fold
13:54:18 <flebron_> Oh pretty.
13:54:27 <flebron_> Would that seem "clear" to you if you saw it?
13:54:32 <linduxed> i'm curious: what's the data like?
13:54:34 <jle`> er sorry, you can use foldMap instead of folding and fmapping even if your type isn't a Functor -- i got the implication in the wrong direction :)
13:54:57 <jle`> flebron_: im really accustomed to seeing chained lifting like that
13:55:06 <jle`> it's similar to (fmap . fmap), or (liftA2 . liftA2)
13:55:20 <jle`> it would be clear to me, or other people who are used to seeing chained lifters
13:55:22 <fen> jle` where do you use that!?
13:55:28 <glguy> since it's already not a complete chain you could just write: foldMap (foldMap fold)
13:55:33 <jle`> alternatively if you want to super-chain it, `(foldMap . foldMap . foldMap) id`
13:55:46 <fen> super-chain!?
13:55:46 <jle`> fen: (fmap . fmap) is pretty common if you want to, say, map over two "layers" of functors
13:55:51 <glguy> :t view (folded . folded . folded)
13:55:52 <lambdabot> (Foldable f3, Foldable f2, Foldable f1, Monoid a, MonadReader (f1 (f2 (f3 a))) m) => m a
13:55:53 <dmwit> :t getCompose . getCompose . fold . Compose . Compose
13:55:54 <lambdabot> error:
13:55:55 <lambdabot>     Variable not in scope: getCompose :: b0 -> c
13:55:55 <lambdabot> error:
13:55:58 <jle`> > (fmap . fmap) (*2) [Just 1, Nothing, Just 2]
13:56:00 <lambdabot>  [Just 2,Nothing,Just 4]
13:56:14 <dmwit> % import Data.Functor.Compose
13:56:15 <yahb> dmwit: 
13:56:21 <dmwit> % :t getCompose . getCompose . fold . Compose . Compose
13:56:21 <yahb> dmwit: forall k2 k3 k4 k5 k6 (f1 :: k3 -> *) (g1 :: k2 -> k3) (g2 :: * -> k2) (f2 :: k4 -> *) (g3 :: k5 -> k4) (g4 :: k6 -> k5) (a :: k6). (Foldable (Compose (Compose f1 g1) g2), Monoid (Compose (Compose f2 g3) g4 a)) => f1 (g1 (g2 (Compose (Compose f2 g3) g4 a))) -> f2 (g3 (g4 a))
13:56:23 <jle`> fen: super-compose as in, see the entire problem as just a series of function liftings
13:56:29 <dmwit> Oh my.
13:56:53 <fen> jle` does that mean you can actually comprehend what is up with this stateN / nested containers equivalence? it seems plausable, but being totally overwhelmed by such an idea it barely seems reasonable at all
13:56:54 <dmwit> Ah, whoops.
13:56:58 <dmwit> % :t fold . Compose . Compose
13:56:59 <yahb> dmwit: forall k1 k2 (f :: k2 -> *) (g1 :: k1 -> k2) (g2 :: * -> k1) c. (Foldable (Compose (Compose f g1) g2), Monoid c) => f (g1 (g2 c)) -> c
13:57:08 <dmwit> flebron_: ^
13:57:10 <jle`> fen: i'm not sure where state etc. is coming up here
13:57:22 <jle`> but (fmap . fmap) is a pretty common idiom
13:57:29 <fen> :t \f s -> let go fs fa (b,ms) = maybe (b,ms) (go fs fa) (ms >>= \s -> fmap (\(a,s') -> (fa a b,s')) (fs s)) in go  f (:) ([],Just s)
13:57:30 <lambdabot> (t -> Maybe (a, Maybe t)) -> t -> ([a], Maybe t)
13:57:46 <jle`> haskellers are often used to seeing (fmap . fmap), and sometimes may also be used to seeing other chained lifters
13:57:48 <fen> thats turning a State2 into a State1 of an unfolded thing
13:57:56 <fen> you could unfold that state and it would give a [[a]]
13:57:57 <jle`> like (liftA2 . liftA2), (traverse . traverse), (foldMap . foldMap), etc.
13:58:42 <jle`> flebron_: fmap . fmap is fmapping through "two layers", traverse . traverse is traversing "two layers", so foldMap . foldMap is folding over "two layers"
13:58:46 <fen> data MaybeN n a = NothingN (BoundedNat n) | JustN a
13:58:59 <fen> type StateN n a s = MaybeN n (a,(MaybeN n s))
13:59:02 <flebron_> linduxed: I have a fs :: [F (G (a -> b))], and a xs :: [F (G a)], and I do zipWith (liftA2 (<*>)), and now I want to collapse all of these, so I do that foldMap . foldMap fold thing.
13:59:26 <jle`> flebron_: ah, you can probably go directly without the extra <*> step
13:59:49 <jle`> oh nvm, i misread
13:59:52 <fen> there is an implementation of BoundedNat somewhere too...
14:00:09 <linduxed> flebron_: oh... we'll i'll need to think about that for a moment. i haven't used lift yet
14:00:48 <jle`> heh, you can also see your zipWith liftA2 thing as multi-level lifting too
14:00:53 <fen> not sure if state / unfold / fold / hylo is anything to do with "lifting"
14:00:54 <jle`> it's (zipWith . liftA2 . liftA2) ($)
14:01:11 <jle`> not that that is any more practical than what you have now
14:01:22 <jle`> but just showing you how common the "multi-lifting" idiom pops up :)
14:01:43 <jle`> here you're lifting ($) over G (with the last liftA2), over F (with the middle liftA2), and then over [] (with the zipWith)
14:02:10 <fen> oh so its like commuting into an applicative?
14:02:24 <jle`> fen: ah sorry, i see the confusion now. my original message was in response to flebron_, sorry!
14:02:25 <fen> like traverse basically
14:02:35 <fen> jle` was just begining to realise
14:02:45 <fen> just because of the nested containers similarity, sorry
14:02:53 <jle`> the curse of irc :)
14:03:04 <fen> but might thought you could understand the situation with the state unflod thing
14:03:10 <fen> cos its totally mental
14:03:53 <fen> not sure if it counts as "taking haskell too far"
14:04:20 <fen> but its certainly basically at the limit of comprehensability 
14:04:52 <fen> the really daunting thing is that it seems to be a kind of version of the Foldable / Unfoldable classes that works on nested containers
14:05:16 <fen> hmm, maybe it needs a FreeN thing to make that seem less crazy
14:05:46 <fen> seems reasonable if thats kind of dual to StateN written above
14:05:55 <fen> not sure what that duality is exactly...
14:06:04 <fen> state / church duality?
14:06:48 <fen> but yeah, simultantiusly folding or unfolding a whole group of them at a time
14:07:11 <fen> so if it wasnt fixed the order this occured in, how would that be specified!?
14:07:24 <fen> its just waaay too complicated
14:08:19 <fen> ok, ill go and cry about this some other place and maybe return if anything materialises 
14:11:34 <slack1256> Mmmm state / church duality has come so far since the XIX century
14:11:38 <Bish> if i have an list of 5 strings
14:11:49 <Bish> how would i calculate a hash of those 5 strings in threads?
14:12:33 <Bish> i expect something like map (\x->) $replicateM 5 newEmptyMVar ...
14:12:50 <Bish> but i get why that is wrong
14:14:09 <slack1256> Bish: say you hash function is `hash :: ByteString -> IO Hash`
14:14:19 <slack1256> err
14:14:26 <Bish> slack1256: yeah but i don't
14:14:27 <slack1256> `hash :: ByteString -> Hash`
14:14:32 <Bish> yeha i have that
14:14:40 <slack1256> Then you can use parallel instead on concurrency
14:14:56 <Bish> i would like to see both
14:15:30 <slack1256> https://hackage.haskell.org/package/parallel-3.2.2.0/docs/Control-Parallel-Strategies.html 
14:15:52 <Bish> yeah i read those but i think i would get it if i see an example
14:16:01 <slack1256> you process the list "in parallel" using one of those strategies. That can be done without thei IO monad
14:16:08 <Bish> and honestly that strategy stuff confused me
14:16:09 <slack1256> Mmm let me see if I can hack one
14:18:14 <MarcelineVQ> adamCS: not that I can figure out
14:18:14 <slack1256> % map (+1) [1000, 1002, 5000, 13000] `using` parTraversable rdeepseq
14:18:14 <yahb> slack1256: ; <interactive>:9:36: error:; * Variable not in scope: using :: [Integer] -> t0 -> t; * Perhaps you meant `fusing' (imported from Control.Lens); <interactive>:9:44: error: Variable not in scope: parTraversable :: t1 -> t0; <interactive>:9:59: error: Variable not in scope: rdeepseq
14:18:17 * hackage mattermost-api 50200.1.3 - Client API for Mattermost chat system  https://hackage.haskell.org/package/mattermost-api-50200.1.3 (JonathanDaugherty)
14:18:32 <slack1256> % import Control.Parallel.Strategies
14:18:33 <yahb> slack1256: 
14:18:47 <slack1256> % map (+1) [1000, 1002, 5000, 13000] `using` parTraversable rdeepseq
14:18:48 <yahb> slack1256: [1001,1003,5001,13001]
14:19:10 <slack1256> Bish: change the `(+1)` to your hash function and the list to you actual data
14:19:17 * hackage matterhorn 50200.3.0, mattermost-api-qc 50200.1.3 (JonathanDaugherty): https://qbin.io/voip-philip-o38b
14:19:34 <Bish> well, still wont understand how that works :/
14:19:49 <slack1256> ``using` parTraversable rdeepseq` says that using a parallelism on the Traversable container (the list) evaluate using a rdeepseq stratetegy
14:20:12 <Bish> would you still showme the mvar approach?
14:20:18 <monochrom> This is what's wrong with "n languages in n days"
14:20:44 <slack1256> Bish: you don't *need* to understand it, but basically the parallelism is an Strict Identity monad which evaluate all the arguments using `par/ pseq`
14:20:44 <MarcelineVQ> adamCS: If it's at all helpful remember that you can say "serially $ foo" to give 'foo' the context of being SerialT, and similar for other Stream types, which gives you a lot more typeclasses to draw from. Like MonadBase and Foldable and Monoid etc
14:20:55 <Bish> slack1256: i get what basicially happens
14:21:01 <monochrom> If you make it "10n days" it will be more realistic.  It takes a couple of days to study the parconc book.
14:21:08 <Bish> but in order to learn i chose that way.. i can learn about more advanced stuff later
14:21:19 <slack1256> Bish: you got that backwards
14:21:27 <slack1256> parallel is more basic that mvar stuff
14:21:43 <Bish> well, i know what happens in the basic mvar exmaple
14:22:01 <Bish> i dont know what happens using those pure parallel stuff
14:22:06 <nshepperd> Bish: a value of type 'Strategy b' is a plan or method for evaluating a value of type b
14:22:21 <slack1256> yeah, you will have to read to understand it completely
14:22:35 <Bish> so its less basic to me
14:22:36 <slack1256> for now think of it as a scheme on how to evaluate stuff in parallel
14:22:53 <monochrom> Also, if you took "learning" seriously, the whole point of claiming to "learn" is to study what you don't know, not re-affirming what you already know.
14:23:06 <nshepperd> Bish: rdeepseq :: Strategy Hash -- a method that fully evaluates a single hash the usual way (single threaded)
14:23:50 <Bish> monochrom: so.. i end up learning about physical effects of transistors? because i want parallelism
14:23:53 <Bish> i have to focus somewhere
14:23:55 <nshepperd> Bish: parList rdeepseq :: Strategy [Hash] -- a method that evaluates a list of hashes, by applying rdeepseq to each hash, in parallel
14:24:16 <monochrom> You can focus on parChunks etc, as said by others.
14:24:22 <MarcelineVQ> adamCS: but your concatMapM is the only thing I can find that works
14:24:37 <slack1256> Bish: try to work out your way, when you find a specific roadblock come back and ask
14:24:37 <Bish> monochrom: so i go deeper the rabbit hole, before exploring things that i already understand
14:24:40 <monochrom> maybe it's spelled parListChunk(s), I forgot the exact name.
14:24:55 <Bish> i believe, its the better way, but i disagree on the learning part
14:25:37 <slack1256> Bish: hey, do it your way, go nuts, you only know yourself
14:25:49 <Bish> well, yeha and i asked for specific help
14:26:27 <Bish> thats like going to a c novice who asks for loops "just do it with recursion"
14:26:31 <Bish> and hes like, okay, whats that
14:26:42 <Bish> just adds confusio
14:26:59 <slack1256> the idiomatic haskell way to do the stuff you wanted to do is parallel
14:27:06 <slack1256> is exactly backwards to your example
14:27:11 <slack1256> but hey, you do you
14:27:15 <Bish> yeah and idiomatic is not the first you learn
14:27:24 <Bish> i never disagreed on the idiomatic way
14:28:02 <monochrom> I think your analogy is broken.
14:28:21 <Bish> it might be, but what i tried to explain isn't
14:28:56 <nshepperd> are you having any specific issue with understanding parallel?
14:29:08 <Bish> i don't get it at all, and i don't want to yet
14:29:29 <Bish> if you really wanted to help, you would say: "this is the way you do it... but thats bad because xyz, you can do it this way"
14:29:39 <Bish> otherwise you don't want to help, which is fine, but don't
14:30:24 <nshepperd> err
14:30:25 <slack1256> That is really rich coming from someone who asked for help, received the help and didn't like it.
14:30:38 <Bish> no, i have never recived help for my question
14:30:50 <nshepperd> well, you need to understand deepseq and stuff if you're going to do it with mvars anyway
14:30:57 <Bish> i asked for a boat, and you gave me a plane, while i mcuh rather would like the boat
14:31:16 <Bish> and i specificially asked for the boat to get there
14:31:23 <Bish> you never received help in that regard
14:31:26 <Bish> i*
14:31:54 <Bish> nshepperd: how so? i google "mvar example" and i get it on the spot
14:32:11 <Bish> i just can't map it to multiple instances, cleverly
14:32:47 <monochrom> I actually don't understand why mvar is relevant for this, even when you would like to use forkIO.
14:33:29 <Bish> well, because it spawns threads(forkIO) and i figured i go with something familiar, coming from imperative stuff
14:34:43 <Bish> and it doesn't matter if you know why i would like to do it that way.. geez
14:35:50 <nshepperd> result <- for hashes $ \hash -> do { mvar <- newEmptyMVar; forkIO (evaluate (force hash) >>= putMVar mvar); takeMVar mvar }
14:36:23 <nshepperd> it's easier done with 'async', and even easier done with 'parallel'
14:36:34 <monochrom> OK I see my mistake. mvar is relevant for getting notified that a thread has finished.
14:37:04 <Bish> what is evaluate good for? i think i understnad the rest
14:37:10 <Bish> oh, and "for%"
14:37:31 <nshepperd> 'for' is just traverse with the arguments reversed
14:37:31 <Bish> oh, im guessing it's like for :D?
14:37:37 <nshepperd> :t for
14:37:38 <lambdabot> (Applicative f, Traversable t) => t a -> (a -> f b) -> f (t b)
14:38:24 <nshepperd> 'evaluate' is good for evaluating things
14:39:08 <nshepperd> you need it or else your thread doesn't do anything
14:39:38 <Bish> why does it do something when i do mapM forkIO [putStrLn "1"]
14:40:18 <nshepperd> in this case, i mean
14:41:37 <isn> Hey guys. I have to create a project with Haskell in a functional programming course for my university. Could you guys suggest me ideas of what would be nice (and challenging) project to create with Haskell / FP?
14:42:25 <Bish> force is my hash function i suppose? why that weird name :o
14:42:39 <nshepperd> no, 'force' comes from the deepseq package
14:42:59 <nshepperd> it ensures that the value is fully evaluated, not just the outer constructor
14:43:14 <Bish> shit thats confusing
14:43:21 <nshepperd> it may or may not be necessary, depending on how the hash type is represented
14:43:31 <slack1256> isn: how introductory or advanced is the course?
14:43:33 <geekosaur> Bish, actual I/O will happen. pure computations don't necessarily.
14:43:56 <nshepperd> Bish: i've assumed that you already calculated the hashes, with 'let hashes = map myHashFunction strings' or so
14:43:57 <geekosaur> in partiuclar, `return (pure computation here)` gives you back an unevaluated expression that gets forced later
14:44:24 <Bish> nshepperd: oh i did, i was here yesterday crying about haskell eating my ram
14:44:37 <isn> slack1256: Well, we have to learn Haskell from the book Seven Languages in Seven Weeks. They told us that we have to create something that is advanced. That's all info I've got lol
14:44:45 <nshepperd> s/calculated/defined/ rather
14:44:53 <Bish> geekosaur: i figured something like that what was the term.. thunks?
14:45:17 <geekosaur> that's the term for how ghc accomplishes that, yes
14:45:27 <isn> I suggested something like compression algorithm to my prof and he said that it could be too easy
14:45:32 <geekosaur> it's something of an internal detail, although we do sling it around a bit when talking about it
14:46:10 <monochrom> Depends on which compression algorithm. RLE is too easy. Huffman and LZW will be hard in any language at all.
14:46:27 <monochrom> RLE is something I gave on an exam.
14:47:52 <isn> Thanks, I'll look into Huffman and LZW. Do you have any other ideas?
14:48:12 <isn> Like what would be a good project to make using pure Haskell without importing too many modules
14:48:13 <monochrom> How thick is this bloody "7 language 7 weeks" book?
14:48:45 <isn> just 3 chapters of about 20 pages each. But they want us to look furhter than the book
14:49:18 <Bish> nshepperd: thanks alot i will have to digest that
14:49:35 <Bish> and im grateful for that strategy stuff i promise i will read it, yourr effort will not be in vain
14:49:38 <isn> Maybe i'll just create a parser or something
14:50:41 <slack1256> I guess you could make a very basic http server (for a subset) if you already know about http
14:50:44 <Rembane> A LISP interpreter! :D
14:51:17 <slack1256> the trick that the "create a thread per request model" actually works on haskell
14:51:22 <slack1256> so you can show off that
14:51:24 <__monty__> All of those sound simpler than implementing a compression algorithm : >
14:51:51 <isn> Yeah true, but I would like to have a bit of fun whilst working on this project :p
14:51:54 <Rembane> Implement a compression algorithm in the resulting lisp.
14:52:23 <slack1256> Impelment a compression algorithm in the resulting lisp program of a web server
14:53:02 <Bish> write a blokus game in haskell (i liked that very much)
14:53:32 <Bish> because writing game rules as functions is declarative and satisfying
14:53:53 <isn> nice, a game!
14:55:23 <slack1256> A 2048 clone?
14:55:40 <Bish> https://en.wikipedia.org/wiki/Blokus
14:55:45 <Bish> i enjoyed writing this in haskell
14:56:02 <isn> nice, how long did it take you?
14:56:11 <isn> I'm aiming for a project that I could finish in a couple of days
14:56:17 <isn> and i'm a noob :p
14:56:24 <Bish> well.. if you count in understanding what a freakin monad is
14:56:26 <Bish> months..
14:56:29 <Bish> (im not really clever)
14:56:58 <Rembane> Bish: What kind of user interface did you create?
14:57:49 <Bish> textual, my plan was http server and http/2 but in the end i didn't
14:58:04 <isn> haha damn
14:58:24 <Bish> still learning haskell because there is no freaking languages that handels http/2 well
14:58:44 <Rembane> Bish: Cool! I hoped for text adventure for a little while there.
14:58:47 <Bish> and i hope i will get there some day.. but haskell is every so often so damn uneccessarely complicated
14:59:18 <Bish> Rembane: well if your brain can render the history of turns into a board :D
14:59:36 <monochrom> How much time do you have for this project?
14:59:48 <Rembane> Bish: I know people who play Go without a board, so this should work out... :D
15:00:16 <Bish> i know the list of people worse in go than me: []
15:00:53 <isn> I've got like about 3-4 days
15:01:20 <Bish> write a threaded sha1 hash-cracker :p
15:01:25 <isn> I could add in 1 one more voluntarily since I'm starting to like haskell
15:01:45 <monochrom> Because I gave very simply http://www.cs.utoronto.ca/~trebla/CSCC24-2019-Winter/A2/ for homework, and the students had about 2 weeks (maybe plus 1 or 2 days, I forgot), and before this homework they had 3 weeks learning Haskell.
15:02:23 <monochrom> And so altogether it's like 5 weeks and the students still had to work hard, or rather, think hard.
15:03:32 <isn> Yeah, it seems like a hard - or rather time consuming - project
15:04:18 <monochrom> Despite the fact that my solution is like just 10 lines. And does not involve monad or IO or parallelism or any "advanced" even "intermediate" things. It's just lazy lists and dictionaries.
15:04:42 <monochrom> and logical-and, logical-or.
15:06:08 <isn> hmm, yeah most of the time such problems can be solved with just a couple of lines
15:06:51 <isn> it's just that you need to learn how to think correctly etc
15:13:17 <monochrom> Ray-tracing could be doable if you are OK with let's say 1/3 of the speed of C.
15:14:08 <monochrom> But who am I kidding. We're talking about an instructor who expect the undoable.
15:15:47 <isn> anyway, thank you guys for the suggestions. I wrote them all down. I'm gonna look into it tomorrow and pick one. Gotta sleep now. cyaaa
15:18:57 <monochrom> I think I heard that people who can play Go without a board require you to make rational moves. If you start making random moves, they will fail to keep track. Too much entropy.
15:19:21 <Solonarv> monochrom: you already win by saying "you may import useful modules here" ;)
15:19:49 <monochrom> Um... what kind of "win"?
15:19:58 <Rembane> monochrom: This needs to be tested. For science! 
15:20:55 <Solonarv> the "you make good, sensible exercises" kind of "win" ;)
15:21:21 <monochrom> Yeah!
15:23:18 <monochrom> I don't actually allow completely arbitrary packages on hackage. But I wrote my solution under GHC-only first to ensure it is reasonable and no reinvent-the-wheel before I committed to this problem.
15:23:50 <monochrom> Even then, when a few students preferred Hashmap to IntMap, I added unordered-containers for them.
15:24:48 <DigitalKiwi> monochrom: i want edwardk to take one of your courses
15:25:03 <monochrom> Haha. Wait, what?
15:25:29 <monochrom> As in "learn to not have a huge dependency tree"?
15:25:34 <DigitalKiwi> ha
15:26:14 <monochrom> OK this must be permanently enshrined.
15:26:28 <Tuplanolla> It would've been a good April fools joke to make a `superlens` package that actually contains all of its dependencies within.
15:26:33 <DigitalKiwi> that'd be amusing too but i meant essentially the opposite, he'd have a 3 line solution and a dozen imports of his packages
15:26:49 <monochrom> @remember DigitalKiwi monochrom: i want edwardk to take one of your courses
15:26:49 <lambdabot> I will never forget.
15:29:03 <DigitalKiwi> i do like the idea of making him use only the tools of mortals
15:41:12 <tA> anyone had luck using sdl2 with nixos? im getting this: sdl-space: Error in case ("/pollEvent/pollEvent 1"):
15:41:14 <tA>   error: XDG_RUNTIME_DIR not set in the environment.
15:41:16 <tA> sdl-space: SDLCallFailed {sdlExceptionCaller = "SDL.Init.init", sdlFunction = "SDL_Init", sdlExceptionError = "No available video device"}
15:41:47 * hackage cmark 0.6 - Fast, accurate CommonMark (Markdown) parser and renderer  https://hackage.haskell.org/package/cmark-0.6 (JohnMacFarlane)
15:48:57 <fen> tA: any way to reproduce the error?
15:54:15 <tA> fen: give me a second ill upload what ive got
15:54:21 <tA> the nix is a little messy at the moment
15:56:23 <tA> fen: https://git.lain.church/tA/imi get the error doing `nix-shell --pure`
16:05:17 <ddellacosta> I'm doing this from inside a nix shell where I have cabal and a specific version of ghc installed: what am I missing if I can build with `cabal build` but `ghc src/Main.hs` fails?
16:05:34 <ddellacosta> complains about not being able to find prelude
16:07:17 <geekosaur> you may have multiple versions of ghc, and cabal is using one while the shell finds a different one that's missing its package db for some reason
16:07:28 <ddellacosta> geekosaur: thanks, that makes sense
16:07:52 <geekosaur> possibly because nix pointed it at the version of ghc it expects, but $PATH finds a system one first or etc,
16:08:13 <geekosaur> package dbs are per ghc version so it wouldn't find its packages
16:08:18 <ddellacosta> using nix has highlighted how much of the ghc and cabal machinery I've yet to understand, which is probably for the best
16:08:18 <ddellacosta> yeah, that makes sense, definitely
16:09:05 <geekosaur> nix is good at pointing that up for every language :)
16:09:09 <ddellacosta> haha, I bet
16:11:17 * hackage pandoc-pyplot 2.1.0.1 - A Pandoc filter for including figures generated from Matplotlib  https://hackage.haskell.org/package/pandoc-pyplot-2.1.0.1 (LaurentRDC)
16:43:03 <fen> whats the idea with linking with unix on windows
16:43:18 <adamCS> MarcelineVQ: Thanks!  Seems like a relatively straightforward thing to want to do, as evidenced by its presence in Streaming.  But the concatMap thing works fine so I'll stick with that...
16:43:37 <fen> how can it be sure to make the libraries accessable?
16:45:00 <fen> like, to not have the msys version install things in another location, or reinstall things or not have the windows cmd prompt fail to access the correct unix compatible libs
16:45:32 <MarcelineVQ> adamCS: yeah, there's a sort-of version of it via sequence with t m (m a) -> t m a but I'm not sure why there isn't a "t m (t m a) -> t m a" which would make things pretty direct
16:45:48 <fen> or do you have to install using the windows unix emulator the first time you install haskell and always use it from within this environent?
16:46:41 <MarcelineVQ> direct in the sense that you'd just need a yeildM to get going
16:47:02 <fen> basically as soon as there is a unix dependency on windows its best to just not use that library?
16:47:10 <fen> never seems to work...
16:47:33 <hpc> any cross-platform package that has a dependency on unix will use a conditional dependency
16:47:41 <hpc> and on windows it will do something else, like maybe depend on win32
16:48:07 <fen> guess as soon as its not just down to cabal, ie when it relies on an external build tool, then its not within the remit of the haskell team to make a reproducible thing 
16:48:14 <geekosaur> or unix-compat, which can emulate some of it (with caveats)
16:48:53 <fen> hpc: what does that result in?
16:49:43 <hpc> it results in something like http://hackage.haskell.org/package/directory
16:49:44 <fen> just for the sake of argument assume MSYS because cygwin seems to be slightly less stable last time I checked
16:49:48 <hpc> (look at its cabal file)
16:50:28 <fen> http://hackage.haskell.org/package/directory-1.3.3.2/src/directory.cabal
16:50:31 <fen> this^ ?
16:50:46 <hpc> yes
16:50:57 <fen>     if os(windows)         build-depends: Win32 >= 2.2.2 && < 2.9     else         build-depends: unix >= 2.5.1 && < 2.9
16:52:57 <fen> hmmm
16:53:09 <fen> for example; http://hackage.haskell.org/package/sdl2-2.4.1.0/src/sdl2.cabal
16:53:36 <fen> which returns an error if cabal install SDL is called from the cmd prompt on windows
16:54:03 <Solonarv> that's because it can't find the SDL2 libraries/headers
16:54:17 <hpc> also, it's cabal install sdl2
16:54:22 <hpc> SDL is a different package
16:54:28 <Solonarv> you can install them through msys pretty easily
16:54:33 <fen> oh right, wrong cabal file sorry
16:54:50 <fen> sdl2 has an error also; cabal.exe: The program 'pkg-config' version >=0.9.0 is required
16:54:58 <fen> that looks like a unix like issue
16:55:04 <hpc> it's not
16:55:20 <Solonarv> pkg-config is available on windows
16:55:21 <hpc> it means you need the program 'pkg-config'
16:55:26 <Solonarv> through msys for example
16:55:29 <fen> setup.exe: The package has a './configure' script. If you are on Windows, This requires a Unix compatibility toolchain such as MinGW+MSYS or Cygwin.
16:55:33 <fen> thats the SDL error
16:55:39 <fen> thats definatly a unix error
16:55:50 <Solonarv> how often do I have to say "use msys" before you do it?
16:56:00 <fen> ok, so ./configure and pkg-config are different build tools
16:56:16 <Solonarv> if you're using stack it comes with an msys environment built in (accessible in 'stack exec foo'
16:56:23 <fen> Solonarv: that does not work
16:56:35 <fen> it gets all mixed up with the existing installs
16:56:45 <fen> do you have to use just MSYS from the very begining?
16:56:54 <fen> like, from when you get the haskell platform
16:56:57 <hpc> ./configure is a script that's part of sdl2
16:57:09 <Solonarv> no, you can install ghc+cabal however
16:57:23 <Solonarv> I installed them through chocolatey
16:57:26 <fen> or is there some special process to get msys to work in conjunction with the existing haskell platform installed within the windows environment
16:57:33 <Solonarv> yes, a bit
16:57:48 <fen> otherwise it would be in the msys home dir
16:57:55 <Solonarv> you need to tell msys to inherit the PATH env var from "outside"
16:57:56 <fen> instead of the windows user dir
16:58:02 <fen> aha!
16:58:22 <Solonarv> and you probably want to make the msys home dir a junction to the users dir (normally C:\Users)
16:58:22 <fen> this is probably the one thing keeping windows users from easily using msys with unix haskell projects
16:58:26 <fen> thanks Solonarv!
16:59:05 <fen> is there any command like prompt to write into the msys terminal to do those 2 things?
16:59:31 <Solonarv> to make msys inherit the path you just edit a config file
16:59:44 <fen> msys can use batch files right?
16:59:52 <fen> oh, editing a config file is not as easy
16:59:59 <Solonarv> there are three different msys shells - msys, mingw32, mingw64 - and therefore three different config files
17:00:10 <fen> no its msys
17:00:15 <fen> the others just go below it
17:00:38 <Solonarv> there are three different shells
17:00:42 <fen> or do they all have to be wrangled?
17:00:46 <Solonarv> they are all part of the msys install and do share some stuff
17:00:51 <fen> there are, but we can just use msys
17:00:54 <Solonarv> the home dir is sared for example
17:01:03 <fen> ah ok
17:01:11 <Solonarv> actually I had some issues with that, the mingw64 shell seems to work best
17:01:16 <Solonarv> can't remember what the problems were
17:01:25 <fen> hmm, ok
17:01:43 <Solonarv> creating the junction has to be done in cmd.exe I think
17:02:09 <fen> can use mingw64 instead, probably works as well, not sure why msys was better, might have been for some C project... nvm
17:02:33 <Solonarv> to be specific: I use the mingw64 shell that is part of the msys install
17:02:40 <Solonarv> I'll toss my setup into a gist, one sec
17:03:34 <fen> oh yeah, it was for trying to get ASIO4All to work...
17:04:03 <fen> and then trying to see if the unix "jack" bindings would work on windows, but never managed to get that far
17:04:47 * hackage extensible-effects-concurrent 0.20.0 - Message passing concurrency as extensible-effect  https://hackage.haskell.org/package/extensible-effects-concurrent-0.20.0 (SvenHeyll)
17:04:49 <fen> http://hackage.haskell.org/package/jack
17:05:47 <fen> because the FFI for the asio bindings seemed incomplete; https://hackage.haskell.org/package/proteaaudio-0.6.5/docs/Sound-ProteaAudio.html
17:06:47 <fen> https://hackage.haskell.org/package/proteaaudio-0.6.5/src/cbits/include/asio.cpp
17:07:33 <fen> anyway nvm that, maybe another time
17:10:14 <fen> oh yeah, there was another question about android haskell, which is that if the openGL bindings have their own shader drivers, that this seems incompatible with android
17:11:05 <fen> so that there would either need to be a different backend for the main graphics interfaces like juicy, or else, something like making openGL run on android
17:11:18 <fen> cant understand which is more onerous a task!
17:12:26 <Solonarv> fen: https://gist.github.com/Solonarv/3c023fa7de9b0ca38781bd96943a11ee
17:12:30 <fen> thanks!
17:13:57 <fen> hmm that seems backwards from the way it is installed 
17:13:59 <fen> C:\MinGW\msys
17:14:12 <fen> instead of C:\msys64\mingw64.exe
17:14:38 <fen> oh is msys2 something totally different
17:14:45 <fen> hmm, that could be helpful
17:15:59 <Solonarv> they're sort of related but not the same thing, not sure exactly tbh
17:16:47 * hackage comprehensions-ghc 0.1.0.1 - Plugin to generalize comprehensions  https://hackage.haskell.org/package/comprehensions-ghc-0.1.0.1 (MatthewFarkasDyck)
17:18:09 <fen> anyway, there did not seem to be a way to remove latency between recording and playthrough without getting buffer overflows
17:18:14 <MarcelineVQ> adamCS: closest I can figure on getting the constraints https://gist.github.com/MarcelineVQ/3779d979ed8a0f044d30bcf3e777b0b9 seemed to worked in a small test
17:18:49 <Solonarv> oh crap, my 'cabal v2-repl sdl2' experiment is building lens
17:18:56 <Solonarv> no wonder my laptop is so sluggish ;)
17:19:00 <fen> is that something haskell could help with or is it always going to be limited by what the C backend can do?
17:21:47 <fen> oh so thats just uncommenting one line of the .ini file
17:21:53 <fen> easy when you know how!
17:22:31 <MarcelineVQ> adamCS: it's weird looking but (t m) should always be a Monad since t's are things like SerialT so it should be ok
17:23:50 <fen> ooh and this version comes with pacman!
17:24:15 <fen> pretty useless when there isnt even an apt-get with the distribution...
17:24:39 <Solonarv> yep yep, pacman is how you get pkg-config and the packages themselves (e.g.SDL2)
17:26:38 <Solonarv> updated my gist with a bit of extra info
17:27:59 <jackdk> I am using lens-pandoc and have constructed the following `Traversal'` to look at all the tables in a document: `body . traverse . _Table :: Traversal' Pandoc (args-to-table-ctor)`. I want to make a traversal that picks out the nth table in the document, but I'm not sure how to do this.
17:28:28 <jackdk> Is there a combinator that turns a traversal into a lens over a list, that I could then compose with `ix`?
17:31:03 <Solonarv> I think there is one, let me see if I can find it
17:31:37 <jackdk> Solonarv: I have found `elementOf (body . traverse . _Table) n`, which seems to do what I want. Is that what you had in mind?
17:31:41 <c_wraith> partsOf?
17:31:55 <jackdk> It doesn't do the "lift into list" thing, which would be cool to know about
17:32:05 <Solonarv> partsOf is what you want, I think
17:32:57 <Solonarv> we can pretend that partsOf :: Traversal' s a -> Lens s [a]
17:33:02 <c_wraith> it... converts a Traversal to a Lens over a list. isn't that what you asked for?
17:33:03 <Solonarv> er, Lens*
17:33:56 <jackdk> yeah, `partsOf (body . traverse . _Table)` solves the question-as-asked, and works with `ix`. Is it better/worse than `elementOf` here?
17:34:23 <Solonarv> oh, damn - I'd definitely use elementOf here
17:34:40 <Solonarv> hadn't even looked at that yet - it's exactly what you were looking for
17:35:27 <adamCS> MarcelineVQ:  Ah!  That's confusing but also makes sense.  Thanks!
17:35:49 <jackdk> thank you both for your help Solonarv c_wraith
17:50:19 <fen> huh, its installing
17:50:21 <fen> awesome
17:50:30 <fen> so what cool things can we do with SDL?
17:51:54 <Solonarv> windowing (e.g. "give me a 640x480 window I can draw graphics in"), getting an OpenGL context, simple 2D drawing, input handling
17:51:58 <Solonarv> just off the top of my head
17:52:08 <Solonarv> if you add in SDL2_ttf you get text rendering too
17:52:26 <Solonarv> SDL2_mixer for fancier sound
17:53:04 <fen> an OpenGL context?
17:53:15 <fen> usially just gloss and glut are working ok
17:53:26 <fen> where does SDL enter the picture?
17:54:44 <Solonarv> SDL lets you say "give me a window with such-and-such properties, now let me draw on it with OpenGL and get out of the way"
17:54:56 <fen> oh right, it just has an opengl backend for its graphics stuff
17:55:11 <Solonarv> has other backends too I think, but I haven't really looked into those
17:55:38 <fen> so how is that better than just the window that openGL opens up?
17:55:48 <Solonarv> I've barely even looked into the OpenGL backend, tbh - using OpenGL directly from Haskell makes me want to tear my hair out
17:55:52 <fen> is it some kind of interface for adding drop down menues and stuff?
17:56:14 <fen> well no, not directly, but juicy provides a nice api
17:56:30 <Solonarv> ah, I'll have to try that at some point
17:56:53 <Solonarv> I mean honestly just look through the SDL2 haddocks to see what you can do with it
17:57:05 <Solonarv> I certainly don't know everything off hand
17:57:32 <MarcelineVQ> opengl doesn't open up windows
17:57:51 <fen> wait, not juicypixles
17:58:47 <fen> gloss
17:58:57 <fen> gloss simulate is a good interface
17:59:25 <fen> MarcelineVQ: well it certainly opens up *a* window
17:59:38 <fen> just wondering what the SDL thing is for
18:00:13 <fen> normally just can get keyboard and mouse to interact with a scene using the gloss interface to opengl 
18:00:30 <fen> which if you were doing on android might create problems
18:00:43 <int-e> SDL provides simple access to audio and graphics, input and time, in a fairly platform-neutral way.
18:00:47 * hackage liquidhaskell-cabal 0.2.0.0 - Liquid Haskell integration for Cabal and Stack  https://hackage.haskell.org/package/liquidhaskell-cabal-0.2.0.0 (MichaelSmith)
18:01:24 <int-e> "Simple DirectMedia Layer"
18:01:49 <fen> maybe there is a way to use it with a different backend such as a custom patching to some small set of android utilities
18:02:03 <fen> like draw to screen, tilt, swipe etc
18:02:23 <fen> but only as many as you would want to have to try and write by hand in java *shudders*
18:03:19 <fen> there must be some really simple api for mirroring through these basic things
18:04:35 <Solonarv> SDL tries to do that
18:05:06 <Solonarv> the graphics and audio stuff should Just Work, I think (assuming you get the cross-compiling working)
18:05:26 <fen> what, its so cross platform as to work on android!?
18:05:35 <fen> opengl too?
18:05:50 <fen> wow that would be really awesome 
18:06:06 <Solonarv> yes, SDL is *very* cross-platform
18:07:47 <fen> so how do you compile it using ghcjs for importing into android studio?
18:08:13 <Solonarv> no ghcjs needed, you can compile to native code IIRC
18:08:23 <Solonarv> I have no experience with that though, just repeating what Cale said a while ago
18:08:38 <fen> not sure what it is "native code"
18:08:47 * hackage liquidhaskell-cabal-demo 0.2.0.0 - Demo of Liquid Haskell integration for Cabal and stack  https://hackage.haskell.org/package/liquidhaskell-cabal-demo-0.2.0.0 (MichaelSmith)
18:08:48 <fen> thought it had to be included as a .jar 
18:09:27 <Solonarv> android lets you run native code via JNI (Java Native Interface)
18:09:50 <fen> Cale mentioned; https://github.com/obsidiansystems/obelisk#android
18:10:47 <Solonarv> ah, nice
18:11:19 <fen> nix!?
18:11:29 <fen> damn gona have to get virtualbox on the go
18:11:46 <fen> there is a tarball here; https://www.oracle.com/technetwork/server-storage/virtualbox/downloads/index.html
18:12:01 <fen> cant we get that source code and convert it to haskell?
18:12:28 <fen> its open source right?
18:12:44 <fen> then we could do cabal install virtualbox
18:12:47 <Cale> You shouldn't need virtualbox to run nix -- you only need the package manager, not the whole OS
18:13:12 <Cale> also, the setup will install nix for you if you don't have it
18:13:19 <Cale> so there's no need to install it separately
18:13:54 <fen> in mingw64 on windows?
18:14:26 <Cale> Yeah, that's a windows thing
18:15:24 <Cale> I'm not sure whether any of our stuff will run on Windows.
18:17:02 <Cale> Heh, in that case, maybe you *do* need VirtualBox, or perhaps just another partition on which you can run Linux
18:17:23 <fen_> yeah, that was the point
18:17:42 <fen_> but then your saying you wouldnt use NixOS as the linux distro?
18:17:53 <Cale> Well, you certainly can -- many of my coworkers do
18:18:03 <Cale> Personally, I prefer Linux Mint for my desktop
18:18:14 <Cale> You can really use any Linux, or even MacOS
18:18:23 <fen_> it should be under a few Mbs
18:18:29 <fen_> and run on Ghci
18:18:32 <fen_> !!
18:18:44 <Cale> What should be?
18:18:48 <fen_> why cant we run Halvm instead of virtual box?
18:19:04 <MarcelineVQ> are you drinkin :>
18:19:41 <fen_> the C source is available, we should just compile it to haskell and have a haskell virtualbox and be done with it
18:20:08 <fen_> and slowly refactor it into something less scrapyardy
18:20:43 <Clint> compile it to haskell
18:20:55 <fen_> exactly
18:21:04 <Cale> What do you mean "compile it to Haskell"? With the C -> Haskell compiler that nobody's ever going to write?
18:21:40 <fen_> well i guess using fir is out of the question
18:22:29 <fen_> Cale: sure they will, save all this crazy FFI stuff
18:22:58 <fen_> only the absolute minimal C code should under haskell, just for the basic memory management 
18:23:04 <fen_> not whole libraries
18:28:54 <fen_> so is there a hello world app for obelisk ?
18:29:17 <Cale> It comes with one
18:29:43 <Cale> When you ob init, there will be a skeleton app which doesn't do quite as much as it probably ought to, but it's something
18:30:27 <fen_> nix-env -f https://github.com/obsidiansystems/obelisk/archive/master.tar.gz -iA command
18:30:39 <fen_> that?
18:30:46 <fen_> ob init?
18:30:51 <Cale> Well, that should install the ob command
18:31:36 <Cale> and then you should be able to go into an empty directory and run "ob init"
18:32:39 <Cale> and then you can try "ob run"
18:33:27 <Cale> It'll download a bunch of stuff the first time, and if all goes well, you should end up with a running webserver with the skeleton app in it.
18:34:05 <Cale> (which is basically just a "Hello World" without that string in it)
18:34:20 <fen_> yeah but how do you get that into an .apk
18:34:47 <fen_> thats when you need to crosscompile right?
18:34:57 <Cale> https://github.com/obsidiansystems/obelisk/#android -- there are instructions here
18:35:15 <Cale> You'll have to set some android-specific values in the default.nix file which was generated for your project
18:35:26 <fen_> ah thats when you do that
18:35:39 <fen_> but, where is the hello world app located to change this?
18:36:33 <fen_> hang on, you dont need android studio at all!?
18:36:34 <Cale> In whatever directory you ran ob init from
18:36:46 <Cale> That's... what I've been telling you repeatedly
18:37:13 <fen_> well, there was a "no you dont need to make an import java library or jar"
18:37:34 <fen_> but still thought it would have to go through the android dev kit
18:37:50 <fen_> so, it uses gradle directly?
18:39:28 <Cale> Yeah, I think that's right.
18:39:48 <Cale> Some sort of maven... gradle shenanigans
18:39:53 <Cale> I don't often have to think about it
18:40:22 <fen_> haha
18:40:24 <fen_> awesome
18:40:34 <fen_> this is a really great tool
18:41:38 <fen_> and, just judging by how long virtual-box is taking to install oblelisk, it might not be any slower to actually run it on a phone!
18:41:48 <Cale> hahaha
18:42:33 <Cale> Yeah, I'd recommend just actually having a linux machine if you're going to really go at it... the actual final deployment compile times can be a bit brutal even without the VM
18:42:48 <fen_> but this can compile itself to run on android no?
18:42:50 <Cale> But thankfully, "ob run" usually gives you a close enough approximation to how the app works
18:43:05 <Cale> No, the compiler itself won't run on Android
18:43:21 <fen_> because it needs the nix package manager?
18:43:55 <Cale> Well, for one, getting nix to run on Android would be pretty huge, but then also just running GHC at all sounds kind of absurd to me. Maybe it's theoretically doable.
18:44:13 <fen_> oh it needs ghc as well
18:44:33 <Cale> Well, ghc is the Haskell compiler you're using
18:44:38 <Cale> if you're using this :)
18:44:39 <fen_> as said before, there is a version of debian which runs as an app on android available from the play store
18:44:45 <fen_> and ghci works on it
18:44:52 <Cale> Also, ghcjs for building javascript for the web version
18:44:55 <fen_> ok, wait let me check if ghc does
18:45:17 <fen_> thought that open-gl on android would just not work, but it might be worth checking 1 sec
18:46:49 <Cale> anyway, I've got to run to the store, be back shortly
18:47:03 <fen_> so how does obelisk manage to have a hardware interface?
18:47:09 <fen_> damn...
18:49:01 <siraben> Here's a weird problem I'm seeing: when I pipe http://ix.io/1FI2 to http://ix.io/1FI1 I get http://ix.io/1FI3 but then the evaluator on Codeforces sees http://ix.io/1FI4 as the output
18:50:40 <siraben> I'm on NixOS if that matters
18:50:52 <siraben> The B.append function seems to truncate the string by one byte
18:54:20 <pavonia> I'd rather think B.getLine is different on the two systems, one might also take the '\n' into account
18:55:26 <siraben> pavonia: what output do you get on your end?
18:58:41 <pavonia> siraben: The version without the final letter (on a Windows system)
18:59:43 <fen_> nix wont install on gnu-root debien "sh: sorry there is no binary distribution of Nix for your platform
18:59:57 <fen_> dont much want to build it from source on the phone either...
19:00:35 <pavonia> siraben: It's actually different if I convert the input file to Windows newline style
19:06:20 <pavonia> siraben: When you look at http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/src/Data.ByteString.html#hGetLine it does indeed only look for '\n's and ignores extra '\r's that are also part of the endline marker on Windows
19:07:00 <fen_> ghc works on the phone but cabal doesnt! abandoning project!
19:08:55 <fen_> well if oblelisk can compile to .apk then it should be able to make a better working version of debien or nixos that runs on android
19:11:25 <fen_> or a haskell version of virtualbox :D
19:12:05 <fen_> wait actually, if we can link it with ffi does that mean that it can be compiled to android this way?
19:13:09 <fen_> like, we have vlc: https://github.com/mplamann/vlc-hs
19:15:38 <siraben> pavonia:  I see.
19:15:43 <siraben> So I should probably use something like lines
19:18:47 <pavonia> > lines "foo\nbar\r\nbaz"
19:18:49 <lambdabot>  ["foo","bar\r","baz"]
19:19:00 <siraben> I changed it to "replicateM n (head <$> B.words <$> B.getLine)"
19:19:13 <siraben> There should be a better way
19:20:40 <fen_> whats this? https://hackage.haskell.org/package/hnix
19:20:47 <fen_> its not a linux is it?
19:21:56 <fen_> do we have any ffi bindings to linux source?
19:22:51 <siraben> fen_:  do you mean what's hnix or what's Nix?
19:23:13 <siraben> fen_:  https://nixos.org/nix/
19:23:14 <fen_> well it doesnt seem to be nixos bindings which is whats needed
19:23:54 <fen_> there are all these prerequisites; https://nixos.org/nix/manual/#sec-prerequisites-source
19:24:07 <fen_> not sure those would all need ffi bindings or what
19:25:26 <fen_> what we really need is a C to haskell compiler!!
19:26:42 <maerwald> fen_: why?
19:26:54 <maerwald> now you have the same library twice on your system :o
19:26:58 <fen_> to compile all those nixos prerequisites 
19:27:12 <maerwald> and although they are the same code, they may behave totally different
19:27:15 <pavonia> siraben: This issue seems to have been open for 5 years now https://github.com/haskell/bytestring/issues/13 :(
19:27:17 <fen_> what?
19:27:39 <fen_> how else are we going to get a linux in haskell?
19:27:46 <maerwald> why would you do that?
19:27:57 <fen_> to compile it to android
19:28:06 <fen_> to get a linux on android to run ghc on
19:28:21 <fen_> and to run the haskell to apk compiler
19:28:30 <fen_> to get a native android haskell compiler
19:29:32 <fen_> on which you could compile new linuxes for android on!
19:30:43 <fen_> and if we had the first step, the C to haskell compiler, originally for use in compiling a linux to haskell
19:30:54 <fen_> we could also compile anything else to haskell, and then to android!
19:31:20 <fen_> it would give a rout to running FOSS stuff written in C on android via haskell
19:33:22 <fen_> maerwald: twice? no its not compiling to C its using ghcjs
19:33:41 <fen_> or something... idk how obelisk works...
19:34:09 <fen_> anyway it returns an .apk apparently, so no not just another C lib
19:34:39 <fen_> maybe there is a more direct way to link c libraries, but its a haskell tool, so maybe not
19:35:09 <fen_> well, thats just ffi
19:35:20 <fen_> but the point is that could be avoided by direct compilation
19:35:28 <fen_> it would give more readable source code
19:35:36 <fen_> (if it could be refactored nicely)
19:38:31 <fen_> like the main point is that nothing except the most essential memory access code that ghc uses should actually remain in C, and everything else could be better written in haskell
19:38:34 <fen_> probably...
19:38:43 <fen_> well, it would make it legible at least
19:39:17 <tsizz_> hi to define arbitrary types in a list for a functio
19:39:24 <tsizz_> do i do function: [a] -> [a]
19:39:54 <fen_> :t map
19:39:55 <lambdabot> (a -> b) -> [a] -> [b]
19:40:06 <fen_> > map (+1) [1,2,3]
19:40:08 <lambdabot>  [2,3,4]
19:40:20 <fen_> does that help tsizz_ ?
19:41:13 <tsizz_> fen_: but a and b are same type ?
19:41:17 * hackage cairo-core 1.16.7 - Cairo Haskell binding (partial)  https://hackage.haskell.org/package/cairo-core-1.16.7 (magicloud)
19:41:21 <tsizz_> can it just be a->a -> [a] -> [a]
19:41:24 <fen_> Cale: the tests for happy take ages and they fail
19:41:42 <fen_> :t map (+1) 
19:41:43 <lambdabot> Num b => [b] -> [b]
19:41:48 <fen_> :t map (show) 
19:41:50 <lambdabot> Show a => [a] -> [String]
19:42:05 <fen_> not necessarily, just in that case
19:42:45 <tsizz_> mhm okay 
19:42:47 <fen_> :t map :: (a->a) -> [a] -> [a]
19:42:48 <lambdabot> (a -> a) -> [a] -> [a]
19:42:57 <tsizz_> hm if i take list as input
19:43:01 <tsizz_> do i just do function [a]
19:43:03 <tsizz_> =
19:43:19 <fen_> can you try writing actual haskell syntax?
19:43:31 <tsizz_> yeah lol sorry im just rushing to finish this assingment ill try it
19:45:23 <fen_> Cale: it did not work! 
19:45:52 <Cale> fen_: Where did you get stuck?
19:46:06 <fen_> it did not complete
19:46:19 <fen_> nix-env -f https://github.com/obsidiansystems/obelisk/archive/master.tar.gz -iA command
19:46:23 <Cale> ah
19:46:24 <Cale> hmm
19:46:26 <fen_> the happy tests failed
19:46:36 <Cale> Well, that's pretty spurious seeming
19:46:46 <Cale> Wait, is it compiling stuff?
19:47:02 <fen_> yeah it installs basically everything but it fails on happy every time
19:47:10 <Cale> It shouldn't need to even compile anything, it should just download a bunch of already-cached stuff
19:47:19 <Cale> Unless you're on a weird architecture or OS
19:47:33 <fen_> its nixos on virtualbox
19:47:36 <Cale> You're on Linux inside a VM? hmm
19:47:57 <Cale> Did you set up the caches?
19:47:59 <fen_> the "virtualbox applience" from here; https://nixos.org/nixos/download.html
19:48:12 <fen_> what caches?
19:48:26 <Cale> https://github.com/obsidiansystems/obelisk/#installing-obelisk
19:48:37 <Cale> Follow the steps :)
19:48:57 <fen_> oh i skipped those steps because i couldnt read them
19:49:07 <fen_> maybe they were important for something, ill try again
19:50:27 <Cale> (though, the caches alone don't seem like they should be able to account for that)
19:50:58 <fen_> yah, well if you have a stable tested thing should at least follow the instructions
19:52:59 <Cale> At the very least, it should save a whole bunch of time -- nothing should need to compile if it's working correctly
20:03:19 <fen_> nope that didnt seem to help
20:06:55 <fen_> ok lets try with linux mint
21:05:17 * hackage shh 0.3.1.1 - Simple shell scripting from Haskell  https://hackage.haskell.org/package/shh-0.3.1.1 (lukec)
21:07:15 <kadoban> luke-clifton[m]: In the description of ^ , missing a verb in "It helps you all external binaries"
21:25:26 <fen_> Cale: well, on linux thats not nixos, the nix.conf file seems to be nowhere to be found
21:25:44 <fen_> so how to add these flags to it seems impossible
21:32:47 * hackage cmark-gfm 0.2.0 - Fast, accurate GitHub Flavored Markdown parser and renderer  https://hackage.haskell.org/package/cmark-gfm-0.2.0 (kivikakk)
21:41:17 * hackage shellmet 0.0.1 - Out of the shell solution for scripting in Haskell  https://hackage.haskell.org/package/shellmet-0.0.1 (shersh)
21:48:47 * hackage failable 1.2.1.0 - A 'Failable' error monad class to unify failure across monads that can fail  https://hackage.haskell.org/package/failable-1.2.1.0 (erick)
22:00:47 * hackage failable 1.2.2.0 - A 'Failable' error monad class to unify failure across monads that can fail  https://hackage.haskell.org/package/failable-1.2.2.0 (erick)
22:02:00 <fen_> oh right, you can just create the nix.conf file in /etc/nix if it does not exist and then it will search there
22:14:39 <fen_> then; https://github.com/obsidiansystems/obelisk/blob/develop/skeleton/default.nix
22:14:42 <fen_> on line 9
22:15:13 <fen_> uncommenting and setting to true, the acceptance of the android licence as indicated, gives the error;
22:16:07 <fen_> anonymous function at .... called with unexpected argument "config" ...
22:16:49 <fen_> when editing the default.nix file of the package created by ob init
22:21:28 <fen_> Cale: ^
22:41:22 <mathlover2> Has anyone tried writing neural network implementations in Haskell?
22:42:36 <mathlover2> And if so, are any particularly good?
22:52:57 <mathlover2> I looked up a package for neural networks called HNN. Any thoughts?
22:58:20 <jackdk> HNN........
22:58:26 <jackdk> no, sorry
22:58:45 <mathlover2> Any experience with neural networks in Haskell?
22:59:14 <jackdk> No, but I am aware of a library called "grenade", which does some cool type-level stuff to ensure things get put together sensibly. But I've never used it and I don't know what its perf is like
23:00:35 <mathlover2> Found it, jackdk.
23:11:04 <mathlover2> I looked up grenade. It may be suitable for my purposes.
23:11:36 <mathlover2> Anything done in haskell with topological data analysis?
23:14:39 <merijn> mathlover2: Someone has *probably* done some stuff along those lines, but no clue if there's anything polished/finished around
