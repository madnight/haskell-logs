00:00:02 <Twey> pharaun: But you can't guarantee that it won't (indirectly).  Once you're out into the big wide impure world, all bets are off.
00:00:18 <Twey> 'bye, Kron!
00:00:21 <colluphid> when your'e in a monad to you 'get out' by preforming some sort of lift function?
00:00:26 <mm_freak> bye Kron =)
00:00:28 <Twey> donri: No
00:00:35 <Twey> donri: STRefs can be re-used within the same ST region
00:01:01 <Twey> And the value in them can be re-read as many times as you like; there's no way to ‘invalidate’ a single STRef
00:01:03 <mm_freak> pharaun: i was mainly talking about region-based I/O
00:01:03 <Kaidelong> colluphid: lifting is more for getting things into the context... how you make values in a context into a pure value depends on the monad
00:01:28 <Kaidelong> and not all of them actually can do that... [], Maybe, and IO for example
00:01:33 <mm_freak> Twey: there is actually
00:01:35 <dolio> donri: You can view ST as managing a linearly typed heap behind the scenes. And STRefs point at a location in that implicit heap.
00:01:39 <Twey> donri: C++'s unique_ptr is a better analogy, though there's no compile-time checking
00:01:44 <Twey> mm_freak: There is
00:01:45 <Twey> ?
00:01:55 <mm_freak> Twey: ever tried to return an STRef from an ST computation?
00:02:22 <Twey> Oh, yes… but within the computation, there isn't.  You can invalidate the whole region, but not just the one reference.
00:02:34 <Kaidelong> although you can do things that are close like substituting a default value for Nothing
00:02:39 <Kaidelong> or folding a list
00:02:41 <dolio> For ST it actually makes some sense. Just not for IO.
00:02:42 <mm_freak> Twey: that's an interface choice…  you can very well invalidate stuff as you go
00:02:42 <Twey> So long as you have that type parameter, you have unlimited access to everything it controls
00:02:51 <Twey> Hrm, yes
00:02:56 <Twey> Has nobody done that?
00:03:09 <mm_freak> Twey: of course…  i mention region-based I/O again =)
00:03:15 <Twey> Ah, right :þ
00:03:20 <Kaidelong> but generally you use things like lift to do your calculations inside the context, rather than trying to get values out of it
00:03:34 <Kaidelong> and with IO, that is all you're allowed to do
00:03:34 <mm_freak> Twey: and i do it all the time with some static information passed on the type level
00:03:49 <Twey> That's a nice idea
00:03:52 <mm_freak> Twey: you can't mix stuff up, and you can't use it, when it's no longer valid
00:03:58 <colluphid> Kaidelong: is there a way to pull a value out of a Maybe monad?
00:04:12 <Twey> colluphid: ‘maybe’
00:04:14 <Kaidelong> no, no total way
00:04:15 <Twey> :t maybe
00:04:16 <lambdabot> b -> (a -> b) -> Maybe a -> b
00:04:31 <Kaidelong> but you can sort of do it if you give a default value
00:04:46 <Twey> And pattern-matching, of course
00:04:56 <mm_freak> lambdabot: buddy?
00:04:56 <mm_freak> @botsnack
00:04:56 <lambdabot> :)
00:04:57 <donri> :t fold `asAppliedTo` Just 5
00:04:58 <lambdabot> (Num b, Monoid b) => Maybe b -> b
00:05:11 <colluphid> or do you just 'lift' the other operations so everything is in the same context?
00:05:35 <mm_freak> colluphid: Maybe is a monad
00:05:45 <mm_freak> > do x <- Just 3; y <- Just 4; return (x + y)
00:05:46 <lambdabot>   Just 7
00:05:49 <Kaidelong> that's generally what you want to do, because unwrapping and rewrapping into the same context is kind of a waste
00:05:53 <Twey> colluphid: You can extract the value from a Maybe through the usual mechanisms
00:06:21 <Kaidelong> it's also more convenient than having to account for "what if it is empty?"
00:06:44 <Kaidelong> \Just x -> f x can fail but fmap f never will
00:07:03 <donri> :t liftA2 (+) `asAppliedTo` Just 3
00:07:04 <lambdabot> Num c => Maybe c -> Maybe c -> Maybe c
00:07:22 <Kaidelong> because you preserve the context your input was in
00:07:26 <pharaun> mm_freak: looks like i need to look up exactly what region-based i/o is
00:07:49 <donri> pharaun: http://okmij.org/ftp/Computation/resource-aware-prog/region-io.pdf
00:07:53 <Kaidelong> pharaun: I'm sure you gathered this already, but it's a way to statically manage memory
00:08:08 <Kaidelong> by determining in advance where to allocate and where to deallocate
00:08:21 <donri> pharaun: or if papers scare you, slides! http://www.cs.rutgers.edu/~ccshan/capability/region-io-talk.pdf
00:08:27 <mm_freak> s/memory/resources/
00:08:28 <colluphid> Kaidelong: thanks for the help
00:08:33 <Twey> Oleg papers scare me
00:08:35 <Sgeo> Does map id someList have any runtime cost, or does the compiler somehow know that it's id? Reason I ask is the discussion about new GHC mentioned something about eliminating runtime cost of similar things with newtype constructors
00:08:49 <donri> Twey: :) but the regions paper is straight forward i think
00:08:50 <pharaun> donri: depends :) i like both :) i find slides usually are too sparse on details but they can serve as a great warming up aid
00:09:04 <Twey> Sgeo: It could have runtime costs
00:09:05 <donri> pharaun: agreed
00:09:05 <Kaidelong> there no rewrite rule to turn fmap id into id?
00:09:25 <Kaidelong> it's a functor law so there really should be
00:09:27 <donri> Kaidelong: i don't think there's any rewrite rules for fmap in general no
00:09:38 <Twey> Kaidelong: That won't work for ‘map’, though
00:09:49 <pharaun> thanks :)
00:10:07 <Twey> That would lead to some very confusing bugs if your functor didn't obey the laws, though
00:10:27 <Kaidelong> I thought that was why you had to make sure your functor obeyed the laws
00:10:36 <Twey> Heh
00:10:36 <Kaidelong> because the compiler and other people are allowed to assume it does
00:10:56 <donri> @check \xs -> fmap id xs == xs && map id xs == xs && id xs == xs
00:11:02 <lambdabot>   +++ OK, passed 100 tests.
00:11:03 <Twey> Other people yes, but I don't think the compiler is allowed to
00:11:18 <donri> Twey: how does map break this?
00:11:31 <ion> @check \xs -> fmap id xs == reverse xs
00:11:35 <lambdabot>   +++ OK, passed 100 tests.
00:11:40 <Twey> donri: It doesn't; I just meant that a rewrite rule for fmap wouldn't apply to map
00:11:49 <donri> ion: wait wat
00:11:52 <pharaun> oh whoa i didn't know lambdabot could do @check
00:11:56 <donri> Twey: ah
00:11:58 <Twey> Haha
00:12:19 <donri> :t revers
00:12:20 <lambdabot>     Not in scope: `revers'
00:12:20 <lambdabot>     Perhaps you meant one of these:
00:12:20 <lambdabot>       `reverse' (imported from Data.List),
00:12:20 <donri> :t reverse
00:12:21 <lambdabot> [a] -> [a]
00:12:24 <Twey> donri: It's defaulting to [()]
00:12:26 <Kaidelong> quickcheck must have used [()]
00:12:28 <Kaidelong> yeah
00:12:31 <donri> oh, duh.
00:13:12 <Kaidelong> there really should be a better default than ()
00:13:15 <Twey> Hmph.  Now I have to find something to do while GHC 7.7 compiles.
00:13:16 <donri> couldn't it be smarter about that and say "passed 2 tests"
00:13:21 <Kaidelong> perhaps a trivial non-commutative monoid
00:13:26 <Twey> donri: It didn't pass 2 tests
00:13:42 <donri> Twey: well the Gen only generated two cases no?
00:13:46 <donri> [] and [()]
00:13:52 <Twey> [] == reverse [], [()] == reverse [()], [(), ()] == reverse [(), ()] …
00:13:57 <ion> and [(),()] and
00:14:00 <donri> oh, duh
00:14:12 <donri> why am I in #haskell pre-morning-coffee
00:14:15 <Twey> Hehe
00:14:27 <Twey> Why are you even up so early?  :þ
00:14:37 <donri> good question
00:14:49 * hackagebot http-streams 0.7.0.2 - An HTTP client using io-streams  http://hackage.haskell.org/package/http-streams-0.7.0.2 (AndrewCowie)
00:14:49 * hackagebot monoid-extras 0.3.2.3 - Various extra monoid-related definitions and utilities  http://hackage.haskell.org/package/monoid-extras-0.3.2.3 (BrentYorgey)
00:16:47 <Twey> Kaidelong: A non-commutative monoid would break the monoid laws :þ
00:16:57 <Twey> … never mind
00:16:58 <donri> Twey: no?
00:17:01 <Twey> It's early here too >.>
00:17:08 <donri> you're thinking of abelian groups or something :)
00:17:19 <Twey> No, I just mixed up commutativity and associativity.
00:17:28 <donri> yeah
00:17:28 <Kaidelong> you can have an abelian monoid too
00:17:30 <Twey> Something I *still* do regularly, for some reason.
00:17:43 <Kaidelong> and all abelian groups are also abelian monoids, woo
00:17:53 <donri> Kaidelong: isn't that just called commutative monoid
00:18:06 <Kaidelong> I think wiki said it's all good
00:18:17 <Kaidelong> people have been caught saying both
00:18:26 <Kaidelong> and no one really cares
00:18:38 <Twey> « A monoid whose operation is commutative is called a commutative monoid (or, less commonly, an abelian monoid). »
00:18:39 <donri> not sure why i didn't claim Twey was thinking of, more obviously, commutative monoids
00:18:54 <donri> "a non-commutative commutative monoid would break the commutativity law" :P
00:19:03 <Twey> Yes.  Yes it would.
00:19:07 <donri> :D
00:20:02 <donri> hm i wonder what a commutative category is... an isomorphism?
00:21:09 <johnw> 1 would be a commutative category :)
00:21:18 <johnw> as would 2
00:21:20 <Kaidelong> I guess it has to be, because it could only be a monoid
00:21:37 <Kaidelong> due to how composition works
00:21:39 <donri> Kaidelong: isn't that an endomorphism, rather
00:21:43 <donri> uuh
00:21:46 <Twey> Undirected graphs are a commutative category… the morphism would be an isomorphism, I guess
00:21:58 <Twey> … wait, no
00:22:32 <Kaidelong> a -> b   b -> c... commute them and you wind up matching a -> c... which is okay if there is only one object in the category
00:22:40 <Kaidelong> a and c I meant
00:23:38 <Kaidelong> although I guess you could make a commutative definition specifically for categories which requires each morphism a -> b has a corresponding morphism b -> a
00:23:44 <Kaidelong> I think that is a thing and it is called a groupoid
00:24:19 <Kaidelong> because of the analogy to groups as all functions have inverses such that a -> b o b -> a == id
00:24:26 <Kaidelong> all morphisms, I meant
00:25:41 <Kaidelong> yeah it is a groupoid
00:25:59 <donri> i'm not sure it makes sense to speak of "commutative" categories though
00:26:02 <Kaidelong> but apparently groupoid has multiple definitions and the definition of groupoid as a restricted category isn't the only one
00:26:20 <Kaidelong> the only way I could imagine it making sense, it'd be what you call a groupoid anyway
00:26:25 <Kaidelong> so I'll agree with that
00:26:48 <Kaidelong> except in the other sense, monoids are commutative categories
00:26:59 <donri> oh dear
00:27:33 <Kaidelong> or a category restricted to two objects, that would work too
00:27:56 <Kaidelong> because all morphisms have the form either a -> b or b -> a and those can be commuted in composition
00:29:52 <johnw> actually, I don't think the two object category works
00:29:54 <iamtakingiteasy> hmm... is it possible to write in haskell way (like, defining what things are) without comprehensive understanding of problem you're trying to solve?
00:29:58 <Kaidelong> oh that would still require the two objects to be isomorphic to one another
00:30:03 <johnw> dom(f . g) /= dom(g . f)
00:30:06 <Kaidelong> yeah
00:30:13 <Kaidelong> so you'd need a == relationship between the two
00:30:17 <johnw> but the one object category works
00:30:21 <iamtakingiteasy> like, it is possible on C or Java to understand the problem while trying to write a solution
00:30:21 <Kaidelong> to get the commutativity out of it
00:30:47 <iamtakingiteasy> but hardness of haskell' debugging and logging makes it is quite a bit harder than there
00:30:48 <donri> iamtakingiteasy: i would say haskell is particularly good for that
00:31:11 <donri> well you do need to know *haskell*, even if you don't fully understand the problem at hand :)
00:31:21 <iamtakingiteasy> hmm
00:31:54 <iamtakingiteasy> then how is debugging and tracing logging is done in haskell?
00:31:58 <Kaidelong> I actually never understood why people think haskell is bad for debugging, but that might be because I tend to debug things through reasoning on paper and sleeping on it rather than say, dumping what's in memory at the time of the bug
00:32:10 <donri> iamtakingiteasy: there's Debug.Trace though i never use it myself
00:32:19 <johnw> i use debug.trace pretty often
00:32:46 <Kaidelong> there's a really cool debugging library that I never used for actual debugging I'm trying to remember the ... Hood!
00:33:00 <Kaidelong> hood is a nice tool, it lets you watch how data structures change
00:33:12 <iamtakingiteasy> it is capable of embedding into pure constructs (making them this inpure, but letting you to see the flow of your program) ?
00:33:16 <johnw> Hat is pretty nice too
00:33:22 <iamtakingiteasy> impure*
00:33:23 <johnw> and works with 7.6.3
00:33:30 <donri> iamtakingiteasy: yes
00:33:36 <iamtakingiteasy> nice, thank you
00:33:38 <donri> iamtakingiteasy: http://hackage.haskell.org/package/base-4.6.0.1/docs/Debug-Trace.html
00:34:38 <donri> iamtakingiteasy: not that these side-step purity
00:34:53 <Kaidelong> actually they could if you pipe the output to a file
00:35:05 <Kaidelong> </nitpick>
00:35:09 <donri> ?
00:35:14 <Twey> iamtakingiteasy: Quite often, if you define your data structures right, the algorithm becomes obvious.
00:35:33 <Kaidelong> oh wait
00:35:47 <Kaidelong> that might not work because the file has to be opened for writing until the process ends
00:36:27 <Kaidelong> donri: most command shells can redirect output from stderr and stdout
00:36:44 <iamtakingiteasy> Twey: yeah, but finding the right data structures often requires lots of experiments on possible ways to represent the data or other kinds of getting experience
00:37:47 <frx> if you could rewrite length, what type would it return? Integer? Num? or still Int?
00:37:59 <Kaidelong> Nat ;.;
00:38:13 <Kaidelong> Integer I guess
00:38:23 <Kaidelong> actually, why return Integer
00:38:28 <Kaidelong> return (Integral t) => t
00:39:19 <frx> yeah I don't know why I mentioned Integer, so Int vs Num? if it was written all over again, would we just have length returning Num? instead of length and genericLength
00:40:30 <Kaidelong> better to return an Integral instance than a Num instance
00:40:48 <Kaidelong> @ty genericLength
00:40:49 <lambdabot> Num i => [b] -> i
00:41:24 <frx> with a Num you can avoid fromIntegral calls when you use the result as something other than Int/Integer
00:42:18 <frx> for example
00:42:20 <frx> > genericLength "foo" / 2
00:42:21 <lambdabot>   1.5
00:42:25 <frx> > length "foo" / 2
00:42:26 <lambdabot>   No instance for (GHC.Real.Fractional GHC.Types.Int)
00:42:27 <lambdabot>    arising from a use o...
00:44:10 <frx> so to rephrase my question, would length (and things like length) ideally return a generic Num?  but don't for historical reasons
00:44:52 * hackagebot scrypt 0.4.0 - Stronger password hashing via sequential memory-hard functions.  http://hackage.haskell.org/package/scrypt-0.4.0 (FalkoPeters)
00:45:44 <donri> Kaidelong: what's this got to do with anything?
00:48:27 <kryft> !log lordlovebone oghe d:10
00:48:44 <kryft> Sorry, wrong window
00:49:04 <kryft> I think elliott will appreciate this
00:51:00 <Kaidelong> donri: oh, you are right
00:51:12 <Kaidelong> when you read the information it still ends up in IO
00:51:15 <Kaidelong> so no purity violation
00:51:17 <donri> Kaidelong: sorry i'm not even sure what you're addressing :D
00:51:55 <Kaidelong> I was thinking that you might be able to get Debug.Trace to be impure using a shell redirect but that was just me forgetting the basic thing that input is IO too
00:52:12 <donri> well that's what i mean by side-step purity
00:52:28 <donri> the types still "look" pure but it's side-stepping it with unsafePerformIO
00:52:54 <donri> so, using Debug.Trace can in fact change the answer
00:54:00 <Ghoul_> how do I solve a dependency graph?
00:54:56 <Ghoul_> I need some general guidance - I need to produce a graph of things depending on multiple other things (a web, actually) and then I need to pluck things out in the order to make everything happy.
00:56:28 <Kaidelong> only if you're able to observe the trace output though
00:56:45 <Kaidelong> I don't think there's any way to do that without further unsafePerformIO
00:56:56 <Kaidelong> however I guess you could argue the *human* could notice the difference
00:57:00 <Kaidelong> but I guess that is the point
00:58:22 <donri> i'm not quite sure how either, but there's a lot that needs to happen to print something to the stdout fd
00:58:52 <donri> also it can affect strictness, i imagine
00:59:10 <Kaidelong> really? that would make Debug.Trace worse than useless in some situations
00:59:11 <donri> traceShow a value and it needs to be forced
00:59:17 <Kaidelong> if it can trigger forcing
00:59:46 <Kaidelong> cause it'll change the behavior of your program, presumably what you are trying to debug
01:00:54 <donri> Prelude Debug.Trace> let inc xs = traceShow xs (map succ xs) in init (inc [1,2,3,undefined])
01:00:54 <donri> *** Exception: Prelude.undefined
01:02:06 <colluphid> :t maybe
01:02:06 <lambdabot> b -> (a -> b) -> Maybe a -> b
01:02:25 <colluphid> :t Just
01:02:26 <lambdabot> a -> Maybe a
01:05:16 <Kaidelong> donri: I guess that's unavoidable, yes
01:05:20 <Kaidelong> sometime to watch out for
01:05:39 <Kaidelong> something even
01:06:30 <Ghoul_> Woooow
01:06:34 <Ghoul_> Data.Graph, topSort is magical!
01:06:44 <Ghoul_> I love haskell libraries.
01:06:46 <johnw> how so?
01:07:00 <Ghoul_> I think its the dependancy graph solver I need, in 1 function.
01:07:54 <absence> is there an easy way to reinstall all packages in a sandbox without deleting the sandbox dir? i want to keep manually added package sources
01:08:21 <johnw> cabal install world --force-reinstalls --reinstall?
01:09:00 <frx> will haskell allocate the list in memory before multiplying all the numbers? fact n = product [1..n]
01:09:28 <frx> or I guess s/haskell/ghc
01:09:40 <Ghoul_> No, it's lazy
01:09:44 <absence> johnw: it fails quickly, complaining it can't find profiling libraries for some dependency (i've enabled profiling libraries in the config, which is why i want to rebuild)
01:09:54 <Ghoul_> it allocates them as it needs them, or, more likely, it's fused together with list fusion.
01:10:02 <Ghoul_> deforestation etc.
01:11:00 <frx> I thought so too but wasn't sure. thanks
01:11:05 <absence> johnw: it seems the "world" file only contains packages explicitly installed, not dependencies
01:11:15 <johnw> ah, that's true
01:11:33 <Ghoul_> You can create a memory leak by using foldl' though if you want one
01:11:42 <Ghoul_> > foldl' (*) [1..4000]
01:11:43 <lambdabot>   No instance for (Data.Typeable.Internal.Typeable t0)
01:11:44 <lambdabot>    arising from a use ...
01:11:50 <Ghoul_> > foldl' (*) 1 [1..4000]
01:11:51 <lambdabot>   182880195151406501331474317557391904421737771073043921970645269542089597979...
01:12:10 <Twey> That's not a memory leak
01:12:23 <Ghoul_> sorry, I think it's a space leak.
01:12:30 <Ghoul_> wrong terminology there, but correct no?
01:12:37 <johnw> no, it's not a leak of any kind
01:12:37 <Twey> No
01:12:40 <johnw> it will run in constant space
01:12:48 <Twey> foldl' is strict in its function, but the list is still lazy
01:12:51 <Ghoul_> Even though the list is strict?
01:12:54 <Ghoul_> Oooh, okay.
01:13:19 <Ghoul_> is there a function for strict list ranges?
01:13:30 <Twey> I'm not sure what that means
01:13:52 <Ghoul_> instead of pulling in bang patterns and doing something like this, !x = [1..n]
01:14:11 <absence> johnw: hm, seems like deleting everything inside .cabal-sandbox except add-source-timestamps did the trick :)
01:14:19 <Twey> That still wouldn't make the list strict
01:14:27 <Ghoul_> Why not?
01:15:02 <Twey> It would match only to WHNF, i.e. 1 : restOfList
01:15:08 <Twey> (not even; the 1 may not be evaluated)
01:15:32 <Twey> Well, that is ‘strict‘, but probably not what you meant
01:15:35 <Ghoul_> so I'd have to deepseq it ?
01:15:39 <Twey> Yes
01:15:50 <Ghoul_> That's kind of painful, but a good thing to know, thanks/
01:16:02 <Twey> It's… not something you'll ever need to do, I suspect
01:16:35 <Twey> If you're using lists like that you might prefer an array, to start with
01:19:46 <frx> why did this make ghci crash with memory error? I thought list won't be allocated. foldr (+) 0 [1..1000000000]
01:20:04 <opqdonut> ghci doesn't do optimizations
01:20:12 <frx> > foldr (+) 0 [1..1000000000]  ; evil grin
01:20:13 <lambdabot>   <hint>:1:30: parse error on input `;'
01:20:20 <frx> > foldr (+) 0 [1..1000000000]  -- evil grin
01:20:21 <lambdabot>   *Exception: stack overflow
01:20:33 <opqdonut> also, the problem in this case is actually not the list
01:20:51 <ion> @src foldr
01:20:51 <lambdabot> foldr f z []     = z
01:20:51 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
01:21:03 <ion> frx: Try evaluating that by hand step by step.
01:21:04 <opqdonut> but rather the fact that foldr builds up a huge lazy expression ((...+(999999999+1000000000)))
01:21:48 <frx> ah right, it calls itself recursively until the last element
01:21:55 <opqdonut> mm, yes
01:21:58 <opqdonut> > foldl (+) 0 [1..1000000000]
01:22:05 <lambdabot>  Terminated
01:22:10 <opqdonut> and that builds the huge expression
01:22:17 <opqdonut> > foldl' (+) 0 [1..1000000000] -- and this is efficient
01:22:25 <lambdabot>   mueval-core: Time limit exceeded
01:22:44 <opqdonut> well, you'd see it in ghci
01:23:42 <frx> @src foldl
01:23:42 <lambdabot> foldl f z []     = z
01:23:42 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
01:23:56 <ion> > foldr (+) 0 [1..1000000000] :: Expr
01:23:57 <lambdabot>   1 + (2 + (3 + (4 + (5 + (6 + (7 + (8 + (9 + (10 + (11 + (12 + (13 + (14 + (...
01:24:07 <ion> > foldl' (+) 0 [1..10] :: Expr
01:24:08 <lambdabot>   0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10
01:24:21 <frx> why is foldl causing memory error as well, isn't that tail recursive?  only foldl' worked
01:25:48 <opqdonut> frx: foldl produces this huge lazy thunk that only gets evaluated in the end
01:26:06 <opqdonut> foldl' forces the partial sum at each step, and thus uses very little memory
01:26:07 <frx> because (:) is lazy?
01:26:12 <opqdonut> no, because haskell is lazy
01:27:37 <ion> foldl (+) 0 [1..10] = foldl (+) (0 + 1) [2..10] = foldl (+) ((0 + 1) + 2) [3..10] = foldl (+) (((0 + 1) + 2) + 3) [4..10] = … = (((((((((0 + 1) + 2) + 3) + 4) + 5) + 6) + 7) + 8) + 9) + 10, and nothing is demanding the evaluation of those a+bs in the middle of evaluation.
01:28:08 <opqdonut> you might think that foldl makes no sense (compared to foldl'), and that's pretty much always the case
01:28:32 <frx> @src foldl'
01:28:35 <lambdabot> foldl' f a []     = a
01:28:37 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
01:29:22 <ion> Alternatively: foldl' f !a (x:xs) = foldl' f (f a x) xs
01:29:44 <ion> Well, that’s not exactly the same.
01:29:55 <frx> first time I see !a syntax.
01:30:16 <opqdonut> btw, if you make a haskell source file with "main = print $ foldl (+) 0 [1..10000000]" and compile it with both -O2 and no flags
01:30:28 <ion> The !a version is like foldl' f a (x:xs) = a `seq` foldl' f (f a x) xs
01:30:33 <opqdonut> and then run it with +RTS -s, you'll see that -O2 does the strictness optimization for you
01:30:34 <frx> opqdonut it's optimized away?
01:30:42 <frx> nice
01:30:49 <opqdonut> "498,902,952 bytes maximum residency" vs. "28,664 bytes maximum residency"
01:31:16 <w0rm_x> > let (+) = (*) in ((+ 5) 5) + (let (*) = (+) in ((* 5) 5))
01:31:17 <lambdabot>   625
01:31:38 <absence> what's the right way to enable profiling for my program when building with cabal? adding -prof to ghc-options in the .cabal file causes complaints and tells me to use --enable-executable-profiling instead. i tried adding executable-profiling: True to cabal.sandbox.config, but the resulting executable doesn't have profiling included
01:36:50 <Saizan> tried on the commandline?
01:39:03 <absence> cabal configure --enable-executable-profiling works. can i add the setting to a config file somehow?
01:40:24 <Saizan> i don't think it'd work that well, exectuables built with profiling enabled can be quite slower
01:41:14 <Saizan> but i don't know if it's possible
01:43:30 <volko> is it possible to statically compile an executable so someone doesn't need to have ghc or haskell libraries installed?
01:43:54 <Ke> -static
01:44:07 <Ke> -optl-static -optl-pthread -optl-dl
01:44:53 <volko> what is -optl-dl for?
01:45:09 <Ke> can't remember
01:45:30 <volko> cool, thanks
02:05:38 <Lethalman> is there any functor instance for a -> b on a?
02:05:47 <Lethalman> I know it's not possible, but maybe there's some newtype somewhere?
02:06:43 <Lethalman> @djinn (a -> b) -> (a -> c) -> (c -> b)
02:06:43 <lambdabot> -- f cannot be realized.
02:07:05 <Lethalman> mh right
02:08:35 <Lethalman> doesn't make sense
02:08:41 <donri> @hoogle (a -> b) -> (a -> c) -> (c -> b)
02:08:42 <lambdabot> Prelude until :: (a -> Bool) -> (a -> a) -> a -> a
02:08:42 <lambdabot> Prelude (.) :: (b -> c) -> (a -> b) -> a -> c
02:08:42 <lambdabot> Data.Function (.) :: (b -> c) -> (a -> b) -> a -> c
02:09:57 <arkeet> :t flip (.)
02:09:59 <lambdabot> (a -> b) -> (b -> c) -> a -> c
02:10:05 <arkeet> hmm
02:10:11 <arkeet> wait.
02:10:11 <Lethalman> it's not possible
02:10:13 <arkeet> yeah that doesn't exist.
02:10:17 <Lethalman> ;)
02:10:27 <arkeet> as djinn correctly concluded.
02:10:46 <arkeet> (-> b) is a contravariant functor, though
02:11:03 <arkeet> http://hackage.haskell.org/package/contravariant-0.4.4/docs/Data-Functor-Contravariant.html
02:11:06 <arkeet> see Op
02:35:33 <Lethalman> Functor f .... fmap :: (a -> b) -> f a -> f b
02:36:01 <Lethalman> is there something like that for (a -> a) -> f -> f or such
02:36:15 <Lethalman> I'd like to change the value inside a data type
02:36:19 <Lethalman> but that value can't be of any type
02:36:55 <Lethalman> so instead of writing (Foo a) = Foo (f a) manually when pattern matching
02:37:01 <Lethalman> I have a function to do so
02:40:09 <Lethalman> class Something f a where (a -> a) -> f -> f
02:40:26 <Lethalman> class Something f a where smap :: (a -> a) -> f -> f
02:40:52 <Lethalman> so that newtype Foo = Foo String can be instance with smap f (Foo s) = Foo (f s)
02:41:37 <Lethalman> in this case should be Something f a | f -> a I guess
02:43:29 <Twey> Sounds like you want lenses
02:44:23 <Lethalman> Twey, ok, apart lenses.... :)
02:44:26 <Lethalman> is there such a class?
02:44:52 <Twey> No; lens is essentially what you're describing, I think
02:45:14 <Twey> (but more general)
02:45:44 <Ralith> sounds like fmap is what he's describing but more general, too
02:46:22 <Twey> I"m not sure about that
02:46:30 <Twey> s/"/'/
02:46:56 <Lethalman> Ralith, but I can't make Foo a functor instance
02:47:08 <Lethalman> there must be such a class somewhere, I know it
02:47:40 <Twey> There is: it's called Setter, and it's in lens :þ
02:49:10 <supki_> Setter isn't a class
02:49:31 <Twey> No, you're right
02:50:06 * hackagebot citation-resolve 0.4.2.2 - convert document IDs such as DOI, ISBN, arXiv ID to bibliographic reference.  http://hackage.haskell.org/package/citation-resolve-0.4.2.2 (TakayukiMuranushi)
02:50:07 <supki_> Lethalman: you may want to look at C.L.Each or mono-traversable package
02:50:44 <Lethalman> ah ok, monofunctor
02:51:46 <Lethalman> let's try
02:55:06 * hackagebot authoring 0.3.2 - A library for writing papers  http://hackage.haskell.org/package/authoring-0.3.2 (TakayukiMuranushi)
02:57:17 <Lethalman> mh why type instance Element Foo = String is not a valid type instance using MonoFunctor :(
02:57:30 <Lethalman> "Illegal family instance"
02:57:36 <Lethalman> where newtype Foo = Foo String
03:00:27 <Lethalman> why type instance Element S.ByteString = Word8 is ok but type instance Element Foo = String is not :(
03:01:32 <Lethalman> ops -XTypeFamilies, ghc-mod showed me only the first line of the error :P sorry
03:15:09 * hackagebot hakyll 4.4.1.2 - A static website compiler library  http://hackage.haskell.org/package/hakyll-4.4.1.2 (JasperVanDerJeugt)
03:42:44 <yesthisisuser> What does it mean to say that Haskell records are not "first-class"?
03:45:13 * hackagebot tensor 0.3.0.1 - A completely type-safe library for linear algebra  http://hackage.haskell.org/package/tensor-0.3.0.1 (NicolaSquartini)
03:45:31 <mauke> you can't separate 「a { b = c }」 into 「a { x = c } where x = b」
04:14:07 <Lethalman> grr cabal install pathtype installs directory 1.0 instead of the latest
04:14:14 <Lethalman> look the deps: http://hackage.haskell.org/package/pathtype
04:14:23 <Lethalman> there's an "or", and he probably prefers the first way
04:14:35 <Lethalman> and directory 1.0 is uninstallable due to an error
04:14:48 <Lethalman> how can I force a version of directory to be installed instead of 1.0 ?
04:15:12 <donri> Lethalman: why are you installing pathtype
04:15:27 <Lethalman> donri, mh thought the phantom types there were cool :P
04:15:42 <donri> Lethalman: i'm asking because i'm working on a modern version of it
04:15:47 <donri> Lethalman: https://github.com/dag/path
04:15:49 <Lethalman> donri, ah awesome
04:16:17 <Lethalman> donri, why are you rewriting it?
04:16:36 <Lethalman> there're already 100 different path hackages :S
04:16:48 <donri> Lethalman: http://www.reddit.com/r/haskell/comments/1nw7ji/pipes_resource_problems/ccndmuo
04:17:34 <Lethalman> donri, and can't you just fix pathtype?
04:18:17 <donri> Lethalman: that would probably be more work and not as interesting unless i break back-compat anyway
04:18:38 <donri> Lethalman: pathtype doesn't really have any users
04:18:44 <Lethalman> ok
04:42:13 <malaclyps> so I'm trying to install pem, and I'm getting this error http://lpaste.net/94481 -- any suggestions as to what to do?
04:51:32 <gauthier_> I want to define a data type to represent binary file structure (small files), I'm gathering that using Repa would be a good idea, how can I define a type alias (if it's a good idea) representing a fixed length array of Word8? (http://lpaste.net/94482), I'd like to constrain size to Int type
04:52:43 <gauthier_> is anything like that possible? http://lpaste.net/94482
04:53:36 <Cale> malaclyps: You have an old version of base64-bytestring, and pem's cabal file doesn't set an appropriate lower bound
04:53:49 <malaclyps> Cale, thanks!
04:55:33 <Cale> gauthier_: You might be able to do fancy things with type level naturals (especially when GHC 7.8 comes out), but largely you'll find this kind of approach very inconvenient.
04:56:21 <Cale> (Haskell isn't dependently typed, so you're not actually allowed to index types with values)
04:56:39 <gauthier_> Cale: what approach should I use to declare data types that are more or less matching C structures declared with fixed size arrays?
04:57:26 <gauthier_> Cale: maybe what I want is just to embed a fantom size, which isn't actually used (yet?) but conveys this fixed size information
04:59:28 <gauthier_> Cale: BTW I did progress due to your help last time regarding my issues with zmq, I found an issue with usage of getErrno crossing mixed C runtimes, I know get proper error description where I was stuck with an error with "no error"
04:59:56 <ocharles> If I'm building a parser for PostgreSQL-specific SQL - do people recommend going the whole Alex + Happy route, or just Parsec these days?
05:00:12 <ocharles> I have something that works in Parsec, and today I learnt enough Happy & Alex to do it with that
05:00:16 <Cale> Yeah, I'm not really sure what to recommend with regard to encoding the sizes of structures in types. You could make types specifically for each field/size and use module boundaries with smart constructors to make sure that the data in them is well-formed.
05:00:17 <ocharles> I can't decide which I prefer...
05:00:41 <Ghoul_> well, for a while I wasn't motivated to shoot myself in the head
05:00:56 <Ghoul_> but it came back after reading Generic.Pointless.Recursion
05:01:41 <Cale> http://hackage.haskell.org/package/pointless-haskell-0.0.3/docs/Generics-Pointless-RecursionPatterns.html ?
05:01:51 <Ghoul_> my eyes, they burn
05:02:02 <Ghoul_> don't read the source code, you'll be scarred forever.
05:03:07 <Lethalman> ahah
05:03:11 <Lethalman> nice hackage
05:04:55 <gauthier_> Cale: isn't repa using something to encode the dimensions of arrays? it sounds similar (to my naive mind) to what one would do to encode length of a dimension
05:05:54 <Ghoul_> It was nice serving with you. Folds met pointfree, and the hapocalypse is imminent.
05:06:06 <Cale> gauthier_: Repa only puts information about the shapes of arrays at the type level
05:06:12 <Cale> not their sizes
05:18:18 * haasn .oO( http://hackage.haskell.org/package/recursion-schemes-3.0.0.2/docs/Data-Functor-Foldable.html )
05:20:11 <w0rm_x> http://ghc.haskell.org/trac/ghc/wiki/AboutVideos any reason why links to those videos are broken
05:34:45 <gauthier_> Cale: does this sound useful: http://hackage.haskell.org/package/fixed-storable-array-0.3.0.0/docs/Foreign-Marshal-FixedStorableArray.html ? or woeful
05:36:11 <Cale> gauthier_: Well, it's using the new TypeNats, so it might be all right
05:38:28 <frx> @src succ
05:38:28 <lambdabot> Source not found. My pet ferret can type better than you!
05:39:13 <frx> every Enum defines one?
05:39:42 <Cale> frx: right
05:39:55 <Iceland_jack> @ty succ
05:39:55 <lambdabot> Enum a => a -> a
05:40:01 <Iceland_jack> > succ 'a'
05:40:02 <lambdabot>   'b'
05:40:22 <Cale> (though personally, I think Enum should just be pruned down to the 4 methods that are used to define the list syntaxes
05:40:26 <Cale> )
05:40:42 <Iceland_jack> Cale: Why?
05:40:56 <Cale> The other stuff is pretty unrelated
05:41:08 <Iceland_jack> You could then simply define succ as:
05:41:08 <Iceland_jack>     succ n = [n..] !! 1
05:41:20 <Cale> heh
05:42:59 <frx> @src range
05:42:59 <lambdabot> Source not found. Sorry.
05:43:34 <Cale> range is a method of Ix
05:53:25 <absence> when heap profiling with -hy, what do ->Something and ->>Something mean?
06:06:48 <gauthier_> how can I define a type alias for StaticVector (https://github.com/chowells79/storable-static-array/blob/master/Foreign/Marshal/StaticVector.hs)?
06:08:15 <gauthier_> nevermind, type seems to work just fine
06:14:01 <stbuehler> hi. i'm working on a "safe" binding for the nettle crypto library (https://github.com/stbuehler/haskell-nettle). i'm thinking about applying for a hackage account for it, but i'd like to get some feedback first (package naming/meta fields, horrible code, ..)
06:26:12 <Philonous> stbuehler, looks useful. You should put it on hackage.
06:43:33 <Vamp> I'm making a Monad instance for my DecisionTree, but I don't know how I should do this for the bind, the comments should be the type correct definition: http://lpaste.net/7114244555636998144
06:46:44 <Philonous> Vamp, Result a >>= f = f  (that's one of the monad laws)
06:47:09 <benmachine> Philonous: f a, you mean
06:47:18 <Philonous> Yes
06:55:39 <Philonous> Vamp, one obvious way to implement the other clause is " Dec xs >>=f = Dec $ map (>>= f) xs
06:56:04 <Philonous> It might actually be the only correct way
06:56:58 <Philonous> In any case, Dec xs >>= return = Dec $ map (>>= return) xs = Dec $ map id xs = Dec xs
06:59:26 <Franesco> Hello everyone ! :)
06:59:35 <Taneb> Hi
06:59:57 <Vamp> Philonous: What do you mean with other clause?
07:00:22 <Philonous> Vamp, You need one for Result and one for Dec
07:01:17 <Vamp> Philonous: Aha I see, just like Nothing and Just for Maybe?
07:02:04 <Philonous> Yes
07:11:20 <Vamp> Philonous: Btw what do you mean with the sentence after the implemention of the other clause?
07:11:34 <Vamp> The sentence that starts with In any case
07:13:48 <stbuehler> Vamp: x >>= return should equal x (see http://hackage.haskell.org/package/base-4.6.0.1/docs/Control-Monad.html#t:Monad)
07:14:15 <Philonous> Vamp, Ah, I was trying to demonstrate that one of the other monad laws holds for this implementation
07:14:39 <alexander__b> how to I turn "(Maybe Foo, Bar)" into "Maybe (Foo, Bar)"?
07:14:42 <Vamp> Aha I see
07:15:19 <Philonous> :t \(a,b) -> a >>= (,b)
07:15:19 <lambdabot> Illegal tuple section: use -XTupleSections
07:15:30 <Philonous> :t \(a,b) -> a >>= \a' -> (a,b)
07:15:31 <lambdabot>     Occurs check: cannot construct the infinite type: t0 = (t0, a0)
07:15:31 <lambdabot>     In the expression: a
07:15:31 <lambdabot>     In the expression: (a, b)
07:15:35 <Iceland_jack> @djinn (Maybe a, b) -> Maybe (a, b)
07:15:37 <lambdabot> f (a, b) =
07:15:39 <lambdabot>     case a of
07:15:41 <lambdabot>     Nothing -> Nothing
07:15:43 <lambdabot>     Just c -> Just (c, b)
07:16:26 <Philonous> :t \(a,b) -> fmap (flip (,) b) a
07:16:27 <lambdabot> Functor f => (f a, b) -> f (a, b)
07:17:00 <alexander__b> Philonous: OK. might look ugly but will work. thanks.
07:17:22 <alexander__b> I really don't like flip or `on` and a few others. I think they are difficult to read.
07:18:12 <supki_> > _1 id (Just 3, 5)
07:18:15 <lambdabot>   Just (3,5)
07:18:23 <supki_> > _1 id (Nothing, 5)
07:18:25 <lambdabot>   Nothing
07:21:48 <alexander__b> I've rewritten my code to be able to do "fmap ((,) foo) bar". that's nice enough. how/where do I activate -XTupleSections? I'm using cabal
07:22:22 <stbuehler> you don't need TupleSections for that way
07:22:25 <Philonous> alexander__b, put {-# LANGUAGE TupleSections #-} at the top of your file
07:22:33 <alexander__b> stbuehler: ghc-mod begs to differ =/
07:22:41 <alexander__b> ghci doesn't complain when I do it there though
07:22:48 <stbuehler> hm
07:23:52 <alexander__b> Philonous: oh, so that's what those odd things are. I have just not bothered reading them when I've come across them, figuring I'd learn their purpose soon enough. :-) thanks.
07:24:38 <alexander__b> Philonous: what does "the top of the file" mean? literally the top, before the licence header, or can it be below that? above or below "module Foo where"?
07:25:57 <Philonous> alexander__b, Has to be before the module declaration, but otherwise it shouldn't matter
07:26:15 <stbuehler> why would (,) need TupleSections? can't reproduce it here..
07:26:23 <Philonous> It shouldn't
07:28:39 <staafl> what was the name of the type system entities above kinds?
07:28:54 <alexander__b> stbuehler: because I have a typo heh
07:28:55 <staafl> i.e. types, kinds and ...?
07:29:05 <meow45> Has development of scion (wrapper around the GHC API for providing IDE functionality) stopped? Has it been replaced with a more popular library?
07:29:12 <alexander__b> staafl: I had (, foo) instead of ((,) foo), sorry.
07:29:31 <monoidal> staafl: sorts
07:29:33 <Philonous> staafl, sorts
07:30:17 <staafl> monoidal, Philonous thanks
07:30:24 <Philonous> alexander__b, , note that (, foo) = (flip (,) foo), though
07:30:41 <alexander__b> Philonous: oh. good to know! thanks.
07:30:53 <staafl> am I correct in thinking that, considering that kinds cannot be applied, there are no higher tiers than that?
07:30:59 <staafl> i.e. there's nothing above 'sorts'
07:32:16 <staafl> > (, foo)
07:32:17 <lambdabot>   Illegal tuple section: use -XTupleSectionsNot in scope: `foo'
07:32:17 <lambdabot>  Perhaps you ...
07:33:49 <srhb> Are kinds the "types" of types or the "types" of type constructors (or are type constructors and types the very same thing) ?
07:34:02 <srhb> Mostly a linguistic question here.
07:35:39 * hackagebot data-pprint 0.2.3 - Prettyprint and compare Data values  http://hackage.haskell.org/package/data-pprint-0.2.3 (PeterDivianszky)
07:38:08 <Philonous> staafl, Not in Haskell2010, but with DataKinds you can have kind constructors
07:38:25 <staafl> Philonous, are they of any utility?
07:40:09 <Res> Hi, I am a newbie and I am trying to use Parsec. I would like to parse the content of a pair of parens. This should work, even if it contains further parens.
07:40:39 * hackagebot OpenCL 1.0.3.4 - Haskell high-level wrapper for OpenCL  http://hackage.haskell.org/package/OpenCL-1.0.3.4 (LuisCabellos)
07:41:04 <Philonous> staafl, It's a step toward dependent types.
07:41:05 <Res> I am using "parenContent <- manyTill anyChar (char ')') " but this will delete closing parens.
07:41:45 <staafl> Philonous, ok, thanks for the input :-)
07:41:53 <dwcook> Res, why not use between?
07:41:55 <dwcook> @type between
07:41:56 <lambdabot> Not in scope: `between'
07:42:02 <dwcook> @hoogle between
07:42:02 <lambdabot> Text.ParserCombinators.ReadP between :: ReadP open -> ReadP close -> ReadP a -> ReadP a
07:42:02 <lambdabot> Text.Parsec.Combinator between :: Stream s m t => ParsecT s u m open -> ParsecT s u m close -> ParsecT s u m a -> ParsecT s u m a
07:42:02 <lambdabot> Text.ParserCombinators.Parsec.Combinator between :: Stream s m t => ParsecT s u m open -> ParsecT s u m close -> ParsecT s u m a -> ParsecT s u m a
07:42:43 <Res> I tried between but this did not work with further nested parens.
07:42:56 <dwcook> It ought to. Show what you tried.
07:43:47 <Philonous> Res, parenContent <- manyTill anyChar (lookAhead $ char ')')
07:45:32 <Philonous> Res, You could just let it eat the closing paren and treat it as already handled
07:46:53 <gauthier_> using Data.Binary.Get Get monad, how can I have something like this: getN a :: Int -> Get a -> Get [a]?
07:47:16 <Res> It does not just eat the closing paren. If I parse "a (b c (d) e )" I get ["a","b c (d"] .
07:47:40 <Res> The ")e" disappears.
07:48:02 <Iceland_jack> gauthier_: replicateM ?
07:48:05 <Iceland_jack> @ty replicateM
07:48:06 <lambdabot> Monad m => Int -> m a -> m [a]
07:49:25 <aristid> i must be measuring wrong... ~360 MB/s for some unoptimized code seems hard to believe oO
07:50:20 <gauthier_> Iceland_jack: sounds spot on :)
07:50:50 <Iceland_jack> :)
07:53:34 <Res> With "between" I was having trouble with the last argument. I used "many anyChar". However, this eats the closing paren.
07:53:50 <aristid> ok, i was. still, 78 MB/s is also rather decent. yay for ghc!
07:54:26 <Res> I need a parser, which eats everything, up to but not including the last closing paren.
07:56:44 <Res> dwcook, when I do  "parenContent <- between (char '(') (char ')') (many anyChar)" I get "unexpected end of input expecting ")"
07:59:41 <dwcook> Res, oh, I see. In that case, would using noneOf ")" serve?
07:59:50 <dwcook> many (noneOf ")")
08:00:56 <meow45> Are there any differences between pattern matching using let and where? For instance, when it comes to laziness/strictness?
08:01:40 <sipa> let is expression syntax
08:07:07 <monoidal> meow45: http://www.haskell.org/haskellwiki/Let_vs._Where
08:07:55 <monoidal> meow45: there is no difference in laziness/strictness
08:13:39 <Res> dwcook, no, I don't think. If I parse ( a b (c (d ) e f) g ) I want to get ab (c (d) e f ) g.  noneOf ')' would match the inner closing parens.
08:15:23 <dwcook> Res, noneOf ")" doesn't match any closing parens, that's what it's for.
08:17:43 <Res> Yes, I understand that. I want to match everything, that is between the outermost opening and closing parens. This includes closing parens as well. That's why I can't use noneOf ")".
08:19:44 <meow45> monoidal: Thanks!
08:20:20 <geekosaur> sounds like you want to recursively match parenthesized groups
08:21:54 <geekosaur> o.O why is there a gssapi-related protocol called kitten?
08:22:06 <geekosaur> channel, oops
08:22:24 <geekosaur> trying to do too many things at once, sigh
08:23:18 <Res> Yes, geekosaur, that's what I am trying to achieve. But I have not find a Parsec combinator, which would help me with that.
08:27:10 <geekosaur> this isn't something parsec does, it's what you do. you write a base parser for the non-recursive case, and reuse it for the recursive one which reinvokes itself (hence recursive) to parse when it sees '('
08:27:15 <Res> I have found something on stackoverflow: http://stackoverflow.com/questions/16182833/parsec-using-between-to-parse-parens
08:27:40 <Res> It uses
08:27:42 <geekosaur> between captures part of it, yes. the other part is recursion
08:27:44 <Res>        recurse  = List <$>                   (between `on` char) '(' ')' (expr `sepBy1` char ' ')
08:27:56 <Res> But I don't understand that.
08:31:24 <alexander__b> OK after a complete rewrite I now have a big [(Maybe Normal, Velocity)]. now I want to msum the normals. how do I do that?
08:32:02 <Res> Let me try to understand and play with this. Thank you guys a lot.
08:32:19 <alexander__b> i.e. I want to return the first [(Just Normal, Velocity)] I can find as a Just (Normal, Velocity) -- or Nothing if there is none
08:41:30 <stbuehler> Res: let i = many (o <|> many1 (noneOf "()")) >>= return . concat; o = between (char '(') (char ')') i >>= \s -> return ("(" ++ s ++ ")") in parse (between (char '(') (char ')') i) "" "( a b (c (d ) e f) g )"
08:41:35 <stbuehler> perhaps that helps you :)
08:45:46 * hackagebot authoring 0.3.3 - A library for writing papers  http://hackage.haskell.org/package/authoring-0.3.3 (TakayukiMuranushi)
08:46:00 <Res> stbuehler, let me try. Thanks a lot.
08:49:57 <stbuehler> i registered an account on hackage, and sent the mail for upload request. didn't get a response, but it seems i could upload anyway (or it got approved without response, or my mail setup doesn't work^^)
08:50:10 <stbuehler> but it looks like it failed to build the docs
08:50:58 <stbuehler> http://hackage.haskell.org/package/nettle-0.1.0/candidate - it build docs for dependencies (http://hackage.haskell.org/package/nettle-0.1.0/candidate/docs/), but my own modules are missing, although there are links to the not existing pages
08:51:55 <stbuehler> any idea whether this is my fault, or candidates just don't have docs, or a hackage bug, or i have to wait longer, or whatever?
09:09:13 <moosefish> Is there any way to force the ghc profiler's output (to a file) from within a running haskell program?
09:10:04 <moosefish> The problem I'm facing is trying to profile a running server, and one of the libraries (http-server) I depend on catches all exceptions… including System.Exit.exitSuccess
09:13:39 <gspr> In x = unsafePerformIO foo  , are there any guarantees that if foo :: IO () is run, it will be allowed to complete? Could GHC decide, for example, that x is no longer needed while foo is still running, and decide to terminate foo before it completes?
09:17:24 <hpc> gspr: ghc would never decide that mid-evaluation
09:17:28 <hpc> that i know of
09:18:00 <gspr> hpc: OK. Thanks. Do you know what resources there are (if any) that describe such and other behavioral guarantees for unsafePerformIO and friends?
09:18:40 <geekosaur> I am tempted to say that if that is even a question then perhaps unsafePerformIO is a bad idea...
09:19:18 <quchen> Right, if you unsafePerformIO something you better be sure it's pure
09:20:21 <gspr> quchen, geekosaur: I know. But one could imagine a C function that is pure in the sense that it always gives the same output for a given input, but for example belongs to a library that uses global state, so it has to be protected by locks (or something like that), right?
09:21:10 <gspr> then I guess unsafePerformIO could plausibly be desired, but one would want to be certain that the IO action doesn't get as far as acquiring the lock, and then being terminated before releasing
09:21:16 <geekosaur> that sounds like a misdesigned library, if it's using global state for a pure function. (not that there aren't such...)
09:21:30 <gspr> geekosaur: I agree, but such things exist
09:21:36 <stbuehler> ever heard of "memory allocation" ?
09:22:18 <gspr> stbuehler: Talking to me? :)
09:22:37 <stbuehler> just an example what usually needs global state
09:22:40 <stbuehler> :)
09:22:45 <gspr> ah
09:22:58 <geekosaur> arguably if it does memory allocation (even if it frees before returning) it's not pure
09:23:04 <geekosaur> but C doesn't have ST
09:23:48 <stbuehler> then creating new values in haskell isn't pure either?
09:24:14 <stbuehler> i think this kind of argument doesn't hold :)
09:24:22 <hpc> stbuehler: explicit allocation
09:25:08 <quchen> "malloc stuff"
09:36:30 <thoughtpolice> gspr: so, yes, this happens when writing C libraries sometimes where you want a 'Haskell API' to some low-level imperative library. wrapping it can be a bit of work to make it 'feel' like Haskell, but it's worth it for your users
09:36:59 <thoughtpolice> gspr: if this is what you're doing, there are a good set of slides from a talk about how to do this (they should be relatively easy to follow on their own)
09:37:02 <thoughtpolice> http://www.ugcs.caltech.edu/~keegan/talks/high-level-ffi/talk.pdf
09:37:17 <thoughtpolice> s/writing C libraries/writing Haskell libraries
09:37:36 <identity> No one in #math is responding, so I wonder if one of you guys can anwer a quick question regarding propositional logic: If I prove that P is false by proving that (not P) is true, is that proof by.. contraposition? Or contradiction?
09:41:30 <arnsholt> Just a normal direct proof, probably
09:41:39 <VectorBundleThom> identity: the distinction is not as clear as you might hope to get, as contraposition itself is proved with contradiction and is not valid in constructive logics.
09:42:26 <gspr> thoughtpolice: Yes, I've seen that one. Thanks, it's good! I was just worrying a bit about the documentation not clearly stating that GHC won't decide to interrupt an unsafePerformIO-wrapped IO action during its execution (for example if it realized the result is no longer needed)
09:42:37 <identity> VectorBundleThom: I see.
09:43:03 <identity> I will simply leave out what it is called, then, and just say that I prove that P is false by proving that not P is true.
09:44:37 <VectorBundleThom> sounds fine
09:46:20 <identity> VectorBundleThom: thanks!
09:46:53 <VectorBundleThom> unless you work on a level of sophistication where you need to explicitly mention the "deduction theorem", you don't need to differentiate between "P is false" and "not P is true"
09:49:38 <identity> VectorBundleThom: I see what you mean, but in this case, I have something like: P: exists x in N, forall y in N where x = y. The question is whether it is true. It is easier to prove the opposite, that forall x there exists an y where x =/= y.
09:50:15 <identity> (apart from the fact that it is obviously not true)
09:53:34 <VectorBundleThom> yeah thats perfectly fine
09:55:16 <VectorBundleThom> the reason you felt slightly confused about contradictions in this setting
09:55:50 <VectorBundleThom> is that in formal logic there is a difference between P|- falsity and P=>falsity
09:56:08 <Kaidelong> ...really?
09:56:18 <VectorBundleThom> the second thing is typically called "not P"
09:56:40 <VectorBundleThom> but alsmost no one shoul care about the difference between semantic entailment and syntactic entailment
09:57:06 <VectorBundleThom> as the deduction theorem guarantees that is turns out to be the same
10:00:54 * hackagebot openpgp-crypto-api 0.6.3 - Implement cryptography for OpenPGP using crypto-api compatible libraries  http://hackage.haskell.org/package/openpgp-crypto-api-0.6.3 (StephenWeber)
10:04:45 <VectorBundleThom> oh i messed up
10:05:07 <VectorBundleThom> difference between P|- falsity and P->falsity
10:06:10 <monochrom> the grand unifying deduction theorem says that |-, ->, => are equivalent anyway
10:06:46 <monochrom> and the theorem of everything adds |= to the mix.
10:08:34 <VectorBundleThom> yeah so the only reason to speak about this kind of metalogic is when you worry what "not P" is supposed to mean in general
10:09:24 <VectorBundleThom> for quantifyers and equality this is not an issue, unless you also want to worry about equality
10:10:46 <absence> > [0..] !! 1
10:10:47 <lambdabot>   1
10:11:18 <absence> > (IM.fromList . map (\x -> (x,x)) $ [0..]) IM.! 1
10:11:26 <lambdabot>   mueval-core: Time limit exceeded
10:11:39 <monochrom> what is IM?
10:11:45 <absence> Data.IntMap
10:12:04 <monochrom> yeah, that one is not going to be non-strict
10:12:24 <absence> is there a data structure faster than O(n) where infinite input can work?
10:13:03 <absence> with lookup faster than O(n) i mean
10:13:37 <quchen> absence: An infinite but balanced tree?
10:13:40 <monochrom> yes. you can steal the code of Data.IntMap and make it more non-strict
10:14:04 <quchen> monochrom: What about Map.Lazy?
10:14:15 <monochrom> where is Map.Lazy? never heard of it
10:14:23 <absence> quchen: i think lazy is the default
10:14:26 <srhb> Containers.
10:14:32 <srhb> Data.Map.Lazy, that is.
10:14:57 <monochrom> Data.Map.Lazy's lazy or non-strict refers to something unrelated
10:15:04 <quchen> Eh nevermind yeah
10:15:23 <quchen> It just came to my mind when someone said "making a Map lazy.
10:15:54 <monochrom> yeah think about Control.Monad.State.Lazy and Control.Monad.State.Strict too
10:15:57 <quchen> But the size and children etc. are still in WHNF even for lazy maps
10:16:20 <srhb> When GHC panics because I made a really stupid mistake, should I still consider it a bug and do something about it?
10:16:59 <klugez> I think so. It should give you an error message, not panic.
10:17:03 <monochrom> it is still a GHC bug
10:21:20 <srhb> Wow, the track page is rather broken.
10:21:23 <srhb> trac*
10:22:00 <srhb> Asks me to register. I enter things and click register. Up pops a HTTP password thingy, which apparently(?) does not relate to my username/password I just entered
10:22:34 <srhb> Then I get a verification email anyway(!) which sends me to a page where I think I should save my name and e-mail. It then says my e-mail is already in use. Well, duh. :P
10:22:43 <monochrom> I didn't register and I still filed bugs
10:23:00 <srhb> Sure, they just mention it's not preferred.
10:23:15 <srhb> It's actually impossible to change your name in there without also changing your e-mail. Clever stuff.
10:25:10 <monochrom> now you need a meta-trac to file this meta-bug :)
10:25:38 <lispy> srhb: I think there is a guest account
10:25:51 <lispy> srhb: for people who don't want to make an account just to issue a bug ticket :)
10:26:41 <srhb> I just registered and filed it. Despite the confusing bugs in the registration process, it still _works_ :P
10:33:26 <absence> hm yeah, fromList is basically insert(insert(insert(insert(..... empty)))), so when (!) pattern matches on the result of that, i guess it forces all the thunks?
10:35:27 <chrisdone> absence: sure
10:40:25 <absence> that explains why infinite input works so bad then :) a stackoverflow answer suggests MemoTrie instead
10:41:08 <derek__> I'm having trouble understanding folds, could someone explain them to me please?
10:41:31 <monochrom> what is the trouble?
10:41:54 <Iceland_jack> derek__: Do you understand some usages of folds?
10:42:04 <derek__> i don't really understand what the accumulater does
10:42:08 <Iceland_jack> > foldr (+) 0 [1,2,3,4,5,6]
10:42:10 <lambdabot>   21
10:42:15 <monochrom> lest I tell you the same thing you already heard and had trouble with
10:42:51 <monochrom> "the accumulator" would refer to foldl. so you want to know about foldl?
10:43:03 <monochrom> you don't, in fact, have to think "accumulator"
10:43:07 <mauke> > foldr f z [x, y, z]
10:43:08 <lambdabot>   f x (f y (f z z))
10:43:10 * quchen thinks foldl isn't a very good example for a fold. :-/
10:43:13 <mauke> > foldl f z [x, y, z]
10:43:15 <lambdabot>   f (f (f z x) y) z
10:43:17 * Iceland_jack agrees
10:43:26 <mauke> > foldl f z [a, b, c]
10:43:27 <lambdabot>   f (f (f z a) b) c
10:43:31 <mauke> ok, this makes more sense
10:44:10 <quchen> "A list looks like a:b:c:[]. `foldl f z list` replaces every ':' in a list with 'f', and the '[]' with 'z'."
10:44:18 <Iceland_jack> derek__: Have you programmed in an imperative language? C, Python, ...
10:44:27 <quchen> Woooops, foldr above there
10:44:32 <quchen> Dammit.
10:45:08 <quchen> That also explains why "foldr (:) []" is the identity on lists: it replaces all (:) with (:) and [] with [].
10:45:35 <mauke> http://en.wikipedia.org/wiki/File:Fold-diagrams.svg
10:46:13 <quchen> The scan* diagrams are pretty silly.
10:46:40 <mangaba_leitosa> > foldl f z [a, b, c]
10:46:41 <lambdabot>   f (f (f z a) b) c
10:46:43 <mangaba_leitosa> > f z
10:46:44 <lambdabot>   No instance for (Debug.SimpleReflect.Expr.FromExpr a0)
10:46:45 <lambdabot>    arising from a us...
10:46:53 <mauke> > f z :: Expr
10:46:54 <lambdabot>   f z
10:47:07 <mangaba_leitosa> > f z a
10:47:12 <lambdabot>   No instance for (Debug.SimpleReflect.Expr.FromExpr a0)
10:47:16 <lambdabot>    arising from a us...
10:47:24 <mangaba_leitosa> Hmm, how this foldl works if 'f z a' doesn't? :-)
10:47:30 <mauke> > f z a :: Expr
10:47:32 <lambdabot>   f z a
10:47:35 * mauke sighs
10:47:56 <mangaba_leitosa> mauke: why you don't need ::Expr in the foldl above? :-)
10:48:08 <mauke> because foldl itself constrains the types
10:48:22 <mauke> :t foldl
10:48:24 <lambdabot> (a -> b -> a) -> a -> [b] -> a
10:49:50 <mangaba_leitosa> mauke: I know the definition of fold, but I think it's the first time I see when 'foldl f z [a, b, c]' works, and 'f z a' doesn't
10:50:06 <mauke> I said "type", not "definition"
10:50:21 <mangaba_leitosa> I know the type signature of foldl as well yes :-)
10:50:23 <monochrom> time to say, "I know the type of foldl, too"
10:50:50 <mangaba_leitosa> (I'm completely unclear about 'f', 'z' and 'a', though)
10:50:56 <Iceland_jack> > id x
10:50:57 <mauke> > let foo :: (a -> a) -> a -> a; foo = id in  foo f z
10:50:58 <lambdabot>   x
10:50:59 <lambdabot>   f z
10:51:19 <mauke> :t f
10:51:20 <lambdabot> FromExpr a => a
10:51:23 <mauke> :t z
10:51:24 <lambdabot> Expr
10:51:34 <mauke> :t f z
10:51:35 <lambdabot> FromExpr (Expr -> t) => t
10:52:03 <mangaba_leitosa> ah, so FromExpr is the tricky part :-)
10:52:45 <mauke> > 1 .|. 2
10:52:46 <lambdabot>   3
10:54:27 <linduxed> hey guys
10:54:27 <mangaba_leitosa> mauke: where are FromExpr and Expr defined?
10:54:46 <quchen> mangaba_leitosa: simple-reflect
10:54:48 <linduxed> i was wondering if you have some tool which would run a suite of tests whenever a certain file is saved?
10:54:56 <quchen> mangaba_leitosa: or maybe simplereflect
10:54:58 <mangaba_leitosa> quchen: thanks
10:55:16 <linduxed> currently i'm thinking of running ruby's guard and have guard execute "runghc theFileWithTests.hs"
10:55:16 <quchen> http://hackage.haskell.org/package/simple-reflect
10:55:29 <hpc> linduxed: you will likely find that having it run tests on commit is better than on save
10:56:02 <kqr> what do you do if you want to create a Random instance for your type, but the concept of a "range" doesn't make sense for it? Random requires you to define randomR. can you just randomR _ = random or is that bad?
10:56:04 <linduxed> hpc: having worked with with guard for quite some time, i really like to have my tests run right away
10:56:06 <hpc> so you aren't constantly running potentially IO/cpu heavy tests
10:56:19 <linduxed> hpc: that way i can see what's breaking and what my errors are
10:56:31 <linduxed> hpc: that's at least how i develop with TDD in ruby-land
10:56:37 <hpc> linduxed: you might try having guard run "cabal test"
10:56:58 <linduxed> hpc: that would mean that i would have create a cabal file, right?
10:57:01 <hpc> yes
10:57:06 <hpc> which you should be doing anyway
10:57:06 <linduxed> hmmm, ok
10:57:22 <linduxed> well, this wasn't a package previously, don't think it will be
10:57:26 <linduxed> or well
10:57:33 <linduxed> now it's actually taking shape into something
10:57:39 <linduxed> maybe it's worth it
10:57:41 <linduxed> anyway
10:58:06 <linduxed> is guard what i should use for this endeavour? aren't there some haskell tools for this kind of thing?
10:58:06 <hpc> cabalizing isn't just for packaging, it's a lot like make, kinda
10:58:31 <monochrom> kqr: then you hope that no one uses randomR on your type :)
10:58:31 <hpc> you can use it yourself if you ever find yourself needing to restore your system or whatever
10:58:43 <hpc> and it will automatically install depends for you too
10:58:50 <kqr> monochrom, lol okay. but it's a fair solution to alias it to random?
10:58:52 <hpc> or as mentioned, for testing
10:58:59 <hpc> or for making stand-alone binaries
10:59:26 <linduxed> hmmm, now that i think of it
10:59:36 <linduxed> sounds like a Gemfile, and i always have those in my projects
10:59:43 <linduxed> for ruby, that is
10:59:47 <linduxed> so yeah, makes sense
10:59:56 <hpc> yeah
11:00:03 <monochrom> it's choosing between a rock and a hard place. alias it to random, or alias it to undefined. I would toss a coin to decide.
11:00:36 <kqr> oh okay
11:00:39 <kqr> yeah it is a hard decision
11:03:32 <Vamp> Someone knows another way to define this monad instance for dtree? http://lpaste.net/4643516291640983552 Because with this version my observed result doesn't match with the expected result: http://lpaste.net/5057573842172510208, And I don't know what the test input is so that kinda sucks
11:06:01 * hackagebot path-pieces 0.1.3 - Components of paths.  http://hackage.haskell.org/package/path-pieces-0.1.3 (MichaelSnoyman)
11:19:16 <quchen> That is a very non-minimal example.
11:20:08 <lpaste> derdon pasted “add vs add'” at http://lpaste.net/94486
11:20:24 <derdon> why do the signatures differ?
11:20:43 <derdon> ooops, forgot the definitions
11:21:05 <derdon> add is defined as "let add a b = a + b"
11:22:37 <quchen> Vamp: Your type looks like it's the free Monad for lists by the way, DTree a = Free [] a, and I think that means the Monad instance is unique. (Unless the specification to [] introduces new possibilities that I'm overlooking.)
11:23:14 <quchen> derdon: Looks like the monomorphism restriction.
11:23:26 <Vamp> quchen: They indeed call it a free monad here
11:23:32 <quchen> derdon: Try ":set -XNoMonomorphismRestriction" and run it again.
11:23:48 <derdon> quchen: ah, the weird confusing thing I still don't understand
11:24:42 <quchen> derdon: It's one of the few things I agree with can and should be hated even when you don't know much about it ;-)
11:25:28 <ibid> the monomorphism restriction sounds scary but is fairly simple. whether it is a good thing or not is debatable (and debated)
11:26:27 <Vamp> quchen: Don't really know how to define the instance differently
11:29:53 <quchen> Maybe your expectation is wrong? The Monad instance looks correct.
11:30:14 <chrisdone> quchen: lpaste should have a feature that compiles the module and if it can't compile it says "not minimal enough!" =p
11:30:42 <quchen> chrisdone: That's easy to add for this one. Just reject lines longer than 100 characters. :-s
11:31:51 <Vamp> It should somewhat resemble the last exercise of http://www.cs.nott.ac.uk/~gmh/monads the Monad instance for Eval
11:31:59 <derdon> ibid: can you tell me where it is explained as simple as it is?
11:32:44 <quchen> I don't see "Monad Eval" in that file.
11:33:13 <Vamp> If you scroll to the bottom of the page you'll see An Exercise
11:41:32 <monochrom> it's "Monad Expr"
11:42:32 <monochrom> but you would think, if I bothered to give you a URL and asked you to look for a string, I should first personally check that the string occurs in the file as I promised.
11:43:50 <ibid> derdon: the technicalities are complex, but basically if you define a function without explicitly listing its parameters (as in add = as opposed to add a b =) and without an explicit type signature, then the MR kicks in and forbids such type variables that require type class qualification from appearing in the function's type
11:45:13 <ibid> derdon: in add :: Num a => a -> a -> a, the a is qualified by Num a, which the MR forbids for add' and thus a monomorphic type is generated
11:46:37 <derdon> ah, I see. so the monomorphism restriction can only be applied if a pointfree function is used? or better, it can only be applied to arguments which are not given explicitly in the definition of the function?
11:47:01 <ibid> derdon: the MR is about functions that are declared as if they were variables
11:47:22 <ReinH> ibid: what?
11:47:24 <ibid> derdon: well, actually, not just about functions
11:47:35 <derdon> what are variables in haskell exactly?
11:47:36 <ibid> variable-like bindings in general
11:47:53 <ReinH> can we please not use the term "variable-like bindings"?
11:47:56 <ReinH> What does that even mean?
11:48:01 <ibid> ReinH: no
11:48:26 <dolio> Bindings of the form 'v = ...'
11:48:28 <ibid> derdon: variable-like definitions more to the point.  the technical name is "simple pattern binding"
11:48:30 <monochrom> every name in lowercase is a variable
11:49:23 <ReinH> that term seems as likely to confuse as it is to explain
11:49:29 <monochrom> "joy = True" makes joy a variable. even though it's immutable so you call it a constant.
11:50:24 <derdon> monochrom: so a variable is nothing else than a name, a label for an expression?
11:50:29 <monochrom> yes
11:51:11 <derdon> then functions cannot be used as if they were variables. that doesn't make any sense
11:51:21 <ReinH> see what I mean?
11:51:24 <derdon> variable are names. and functions can be assigned to names
11:51:38 <ibid> derdon: remember, i said *declared*, not *used*
11:52:07 <ibid> derdon: if you do s/declared/used/g, it indeed does not make any sense
11:52:32 <derdon> ibid: so ``\a b-> a + b`` is translated to ``_ = \a b -> a + b`` by ghc?
11:52:41 <ibid> derdon: no
11:52:47 <monochrom> functions can of course be used as if they are variables. in "map delight xs", "delight" and "xs" are variables. lowercase names. hell, "map" is too, but that's for another day.
11:53:09 <monochrom> but guess what, "delight" came from "delight x = not x && x"
11:53:16 <ibid> ReinH: what's your alternative name for the concept i was trying to convey? other than the technical "simple pattern binding"?
11:53:59 <ReinH> ibid: eta-normal form?
11:54:18 <ibid> ReinH: very pretty :-P
11:54:22 <ReinH> ofc that presumes knowledge of eta reduction
11:54:26 * monochrom prefers alpha-normal form
11:54:52 <derdon> ibid: what is "type class qualification"?
11:54:56 <ibid> ReinH: i don't think it's a NF in a general sense
11:55:03 <ibid> derdon: Num a => or similar
11:55:08 <derdon> ah
11:55:53 <monochrom> you could, you know, say "definitions of the form 'name = ...'"
11:55:55 <ReinH> ibid: in this case it's beta-eta normal form iinm
11:56:34 <ReinH> ibid: right, it's a normal form in a specific sense :p
11:56:39 <ibid> :-P
11:56:46 <derdon> and *why* does the MR have to exist? does it have any advantages? Or does it only exist because the ghc is not perfect and it makes the implementation of the compiler simpler?
11:56:56 <ibid> derdon: it makes the compiler more complex
11:56:57 <monochrom> but then, I would not have the delightful opportunities to shock people with the many faces of "variable" :)
11:57:13 <simpson> derdon: It's not GHC-specific. It's in the spec because it simplifies compiler design.
11:57:17 <arianvp_> arghh
11:57:24 <derdon> simpson: ah
11:57:33 <ReinH> monochrom: and make me twinge? :)
11:57:33 <arianvp_> why are Nats 0-based in agda ): that way  the definition of   Integer is really ugly ):
11:57:33 <dolio> No.
11:57:34 <ibid> simpson: it doesn't simplify compiler design
11:57:42 <monochrom> it exists because of how you will give type to "x = 5" and what are the controversial consequences
11:57:42 <dolio> It's suposed to make things less confusing for users.
11:58:03 <simpson> ibid: Oh. Then I guess I misunderstood what it does.
11:58:09 <arianvp_> because now you gotta make a distinction between +0 and -0
11:58:11 <arianvp_> ... :(
11:58:20 <derdon> monochrom: "x = 5" should throw an error if the type of x is not declared IMHO
11:58:31 <monochrom> you could say, "make it general, x=5 has type x :: (Num a) => a". but it has performance penalties in some cases.
11:59:40 <ibid> derdon: the reason is explained in the Haskell Report. in foo = ... the '...' can be a long and complex calculation.  the programmer likely gave it a name to benefit from laziness-induced sharing so that it's computed only if needed and only once.  without the MR, for technical reasons, that sharing does not happen, and every time foo is used, the computation is redone
12:00:20 <lispy> ibid: right, but it's only redone in the cases where the MR disallows it
12:00:27 <ibid> derdon: the advocates say that the benefit from getting rid of that surprise outweigh the annoyance of MR; the detractors say it doesn't
12:00:29 <monochrom> so the monomorphism restriction says, "pick one specific type". now the performance penalty disappears, but now we have to explain it to everyone
12:00:31 <ibid> lispy: true :)
12:00:52 <dolio> Try the following definition with and without the monomorphism restriction:
12:01:01 <dolio> fibs = 1 : 1 : zipWith (+) fibs (tail fibs)
12:01:11 <dolio> fibs !! 100
12:02:29 <monochrom> guess what, "does compute-once-and-remember help or hurt performance" is another controversy.
12:02:40 <dolio> Indeed.
12:02:47 <ibid> and depends on the specific case
12:02:53 <derdon> dolio: at least I could not feel any performance difference. 100 was not high enough ;)
12:02:57 <itsme_> Hello, let's say I have a signature f :: Integer -> Integer -> Integer -> Integer which i can't change. In the implementation of f I use the parameters only as a list, e.g. f a b c = sum [a, b, c]. Is there a way to write this shorter, like "f = sum arguments" (like arguments in JavaScript) ?
12:03:07 <dolio> derdon: I don't believe you. :)
12:03:18 <dolio> With the MR it is instantaneous.
12:03:24 <monochrom> here is the overarching controversy. "when the compiler decides for you, does it help or hurt performance?"
12:03:31 <dolio> Without, it has not completed since I issued the challenge.
12:03:41 <derdon> weird
12:03:42 <monochrom> that controversy will not end until humanity ends.
12:04:43 <dolio> Also, watch out. It might make your machine start swapping.
12:05:49 <quchen> itsme_: There is a hack to allow a function to take different amounts of arguments, but it's probably not what you want.
12:06:19 <derdon> dolio: even with 10000 it spits the number out almost immediately in both cases
12:06:28 <quchen> itsme_: When you want to sum things of the same type, store them in a list and use `sum`.
12:06:32 <derdon> my computer is too fast :(
12:06:46 <ReinH> itsme_: no, there is no access to "arguments" as f technically only takes one argument
12:06:56 <itsme_> quchen: No, I just want the parameters as a List instead of naming every single one
12:07:12 <ibid> itsme_: would a tuple do instead?
12:07:47 <klugez> dolio: It's instant for me as well whether fibs :: :: Num a => [a] or fibs :: [Integer]
12:07:50 <itsme_> ibid: I don't think so. I sort the list and use fold
12:08:03 <dolio> Hmm. I guess it was ghci and lack of optimization doing something.
12:09:03 <ibid> itsme_: i don't think there's a general solution to it in that case
12:09:07 <ReinH> itsme_: you can write a combinator that does your special case
12:09:25 <ReinH> > let listify f a b c = f [a,b,c] in listify sum 1 2 3
12:09:27 <lambdabot>   6
12:09:36 <dolio> I'll have to think of a better example.
12:09:48 <ReinH> but there's no general solution
12:10:07 <itsme_> ok, thanks
12:10:20 <skypers> hi
12:10:28 <skypers> isn’t there a fmodex binding yet?
12:10:33 <skypers> I didn’t find any
12:10:37 <skypers> in hackage
12:11:57 <absence> does anyone have experience with MemoTrie? is it like a cache?
12:12:31 <jmcarthur_mobile> It just transforms functions into functions that remember inputs they have computed already and reuse the same output
12:13:46 <chrisdone> existentials + typeable ftw http://lpaste.net/8853075813612912640
12:15:20 <chrizz_> @pl \ref f -> readRef ref >>= writeRef ref . f
12:15:20 <lambdabot> ap ((.) . (>>=) . readRef) ((.) . writeRef)
12:15:33 <chrisdone> modifyIORef?
12:16:13 <monochrom> absence: it is like an unbounded cache
12:16:56 <chrizz_> @chrisdone Fay :) gotta write my own
12:16:56 <lambdabot> Unknown command, try @list
12:17:03 <chrizz_> chrisdone: ^
12:17:34 <absence> jmcarthur_mobile: i experimented with it in ghci. it seems like "let t = trie f" followed by "untrie f x" works (subsequent calls are fast), but "memo f x" is always slow. would that be different in a compiled program?
12:17:40 <dolio> derdon, klugez: Okay, if you just type it in a file, and use -O2, GHC optimizes it too well.
12:18:03 <chrisdone> chrizz_: ah =)
12:18:37 <jmcarthur_mobile> absence: you need to reuse the function produced from memo, not reapply memo every time
12:20:03 <dolio> derdon, klugez: http://lpaste.net/94489
12:20:10 <dolio> Try that.
12:21:39 <derdon> dolio: now I can reproduce what you meant :)
12:21:46 <absence> jmcarthur_mobile: it seems so obvious now that you say it :) thanks
12:21:59 <dolio> derdon: If you don't prevent it from inlining, GHC optimizes it to the Integer only version.
12:22:14 <Cale> Oh really?
12:22:36 <derdon> interesting
12:22:38 <dolio> Seems to. fibs is small enough to inline everywhere, apparently.
12:23:12 <absence> so memo ([0..] !!) would be a faster-than-O(n) way to look up values in an infinite list? (it will be more complex than [0..] in actual code of course)
12:23:12 <klugez> dolio: I was just typing it into ghci 7.4.1, but the pasted file indeed fails with "out of memory (requested 1048576 bytes)" in gfibs.
12:23:16 <Cale> ah, and then it'll get specialised with the Integer dictionary and stop being secretly a function
12:23:21 <Cale> hm
12:23:51 <elliott> maybe (c => a) should be a memoised function :)
12:24:37 <dolio> klugez: Not sure how it would work in ghci of any version.
12:25:05 <klugez> dolio: http://lpaste.net/94491
12:25:15 <dolio> Cale: GHC also seems to optimize 'fibs () = 1 : 1 : zipWith (+) (fibs ()) (tail $ fibs ())' into something fast.
12:25:37 <dolio> Wow.
12:25:54 <Cale> dolio: That's a good thing, but somewhat unintuitive.
12:26:27 <dolio> It's a bad thing if you're adding the () to avoid leaks. :)
12:26:38 <Cale> right
12:27:08 <Cale> dolio: Does it perform the optimisation if you use the thing more than once?
12:27:24 <dolio> Cale: Yes, it seems to.
12:27:28 <Cale> huh
12:27:34 <dolio> It only doesn't if I prevent it from inlining.
12:27:53 <Cale> I guess they've decided more aggressive inlining by default is better.
12:28:29 <Cale> I've also seen it strangely lift definitions to top level that I wouldn't have expected it to.
12:28:30 <jmcarthur_mobile> absence: it would be O(log n) instead of O(n) in the index you are looking up, after the first
12:28:37 <Cale> (maybe the same thing as this)
12:29:46 <jmcarthur_mobile> absence: of course the first time you lookup any given index, it will be O(n)
12:30:30 <dolio> Cale: Yeah, -ddump-simpl in my test ends up with a bunch of definitions for each type. Int{,64,32,16}, Integer, Double, Float.
12:30:56 <absence> jmcarthur_mobile: great, thanks
12:31:25 <dolio> So it's specializing the definition to each type, unless I prevent inlining. Which probably comes from it being deigned INLINABLE.
12:31:45 <dolio> Deemed, even.
12:43:15 <aristid> is it normal for ghc profiling to slow things down by something like a factor of 10?
12:44:48 <monochrom> not normal, but I don't know why
12:48:35 <aristid> maybe because i have too many small top-level functions
12:49:01 <aristid> i wonder if callgrind would work on haskell programs :D
12:50:05 <monochrom> pretty unlikely. GHC-generated code is very strange
12:50:31 <aristid> *sigh*
12:51:07 <monochrom> as a first-order approximation, the code doesn't use "call" a lot. instead it uses "push return address manually, then jump" all the time.
12:51:18 * hackagebot husk-scheme 3.13 - R5RS Scheme interpreter, compiler, and library.  http://hackage.haskell.org/package/husk-scheme-3.13 (JustinEthier)
12:51:38 <monochrom> and the second-order refinement to that: replace "return address" by "continuation address"
12:52:46 <monochrom> i.e., I call you, but when you're done, don't bother returning to me, return to putStrLn, because that's the next thing to do anyway
12:53:50 <aristid> kinda makes sense i suppose
12:54:12 <aristid> just a bit of a shame that it means we can't use awesome tools like callgrind :/
12:54:24 <monochrom> you see how this scheme defeats every asm analysis tool that assumes idiomatic asm :)
13:00:24 <aristid> monochrom: and i suppose especially the second-order thing is crucial to get reasonably fast programs out of ghc?
13:03:30 <monochrom> it probably isn't the only way to get things fast. but it certainly is one way fast and straightforward for the code generator.
13:05:28 <arnsholt> Note that low-level profiling tools likely aren't what you want anyways, if you're programming in Haskell
13:06:15 <arnsholt> Something that profiles at the Haskell-level is going to be more useful
13:06:50 <derdon> haha, from the ghc man page: "This manual page was generated from the XML documentation of GHC with blood, sweat, tears and a breaks-if-you-look-at-it-the-wrong-way XSL stylesheet"
13:10:17 <absence> hmm, will "map (list1 !!) list2" be O(n) due to laziness?
13:12:09 <aristid> absence: no.
13:13:38 <absence> i get the same speed if i use MemoTrie or IntMap
13:20:08 <quchen> Does laziness affect asymptotics at all?
13:22:10 <absence> maybe it's not laziness i'm thinking of, but the mechanism that avoids recalculating stuff in certain situations
13:22:40 <aristid> absence: how big is your list?
13:23:09 <aristid> absence: and do you actually fully evaluate the result of that map?
13:24:06 <quchen> absence: Laziness doesn't avoid recalculation I think. It just avoids unnecessary calculation.
13:24:52 <quchen> absence: Memoization on the other hand does avoid recalculation, but a function that is applied to new parameters every time is not memoized.
13:25:05 <absence> aristid: list1 is 8000, list2 is much larger (but that's probably not important)
13:25:23 <quchen> So if you call "f 1; f 2; f 3", then none of the resulting values will be kept in memory on their own.
13:25:45 <quchen> On the other hand, if you give them names, like "f1 = f 1; f2 = f 2; ..." then f1 will "memoize" f 1.
13:26:21 <aristid> absence: how do you measure the speed of the calculation?
13:26:24 <absence> quchen: with f = memo ([0..] !!), f 1000000 is slow, but f 1000001 is fast afterwards
13:27:09 <quchen> absence: Sure, if you use a memoization library then you can change memoization behaviour.
13:27:23 <absence> aristid: profiling the entire program, which is probably a bad idea. i should make it profile that specific part of it
13:29:38 <aristid> absence: ok, and what does the program do with the list?
13:30:01 <aristid> absence: e.g. if you just call "length" on the list, it won't bother actually evaluating the elements, so it will be fast ;)
13:31:08 <quchen> > let x = undefined in length [x, 1 `div` 0]  -- Which is also pretty useful sometimes.
13:31:09 <lambdabot>   2
13:31:49 <absence> aristid: writes the contents to a file
13:33:00 <absence> aristid: (eventually, it first passes each element downstream in a Pipe)
13:34:53 <aristid> absence: the cost of iterating through up-to-8000 elements might just be too slow to notice :)
13:37:49 <quchen> absence: Anyway, to solve your original problem, have a look at Data.List.findIndices
13:41:00 <absence> aristid: too low you mean? it's possible that it's dwarfed by the rest of the program, it just seemed strange since it iterates through the up-to-8000 elements millions of times. but yes, i'll see about some more fine-grained benchmarking :)
13:42:12 <quchen> Sort list2, then roll your own "lookup indices" function.
13:42:18 <aristid> i'm still amazed: so with good input data and a reasonable block size, i'm getting ~200 MB/s on my input data with my simple algorithm - even before I tried to optimize. and my attempts at tweaking it so far have given me almost no gains. i'm sure somebody who knows what he's doing could double the throughput easily though.
13:43:18 <aristid> absence: you may want to try using (unboxed, if possible) Vector though
13:43:38 <absence> quchen: i don't understand. findIndices takes a predicate and returns the indices that match, it sounds almost like the reverse of what i do
13:44:13 <absence> aristid: list1 grows for each lookup (it's lzw decompression)
13:45:03 <quchen> absence: Hm. Well maybe I was too quick saying that. My last comment still stands though.
13:45:12 <quchen> Unless list2 is infinite of course.
13:45:26 <aristid> absence: so you want a container with fast append-at-the-end and random-read?
13:46:20 <aristid> absence: at least in terms of complexities, Seq might fit the bill. no clue what's the overhead though
13:47:02 <absence> aristid: yes, and preferably some laziness (which seq doesn't offer i think)
13:48:11 <aristid> absence: you can definitely have lazy values in there.
13:48:54 <absence> aristid: but can i look up values that aren't added yet, so long as they get added before the lookup is evaluated?
13:51:05 <aristid> absence: well depends on your definition of adding ;)
13:51:33 <aristid> absence: it almost sounds like boxed vectors might even fit your bill if you rely on laziness to add elements.
13:52:48 <absence> aristid: doesn't adding items cause a O(n) copy?
13:52:59 <absence> in vectors
13:53:45 <aristid> absence: that's why you'd create a vector that already contains all the elements.
13:54:57 <absence> ah, but they aren't known up front :) each output element is added. see decode_LZW at http://www.haskell.org/haskellwiki/Toy_compression_implementations
13:54:57 <skypers> hey
13:55:09 <skypers> I’m writing a Haskell binding over a C lib
13:55:29 <skypers> there’s a typedef enum { lot of shit } the_enum;
13:55:35 <aristid> absence: do you know the output size in advance?
13:55:35 <absence> aristid: i'm sure it's called toy for a reason, i'm just trying to learn by, well, toying around with it
13:55:40 <skypers> what type do that shit should have in Haskell?
13:55:42 <chrisdone> "lot of shit" is undefined behaviour
13:55:44 <skypers> does*
13:55:52 <skypers> chrisdone: well lot of symbols
13:56:25 <absence> aristid: i know the input size. the output size depends on the input contents
13:56:26 <chrisdone> skypers: are enums represented as bytes in c? i can't remember
13:56:50 <mauke> chrisdone: does it matter?
13:56:58 <geekosaur> some integral type large enough to hold all the values. since you can use initializers, the actual values can be large
13:57:09 <skypers> chrisdone: int imho
13:57:24 <chrisdone> mauke: yeah. if it's equivalent to a uint_32 then it can be just casted and passed back to haskell as an uint_32?
13:57:31 <mauke> o_O
13:57:40 <skypers> for opaque structs
13:57:45 <mauke> wat
13:57:49 <skypers> I guess I can simply use something like
13:57:59 <skypers> data OpaqueCStruct = OpaqueCStruct
13:58:13 <skypers> and use a Ptr on it when needed
13:58:49 <chrisdone> mauke: how are enums stored in memory in c?
13:58:55 <skypers> int
13:59:13 <aristid> chrisdone: enum sizes can vary depending on the values in the enum
13:59:21 <skypers> aristid: huh?
13:59:31 <aristid> skypers: that's what the standard says.
13:59:34 <skypers> thought it was union
13:59:39 <aristid> skypers: ?
13:59:39 <geekosaur> ?
13:59:48 <mauke> chrisdone: I don't know and I don't care
13:59:52 <skypers> for me in C, enum :: int
14:00:01 <skypers> and in C++11 you can safe type them
14:00:02 <aristid> enum { X=0, Y=1 }  - this may only take 1 byte, if the compiler wants to do it.
14:00:11 <chrisdone> mauke: ok. thanks for your characteristically abrasive input =)
14:00:13 <skypers> oh? that’s nice
14:00:21 <aristid> but the compiler also may decide to use 4 bytes. or 3200.
14:00:28 <skypers> ok so
14:00:28 <quchen> mauke: How are unions stored in memory in c?
14:00:33 <mauke> chrisdone: I don't understand how this matters
14:00:36 <skypers> how should I represent that in Haskell?
14:00:49 <mauke> skypers: why do you want to represent it in the first place?
14:00:55 <aristid> quchen: all the values are stored in the same place, which is aligned to the most-alignment-demands element.
14:01:06 <skypers> mauke: because some functions use the enumerated values
14:01:11 <mauke> skypers: use them how?
14:01:12 <skypers> and I’ll be using then for sure
14:01:19 <quchen> aristid: That would've been my guess.
14:01:20 <skypers> pass them around as args
14:01:27 <skypers> like
14:01:45 <skypers> foo(RED | BLUE | YELLOW | NONSENSIKNOW)
14:01:59 <mauke> I don't think the result of that has an enum type anyway
14:02:04 <quchen> aristid: I just wanted to be sure. And since mauke didn't immediately object to your answer, it's proven correct.
14:02:13 <mauke> \o/
14:02:30 <aristid> quchen: proof-by-mauke's-silence, a well-accepted methodology indeed
14:02:32 <skypers> mauke: well, anyway, I have to pass them to C function
14:02:40 <chrisdone> well the representation matters because if it can be cast to an int then i could just use it as an int or do a case-analysis to convert it to a Haskell sum type. if its reprensetation is undefined/unreliable, then i'd have to write a case analysis in C to convert to some intermediate value that the Haskell FFI can accept
14:02:41 <mauke> yeah, that's the real issue
14:02:59 <mauke> chrisdone: I don't follow
14:03:17 <aristid> chrisdone: if you cast them to 64-bit ints you'd be pretty safe.
14:03:29 <skypers> yeah but it’s quite bazooka
14:03:45 <aristid> *shrug* a 64-bit int is just one register these days.
14:03:57 <skypers> sowhat?
14:03:58 <mauke> skypers: I'd probably use hsc2hs and its #type directive
14:04:29 <skypers> I don’t know that program, I only use ForeignFunctionInterface
14:04:38 <mauke> it's a preprocessor
14:04:50 <aristid> skypers: you said that int64 would be too bazooka
14:04:55 <aristid> i don't think it would be.
14:05:09 <mauke> you pretty much need it (or something similar) for all nontrivial ffi things
14:05:25 <geekosaur> skypers, doing this stuff by hand is madness. use a program that knows how to get the answer for the platform you're building on (usually by asking the appropriate compiler or something).
14:05:44 <geekosaur> you do NOT know better than it does
14:06:00 <skypers> I see
14:06:12 <skypers> I’m going to look forward it then
14:06:23 <chrisdone> it depends on the library
14:06:26 * hackagebot uuid 1.3.0 - For creating, comparing, parsing and printing Universally Unique Identifiers  http://hackage.haskell.org/package/uuid-1.3.0 (AntoineLatter)
14:06:48 <skypers> I’m writing a minimal binding over fmodex
14:06:53 <skypers> it’s a sound library
14:06:55 <chrisdone> if it's simple you can just write some c functions that wrap the C API into something more simple that the haskell FFI can grok readily
14:07:17 <aristid> btw. in C the type of an enum value is not that enum type, i think
14:07:19 <aristid> it's int
14:07:27 <skypers> yeah
14:07:29 <mauke> wouldn't surprise me
14:07:32 <skypers> that’s what I said
14:07:34 <staafl> using ghci, how would I open a file containing a bunch of integers separated by spaces, and parse them to a list?
14:07:50 <chrisdone> oh
14:08:03 <skypers> staafl: readFile, lines, splitWhen
14:08:15 <fizruk> words, rather
14:08:18 <mauke> staafl: xs <- map read . words <$> readFile "asdf"
14:08:23 <skypers> oh words
14:08:24 <skypers> yeah :)
14:08:32 <skypers> wordsBy for non trivial case
14:08:38 <aristid> in c++11 there's "enum class" which fixes enums :>
14:08:49 <mauke> "fixes"
14:08:55 <skypers> yeah :D
14:09:06 <staafl> mauke, yeah, 'words' was escaping me too
14:09:09 <staafl> thanks :-)
14:09:34 <staafl> skypers, fizruk, thank you too
14:10:01 <chrisdone> skypers: so is the int value of the enum directly correspondant to the order of enum entries? a la data Foo = Bar | Mu deriving (Ord)?
14:10:04 <staafl> skypers, where does splitWhen live?
14:10:10 <chrisdone> Data.List.Split
14:10:40 <mauke> chrisdone: enum values are assigned in ascending order (by default) starting from 0 (by default)
14:11:00 <skypers> chrisdone: depends
14:11:09 <skypers> enum a { OK, CANCEL }
14:11:10 <mauke> enum { A, B, C = 42, D }; enum { X = 100, Y, Z = 100 };
14:11:17 <skypers> it would result in A = 0, B = 1
14:11:18 <skypers> ut
14:11:19 <skypers> but
14:11:23 <mauke> A = 0, B = 1, C = 42, D = 43, X = 100, Y = 101, Z = 100
14:11:29 <aristid> chrisdone: an int enum value that has no explicit initialisation is the last one with an initialisation +1, or 0 if it's the first one.
14:11:32 <skypers> enum a { A = 4, B } would result in A = 4, B = 5
14:11:45 <chrisdone> gotcha
14:11:46 <aristid> chrisdone: which is what mauke implied with his example.
14:11:54 <skypers> staafl: splitWhen is really nice
14:12:10 <skypers> I still wonder why it’s not in Data.List
14:12:13 <skypers> even Prelude
14:12:22 <skypers> I always use it when parsing
14:12:24 <staafl> skypers, indeed, it looks quite useful
14:12:31 <aristid> chrisdone: may i ask what you're trying to do?:)
14:12:32 <skypers> it is yeah
14:12:41 <chrisdone> aristid: i'm not doing anything. it's skypers who's doing stuff
14:13:14 <aristid> chrisdone: but you're questions are not rhetoric?
14:13:18 <aristid> *your
14:13:33 <fizruk> chrisdone, so nice to be you :)
14:14:09 <chrisdone> 〈(゜。゜)
14:15:02 <frxx> can someone help me with this?
14:15:11 <lpaste> frxx pasted “No title” at http://lpaste.net/94492
14:16:03 * aristid wonders why anybody would use UUIDs other than v4
14:16:06 <fizruk> frxx, wow
14:16:45 <absence> what does it mean when the profiler says ->Proxy and ->* uses lots of mem? * is uknown type iirc, but what are the arrows?
14:17:57 <staafl> why would reading and splitting an 800 KB file result in 135 MB allocations?
14:17:59 <staafl> as per :set +s
14:18:36 <geekosaur> staafl, ghci is not optimized, it will tend to do more small allocations than compiled code which can optimize things away
14:18:39 <fizruk> frxx, oh I see
14:18:51 <frxx> yes?
14:18:52 <fizruk> frxx, try 1 `elem` [0,2..]
14:18:59 <fizruk> > 1 `elem` [0,2..]
14:19:00 <frxx> ahh
14:19:06 <lambdabot>   mueval-core: Time limit exceeded
14:19:10 <staafl> geekosaur, then its allocation counter looks mostly useless?
14:19:22 <staafl> here we have a 200x difference
14:19:26 <fizruk> frxx, also why not use filter?
14:19:48 <geekosaur> it's somewhat useful, but I generally don't bother with it, yeh
14:19:52 <absence> staafl: use it with the compiled code instead. yourexecutable +RTS -s
14:19:55 <frxx> yeah filter would be more appropriate
14:20:06 <fizruk> you shouldn
14:20:20 <staafl> absence, ghci <my binary> +RTS -s ?
14:20:32 <Cale> staafl: That's 135MB of *allocation*, it doesn't mean that at any point in time, 135MB of memory were in use.
14:20:43 <fizruk> frxx, you should't use infinite list of indices anyway (I think)
14:20:44 <Cale> i.e. the number doesn't go down when things are deallocated
14:21:04 <Cale> You can easily rack up gigabytes of allocation in a few seconds.
14:21:10 <fizruk> frxx, maybe Set would be more appropriate
14:21:16 <staafl> Cale, but it makes no sense in this context
14:21:18 <Cale> and not use very much actual space at all
14:21:24 <absence> staafl: ghci is the interpreter. if you compile the code into an executable, it will get more optimised
14:21:25 <staafl> what is it using it for?
14:21:35 <Cale> It's probably mostly garbage?
14:21:37 <staafl> absence, but where does the +RTS flag come from
14:21:52 <absence> staafl: you pass it to your executable file
14:21:56 <frxx> fizruk make a set out of indices before calling filter?
14:22:06 <Cale> I don't know what your program does, but if you're using String, you should be aware that String is a linked list of 32-bit wide lazy Char values.
14:22:08 <geekosaur> staafl, it's handled by the GHC runtime
14:22:20 <staafl> absence, I don't quite get it, does GHC compile its own switches into my programs?
14:22:22 <staafl> that's new to me
14:22:48 <absence> staafl: yes
14:22:53 <fizruk> frxx, I don't know your use case, but I'd probably make a Set before using getElems
14:22:54 <geekosaur> staafl, even C programs do that
14:23:12 <staafl> Cale, here's the 'code' in question :-)
14:23:13 <staafl> readFile "test.009.in" >>= (return . length . words)
14:23:25 <geekosaur> well, not options in C normally, but perhaps you've heard of LD_LIBRARY_PATH and LD_PRELOAD envars?
14:24:02 <geekosaur> you can do the same thing with GHCRTS envar to send parameters to ghc's runtime... but ghc's runtime also intercepts +RTS -RTS and --RTS
14:24:17 <staafl> geekosaur, it makes a little more sense to use envars than command line switches
14:24:18 <geekosaur> (--RTS lets you turn off this interception, anything following it goes to your program)
14:24:26 <frxx> fizruk make a Set out of indices?
14:24:52 <staafl> switches have a potential for nasty surprises
14:24:58 <fizruk> frxx, yes
14:25:00 <geekosaur> which is why --RTS exists
14:25:09 <Cale> staafl: have you compiled that code with -O?
14:25:19 <Cale> Or are you just running it out of ghci interpreted?
14:25:24 <staafl> Cale, the latter
14:25:32 <staafl> I'll compile it in a minute
14:25:42 <fizruk> frxx, also if your set is formed by a predicate, I'd rather passed that predicate directly to the getElems
14:26:10 <fizruk> frxx, guessing from your example with [0,2..]
14:27:01 <Cale> So, each constructor of the list which is being constructed by readFile will at minimum consist of a machine integer tag (0 or 1 depending on whether it's [] or (:)), together with two code pointers (the pointer to the element of the list, and the pointer to the tail of the list)
14:27:45 <Cale> If you're on a 64 bit architecture, that's already 24 bytes per character.
14:27:56 <Cale> I think there's more overhead still though.
14:28:42 <Cale> When you do words, that's going to be repeated again. Each of the words is going to be allocated as a new list of Chars
14:28:49 <absence> anyone know what ->* in the -hy output means?
14:29:01 <texasmynsted> anybody know of a "howto" to learn haskell for scala programmers?
14:29:06 <Cale> absence: I've seen that too, and I don't really know, but I suspect function closures.
14:29:33 <absence> Cale: yeah, that makes sense. but there's also ->>* :)
14:29:35 <Cale> (like partial applications)
14:29:50 <SaBer> texasmynsted: not specially for scala programmers, but a good intro to haskell: http://learnyouahaskell.com/
14:29:51 <absence> texasmynsted: learnyouahaskell.com
14:30:07 <Cale> texasmynsted: also ask lots of questions here :)
14:31:50 <absence> Cale: maybe the number of > is the number of "missing" parameters during partial application
14:31:59 <absence> Cale: i even have ->>>Proxy here :p
14:32:01 <staafl> same deal
14:32:02 <staafl> 134,292,512 bytes allocated in the heap
14:32:13 <Cale> staafl: In general, you only worry about reducing raw allocation if your program is spending the better part of its time in the GC. GHC's garbage collector is pretty good at cleaning up short-lived garbage.
14:32:22 <texasmynsted> ok, that works
14:32:31 <staafl> Cale, but that's not my point
14:32:34 <Cale> If you want that program to be faster, you could switch to using Text instead of String.
14:32:49 <staafl> there's no reason for 135 MB to be allocated
14:33:01 <Cale> At no point in time will your program be using 135 MB.
14:33:05 <absence> staafl: the 135 MB aren't allocated at the same time
14:33:29 <staafl> sure, but still, 800 KB input and a trivial transformation
14:33:48 <Nimatek> It's still a good idea to use Text if you worry about efficiency.
14:33:56 <Cale> 800 KB * 24 bytes per character is already 19.2 MB
14:34:10 <Cale> er
14:34:13 <Cale> yes
14:34:40 <staafl> ok, so it's allocating its input six times over
14:35:08 <mauke> I have determined by math that the unit of the result is square bytes per character
14:35:16 <Cale> and don't quote me on 24 bytes per character for String
14:35:20 <Cale> I'm not 100% sure that's true
14:35:24 <Cale> It might be worse
14:35:28 <Cale> that's a lower bound
14:35:34 <staafl> Cale, wait one second
14:35:38 <staafl> 24 *BYTES*
14:35:42 <Cale> yes
14:35:58 <texasmynsted> what is the normal approach with haskell to using files as templates, such as is often done for web sites, and text documents?
14:36:11 <staafl> Cale, what on earth
14:36:22 <geekosaur> staafl, String is convenient, it's not anywhere near optimal
14:36:24 <geekosaur> [19 21:20] <Cale> [21:19:05] So, each constructor of the list which is being constructed by readFile will at minimum consist of a machine integer tag (0 or 1 depending on whether it's [] or (:)), together with two code pointers (the pointer to the element of the list, and the pointer to the tail of the list)
14:36:33 <Cale> staafl: As I explained before, you have the list cons cells, which consist of an integer tag (machine sized) together with two pointers
14:36:47 <Cale> and then the first of those pointers points at a 32 bit Char value
14:36:50 <triliyn> mauke: but bytes = character, so square bytes per character is just bytes again
14:37:07 <texasmynsted> example: with java one might use freemarker,
14:37:09 <geekosaur> real programs use Text for general Unicode text and ByteString for octet streams (like raw network connections)
14:37:19 <frxx> am i trying to be too clever in filter predicate? maybe lambda would be more readable?
14:37:23 <frxx> getElems' indices xs = map snd . filter ((`elem` indices) . fst) . zip [0..] $ xs
14:37:43 <Cale> String is actually fine in most cases, and it's convenient to work with in many programs, but if you care about performance, it's *horrible*
14:37:51 <absence> staafl: String is a linked list of Char, it's not an array
14:37:52 <fizruk> frxx, that's ok (I think)
14:38:19 <staafl> absence, sure, but I didn't realize just how unoptimized it is
14:38:31 <frxx> okay. should have removed xs too
14:38:34 <Cale> But in most cases, the range of constant factors which still result in acceptable performance is very large.
14:38:37 <fizruk> frxx, also I think you should try lambda and see if it pleases you more
14:38:58 <mauke> frxx: could be done with a list comprehension
14:39:37 <fizruk> mauke, good point...
14:39:51 <staafl> Cale, I don't think I'd ever take that hit in any code that's even remotely a hot path
14:39:53 <Cale> If your strings are like 20 character long labels for a few dozen UI widgets or something, even if they were 1000 times larger than they could be, it wouldn't be a big deal.
14:40:09 <geekosaur> staafl, depends on what you are doing. space optimization is poor, speed optimization is sometimes very very good due to list fusion
14:40:23 <geekosaur> but it depends on what you're doing
14:40:33 <absence> staafl: in a hot path you want to use Text
14:40:48 <Cale> Text also does a decent amount of fusion though
14:40:55 <staafl> ok, I get it
14:41:14 <staafl> it's a caveat i'll be sure to remember
14:41:25 <Nimatek> texasmynsted: HStringTemplate, and for html there is hamlet from the yesod framework and heist from the snap framework
14:41:39 <frxx> yeah list comprehensions solution is nicer in this case
14:41:49 <staafl> map (say "thanks for the input") [Cale, absence, geekosaur]
14:41:51 <Cale> staafl: For the most part, this inefficiency is historical though.
14:42:08 <Cale> staafl: When the Prelude was written, ByteString and Text didn't exist.
14:42:23 <texasmynsted> thank you
14:42:31 <frxx> staafl mapM :)
14:42:44 <Cale> Probably if we had to do it again today, the basic I/O stuff would all be ByteString or Text based.
14:42:49 <SaBer> staafl: You should also remember "Make things work, profile, optimize. In that order." i.e. you should only worry about performance once you've actually measured that it is a problem
14:42:52 <staafl> frxx, noted :-)
14:42:58 <simpson> At least we have OverloadedStrings.
14:43:03 <simpson> That takes away a bit of the pain.
14:43:14 <staafl> SaBer, of course, but there's no reason to throw away performance like that
14:43:52 <derdon> hmm, haskell doesn't support expressions like "5 < 8 < 10" but math does. it's nice syntactic sugar
14:43:55 <Cale> staafl: Well, it does let you have the illusion that bits of text are lists, and write beginner-ish recursive code to manipulate them.
14:44:11 <Cale> staafl: In the long run, that's probably not worth much, because you'll avoid direct recursion anyway.
14:44:16 <nisstyre> simpson: how long until the entire syntax is overloaded?
14:44:45 <simpson> nisstyre: What's left to overload? Lambdas?
14:44:58 <nisstyre> simpson: yeah that could be done
14:45:04 <nisstyre> could also overload types
14:45:05 <nisstyre> somehow
14:45:19 <simpson> I think that ArrowNotation's already got this covere.d
14:45:20 <triliyn> Overload spaces
14:45:32 <Cale> simpson: We could vastly improve Arrow
14:45:39 <lightquake> triliyn: Monad overloads \n
14:45:40 <triliyn> Then we wouldn't have to write >>= and <*>!
14:46:20 <nisstyre> simpson: overloaded tuples?
14:46:21 <simpson> Cale: Yeah. I've been learning how to netwire, and there's definitely a lot of unexplored territory.
14:46:42 <Cale> The thing which people really want out of Arrow is the stuff which defines symmetric monoidal categories + a handful of other things (arr should exist, but be separate)
14:47:03 <absence> staafl: some of the default stuff in haskell is weird or inefficient. it's older than java and has accumulated some legacy over the years
14:47:11 <Cale> and if you put all that stuff in, the translation for the arrow syntax can be made much much better
14:47:28 <Cale> Currently the Arrow desugaring inserts 'arr' between almost every pair of computations
14:47:39 <staafl> absence, yeah, I forget that
14:47:56 <Cale> which makes desugared arrow code almost completely opaque to any kind of runtime optimisation you might want to do
14:48:09 <staafl> it somehow feels like a young language
14:48:33 <danharaj> Cale: speaking from experience yes?
14:48:39 <Cale> danharaj: yeah
14:48:50 <absence> staafl: there's certainly a lot going on with it :)
14:48:52 <danharaj> I've been trying to get Ryan to show me that code for months now :P
14:49:23 <triliyn> I was reading about an FRP gui library that had to "traverse the whole network" even when nothing needed to happen because the compiler can't tell the difference between arr (\x -> f x) and arr (\_ -> 3)
14:49:29 <Cale> danharaj: I could send it to you, but if he doesn't want to show you for some reason, then maybe I shouldn't!
14:49:48 <danharaj> I think he wants time to sit down and hack on it before he starts strutting it around.
14:49:56 <Cale> Well, yeah, it's quite rough
14:49:58 <danharaj> Maybe we will beat up Hudak at the NY Meetup :P
14:50:04 <danharaj> and press him into service.
14:50:17 <Cale> But it's already a lot better than Control.Arrow
14:51:10 <absence> speaking of GUI, wasn't there a gsoc project for qt bindings?
14:51:16 <Cale> Control.Arrow is kind of unusable for the niche set of libraries which it's designed to capture, which is why hardly anyone uses it.
14:52:24 <Cale> The whole point of >>> as opposed to >>= is that both of its arguments are in a datatype you control (while the right parameter to >>= is a function that you can't inspect), so there's hope for fusing together computations across it.
14:52:41 <Cale> But that's no longer true when every pair of computations is separated with an arr with an arbitrary function in it.
14:53:20 <danharaj> mmhm
14:53:44 <Cale> Applicative is also a good compromise, but also involves lots of black box functions.
14:54:06 <absence> Cale: is it a problem with the desugaring or the Arrow itself?
14:54:11 <Cale> both
14:54:30 <monochrom> ah, the desugaring doesn't give really arbitrary functions to arr, we kind of know what functions they are. but the optimizer doesn't know.
14:54:35 <Cale> Arrow doesn't have the primitives that you'd want, and even if you put them in, the desugaring needs to use them.
14:54:45 <Cale> right, exactly
14:54:55 <monochrom> but wait a second, can't that be mitigated by a lot of rewrite rules?
14:55:22 <Cale> Maybe, but they'd usually be complicated rewrite rules, and it's hard to rely on that.
14:55:28 <Cale> complicated and specific ones
14:55:55 <Cale> Because which optimisations you can have in fusing arrow computations together is going to depend on your library
14:56:03 <monochrom> I see
14:56:30 <Cale> and again, I suppose you could do similar rewrite rules for Applicative or Monad, because rewrite rules can see through lambda (I think)
14:56:40 <monochrom> well, you have worked with people who have worked with arrows in anger. you know the terrain. :)
14:56:55 <Cale> The point of Arrow (or at least as I see it), is to expose all the binding and wiring at runtime.
14:57:12 <absence> lpaste.net/94493 <- why does one space leak and not the other? only difference is forever and the go [] case
14:57:38 <hpc> monochrom: the best libraries are written out of sheer spite for the problem they solve ;)
14:59:13 <Cale> The other thing about Arrow which is bad is only implicit, and that's that Hughes original paper explicitly rejects the rule that (f *** g) >>> (h *** k) = (f >>> h) *** (g >>> k) because he wanted to be cool and generalise monad and comonad.
14:59:21 <Cale> But arrows that don't satisfy that rule are evil.
14:59:37 <absence> also, what is the origin of the "in anger" meme? ;)
15:00:08 <monochrom> I don't know. but it doesn't mean "angry". it means "serious"
15:00:25 <Cale> If you don't have that law, it's like working with circuits which disobey the lumped component abstraction and have sneaky interference effects.
15:00:46 <Cale> and it's really hard to reason about or optimise anything
15:01:26 <Cale> In fact, it's almost worse, in that *how you chop up the diagram* matters.
15:01:37 <Cale> Not just how you position the components on the circuitboard ;)
15:02:03 <monochrom> also I doubt that it counts as a meme. because old-fashioned people say it. Tony Hoare says it. "these people use that in anger".
15:02:41 <absence> Cale: you mentioned Applicative briefly, how does that fit in?
15:02:47 <danharaj> cale: that's weird that that law isn't implied by the other arrow laws
15:02:51 <danharaj> I have to think about it.
15:03:10 <danharaj> Trying to think what that condition is in profunctorese
15:03:24 <absence> monochrom: oh, it just seems to appear quite often in haskell related stuff lately :)
15:04:29 <monochrom> I suppose. people now care about whether you use haskell in practical projects or not. so they ask "do you use haskell in anger". but I first heard it from Hoare.
15:04:30 <Cale> absence: Well, we're generally talking about libraries which consist of some sorts of primitive computations, and then some ways of gluing those computations together into more complicated ones. All these classes are various shapes that the combining glue can take on.
15:05:02 <Cale> absence: There is, iirc, some kind of formal connection between Applicative and Arrow, but I don't really understand it in detail.
15:05:12 <danharaj> monochrom: I think Cale can vouch that I am constantly angry when I use Haskell at work.
15:05:16 <elliott> monochrom: I don't know about you, but when fighting with GHC extensions I often use the compiler in anger.
15:05:18 <monochrom> haha
15:05:24 <Cale> haha
15:05:42 <Cale> danharaj: OooOooOo Skedge1.hs
15:05:48 <danharaj> Don't even
15:05:49 <danharaj> don't.
15:06:02 <danharaj> That thing is so bit rotted and I have to fix it next week ~_~
15:06:13 <elliott> modern Haskell programming is translating the Agda you wanted to write into the Haskell you can actually run
15:06:25 <aristid> monochrom: i tried callgrind on my program :D - if i use -fllvm it crashes because it doesn't recognize some instruction, and without the call graph is indeed almost pointless
15:06:26 <absence> Cale: yes, i read some stuff about Arrow being a combination of Applicative, Category, and some extra laws
15:06:31 <Cale> danharaj: I should put in some hours adding Lens to the code base.
15:06:41 <danharaj> That's on my list too.
15:06:46 <Cale> danharaj: I have a feeling that a lot of things would be made better by it.
15:06:46 <danharaj> Abolish all the record fields.
15:06:51 <monochrom> yikes, crashing is bad
15:07:04 <Cale> Our record fields already have underscores, might as well makeLenses :)
15:07:07 <danharaj> I've been trying to use prisms et al. where I can instead of odious pattern matching.
15:10:02 <absence> lpaste.net/94493 <- why does one space leak and not the other? only difference is forever and the go [] case
15:10:24 <aristid> monochrom: well if llvm decides to use AVX or whatever, it wouldn't be too surprising if valgrind doesn't know that
15:11:33 * hackagebot rdf4h 1.2.0 - A library for RDF processing in Haskell  http://hackage.haskell.org/package/rdf4h-1.2.0 (RobStewart)
15:12:44 <Igloo> absence: Should lzwP be lzwPspaceLeak? And do they have the same type?
15:13:13 <absence> Igloo: whoops, yes
15:13:33 <absence> Igloo: both functions should call themselves, i forgot to change the name in both places
15:14:16 <absence> Igloo: type is lzwP :: Monad m => Int -> Pipe Int Word8 m ()
15:16:05 <monochrom> absence: I am, in fact, not convinced that lzwPspaceLeak and lzwPnoSpaceLeak do the same thing
15:16:31 <monochrom> I am looking at "go (Nothing:_) = return ()"
15:16:33 <saep> absence: The space leak 'variant' loops infinitely if you happen to reach the empty list case.
15:17:13 <monochrom> without "forever", it exits. with "forever", it doesn't exit, it just proceeds to more iterations.
15:19:35 <absence> you're right, i didn't notice that because the Nothing case is an error condition, and i've only fed it valid input when testing :) the output files end up identical though, so lets ignore that detail for now. what's causing the space leak?
15:19:45 <derdon> from ghci, is it possible to get the docstring of a function with a certain command? (by docstring, I mean the multi-line comment above the respective function which describes it)
15:20:27 <joelteon> no
15:20:57 <derdon> ok
15:21:44 <geekosaur> derdon, ghci's not quite as fully functional as e.g. the python repl. maybe someday (I expect they'd love to see patches, but I also expect beginners to run away screaming from the code :)
15:21:54 <geekosaur> beginners at ghc hacking that is
15:22:09 <absence> since the forever version prevents termination in the error case, i like the recursive version better, but not while it prevents the gc from freeing the memory allocated in lzwChunk2
15:23:05 <geekosaur> in general the ghc ecosystem is designed for compiling
15:23:31 <monochrom> I understand that some people expect a repl to be a complete IDE. for example, they not only look up docs at the python prompt, but also in fact type in an entire 1000-line module right there, cold.
15:23:48 <monochrom> just be aware that ghci is not one such IDE
15:24:06 <joelteon> well, python's docstrings aren't quite like any other language's, are they
15:24:35 <derdon> monochrom: alright, I'll keep that in mind
15:24:41 <monochrom> and because over the past 20 years ghci has never been, I'm pretty sure that in the next 20 years it will still not be
15:25:14 <derdon> joelb: python's docstring is simply the first string literal in a module, class or function body. that's it.
15:25:39 <Iceland_jack> It would be nice if Haskell had doc-strings and ghci allowed you to easily print the documentation of a value/datatype/module and functions' source
15:25:45 <joelteon> sure, but it's not "just a comment"
15:25:51 <derdon> indeed
15:25:54 <joelteon> it's not a comment at all
15:26:11 <derdon> and no other expression may occur before this first string literal
15:26:20 <derdon> so it's a bit special, yes
15:26:21 <AshyIsMe> jump to definition is pretty much the same thing though
15:26:45 <mauke> I don't see the use of docstrings
15:26:49 <derdon> AshyIsMe: what's that and how does it work?
15:27:10 <AshyIsMe> i think vim should have that with tags but i havent got it going with haskell yet
15:27:11 <derdon> mauke: it's just a shortcut for googling the function and looking up the docs online
15:27:31 <mauke> derdon: googling?!
15:27:43 <AshyIsMe> derdon: look for: vim ctags haskell
15:27:57 <derdon> mauke: sorry, I meant hoogling :D
15:28:53 <triliyn> Which packages does hoogle search? It provides no results for wordsBy, but it can find OpenGL functions
15:29:00 <AshyIsMe> derdon: :help tags
15:29:25 <AshyIsMe> has some non-haskell specific tags docs
15:29:26 <merijn> triliyn: Hoogle only indexes a small number of packages. It's possible to install a local hoogle database that indexes more, though
15:29:43 <merijn> triliyn: Additionally Hayoo searches more, but doesn't search by type (boo!)
15:29:48 <triliyn> merijn: oh, thanks
15:29:59 <mauke> and hayoo is down
15:30:03 <merijn> triliyn: "cabal install hoogle"
15:31:44 <merijn> derdon: ghci didn't support datatype definition until quite recently, so most people have always used a dev style of having one window of vim/emacs/whatever and one of ghci and just loading whatever file you're working on in ghci and play with code that way
15:32:31 <derdon> merijn: in fact, that's the way my tutor taught us haskell in the first tutorial
15:33:06 <litb> hello all folk
15:34:28 <monochrom> to me, it is not so much what ghci supports, but how many lines I'm going to write.
15:34:49 <monochrom> most SML prompts accept unrestricted code too. I still don't do it.
15:35:19 <monochrom> if I write so much as 4 lines, I will have typos, I will have thinkos, I will have to keep going back and edit things.
15:35:38 <hpc> thinko is my new favorite word
15:35:48 <monochrom> now, how do you edit 5 lines of code at the SML prompt? how do you edit 5 lines of code at the python prompt? I want to know too.
15:36:05 <derdon> monochrom: python prompt? choose ipython
15:36:24 <monochrom> yes, precisely. use an editor, or a full IDE.
15:36:36 <chrisdone> monochrom: in SLIME or elisp's prompt i regularly write multiline inputs, editing them in emacs =)
15:36:47 <derdon> if you edit a block of code (function, class, loop) and go back one step in the history, you can edit the whole function easily and do not get only the last line
15:36:50 <monochrom> in the scheme case, use Racket
15:38:04 <chrisdone> although depending on what you're doing it might be nicer just to write an expression in your haskell file and send it to ghci with a key binding
15:38:24 <absence> http://lpaste.net/94493 <- ok, now they do the same i think
15:38:26 <chrisdone> sometimes it's nice to have repl history, other times not
15:39:59 <derdon> ah, what I also noticed: consecutive duplicates are not ignored intelligently like zsh can do (e.g. "let a=23", "let a=23" saves two entries in the history)
15:40:12 <derdon> but it could be worse :)
15:40:41 <geekosaur> haskeline is a subset of readline, I don't think that functionality is supported
15:40:58 <geekosaur> (we used to use readline but that caused portability problems on windows and os x)
15:41:07 <derdon> yeah, it's a general readline issue
15:41:09 * geekosaur yet again shoots Apple for having a -lreadline that isn't
15:41:33 <hpc> we don't need standards, we're a multibillion dollar company!
15:41:55 <hpc> (see also redhat, a single-billion dollar company)
15:42:21 <monochrom> it is standard. company standard.
15:42:37 <hpc> standard oil
15:49:22 <absence> hmm, searching the web i found that forever used to leak space, but was changed to use explicit sharing, which fixed the problem. seeing as the forever version doesn't leak space, could that be the key to fixing the non-forever version?
15:51:14 <monochrom> unlikely.
15:51:36 <absence> aw
15:51:52 <monochrom> it is not as simple as "sharing = less memory". because under some other conditions, "share = more memory".
15:53:31 <monochrom> it is perhaps worthwhile to try this
15:57:51 <absence> monochrom: i'm not quite sure what's meant by explicit sharing
15:58:19 <lpaste> monochrom annotated “No title” with “No title (annotation)” at http://lpaste.net/94493#a94499
15:58:25 <absence> apparently it's used here: forever a = let a' = a >> a' in a'
15:58:43 <monochrom> that one. I want to know what difference it makes
15:59:16 <monochrom> I still don't know what is going on. but this will be a valuable data point.
16:01:40 <jmcarthur_mobile> derdon: haskeline supports that deduping behavior if you configure it to
16:02:01 <jmcarthur_mobile> derdon: you can set it up in a dot file for all programs that use haskeline
16:02:20 <derdon> jmcarthur_mobile: ah, good to know! thank you
16:02:33 <danilo2> Hello! I was talking almost 2 days ago here about a problem - I'm generating Haskell code, which should mimic an OO behaviour (classes, methods etc). My sample generated code does not compile because of very interesting type problem (http://lpaste.net/94500). I was told, that maybe it could be solvable using type families and GADTs, but I've read a lot of materials about hthese features and I do not know, how they could help me
16:02:49 <frxx> can you have a list of typeclasses?
16:02:57 <absence> monochrom: thanks, that did the trick actually :)
16:03:37 <frxx> for example a list of Enums
16:03:48 <absence> monochrom: but i don't understand why
16:04:06 <Cale> danilo2: What are you actually trying to accomplish?
16:04:47 <monochrom> then it lends more support to the hypothesis "the sharing created by forever leads to less memory". because you see I'm emulating forever, with just one small difference. but I still don't know what's going on.
16:04:52 <Cale> danilo2: If you try to blindly translate OO code into Haskell, it may not work, especially if you want things like inheritance.
16:05:21 <danilo2> Cale: The code, I've posted (http://lpaste.net/94500) is a handwritten code - but it is identical to a code generated by my parser. I do **not** want any inheritance - only "classes" and "methods"
16:05:24 <Cale> danilo2: But if you take your problem, and consider how to break it down using the tools that Haskell gives you, you'll usually find that things work out not so bad.
16:06:16 <Athan> Hey everyone I've got a tough question
16:06:20 <danilo2> Cale: please look at lines 38 and 39 - they are "taking" the method from a class instance and claling it on 2 ints and 2 stirngs. If you comment out one of these lines it works, but if both of thesel ines are used, I'm getting a tpye error
16:07:00 <Athan> I'm trying to make an XML DOM manipulation optimizer in haskell
16:07:14 <Athan> by comparing two slightly changed XML files
16:07:44 <danilo2> Cale: the part "(getCF_Vector_add $ member Func_add v)" should return function a->b->(a,b)  (it returns _Vector_add function). The problem is, that while Haskell chcecks the types, it does not know that it is a->b->(a,b) and firstly things it is Int->Int->(Int,Int) and then matches it against String
16:07:52 <Athan> is it possible to compare the two, and construct a fully optimized + compiled function that creates the DOM manipulations?
16:08:17 <Cale> danilo2: Okay, so here's the translation which I typically use if I'm thinking "this would really benefit from an OO sort of approach". Take each collection of methods which is relevant (i.e. abstract base class sort of thing), and make a record datatype which has those methods as functions. If you want a pure interface, then each object type will have methods which instead of modifying the object directly, will produc
16:08:17 <Cale> e a new object as part of their output. Or of course you can use IO or something with mutable state.
16:08:22 <danilo2> Cale: If you comment out one of lines 38 or 39 - the ocde works as it should - then you'll see exactly what problem I'm tlaking about
16:09:14 <Cale> Then for each of the *actual* objects which implement the interface, you define functions taking the "private" bits of the object as parameters, and producing a record of how all the methods are implemented.
16:09:33 <Cale> Does that make sense?
16:10:04 <danilo2> Cale: give me a second. I'm trying to understand, what you've written
16:10:32 <absence> monochrom: maybe the outer function somehow removes references to the closure and lets the garbage collector clean up instead of having the closures accumulate for each recursion
16:11:00 <cbw> Hello, I am new to Haskell. I am having a problem using show. https://gist.github.com/cameronbwhite/7062578 There is a short comment giving an example of my error and what I want.
16:11:16 <Cale> danilo2: Let me quickly make a small example.
16:11:16 <absence> monochrom: memory use only accumulated linearly up to a point btw, then it remained constant
16:11:38 <Iceland_jack> cbw: Don't do show
16:11:55 <Iceland_jack> if you want a character to be shown as a string, use the monkey! (:[])
16:11:58 <Iceland_jack> > show 'a'
16:11:59 <lambdabot>   "'a'"
16:12:01 <Iceland_jack> > (:[]) 'a'
16:12:02 <lambdabot>   "a"
16:12:04 <Iceland_jack> > ['a']
16:12:05 <lambdabot>   "a"
16:13:16 <cbw> Ok. What do you call this? So I can google more about it
16:13:26 <Iceland_jack> cbw: You don't call it anything
16:13:34 <Iceland_jack> recall that strings are simply lists of characters
16:13:48 <Iceland_jack> > (\ch₁ ch₂ -> [ch₁, ch₂]) 'a' 'b'
16:13:49 <lambdabot>   "ab"
16:14:01 <cbw> Oh I see I am using list comprehension
16:14:15 <Iceland_jack> cbw: List comprehension?
16:14:47 <cbw> (:) Is the list comprehension function
16:14:50 <Iceland_jack> No
16:14:54 <Iceland_jack> (:) is just cons
16:15:16 <Iceland_jack> there is not “list comprehension function”, unless you mean the functions list comprehensions desugar to
16:16:12 <cbw> I understand. I was using the wrong words
16:16:25 <Iceland_jack> No problem
16:16:45 <cbw> thanks btw
16:16:57 <Iceland_jack> Just to be sure: "test" == ['t','e','s','t'] == 't':'e':'s':'t':[]
16:17:00 <gauthier_> each package representing sequential data (list, array, bytestring, etc) seems to have basic operations (take, drop, head, tail, init, etc.) is there any package with a type class making that polymorphic?
16:17:02 <Iceland_jack> You're welcome
16:17:53 <gauthier_> > Just $ "test" == ['t','e','s','t'] == 't':'e':'s':'t':[]
16:17:54 <lambdabot>   Precedence parsing error
16:17:54 <lambdabot>      cannot mix `GHC.Classes.==' [infix 4] and `GH...
16:18:07 <lil-polar-bear> gauthier_: there is ListLike on hackage which kind of does that
16:18:21 <jmcarthur_mobile> But it is pretty annoying
16:18:54 <Iceland_jack> > "test" == ['t','e','s','t'] && "test" == 't':'e':'s':'t':[]
16:18:55 <lambdabot>   True
16:19:13 <lpaste> Cale pasted “OO in Haskell example” at http://lpaste.net/94503
16:19:23 <Cale> danilo2: ^^ something like that?
16:19:42 <Cale> danilo2: I'm using the RecordWildCards extension there for syntactic convenience
16:20:07 <Cale> danilo2: It just lets me define the record fields in a where clause rather than using lambdas inside the curly braces.
16:20:21 <gauthier_> lil-polar-bear: thanks I'll look at this :)
16:20:49 <gauthier_> jmcarthur_mobile: were you refering to listlike being annoying?
16:20:57 <danilo2> Cale: Thank you, I see what you mean. There are 2 main problems I see with this approach., First is, I do not know the types of methods (but of ocurse I can use parametric classes in my generated code to mimic it or use TH to read them in compile time) and the second problem is (I think) the same as with mine approach
16:21:06 <danilo2> Cale: Give me a second, I'll make an example :)
16:21:12 <jmcarthur_mobile> Yes
16:21:22 <Cale> danilo2: Why wouldn't you know the types of the methods at compile time?
16:21:30 <jmcarthur_mobile> It is very complicated and ad hoc
16:21:47 <Cale> danilo2: Wouldn't you have the same issue in, e.g. Java?
16:21:55 <jmcarthur_mobile> It is not principled in the way that, say, Foldable is
16:22:05 <danilo2> Cale: I do not know the types of methods **while generating code**, but at compiel time, all the types would be known
16:22:14 <gauthier_> jmcarthur_mobile: isn't it annoying to have to prefix calls to take / drop with the specific package according to the instance while it can be generic?
16:22:20 <Cale> danilo2: hmm
16:22:28 <danilo2> Cale: No - it is not something Javalike - lets say Haskell with only few OO things (like classes and methods)
16:22:55 <Cale> danilo2: I mean, I'm not sure how that makes sense. How do you write code which uses objects whose methods you know nothing about?
16:22:59 <jmcarthur_mobile> If there were an Unfoldable class (maybe there is) then ListLike could just be Foldable+Unfoldable, I think
16:23:29 <Cale> danilo2: If you don't know anything about the interface that an object supports, then you can't even begin to try to use it beyond passing it around.
16:23:41 <jmcarthur_mobile> gauthier_: not as annoying as unprincipled overloading (in my opinion)
16:25:35 <danilo2> Cale: Ok, my "communication mistake" - lets say, user is writing code in a pseudocode: "def f(a,b): (a,b)" - If I do not provide my custom typechecker (and some parts of inferencer) I do not know (in code-generation-time), that type of f is a->b->(a,b).
16:26:07 <Cale> Well, sure, but f is not going to be a Haskell function.
16:26:10 <danilo2> Cale: Of course Haskell knows such thing and I can "ask him" (for example using TH) to give me this infered type. Give me a second - I';m making example with you approach :)
16:26:11 <jmcarthur_mobile> gauthier_: if I see a polymorphic function with a ListLike constraint, it was probably nonetheless written with a particular instance in mind
16:26:28 <Cale> f is a function in the programming language you're implementing
16:26:38 <Cale> Not in your interpreter or compiler.
16:27:18 <Cale> right?
16:27:21 <jmcarthur_mobile> gauthier_: and since ListLike is kind of meaningless by itself (no properties I can rely on besides parametricity), I don't gain anything by using it polymorphically
16:27:38 <jmcarthur_mobile> Well, apart from the parametricity I guess
16:27:43 <gauthier_> jmcarthur_mobile: maybe what annoys you is that the underlying implementation doesn't have similar costs? I'm primarily concerned with the intent, and those operations being pretty generic I don't see hurting, I need to look at ListLike package
16:28:50 <jmcarthur_mobile> What annoys me is that it doesn't provide any benefit for me
16:28:56 <benmachine> jmcarthur_mobile: I'd think that most uses of ListLike probably have 2-3 instances in mind, instead of 1
16:28:56 <jmcarthur_mobile> For the reasons I gave
16:29:05 <danilo2> Cale: Could you please look at new code here: http://lpaste.net/94504 ?
16:29:15 <benmachine> but that's still fewer than I'd like
16:29:17 <jmcarthur_mobile> That's still not infinite the way most uses of type classes are
16:29:27 <benmachine> right
16:29:56 <danilo2> Cale: If I understood you correctly, thi mimic the generated code and the problem is the same as before (We get error, that string cannot be mathced to Ints) and it works if you comment out line 21 OR 22.
16:30:09 <danharaj> parametrized modules would be a better solution to the ListLike / Vector problem than typeclasses
16:30:31 <jmcarthur_mobile> I don't mind putting preconditions on function arguments, but putting preconditions on constraints is a lot harder to accept
16:30:35 <Cale> danharaj: What is the type of f?
16:30:42 <danharaj> Cale:?
16:30:43 <jmcarthur_mobile> danharaj: agreed
16:30:50 <Cale> sorry nick completion fail
16:30:56 <Cale> danilo2: What is the type of f?
16:30:56 <danharaj> thanks Obama.
16:31:03 <jmcarthur_mobile> Explicit parameters make more sense to assign preconditions to
16:31:17 <benmachine> I'd like parametrised modules in Haskell
16:31:29 <jmcarthur_mobile> It would be really nice
16:31:38 <benmachine> I wonder if they're hard, or if it's just "we don't need them so much because typeclasses, so no-one's bothered"
16:32:01 <Cale> danilo2: That is, what type do you expect f to have?
16:32:15 <jmcarthur_mobile> It's mostly the latter. It's hard to justify a complicated extension that overlaps so much with existing features
16:32:48 <jmcarthur_mobile> Most people want it but can't agree on form
16:34:08 <danilo2> Cale: I see the problem. There EXIST a situation, the f will work (like in the provided code) - (method1 x) in this example ives us a->b->(a,b), so Haskell could infer type of f to be (F_method1 m (a->a->c)) => m ?
16:34:47 <danilo2> Cale: but it does not and I'm looking for any solution, hoI can mimic such behaviour, because "method1" can be used on both Ints, Strings and any datatype
16:35:40 <Cale> f :: (forall a. (Show a) => X (a -> a -> (a,a))) -> IO ()
16:35:55 <Cale> If you turn on RankNTypes and give that type signature, your code will build
16:37:52 <Cale> But as to whether this is a solution, I don't know.
16:38:02 <osa1> I remember seeing a \case -> syntax some time ago, can we use it now?
16:38:11 <Cale> osa1: yes
16:38:15 <Cale> LambdaCase
16:38:21 <osa1> thanks
16:38:52 <danilo2> Cale: I'm checking it right now. Would you be so nice and tell me a little more, why this works, and why Haskell does not infer this by default? I simply do not understand, why Haskell cannot infer this type
16:39:10 <cbw> Anothir newbie question :) Why does showRegExp work but not the instance of show https://gist.github.com/cameronbwhite/7062841
16:39:23 <Cale> GHC will never instantiate a type variable at a polymorphic type while inferring types.
16:40:14 <Cale> There are a number of reasons why it would be bad to do so, one of which being that there's in general not a unique way to do it.
16:41:03 <Cale> This works in this case, because we're saying that f *demands* the parameter you give it is a *polymorphic* value
16:41:11 <geekosaur> cbw: you have Show a => Show (RegExp Char); ghc has no way of knowing what a is
16:41:36 <geekosaur> in this case I don't think you need the Show constraint at all, since you specified RegExp Char and Char is known to have a Show instance
16:41:48 <danilo2> Cale: Ok, I understand it. Hmm - great it works, It is a big step forward to me, thank you :) There is one other problem with it - I have to generate in the code the signature of the function. Right now I was generating signatures of instances (etc) using TH. Do you see any possible way to generate such signatures automatically?
16:42:10 <Cale> If you don't explicitly say this, it will get as far as inferring that x :: X t for some type t, and it'll look at the first call to method1 and determine that t = Int -> Int -> t' for some type t'
16:42:18 <danilo2> Cale: It is gneerated code, so you see, it would be hard to tell user to write such singatures if I do not want to force him to use singatures in "methods"
16:42:25 <cbw> geekosaur: oops Char should be a but that does not solve the  problem
16:42:35 <Cale> I really doubt that this code is anything like the code that you're after though...
16:42:36 <geekosaur> ```instance Show a => RegExp a``` would make sense, but the constraint is meaningless for a concrete type like RegExp Char
16:43:18 <danilo2> Cale: Ok, but maybe have you an idea how (maybe other way) can I mimic, what I want - I mean "OO classes and methods" with inferred types?
16:43:31 <Cale> danilo2: What exactly are you doing? Are you compiling some other language into Haskell code?
16:43:37 <geekosaur> cbw: your first case uses ```a``` directly, not via Show
16:44:10 <Cale> danilo2: You showed me some user-code which looked like non-Haskell code, which would indicate to me that you're writing an interpreter or compiler.
16:44:11 <danilo2> Cale: yes, it is a custom language. It is a functional language, which has got classes and methods
16:44:25 <danilo2> Cale: It is an compiler
16:45:21 <danilo2> Cale: I would love to allow the iuser to write a "class" with a method (pseudocode: "test(a,b) -> (a,b)"), whcih he can use like x.test(1,2) or the same but ith stirngs
16:45:43 <Cale> So, you probably want to do something non-trivial when implementing objects. You need to implement them by vtables or some such thing.
16:45:59 <geekosaur> cbw: if I replace your One case with ```show (One a) = show a``` then it compiles
16:46:39 <solrize> http://www.thebookseller.com/news/youtube-star-signed-profile.html
16:46:41 <solrize> wow
16:46:55 <solrize> that's about one of the catsters
16:46:58 <cbw> geekosaur: but then I am back to my original problem. If is use ```show a`` then I will get "'a'" instead of "a"
16:47:39 <geekosaur> cbw, I suspect you're using the wrong "tool" for this, then.
16:47:53 <cbw> geekosaur: showRegExp works
16:48:09 <danilo2> Cale: I really want the final code to be as fast as possible. I do not have inheritance here, so I do not know if vtables would be the best thing to use here. Is there any Haskell mechanism, that would work instead? These Rank2Types work well if we provide the signature  maybe there is a way to automatically infer these signatures - it would work then and produce fast binaries
16:48:12 <geekosaur> you cannot do what you did, because you told it "any a which has a Show instance" but then you did something that will only work if a is exactly type Char
16:48:40 <geekosaur> furthermore you are almost certainly abusing Show
16:48:51 <geekosaur> it's not a prettyprinter, so much as a debug printer.
16:48:54 <cbw> geekosaur: Sorry, I corrected that. Look again. https://gist.github.com/cameronbwhite/7062841
16:49:18 <Cale> Well, it depends on how you're implementing objects, but *either* you're going to implement them properly using explicit closures (i.e. pairs of context maps from variables in scope to bound values, together with code with free variables in it that refer to the variables in the context), or else you're going to have some kind of indexed bunch of methods for each class in the way that e.g. C++ does things, and once you
16:49:18 <Cale> know the type of x, then you know which bit of code x.test refers to.
16:49:49 <geekosaur> cbw: showRegExp works because ghc can infer that a is always Char because of your ```(:[]) a```
16:49:51 <Iceland_jack> cbw: You shouldn't actually use (:[]) x as a function
16:49:59 <Iceland_jack> you should us [x]
16:50:02 <Iceland_jack> *use
16:50:06 <geekosaur> (also that's better written ```[a]```)
16:50:07 <Iceland_jack> or in your case; [a]
16:50:21 <geekosaur> but in any case you still have the problem that it fixes the type to Char
16:50:29 <cbw> geekosaur: showRegExp will take numbers too
16:51:28 <danilo2> Cale: yes, but both of this methods (correct me if I'm wrong) produce slower function calling code (after compilation) than caling simple Haskell functions?
16:52:01 <geekosaur> *Main> :t showRegExp
16:52:01 <geekosaur> showRegExp :: RegExp Char -> [Char]
16:52:12 <geekosaur> I commented out your disordered Show instance
16:52:20 <cbw> Iceland_jack: If I use [a] instead of (:[]) then it wont take numbers
16:52:28 <Cale> No, if you're compiling to machine code, you get to decide how this all goes down. Closure evaluation might be as simple as pushing the contents of the environment onto a stack and then jumping into the code.
16:52:34 <Iceland_jack> cbw: there is no difference
16:52:50 <geekosaur> cbw, either you are not showing us your real code or you are incorrect
16:52:52 <Cale> But... it's really hard to talk about this in complete generality.
16:52:53 <danilo2> Cale: C++ is also optimized in a way, that if youre not using virtual methods, than calling a function is mapped to simply a cell in memory, where the "body" is kept. But If I want to use GHC inferencer, then I have to produce Haksell code. If I output Haskell code, and implement "vtable-like" in code, it owuld not be cut off by the compiler, i think
16:52:56 <Iceland_jack> :t \a -> (:[]) a
16:52:57 <lambdabot> a -> [a]
16:53:00 <Iceland_jack> :t \a -> [a]
16:53:00 <lambdabot> t -> [t]
16:54:30 <osa1> is there a conventional name to give to the parameter of function that refers to function itself? ( to be used with fix )
16:54:31 <Cale> If you're compiling with Haskell as the target language, then you could probably just as well use completely separate function names for every single method implementation.
16:54:43 <danilo2> Calle -  simply want to use Haskells type inferencer, laziness and optimizations, so I do not want to compile to machine code, but to Haskells code or eventually using a GHC-API
16:55:06 <cbw> Iceland_jack: I was incorrect
16:55:11 <Cale> (and have your compiler work out which method is appropriate?)
16:55:18 <Iceland_jack> osa1: ‘f’ or ‘g’ or ‘h’ are sometimes used
16:55:21 <Cale> I don't know, you have to pick somewhere.
16:55:28 <Iceland_jack> I've seen ‘self’ and ‘ego’
16:55:35 <elliott> I like "me".
16:56:01 <Iceland_jack> yeah, ‘me’ is good
16:56:26 <danilo2> Cale: Of course I can use completely separate names for every function in every "class", but then, how would I implement a calling mechanism in a function "test(x): x.f()" - it is undoable unless I've got a type inferencer, or use type classes here :(
16:56:44 * hackagebot pandoc-types 1.12.3 - Types for representing a structured document  http://hackage.haskell.org/package/pandoc-types-1.12.3 (JohnMacFarlane)
16:56:46 <osa1> thanks, self looks good to me
16:57:08 <Cale> I dunno. I would think you'd want to infer types for yourself, as your type system is likely to be very different from Haskell's.
16:58:02 <chrisdone> Cale: you use Emacs right?
16:58:18 <Cale> chrisdone: In the past, I have. Mostly I use vim though.
16:58:32 <chrisdone> k
16:58:52 <Cale> chrisdone: For some value of "use".
16:59:30 <cbw> geekosaur: Iceland_jack: Here is my solution. I removed the variable typing on data RegExp because really char is the only thing that makes sense. https://gist.github.com/cameronbwhite/7062841 and now it works. Unless you have a better idea
16:59:39 <Cale> chrisdone: As long as my editor does basic syntax highlighting, converts tabs to spaces, and is able to start successive lines on the same column as the previous, I'm reasonably happy.
16:59:55 <Cale> So I might as well be using gedit or something (and sometimes I do)
17:00:05 <danilo2> Cale: Ok, thank you very much for all the help :)
17:00:08 <geekosaur> cbw: more or less, although I would consider that Show abuse
17:00:50 <cbw> geekosaur: Can you explain why it is Show abuse?
17:00:50 <Iceland_jack> cbw: (You can always use printf from Text.Printf: printf "(%s + %s)" (show a) (show b))
17:00:53 <geekosaur> show is mostly intended for debugging, not pretty printing; I expect to see the constructors.
17:00:58 <Cale> danilo2: Good luck! I'm not willing to rule out the possibility that you can get a free lunch somehow here, but it's probably going to be tricky.
17:01:37 <Iceland_jack> geekosaur: That's more of a problem with Haskell not having two standard type classes for those
17:01:38 <Iceland_jack> imo
17:02:10 <cbw> Iceland_jack: Do you mean like how python has __str__ and __repr__ ?
17:02:29 <Iceland_jack> Yes quite
17:02:39 <danilo2> Cale: I hope so - If you'll accidentally come to an idea how I can get "the free lunch" I would be very very thankfull If you'll tell me :)
17:03:01 <Iceland_jack> That is actually something that people don't bring up very often is how closely Python's magic methods mirror Haskell's type classes
17:03:03 <triliyn> Idris has a nice thing where a type can have multiple instances for a typeclass
17:03:04 <danilo2> Cale: every tip would be very helpful :)
17:03:25 <triliyn> (At least, I think it's nicer than the current newtype thing that you use in haskell)
17:04:17 <carter> wait waht
17:04:26 <geekosaur> cbw: so, the convention is that a Show instance produces something that you could cut and paste into a Haskell source file to represent a value
17:04:29 <carter> triliyn: how
17:04:41 <Iceland_jack> Num (__add__, __mul__), Eq (__eq__, __ne__), Ord (__le__, __gt__), Hashable (__hash__), etc.
17:04:41 <carter> geekosaur: its a pretty handy feature
17:04:59 <geekosaur> likewise a Read instance accepts such a thing (but not necessarily all of the possibilities, although that is recommended)
17:05:13 <geekosaur> carter, was that really intended for me?'
17:05:29 <carter> geekosaur: copy and pasting shows into source is handy :)
17:05:31 <carter> soyes
17:05:42 <carter> i do want to figure out getting some of idris's magic into ghc too though :)
17:05:47 <triliyn> carter: I don't remember exactly how it works, but there's some way to name your instances and then you can kind of qualify typeclass functions by instance name
17:05:51 <Iceland_jack> yes in general you'd like (show ∘ read = id) with some minor quirks
17:06:00 <Iceland_jack> but it's not meant for serialization
17:06:04 <geekosaur> cbw: in other words, I would expect a Show for your RegExp type to produce things like (One 'a')
17:06:21 <triliyn> And I think you can also have a default instance that is used when the functions aren't qualified
17:06:40 <geekosaur> this is very useful for debugging, typesafe serialization, and various other uses. its not prettyprinting, but that's not really what Show is about
17:06:46 <carter> Iceland_jack: i think you want that (show .read . show .read ) == (show . read)
17:07:05 <geekosaur> there are various prettyprinting classes available on Hackage and I think in the standard library (the Haskell Platform)
17:07:15 <Iceland_jack> yes that takes care of some of the quirks
17:07:17 <carter> triliyn: yeah, i know you can have names defined on different types and they get resovled correclty
17:07:22 <cbw> geekosaur: I understand what you are saying. The plan is for the program to read in regEx in the format I am printing it out. Since this is just for me I might keep it the way it is.
17:08:03 <Iceland_jack> cbw: I like writing my own personal pretty-printing Show for debugging
17:08:42 <Iceland_jack> especially for quick and dirty code
17:09:14 <carter> i do think that  read *should* take a proxy value of the right type
17:09:16 <cbw> I might try to write a Print class that is like __str__ in python then some print functions which use it.
17:09:33 <carter> to prevent the ambiguity from read . show
17:10:02 <Iceland_jack> cbw: The trouble is that ghci uses ‘show’ by default :) it is possible to change the interactive show function in newer versions of ghci
17:11:21 <cbw> Iceland_jack: So I would need to write special functions? Like ```print :: (Print a) => a -> String```
17:11:41 <Iceland_jack> Have you written a type-class before cbw?
17:11:46 <cbw> No
17:12:00 <triliyn> print is actually already defined in the prelude, but it's just putStrLn . show
17:12:03 <Iceland_jack> You start out with:
17:12:04 <Iceland_jack>     class Print a where
17:12:04 <Iceland_jack>         pretty :: a -
17:12:05 <Iceland_jack> oops
17:12:11 <Iceland_jack>     class Print a where
17:12:14 <Iceland_jack>         pretty :: a -> String
17:12:28 <Iceland_jack> and then you can define instances of Print for what ever type you want
17:12:56 <Iceland_jack> instance Print RegEx where print … = …
17:12:59 <cbw> triliyn: The name was just an example.
17:13:39 <arguser> hello
17:13:42 <triliyn> cbw: right
17:13:51 <Iceland_jack> that's rather like how Show is defined:
17:13:51 <Iceland_jack>     class Show a where show :: a -> String
17:13:51 <Iceland_jack> minus some detail
17:14:03 <arguser> im having issues trying to install postgresql-simple on windows
17:14:17 <arguser> regarding a C library pq
17:14:19 <cbw> It essetrially the same thing as Show but intended for a different use
17:14:24 <Iceland_jack> Yes
17:14:55 <Iceland_jack> there are some libraries who do the same but it sounds like a good exercise for you
17:16:10 <cbw> Iceland_jack: yeah it will give be a go at making typeclasses.
17:17:54 <geekosaur> arguser, yes, you need a Postgres client installation and you need to indicate where the Postgres client library lives. sadly Windows doesn't have a standard for doing this like Unixlikes do
17:18:22 <arguser> have the client and did add the extra include/lib path
17:18:24 <geekosaur> (that's probably pg instead of pq)
17:18:35 <arguser> but got the same error
17:18:57 <triliyn> Are you using cabal from cmd?
17:19:13 <triliyn> (or from any of the various cygwin-type things)
17:19:31 <triliyn> You'll probably have to do it from a new cmd/cygwin/whatever window for the path to be updated
17:20:04 <arguser> yes
17:20:06 <arguser> cmd
17:20:10 <arguser> no cygwin
17:21:52 <arguser> also got the issue on running the old cabal
17:22:01 <arguser> even when i updated the path and reopen cmd
17:22:13 <triliyn> hmm, not sure then
17:22:31 <triliyn> I've had a lot of trouble with installing binding libraries on windows too
17:24:08 <arguser> maybe being 64 bits its a problem
17:25:50 <arguser> going to try later
17:25:51 <arguser> thanks
17:35:46 <osa1> (!) operation on Arrays is O(1), right?
17:36:04 <monochrom> yes
17:36:45 <osa1> okay, as far as I can see it's not mentioned in documentation
17:37:37 <osa1> (on the other hand, I know it's used in Happy to implement parsing tables etc. which requires O(1) access ...)
17:38:22 <zorzar> i don't understand what the problem here is: https://gist.github.com/zoranzaric/14b3235a9290ef280ed4
17:39:20 <geekosaur> zorzar, you can't use a (Maybe a) as an (a)
17:39:47 <Iceland_jack> zorzar: The error message is a hint
17:39:50 <zorzar> geekosaur: how do i solve this instead?
17:40:27 <monochrom> osa1, I think the author hopes that the word "array" is "enough said" :)
17:40:37 <Iceland_jack> You can use fromJust if you're certain that the list given to lastElement is never empty
17:40:54 <Iceland_jack> > fromJust (Just 5) + 10
17:40:55 <lambdabot>   15
17:41:02 <geekosaur> I would say the simplest fix is to replace x with Just x
17:41:09 <geekosaur> in x == ...
17:41:32 <zorzar> Iceland_jack: ah great!
17:41:45 <zorzar> Iceland_jack: i guess i should add a guard?
17:41:47 <Iceland_jack> in general fromJust is icky at best
17:41:48 <geekosaur> (simplest fix that won't crash if you feed it an empty list)
17:42:21 <Iceland_jack> Right, what geekosaur said
17:42:45 <Iceland_jack> You can write: Just x == lastElement xs && …
17:43:31 <Iceland_jack> for other cases you might use something like this:
17:43:31 <Iceland_jack> > fmap (== 5) (Just 5) == Just True
17:43:32 <lambdabot>   True
17:45:38 <zorzar> ok my next problem... i updated the gist with the new error
17:47:07 <Iceland_jack> Try adding a type signature to the empty list:
17:47:07 <Iceland_jack>     estCase (assertEqual "[]" True (isPalindrome ([] :: [Int])))
17:47:09 <AshyIsMe> hmm, SHIM is doing some strange things in vim for me
17:48:01 <geekosaur> :t []
17:48:02 <lambdabot> [a]
17:48:06 <geekosaur> zorzar: ^^
17:48:53 <geekosaur> the empty list is polymorphic; if the compiler can't guess the type you intend from how it's used, you need to do something like ([] :: [Int]) to specify *which* empty list
17:49:33 <geekosaur> and indeed, the way you're using it could be [Char] or [Int] or ... and it can't figure out which you want
17:49:41 <zorzar> couldn't match expected type [Int] with actual type Bool, but if i use Bool it doesn't work either
17:49:58 <SLDR> Is there any handy way of forcing Haskell to not be lazy and evaluate, say, a list before doing something else?
17:50:03 <Iceland_jack> zorzar: You're probably missing parentheses
17:50:17 <zorzar> then i gat ambiguous type variable
17:50:22 <geekosaur> this generally won;t happen in ghci because it uses extended rules and will infer [()] in this case
17:50:29 <fizruk> SLDR, seq/deepseq?
17:50:40 <SLDR> fizruk: Checking...
17:50:45 <geekosaur> I think you need to show your updated actual code here again
17:51:45 <zorzar> geekosaur: i updated the gist again
17:52:17 <Iceland_jack> zorzar: Why are you doing ∷ Bool?
17:52:25 <Iceland_jack> Nobody suggested that
17:52:39 <geekosaur> isPalindrome ([] :: [Int])
17:52:41 <geekosaur> or something
17:52:48 <zorzar> i tried that
17:52:54 <Iceland_jack> Haskell knows that (isPalindrome …) is always Bool
17:53:04 <Iceland_jack> zorzar: Well then let us see *that* attempt
17:53:08 <geekosaur> :: will gobble as much as it can
17:53:18 <SLDR> fizruk: Alright, seq may be the thing, but I'm not quite in the clear on _how_ it works
17:53:28 <Iceland_jack> and you'll see that my earlier comment about the parentheses is quite possibly correct :)
17:53:29 <zorzar> doh
17:53:42 <zorzar> it was a parantheses error as you suggested...
17:53:50 <SLDR> fizruk: Not theoretically; hoogle just wasn't very clear on how to use the thing
17:53:55 * Iceland_jack whistles
17:54:20 <zorzar> thanks a lot!
17:54:36 <Iceland_jack> You're welcome zorzar!
17:54:46 <Iceland_jack> Keep the Haskell questions rolling :)
17:55:01 <Iceland_jack> That's how this channel makes money, from answering Haskell questions
17:55:02 <fizruk> SLDR, length xs `seq` doSomeOtherStuff will result in evaluating length xs first and doSomeOtherStuff next
17:55:06 <zorzar> Iceland_jack: hehe
17:55:53 <zorzar> ok why do i need the additional paranthesese in line 54 and not in line 40=
17:56:09 <SLDR> fizruk: Let's say doSomeOtherStuff depends on the result of length xs. How would that work?
17:56:10 <monochrom> because of the grammar
17:56:22 <Iceland_jack> zorzar: What are the types? :)
17:56:31 <Iceland_jack> butLast returns the same type as it takes in
17:56:52 <zorzar> ah!
17:56:53 <Iceland_jack> so (butLast (… ∷ [Int])) means that the entire expression has type [Int]
17:57:06 <Iceland_jack> and (butLast …) ∷ [Int] means that … has type [Int]
17:57:35 <Iceland_jack> (isPalindrome xs) always has type Bool, regardless of the type of xs
17:57:41 <Iceland_jack> Does that answer your question?
17:57:49 <zorzar> Iceland_jack: yes, thanks
17:58:10 <Iceland_jack> You can think of ‘unification’ as a detective game :) and it often is
17:58:23 <Iceland_jack> where you try to gather evidence of types
17:59:18 <Iceland_jack> For example, “how does ghc know that this has type [Bool] -> Bool?”
17:59:18 <Iceland_jack> @ty \(a:as) -> a && a
17:59:19 <lambdabot> [Bool] -> Bool
18:00:53 <monochrom> unification is one of the two prerequisite skills for learning haskell
18:01:40 <monochrom> people ask about the prerequisites, and I say: two skills from highschool algebra. people flunk highschool algebra, it's the sole reason why they have difficulties with haskell.
18:02:16 <monochrom> first highschool skill is "substitute equal for equal". if "f x = x+x", then it stands to reason that "f (g 5) = g 5 + g 5"
18:02:17 <sipa> i didn't learn unification in high school...
18:02:34 <codygman> I'm on chapter 8 of real world haskell, what would be the new style way to handle this with exceptions: http://dpaste.com/1422890/ (I found this related stack overflow: http://stackoverflow.com/questions/6009384/exception-handling-in-haskell but can't seem to figure out the correct syntax)
18:02:46 <monochrom> (btw, most non-haskell languages break that law. it's why people who flunk highschool algebra love those languages)
18:03:32 <cbw> who takes algebra in highschool
18:03:44 <zomg> cbw: the nerds!
18:03:48 <carter> depends on your definition of albegra
18:03:50 <zomg> man, those nerds!
18:03:53 <cbw> I took it in middle school
18:03:54 <zomg> they are so bad in football
18:03:54 <codygman> I had algebra 1/2 in high school and I was on the "normal" track
18:03:57 <zomg> lol
18:04:06 <codygman> 1 & 2 I should say
18:04:09 <Iceland_jack> codygman: You need to specify the type of the exception you mean to catch
18:04:12 <Iceland_jack> or ‘handle’
18:04:18 <cbw> Now Linear algebra is for the nerds
18:04:35 <monochrom> second highschool algebra skill is unification. it means that suppose you're given "x+y = y+x, it's a law", and you are faced with "b + 3*a", you can instantiate x=b, y=3*a, and proceed with "b + 3*a = 3*a + b"
18:04:45 <carter> linear algebra is seldom done right
18:04:57 <codygman> Iceland_jack: Hold on, I tried that and got some errors. I'll paste my attempt.
18:05:10 <Iceland_jack> you can do that using:
18:05:10 <Iceland_jack>     handle (\(SomeException a) -> return []) $ do
18:05:20 <Iceland_jack> Only you probably don't want to catch “SomeException”
18:05:59 <monochrom> (btw, every untyped language breaks unification. it's why people who flunk highschool algebra love untyped languages)
18:06:33 <simpson> monochrom: Even Prolog? (I assume "untyped" means "not statically typed" here.)
18:06:37 <Iceland_jack> I'm not sure that's the reason :P
18:07:07 <monochrom> oh yikes, I forgot prolog. but my main point stands, people who flunk highschool algebra hate prolog :)
18:07:23 <Iceland_jack> They also hate Scheme!
18:07:32 <triliyn> And calculus!
18:07:33 <Iceland_jack> (since we're making bold generalizations)
18:07:43 <cbw> untyped would probably mean dynamic?
18:07:53 <Iceland_jack> cbw: Yes
18:07:55 <stephenmac7> Why use liftM and ap when you can use fmap and <*>
18:08:06 <Iceland_jack> why use fmap when you can use <$>
18:08:10 <dwcook> stephenmac7, hysterical raisins
18:08:10 <monochrom> yes, use fmap and <*>
18:08:26 <stephenmac7> I meants fmap or <$>
18:08:32 <stephenmac7> *meant
18:08:35 <ion> fmap is <$> is fmap
18:08:40 <simpson> cbw: There is a distinction between dynamically typed systems and systems that have no type information or only a single type.
18:08:42 <Iceland_jack> also fmap/<$> don't work for monads
18:08:43 <stephenmac7> Exactly
18:08:45 <stephenmac7> :t fmap
18:08:45 <lambdabot> Functor f => (a -> b) -> f a -> f b
18:08:53 <stephenmac7> :t (<$>)
18:08:53 <lambdabot> Functor f => (a -> b) -> f a -> f b
18:08:54 <Iceland_jack> oops no
18:08:54 <triliyn> fmap works with monads because monads are functors
18:08:58 <Iceland_jack> (((yes yes yes)))
18:09:01 <simpson> But that distinction is often ignored in statically typed language communities for reasons I don't grok.
18:09:03 <triliyn> But liftM doesn't work with things that are not monads
18:09:05 <Iceland_jack> I meant other way around
18:09:38 <Iceland_jack> simpson: Because ‘if it's not statically typed, it may as well be un(i)typed’ I've found :)
18:09:56 <Iceland_jack> I've found that to be the attitude, it's not mine
18:10:03 <stephenmac7> So... no reason to use liftM over <$>/fmap
18:10:07 <simpson> Iceland_jack: Which is unfortunate but forgiveable.
18:10:15 <stephenmac7> :t liftM
18:10:16 <lambdabot> Monad m => (a1 -> r) -> m a1 -> m r
18:10:20 <cbw> I like duck typing
18:10:24 <glguy> If you're in a context that only has a Monad constraint, use liftM. If you are in a context that has Functor, use fmap
18:10:51 <stephenmac7> gienah: But why use liftM in that context?
18:10:57 <stephenmac7> Because it makes the code clearer?
18:10:57 <cbw> Haskell typeclass is like static duck typing LOL
18:11:15 <dwcook> stephenmac7, if you don't have a Functor constraint, you can't use fmap.
18:11:15 <Iceland_jack> So not like duck typing at all? :)
18:11:25 <cbw> It made sense kinda
18:11:38 <stephenmac7> dwcook: Ah
18:11:40 <stephenmac7> I see.
18:11:45 <Iceland_jack> class Quackable animal where …
18:11:59 <stephenmac7> Why not just add Applicative as a contraint to Monad?
18:12:02 <dwcook> Unless, of course, you're working with a *specific* type with Functor
18:12:06 <triliyn> Well, you can kind of look at interfaces as a formalization of duck typing, and typeclasses are basically interfaces
18:12:08 <Iceland_jack> stephenmac7: Funny you should say that…
18:12:10 <dwcook> stephenmac7, they're actually doing that
18:12:10 <SLDR> If a function works perfect if I hard-code the list it's supposed to work on but fails when I give it the result from another function, what's going on? (The hard-coded list and second function results are identical)
18:12:38 <Iceland_jack> stephenmac7:
18:12:39 <Iceland_jack> http://ghc.haskell.org/trac/ghc/wiki/Status/Oct13
18:12:42 <stephenmac7> So, in the future they'll be getting rid of these extra functions?
18:12:53 <Iceland_jack> Read under future plans:
18:12:53 <Iceland_jack>     Applicative as a superclass of Monad - A long-standing proposal, GHC 7.10 will finally make Applicative a superclass of Monad. GHC 7.8 features warnings to ensure users know where their code will break as a result of this API change.
18:12:56 <dwcook> stephenmac7, probably not. But you will at least be able to use fmap on Monads.
18:13:01 <Iceland_jack> They won't be getting rid of them
18:13:06 <elliott> stephenmac7: in the very long term, perhaps
18:13:46 <stephenmac7> It seems haskell doesn't care about backwards compatibility so... I would think they'd remove it
18:14:00 <dwcook> It cares about it in the small, at least
18:14:28 <stephenmac7> mtl killed everything that used it...
18:14:32 <hpc> it cares about compatibility wrt runtime errors, but if code stops compiling whatever
18:14:37 * Iceland_jack wants to point out that ghc ≠ Haskell
18:14:45 <dwcook> Besides, it's convenient to be able to say: instance Functor MyType where fmap = liftM
18:14:58 <stephenmac7> True, but ghc dictates haskell's direction, it seems
18:15:04 <Iceland_jack> Absolutely
18:15:14 <Iceland_jack> But Haskell is not an implementation
18:15:31 <stephenmac7> In practice, ghc is haskell because there are no other usable implementations
18:15:34 <hpc> ghc is more the "exploration"
18:16:01 <hpc> haskell itself is extremely conservative in what it allows, to encourage alternate implementations that don't take 20 years of non-stop PhD level development
18:16:10 <Iceland_jack> exactly
18:16:23 <codygman> Iceland_jack: I tried the code you gave me but I'm getting a "not in scope error" and not quite sure why since I am importing the correct things as far as I can tell: http://dpaste.com/1422900/ (traceback on bottom)
18:16:44 <stephenmac7> Who wrote the haskell spec?
18:16:54 <hpc> stephenmac7: it was a committee thing
18:17:03 <hpc> http://www.haskell.org/onlinereport/haskell2010/
18:17:23 <Iceland_jack> codygman: IOException is not something you pattern match against :)
18:17:27 <stephenmac7> Ah, I see.
18:18:09 <Iceland_jack> You can do:
18:18:09 <Iceland_jack>     handle (\(e ∷ IOException) -> return []) $ do
18:18:12 <AshyIsMe> wow haskell can be concise
18:18:15 <hpc> simon marlow is the listed editor of the 2010 report and i can't find any larger authorship citations
18:18:29 <AshyIsMe> im up to chapter 4 of real world haskell and the capCount function is pretty sweet
18:18:33 <Iceland_jack> and enable ScopedTypeVariables by -XScopedTypeVariables or {-# LANGUAGE ScopedTypeVariables #-} at the top of your file
18:18:36 <hpc> haskell 98 was written by about 20 people
18:18:40 <AshyIsMe> capCount = length . filter (isUpper . head) . words
18:18:49 <triliyn> I wish there was a third case (upper / lower / ???) so that we could distinguish value constructors from type constructors
18:18:52 <stephenmac7> hpc: Ah, I see.
18:18:54 <AshyIsMe> one liner to count the number of words in a string that start with a capital letter
18:19:20 <Iceland_jack> AshyIsMe: Yes it's quite nice to work with
18:19:30 <Iceland_jack> shows you how powerful composition is
18:20:31 <Iceland_jack> codygman: You may also prefer
18:20:31 <Iceland_jack>       handle (const (return []) ∷ IOException -> IO [String]) $ do
18:21:04 <stephenmac7> :t liftM3
18:21:05 <lambdabot> Monad m => (a1 -> a2 -> a3 -> r) -> m a1 -> m a2 -> m a3 -> m r
18:21:11 <stephenmac7> :t liftA3
18:21:11 <lambdabot> Applicative f => (a -> b -> c -> d) -> f a -> f b -> f c -> f d
18:21:42 <Iceland_jack> :t \f a b c -> f <$> a <*> b <*> c
18:21:43 <lambdabot> Applicative f => (a2 -> a1 -> a -> b) -> f a2 -> f a1 -> f a -> f b
18:22:08 <Iceland_jack> codygman: Does that answer your question?
18:24:21 <charco> Hey, how would you write iterate using foldr? I can't get a clean way to do it I have tried various attempts, but I can only get ugly solutions :(
18:25:03 <AshyIsMe> codygman: cody goodman?
18:26:05 <danilo2> Hi! I've got a question connected to RankNTypes in Haskell. Why in the following example (http://lpaste.net/94506) the function type in line 23 compiles, but the one in line 22 does not? They should be the same in my opinion.
18:29:14 <codygman> AshyIsMe: Yes... I thought that was you
18:29:19 <codygman> funny we both end up doing haskell
18:29:35 <codygman> Iceland_jack: Yes that answers my question, sorry was experimenting with them.
18:30:13 <Iceland_jack> no problem
18:30:43 <ryantrinkle> does anyone have a suggestion for tutorials for a beginner workshop? http://www.meetup.com/NY-Haskell/events/144356872/
18:30:51 <AshyIsMe> codygman: haha yeah, though ive only just started
18:30:58 <ryantrinkle> we've got two "tracks" for participants already set up: Project Euler and Snap
18:31:14 <ryantrinkle> i'd like to add a third - i was thinking video games, but I couldn't find any sufficiently-simple tutorials
18:31:48 <codygman> AshyIsMe: Yeah, I've just started in haskell too. Chap. 8 of Real world haskell and read most of Learn You A Haskell. Some cool stuff is just starting to come together for me :D
18:33:37 <codygman> Which of the haskell web frameworks are most idiomatic haskell? For instance, for python I'd say (and think most would agree) that Flask was more pythonic than Django.
18:35:21 <AshyIsMe> Yesod is the framework im intending on using for my next project once i know haskell well enough
18:35:30 <AshyIsMe> but only because i read the article about warp and it sounds sweet
18:36:04 <carter> codygman: they are all idiomatic
18:37:00 * hackagebot pandoc-citeproc 0.1.2.1 - Supports using pandoc with citeproc  http://hackage.haskell.org/package/pandoc-citeproc-0.1.2.1 (JohnMacFarlane)
18:37:17 <Iceland_jack> You can add {-# LANGUAGE IdiomaticOnly #-} and then non-idiomatic Haskell code won't compile
18:37:23 <codygman> carter: Okay, cool. I just wasn't sure and didn't want to build expertise on one that wasn't (like I did with Django). I was thinking about using Yesod also and reading Yesod and the web (or something like that) after real world haskell.
18:37:41 <carter> codygman: Snap and happstack are also nice
18:37:48 <carter> they'll all different styles
18:37:53 <carter> and all idiomatic haskell
18:38:13 <carter> and honestly, if you really want, its possible to mix and match pieces, because types make it possible
18:38:19 <zomg> codygman: out of curiosity, what is it you found non-pythonic with django?
18:38:26 <carter> though usually its easier to stick with a single lib's ecossyte
18:38:38 <zomg> Not done a whole lot of python stuff so can't really compare for myself =)
18:38:54 <fizruk> danilo2, I think `m' cannot be unified with a polymorphic type (as you intend)
18:39:41 <fizruk> danilo2, I'm not sure what I'm talking about though...
18:40:05 <cschneid> I am working on a set of programming problems. I'd like each to be a separate executable, with a shared lib behind it as I find reusable parts (as the problems build up). Where should I look for an example .cabal?
18:40:09 <danilo2> fizruk: So is there any way to do it? (by "it" I mean replace X (a -> a -> (a,a)) with "F_method1" something)?
18:40:37 <codygman> zomg: Honestly, it's more of a feeling. It could be unfounded, but I feel like there is quite a bit of unneeded complexity. Perhaps I've just had bad luck having to trace bugs through 8 levels of abstraction.
18:41:00 <zomg> codygman: heh, yeah django certainly is more tightly coupled than flask or such
18:41:01 <codygman> Though it can be argued to provide that level of generic with python the complexity is needed.
18:41:46 <codygman> zomg: And I just don't like OOP that much... it's always felt like spaghetti code in separate bowls to me.
18:42:46 <dissipate> codygman, o rly? so everyone doing OOP is an idiot?
18:43:42 <zomg> dissipate: yes, you must be new here
18:43:45 <zomg> ;>
18:43:48 <Iceland_jack> @ty orly
18:43:49 <lambdabot> (y -> a) -> r -> l -> y
18:44:20 <codygman> dissipate: I wasn't saying that. I wouldn't call myself an idiot ;0
18:44:48 <partycoder> spaghetti code can arise in any language
18:45:16 <dissipate> partycoder, spaghetti haskell?
18:45:31 <partycoder> if you want to obfuscate code you can
18:45:58 <partycoder> http://www.haskell.org/haskellwiki/Obfuscation
18:46:09 <fizruk> danilo2, not sure, but try class F_method1 cls sig a | cls a -> sig, sig -> a where ..
18:46:56 <fizruk> danilo2, so you could write (forall a. Show a, ... => m a) -> IO ()
18:48:17 <heatsink> Clean code can arise in any language.  In Haskell, you rarely have to choose between the clean way and the easy way of writing code.
18:48:45 <henk> Is there a parser for date and time who dynamically adjusts to the format? i.e. recognizes unix epoch, iso 8601 in its various formats, unix locale time representation, etc
18:49:08 <danilo2> fizruk: Ok, thank you :) I'll try it out :)
18:49:25 <fizruk> danilo2, I failed to make that work though
18:49:47 <fizruk> danilo2, I'm also not sure what is the problem actually
18:50:14 <danilo2> fizruk: Im not sure too :/
18:50:47 <codygman> dissipate: Why were you trying to turn me into a troll? lol
18:51:18 <danilo2> Anyway - maybe someone will now what is the problem, so I'lll ask one more time :) Why in the following code the typesignature in line 23 compiles and in line 22 not? (http://lpaste.net/94506)
18:52:51 <dissipate> codygman, you were trollin'
18:53:29 <chrisdone> dissipate: https://www.youtube.com/watch?v=Cdiz0k0Rudw
18:53:46 <zomg> gooby pls
18:54:35 <fizruk> danilo2, I thinks I have a clue
18:54:41 <heatsink> danilo2, m uniquely determines a due to the fundep, but you have two as for the same m
18:55:01 <fizruk> heatsink, fundeps are irrelevant here, actually
18:56:51 <danilo2> fizruk: What is the clue? :>
18:57:36 <lpaste> fizruk pasted “Clue 4 danilo2” at http://lpaste.net/94509
18:58:11 <fizruk> danilo2, uuic this is a tiny example of your situation
18:58:54 <danilo2> fizruk: Ok, thnak you :) Im looking inot it right now :)
19:00:01 <lpaste> fizruk annotated “Clue 4 danilo2” with “Clue 4 danilo2 (annotation)” at http://lpaste.net/94509#a94510
19:00:14 <fizruk> danilo2, take a look at the annotation
19:00:28 <fizruk> danilo2, actually that should reveal the problem
19:00:32 <heatsink> annotation looks same to me
19:01:00 <fizruk> heatsink, single-parameter typeclass
19:01:01 <heatsink> Oh, f a became a
19:01:30 <fizruk> heatsink, that makes it clearer that one cannot turn (forall a. Contraint a => a) into any b
19:02:26 <heatsink> right.  It should work if you have a Test b constraint
19:02:27 <danilo2> fizruk: Ok I think I "feel" where is the problem, but I cannot say it precisely :) Anyway - I'll try to rewrite typeclasses and make it working :)
19:03:45 <BigJ2> What is haskell best used for?
19:03:55 <Iceland_jack> BigJ2: A lot of things…
19:04:46 <chrisdone> @faq What is haskell best used for?
19:04:46 <lambdabot> The answer is: Yes! Haskell can do that.
19:05:14 <heatsink> danilo2, where are the class instances that define 'method1' for lines 25 and 26 when you're not using the X data type?
19:06:24 <dissipate> BigJ2, it's best used to feel smug
19:06:27 <danilo2> heatsink: line 19?
19:06:41 <heatsink> line 19 is for X
19:06:54 <Iceland_jack> dissipate: It can do a lot of other things as well :)
19:06:57 <SamuelSF> Newb question.  I know that Haskell was made with ideas drawn from such parts of math as lambda calculus, combinators and category theory, but does proficiency in the language require familiarity with these topics?  I ask because I only have experience with abstract algebra and topology, so while I could study those topics I want to know if it really is requisite.
19:07:05 <heatsink> but if you only want to use the code with X, then you don't need the type class
19:07:44 <Iceland_jack> SamuelSF: This seems to be asked quite a bit, knowledge of them is not needed
19:08:08 <danilo2> heatsink: I know it :) But of course this is only the very simple example. There are other datatypes than X and X is only introduced for this example
19:09:17 <heatsink> SamuelSF, you need to know some lambda calculus, because first-class functions are used all the time.  You don't need to know combinator models of execution or category theory.
19:09:35 <heatsink> You can learn the necessary lambda calculus while you're learning Haskell.
19:09:48 <Iceland_jack> Right, but you don't need to know about the lambda calculus at all
19:10:19 <Iceland_jack> Just like you can use variables, function application and ‘lambda’ in Python without knowing about the lambda calculus
19:10:20 <SamuelSF> Okay.  Right now I'm going I'm learning scheme through SICP, but someone said that someone with my math background would like Haskell.
19:10:46 <codygman> dissipate: you are a trol
19:11:03 <Iceland_jack> SamuelSF: Quite possibly, Haskell allows for interesting abstractions
19:11:03 <triliyn> I remember when I first read about lambdas in python I had no idea what it meant
19:11:23 <triliyn> I looked it up in some docs that just said "introduces a lambda abstraction"
19:11:34 <Iceland_jack> triliyn: hah
19:11:53 <carter> lambdas in python are crippled thogh
19:11:55 <Iceland_jack> lambda: introduces a lambda abstraction
19:11:55 <Iceland_jack> lambda abstraction: what is introduced by lambda
19:12:04 <Iceland_jack> carter: absolutely
19:12:06 <triliyn> And I thought it was some kind of statistical distribution that dealt with complex numbers or something
19:12:31 <eitan> i don't know lambda calculus...is it anything more complicated than \x -> expression involving x?
19:12:35 <SamuelSF> I've been asking questions in the functional language chatrooms and one thing I've noticed is that they're packed fulll of smart people that have good advice, not just in "functional language x" but programming as a whole.
19:12:59 <chrisdone> eitan: no it's very simple. pretty much everything you need to know is on here http://en.wikipedia.org/wiki/Lambda_calculus
19:13:16 <Iceland_jack> eitan: well… you shouldn't be surprised to hear that “yes” it is more complicated if you want to dive deep, but the core calculus is very simple
19:13:55 <heatsink> danilo2, I think what fizruk is pointing out is that the F_method1 instance has to come from somewhere
19:14:12 <Iceland_jack> SamuelSF: If you're interested in learning Haskell really the de facto place to start is Learn You a Haskell:
19:14:12 <Iceland_jack> @where lyah
19:14:12 <lambdabot> http://www.learnyouahaskell.com/
19:14:13 <chrisdone> SamuelSF: SICP seems a solid approach to me
19:14:27 <Iceland_jack> Otherwise SICP is excellent
19:14:31 <eitan> thanks chrisdone and Iceland_jack...I know category theory very well and Haskell seems very natural to me...i never learned lambda calculus and don't understand why it is considered more important than knowing category theory
19:14:35 <heatsink> danilo2, and the more general definition of 'f' says that it works for all sorts of F_method1 types, not just X
19:14:45 <SamuelSF> I've already started with SICP so I'll keep at it.  If I keep switching, everything stays half-done.
19:14:49 <Iceland_jack> eitan: You don't need to know category theory at all to study Haskell
19:14:49 <heatsink> but it doesn't say where to get the instance from
19:15:27 <eitan> Iceland_jack...I knew category theory _before_ I knew Haskell...it's helped me to understand Haskell
19:15:51 <Iceland_jack> Yes I am aware eitan, I just wanted to stress that point
19:15:58 <carter> indeed, category Theory is definitely not needed to usehaskell
19:16:15 <eitan> in what way is lambda calculus needed?
19:16:29 <Iceland_jack> eitan: It's hard to talk about being “needed” here
19:16:36 <heatsink> lambda calculus gives you a high-level computational model for how Haskell executes
19:16:39 <Iceland_jack> If you use function application, are you ‘using’ the lambda calculus?
19:17:10 <Iceland_jack> > (\x -> x * x) 5 -- ← Does this require lambda calculus?
19:17:11 <heatsink> Well, lambda calculus is a set of related models of execution, and Haskell is a special case of it
19:17:12 <lambdabot>   25
19:17:32 <eitan> teehee...thanks lambdabot :-)
19:18:00 <Iceland_jack> The lambda calculus is just a model of computation, you don't need it to learn Haskell but you will probably find it familiar after learning Haskell
19:18:19 <carter> exactly
19:18:25 <eitan> i'd like to skip it and just learn HoTT ;-)
19:18:37 <heatsink> I'd say that, when you figure out that (\x -> x * x) 5 reduces to 5 * 5, you're using some knowledge that's part of lambda calculus
19:18:39 <Iceland_jack> eitan: Sure?
19:18:42 <mgsloan> Kinda like how cartesian closed categories seem kinda familiar after learning haskell :)
19:18:50 <SamuelSF> I wen't to Planet Linux, a local hackerspace.  No one had heard of SICP and several told me that functional languages are overly theoretical and practically useless academic digressions.
19:18:54 <lpaste> fizruk pasted “Working with class... danilo2” at http://lpaste.net/94511
19:19:10 <eitan> i probably know lambda calculus without knowing that i know it :-/
19:19:15 <fizruk> danilo2, ok this is how you can patch your paste ^
19:19:38 <ReinH> heatsink: you mean beta reduction? :)
19:19:44 <heatsink> yes
19:20:04 <Iceland_jack> heatsink: Sure, but to what extent? People who add two numbers are using groups ‘without knowing’, but it's utterly meaningless to make to point
19:20:10 <eitan> what is a good rigorous math source for lambda calculus?
19:20:16 <Iceland_jack> *to make that point
19:20:56 <ReinH> Iceland_jack: well, to be fair, people who concatenate strings and add numbers start to get a very basic intuition for group-like structures
19:21:15 <Cale> eitan: HoTT is a lambda calculus.
19:21:17 <eitan> string concatenation is not a group operation...no inverses ;-)
19:21:27 <fizruk> I personally found myself understanding lambdas when reading Pierce's "Types and programming languages"
19:21:44 <ReinH> anyone who's used foldr a bit has probably gotten some intuition for free monoid homomorphisms, etc
19:21:46 <Cale> eitan: Depends on what kind of perspective you want on it.
19:21:47 <Iceland_jack> Yes but bringing groups into it is just an odd thing, since it's like asking “do you need to understand abstract algebra to add two numbers”
19:22:04 <heatsink> Iceland_jack, I never studied lambda calculus per se, but after learning Haskell I could read theoretical CS papers that use lambda calculus.  So I acquired a working knowledge of lambda calculus by learning Haskell.
19:22:10 <ReinH> Iceland_jack: sure, but it's a nice way to introduce the subjects
19:22:13 <Iceland_jack> Yes exactly
19:22:20 <Cale> eitan: You could, for instance, get a certain view on it from the chapter in Awodey's Category Theory on Cartesian closed categories.
19:22:38 <Cale> eitan: There's TaPL which gives the traditional PL view
19:22:48 <eitan> ooo...that sounds like the right title for me...thanks Cale
19:22:54 <heatsink> So is it really that far off to say that knowing lambda calculus is part of knowing how to use Haskell?
19:22:54 <Iceland_jack> it makes newbies confuesed and wonder if they really need to study λc and ct before doing a “hello world” in Haskell and makes non-Haskellers make bad jokes about category theory and monads
19:23:06 <ReinH> Cale: btw I just got Serge Lang's Algebra
19:23:12 <ReinH> Cale: I really like his presentation
19:23:24 <Iceland_jack> heatsink: In the same way that ‘monoids’ and ‘groups’ and ‘fields’ are a part of basic arithmetic
19:23:29 <Cale> If you want a big tome, I've heard Barendregt is pretty comprehensive
19:23:31 <Iceland_jack> well, that's not completely accurate
19:23:39 <Cale> ReinH: cool
19:23:46 <Cale> I haven't read Lang's algebra.
19:23:49 <eitan> serge lang's algebra is good
19:23:59 <Cale> But I've heard good things about it.
19:24:00 <eitan> no one's read the whole book...it's massive
19:24:06 <ReinH> yeah it's a door stopper
19:24:15 <eitan> i read the part on spectral sequences
19:24:22 <ReinH> but it's almost like an ornithological catalogue of algebraic structues
19:24:36 <Cale> I'm pretty sure that Lang has read it
19:24:37 <ReinH> "and here we have the red-breasted seminearring"
19:24:47 <Iceland_jack> heh
19:24:48 <eitan> lol ReinH
19:24:49 <ReinH> "in its native habitat"
19:24:49 <ReinH> etc
19:25:18 <Iceland_jack> “The abelian group approaches the baby ringlings: …”
19:25:25 <ReinH> lmao
19:25:29 <eitan> :-D
19:25:40 <fizruk> hmm... is there an "algebra for a computer scientist" or something?
19:25:45 <carter> eitan: Cale  i'm kinda bleh about langs writing for learning algebra
19:25:53 <ReinH> "We must be very quiet now. We don't want to disturb the trace monoid."
19:25:53 <carter> its a great refernce once you have the vocab
19:26:22 <ReinH> carter: what do you prefer?
19:26:25 <carter> hrm
19:26:29 <Cale> Like, what structures does Lang's algebra talk about that you wouldn't find in any other commutative algebra text?
19:26:47 <eitan> cale: spectral sequences!
19:27:00 <carter> the algebra book by the mit guy seems to have lots of neat examples
19:27:02 <carter> though i never read it
19:27:11 <carter> lemme pull out my pile of algebra tomes
19:27:12 <carter> hangon
19:27:16 <eitan> is that michael artin?
19:27:25 <eitan> i don't remember what text i used for algebra
19:27:30 <eitan> i think just class notes
19:27:39 * Iceland_jack would watch a ‘nature’ series on algebraic structures 
19:27:44 <eitan> best algebra book in my opinion is Atiyah's Commutative Algebra
19:27:45 <SamuelSF> There's a very nice book that doesn't get much notice.  Algebra Chapter 0 by Paolo Alluffi.
19:27:56 <eitan> but that's pretty focused on just commutative algebra
19:28:36 <SamuelSF> It's a good intro to algebra, but it presents everything from a category theoretic perspective from the start.
19:29:01 <ReinH> Iceland_jack: yes please
19:29:23 * ReinH adds to his book list
19:29:33 <eitan> Cale: I don't see Awodey's lambda calc book...just "Category Theory"
19:30:10 <Dodek> i read chapters about field and galois theory in aluffi's book and found them to be very good
19:30:55 <Cale> eitan: Category Theory discusses lambda calculus a bit
19:31:08 <Cale> (that's what I was referring to)
19:31:29 <Cale> It's not a whole lot, just basically STLC from a categorical perspective
19:32:14 <fizruk> what's STLC?
19:32:19 <eitan> simply typed?
19:32:30 <danharaj> I wonder
19:32:36 <eitan> hi dan ;-)
19:32:39 <danharaj> yeah
19:32:45 <danharaj> there's only like 3 eitans outside of Israel
19:32:51 <danharaj> :P
19:33:04 <eitan> how do you know i'm outside of israel
19:33:26 <danharaj> I checked your hostname.
19:33:31 <carter> eitan: yeah, artin
19:33:33 <carter> i don't have a copy
19:33:42 <carter> eitan: i think i have atiyah
19:33:51 <eitan> atiyah is great...hard but great
19:34:25 <carter> what the goal you have in mind is also important too
19:34:42 <eitan> so dan...i heard you sold your btc...a couple weeks ago :-o
19:35:01 <danharaj> yeah
19:35:06 <danharaj> I decided it wasn't worth the cognitive effort.
19:35:12 <carter> good call
19:35:44 <danharaj> BTW Mac Lane and Birkhoff have a great undergrad algebra book.
19:35:58 <danharaj> The only problem is that it doesn't have enough hard exercises.
19:36:24 <eitan> at stony there was a pretty good undergrad alg text...don't remember the authors but i tutored one kid on it and thought it looked real good
19:36:33 <eitan> was that mac lane/birkhoff?
19:36:37 <danharaj> I don't think so.
19:36:58 <carter> i'll skim my epic pile of  books to have an opinion… may take a few weeks to have an opinion again. https://alpha.app.net/cartazio/post/13138233/photo/1 might take a while to have opinions again
19:37:02 <danharaj> I didn't actually attend that class even though I enrolled in it :P
19:37:11 <carter> i did really enjoy reading hungerfod
19:37:14 <carter> *hungerford
19:37:16 <eitan> lol
19:37:27 <eitan> carter...you mean hunger games?
19:37:32 <carter> nah
19:37:44 <carter> eitan: i have an excuse: i've hit the point in my own projects where I need a sane numerical prelude
19:37:52 <carter> or i can't give the correct safe interfaces to my code
19:37:56 <danharaj> Mac Lane Birkhoff is good because it emphasizes universal properties immediately and has a chapter on category theory.
19:38:03 <carter> maclanes is nice too
19:38:06 <carter> its very accessible
19:38:10 <carter> and concrete yet modernish
19:38:13 <carter> despite its relative age
19:38:16 <eitan> which prelude do you like carter?
19:38:25 <carter> eitan: none of them currently
19:38:37 <eitan> what features do you need?
19:38:45 <eitan> or what typeclasses?
19:38:51 <eitan> euclidean domain?
19:38:54 <carter> YES
19:38:55 <carter> that
19:39:06 <carter> Enum being a parent of Integral pushed me over the edge
19:39:19 <eitan> YAP has euclidean domains
19:39:27 <carter> @hackage yap
19:39:27 <lambdabot> http://hackage.haskell.org/package/yap
19:39:51 <carter> oh
19:39:52 <carter> sweet
19:39:55 <carter> maybe i'll start with that
19:39:59 <carter> to defer my yak shaving
19:40:04 <danharaj> If you use a nonstandard prelude
19:40:04 <eitan> yeah...yap is pretty reasonably organized
19:40:09 <danharaj> I will never use your package.
19:40:18 <intrados> I'm using tables (http://hackage.haskell.org/package/tables-0.2/docs/Data-Table.html) which is based on lens. I can't figure out how to get it to return only a subset of the fields (effectively a SELECT a, b FROM ...)
19:40:20 <carter> danharaj: well, you're not doing any math right now
19:40:22 <carter> so i don't care
19:40:24 <eitan> dan...why is that?
19:40:27 <carter> danharaj: i'm writing math tools
19:40:30 <danharaj> eitan: Because it is a massive pain.
19:40:36 <eitan> carter...what kind of tools?
19:40:41 <danharaj> carter: I would be doing math in Idris or Agda.
19:40:45 <danharaj> or in a DSL
19:40:47 <carter> danharaj: then you're not doing numerical math
19:40:53 <carter> i want to have nice tools in haskell
19:40:59 <eitan> dan...why is it such a pain?
19:41:11 <eitan> does it force you to use the same prelude?
19:41:15 <danharaj> eitan: Because it is hard to integrate other libraries with a new prelude.
19:41:24 <danharaj> or at the very best unknown how well it integrates.
19:41:32 <eitan> can't you just import it qualified?
19:41:39 <danharaj> I could but then I am angry.
19:41:44 <danharaj> Because I have yet another namespace to care about.
19:41:50 <carter> well, if you're doing numerical math
19:41:55 <carter> you'll get angry at the current prelude
19:41:57 <eitan> plus...why would he export the functions from that prelude in his library?
19:42:05 <carter> indeed, i wont
19:42:21 <danharaj> eitan: well it stands to reason if I'm using his library it will idiomatically best be served by the prelude it uses.
19:42:27 <carter> danharaj: nope
19:42:40 <danharaj> so you're going to give me an interface that uses another prelude
19:42:40 <carter> thats a different issue
19:42:52 <carter> i'm not doing another prelude
19:43:04 <carter> just not using the numerical classes in the standard one because they're horribly wrong
19:43:20 <eitan> they are very wrong, it's true
19:43:21 <danharaj> fair enough
19:43:42 <eitan> yap is nice because it's right without going way overboard
19:43:53 <carter> like,  i think currently you can't really even use complex rationals currently
19:44:20 <carter> eitan: i'll stare at yap and see if its
19:44:23 <carter> right
19:44:31 <carter> at the very least, i want to for now, not do much more than what Yap does
19:44:51 <carter> and only refine / break things further as i have need of it in actual code
19:44:54 <eitan> carter: what kind of numerical work are you doing
19:45:12 <carter> eitan: i want a numerical array / linear algebra substrate thats nice AND fast
19:45:41 <carter> and usable
19:45:43 <eitan> cool
19:45:46 <carter> and extensible
19:45:57 <carter> i've spent much of the past year figuring out some of the performance story
19:46:08 <carter> now i'm just playing wack-a-mole on the api polish
19:46:54 <eitan> i see
19:47:24 <carter> like, i have a nice story for making reasoning about memory locality pretty nice
19:48:54 <Twey> http://lpaste.net/94514 — why doesn't this unify?  monoidal said it would be okay on GHC 7.7, but that doesn't seem to be the case (at least with 7.7.20130809)
19:49:18 <carter> eitan: lol NOP, yap has the problem :(
19:49:21 <wagle> @hoogle join
19:49:21 <lambdabot> Control.Monad join :: Monad m => m (m a) -> m a
19:49:21 <lambdabot> package join
19:49:21 <lambdabot> System.FilePath.Windows joinDrive :: FilePath -> FilePath -> FilePath
19:49:28 <carter>  http://hackage.haskell.org/package/yap-0.2/docs/Prelude-YAP.html#t:Integral
19:49:35 <carter> Integral is busted on YAP
19:50:11 <carter> :(
19:50:23 <carter> well
19:50:24 <carter> hrmm
19:50:25 <wagle> where do I find the join for lists?
19:50:43 <danharaj> :t join
19:50:44 <lambdabot> Monad m => m (m a) -> m a
19:50:47 <carter> well, hrmmm
19:50:47 <fizruk> @src [] join
19:50:47 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
19:50:49 <danharaj> > join [[1]]
19:50:50 <lambdabot>   [1]
19:51:00 <wagle> google is no help, and I dont know how to focus hoogle
19:51:05 <carter> i guess i could use euclideandomain
19:51:06 <carter> hrmmm
19:51:07 <carter> yay
19:51:25 <wagle> @src join
19:51:25 <lambdabot> join x =  x >>= id
19:51:29 <Twey> > join [[1], [2, 3], [4, 5]] -- wagle
19:51:29 <fizruk> > join [[1 2] [3 4]]
19:51:30 <lambdabot>   [1,2,3,4,5]
19:51:31 <lambdabot>   can't find file: L.hs
19:51:39 <wagle> ohhh, noow i remember
19:51:44 <carter> eitan: thanks!
19:52:19 <wagle> didnt know what package it was in, though
19:52:59 <wagle> nm, i thnk i'm set now
19:53:17 <eitan> carter: you're welcome...what for?
19:53:29 <carter> eitan: I can use EuclideanDomain instaed of Integral
19:53:40 <eitan> ahh...great
19:53:47 <carter> i need to think about this more too
19:53:52 <eitan> i needed EuclideanDomain too...
19:55:27 <carter> oh
19:55:31 <carter> what'd you use it for?
19:56:29 <eitan> some elliptic curve cryptography...a learning project...i'm still a bit of a noob...
19:56:31 <heatsink> What kind of array performance characteristics are you going for?
19:56:50 <danharaj> 12
19:57:05 <carter> heatsink: nearly as fast as hand tuned assembly is the ultimatel goal
19:57:24 <carter> within 5x of that robustly with care  is the near term goal
19:57:37 <heatsink> With an IO/ST interface?
19:57:39 <ReinH> carter: :)
19:57:46 <t4nk117> hi, sorry the the basic question but I am still learning Haskell.. is it possible to pattern match types which derive a certain class (e.g Show) so that I can use that in my func? e.g myFunc a = show a ?
19:57:47 <carter> heatsink: yes, that too
19:57:54 <carter> both imperative and pure interfaces
19:58:11 <ReinH> t4nk117: you don't pattern match types, you pattern match values.
19:58:12 <carter> also i have some stuff that i think is kinda like a final ecoding, so you could have multiple backends
19:58:13 <heatsink> That's a pretty tough target
19:58:20 <ReinH> t4nk117: your type signature can have constraints
19:58:22 <carter> heatsink: i've been kinda working on this for > 1 year
19:58:28 <carter> nearly 2  at this point
19:58:43 <carter> hard part was figuring out the right memory locality story
19:58:45 <carter> and associated api story
19:58:53 <ReinH> myFunc :: Show a => a -> b -- or whatnot
19:58:57 <t4nk117> ReinH: right, I tried to declare it like this: printMaybe2 :: Maybe (Show a) -> IO ()
19:59:05 <carter> ReinH: i'm slowly hacking on it
19:59:07 <carter> :)
19:59:10 <carter> making monotoinci progress
19:59:19 <ReinH> t4nk117: printMaybe2 :: Show a => Maybe a -> IO ()
19:59:22 <liftM> printMaybe2 :: Show a => Maybe a -> IO ()
19:59:41 <ReinH> t4nk117: http://www.haskell.org/tutorial/classes.html
19:59:50 <heatsink> I wish we could reduce the set of useful array types in Haskell
20:00:05 <ReinH> carter: :D glad to hear that you are not regressing
20:00:11 <heatsink> we have some types in Data.Array, some in Data.Vector, ByteString
20:00:14 <t4nk117> thanks guys, will do some more reading
20:00:23 <carter> heatsink: nope
20:00:29 <carter> different design constraints
20:00:38 <carter> theres no one true array api
20:00:51 <ReinH> heatsink: carter's array library brings them all and in the darkness binds them
20:00:53 <ReinH> carter: shhh
20:01:03 <ReinH> probably via unsafeCoerce
20:01:18 <carter> ReinH:  I only have one unsafeCoerce so far
20:01:20 <carter> :)
20:01:23 <ReinH> carter: not bad!
20:01:35 <heatsink> haha
20:02:22 <carter> i did use unsafeDupablePerformIO  in a consulting  project last week :)
20:02:32 <carter> in a totally safe way mind you
20:02:32 <ReinH> carter: btw I've got a couple brand new nvidia 760s to play with gpu stuff :D
20:02:43 <carter> ReinH: i'm still a few months away from gpu stuff at the soonest
20:02:46 <ReinH> carter: ostensibly these are powering a gaming computer, but I think we know the real reason
20:02:48 <triliyn> unsafePerformIO is nice for printing debug messages
20:03:02 <ReinH> triliyn: why not use Debug.Trace ?
20:03:03 <carter> ReinH: a bewulf cluster of games?
20:03:19 <triliyn> ReinH: haven't heard of it; I might look it up
20:03:20 <carter> yeah… don't do unsafePerformIO for debug messages
20:03:26 <carter> thats actually not going to help
20:03:29 <triliyn> I don't really do a lot of debug messages anyway though
20:03:39 <carter> thats a code smell like a tire fire is a bad smell
20:04:01 <ReinH> Debug.Trace lets you print stuff in unsafe ways without crashing your program
20:04:36 <triliyn> Can unsafePerformIO crash when it's just printing to stdout?
20:05:11 <heatsink> carter, do you know if there's been any progress toward making concatMap fast?
20:05:25 <carter> heatsink: whats you actual goal?
20:05:39 <carter> you probably want to use Builder or something
20:05:43 <ReinH> triliyn: probably
20:06:04 <carter> triliyn: also if you're not using unsafePerformIO right, it could lie
20:06:33 <carter> triliyn: do you know the rules for safely using unsafePerformIO?
20:07:09 * hackagebot whois 1.1.0 - WHOIS client library.  http://hackage.haskell.org/package/whois-1.1.0 (RickyElrod)
20:07:26 <triliyn> carter: I've seen them in passing, but I've actually never used it in this context, I just showed it to a friend who wanted debug messages
20:07:40 <triliyn> Looking at Debug.Trace now to show her
20:07:44 <carter> triliyn: very very vad role model you are
20:07:53 <triliyn> Clearly!
20:08:16 <ReinH> triliyn: bad triliyn, no cookie for you
20:08:31 <elliott> Debug.Trace is useful
20:08:42 <ReinH> elliott: it sure is
20:08:44 <heatsink> Well, one issue I've seen is that the "nested loop that builds a histogram" pattern is hard to write efficiently in higher-order function style
20:08:49 <heatsink>  I've been working on some parallel compiler stuff.
20:09:02 <carter> well, don't use lists :)
20:09:05 <carter> is step one
20:09:24 <heatsink> For instance, histogram 20 [f x y | (x:ys) <- tails xs, y <- ys]
20:09:47 <ReinH> elliott: I just don't understand why it doesn't ship with a "show and print this and then return it", i.e. \x -> traceShow x x
20:09:48 <carter> don't use lists
20:09:50 <ReinH> elliott: since I ALWAYS write this
20:09:57 <elliott> ReinH: because nobody can agree on a name
20:10:00 <carter> lists are wrong for parallelism
20:10:03 <ReinH> at least you can use join traceShow
20:10:17 <carter> and fusion is not always usefull
20:10:20 <carter> sometimes fusion is bad
20:10:25 <ReinH> elliott: something something tee
20:10:53 <ReinH> fair enough, I don't have a name I'm happy with either
20:10:59 <ReinH> I usually call it `tracing'
20:11:59 <heatsink> I can get pretty efficient code by using forM_ and mutable arrays.
20:12:09 <heatsink> And histogram privatization if I want parallelism.
20:12:13 <carter> ok
20:12:14 <heatsink> But then I'm basically writing C code in Haskell
20:12:20 <carter> wel
20:12:31 <triliyn> carter: out of curiosity, are there any simple examples of cases where fusion is bad?
20:12:38 <carter> matrix multiplication
20:12:39 <carter> done
20:12:54 <ReinH> heatsink: not really, you still have well encapsulated effects
20:12:55 <carter> fusion only really works well and reliably for pointwise operations
20:13:00 <ReinH> heatsink: especially with ST
20:13:10 <heatsink> Repa has a matrix multiplication example
20:13:13 <carter> nope
20:13:18 <carter> crap locality
20:13:21 <carter> and can't fuse
20:13:21 <heatsink> ah
20:13:37 <heatsink> Their fusion is based on representing loops as functions from array index to value
20:13:38 <carter> heatsink: let me clarify
20:13:51 <carter> its an example of writing code in repa
20:13:57 <carter> but not an example of repa fusing
20:14:07 <heatsink> ok
20:14:39 <heatsink> So why is matrix multiplication fusion bad?
20:14:45 <carter> thers IS no fusion
20:14:46 <carter> none
20:14:48 <carter> zero
20:14:52 <carter> its just written in reap
20:14:53 <ReinH> zilch
20:14:54 <carter> repa
20:14:55 <ReinH> nada
20:15:04 <carter> Just Nothing
20:15:05 <ReinH> I'm helping.
20:15:10 <carter> Maybe Maybe Void
20:15:25 <carter> Maybe (Maybe Void )
20:15:46 <carter> heatsink: its an example of parallel dot product
20:15:47 <carter> not fusion
20:15:56 <triliyn> MaybeT Maybe Void
20:15:59 <carter> REPA is a show case for parallelism + fusion search
20:16:00 <carter> thankes
20:16:41 <carter> triliyn: :)
20:17:43 <carter> point being: fusion only makes sense for pointwise things
20:17:49 <carter> parallism is handy for matrix mult
20:17:51 <carter> but not fusion
20:17:53 <triliyn> (I recently played with monad transformers and now I'm not hopelessly confused about them! Though I did get a compilation-time crash that vanished on my next attempt)
20:17:54 <triliyn> hmm
20:18:08 <triliyn> That's not fusion being bad though, is it? It just can't do anything good
20:18:45 <triliyn> Or maybe I don't understand what you mean, in which case I should just stop following this thread until I read more about what fusion actually is
20:18:52 <carter> triliyn: too much fusion = your code is too big
20:19:17 <heatsink> If I understand what you mean by pointwise fusion, then filter/filter fusion isn't pointwise
20:19:22 <carter> nope
20:19:24 <carter> but its related
20:19:33 <triliyn> In terms of executable size?
20:19:36 <carter> your'e talking about series fusion?
20:19:45 <heatsink> filter f . filter g
20:19:51 <carter> oh
20:19:52 <carter> thats pointwise
20:20:25 <heatsink> Then I don't understand.  What do you mean by pointwise?
20:20:41 <carter> the predicate acts on points
20:20:58 <sclv> you don't have something e.g. summing together every element of the list
20:21:05 <carter> filter fusion just gives you \x -> ( g x  && f x)
20:21:12 <sclv> so you can define it via a traversal order
20:21:34 <carter> yeah
20:21:46 <carter> matrix mult, each result element is reading 2n inputs
20:22:14 <heatsink> Okay, so the pointwise operation is relevant because you can slice the work into independent input-to-output transformations?
20:22:18 <carter> yes
20:22:31 <carter> well, thats part of it
20:23:52 <triliyn> Is "fusion" just a shortening of "stream fusion" or is there a difference?
20:24:05 <heatsink> Stream fusion is a specific way of doing fusion
20:24:17 <triliyn> hmmm, okay
20:24:29 <triliyn> That makes sense
20:24:29 <heatsink> You're referring to dcoutts's paper, right?
20:24:52 <triliyn> I don't remember exactly whose paper it was, but the only thing I've read about fusion was some "generalized stream fusion" thing
20:25:12 <triliyn> Which was about using bundles of several different stream representations instead of a single stream
20:25:15 <carter> theres a few others
20:25:18 <carter> oh
20:25:23 <heatsink> Oh, the Haskell Beats C paper
20:25:28 <triliyn> Yeah
20:25:33 <carter> i'm meh about that paper
20:25:41 <carter> because it doesn't actually address teh important issues
20:25:46 <carter> at least for any intersting algs
20:25:52 <carter> its still essentially pointwise fusion
20:25:55 <carter> just vectorized ish
20:25:59 <carter> and not usable currently
20:26:10 <triliyn> oh, it's not usable?
20:26:11 <carter> even in 7.8 it wont' be correct / safe
20:26:14 <carter> yes
20:26:16 <carter> if you used it
20:26:22 <triliyn> I didn't use it
20:26:23 <carter> you'd not be able to have ANY code built with -fasm
20:26:37 <carter> because only the LLVM backend currently has  SIMD support
20:26:37 <heatsink> oh my
20:26:42 <triliyn> But the paper said haskell could do it so I kind of assumed it was like 10 years old and the things discussed were standard
20:26:55 <carter> triliyn: it can beat C
20:27:02 <carter> just
20:27:08 <carter> theres more interesting / general ways to do it
20:27:19 <carter> provide the abstractions that robustly give good perf
20:27:21 <triliyn> Well I mean, the paper said haskell could use generalized stream fusion
20:27:25 <carter> yes
20:27:27 <heatsink> What are the stream fusion issues you're interested in?
20:27:28 <carter> i don't care about that
20:27:35 <carter> i think fusion is missing the point
20:27:38 <carter> its one tool
20:27:44 <carter> thats mostly useless for algs i care about
20:27:45 <carter> :)
20:28:03 <carter> doesn't help me with any alg that uses sparse or dense matrix mult
20:28:08 <triliyn> I'm not actually interested in stream fusion issues, I was just reading things and I found this one paper that left me woefully ignorant of what exactly fusion is in the general case
20:28:14 <carter> oh
20:28:20 <carter> fusion is just a way of simplifying compositions
20:28:27 <carter> eg map f . map g = map (f. g)
20:28:33 <carter> is one fusion
20:28:41 <triliyn> Right
20:28:49 <carter> thats essentially ALL stream fusion is
20:28:50 <carter> roughly
20:28:52 <carter> theres a bit mroe going on
20:29:03 <carter> i'm over simplifying
20:29:13 <triliyn> My friend was kind of interested in where fusion is likely to occur in GHC
20:29:17 <carter> well
20:29:21 <carter> he shoudl explore !
20:29:23 <triliyn> And that made me curious too so I started looking into it
20:29:28 <carter> you should to
20:29:37 <carter> if you see spots where it should happen and it doesn
20:29:38 <triliyn> Yeah, I plan to continue :)
20:29:42 <carter> or where it does, and shouldn't
20:29:45 <carter> report bugs!
20:29:45 <carter> :)
20:29:47 <carter> to ghc
20:29:54 <carter> inlining can be a win
20:29:56 <carter> but it can be bad too
20:30:22 <triliyn> The only drawback of inlining is code size, right? And I guess it can fool debuggers maybe
20:30:54 <carter> well
20:30:59 <carter> its not always a win
20:30:59 <triliyn> oh, and maybe it recomputes things that might not need to be recomputed?
20:31:16 <carter> that too
20:31:23 <carter> or prevents a higher level simplification from happening
20:32:33 <carter> you're asking a question about an area of active applied research spanning 20+ years
20:32:41 <carter> theres no "one true simple trade offs"
20:32:41 <carter> :)
20:32:49 <triliyn> Yeah, I'm starting to see how many different situations there might be
20:33:18 <heatsink> The biggest benefit of inlining is that it can enable other optimizations.  But it's hard to detect which inlining cases will enable optimizations
20:33:28 <carter> and it won't always
20:33:55 <heatsink> yeah
20:34:07 <carter> eg: i think dolio wishes his vector-algorithms lib didn't need to inline like crazy, but currently its the only way he can give it predictably good perf
20:34:23 <carter> but it also means epic compilation + code size blow ups afaict
20:34:50 <carter> next time you build a lib by Bos or someone else, and it takes a while, inlining may be a culprit
20:35:03 <triliyn> hmmm
20:35:43 <heatsink> Hmm, it seems like vector-algorithms would benefit if you could get GHC to monomorphise, rather than inline
20:36:04 <heatsink> so if you have three places where you sort a vector of Foo, you'd get one optimized copy of the code instead of three
20:36:26 <heatsink> I mean specialize instead of inline
20:36:47 <heatsink> Does dense and sparse matrix multiplication just have to be implemented as a family of library functions for each scalar type, or is there more to it?
20:37:00 <carter> depends
20:37:09 <carter> "does all of math just need to be designed one way or another"
20:37:13 * hackagebot whois 1.1.1 - WHOIS client library.  http://hackage.haskell.org/package/whois-1.1.1 (RickyElrod)
20:37:26 <carter> heatsink: specialize currently is only possible if you're got a type class interface
20:37:31 <carter> not for stand alone functions
20:37:56 <carter> and you can only add specialize instances if a function is INLINEABLE
20:38:01 <carter> heatsink: you do have the right idea
20:38:17 <carter> better shared monomorphization support would solve many inlining use cases
20:38:18 <sclv> carter: ad-hoc specialize pragmas on functions seem super useful
20:38:21 <heatsink> I see
20:38:25 <carter> sclv: agreed
20:38:30 <sclv> carter: add it to modest ghc proposals!
20:38:43 <carter> sclv: yeah, its simpler than my ABI idea
20:38:47 <carter> is there a list?
20:38:54 <carter> i'm pretty sure theres a trac ticket
20:39:03 <sclv> yeah you created the page remember http://www.haskell.org/haskellwiki/Modest_GHC_Proposals
20:39:04 <carter> heatsink: if you want to help work on that for 7.10, i'd be happy to try to help out
20:39:42 <carter> k
20:39:44 <carter> i'll add it
20:39:53 <carter> plus my ABI  experimentation stuff
20:40:01 <heatsink> I might come back to that
20:40:40 <carter> heatsink: i'm happy to help cheerlead  / be an extra head to mull it over with
20:40:48 <carter> i've a lot of other ghc things i want to try and do as i have time
20:40:53 <heatsink> thanks
20:41:18 <carter> but luring people into getting involved is apparently something i'm good at, see the blurb austin wrote here  http://ghc.haskell.org/trac/ghc/wiki/Status/Oct13 :)
20:41:19 <carter> about me
20:41:35 <carter> heatsink: you don't have to figure out the design
20:41:47 <carter> we just need a warm body to make it so :)
20:42:01 <carter> because theres so much different ways GHC needs more awesome
20:42:10 <carter> that idk if i'tll happen in the next year without someone owning
20:42:11 <carter> it
20:42:41 <heatsink> Oh, that's nice.  Stuff involving cross-file interfaces tends to touch a lot of places in a compiler, I wouldn't want to figure that out myself.
20:43:05 <heatsink> I expect to have time for a project in a month
20:43:11 <carter> heatsink: sweet
20:43:15 <heatsink> a month from now, I mean
20:43:19 <carter> cool
20:43:28 <carter> are you a student or ?
20:43:33 <heatsink> yeah
20:43:37 <carter> grad?
20:43:56 <carter> we have a really cool hs student helping a lot on ghc right now
20:43:57 <heatsink> yup.  I've been working on parallel compiler stuff
20:44:01 <carter> neat
20:44:11 <carter> another project i want to help figure out
20:44:11 <heatsink> You're hooking 'em early
20:44:18 <carter> is better numa support in ghc
20:44:24 <carter> i've some silly rough ideas
20:44:35 <carter> but I want to make it easier to do locality aware parallel code
20:44:55 <heatsink> That's kinda tricky to recruit for if you don't have a numa machine you can share
20:45:07 <carter> yeah
20:45:11 <carter> well
20:45:20 <wagle> woo!  a continuation!
20:45:23 <carter> i think i know a few folks who would be happy to donate time
20:45:31 <heatsink> awesome
20:46:19 <carter> but i think that one could be first done by writing a user land binding for hwloc http://www.open-mpi.org/projects/hwloc/
20:46:25 <carter> and playing with ideas user land
20:46:36 <carter> and then figure out how to experiment with adding that knowledge to ghc itself
20:46:41 <carter> hwloc seems pretty neat
20:47:11 <carter> heatsink step 1: start lurking on #ghc
20:47:12 <carter> :)
20:47:13 <carter> step 2
20:47:15 <carter> umm
20:47:23 <carter> we should figre that out when you have more time :)
20:47:33 <Kaidelong> I have some experience with the haskell-mpi binding
20:47:35 <heatsink> alright
20:47:38 <carter> Kaidelong: oh?
20:47:40 <Kaidelong> if that is relevant at all
20:47:43 <carter> idk
20:47:47 <monochrom> use laziness. step 2 and more will be figured out after finishing step 1.
20:47:52 <wagle> is there a (design?) pattern for traversing a list, labeling each element uniquely, then returning the newlist and the last unused label?
20:47:53 <carter> mpi is its own thing
20:48:12 <carter> wagle: use numbers or something else you can "increment"
20:48:13 <carter> :)
20:48:19 <carter> as your labels
20:48:23 <Kaidelong> haskell-mpi is actually pretty neat if you want to do distributed computing
20:48:25 <carter> Integer maybe
20:48:29 <carter> Kaidelong: huh
20:48:35 <carter> i think the hwloc stuff is its own self contained thing
20:48:41 <carter> @hackage haskell-mpi
20:48:41 <lambdabot> http://hackage.haskell.org/package/haskell-mpi
20:49:12 <wagle> right, i mean Int -> [Item] -> (Int,[Item])
20:49:34 <carter> folds!
20:49:57 <carter> wagle: you want (Int , [(Int,Item)])
20:50:10 <wagle> i want to foldl, but return the final result with the list
20:50:26 <wagle> right, sorry, I meant that
20:50:27 <monochrom> you may like mapAccumL
20:50:41 <wagle> hmm...
20:50:50 * wagle looks for mapAccumL
20:51:00 <fizruk> :t mapAccumL
20:51:00 <lambdabot> (acc -> x -> (acc, y)) -> acc -> [x] -> (acc, [y])
20:51:23 <heatsink> Do you know if HdpH is being used, or just in the proof-of-concept stage
20:51:37 <carter> its missing the point
20:51:40 <carter> toooooooo general
20:51:53 <carter> its a really really really really ambitious research program
20:51:55 <triliyn> HdpH?
20:51:57 <carter> they've been doing for a few years
20:52:00 <carter> DPH
20:52:06 <triliyn> oh, data parallel haskell?
20:52:07 <carter> data parallel haskell
20:52:15 <Kaidelong> that's a whole other compiler too
20:52:29 <carter> DPH is in ghc….
20:52:31 <heatsink> Oh, DPH is not the same as HdpH
20:52:41 <Kaidelong> oh it is? I thought it was a fork of GHC
20:52:45 <carter> nope
20:52:54 <Kaidelong> that's nice then
20:53:30 <buckmaster> any Yampa users out there?
20:53:40 <Kaidelong> one sneaky approach to data parallelism I liked was DSH which actually doesn't provide any at all but relies on SQL servers working like that in their implementation
20:53:47 <heatsink> HdpH is a library for distributed Haskell.  Their main thing is making it easy to move data and tasks from one node to another
20:53:51 <Kaidelong> by turning haskell code into SQL queries
20:55:09 <heatsink> Is that really practical?
20:55:35 <heatsink> carter, were you commenting about DPH or HdpH?
20:55:40 <carter> heatsink: my stance on DPH the haskell lib / research project / ghc thingy
20:55:49 <heatsink> ok, yeah
20:55:54 <heatsink> That's my impression too
20:56:01 <carter> is that the moment you need to have a research projgram to optimize your DSL
20:56:06 <carter> your DSL isn't helping you
20:56:14 <Kaidelong> http://hackage.haskell.org/package/DSH
20:56:19 <carter> its tooo darn general
20:56:23 <carter> i just want to write math thats fast
20:56:36 <carter> and have explainable, predictable, optimizable performance
20:57:08 <heatsink> the vectorization approach is appropriate for a small class of programs, but for many programs it ends up making stupid parallelization decisions that are hard to fix with subsequent optimizations.
20:57:16 <carter> yeah
20:57:22 <frase> hi #haskell ; what is the defacto standard time library in Hackage (if there is one)?  For basic stuff like construct construct UTC from Num seconds from epoch, compare two times, et cetera?
20:57:50 <carter> heatsink: i also don't like auto vecotrization for a very simple reason: it doesn't let me use SIMD reigsters a sort of L0  cache
20:58:11 <carter> i've got some toy examples where i get a 1.5x perf boost from that versus pointwise C code
20:58:16 <carter> when i used simd intrinsics
20:58:16 <Kaidelong> there's "thyme", and then there was the time library in the haskell platform which I think is just "time"
20:58:17 <heatsink> I don't remember which one is the standard now.  Data.Time maybe?
20:58:23 <carter> heatsink: another project i want to do
20:58:29 <carter> is add support for SIMD shuffles in a type safe way
20:58:42 <Kaidelong> apparently you should use thyme as it fixes headaches with time
20:58:56 <carter> heatsink: even better, some of the same work could be abused to allow me to say, add support for a magic inline ASM primop
20:59:12 <wagle> monochrom: perfect!  thanks!
20:59:15 <wagle> > mapAccumL (\s x -> ((s + 1), (x,s))) 0 [10,20,30]
20:59:16 <lambdabot>   (3,[(10,0),(20,1),(30,2)])
20:59:55 <heatsink> So this involves injecting instructions that progress all the way down to the backend?
21:00:02 <heatsink> from Haskell source?
21:00:08 <frase> thanks for the time library suggestions folks
21:00:30 <carter> heatsink: the trick is kinda horrible and awesome
21:00:51 <carter> for simd shuffles i need to add support for static literal compile time data
21:01:00 <carter> the inline asm op could just take a literal string
21:01:15 * stephenmac7 bounces with joy
21:01:25 <carter> inlinePureAsm :: Static String -> a
21:01:34 <carter> so you can give it the "right" type
21:01:37 <carter> you'd also have
21:01:39 <stephenmac7> I've finished Learn you a Haskell for Great Good!!!
21:01:51 <carter> inlineCanFailAsm
21:01:59 <carter> and inlineEffectfulAsm
21:02:48 <heatsink> With inline assembly, you'll still want the code generator to do register allocation on your asm
21:02:54 <carter> heatsink: nope
21:03:07 <carter> heatsink: that'd be ok for inline C--
21:03:09 <carter> but not inline asm
21:03:18 <triliyn> What is pure asm?
21:03:34 <carter> it'd be assembly that has pure semantics wrt haskell execution
21:03:40 <triliyn> hmmm
21:03:58 <carter> i'm talking about a language feature i've been chewing on how to design right
21:04:09 <triliyn> The purity wouldn't really be verifiable by the compiler, would it?
21:04:23 <carter> triliyn: yup
21:04:41 <carter> it'd be "i'd better only use this if i REALLY KNOW WHAT I"M DOING or BAD THINGS will knock at my door"
21:05:18 <triliyn> ahh, okay
21:05:32 <carter> it'd make inlinePerformIO look like a teletubby by comparision
21:05:33 <heatsink> Oh, DSH is an embedded DSL, it's not actually turning Haskell code into SQL
21:05:44 <carter> @hoogle inlinePerformIO
21:05:44 <lambdabot> Data.Text.Unsafe inlinePerformIO :: IO a -> a
21:05:58 <carter> seriously: inlinePerformIO is super evil if you're not careful :)
21:06:15 <heatsink> So all the asm functions should have an unsafe prefix
21:06:19 <simpson> Do I want to know why this is worse than unsafePerformIO? :3
21:06:20 <carter> sure
21:06:30 <carter> because i'td let you write arbitrary asm :)
21:06:38 <triliyn> unsafeInlineCanFailEffectfulASM
21:06:43 <carter> yes
21:06:56 <carter> well
21:07:03 <heatsink> crash = inlinePureAsm "lulz"
21:07:15 <carter> heatsink: i think that'd be caught by seeing if gcc can parse it
21:07:30 <ReinH> carter: you keep coming up with new and exciting ways to get GHC to segfault ;)
21:07:35 <carter> ReinH: someone has to
21:07:40 <carter> just doing my job
21:07:43 <carter> and pushing buttons
21:07:43 <heatsink> It's going through the C backend?
21:07:46 <carter> heatsink: nope
21:08:04 <carter> would be easy to support on the native and llvm codegens
21:08:12 <jmcarthur> is the only reason this is better for your purposes than new primops and possibly inline C-- that you don't have to introduce new primops to get access to new instructions?
21:08:17 <carter> jmcarthur: yes
21:08:23 <carter> exactly that
21:08:42 <carter> we might still want to expose safer wrappers
21:08:42 <heatsink> It was nice meeting you carter, I'm off for tonight
21:08:46 <carter> enjoy
21:09:05 <carter> jmcarthur: like, i think GHC should never have the aes instructions as a supported primoip
21:09:17 <carter> but this would give a motivated crazy  person a way
21:09:29 <carter> i'm mostly interested in SIMD things
21:09:53 <carter> but eg, it'd give a sane way to support all the fancier prefetches that are architecture specific
21:10:01 <jmcarthur> could you not just use template haskell and foreign imports?
21:10:12 <jmcarthur> is there some overhead in unsafe imports that would make that no good?
21:10:28 <carter> jmcarthur: if you want it to be straight line code, tis an issue
21:10:34 <jmcarthur> ah
21:10:38 <carter> pipelining is a thing after all
21:10:38 <jmcarthur> no inlining with imports
21:10:42 <carter> yeah
21:11:12 <carter> can foreign cmm be inlined into hs code?
21:11:27 <carter> i don't think so
21:11:39 <jmcarthur> it seems plausible, but i don't know
21:11:55 <carter> seems like something that we should make possible if sane
21:12:09 <jmcarthur> maybe adding inline asm to cmm and inline cmm to haskell would be a way to go :P
21:13:09 <carter> at that point its easy to add it properly to haskell as a primop
21:13:21 <carter> jsut require a clobber list etc
21:13:32 <jmcarthur> i don't know what a clobber list is
21:13:35 <carter> oh
21:13:45 <carter>  "i'm usng these registers in this inline fragment"
21:13:49 <jmcarthur> i have never added a primop
21:13:51 <carter> oh
21:13:54 <jmcarthur> i see
21:13:54 <carter> i've 1 down
21:13:58 <carter> several more to go
21:14:06 <carter> i've some ideas for cleaning up the native code gen
21:14:22 <carter> if i can clean it up enough, maybe i can make it more register alloation friendly for this use case
21:14:23 <jmcarthur> the new one?
21:14:29 <carter> yes
21:14:38 <carter> it may be newish
21:14:50 <carter> but its by no means easy to extend / modify
21:15:00 <jmcarthur> well, it's only becoming the default in the next release, therefore it's "the new one"
21:15:28 <carter> well, theres no OLD one in head
21:15:35 <carter> soooo i've only played with head
21:15:35 <jmcarthur> ah
21:16:10 <carter> simon marlow was like "you could do a mini llvm!"
21:16:13 <carter> at icfp
21:16:25 <carter> i was like "i wish i had that kinda productive free time, not this year"
21:17:49 * wagle runs out of stack space...  again
21:18:17 * wagle gets strict to no avail
21:18:48 <foozab> can i rely on the lexographic ordering of the values which result from this expression: let ns = [0,1] in do { x<-ns; y<-ns; z<-ns; return (x,y,z) }
21:19:04 <foozab> lexicographic*
21:19:23 <elliott> yes
21:19:28 <foozab> elliott: thanks!
21:19:42 <foozab> elliott: is there a concept behind that which i should be aware of?
21:20:21 <elliott> I think because you use the monadic interface there, there is only one possible ordering.
21:20:31 <elliott> but also, just, standard interfaces are defined fully, they're not going to change from underneath you like that :)
21:20:34 <elliott> *instances
21:20:46 <foozab> elliott: ok .. yeah that makes sense
21:20:47 <foozab> another question: what's the syntatically correct way of putting the "let" inside the do-block on one line? .. i'm not going to do it, because it's horribly unreadable, but i'm curious
21:21:07 <elliott> do { let ns = [0.1]; ... }
21:21:15 <elliott> *0..1
21:21:26 <elliott> you can also say:
21:21:35 <elliott> let ns = [0..1] in liftA3 (,,) ns ns ns
21:21:52 <foozab> elliott: <interactive>:39:23: parse error on input `<-'
21:22:00 <foozab> *Main System.Environment> do { let ns = [0,1]; x<-ns; y<-ns; z<-ns; return (x,y,z) }
21:22:58 <elliott> oh
21:22:59 <foozab> elliott: it's not important.. just curious again..
21:23:04 <Iceland_jack> > do let {ns = [0,1];}; x <- ns; y <- ns; z <- ns; return (x,y,z)
21:23:05 <lambdabot>   [(0,0,0),(0,0,1),(0,1,0),(0,1,1),(1,0,0),(1,0,1),(1,1,0),(1,1,1)]
21:23:07 <elliott> I guess on one line you need let { ns = [0,1] }
21:23:10 <Iceland_jack> yes
21:24:22 <foozab> ok.. so the let needs its own little block
21:24:24 <foozab> got it! :)
21:25:17 * wagle invents mapAccumL' and runs out of stack even faster
21:25:47 <simpson> foozab: Be aware, BTW, that do-blocks with a let at the beginning immediately desugar into having that let on the outside.
21:25:58 <simpson> @undo do let {ns = [0,1];}; x <- ns; y <- ns; z <- ns; return (x,y,z)
21:25:59 <lambdabot> let { ns = [0, 1]} in ns >>= \ x -> ns >>= \ y -> ns >>= \ z -> return (x, y, z)
21:26:26 <foozab> simpson: i see! .. is there a desugar inside ghci?
21:27:06 <simpson> Probably. I'd be surprised if there wasn't.
21:27:32 <foozab> simpson: well thanks for showing :)
21:28:00 <tedmiddleton> Does anyone know anything about how ghc links libraries? I'm really puzzled by some behavior I'm seeing with LibClang
21:29:34 <s00pcan> where is the repository for haskell-platform?
21:30:22 <tedmiddleton> LibClang cabal-install's quite nicely on OSX, provided it finds llvm-config (which it does on my system)
21:30:46 <tedmiddleton> And it works very nicely when built with ghc into an executable
21:30:54 <Cale> foozab: There isn't a command in ghci to show you how the do-notation desugars, but ghc/ghci *perform* this desugaring as one of the first steps in compilation.
21:31:34 <tedmiddleton> But if you try to do anything with LibClang in ghci, ghci tries to load libLLVMInstrumentation.dylib
21:32:31 <tedmiddleton> Thing is, libLLVMInstrumentation.dylib doesn't exist. There is a libLLVMInstrumentation.a, which I imagine ghc is finding when it compiles my program, but ghci is really stubborn about trying to find libLLVMInstrumentation.dylib
21:32:48 <tedmiddleton> Does anyone know where that decision is made in ghci or LibClang?
21:33:48 <tedmiddleton> I've tried tracing the failed dlopen call back with dtrace, but dtrace can't given me a stack trace into ghci - I guess the ABI is just too different.
21:34:20 <foozab> Cale: ah. well it isn't super important, just seemed like a good learning tool
21:35:04 <cschneid> I have an IO action (readFile) which I then want to process a bit before handing back. so I do  corpus <- readCorpus path; return $ normalizeStats $ calculateRawStats corpus
21:35:05 <cschneid> which works fine
21:35:08 <cschneid> but how do I one-line that
21:35:25 <monochrom> haha, one moment
21:35:50 <Cale> fmap (normalizeStats . calculateRawStats) (readCorpus path)
21:35:51 <monochrom> (normalizeStatus . calculate RawStats) <$> readCorpus
21:35:53 <arkeet> fmap (normalizeStats . calculateRawStats) etc
21:35:55 <geekosaur> normalizeStats . calculateRawStats <$> readCorpus path -- ? (or fmap)
21:35:58 <geekosaur> yeh
21:36:00 <arkeet> haha
21:36:07 <monochrom> I forgot path
21:36:25 <cschneid> ahh sure, fmap to hoist the function into the IO monad (in this case)
21:36:57 <cschneid> I "know" this, but it's hard to see the patterns as I try to use it
21:36:57 <Cale> or I suppose you could   return . normalizeStats . calculateRawStats <=< readCorpus
21:37:17 <monochrom> it's ok, I like giving concrete examples
21:37:35 <tedmiddleton> Would I be better off asking in a ghc-specific channel?
21:38:48 <cschneid> my initial attempt was to use >>= to chain them together, but that fails since normalizeStats and calculateRawStats are pure functions, which doesn't match up with >>=. The pattern there is to look at fmap to pull a pure function into the monadic context. Yes?
21:38:53 <cschneid> (just talking my way through that)
21:39:22 <arkeet> @undo do { corpus <- readCorpus path; return $ normalizeStats $ calculateRawStats corpus }
21:39:22 <lambdabot> readCorpus path >>= \ corpus -> return $ normalizeStats $ calculateRawStats corpus
21:39:32 <arkeet> = readCorpus path >>= return . normalizeStats . calculateRawStats
21:39:38 <arkeet> now x >>= return . f = fmap f x
21:39:41 <cschneid> arkeet: right, that's what I had originally.
21:39:50 <arkeet> @src liftM
21:39:50 <lambdabot> liftM f m1 = do { x1 <- m1; return (f x1) }
21:39:52 <monochrom> if you use >>=, you have to add "return". fmap and liftM are exactly that combination of >>= and return
21:40:09 <cschneid> nice. fmap is a more general version of liftM?
21:40:15 <arkeet> yes
21:40:19 <arkeet> :t fmap
21:40:19 <lambdabot> Functor f => (a -> b) -> f a -> f b
21:40:20 <arkeet> :t liftM
21:40:21 <lambdabot> Monad m => (a1 -> r) -> m a1 -> m r
21:40:29 <arkeet> a1 =(
21:40:38 <cschneid> cool, don't think I made that connection.
21:40:49 <arkeet> every Monad is a Functor. (or ought to be.)
21:40:56 <arkeet> (and will be, in ghc 7.10)
21:41:48 <cschneid> right. I "knew" that, but actually seeing the connection...
21:41:54 <cschneid> and then the extra step of actually using it in code
21:42:09 <monochrom> yeah, concrete examples are great
21:42:24 <cschneid> it's cool going back and reworking code I did a few months ago. Halving the general LOC and using an actual cabal build setup.
21:52:49 <wagle> is there a way to do something like mapAccumL on a million element list without running out of stack?
21:53:29 <monochrom> I know how to answer that. but you should just raise your stack limit.
21:54:09 <monochrom> after a decade of fighting, we have finally got SPJ to agree in writing: maybe 8MB is too low
21:54:54 <wagle> whats the other answer?  i've already sullied my hands writing assembly code in data.vector.mutable
21:57:00 <wagle> i'm needing to know how to push the memory limits of haskell, so I want to learn the not-necessarily good ways so I can improve on them
21:58:57 <dolio> mapAccumL already works on a list of a million elements.
22:00:39 <monochrom> mapAccumL (\s x -> let t = s+1 in t `seq` (t, (x,s))). is that enough?
22:00:39 <wagle> not for me..
22:01:01 <wagle> i'll try it
22:01:49 <janja> http://MegaStoon.Com/sms/sms.php?share=178616
22:03:27 <wagle> nope..  if you are thinking unsafe operations, I'm trying to avoid those
22:05:19 <wagle>   let (!free, !subst) = mapAccumL' (\s x -> let s' = s+1 in s `seq` (s', (x,s))) 1 millionlist
22:05:22 <wagle> ...
22:05:52 <monochrom> that !free is going to cause more stack usage, not less
22:06:44 <wagle> oh ok..  maybe i need to go read that arrows fix leaks paper
22:06:58 <monochrom> here is a secret. without doing anything special, without adding any seq or !, if you completely use subst before you use free, there is no stack usage. any other usage order, it will incur stack usage.
22:07:55 <wagle> i have let !_ = show foo in my IO monad
22:08:22 <wagle> i figured that would dig all the way down, and it did
22:08:24 <monochrom> who is foo?
22:08:47 <wagle> both free and subst
22:09:05 <monochrom> in what order? I just said order is important
22:09:23 <wagle> right, lemme split them up
22:10:05 <monochrom> "!_ = show subst" will not completely use subst
22:10:22 <monochrom> it is worthwhile to repeat and emphasize. will not.
22:11:22 <Kaidelong> I had no idea Traversable was such a useful typeclass
22:11:35 <arkeet> it's pretty great.
22:13:12 <wagle> let !_ = ... in the IO monad, sandwiched between two putStrLn's
22:13:41 <monochrom> repeat. will not. being in IO does not make a difference
22:14:16 <wagle> well, ok, but I am getting stack crashes between two of the prints
22:14:26 <monochrom> putStrLn itself does. but it is not significantly helped by any ! before. and any ! after may harm, not help.
22:15:03 <monochrom> you still haven't told me which order.
22:15:07 <simpson> wagle: What's in the accumulator?
22:15:20 <wagle> i put the !'s in one at a time in an arbitrary (sigh) order when I started running out of stack
22:15:23 <monochrom> but I have to go. you now can tell and it will still not matter
22:15:44 <wagle> monochrom: thanks, cya
22:15:55 <arkeet> !_ = show subst  will evaluate subst exactly far enough to tell whether show subst is nonempty
22:18:01 <wagle> arkeet, its running out of stack between these two putstrln's:   putStrLn "woof!"; let !_ = (show free); putStrLn "tick2"
22:18:22 <wagle> i believe you, but I am having this experience, so wondering why
22:18:53 <monochrom> that uses free first. that uses more stack, not less.
22:19:17 <monochrom> here is a secret. without doing anything special, without adding any seq or !, if you completely use subst before you use free, there is no stack usage. any other usage order, it will incur stack usage.
22:19:40 <Kaidelong> ekmett mentions that when you use Data.Text.Strict.Lens you lose the advantages of fusion in the lens library
22:19:51 <Kaidelong> couldn't this be worked around with the #SPECIALIZE pragmas?
22:20:05 <Kaidelong> err in the text library
22:20:06 <Kaidelong> not lens
22:21:33 <wagle> i am showing subst before that, but as you say, that doesnt work..  hmm..  lemme try some things
22:22:33 <simpson> wagle: Again, what's in the accumulator, and why are you using it first?
22:23:13 <wagle> simpson: sorry, its the Int result I'm trying to print
22:23:58 <simpson> wagle: Are you interested in the resulting list at all, or is it just a side effect?
22:24:26 <wagle> i need both results..  i use the subst before the int though
22:25:53 <wagle> simpson: ^^^
22:26:48 <simpson> And by "use" you mean that you feed it into subsequent computations, not that you're just showing it, right?
22:28:11 <codygman> I'd like to use haskell for a project I'm working on where a user provides a video on a webpage, then I use ffmpeg (or something better if exists/suggested) to turn that video into screencaps. I see the only binding is hs-ffmpeg but it only works with an old version of ghc. Where should I go from here?
22:30:07 <wagle> if I show (last subst), then I run out of stack then
22:30:28 <wagle> I apparently need to read http://haskell.cs.yale.edu/wp-content/uploads/2011/01/leak.pdf now
22:31:06 <wagle> subst is a [(Int,Int)]
22:31:40 <wagle> simpson: ^^^
22:32:18 <wagle> simpson: the paper is supposed to explain leaks in general
22:36:22 * wagle reads the paper
22:52:19 <Twey> triliyn: stdout can be closed, you can receive signals to suspend for console output, the console buffer can fill up…
22:52:42 <Twey> triliyn: Writing text is a dangerous affair :þ
23:08:13 <cschneid> how do I use a list monad to do arbitrary length? [rand, rand, rand.... of length x] basically. I can make a fixed one easy enough.
23:09:23 <Twey> cschneid: You wouldn't usually use the list monad for that
23:09:30 <Twey> :t randoms
23:09:33 <lambdabot> (RandomGen g, Random a) => g -> [a]
23:09:45 <cschneid> Twey: what's the easiest way? I don't mean actual random values, I want all values to come out.
23:09:52 <Twey> That gives you an infinite list of random values; just take as many as you want
23:10:32 <cschneid> I have a func using list monad already that gives me all the values between 0..255.  I want several bytes worth of values, so a function which is: "ofLength x = ..."
23:10:54 <cschneid> sorry I wasn't clear - I don't mean a single random value, but an enumeration of all values in the range specified.
23:12:05 <Twey> Like [[0 .. 255], [0 .. 255]] ?  Or like [[0, 0], [0, 1], [0, 2], … , [1, 1], [1, 2], … , [255, 255]]?
23:12:23 <Twey> (for n = 2)
23:12:31 <Makoryu> > take 20 [minBound ..] :: [Char]
23:12:32 <lambdabot>   "\NUL\SOH\STX\ETX\EOT\ENQ\ACK\a\b\t\n\v\f\r\SO\SI\DLE\DC1\DC2\DC3"
23:12:37 <Makoryu> > take 20 [minBound ..] :: Float
23:12:38 <lambdabot>   Couldn't match expected type `GHC.Types.Float'
23:12:39 <lambdabot>              with actual typ...
23:12:42 <cschneid> Twey: right, I am brute forcing an xor encryption key. (part of a set of encryption puzzles)
23:12:48 <Makoryu> > take 20 [minBound ..] :: Bool
23:12:48 <lambdabot>   Couldn't match expected type `GHC.Types.Bool'
23:12:49 <lambdabot>              with actual type...
23:12:50 <Makoryu> Oops
23:12:52 <Twey> cschneid: Ah
23:12:53 <Makoryu> > take 20 [minBound ..] :: [Bool]
23:12:54 <lambdabot>   [False,True]
23:13:01 <Twey> > replicateM 3 [1 .. 3]
23:13:02 <lambdabot>   [[1,1,1],[1,1,2],[1,1,3],[1,2,1],[1,2,2],[1,2,3],[1,3,1],[1,3,2],[1,3,3],[2...
23:13:33 <Makoryu> Isn't there a library somewhere for doing that "diagonally"
23:13:41 <cschneid> Twey: interesting. I have a func already that makes 1 byte worth of values. So just the repeating part is what is getting me.
23:13:53 <Twey> cschneid: replicateM is what you need
23:14:18 <cschneid> cool - I'll give it a go
23:14:27 <Twey> [0 .. 255] is one byte's worth of values.  replicateM n [0 .. 255] is n bytes' worth.
23:14:34 <Twey> (divided up into bytes)
23:14:56 <Twey> You can also, of course, just do [0 .. 255 ** n], if you don't want separate bytes
23:15:36 <Twey> Or [0 .. 256 ** n - 1] or something; it's too early in the morning for me to figure out the off-by-one there :þ
23:16:32 <cschneid> Twey: :) Cool. thanks
23:17:07 <Twey> Makoryu: What, a whole library?  :þ
23:17:16 <wagle> monochrom was right!  increase the stack space!  I'm leaking all over the place
23:17:54 <Makoryu> Twey: I dunno.... I don't really remember
23:18:15 <Hermit> wagle: eww, that's disgusting
23:18:26 <Hermit> :P
23:56:28 <zzo38> In some mathematical descriptions of some things I have made like (F : enum, V : enum, C : F -> set V) and so on; in this case "enum" is a type of finite sets and these value are usable as a type, too, as shown here; only equality is available. Is there a way to make such a thing in Haskell?
23:58:44 <Makoryu> zzo38: Not sure I entirely follow you. But I can point out that while types and values are totally separate namespaces in Haskell, there are still ways to translate between them
23:59:06 <zzo38> Makoryu: I am not talking about namespaces.
