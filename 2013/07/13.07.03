00:01:10 <FreeFull> C was my first
00:02:46 <johnw>  FreeFull: what year was that?
00:03:19 <finishingmove> We were still doing C in highschool, that was some 10 years ago
00:03:39 * zvrba learned C64 basic first, then Pascal
00:04:11 <finishingmove> Pascal is a good language for learning programming
00:04:58 <caper> finishingmove: told your brother to learn haskell first?
00:05:24 <FreeFull> johnw: 2007-2009 I think? I don't remember anymore
00:05:30 <FreeFull> johnw: Was from my own initiative
00:05:59 <FreeFull> Might have even been 2010
00:07:51 <caper> can anyone recommend good books to help me learn haskell?
00:08:11 <FreeFull> Seems 2009
00:08:20 <FreeFull> caper: Learn You A Haskell is a good start
00:08:49 <FreeFull> Once you're done with that you might want to look at typeclassopedia and Real World Haskell
00:08:57 <FreeFull> And go exploring some libraries like lens
00:10:29 <johnw> um, leave lens until a looooong time later, I say
00:12:17 <caper> I'll start tomorrow morning with Learn you a Haskell....Thanks again, I'm off to bed.
00:12:25 <johnw> enjoy!
00:22:29 <ChongLi> wow, I really love lens
00:22:54 <ChongLi> it's taking some effort to learn (with its really cryptic type errors)
00:23:09 <ChongLi> but man is it cool to write generic code with it
00:26:35 <Gracenotes> if a mathematical construct if named after Cantor, you can be certain it's probably pretty weird
00:29:06 <Gracenotes> an abstract gadfly to buzz about some classicist's ears
00:38:20 <Moggle_> I'd like to use WebKitGTK+ with gtk2hs, but it doesn't seem there are bindings. Anyone have any advice?
00:39:08 <Moggle_> aha!
00:39:11 <Moggle_> i found some
00:39:20 <Moggle_> they werent on hackage because I don't really know why.
00:45:31 <Moggle_> i just know i'm not going to be able to build these bindings
00:45:41 <Moggle_> but damnit i'm going to spend three hours being frustrated on the off chance they do
00:47:00 <johnw> you already know how long it will take?  cool
00:49:47 <Moggle_> aha
00:49:51 <Moggle_> and here we have our first problem
00:50:01 <Gracenotes> It will take that long to succeed doing it, and it will also take that long to fail to do it.
00:50:02 <Moggle_> msys doesn't include the 'gperf' hash function generator, whatever that is
00:50:08 <Moggle_> to google!
00:50:31 <Gracenotes> well one of those
00:54:55 <Moggle_> annnnd it needs gcc >= 4.7 and haskell's mingw's gcc is 4.5
00:55:00 <Moggle_> this is going to be a fun adventure :D
00:56:38 <taylorgb> Moggle_: I hope you can remember what it is you wanted to do by the time everything is set up ;
00:56:41 <taylorgb> er ;)
00:57:03 <Moggle_> taylorgb: such is life programming on windows :D
00:57:17 <Moggle_> i hope to god i didnt just break anything
00:58:03 <b_jonas> I was trying to think about how I could prove some invariants at compile time with the type system, but it got ugly and now my head exploded.
00:58:04 <taylorgb> I remember that I once tried to get gtk2hs to work on windows, then decided it was easier just to install linux
00:58:12 <b_jonas> Does the type system do that to others too?
00:58:20 <yitz> Gracenotes: it's always interesting to see what cantoresque mathematical concepts still make sense in the context of intuitionalist logic :)
00:59:05 <taylorgb> b_jonas: I suppose that some of the more advanced practitioners don't have such problems, but I do as well
00:59:09 <johnw> b_jonas: sort of depends on what you were trying to prove
00:59:58 <yitz> b_jonas: a language with dependent types is better suited for that
01:00:24 <Moggle_> taylorgb: hey, same here. installed a linux vm just to use ncurses. dmwit here in #haskell helped me out and got gtk2hs built on windows painlessly though.
01:00:41 <Moggle_> (this is after i spent 3 hours bashing my head on the keyboard of course)
01:01:25 <b_jonas> I might try to formulate a some concrete question if I get it cleaner in my head.
01:03:55 <taylorgb> With respect to the type system the biggest problem I have is that I write C++ for my job, so switching between the very imperative mindset and functional mindset can be tricky. I often find myself part way through implementing ridiculous things in Haskell because of it
01:04:56 <yitz> taylorgb: once you get more used to haskell, you'll have the opposite problem
01:05:25 <yitz> taylorgb: but one problem you'll never get away from is c++ symbol name munging
01:07:25 <taylorgb> For a while I did have the problem that I was trying to implement Haskelly things in C++, but then you realise you really have to keep languages separate and write programs in idiomatic ways otherwise you end up with things that don't really compose well with other work that's done. Not to mention that I don't think that C++ is strong enough in many respects to benefit from some Haskell approaches
01:08:12 <taylorgb> Always quite frustrating though, as usually half the problems you are solving are easy in haskell and the other half are easy in C++ and vice versa
01:08:31 <johnw> what's an example of something that's easy in C++ and not in Haskell?
01:08:33 <taylorgb> But I don't think that's a deficiency in Haskell, just that there are some missing libraries
01:08:34 <Moggle_> I've found that when writing in non-haskell languages I do tend to separate my impure code from my pure code now. Haskell's given me that.
01:09:46 <taylorgb> johnw: Well, at the moment I'm writing a test for our software that does file syncing, so I need to create a tree which represents the file system, then do a bunch of IO and keep the fs up to date then periodically compare the trees to see how it is going to give speed and progress reports
01:10:04 <taylorgb> All the things to do with the structure are trivial in Haskell, and most the things to do with IO are trivial in C++
01:11:06 <nerrz> quick and easy question from a new xmonad user, should xmonad.hs start with module XMonad where .. or just import XMonad and then main
01:12:53 <Kinnison> Here is my (not very good) xmonad.hs
01:12:54 <Kinnison> http://git.gitano.org.uk/personal/dsilvers/resources.git/tree/desktop/xmonad/xmonad.hs
01:13:11 <Kinnison> Note that it uses Taffybar, so don't take it verbatim unless you also intend to use Taffybar
01:13:41 <nerrz> so it is not a module?
01:14:12 <Kinnison> Nope, it's a program
01:14:23 <Kinnison> the xmonad binary then notices if it changes, recompiles it and re-execs it
01:14:27 <Kinnison> Pretty cool
01:14:41 <Kinnison> (obviously only when you tell it to)
01:14:44 <Kinnison> (or on boot)
01:15:55 <astor> taylorgb: Maybe Shake is for you.
01:16:08 <Moggle_> welp, somewhere along the line msys suddenly started recognizing that i have gcc 4.7.2 and i didnt do anything
01:16:17 <Moggle_> all I can conclude, as usual, is that building things on windows is a black art
01:16:21 <Kinnison> Does anyone here have experience of bootstrapping ghc without a haskell compiler on your target system?
01:17:05 <earthy> moggle: that it is. *even* if the things you're building are developed in visual studio with C#.
01:19:18 <Moggle_> earthy: :D I have terrible memories of trying to build something that was a speshul snowflaek and demanded I generate keys to sign everything myself and it was horrible. I think it was for a C# implementation of the GOLD parser.
01:19:30 <Moggle_> windows just makes for a sad programmer in general
01:20:02 <Moggle_> on unix, most libraries are one sudo apt-get install away
01:20:12 <Moggle_> what i wouldnt give for that on windows. well, I guess msys comes close, along with cygwin.
01:20:15 <Moggle_> just not the same though.
01:24:08 <earthy> hm. NuGet these days makes things better
01:24:38 * earthy is refering to 'interesting' issues such as code that does build within visual studio that does not build with msbuild, even though they nominally use the same build process
01:24:52 <earthy> (to the point of the msbuild generating compiler errors that visual studio does not...)
01:25:08 <earthy> (on the exact same effing code)
01:25:37 <earthy> and windows makes for either sad programmers or programmers that have yet to outgrow their crutches.
01:35:29 <Moggle_> unfortunately, I want this program to run everywhere as my users all run Windows so I can't just use my wonderful ubuntu vm
01:35:38 <Moggle_> such is life!
01:37:32 <astor> There are so many list functions that I want.  Is there a function that can collapse consecutive elements like so:  compact :: (a -> a -> These a a) -> [a] -> [a] ?
01:37:57 <augur> astor: whats These a a?
01:39:01 <alpounet> Kinnison, maybe you could checkout the "ghc-android" repo, to see how that guy handles this: https://github.com/neurocyte/ghc-android
01:39:32 <astor> augur: These a b is either a, b, or both a and b.
01:39:35 <shachaf> astor: These a a has a lot of alternative representations, like (a,Either Bool a)
01:40:01 <shachaf> Anyway I'm not completely sure what this function should be doing.
01:40:50 <astor> the function takes pairs of elements in the list and each pair is either passed through as-is or reduced to a single element.
01:40:54 <Kinnison> alpounet: That appears to be for building a cross-ghc
01:41:11 <Kinnison> alpounet: I want to get from system A (with no ghc) to system A (with native ghc)
01:41:15 <augur> astor: then no i dont think there's such a thing..
01:41:21 <astor> maybe it could be :: ((a,a) -> (a, Maybe a)) -> [a] -> [a]
01:41:31 <shachaf> a: How are This and That handled differently?
01:41:37 <shachaf> stor
01:41:43 <Kinnison> alpounet: I the 6.x era, there was a way to have the .c files from a non-registerised build mean that you didn't need ghc to build ghc
01:41:54 <Kinnison> alpounet: But these days, the build seems to always depend on having ghc around
01:41:55 <alpounet> Kinnison, you probably have to build an unregisterized build first, and build a native GHC from there using the unregisterized version
01:41:56 <astor> shachaf: it isn't, it's a bad type.  (a, Maybe a) is more accurate.
01:42:13 <alpounet> Kinnison, the GHC Commentary has some pages about that kind of things
01:42:17 <shachaf> astor: Even (a, Maybe a) doesn't really represent what you want, if you only ever want things to be collapsed or passed as-is.
01:42:18 <mauke> astor: are results reconsidered for further reduction?
01:42:23 <Kinnison> Sections of the GHC build system expect to be able to ghc --make :-(
01:42:28 <Kinnison> Not all, but some bits
01:42:33 <shachaf> astor: More like (a -> a -> Maybe a), maybe, where Nothing means not to collapse.
01:42:36 <alpounet> Kinnison, system A isn't supported by GHC?
01:42:39 <shachaf> But also what mauke said.
01:42:51 <Kinnison> alpounet: Yes it's supported, but doesn't currently have a ghc built for it
01:43:11 <astor> mauke: yes
01:43:18 <Kinnison> alpounet: And no, using binaries from the website isn't acceptable for tracing and licence compliance reasons
01:43:30 <mauke> astor: that makes it complicated
01:43:37 <mauke> can't do it with a simple traversal
01:43:42 <shachaf> This seems like a rather specialized function.
01:43:51 <Kinnison> alpounet: I wasted around 6 hours trying to make it work, but got nowhere :-(
01:44:07 <mauke> foo (x : y : z : ...) may have to reduce x (reduce y z)
01:44:07 <Kinnison> Hell, if the tarball releases carried the .c files so that they didn't need ghc to build themselves, that'd be enough
01:44:26 <alpounet> Kinnison, shoot an email to the ghc-users list
01:44:48 <Kinnison> alpounet: Mmm at some point I shall have to -- Must make room on my mailing list mailbox space first
01:45:39 <alpounet> Kinnison, also, try to explain in that mail where you are stuck and why
01:46:03 <Kinnison> alpounet: Oh, when I do get around to going on the ML, I'll first reproduce where I got stuck and explain the steps to get there
01:46:07 * Kinnison isn't daft :-)
01:46:11 <astor> I think the general case is  ([a] -> (a, [a])) -> [a] -> [a] where the given function folds the list, returns an element and the continuation list.
01:46:20 <alpounet> great :-)
01:46:36 <Kinnison> alpounet: For reference, this is me trying to organise a way to get ghc into Baserock
01:48:19 <gspr> There's no Array analog of Data.Vector.Generic, is there? (I need to take matrices of doubles from the user, and would prefer to write a small Matrix data type using generic vectors, but I'd also rather not deviate too much from standard types,  and not pollute the user's namespace too much, so I thought Arrays would be a better fit..)
01:49:56 <gspr> I guess the question can be rephrased as: How would you best provide matrices of doubles (as a container only, no linear algebra) without writing a Matrix type on top of generic vectors (I often do this for internal projects, but I don't wanna force my matrix data type on others)
01:54:19 <mm_freak_> gspr: one solution is not to force any specific container type at all
01:54:36 <mm_freak_> matrices and matrix operations are well represented by applicative/monadic functions
01:54:39 <mm_freak_> see the 'linear' package
01:55:11 <gspr> mm_freak_: HMm, yes, that's true. Good point.
01:56:07 <alpounet> Kinnison, looks cool! I'll try to keep an eye on glasgow-haskell-users@ :-)
01:56:38 <Kinnison> alpounet: Might be a while yet, I'm super-duper busy :-(
01:56:51 * Kinnison was made a project manager for Baserock, so I have a lot of new processes to learn
01:57:22 <gspr> But then again, I won't be doing any matrix operations at all; I just need to pass this data on to C. The C library expects it row-major, so I'd prefer to the user to supply the data row-major, but doing so as simply a Vector feels kinda un-haskelly
01:58:14 <alpounet> Kinnison, it's fine, I don't plan on un-subscribing soon
01:58:23 <gspr> (The C library does not alter the data, so I would prefer to pass a pointer to the underlying data, as I can with Data.Vector.Storable. Hence I've been going with generic vectors and convert so far)
01:58:31 <Kinnison> alpounet: :-)
02:01:05 <mm_freak_> gspr: if this is really just for interfacing with C, then you should probably select Data.Vector.Storable explicitly
02:01:12 <mm_freak_> there is really no reason to be generic then
02:02:05 <mm_freak_> gspr: however, most matrix operations are really easy to express in haskell and pretty fast, too
02:02:16 <mm_freak_> so you may want to use the applicative interface anyway
02:02:50 <gspr> mm_freak_: Well, I was thinking: Users (at least me) would probably have the data as a Data.Vector.Unboxed Vector (or a matrix based on that), so wouldn't it be nice to have a generic interface?
02:03:41 <gspr> mm_freak_: Yeah, again, I'm not really doing matrix operations. I'm saying "matrix" all the time because the data naturally "belongs" in a 2D array *and* the C library expects the data row-major
02:03:49 <mm_freak_> gspr: unboxed vectors are the wrong choice here…  for interfacing with C you want a storable vector, which is pretty much the same, except that you get some memory location guarantees
02:04:13 <gspr> I know I need storable vectors
02:04:31 <gspr> but I'm producing my matrices in other code, and *that* might naturally be using unboxed for other reasons
02:04:38 <gspr> hence I'm thinking generic is more suited
02:04:49 <mm_freak_> gspr: would you mind explaining your application?
02:06:17 <gspr> mm_freak_: Not at all. I have a rather large private program that now needs to compute some horrible convex hulls. I thought I'd interface with qhull (library) for this. And I try to share such bindings whenever I write them, so I'm trying to come up with a nice interface
02:06:49 <gspr> mm_freak_: For my personal use, I have a suitable matrix type based on generic vectors, and for *my* use this is definitely the right type for my bindings.
02:07:04 <mm_freak_> so the vectors are constructed in the haskell realm and then passed on to C for the hull algorithm?
02:07:24 <gspr> mm_freak_: But polluting the namespace with my stupid (made for my purposes only) Data.Matrix module feels impolite
02:07:53 <gspr> mm_freak_: Indeed
02:07:58 <mm_freak_> a common strategy for bindings is to write a low level binding first
02:08:20 <mm_freak_> the low level binding has concrete library-friendly data types and close-to-API function types
02:08:40 <mm_freak_> then you can wrap a higher level API around that
02:09:17 <gspr> mm_freak_: Indeed. I know. But even for the high level interface, it makes some sense to accept data that is a proper matrix type, as long as the underlying representation is row-major
02:10:15 <mm_freak_> consider this:  hulls :: Matrix -> Result
02:10:33 <mm_freak_> as i understand it your higher level API is happy with any type 'a' that has a function a -> Matrix
02:10:57 <mm_freak_> this can be a storable vector, for which this function may just be 'id' (depending on your library-friendly Matrix type)
02:11:10 <gspr> yeah that sounds like a clean way to do it
02:11:12 <gspr> thanks :)
02:11:20 <mm_freak_> you're welcome
02:12:08 <mm_freak_> this allows users to perform vector/matrix operations using the 'linear' package or any other they are familiar with and then just pass on the result to your library function
02:12:23 <gspr> mm_freak_: That sounds like a very nice way to do it, indeed
02:13:02 <gspr> mm_freak_: Any idea why packages like hmatrix don't do something like that, but instead force their own matrix type?
02:13:07 <SrPx> Hello, is there a haskell implementation in lambda calculus? (:
02:13:54 <mm_freak_> gspr: probably history…  the hmatrix library is old, and back then we didn't have 'linear' or the wide spread usage of comonads
02:14:05 <mm_freak_> SrPx: not sure what you're asking
02:14:18 <gspr> mm_freak_: Alright. Thanks for the input. You really helped clear my mind :)
02:15:37 <SrPx> mm_freak_: I'm asking for an implementation of Haskell (a subset, obviously) using untyped lambda calculus. Not sure what you didn't understand.
02:16:13 <eikke> that wouldn't be haskell, that'd be an interpreter for untyped LC
02:16:27 <eikke> there are several of them, it's used as an example throughout several papers
02:16:37 <mm_freak_> i think SrPx means a haskell implementation (i.e. something like GHC/hugs) in LC
02:16:48 <SrPx> eikke: I'm asking for an implementation of *Haskell* using *lambda calculus*, not the other way aruond.
02:16:54 <eikke> right
02:16:55 <SrPx> yes
02:17:02 <mm_freak_> SrPx: i highly doubt it ;)
02:17:12 <mm_freak_> haskell is difficult enough to implement in haskell =)
02:17:13 <alpounet> mm_freak_, gspr, hopefully pretty soon we'll have a basic linalg library with matrix/vector operations and SIMD-enabled implementation, where available :-)
02:17:27 <SrPx> hmm ok, fair enough
02:17:53 <Moggle_> after half an hour of building glib
02:17:55 <mm_freak_> alpounet: in principle you can already do that by combining linear and your favorite flat-parallel vector library that provides Applicative
02:17:59 <sordina1> Hey Haskellers :)
02:18:00 <Moggle_> i have come to the conclusion that autotools is an abomination
02:18:05 <mm_freak_> hi sordina1
02:18:13 <Moggle_> sordinal: hi
02:18:14 <alpounet> mm_freak_, i'm not fond of linear at all
02:18:25 <mm_freak_> alpounet: why?
02:18:40 <sordina1> I was wondering if there is an implementation of Category (Category, Category) to speak colloquially
02:18:54 <mm_freak_> i know, i know, linear is one more package that helps edwardk rule the world =)
02:19:54 <mm_freak_> sordina1: i didn't get that
02:20:54 <sordina1> Well, say I have two categories, I would like to form a new category based on the pair of the two existing ones.
02:21:18 <sordina1> Like say (Kleisli, (->))
02:21:29 <mm_freak_> sordina1: so Category categories =)
02:21:41 <eikke> that's meta
02:21:55 <johnw> you mean a product category?
02:22:11 <sordina1> johnw: That sounds about right :)
02:22:18 <mm_freak_> well, it's easy enough to do, but you need a newtype
02:22:31 <mm_freak_> newtype Product c d a b = …
02:22:33 <sordina1> But I'd like to have as general an implementation as possible and I'd like to know if someone has already done it.
02:22:39 <mm_freak_> and yes, it's defined in some edwardk package
02:22:44 <mm_freak_> semigroupoids?
02:22:47 <sordina1> Also, I gave it a go and it broke my brain.
02:22:50 <alpounet> mm_freak_, because it was really written with low-dimensional linalg in mind
02:23:04 <alpounet> for example, I don't think it has n x m matrices, for arbitrary n and m
02:23:11 <mm_freak_> no, in categories
02:23:11 <alpounet> also, I don't think it's really optimized
02:23:42 <sordina1> Product category is possibly the least useful google term I can think of too :S
02:23:45 <mm_freak_> sordina1: http://hackage.haskell.org/packages/archive/categories/1.0.6/doc/html/Control-Category-Cartesian.html#t:Product
02:24:05 <mm_freak_> ah no
02:24:05 <mm_freak_> sorry
02:24:12 <mm_freak_> that's regular products, not product categories
02:24:24 <mm_freak_> i'm pretty sure i've seen that somewhere
02:25:00 <mm_freak_> alpounet: it has them, and optimization is undefined by the library…  it depends on which types you use
02:25:01 <sordina1> Ah
02:25:31 <alpounet> mm_freak_, yeah, still it gives you a default impl for vectors, 'V n a'
02:26:52 <alpounet> i'm not saying it's a bad library, I have seen it rise on github little by little, was very interested, and dropped interest (almost) when I saw the direction it was taking
02:28:23 <mm_freak_> alpounet: i'm still not sure what's wrong with it
02:28:54 <mm_freak_> it's just the recognition that vector/matrix operations are best modelled by applicative functors, and it's great at that
02:29:03 <alpounet> yeah
02:29:12 <alpounet> but the library itself isn't enough
02:29:16 <alpounet> you still have to look for backends
02:29:37 <mm_freak_> the predefined vector types are only for low dimensional stuff, but you can get arbitrary many dimensions along with very high speed by using a vector type or a reader monad
02:29:58 <mm_freak_> in fact i'd vote for removing those predefined types or moving them elsewhere
02:29:58 <alpounet> and matrices, well...
02:31:26 <mm_freak_> too bad that repa doesn't have an applicative interface
02:31:47 <adnap> Wow, I didn't know about linear
02:32:02 <adnap> It seems similar to Conal's vector-space package
02:32:03 <mm_freak_> it would be a perfect fit…  repa together with linear algebra…  that would be an amazing example of aspect-oriented programming aka separation of concerns
02:32:16 <mm_freak_> adnap: yeah, i switched from that one to linear
02:32:19 <eikke> mm_freak_: agree
02:32:34 <mm_freak_> vector-space is great for what it does, but linear is more elegant
02:32:50 <eikke> and repa + mainland's work on simd for vector
02:33:42 <mm_freak_> linear is denotation, vector is operation…  in particular linear doesn't tell you the least about how it will be implemented, just what it means
02:34:09 <mm_freak_> however, you do need ZipVector instead of Vector
02:34:10 <adnap> vector-space is the same
02:34:22 <Moggle_> hooray! after a ten minute ./configure and make, i'm getting compilation errors in glib :D
02:34:24 <Moggle_> what fun!
02:34:26 <mm_freak_> adnap: same purpose, completely different interface
02:34:48 <mm_freak_> Moggle_: sounds like you're trying to compile something on windows =)
02:34:53 <adnap> I will have to try linear and compare
02:34:57 <Moggle_> mm_freak: how'd you guess ;D
02:35:15 <adnap> I don't understand what is meant exactly by operational semantics
02:35:24 <mm_freak_> Moggle_: i found wx easier to get up and running
02:35:35 <adnap> How can something in a fuctional language be non-denotational
02:35:53 <eikke> Moggle_: when I need to compile some mostly-linux software for windows, I tend to compile under Fedora using its mingw toolchain
02:35:56 <mm_freak_> adnap: it's not about language semantics, but application semantics
02:36:03 <Moggle_> mm_freak: i did as well. i ended up getting gtk2hs compiling thanks to help from dmwit, but then I realized I'd just love to have webkitgtk+
02:36:17 <adnap> I don't get it
02:36:30 <Moggle_> eikke: that miiiight not actually be a bad plan, the thought of cross compiling (if that's the right term?) didn't occur to me
02:36:38 <mm_freak_> just like you would first specify what an FRP program /means/ mathematically and then implement it…  the implementation will look nothing like the beautiful mathematical function, but there will be an isomorphism between them
02:37:15 <adnap> I don't actually do that
02:37:19 <merijn> elliott: Sorry to bug you again, but do you remember the example you showed where the FreeT inspired Supply approach worked and my initial design didn't? I want to double check, because I'm becoming more and more convinced that the FreeT inspired approach is both less general *and* less flexible
02:37:28 <eikke> Moggle_: some time ago I hacked on something alike. First using mingw/msys/whatever under windows, gave up in the end, used cross-compiling on my fedora system, and only required some minimal manual interventions. They ship glib etc for mingw as well
02:37:45 <merijn> elliott: I just wanna check whether I'm right before I throw out the FreeT inspired one and unify my two transformers
02:37:50 <adnap> Are you saying I should write all my programs as mathematical functions first and then translate them to Haskell?
02:38:04 <Moggle_> eikke: the pre-compiled glib is old. 2.8 or something, I need >= 2.36 to compile webkitgtk
02:38:33 <Moggle_> eikke: hence this ridiculous setup :D
02:38:41 <eikke> Moggle_: a little more work, but in the end it might still be easier to cross-compile ;-)
02:38:57 <mm_freak_> adnap: no, but you do use certain design patterns…  it's always a good idea to have a rigorious mathematical model for them, because design patterns without denotation and laws are meaningless
02:38:58 <Moggle_> eikke: I will look into figuring out how to cross compile, then! :D
02:39:06 <Moggle_> thanks for the suggestion
02:39:09 <Moggle_> it might save me time here
02:39:46 <adnap> mm_freak: At the very least, something written in Haskell will be a function...
02:39:57 <mm_freak_> adnap: 'linear' provides a mathematical (categorical) model of what linear algebra operations mean in terms of generic applicative functions…  the actual implementation is then the Functor/Applicative instance
02:40:12 <adnap> Even the least amount of design results in nice program
02:40:23 <merijn> adnap: "operational semantics" == "what really happens", worrying about when thunks are forced, laziness, etc. is all worrying about operational semantics
02:40:35 <mm_freak_> adnap: something written in haskell is actually just a value of type IO () =)
02:40:40 <mm_freak_> at least programs
02:40:51 <mm_freak_> so you can do all the nasty imperative programming you want to
02:41:03 <adnap> Huh?
02:41:22 <merijn> mm_freak_: Nasty imperative programming in haskell is the best kind of nasty imperative programming :)
02:42:08 <johnw> adnap: denotationally, 10/2 = 5/1; operationally, the two numbers may or may be represented by different bit patterns in memory, that's up to the implementer of Rational
02:42:46 <adnap> Okay. Clearly, operational does not have anything to do with the opposite of denotational
02:42:48 <merijn> also, "denotationally" just means "this collection of symbols"
02:43:25 <adnap> I really don't understand denotational semantics completely and I have read Conal's paper
02:43:29 <merijn> adnap: No, they are completely unrelated. i.e. denotational semantics tell you what a piece of code is supposed to *mean*, operational semantics tell you how you should expect it to be executed
02:43:53 <adnap> The idea seems to just be to define some semantic function which maps from Haskell to a mathematical model
02:44:42 <adnap> And make sure that the operations on the Haskell types correspond to operations on the mathematical model
02:45:06 <johnw> adnap: why would you want to go to that trouble?
02:46:02 <adnap> I don't know. I guess to piggyback on lots of existing mathematical ideas
02:46:22 <adnap> Which people seem to think are "beautiful"
02:46:23 * hackagebot gitlib 1.1.0 - API library for working with Git repositories  http://hackage.haskell.org/package/gitlib-1.1.0 (JohnWiegley)
02:46:25 * hackagebot gitlib-cmdline 1.1.0 - Gitlib repository backend that uses the git command-line tool.  http://hackage.haskell.org/package/gitlib-cmdline-1.1.0 (JohnWiegley)
02:46:27 * hackagebot gitlib-cross 1.1.0 - Run tests between repositories  http://hackage.haskell.org/package/gitlib-cross-1.1.0 (JohnWiegley)
02:47:43 <eikke> what does 'between repositories' mean?
02:48:43 <adnap> Could a library like linear be written in C with bindings to Haskell and still have the same pretty interface? Can you write anything functionally in C and still bind to a nice interface in Haskell?
02:48:52 <Kinnison> eikke: Whatever it means, it seems pretty empty
02:50:23 <mm_freak_> adnap: denotation semantics is pretty much a function from source code to math notation
02:50:36 <Lethalman> adnap, you can use FFI to use C from haskell
02:50:44 <mm_freak_> [[ liftA2 (+) a b ]] = a + b
02:50:48 <mm_freak_> where a and b are vectors
02:50:49 <adnap> Yes, I know that
02:50:57 <adnap> Lethalman
02:51:00 <mm_freak_> that's it
02:51:23 * hackagebot gitlib-libgit2 1.1.0 - Libgit2 backend for gitlib  http://hackage.haskell.org/package/gitlib-libgit2-1.1.0 (JohnWiegley)
02:51:25 * hackagebot gitlib-s3 1.1.0 - Gitlib repository backend for storing Git objects in Amazon S3  http://hackage.haskell.org/package/gitlib-s3-1.1.0 (JohnWiegley)
02:51:32 * hackagebot gitlib-sample 1.1.0 - Sample backend for gitlib showing the basic structure for any backend.  http://hackage.haskell.org/package/gitlib-sample-1.1.0 (JohnWiegley)
02:51:32 * hackagebot gitlib-test 1.1.0 - Test library for confirming gitlib backend compliance  http://hackage.haskell.org/package/gitlib-test-1.1.0 (JohnWiegley)
02:51:32 * hackagebot gitlib-utils 1.1.0 - Generic utility functions for working with Git repositories  http://hackage.haskell.org/package/gitlib-utils-1.1.0 (JohnWiegley)
02:51:33 <adnap> Well, I can't figure out how to write everything mathematically
02:51:44 <adnap> I tend to think in Haskell
02:52:01 <mm_freak_> you don't have to…  but if you think in haskell, you already employ a lot of that
02:52:23 <mm_freak_> every time you use fmap you refer to a mathematical functor
02:52:46 <adnap> Well, I think starting with a mathemtical model might lead to better interfaces
02:52:54 <mm_freak_> definitely
02:53:20 <adnap> Anyway, my question about the FFI was more specific
02:53:26 <adnap> Could a library like linear be written in C with bindings to Haskell and still have the same pretty interface? Can you write anything functionally in C and still bind to a nice interface in Haskell?
02:53:50 <johnw> writing linear in C sort of misses the point of that library
02:53:52 <mm_freak_> the data type in question could be implemented in C
02:54:06 <mm_freak_> the linear library has to be implemented in haskell
02:54:22 <adnap> I mean, could all the number crunching be written in C with the existing interface in Haskell?
02:54:25 <eikke> as far as I understood linear doesn't really 'do' anything, so there's not much you can 'implement in C'
02:54:30 <mm_freak_> adnap: yes
02:54:36 <adnap> If you wanted to just speed it up
02:55:03 <mm_freak_> the question is whether a C implementation would actually speed things up
02:55:10 <adnap> Of course
02:55:17 <adnap> C is way faster than Haskell
02:55:32 <adnap> Like 10 times faster
02:55:32 <mm_freak_> remember that ((->) a) is a perfectly valid vector type as far as linear is concerned
02:55:37 <johnw> adnap: where are you getting that from?
02:55:50 <adnap> The programming languages shootout
02:56:11 <eikke> interesting how linear also works over IntMap, I wonder whether sparse vectors could be easily modeled that way
02:56:12 <johnw> adnap: Haskell can sometimes beat C, not always, but it all depends on how much work you invest in solving the problem in both languages
02:56:13 <adnap> And that's with a terribly ugly Haskell program
02:56:14 <mm_freak_> adnap: really?  that's surprising…  i've written number (well, integer) crunching programs in haskell that outperformed every attempt i made to do it in C
02:56:32 <adnap> How the hell...
02:56:36 <johnw> eikke: linear does handle sparse vectors
02:56:41 <adnap> How could Haskell be faster than C?
02:56:46 <tiffany> and a terribly ugly C program as well
02:56:50 <merijn> adnap: Why couldn't it be?
02:56:52 <johnw> adnap: why wouldn't it be?
02:56:53 <Kinnison> adnap: Because it can optimise better under some circumstances
02:56:56 <adnap> More instructions
02:56:57 <eikke> adnap: inlining, fusion,...
02:57:16 <adnap> Also...
02:57:34 <adnap> Pure functions have to return a modified copy of thheir arguments
02:57:40 * Kinnison often finds that he can hack up a haskell solution, run it, and get an answer, more quickly than the equivalent cycle in C
02:57:48 <adnap> They can't modify something in-place
02:57:55 <merijn> adnap: Implementation detail
02:57:56 <nexx> C code also often outperform my ASM code
02:57:58 <mm_freak_> adnap: let me give you an example
02:58:04 <nexx> (not that I write much ASM)
02:58:05 <Kinnison> adnap: Not at the language level they can't -- but once compiled it often ends up doing so
02:58:07 <johnw> adnap: the persistence of data structures in Haskell allows for sharing of data in ways that can be more efficient
02:58:07 <merijn> adnap: I know functional languages that do do in place update
02:58:16 <Kinnison> adnap: Consider that LLVM has read-only registers, and that it produces good code
02:58:35 <merijn> (referentially transparent/pure functional languages, that is)
02:58:39 <johnw> adnap: be careful not to make too many operational assumptions about Haskell/GHC
02:58:44 <tiffany> there are more abstractions that haskell can compile out than there are for C
02:59:03 <mm_freak_> adnap: suppose that you have two library functions f and g in C, and you write "f(); g();" or "g(f())"…  in both cases the caller would call g, g would return, then the caller would call f, f would return
02:59:12 <mm_freak_> adnap: in haskell g would jump to f directly
02:59:32 <adnap> Well, the fact that the semantics of Haskell don't tell you much about the implementation is a problem for me
02:59:41 <johnw> adnap: why?
02:59:52 <adnap> How am I supposed to reason about my code?
03:00:00 <Kinnison> Haskell is from the top-down school of languages -- where expressing what you MEAN is more important than expressing how you want the computer to do it
03:00:00 <johnw> your answer does not make any sense to me
03:00:06 <mm_freak_> then you have micro-allocations in haskell, which corresponds to stack frame allocation in C…  often haskell's micro-allocation can outperform stack frame allocation
03:00:08 <tiffany> adnap: I suggest a language like rust, it has a better type system than C but without compromising on system's language-level features
03:00:13 <mm_freak_> all these little things add up
03:00:20 * Kinnison finds it very valuable to have code which corresponds to what he means rather than what he thinks the computer should do
03:00:39 <mm_freak_> the reason why a naively written haskell program is usually slower than its C counterpart is because the base library isn't really designed to be as efficient as possible
03:01:10 <Kinnison> e.g. people who do text manipulation entirely in String rather than Text
03:01:23 * hackagebot gitlib-utils 1.1.1 - Generic utility functions for working with Git repositories  http://hackage.haskell.org/package/gitlib-utils-1.1.1 (JohnWiegley)
03:01:25 * hackagebot gitlib-cmdline 1.1.1 - Gitlib repository backend that uses the git command-line tool.  http://hackage.haskell.org/package/gitlib-cmdline-1.1.1 (JohnWiegley)
03:01:36 <mm_freak_> String can be fine and even faster than Text, but in most cases it's not
03:01:41 <Kinnison> Aye
03:02:01 <Kinnison> Knowing when to use one or the other can be an "optimisation" which many people (myself included) don't always understand
03:02:27 <mm_freak_> it's a question of which strictness properties you want
03:02:42 <adnap> Knowing about how the program is executed is useful for optimization. If I don't know how things are carried out in Haskell and only concern myself with how pretty the code looks, I might have a pretty, slow program
03:03:09 <mm_freak_> in particular text editing gives rise to a particularly nice comonad, if you require that every text buffer has at least one character in it
03:03:25 <mm_freak_> or you consider EOF an actual special character
03:03:40 * Kinnison needs to learn about comonads
03:03:46 <Kinnison> But not today
03:03:52 <mm_freak_> learn about the store comonad…  it's simple and very useful
03:04:01 <Kinnison> mm_freak_: ta, I shall find that and bookmark it
03:04:16 <mm_freak_> newtype Store s a = Store s (s -> a)
03:04:40 <mm_freak_> it's an "array" with indices of type s together with an index
03:04:40 <adnap> Anecdoates about how Haskell *might* be faster than C don't help me reason about arbitrary Haskell programs, and I'm not comfortable just hoping that all kinds of neat optimizations are being carried out by the compiler
03:05:07 <Kinnison> Is http://stackoverflow.com/questions/8766246/what-is-the-store-comonad a good discussion o fit?
03:05:11 <mm_freak_> adnap: yes, it needs some experience, but most of it boils down to one question:  "what happens when i pattern-match?"
03:05:59 <johnw> adnap: it's true, you do need some operational knowledge to best optimize programs, even in Haskell; but I think you can defer that until you've got more of the concepts firmly under your belt
03:06:15 <mm_freak_> Kinnison: i don't find that one very helpful, because it's too lens-centric
03:06:31 <mm_freak_> Kinnison: rename "Store" to "Picture"…  does that help?
03:06:33 <Kinnison> mm_freak_: Bah, I'll just bookmark the hoogle page about Control.Comonad.Store.Lazy then
03:06:43 <mm_freak_> type Picture = Store (Int, Int) Pixel
03:06:46 <Kinnison> mm_freak_: I have not read any of it, I'm just bookmarking for future thought
03:07:00 <mm_freak_> it's a picture together with a cursor
03:07:07 <mm_freak_> 'extract' peeks
03:07:08 <adnap> And when I look at the Haskell entries for the programming languages shootout... they're really ugly and are just written in a C style with arrays and such
03:07:30 <mm_freak_> the really useful thing about stores is 'extend'
03:07:30 <adnap> And there are strictness flags everywhere
03:07:34 <Lethalman> mh some of those are written rather nicely
03:07:34 <merijn> arrays and "C style" seem two orthogonal concepts for me
03:07:50 <mm_freak_> extend :: (Store s a -> b) -> Store s a -> Store s b
03:08:01 <adnap> I mean they use mutable state
03:08:04 <mm_freak_> extend :: (Picture -> Pixel) -> Picture -> Picture
03:08:13 <adnap> It's not necessary in C
03:08:26 <adnap> So that was a bad way to describe it
03:08:27 <mm_freak_> it allows you to give pixel values by looking at the neighbourhood of that pixel
03:08:33 <johnw> Kinnison: a related concept which comes up often in reading articles about comonads is cellular automata; you may want to read up on them too, as the abstraction they represent is nicely expressed by comonads
03:08:45 <mm_freak_> that, for example, allows you to express a very concise blurring filter
03:08:47 <merijn> adnap: What's wrong with using mutable state?
03:08:53 <Lethalman> adnap, this is rather nice for example: http://benchmarksgame.alioth.debian.org/u64q/program.php?test=binarytrees&lang=ghc&id=4
03:08:58 <mm_freak_> blurImage = extend blurPixel
03:08:59 <Kinnison> johnw: ta
03:09:16 <mm_freak_> where blurPixel gives you an average of the surrounding pixels at the cursor
03:09:29 <mm_freak_> blurPixel :: Picture -> Pixel
03:09:35 <mm_freak_> does that make sense?
03:09:53 <adnap> What graphics library are you talking about?
03:09:54 <Lethalman> this as well: http://benchmarksgame.alioth.debian.org/u64q/program.php?test=mandelbrot&lang=ghc&id=2
03:09:59 <mm_freak_> adnap: comonad =)
03:10:10 <adnap> That's a graphics library?
03:10:10 <Lethalman> they seem fine to me, not much of "mutable state"
03:11:02 <merijn> Lethalman: Well, I have some stylistic issues with the code, but overal it looks ok, yeah
03:11:04 <mm_freak_> adnap: Control.Comonad.Store from 'comonads-fd' is to graphics what 'linear' is to linear algebra =)
03:11:32 <adnap> That analogy mdoes not make sense to me
03:11:40 <adnap> I need some experience with these
03:12:02 <adnap> I have tried a few Haskell graphics libraries
03:12:11 <mm_freak_> adnap: a store comonad stores a certain indexed structure together with a cursor
03:12:35 <adnap> drawingcobinators and gpipe
03:12:40 <mm_freak_> for example an infinite list [a] can be loosely modelled as Int -> a
03:12:43 <adnap> gpipe was so sloooow
03:13:14 <mm_freak_> then 'Store Int a' is the type of infinite lists with a current index, a cursor
03:13:26 <mm_freak_> Store Int a ~ (Int, Int -> a)
03:13:30 <mm_freak_> does that make sense?
03:13:33 <adnap> No
03:13:41 <mm_freak_> nothing to do with graphics yet
03:13:43 <adnap> What is ~?
03:13:48 <mauke> type equality
03:13:54 <mm_freak_> read it as "isomorphic to"
03:14:43 <adnap> You mean a bijective homomorphism exists?
03:15:01 <mauke> in this case, it directly expands to (Int, Int -> a)
03:15:48 <mm_freak_> adnap: i'm not very rigorous here…  you can read it as "resembles", if you want
03:15:58 <mm_freak_> it's just the idea that you store a function together with an argument
03:16:09 <adnap> "isomorphism" gets thrown around so loosely
03:16:23 <merijn> adnap: Operationally (not in this context, but in haskell source) ~ means that two types unify
03:16:35 <merijn> I guess that's not very operational
03:16:36 <merijn> whatever
03:16:49 <merijn> Semantics are hard, let's go shopping!
03:16:49 <adnap> I understand this type
03:16:58 <mm_freak_> adnap: good, that's totally enough for now =)
03:17:00 <adnap> You've got an indexed list of pixels
03:17:06 <adnap> and an index for the cursor
03:17:25 <mm_freak_> adnap: now let's get two-dimensional:  type Picture = Store (Int, Int) Pixel
03:17:34 <mm_freak_> a picture together with a cursor
03:17:37 <adnap> This is like Conal's work
03:17:47 <mm_freak_> in this case it's edward's work =)
03:17:58 <adnap> He uses the same semantics for an image
03:18:12 <mm_freak_> yeah, because it's great
03:18:21 <johnw> linear provides a type class so that you can interact with its instances as vector spaces.  So, by importing linear, you can suddenly add two Map String Int's together by just using ^+^ without having to do any extra work.  What Data.Monoid is to things that can be treated like monoids, Linear is to things that can be treated like vector spaces
03:18:33 <mm_freak_> anyway, now imagine that you have the following function:
03:18:40 <mm_freak_> blur :: Picture -> Pixel
03:18:52 <adnap> Holy shit johnw
03:19:04 <adnap> add two maps?
03:19:09 <mm_freak_> this takes a picture and blurs the pixel at the cursor by looking it the neighbourhood…  it just returns the blurred pixel value, nothing else
03:19:10 <johnw> if the value is a number, yes
03:19:19 <mm_freak_> adnap: still makes sense?
03:20:03 <adnap> What is a Picture?
03:20:13 <adnap> And why are you calling a color Pixel?
03:20:13 <mm_freak_> type Picture = Store (Int, Int) Pixel
03:20:22 <mm_freak_> it doesn't matter
03:20:35 <mm_freak_> i'll call it Color if you find that more comfortable =)
03:20:40 <adnap> Isn't (Int,Int) the pixel?
03:20:45 <mm_freak_> type Picture = Store (Int, Int) Color
03:20:50 <mm_freak_> blur :: Picture -> Color
03:20:53 <mm_freak_> better?
03:20:58 <adnap> Alright alright
03:21:09 <adnap> Yes, it makes sense
03:21:25 <mm_freak_> but you want to blur the entire image, not just one pixel
03:21:41 <adnap> What does it mean to blur a pixel?
03:21:42 <mm_freak_> how do you achieve that without reinventing 'blur' for the whole image?
03:21:51 <adnap> You need a neighborhood to blur
03:22:11 <mm_freak_> use your imagination…  the neighborhood is there…  you have an image with a cursor
03:22:15 <mm_freak_> that gives you a neighborhood
03:22:27 <tiffany> you also need to pass a radius to blur by
03:22:51 <adnap> That is what a neighborhood is
03:23:07 <mm_freak_> i want to keep things simple…  say that the 'blur' function really just looks at the four/eight adjacent pixels
03:23:18 <mm_freak_> this is completely besides the point
03:23:42 <adnap> Okay..
03:24:16 <adnap> I still don't understand your question about blurring the entire image because I don't know specifically what it means to blur one pixel
03:24:37 <mm_freak_> you have some function that looks at a neighborhood and derives a new value:  w a -> b
03:24:40 <tomboy64> i want to store predicates for a filter in a list, like this: predicates x = [ ((getIndex 'G' x) == 0 || (getIndex 'E' x) == 0) ], but haskell interpretes that as [Char] -> [Bool] - and it wants it to be [[Char] -> [Bool]]
03:24:42 <adnap> I assume you intend to just map the blur opeation over every index
03:24:49 <tomboy64> i'm a bit confused
03:24:58 <mm_freak_> and you want to "extend" this function to construct a completely new structure from it
03:25:04 <mm_freak_> that's what comonads do
03:25:18 <mm_freak_> blur :: Picture -> Color
03:25:23 <mm_freak_> extend blur :: Picture -> Picture
03:25:36 <adnap> Uh, okay
03:25:49 <tomboy64> i want to map it over like map (\x -> filter x list) [list,of,filters]
03:25:51 <adnap> Sorry, that was way too vague
03:25:55 <mm_freak_> so you have a function that blurs a single pixel…  you can extend it to blur the whole image
03:26:04 <adnap> Yeah...
03:26:05 <mm_freak_> that's what comonads have to do with graphics in a very abstract sense
03:26:07 <mauke> blur :: IndexedPicture -> Color
03:26:21 <adnap> I don't even know what a comonad is
03:26:37 <adnap> I think that would be helpful first
03:26:39 <mm_freak_> flip the arrows of 'return' and (>>=)
03:27:04 <mm_freak_> where w is a comonad:  extend :: (w a -> b) -> w a -> w b
03:27:10 <mm_freak_> and:  extract :: w a -> a
03:27:57 <mm_freak_> adnap: explaining comonads is not any simpler than explaining monads, so be brave =)
03:28:10 <adnap> And does comonad help with triangulation, or LOD, ray tracing, and other graphics topics, or is it just helpful for representing images?
03:28:32 <mm_freak_> i doubt that it would help with any of those
03:29:06 <mm_freak_> but look at image/movie editors…  you can express most filters as single-pixel filters and then just 'extend' them
03:29:21 <mm_freak_> with a proper image/movie type you also get parallelism for free that way
03:30:05 <adnap> Yeah, well you can do the same thing with a function, array, and for loop
03:30:42 <mm_freak_> it's a different coding style…  in haskell we love to look at things in isolation
03:30:46 <adnap> Image manipulation lends itself to being broken down into per-pixel operations
03:30:58 <mm_freak_> in a picture you can't get much more isolated than looking at a single pixel =)
03:31:17 <mm_freak_> and remember, pictures/movies are a very specific application
03:31:21 <adnap> But I don't think people do it any differently in C
03:31:30 <mm_freak_> comonads extend (hehe) to many areas =)
03:31:49 <adnap> As far as breaking the problem down goes
03:32:12 <mm_freak_> they do it very differently in C…  filters are pretty much self-contained there
03:32:17 <adnap> The types of the comonad operators are interesting
03:34:08 <adnap> They're so abstract like monad operators through. I don't know how I would use them
03:35:11 <adnap> I end up using monads and applicatives becuase I use libraries that define instances of them and I am forced to, but I never think of instances for my own types
03:36:50 <adnap> I don't know if I'm supposed to have an "ah-ha" moment and realize that my types have an applicative/monad/comond instance, or if I should try to design types from these classes
03:37:52 <merijn> adnap: I usually design types first, then try to fit them into existing typeclasses (potentially changing them a little to fit)
03:38:31 <adnap> My own types are usually just records without any interesting structure
03:38:56 <adnap> Or I don't even bother encapsulating, and just write functions with more arguments
03:39:03 <merijn> adnap: Maybe you're just not working on things that generalise well, then
03:39:08 <merijn> eh
03:39:13 <merijn> *don't* generalise well
03:39:41 <merijn> adnap: Recent example (which I'll hopefully finish once elliott can help answer some design issues :p)
03:40:27 <merijn> adnap: I was playing around with reactive-banana (FRP library) which encourages the use of Applicatives to compose Behaviors, and I ran into the problem of needing to get unique names
03:40:55 <adnap> I am also using reactive-banana
03:40:59 <merijn> I didn't want to have to manually provide them, as that is error prone. The solution is a transformer that wraps the behavior applicative with a supply of unique names
03:41:25 <adnap> Oh, I have this problem too
03:42:28 <klrr> anyone got an idea of a program i can write? i wanna write something that is either useful to me, or sth like a library that might be useful for others at least
03:43:19 <merijn> So instead of composing "(Behavior (a -> b)" "Behavior a" into "Behavior b" I compose "SupplyT s Behavior (a -> b)" and "SupplyT s Behavior a" into "SupplyT s Behavior b". Now it's a matter of doing "runSupplyT :: SupplyT s f a -> (s -> s) -> s -> f a" Where s is the type of names
03:43:44 <merijn> To specialise "runSupplyT :: SupplyT Int Behavior a -> (Int -> Int) -> Int -> Behavior a"
03:44:39 <merijn> adnap: I hope to get a library finished for that today/this week, I just need to fix some minor issues and finish documenting
03:44:57 <merijn> And by fix some minor issues I mean "potentially throw away half the code and unify it with the other half"
03:45:08 <adnap> I don't understand runSupplyT
03:45:32 <adnap> What is the purpose of the Int -> Int function?
03:45:59 <merijn> adnap: "SupplyT s f a" is the type of a computation that consumes values of type s to produce an "f a", the "s -> s" function is used to generate unique names
03:46:21 <adnap> Uh...
03:46:23 <supki> merijn: why would you need an applicative transformer?
03:46:34 <supki> I mean composition of applicatives is applicative, no?
03:46:42 <merijn> adnap: Suppose we want to use unique integers as names, you'd call it with "runSupplyT myCompotation (+1) 0"
03:46:46 <adnap> How could the resulting value of type s be any more unqiue?
03:46:48 <klrr> anyone got an idea of a program i can write? i wanna write something that is either useful to me, or sth like a library that might be useful for others at least
03:46:59 <adnap> Oh...
03:47:03 <merijn> adnap: It consumes an unknown number of s values, not just one
03:47:10 <adnap> The function is a way to get to the next id
03:47:15 <merijn> adnap: Yes
03:47:32 <adnap> Why do you bother to combine the supply and the behaviors?
03:47:33 <Botje_> klrr: not really a program, but you could write small snippets of code for various packages to show how they're used
03:47:34 <merijn> supki: Two reasons, I hope to merge it with the monad transformer and it lets me simplify the use
03:47:47 <merijn> adnap: I'm using unique names *inside* the Behavior
03:48:00 <adnap> Wha?
03:48:10 <klrr> Botje_: you mean like contibuting documentation? :D sounds interesting
03:48:12 <adnap> The Behavior still has its own type
03:48:22 <merijn> adnap: Sure, after you run it, it does
03:48:27 <adnap> You just have a map from id to Behavior
03:48:33 <merijn> adnap: No
03:49:16 <adnap> Well, I don't understand then
03:49:58 <adnap> Seems like you have a map from id to Behavior and a function to produce the next id from the previous one
03:50:00 <Botje_> klrr: compare the Data.Map documentation to pretty much any other package out there to see what I mean :)
03:50:23 <adnap> I'm not sure why you combined these into a single type
03:50:39 <merijn> adnap: "supply :: (s -> f a) -> SupplyT s f a", "foo :: Int -> Behavior Bool" "supply foo :: SupplyT Int Behavior Bool", you can now compose that together with, say "bar :: a -> b -> Bool -> Behavior (Either a b)"
03:51:41 <merijn> eh, wrong type for bar
03:51:44 <klrr> Botje_: almost every function have code examples =o
03:52:40 <merijn> "bar :: a -> b -> Int -> Behavior (Bool -> Either a b)", "bar 1 'c' :: Int -> Behavior (Bool -> Either a b)", "supply (bar 1 'c') :: SupplyT Int Behavior (Bool -> Either a b)"
03:53:06 <klrr> Botje_: i will do that, just gonna try find a package to start with :)
03:53:26 <adnap> I don't understand
03:53:41 <merijn> adnap: Now "supply (bar 1 'c') <*> supply foo :: SupplyT s Behavior (Either a b)", runSupplyT and you magically obtain "Behavior (Either a b)" without having to manually pass Int's everywhere
03:54:42 <supki> klrr: lens!
03:54:44 <adnap> I don't get it
03:55:16 <merijn> adnap: I don't know where to start explaining from the observation "I don't get it"
03:55:29 <adnap> I'm just going to go to bed
03:57:51 <adnap> Okay, I get it
03:58:00 <adnap> I don't see the point...
03:58:39 <adnap> The applicative operators act on the two behavior types, and the supply gets carried along
03:58:45 <merijn> adnap: Yes
03:59:27 <adnap> What is the point of combining all this into one type?
04:00:04 <merijn> adnap: How else would you pass the supply along?
04:00:18 <merijn> Passing the supply along is exactly what the SupplyT type is doing
04:00:23 <adnap> As a map
04:00:34 <klrr> supki: lenses, i dont even know how they work and what they are for, are they important to learn?
04:00:41 <merijn> adnap: How would you get that map where it needs to be?
04:00:56 <merijn> klrr: They are for nested updates of data structure
04:01:25 <adnap> You just have Int -> Behavior a and you fmap the applicative operators
04:01:27 <merijn> imagine you have record in a Map in a Map and want to set a value of one, sounds like an annoying task, right?
04:01:37 <adnap> to change the result of the function
04:01:58 <merijn> adnap: That passes the same Int to every function
04:02:14 <adnap> No
04:02:33 <adnap> This is a function from Int -> Behavior a
04:02:46 <merijn> adnap: Then I'm not sure what you mean by "fmap the applicative operators"
04:02:54 <adnap> fmap on functions
04:03:04 <merijn> adnap: Yes, but fmap on functions passing the
04:03:07 <adnap> changes the type of the result
04:03:19 <adnap> And that is a Behavior
04:03:27 <merijn> adnap: I'm not changing the type of the result, I'm suppling them with an Int
04:03:43 <merijn> fmap on functions is just composition
04:03:45 <klrr> merijn: okey, in what scenarios is it useful for?
04:04:06 <merijn> klrr: Nested record data structures in the State/Reader monad, for example
04:04:22 <adnap> So if you have two functions (Int -> Behavior (a -> b)) and (Int -> Behavior a)...
04:04:33 <merijn> :t fmap `asAppliedTo` (undefined :: Int -> Behavior (a -> b))
04:04:34 <lambdabot>     Not in scope: type constructor or class `Behavior'
04:04:40 <merijn> blah
04:04:54 <merijn> :t fmap `asAppliedTo` (undefined :: Int -> f a)
04:04:55 <lambdabot> Functor f => (Int -> f1 a) -> f Int -> f (f1 a)
04:05:42 <merijn> adnap: You're thinking of the ((->) r) instance of applicative, probably. But that does something different from what Supply does
04:06:07 <adnap> Okay, I don't understand
04:06:12 <adnap> I'm too tired
04:06:51 <adnap> I am curious as to what you are making this for, and if you intend to make a package that is specific to reactive-banana
04:06:54 <merijn> adnap: ((->) r) is just the reader applicative, it passes *one* value to a bunch of functions. Supply passes a *different value to every single function*
04:12:40 <adnap> merijin: Are you still there?
04:12:54 <adnap> merijn: ^
04:13:53 <merijn> Yeah
04:14:27 <adnap> Where is the logic that creates mappings from id to Behavior?
04:14:41 <merijn> adnap: It's not creating mappings
04:14:53 <merijn> I need unique identifiers inside my Behaviors
04:15:10 <merijn> I don't care what they are, as long as no Behavior gets the same one
04:15:27 <adnap> Why do you say "inside"?
04:15:56 <merijn> "Int -> Behavior a" creates a behavior given an Int, I don't care what Int I give it, just that it's unique
04:16:24 <adnap> So, you're Behaviors are derived from Ints?
04:16:27 <adnap> *your
04:16:28 <merijn> adnap: Yes
04:16:36 <adnap> Okay
04:17:09 <merijn> adnap: Combining behaviours the want an Int into bigger behaviours results in a Behaviour that is derived from a supply of Ints
04:17:24 <adnap> Okay
04:17:29 <adnap> So you need two ints
04:17:39 <adnap> if you have two supplies
04:17:49 <adnap> To get two behaviors
04:17:58 <adnap> to combine them into one
04:18:28 <merijn> Yes
04:18:33 <isomorphic> Hrmm - is there a quick way to match any data constructor of a type?  eg: Data Color = Red | Green | Blue - must I write function Red = … ; function Blue = …
04:18:38 <adnap> Will you explain what upyou are using this for?
04:18:46 <adnap> *you
04:18:51 <merijn> isomorphic: You mean if you don't care which it is?
04:18:58 <isomorphic> merijn:  Yes
04:19:10 <mauke> function _ = ...
04:19:16 <merijn> isomorphic: Just use a variable match "foo :: Color -> Bool; foo _ = True"
04:19:45 <merijn> isomorphic: "foo bar = True" would also work, but _ doesn't generate complaints about unused variable bindings
04:20:41 <isomorphic> merijn, mauke :  Ah - I've discovered a new requirement ;)  I do actually need the variable in the function.  Actually, I have a data Foo x = Foo1 x | Foo2 x and I'd like to implement show for (Show x)
04:21:08 <merijn> isomorphic: Ah, then no
04:21:11 <mauke> data Foo x = ... deriving (Show)
04:21:22 <merijn> But yes, deriving should solve the issue :p
04:21:25 * hackagebot NetSNMP 0.3.0.5 - Bindings for net-snmp's C API for clients  http://hackage.haskell.org/package/NetSNMP-0.3.0.5 (PavloKerestey)
04:21:33 <adnap> merijn: Did you see my question?
04:21:43 <isomorphic> Deriving sort of works - but I have some strings and the escaping ends up looking \" weird \"
04:21:52 <mauke> it's supposed to look like that
04:22:02 <mauke> data Foo x = Foo1{ function :: x } | Foo2{ function :: x }
04:22:11 <mauke> data Foo = Foo Bool x
04:22:47 <merijn> adnap: I'm using identifiers to keep track of which Behavior "has" focus, I'm just using the unique Int I passed to the behavior and comparing it to the "focussed :: Behavior Int" if the two match, this behavior has the focus
04:23:18 <isomorphic> Normally that would be okay - what I'm doing is abusing show to print some exception information - my Foo type is an exception type.   I though for neatness I might get rid of the \"s
04:23:25 <adnap> Oh, I see
04:23:59 <adnap> merijn: You said you are implenting a package. What will it be for?
04:24:03 <isomorphic> mauke: merijn :  Thanks for the help :)
04:24:49 <merijn> adnap: GUI framework, if I ever get that far without stopping to yak shave on the way
04:31:25 * hackagebot amqp 0.4 - Client library for AMQP servers (currently only RabbitMQ)  http://hackage.haskell.org/package/amqp-0.4 (HolgerReinhardt)
04:38:09 <klrr> does this look like a lambda? ",\"
04:39:27 <HugoDaniel> klrr: no
04:41:25 * hackagebot fig 1.4.0 - Manipulation of FIG files  http://hackage.haskell.org/package/fig-1.4.0 (AndersLauOlsen)
04:41:56 <quchen> That looks like comma-lambda.
04:42:11 <klrr> what is the most common way of calling a terminal command?
04:42:55 <mm_freak_> klrr: System.Process
04:43:42 <klrr> mm_freak_: thanks!
05:05:54 <elliott> merijn: do { x <- supply; liftIO $ print (); y <- supply; ... }
05:06:00 <elliott> and consider the case where supply is fed from getLine.
05:06:15 <elliott> in fact, I rather doubt your applicative form is a valid monad transformer
05:06:23 <elliott> because it must run the print after the supply, but then what about
05:06:39 <elliott> do { x <- supply; b <- liftIO $ readLn; when b supply }
05:11:36 <acube> @pl let f = f n g = f (g n) pred
05:11:36 <lambdabot> (line 1, column 16):
05:11:36 <lambdabot> unexpected " "
05:11:36 <lambdabot> expecting operator
05:11:47 <acube> @pl \x n g = x (g n) pred
05:11:47 <lambdabot> (line 1, column 8):
05:11:47 <lambdabot> unexpected "="
05:11:47 <lambdabot> expecting pattern or "->"
05:11:51 <acube> @pl \x n g -> x (g n) pred
05:11:52 <lambdabot> flip flip pred . (flip .) . (. flip id) . (.)
05:11:53 <chrisdone> elliott: http://chrisdone.com/shm-adjust.ogv you jelly?
05:12:11 <Bor0> what does @pl mean?
05:12:18 <int-e> pointless
05:12:32 <int-e> an opinionated pun on point-free
05:13:07 <luite> chrisdone: cool! :)
05:13:10 <elliott> chrisdone: nice!
05:13:13 <chrisdone> :D
05:13:16 <elliott> chrisdone: finally haskell learns how to be lisp ;)
05:13:37 <chrisdone> elliott: you got it ;)
05:14:18 <luite> also jelly about high res letters :p
05:14:39 <chrisdone> haha <3
05:15:04 <luite> gchsj linking is 10x faster now that i switched to binary object files \o/
05:15:06 <luite> ghcjs
05:15:17 <luite> and i can do link-time optimization now
05:15:32 <chrisdone> \o/
05:15:41 <rootnode> sometimes I think my head will explode when I read this channel ^^
05:15:43 <arcatan> ä
05:15:47 <ion> What kind of binary object files?
05:15:51 <chrisdone> is it using the `binary' package?
05:16:00 <arcatan> what i mean by ä is \o/
05:16:03 <luite> ion: serialized JMacro AST with an index and some metadata
05:16:08 <luite> using binary yeah
05:16:11 <ion> luite: Alright
05:16:14 <chrisdone> nice
05:16:15 <ion> Not cereal?
05:16:56 <luite> ion: i use cereal for some other binary intermediate files (that describe the function dependencies, but not the code itself)... really i should learn to be more consistent in my library choices :)
05:17:05 <chrisdone> ion: we were trying to ascertain the difference between binary and cereal
05:17:13 <ion> luite: heh
05:17:14 <luite> lazy vs strict bytestrings...
05:17:22 <luite> but they really should be merged
05:17:33 <chrisdone> from what i've been able to do from casual searching is strict vs lazy. performance-wise i haven't found any cogent benchmarks
05:17:35 <luite> so that instances can work with either
05:17:47 <chrisdone> ah, also that binary doesn't do backtracking
05:18:11 <ion> Wasn’t the major difference that “decode” in binary returns bottom upon failures? Or have they fixed that by now?
05:18:14 <luite> i think the plan was to add the missing bits to binary
05:18:18 <quicksilver> I was going to say
05:18:23 <quicksilver> cereal can detect parse failures
05:18:24 <chrisdone> iirc cereal can do backtracking, which Lennart told me is a speed hit
05:18:33 <quicksilver> that was the key difference I recall
05:20:22 <ion> @hackage safecopy is also nice.
05:20:22 <lambdabot> http://hackage.haskell.org/package/safecopy is also nice.
05:20:38 <klrr> anyone got an idea of a program or library i can write?
05:20:48 <chrisdone> ion: i don't think it's fixed. if the parse fails it throws an exception. lazily
05:21:00 <luite> quicksilver: binary does have a way to fail, runGetOrFail
05:21:22 <ion> Safecopy adds on top of cereal versioned serialization with automatic migration when you need to change the format.
05:21:28 <luite> using fail in the Get monad
05:21:35 <luite> perhaps that was added recently
05:22:01 <quicksilver> luite: yes. FSOV "recently"
05:22:15 <quicksilver> sometime between 2007 and now.
05:22:17 <luite> hehe
05:22:37 <luite> ion: GHCJS object files are incompatible between versions anyway so i don't really need versioning
05:22:51 <luite> except perhaps to make sure that it never loads outdated files
05:23:39 <ion> luite: Sure, i didn’t expect it to be useful for the object files; i mentioned it on the topic of serialization in general.
05:23:53 <luite> yeah it's a nice lib
05:24:25 <ion> Just detecting outdated files might be better done by adding and checking a tag directly.
05:24:37 <luite> yeah i'm going to do that
05:25:47 <luite> i'm restructuring a bit anyway, since i want more metadata to be stored directly, not in JMacro format (function arities, static references etc, basically what GHC stores in the info tables, can be generated more efficiently at link time)
05:26:16 <luite> perhap also string and numeric constants
05:26:34 <ion> Hmm, i suppose one *could* use SafeCopy without migrations just for version tagging.
05:27:37 <luite> is the api as complete as binary/cereal?
05:28:12 * elliott finds it sort of a shame that binary and cereal and attoparsec aren't unified... yeah attoparsec has a little different goals but it feels like there's such overlap api-wise
05:30:02 <merijn> elliott: Ola, I need to bug you (hopefully) one last time
05:30:20 <luite> btw what would be a good way to store the symbol table separately? the Get Monad interface seems to make that hard.
05:31:08 <merijn> You were describing (1 or 2 days ago?) an issue with my initial design not working with monad transformers? Can you point out what that was, because the more I think about it, the more I believe my original approach was sound
05:31:10 <ion> luite: AFAIU you can just implement a Serialize instance and your SafeCopy instance can use generics to define “getCopy = contain get; putCopy = contain . put”.
05:31:27 <luite> ion: ah makes sense
05:31:27 <elliott> merijn: I replied :)
05:31:41 <elliott> 13:05:32 <elliott> merijn: do { x <- supply; liftIO $ print (); y <- supply; ... }
05:31:44 <elliott> 13:05:38 <elliott> and consider the case where supply is fed from getLine.
05:31:45 <elliott> oops, sorry for flood
05:31:47 <elliott> 13:05:53 <elliott> in fact, I rather doubt your applicative form is a valid monad transformer
05:31:51 <elliott> 13:06:01 <elliott> because it must run the print after the supply, but then what about
05:31:52 <merijn> oh, silly me
05:31:53 <elliott> 13:06:17 <elliott> do { x <- supply; b <- liftIO $ readLn; when b supply }
05:31:56 <elliott> looked smaller in lastlog :)
05:31:59 <merijn> oh didn't notice the PM hiligh
05:32:51 <merijn> elliott: I don't think it matters, because the Supply monad first satisfies the first item before every moving on to the next?
05:33:18 <luite> extracting all symbols and writing them compactly as a suffix tree is pretty easy, but using the data in Put/Get isnt
05:33:29 <merijn> elliott: My applicative works with monadic feeding, the one I based on FreeT doesn't work with monadic generation
05:34:54 <luite> oh wait, i don't use Get/Put instances anyway (the serializers are partial and i don't like adding orphan instances for JMacro stuff) so it's easy!)
05:34:56 <merijn> elliott: i.e. "do { x <- supply; liftIO $ print () }" won't proceed to the print until x has been supplied
05:35:17 <elliott> I don't know what you mean.
05:35:30 <elliott> again, remember that the whole point is that you can feed it from more than a list
05:35:35 <luite> that also gives me free hash consing when loading objects
05:35:37 <merijn> oh, wait "x <- supply" is nonsensical
05:35:38 <elliott> you can run a Supply action that does getLine whenever supply is run
05:35:47 <elliott> ???
05:36:03 <merijn> elliott: Or rather, I've called that "demand" :p
05:36:29 <merijn> "demand :: Supply s s", "supply :: (s -> a) -> Supply s a"
05:36:43 <luite> btw if anyone has a slow sshfs mount, use woraround=nodelaysrv :) i can't believe how much better this works and how long i put up with that annoying lag
05:36:48 <merijn> (since you're supplying a function with an s or "demanding" an s
05:37:20 <luite> editing files with emacs on a remote server works acceptably now, running ghc-mod through vado :)
05:37:31 <merijn> elliott: Anyway, my initial design was "data SupplyT s m a = Done (m a) | More (s -> SupplyT s m a)", which works fine with feeding from monadic actions, etc
05:38:05 <merijn> elliott: The approach used by FreeT (which you referred too) is "data SupplyT s m a = Done a | More (s -> m (SupplyT s m a))"
05:38:18 <elliott> merijn: I don't believe you. I do not see how that SupplyT can handle my two examples
05:38:21 <elliott> the first one
05:38:39 <elliott> ok, let's say we have runSupplyTAction :: SupplyT s m a -> m s -> m a
05:38:58 <elliott> the semantics are, whenever the action runs supply (demand, whatever), it runs the monadic action to obtain the response.
05:39:31 <merijn> elliott: hmm, the one is possible to implement with the FreeT, I guess.
05:39:34 <elliott> now, it should be the case that: runSupplyTAction (do { x <- supply; liftIO $ print (); y <- supply; return (x, y) }) getLine = do { x <- getLine; print (); y <- getLine; return (x, y) }
05:39:55 <elliott> and that: runSupplyTAction (do { x <- supply; b <- liftIO readLn; when b supply }) getLine = do { x <- getLine; b <- readLn; when b getLine }
05:40:01 <merijn> elliott: You see to be thinking of something entirely opposite from what I want, though
05:40:05 <elliott> I simply don't believe you can do this with your SupplyT
05:40:19 <merijn> elliott: You are paremeterising the supply with m, rather than the result, I think?
05:40:24 <elliott> but more to the point, I simply don't believe you can make it a MonadTrans at all.... how can you represent the "when b supply" there?
05:40:38 <elliott> by the time you can run effects in m, there is no chance to ask for more.
05:40:55 <elliott> merijn: I don't know what you mean
05:43:46 <merijn> elliott: You want the supply to be obtained on demand, which is the exact opposite of what I initially wanted, which explains why your so explanation is so at odds with my initial design. I just didn't notice that before
05:44:18 <chrisdone> hamishmack: i love your g+ picture. it's like “yeah i'm australia. problem?”
05:45:35 <elliott> merijn: well, not exactly.
05:45:40 <elliott> I want the flexibility
05:45:54 <elliott> the ability to feed from both lists, user input, RNG state etc. is very powerful IMO
05:46:01 <merijn> elliott: If that's *not* what you want, then I'm convined *your* the one who is confused
05:46:06 <elliott> and is the clear advantage over the State approach
05:46:26 <merijn> elliott: That's easy, just feed it "repeat (getLine)" from a list
05:46:34 <elliott> ???
05:46:46 <elliott> that will supply it IO Strings, not Strings.
05:47:09 <elliott> ok, but really, forget where the supply comes from
05:47:18 <elliott> do { b <- lift m; when b supply }
05:47:23 <elliott> how do you represent this with your original SupplyT?
05:47:27 <elliott> can you write out the value for me?
05:47:42 <elliott> data SupplyT s m a = Done (m a) | More (s -> SupplyT s m a) -- this one
05:48:00 <elliott> oh, er, what you said was the FreeT approach wasn't actually the same as how FreeT does it... but anyway
05:48:15 <merijn> elliott: It is, I hand substituted it
05:48:35 <merijn> I simplified it a little to eliminate the unnecessary extra type
05:49:30 <elliott> no
05:49:41 <elliott> it is not the same because running actions in "m" is not tied to requesting new values from the supply with FreeT.
05:49:46 <elliott> but anyway, that's a sidetrack.
05:49:59 <merijn> elliott: That's my point
05:50:01 <hamishmack> chrisdone: My dad is Australian, but I am a Kiwi.  Also I actually have a Canadian olympics top on in that photo (although it is hard to tell)
05:50:17 <merijn> elliott: You want the m to be attached to the supplied value
05:50:25 <elliott> well, if that's your point, then you rewrote it into something distinctly non-equivalent to the FreeT. not hand substitution, meaning changing
05:50:29 <merijn> elliott: I'm trying to constructing something with m attached to the result
05:50:39 <elliott> anyway, I'm still most interested in how you expect to represent do { b <- lift m; when b supply }.
05:51:47 <merijn> :t when
05:51:48 <lambdabot> Monad m => Bool -> m () -> m ()
05:54:58 <merijn> Lemme see "lift m >>= \b -> when b supply", "lift = Done", "when b m = if b then m else return ()", "Done m >>= \b -> if b then supply else return ()" "supply = More $ \s -> Done (return s)"
05:55:08 <mapreduce> Can one pattern match on Data.Map's Map?
05:55:28 <elliott> merijn: ok, so now expand >>=
05:55:35 <merijn> "(Done x) >>= f = join $ Done (liftM f x)"
05:55:58 <dropdrive> Do GADTs ever derive Show automatically?
05:56:12 <elliott> ok, so now expand join...
05:56:33 <merijn> hold on, i'm doing this in vim
05:57:47 <jmcarthur_mobile> I'm especially curious what happens if you wrap this in forever... Will m ever execute then?
05:58:28 <jmcarthur_mobile> I feel like there is a law being violated somewhere.
05:58:39 <elliott> I'm not sure I'd say there's a law being violated.
05:58:46 <elliott> instead, I think it's possible the instances simply cannot be written
05:58:51 <elliott> well, without _|_.
06:00:12 <merijn> elliott: Your right, but I think that just means there's no meaningful way to write SupplyT? I'd have to check the FreeT based one, but I think that monad instance might b equally faulty. Not sure, though
06:00:33 <elliott> um... it's perfectly possible.
06:00:36 <elliott> I've used it.
06:00:41 <jmcarthur_mobile> No that one should be fine
06:00:44 <elliott> FreeT ((->) s) is a perfectly fine monad transformer.
06:00:50 <elliott> your version is just not.
06:01:04 <jmcarthur_mobile> Your problem is just that you are hiding the wrapped monad all the way at the bottom of the chain of supply constructions
06:01:16 <merijn> My transformer isn't meant to be FreeT, though
06:01:22 <elliott> newtype SupplyT s m a = SupplyT (m (SupplyThing s m a)); data SupplyThing s m a = Done a | More (s -> SupplyT s m a)
06:01:25 <elliott> ^ perfectly valid
06:01:29 <jmcarthur_mobile> But you need to provide access to the underlying monad at all levels insteaf
06:01:36 <elliott> yeah, what jmcarthur_mobile said
06:01:36 <jmcarthur_mobile> *instead
06:01:58 <elliott> the version where you stuff the m into the More constructor is also wrong
06:02:01 <merijn> jmcarthur_mobile: Yeah, I need to check whether my FreeT version is correct
06:02:05 <elliott> since it means you cannot "lift" without "supply", obviously breaking the laws
06:02:16 <elliott> the correct way is just precisely how FreeT does it
06:02:45 <jmcarthur_mobile> There are other correct ways, to be fair
06:02:59 <jmcarthur_mobile> But this isn't one
06:03:21 <merijn> jmcarthur_mobile: Well, I ended up with what I wanted, I was just trying to make elliott happy and include a somewhat related monad transformer in the library too
06:03:49 <chrisdone> never get tired of reading the emacs manual
06:04:30 <elliott> well, I don't think it's a proper Supply if it can't do these simple things :)
06:04:33 <jmcarthur_mobile> Instead of wrapping everything in m, you can make a separate constructor that has m (SupplyT m a), but then you have an obligation to prevent the programmer from observing the structure since it would allow to distinguish things which should not be distinguishable
06:04:45 <luite> chrisdone: you still coming to zurihac?
06:05:01 <merijn> jmcarthur_mobile: Which was an applicative "transformer" (i.e. just applicative composition with a nicety for letting things work with the plain applicative and composed one)
06:05:13 <chrisdone> luite: did i say i was coming? =p not sure i have any reason to go
06:05:36 <jmcarthur_mobile> For Applicative your data structure might work
06:05:43 <luite> chrisdone: the question to ask is if whether you have a reason not to go ;)
06:05:56 <merijn> elliott: I already put my version into "Control.Applicative.Supply" is was working on a separate "Control.Monad.Trans.Supply"
06:06:12 <merijn> jmcarthur_mobile: I'm pretty sure it does, as all the instance were trivial to write :p
06:06:32 <merijn> So I'm fairly confident in its correctness
06:06:46 <elliott> the applicative version is just Compose (Supply s).
06:06:51 <elliott> where Supply = SupplyT Identity
06:06:57 <luite> chrisdone: i was thinking to go a few days to the mountains, before or after. i'll bring a car and by bike
06:07:50 <jmcarthur_mobile> Buy it should not be a MonadTrans
06:07:50 <jmcarthur_mobile> *but
06:07:56 <merijn> elliott: jmcarthur_mobile I'm not exposing constructors anyway, so the structure can't be observed
06:08:08 <merijn> jmcarthur_mobile: It isn't, atm it's only Functor, Applicative, Alternative
06:08:10 <chrisdone> luite: fun =)
06:08:20 <jmcarthur_mobile> Yeah elliott is right. You don't need anything too fancy for Applicative since all Applicatives are composable
06:08:49 <merijn> jmcarthur_mobile: I know, but my way I don't need to provide separate operations for composed and uncomposed versions
06:09:21 <merijn> Which means I have to write more code for the Supply implementation, but the API is nicer to use in other code
06:09:25 <jmcarthur_mobile> You don't if you do what elliott suggested either
06:09:31 <jmcarthur_mobile> Compose with Identity
06:10:03 <elliott> ]]]]
06:10:05 <elliott> oops
06:10:59 <luite> how many words of overhead does a ByteArray# have?
06:11:04 <merijn> jmcarthur_mobile: "supply :: (s -> f a) -> SupplyT s f a", with "SupplyT s Identity a" that becomes "supply :: (s -> Identity a) -> Supply s a", whereas my approach I get to ensure that "supply :: (s -> a) -> Supply s a" in the Identity case
06:11:26 <merijn> jmcarthur_mobile: i.e. I'm abusing the knowledge that Identity is an Applicative to make that type nicer in the API
06:12:03 <jmcarthur_mobile> I did not realize your supply function used the wrapped functor
06:14:07 <merijn> elliott: Also, look at your "newtype SupplyT s m a = SupplyT (m (SupplyThing s m a)); data SupplyThing s m a = Done a | More (s -> SupplyT s m a)"
06:14:41 <merijn> How is that not equivalent too "data SupplyT s m a = Done a | More (s -> m (SupplyT s m a))"?
06:15:15 <elliott> ...
06:15:19 <merijn> hmm, I guess because the outer one is wrapped in it too
06:15:20 <merijn> nvm
06:15:21 <elliott> how is it?
06:23:38 <acube> When using the Network module, how am I supposed to close the socket? Using sClose gives a deprecation warning
06:23:48 <acube> But using close forces me to import Network.Socket
06:24:30 <acube> oh, sClose doesn't seem to be deprecrated there
06:29:07 <byorgey> acube: sClose is deprecated in both places.
06:29:18 <byorgey> acube: just import Network.Socket and use 'close'.
06:29:23 <acube> ok
06:30:48 <byorgey> given the claims in the documentation for Network (that it is a higher-level interface and you only need Network.Socket for lower-level stuff), I conclude that either (1) the fact that close is not exported from Network is a bug; or (2) using 'close' directly is "low-level" and there is some higher-level combinator which does 'close' for you along with some other stuff
06:31:04 <notdan> acube: if you are using Network then you are probably working with sockets like with handlers, I assume? Closing the handler also supposed to close the socket
06:31:23 <mauke> s/handler/handle/g
06:31:26 <luite> Handle yeah :)
06:31:47 <acube> notdan: listenOn doesn't return a handle, does it?
06:32:14 <luite> acube: you get the handle from accept
06:32:26 <luite> acube: listenOn just returns the listening Socket, you don't have a connection yet
06:32:27 <acube> but when I want to close the server socket?
06:32:34 <mauke> Network.close
06:32:44 <mauke> er
06:32:48 <mauke> Network.Socket.close
06:32:54 <notdan> acube: so if you are writing the server-side part, then you need to 'accept' on the socket
06:33:17 <quchen> mauke: Or Network.sClose - the docs say it's deprecated because of unfortunate reexporting though
06:33:25 <acube> Yes, but when the server exits, it needs to close the listening socket too?
06:33:26 <notdan> If you are not accepting connections and just opening and closing sockets than you have no choice but to use Network.Socket.Close
06:33:36 <notdan> acube: you can just close the Handle
06:33:41 <mauke> quchen: do they?
06:33:55 <mauke> notdan: dude
06:34:35 <mauke> notdan: even if you are accepting connections, you still need to use close if you want to close the listening socket
06:34:39 <eikke> regarding the discussion about linear earlier today -> is there some good paper/introduction to design using denotational semantics?
06:34:43 <mauke> acube: you could just exit
06:35:05 <byorgey> eikke: http://conal.net/papers/type-class-morphisms/
06:35:11 <notdan> mauke: yes, and you can close it with calling hClose on the Handle
06:35:13 <merijn> elliott: You're right, the FreeT approach does work for that, but you're wrong in the sense that you can't turn that monad transformer into an Applicative
06:35:14 <quchen> mauke: Network.Socket defines `sClose = close`, and Network decides to reexport that one :-/
06:35:18 <mauke> notdan: there is no Handle
06:35:26 <luite> notdan: the Handle is for the connection, the Socket is the listening socket
06:35:27 <notdan> 'accept' calls socketToHandle
06:35:36 <mauke> notdan: 'accept' is irrelevant
06:35:40 <luite> notdan: yeah on the new connection Socket
06:35:42 <mauke> notdan: accept does not return a listening socket
06:35:43 <merijn> elliott: The Applicative of the SupplyT you want *requires* Monad
06:35:44 <notdan> and the docs say: > To close the Socket after socketToHandle, call hClose on the Handle.
06:35:54 <eikke> byorgey: ta
06:36:11 <quchen> mauke: Also it's not pragma-DEPRECATED but words-in-doc deprecated.
06:36:11 <luite> notdan: yeah but that's a different socket. accept uses a new one every time
06:36:21 <luite> the listening socket keeps listening
06:36:36 <elliott> merijn: fair enough
06:36:46 <notdan> oh, my bad
06:36:50 <notdan> yeah, sorry
06:36:56 <amyers> If I have an env environment `env :: [(String, String)]` and I want to update one of the values can I do this with lens?  I'm trying to learn lens but it seems I'm not smart enough to figure this out :p
06:37:06 <merijn> elliott: The problem is that FreeF is not an Applicative
06:37:10 <elliott> amyers: you should probably use a Map instead...
06:37:12 <mauke> why isn't Network.close in the haddock?
06:37:22 <acube> Oh, I just discovered that closing an unix-domain socket does not remove the socket file ...
06:37:25 <FreeFull> I get highlighted by FreeF
06:37:35 <FreeFull> I never thought this would be a problem
06:37:45 <merijn> elliott: Only FreeT is, which means the Applicative instance of FreeT can't use "pure" to get something into FreeF, you need Monad so you can return
06:37:53 <amyers> elliott: Normally I would, but this is for a shell environment so I'm doing getEnvironment to get the current env, modify a few variables, then execute a subshell with the new env
06:37:57 <byorgey> amyers: you could do it easily if you had a Map String String
06:38:02 <merijn> elliott: And my wrapper relies on the inside being Applicative too
06:38:02 <notdan> acube: yep, you have to call unlink :(
06:38:07 <amyers> elliott: So the API on boths ends is [(String, String)]
06:38:10 <luite> is there a Text-like thing that supports (almost) O(1) comparison and equality?
06:38:18 <elliott> amyers: not sure we have anything for alists in the len sapi
06:38:20 <elliott> *lens api
06:38:22 <merijn> elliott: So, good news, neither of us have gone completely insane :p
06:39:03 <amyers> elliott: Okay, I was thinking I would be able to wire something together with list and tuple accessors
06:39:16 <elliott> amyers: hmm, I guess you can
06:39:18 <amyers> elliott: I will just do it without Lens, thanks for the help :)
06:39:24 <elliott> but I can't figure it out off the top of my head :p
06:39:45 <amyers> elliott: Okay, I don't feel too bad then, haha
06:40:55 <elliott> ]
06:40:58 <elliott> argh
06:45:32 <eacameron1> Is there a version of >>= that crosses between two monads?
06:45:49 <acube> > [(1,2), (3,4)] & traversed . filtered ((==1) . fst) . _2 .~ 6
06:45:51 <lambdabot>   Not in scope: `&'Not in scope: `_2'
06:45:55 <acube> hmm
06:46:42 <FreeFull> acube: lambdabot doesn't have lens right now
06:46:49 <acube> noticed it :)
06:47:08 <acube> (I remembered that some time ago, someone said it's going to be in lambdabot very soon)
06:47:22 <FreeFull> Very soon would have been several days ago
06:48:00 <merijn> eacameron1: What do you mean by crosses two monads?
06:48:58 <amyers> acube: That's exactly what I want :)
06:49:01 <FreeFull> merijn: He's probably looking for lift
06:49:07 <FreeFull> :t lift
06:49:08 <lambdabot> (Monad m, MonadTrans t) => m a -> t m a
06:49:24 <amyers> acube: works perfectly
06:49:52 * amyers goes off to try to understand why and how
06:50:53 <merijn> FreeFull: Yes, but I wanted to clarify rather than guess
06:51:47 <acube> amyers: you just have to make sure that you don't change the key when you use filtered (with the construction I gave that's not possible, just in case you want to change it :P)
06:52:59 <amyers> acube: I can't think of a reason I would want to do that so shouldn't matter
06:53:16 <amyers> acube: This doesn't have to be terribly efficient
06:54:21 <amyers> acube: Thanks for the warning though
06:54:59 <eacameron1> merijn: Like "m0 a -> (a -> m2 b) -> m2 b
06:55:21 <acube> eacameron1: How would that work? Where would m0 go?
06:55:36 <acube> eacameron1: For example, what would happen if m0 was IO?
06:56:16 <astor> is there a function to get the highest bit set?
06:57:01 <Rarrikins> astor: No, I don't think there is.
06:57:10 <eacameron1> acube: Like this, for example: Monad m => Maybe a -> (a -> m ()) -> m ()
06:57:18 <Rarrikins> astor: If it's a fixed-width integer, you can use the normal tricks.
06:57:55 <acube> eacameron1: What should that function do? Something like doMaybe (Just a) f = f a; doMaybe (Just a) _ = return () ?
06:57:56 <dwcook> Can't you just do that with a logarithm?
06:58:18 <eacameron1> acube: exactly
06:58:26 <Rarrikins> astor: For example: http://graphics.stanford.edu/~seander/bithacks.html#IntegerLog
06:59:37 <supki> @ty for_
06:59:38 <lambdabot>     Not in scope: `for_'
06:59:38 <lambdabot>     Perhaps you meant one of these:
06:59:38 <lambdabot>       `F.for_' (imported from Data.Foldable),
06:59:40 <acube> eacameron1: I think the best you can do is a function of type (Foldable f, Applicative m) => f a -> (a -> m ()) -> m ()
06:59:49 <supki> @ty F.for_
06:59:49 <lambdabot> (Applicative f, Foldable t) => t a -> (a -> f b) -> f ()
06:59:55 <acube> oh, that is what I said :P
07:00:36 <acube> > for_ (Just 3) Nothing
07:00:39 <lambdabot>   Not in scope: `for_'
07:00:39 <lambdabot>  Perhaps you meant one of these:
07:00:39 <lambdabot>    `F.for_' (imported...
07:00:55 <acube> > for_ (Just 3) $ const Nothing
07:00:59 <lambdabot>   mueval-core: Time limit exceeded
07:01:00 <acube> > F.for_ (Just 3) $ const Nothing
07:01:03 <lambdabot>   mueval-core: Time limit exceeded
07:01:23 <astor> Rarrikins: thanks, I think I'll do a simple fold.  I don't need the speed now.  If I did, I'd probably be annoyed by not being able to use the CPU instruction for it.
07:06:33 * hackagebot esqueleto 1.2.4 - Bare bones, type-safe EDSL for SQL queries on persistent backends.  http://hackage.haskell.org/package/esqueleto-1.2.4 (FelipeLessa)
07:08:15 <eacameron1> acube: interesting! I'll look into it
07:08:18 <ion> “Currently, SELECTs, UPDATEs, INSERTs and DELETEs are supported.” Woot! I have been waiting for this.
07:08:37 <ion> meteficha++
07:11:58 <rootnode> I should stop trying to read the messages in here
07:12:25 <byorgey> rootnode: why?
07:12:42 <rootnode> byorgey: because it makes me feel horribly stupid
07:13:15 <bartavelle> rootnode, just read mine, I mostly ask stupid questions
07:13:19 <byorgey> rootnode: ah, then you are going about this the wrong way.  think of them instead as learning opportunities.
07:13:20 <rootnode> I'm glad that I just really understood the concept of functors and applicatives.
07:13:46 <byorgey> rootnode: unlike some other IRC channels, most people here will not think you are stupid just because you don't understand something.
07:14:14 <byorgey> rootnode: congrats!  Then you are definitly not stupid.
07:14:47 <ion> rootnode: You will *always* find people who knows more advanced topics than you do here. What byorgey said.
07:15:25 <rootnode> and I can't for the life of it come up with an idea for a small project to use that stuff.
07:15:31 <int-e> rootnode: you can learn a lot on here just by reading the things that you almost understand :)
07:16:04 <byorgey> I have been hanging out in this IRC channel
07:16:28 <byorgey> I have been hanging out in this IRC channel for 7 years and I know a lot by any objective standard, but people regularly talk about stuff I don't understand.
07:16:34 * hackagebot hatex-guide 1.0.1 - HaTeX User's Guide.  http://hackage.haskell.org/package/hatex-guide-1.0.1 (DanielDiaz)
07:16:35 <byorgey> it's fun.
07:16:51 <bitonic> but byorgey, I thought you knew everything!
07:17:23 <rootnode> at least I switched to xmonad to maybe hack away on some plugins
07:17:31 <bitonic> jokes aside, #haskell is an entertaining channel :)
07:17:33 <int-e> bitonic: but it's only 7 years worth of knowledge ;)
07:18:00 <byorgey> bitonic: I do!  But incredibly, it turns out there is more to know than just everything
07:18:36 <FreeFull> byorgey: What things do you not know?
07:20:29 <byorgey> I don't know how to track down space leaks.  I don't know how to make Haskell programs go really fast.  I don't know what a Kan extension is.  etc.
07:20:48 <byorgey> there is also a much longer list of things I don't know that I don't know.
07:22:45 <bartavelle> Is that even possible to "known" how to track space leaks ? I usually have some unclear picture of what's happening and start hacking until I find the cause ... then I realize it should have been obvious from the start
07:23:35 <FreeFull> bartavelle: GHC does have a profiler
07:23:55 <bartavelle> yes, the information from the profiler gives me the "unclear picture"
07:24:25 <bartavelle> it is never obvious to me what the exact cause is from the profiler output, but maybe I am using it wrong
07:24:47 <klrr> morning
07:25:34 <FreeFull> bartavelle: You can make the information it gives you more precise by adding some stuff into the code AFAIK
07:25:49 <bartavelle> you mean cost centers ?
07:25:51 <seydar> i got some questions on monoids
07:25:55 <bitonic> bartavelle: well with experience you become much quicker at understanding what’s going on, like with any kind of debugging
07:25:59 <byorgey> seydar: ask away
07:26:05 <seydar> can someone explain the monoid of the natural numbers?
07:26:56 <byorgey> seydar: well, the natural numbers have several different monoid structures
07:27:22 <byorgey> seydar: why don't you first tell me the definition of a monoid
07:28:18 <FreeFull> There is multiplication with 1 as identity, and then there is addition with 0 as identity
07:28:19 <seydar> (M, +, e)
07:28:34 <seydar> 1. a set M of objects
07:29:04 <FreeFull> There are probably an infinite amount of monoids over the naturals
07:29:08 <seydar> 2. an operation +
07:29:33 <seydar> 3. and an additive identity e
07:29:43 <seydar> how off am i
07:29:50 <FreeFull> seydar: The two most common monoids for naturals are   (N, +, 0) and (N, *, 1)
07:30:11 <byorgey> seydar: you're close.  you didn't say what property the operation needs to have.  Also, there doesn't have to be anything "additive" about the identity.
07:30:23 <byorgey> it just needs to be an identity for the operation.
07:30:24 <seydar> FreeFull: wow, actually when you write it like that that's just really obvious to the point where i actually don't have any questions
07:30:56 <seydar> byorgey: i just put in the word additive since i used + as the operation and i'm just putting together words i've heard in my various math classes
07:31:06 <byorgey> ok, fair enough =)
07:31:19 <rootnode> basically it's just a semigroup with identity, isn't it?
07:31:19 <seydar> byorgey: and the final property of the operation is that it has to be associative
07:31:21 <FreeFull> > Sum 2 `mappend` Sum 3
07:31:22 <lambdabot>   Sum {getSum = 5}
07:31:25 <FreeFull> > Sum 2 `mappend` Sum 0
07:31:25 <byorgey> seydar: there is at least one other common/useful monoid on the natural numbers I can think of
07:31:26 <lambdabot>   Sum {getSum = 2}
07:31:29 <byorgey> seydar: correct.
07:31:33 <FreeFull> > Product 2 `mappend` Product 3
07:31:34 * hackagebot hatex-guide 1.0.1.1 - HaTeX User's Guide.  http://hackage.haskell.org/package/hatex-guide-1.0.1.1 (DanielDiaz)
07:31:34 <lambdabot>   Product {getProduct = 6}
07:31:36 <FreeFull> > Product 2 `mappend` Product 1
07:31:38 <lambdabot>   Product {getProduct = 2}
07:31:49 <byorgey> seydar: if you try to think of other associative binary operations on naturals you will probably think of it.
07:32:17 <eikke> > mempty `mappend` mempty :: Product Int
07:32:18 <lambdabot>   Product {getProduct = 1}
07:32:50 <FreeFull> I think (N, xor, 0) is a monoid
07:32:58 <FreeFull> But that's probably not what you're thinking of
07:33:01 <seydar> byorgey: i am not a clever man. addition, multiplication, and... everything else seems to be built off of those two, and nothing else would stay in the naturals
07:33:07 <edvardkk> hmm, is there a good online text on category theory ? for a newb
07:33:07 <seydar> byorgey: power?
07:33:16 <acube> power is not associative
07:33:21 <FreeFull> Where xor is bitwise
07:33:25 <byorgey> seydar: the one I'm thinking of is not arithmetical
07:33:27 <seydar> acube: good, i, uh, was testing you
07:33:39 <byorgey> FreeFull: good one!  that's not the one I was thinking of
07:33:46 <acube> maybe the mean of all values? (Can you implement that incremental?)
07:34:01 <seydar> edvardkk: i have a few documents on my computerbox. lemme put them online and give you the links
07:34:14 <byorgey> acube: no
07:34:29 <acube> Ok, Min/Max? :P
07:34:38 <FreeFull> Thinking about it, (N, or, 0) is a monoid too
07:34:46 <Pranz> FreeFull, xor doesn't have an identity element
07:34:51 <byorgey> acube: which one?
07:34:54 <FreeFull> Pranz: 0 is identity
07:35:06 <Pranz> oh
07:35:07 <edvardkk> seydar: thank you!!
07:35:08 <Pranz> bitwise xor
07:35:32 <Pranz> didn't read properly
07:35:35 <acube> I take Max
07:35:42 <byorgey> correct!
07:35:50 <FreeFull> Bitwise and can't be part of a monoid over naturals because there is no identity
07:35:57 <byorgey> min is a semigroup on the naturals, but there's no identity
07:36:06 <elliott> > [1..]
07:36:07 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
07:36:19 <FreeFull> byorgey: max would work over naturals
07:36:22 <FreeFull> with 0 as identity
07:36:27 <byorgey> FreeFull: indeed, acube said that above
07:36:36 <byorgey> that's the other one I was thinking of originally.
07:36:43 <FreeFull> Which is funny, because max wouldn't work over integers
07:36:48 <byorgey> indeed.
07:36:58 <rootnode> seydar: I'd be interested in the documents too
07:37:07 <seydar> rootnode: kk. putting them online now
07:38:04 <jtanguy> (Z, max,-infinity) is a monoid though
07:38:31 <FreeFull> jtanguy: is -infinity an integer though?
07:38:36 <jtanguy> it is the basis of the max-plus algebra
07:38:46 <byorgey> -infinity is not an element of Z.   But you're right that  (Z u {-infinity}, max, -infinity)  works.
07:39:14 <Rarrikins> > 5
07:39:18 <lambdabot>   mueval-core: Time limit exceeded
07:39:24 <Rarrikins> lambdabot is a bit slow
07:39:32 <earthy> 'a bit'?
07:39:38 <Rarrikins> Just a little.
07:39:56 <byorgey> FreeFull: also, you're right that there are an infinite number of monoids over the integers.  For example, the operation which is like addition except 1 behaves like 0 and vice versa.
07:40:13 <byorgey> but most of them are not very interesting/natural.
07:40:30 <byorgey> I meant over the natural numbers.  Though it's true for the integers too.
07:41:27 <ofan> Found a good slide on category theory: http://yogsototh.github.io/Category-Theory-Presentation
07:41:34 * hackagebot hatex-guide 1.0.1.2 - HaTeX User's Guide.  http://hackage.haskell.org/package/hatex-guide-1.0.1.2 (DanielDiaz)
07:41:42 <byorgey> I guess the real question is how many there are, if we consider two monoid structures equivalent when there are monoid homomorphisms in both directions between them.
07:42:05 <byorgey> e.g. my example above is really equivalent to (N,+,0) so it doesn't count as a separate monoid.
07:42:59 <byorgey> I don't know the answer to that.
07:43:09 <elliott> is having monoid homomorphisms in both directions necessarily an isomorphism?
07:43:22 <byorgey> hmm, I don't know.
07:43:39 <tac> elliott: I wouldn't think so
07:43:41 <byorgey> I thought it was when I wrote it, but now I am not sure.
07:44:09 <elliott> tac: it seemed obviously true and obviously false in quick succession
07:44:16 <elliott> so I am no longer asking my intuition :)
07:45:23 <tac> elliott: what about the endomorphism on [()] that takes [] to [] and [()] to [(), ()]
07:45:42 <tac> elliott: then you have the identity on [()] "going the other direction"
07:45:43 <byorgey> in general, no.  e.g. consider  (Z_10, + mod 10, 0) and the homomorphism from Z_10 to itself which sends n to 2n.
07:46:04 <elliott> by "necessarily an isomorphism" I meant "does an isomorphism necessarily exist", btw
07:46:12 <elliott> even if the inverse isn't the "other direction" that you "have"
07:46:14 <byorgey> tac's example is the same as mine but less complicated.
07:46:28 <byorgey> ah, true, that makes it more interesting.
07:46:34 * hackagebot dot2graphml 0.1.0.1 - Converter from GraphViz .dot format to yEd GraphML  http://hackage.haskell.org/package/dot2graphml-0.1.0.1 (IlyaPortnov)
07:46:54 <tac> elliott: You also have the 0 homomorphism, mapping every list to []
07:47:01 <tac> elliott: That is not an iso
07:47:03 <elliott> tac: ah, that makes it clear.
07:47:17 <elliott> so I think byorgey should strengthen his requirements
07:47:23 * byorgey agrees.
07:47:26 <tac> It's always good to think about the most trivial examples you can to check your sanity ;)
07:47:41 <Ankhers> mumble
07:47:43 <Ankhers> miss,,,
07:47:54 <byorgey> Q: how many equivalence classes under ISOMORPHISM of monoid structures are there on N?
07:48:06 <dolio> The monoid with just an identity is both initial and terminal.
07:48:15 <dolio> Therefore all monoids are isomorphic to the monoid with just an identity.
07:48:32 * byorgey disappears in a puff of logic!
07:49:48 <elliott> that's the worst isomorphism ever.
07:49:52 <elliott> you're fired, dolio.
07:50:49 <byorgey> but that's the point!
07:51:02 <lasticot> hello, I'm fresh new to haskell and to familiarize myself with the language I'm trying to code a minimal snake game. The first step would be to be able to have a character move on a 10x10 grid.
07:51:03 <lasticot> I guess my first question would be is it already too advanced?
07:51:04 <lasticot> joins
07:51:10 <byorgey> elliott: "is having monoid homomorphisms in both directions necessarily an isomorphism?"  dolio: "if so, WORST ISOMORPHISM EVER"
07:51:29 <elliott> he's still fired, I'm afraid.
07:51:35 <merijn> lasticot: The answer is, if you're not yet used to the language, a snake game might be a bit tricky, yes.
07:51:37 <byorgey> hi lasticot_, welcome!
07:52:49 <merijn> lasticot: Haskell has an odd difficulty curve compared to other languages. For example, I would say that implementing a compiler in haskell is easier than a snake game (note, this says something about how easy it is to write a compiler, not how hard it is to write snake!)
07:53:08 <Spockz> Does someone have a great source on why breaking referential transparency is a bad thing, or why having referential transparency is so good?
07:53:13 <Pranz> I think it also says something of how hard it is to write snake ;)
07:53:17 <eikke> merijn: writing a snake game is easy. getting it drawn on the screen is the hard part ;-)
07:53:27 <Pranz> Not when you have familliarized yourself with it
07:53:27 <merijn> eikke: Word
07:53:49 <rootnode> excel
07:53:51 <merijn> eikke: Although I think even writing snake can be tricky as a newbie, because you need to figure out so many concepts at once
07:53:56 <rootnode> couldn't resist the pun
07:54:21 <rootnode> especially since it includes IO
07:54:29 <mapreduce> @pl \x -> LeftSide (fst x) (snd x)
07:54:29 <lambdabot> uncurry LeftSide
07:54:33 <merijn> Spockz: Have you ever had to debug a race condition? Ever had to figure out a bug caused due concurrent updates of state?
07:54:39 <acube> hpaste.org takes long to load
07:54:39 <mapreduce> :t uncurry
07:54:44 <lambdabot> (a -> b -> c) -> (a, b) -> c
07:55:10 <mapreduce> Thanks, lambdabot.  No need to ask the humans this time.
07:55:10 <bartavelle> Spockz, or had to write tons of boilerplate code to test a function
07:55:19 <geekosaur> acube, hpaste.org domain name is going away, try paste.tryhaskell.org
07:55:38 <acube> Ah, better, thanks geekosaur :)
07:55:40 <merijn> acube: hpaste is dead, the guy running it wasn't reachable, afaik
07:55:53 <S11001001> @where hpaste
07:55:53 <lambdabot> http://paste.tryhaskell.org/new/haskell
07:55:54 <byorgey> Spockz: also, look up "equational reasoning"
07:56:17 <hpaste> acube pasted “Weird behaviour of the GHC monad with forkIO” at http://paste.tryhaskell.org/90658
07:56:38 <acube> If I use just IO, the code I pastes terminates on Ctrl-C
07:56:48 <Spockz> merijn, byorgey : yes I know the reasons I just don't know a text that clearly explains it all
07:56:53 <Spockz> so I can give it to others
07:57:01 <acube> When I use GHC, it prints test: user interrupt, doesn't terminate and doesn't handle input anymore
07:57:02 <merijn> Spockz: "Why functional programming matters?"
07:57:34 <acube> anyone know how to disable that behaviour of the GHC monad?
07:58:06 <seydar> k, i had to do some funking around on my server but now i'm back
07:58:06 <seydar> http://majoit.us/public/category_theory
07:58:07 <Chousuke> I've become kind of spoiled by things actually making sense most of the time when programming functionally
07:58:18 <seydar> those are the very few links i have amassed
07:59:13 <seydar> rootnode, edvardkk: http://majoit.us/public/category_theory
07:59:15 <Chousuke> just the other day I got weird behaviour in python because I shadowed a variable from outer scope in a list comprehension :/
07:59:23 <Spockz> merijn: that one only mentions referential transparency twice, and only in the introduction
07:59:41 <byorgey> Spockz: ah.  good question then.  I don't really know of one.
07:59:52 <rootnode> seydar: thank you!
08:00:20 <Spockz> byorgey: I think Swierstra mentioned it in his "emeritaat" however I don't have that one available as a searchable document
08:00:50 <Chousuke> python is a decent language but it's really against functional style :(
08:01:42 <seydar> Chousuke: ruby feels your pain and would like to offer you a home
08:01:47 <bartavelle> Spockz, from a "imperative" guru : http://webcache.googleusercontent.com/search?q=cache:Pat891tN5dAJ:www.altdevblogaday.com/2012/04/26/functional-programming-in-c/+&cd=1&hl=en&ct=clnk
08:02:05 <bartavelle> (their site seems to have a problem with the zip headers)
08:02:21 <Chousuke> seydar: if I got to choose I'd go with haskell :P
08:02:47 <seydar> as you should, but i maintain that the two could be a dynamic duo and a powerful team
08:03:01 <bartavelle> ruby is the source of most evil
08:03:16 <Chousuke> programming in javascript and python is enough dynamism for me
08:03:22 <Spockz> bartavelle: It mentions it in a context of testing, but that is not the only reason why you would want ref. transparency
08:03:57 <Chousuke> Spockz: referential transparency is good because it's so difficult to accidentally all the things
08:04:10 <bartavelle> I believe he makes some points about reliability and ease of understanding, but I read it when it went out ...
08:04:40 <Spockz> Chousuke: what does that mean?
08:05:15 <Chousuke> you can still make logic errors, but they will usually not be subtle since you can follow the data at every transformation point
08:05:47 <Chousuke> whereas without referential transparency, any library call you make means you can't follow the data anymore
08:06:46 <Chousuke> the library has done something to it, and you can't be certain what happened just by looking at the data
08:08:20 <seydar> can someone explain applicative?
08:08:37 <FreeFull> seydar: Do you undestand functors?
08:09:00 <seydar> FreeFull: in category theory, yes. in haskell, kinda
08:09:17 <ion> Functor lets you do (a -> b) -> f a -> f b. Applicative lets you do (a -> b -> c) -> f a -> f b -> f c. That also lets you do the equivalent for any number of parameters.
08:09:36 <seydar> oh wait, i DO get functors in haskell. because all it is is fmap
08:09:40 <FreeFull> Applicative also allows you to do   a -> f a
08:09:48 <FreeFull> :t pure
08:09:52 <lambdabot> Applicative f => a -> f a
08:09:53 <mauke> @src Applicative
08:09:53 <lambdabot> class Functor f => Applicative f where
08:09:53 <lambdabot>     pure  :: a -> f a
08:09:53 <lambdabot>     (<*>) :: f (a -> b) -> f a -> f b
08:10:01 <FreeFull> :t (<$>)
08:10:01 <lambdabot> Functor f => (a -> b) -> f a -> f b
08:10:05 <FreeFull> :t (fmap)
08:10:06 <seydar> i'm confused -- why are functor and applicative different, then?
08:10:07 <lambdabot> Functor f => (a -> b) -> f a -> f b
08:10:18 <FreeFull> seydar: applicative has pure and <*>
08:10:19 <ion> seydar: Not all Functors can be Applicatives.
08:10:25 <mauke> because functor is more general and less powerful
08:10:26 <FreeFull> Which aren't implementable using just fmap
08:10:27 <Spockz> Chousuke:  well you can it gave you some data back. It cannot perform side-efffects if it is not in a monad?
08:10:32 <applicative> seydar: 'Applicative' is an additional constraint
08:10:53 <Chousuke> Spockz: hm?
08:11:09 <sclv_> acube: check the source of runghc. i bet its setting a handler to catch the ctrl-c
08:11:42 <Spockz> Chousuke: you say that without referential transparency you cannot know what a library did with the data you gave it. I counter with the argument that you can see that it gave you an answer and that it didn't perform side-effects because the function wasn't in IO
08:11:44 <Chousuke> Spockz: if you pass a data structure to a procedure that is not referentially transparent, you can't trust the data structure to be correct anymore
08:11:50 <seydar> applicative: what's the additional constraint
08:11:51 <seydar> ?
08:12:13 <FreeFull> Spockz: What if the library uses unsafePerformIO?
08:12:19 <merijn> seydar: The ability to put things inside and the ability to get functions back out (temporarily)
08:12:24 <Spockz> FreeFull: then you are doomed anyhow ;)
08:12:37 <Chousuke> Spockz: even if you look at it right after you've executed the call, the procedure might have stored an internal reference to your data (due to a bug or by design) and additional calls to the library could cause trouble
08:12:45 <merijn> FreeFull: That's what SafeHaskell and SafeInferred are for
08:13:07 <mauke> :t liftA2 id
08:13:08 <lambdabot> Applicative f => f (b -> c) -> f b -> f c
08:13:15 <Spockz> Chousuke: point taken
08:13:22 <applicative> seydar: that you can lift not just any function (a -> b), but any function (a -> b -> c ... -> z) , very crudely
08:13:24 <Chousuke> Spockz: with threading it's even worse, since you can't even be sure when code is executed just by looking at code.
08:13:56 <Spockz> Chousuke: how is that a problem of referential transparency and not of laziness?
08:14:00 <seydar> applicative: ok, that makes sense. so if i can create an instance of functor for my type, i should do the same for applicative as well?
08:14:15 <merijn> seydar: If possible, yes
08:14:19 <Chousuke> Spockz: referential transparency makes laziness work.
08:14:22 <mauke> and monad, while you're at it
08:14:31 <applicative> seydar: if you can, not all type-constructors that are functors are applicative functors
08:14:33 <mauke> (monad adds join)
08:14:37 <applicative> so to say
08:14:42 <Sculptor_> yo
08:14:45 <applicative> yo
08:14:50 <mauke> yoyo
08:14:53 <seydar> yo
08:14:55 <Spockz> Chousuke: ah good point
08:14:58 <geekosaur> oy
08:15:00 <mauke> oʎoʎ
08:15:04 <applicative> ha
08:15:05 <Chousuke> Spockz: though of course you can have unpredictable memory or time use if you do laziness wrong, but it shouldn't change the meaning of your program
08:15:19 <seydar> so isn't functor MORE specific than applicative?
08:15:22 <ion> oןoʎ
08:15:31 <seydar> since it is for a -> b instead of a -> ... -> z?
08:15:41 <mauke> seydar: all applicatives are functors
08:15:56 <FreeFull> All monads are applicatives
08:15:57 <ion> And laziness makes referential transparency work. ;-) (The temptation to have arbitrary side effects was too strong for most strict languages.)
08:16:13 <applicative> a -> b is a case of a -> c -> d ... -> b
08:16:52 <jtanguy> is there an equivalent of list comprehensions for sets ?
08:17:23 <applicative> jytanguy no, if Set were a monad, you could use 'monad comprehensions'.
08:17:24 <Botje_> jtanguy: you can walk "elems set" instead
08:17:40 <sclv_> acube: in fact, see initGhcMonad here https://github.com/ghc/ghc/blob/569b26526403df4d88fe2a6d64c7dade09d003ad/compiler/main/GHC.hs
08:17:47 <sclv_> which includes a call to installSignalHandlers
08:18:04 <lasticot> merijn: sorry for the lag I had some connection issues
08:18:05 <Botje_> S.fromList [ ... | el <- S.elems set ] -- roughly.
08:18:17 <Botje_> (assumes Data.Set is imported qualified and bound to S, as is common)
08:18:36 <lasticot> merijn: I did a lot of reading but I've trouble actually starting to code something
08:18:48 <sclv_> acube: you should be able to override those signal handlers the usual way...
08:19:40 <jtanguy> I'm migrating a library from using lists to sets, and unfortunately Set is not a Functor
08:20:17 <applicative> the Ord and Eq constraints are irritating, yes
08:20:22 <lasticot> merijn: do you have any small project that would allow me to understand how to use the state monad? And how to use modules efficiently?
08:20:28 <seydar> so what's a natural transformation?
08:20:45 <jtanguy> I'm wrapping all list comprehensions as Botje_ said
08:21:51 <applicative> jtanguy: I guess that's the natural thing, I wonder if the advantages of set will be lost
08:21:59 <ion> Functor, Applicative and Monad instances for Data.Set http://paste.tryhaskell.org/50278
08:22:39 <applicative> hah, nice
08:23:07 <byorgey> seydar: a natural transformation is a mapping between two functors.  In Haskell, it's a polymorphic function like  forall a. f a -> g a
08:23:58 <seydar> byorgey: can you give me an example using haskell?
08:24:03 <byorgey> the polymorphism is what makes it "natural".
08:24:13 <elliott> ion: how can you live with yourself?!
08:24:15 <ion> byorgey: So, like maybeToList?
08:24:29 <byorgey> ion: yes, that is a natural transformation
08:24:35 <byorgey> @type maybeToList
08:24:36 <lambdabot> Maybe a -> [a]
08:24:38 <ion> elliott: It’s okay, it clearly says that the precondition is not checked. hth
08:24:42 <byorgey> so is 'reverse'
08:24:44 <byorgey> @type reverse
08:24:47 <lambdabot> [a] -> [a]
08:24:57 <ion> byorgey: Oh, ok.
08:25:28 <byorgey> however, something like 'length' is also a natural transformation, if we think of Int as being   Const Int a.
08:25:31 <ion> And repeat . runIdentity?
08:25:31 <byorgey> @type length
08:25:34 <lambdabot> [a] -> Int
08:25:36 <applicative> ion it's interesting that he exports mapMonotonic and so on.
08:25:38 <seydar> byorgey: if i had a function that was f :: Maybe a -> [a], is that a natural transformation?
08:25:51 <byorgey> seydar: yes.
08:26:02 <elliott> in Haskell, a function (forall a. f a -> g a) between Functors f and g is guaranteed to be a natural transformation thanks to parametricity.
08:26:11 <elliott> which is quite wonderful.
08:26:16 <seydar> byorgey: is there some magic part of a natural transformation beyond that?
08:26:30 <elliott> unfortunately, it means that Haskell is a bad way to learn what a natural transformation is
08:26:37 <elliott> because you're blind to unnatural transformations.
08:26:43 <xplat> byorgey: length in particular is also an NT if with think of Int as being [Const () a]
08:26:45 <ion> applicative: It’s okay, the documentation of mapMonotonic clearly says the precondition is not checked.
08:27:12 <ion> Therefore my instances are also fine with said documentation.
08:27:15 <byorgey> xplat: good point
08:27:41 <byorgey> seydar: the magic is that, as elliott mentioned above, polymorphism in Haskell is quite restrictive.
08:27:44 <merijn> lasticot: I think the smallest project to understand the State monad is to try and implement it yourself
08:27:44 <dolio> Or Const Int a.
08:27:46 <ion> elliott: What’s an unnatural transformation then?
08:27:56 <merijn> lasticot: Which is not very hard, fortunately
08:28:10 <xplat> merijn: what's the smallest project to understand the reverse state monad?
08:28:18 <seydar> ion, elliott: wouldn't an unnatural transformation be like f :: Int -> Int ?
08:28:24 <byorgey> seydar: for example, consider this "function":   f :: [a] -> [a];  f xs = if a == Int then [] else reverse xs
08:28:31 <merijn> xplat: Unimplementing the State monad
08:28:46 <byorgey> seydar: f does one thing if its type parameter is Int and otherwise it does something else.
08:28:57 <byorgey> seydar: that is NOT a natural transformation.  But you also cannot write it in Haskell.
08:29:10 <byorgey> but you can write it in many other languages.
08:29:21 <merijn> byorgey: Pfft, wanna bet? :> (Ok, it only works for Typeable a, but still!)
08:29:31 <acube> merijn: Or using type classes
08:29:33 <lasticot> merijn: ok thank you
08:29:38 <byorgey> you cannot write it with that type, is what I meant.
08:29:53 <byorgey> of course you can do it if you have  f :: (Something something a) => [a] -> [a].
08:29:58 <elliott> an unnatural transformation is still (forall a. f a -> g a), it just does illegal things.
08:30:11 <seydar> byorgey: so in the same way that all functors in haskell are endofunctors, all transformations are natural transformations?
08:30:15 <elliott> "natural" basically means what we think of as "parametric polymorphism".
08:30:28 <ion> Is “illegal things” equal to “something dependent on the value of a”?
08:30:29 <elliott> it's not that all functors you can define in haskell are endofunctors... you can do other kinds of functors too
08:30:40 <byorgey> ion: yes.
08:30:41 <xplat> seydar: no, in a much different way
08:30:42 <elliott> it's just that Functor only models endofunctors.
08:30:45 <elliott> that's a library design thing more than a language thing
08:30:57 <merijn> lasticot: To get started I give you "newtype MyState s a = MyState { runMyState :: s -> (a, s) }" (which is record syntax producing "MyState :: (s -> (a, s)) -> MyState s a" and "runMyState :: MyState s a -> s -> (a, s)"
08:31:01 <ion> Ok, thanks
08:31:28 <xplat> seydar: the reason for 'all Functors are endofunctors' is that it's not that easy to model other categories in Haskell, and anyway Functor didn't even try
08:31:53 <xplat> seydar: the reason all transformations are natural is a much more, well, natural reason
08:31:56 <elliott> ion: the law of a natural tranformation eta is that eta . fmap f = fmap f . eta
08:32:03 <merijn> lasticot: Just look at the type signatures of return and (>>=) and try to figure out how to write implementations for those functions given that datatype
08:32:04 <elliott> ion: an unnatural transformation is just one that breaks that.
08:32:11 <ion> elliott: Alright, thanks
08:32:32 <merijn> lasticot: Enlightenment might take some meditation on the types
08:32:38 <dolio> You can think about certain things in Haskell as being functors such that quantification doesn't ensure naturality.
08:32:46 <seydar> xplat: and what's that?
08:33:11 <xplat> also, you technically can make unnatural transformations if you use seq or unsafe things
08:33:11 <lasticot> merijn: Then, meditate I will :-) Thanks
08:33:14 <acube> Hmm, what happens if I use a data type like MyTaggedList a = MyTaggedList { contains_ints :: Bool, list :: [a] }
08:33:57 <dolio> For instance, any monad M can be seen as a functor from the Kleisli category for M back to the ordinary category of types and functions.
08:34:15 <dolio> Both categories can be thought of as having the same objects.
08:34:28 <byorgey> acube: if contains_ints means what you want that to mean, then it is not even a Functor.
08:34:54 <acube> byorgey: right, just thought about that too
08:35:18 <dolio> But, not all functions with type 'forall a. M a -> M a' are natural transformations between said functor.
08:35:23 <quicksilver> dolio: can it? What does that functor take the morphism "x :: a -> m b" into?
08:35:54 <dolio> quicksilver: (>>= x)
08:35:54 <quicksilver> (it can be seen as a functor in the other direction, taking y to return . y)
08:36:09 <xplat> seydar: the reason all transformations are natural is that relational parametricity so happens to imply exactly the commutations law you need to make a transformation of endofunctors natural
08:36:18 <acube> @ty \x -> (>>= x)
08:36:19 <lambdabot> Monad m => (a -> m b) -> m a -> m b
08:36:24 <quicksilver> dolio: oh right, I see.
08:36:34 <quicksilver> of course
08:36:35 * hackagebot handa-gdata 0.6.3 - Library and command-line utility for accessing Google services and APIs.  http://hackage.haskell.org/package/handa-gdata-0.6.3 (BrianBush)
08:36:36 <seydar> xplat: what does parametric mean in the context of category theory and haskell?
08:36:38 <elliott> xplat: "so happens to" makes me sad. I like to imagine it's fate.
08:37:26 <byorgey> I don't think that's the *reason* all transformations are natural.  That's how you *prove* it, given a particular definition of naturality.
08:37:43 <byorgey> but I suppose now I'm getting into philosophy of mathematics.
08:38:16 <mr-> xplat: what is relational parametricity?
08:38:16 <xplat> elliott: when i try to define that 'fate' i end up running into things like dolio just pointed out ...
08:38:35 <ion> Let’s go to the mathematics of the philosophy of mathematics.
08:38:46 <byorgey> seydar: polymorphic functions, data types, etc. are said to be "parametric" if they work "in a uniform way" for all possible types
08:39:15 <byorgey> seydar: e.g.   length :: [a] -> Int   is parametrically polymorphic because it works in the same way no matter what type is substituted for a.
08:39:48 <byorgey> seydar: on the other hand, (+) is not parametrically polymorphic because it works in different ways for different types.
08:40:09 <byorgey> (though from another point of view, it is -- if you think of it as taking a dictionary of Num methods)
08:40:10 <seydar> byorgey, xplat: thank you
08:40:28 <merijn> There's no way to turn "(Monad f, Monad m) => f (m (f a))" into "f (m a)", right?
08:41:01 <byorgey> seydar: this notion of "works in a uniform way for all objects/types" is exactly the same idea as "naturality" in category theory
08:41:16 <seydar> gotcha
08:41:21 <geekosaur> merijn, not for arbitrary monads m, f
08:41:23 * elliott thinks (+) counts as parametrically polymorphic
08:41:31 <acube> merijn: I think there is
08:41:32 <elliott> viewing it as NumDict a -> a -> a -> a
08:41:36 <seydar> so now unnatural transformation makes sense
08:41:40 <byorgey> elliott: didn't I just say that? =)
08:41:40 <seydar> and why it doesn't exist in haskell
08:41:41 <quicksilver> merijn: only with some extra constraints
08:41:43 <acube> ah no, forget that
08:41:48 <elliott> byorgey: oh, oops :)
08:41:59 <quicksilver> merijn: a sufficient constraint is Traversable m
08:42:07 <quicksilver> merijn: but there might be other options or weaker options.
08:42:25 <elliott> m (f a) -> f (m a) is enough too
08:42:26 <merijn> geekosaur, quicksilver: Aww...that makes me a sad panda :\
08:42:29 <kartlos> does anyone know a simple introduction tutorial/article/something to category theory for dummies? :)
08:42:31 <elliott> because you get f (f (m a)) and can join
08:42:38 <byorgey> seydar: as others have pointed out, it sort of does, just not with a type like  forall a. f a -> g a
08:42:42 <quicksilver> elliott: (and that's the type you get from traversable ;)
08:42:43 <acube> elliott: that's sequenceA
08:42:52 <byorgey> seydar: but e.g. you could implement one with a type like  forall a. Typeable a => f a -> g a
08:43:03 <byorgey> seydar: which lets you inspect the type a at runtime
08:43:55 <elliott> quicksilver: er, well, hm, okay, if f is universally quantified over
08:43:59 <merijn> oh...
08:44:05 <elliott> but m might support it for a specific f but not all fs in general
08:44:10 <elliott> i.e. it is the difference between
08:44:14 <quicksilver> elliott: yes indeed
08:44:18 <byorgey> this is a really nice property, akin to referential transparency.  In the same way that you know a function of type  Int -> Int  cannot do I/O (you would need a type like  Int -> IO Int), you know that a function of type  forall a. f a -> ...  cannot inspect a
08:44:21 <elliott> (Monad f, Monad m) => (forall a. m (f a) -> f (m a)) -> ...
08:44:22 <elliott> and
08:44:29 <elliott> (Monad f, Monad m) => (forall g a. Monad g => m (g a) -> g (m a)) -> ...
08:44:52 <quicksilver> elliott: but since merijn wanted it to work for arbitrary f...
08:45:18 <merijn> elliott: Basically I was (trying to) implement "runSupplyTAction :: (Monad m, Monad f) => SupplyT s m a -> f s -> f (m a)" but I don't think that's possible
08:45:36 <elliott> quicksilver: yeah, but now that it's acknowledged that you need to pass in more, passing in (forall a. m (f a) -> f (m a)) lets you work on strictly more (m,f) pairs than requiring Traversale m.
08:45:41 <elliott> *Traversable
08:45:49 <quicksilver> yes.
08:45:59 <merijn> I guess I can just special case the "SupplyT s Identity a" version, as getting the Identities out should be doable...
08:46:16 <quicksilver> as I said "a sufficient constraint is Traversable m but there might be other options or weaker options..."
08:46:21 <merijn> (i.e. just "liftM runIdentity")
08:46:27 <quicksilver> I think it's unnecessary to agree at such length
08:46:30 <elliott> right. and that was my offering in terms of the other/weaker options.
08:46:34 <elliott> hehe
08:46:40 <elliott> no, *you're* right!
08:48:15 <seydar> thank you very much everybody
08:54:59 <merijn> @pl src >>= \s -> f (g s) src
08:55:02 <lambdabot> flip (f . g) src =<< src
08:55:02 <lambdabot> optimization suspended, use @pl-resume to continue.
09:01:36 * hackagebot handa-gdata 0.6.4 - Library and command-line utility for accessing Google services and APIs.  http://hackage.haskell.org/package/handa-gdata-0.6.4 (BrianBush)
09:03:25 <tomboy65> anyone got an idea why this fails? http://bpaste.net/show/111682/
09:04:30 <mapreduce> tomboy65: The second parameter of iterGS should be a ([Char],[Char])
09:05:14 <tomboy65> thanks
09:05:18 <tomboy65> -.-
09:05:19 <tomboy65> i see it now
09:05:35 <mapreduce> Really?  I was just starting to doubt myself. :)
09:07:14 <tomboy65> :p
09:07:19 <tomboy65> i was alread
09:07:23 <tomboy65> y
09:07:35 <tomboy65> doubting myself, not you :p
09:08:55 <tomboy65> hmm
09:09:13 <tomboy65> how do i get it to accept empty strings and feed back filled ones?
09:10:03 <applicative> getSums str = iterGS str ([],[])
09:10:20 <applicative> I guess, tomboy65 ^^^
09:10:31 <tomboy65> 67no
09:10:32 <tomboy65> no
09:10:35 <tomboy65> doesn't work
09:10:41 <merijn> hmmm, my code compiles without any errors, time to work on this issue:
09:10:44 <merijn> $ grep -r undefined * | wc -l 24
09:10:48 <applicative> oh you missed the null string case
09:11:36 <applicative> what should iterGS "" ("blah","goo") be?
09:11:37 <applicative> ("blah","goo") I guess.
09:11:48 <applicative> tomboy65: so add that as separate line to the definition of iterGS
09:20:21 <elliott> hm, GHC's "showSDocOneLine" seems to have a lying name
09:21:01 <yitz> @hoogle showSDocOneLine
09:21:01 <lambdabot> No results found
09:21:11 <yitz> @google showSDocOneLine
09:21:12 <lambdabot> http://www.haskell.org/ghc/docs/6.12.3/html/libraries/ghc-6.12.3/Outputable.html
09:21:13 <lambdabot> Title: Outputable
09:21:45 <yitz> elliott: ghc 6.12.3?
09:22:10 <elliott> 7.6.3
09:23:30 <elliott> maybe it is a different meaning of "one line".
09:24:39 <yitz> elliott: where is that function?
09:24:59 <elliott> Outputable
09:25:23 <ocharles> fryguybob: were you working on tsx stuff with haskell?
09:27:52 <yitz> what?
09:28:25 <elliott> ?
09:28:51 <yitz> do you see any module with that name here? http://www.haskell.org/ghc/docs/latest/html/libraries/index.html
09:29:07 <elliott> http://www.haskell.org/ghc/docs/latest/html/libraries/ghc-7.6.3/index.html
09:29:08 <yitz> elliott: those are all of the publicly visible libraries that come with ghc
09:29:23 <elliott> no, there is also http://www.haskell.org/ghc/docs/latest/html/libraries/ghc-7.6.3/index.html
09:33:28 <yitz> oh the ghc api
09:33:45 <yitz> i see in the source that is uses PageMode instead of OneLineMode
09:34:12 <elliott> yeah, maybe just nobody has ever used it...
09:34:15 <elliott> I'll inline my own version I suppose
09:34:20 <yitz> probably it used to be OneLineMode, then they changed how things work and it never got commented in the code
09:34:36 <yitz> lots of stuff like that in internal ghc. you need to know the secrets.
09:35:24 <yitz> elliott: yeah it's only a couple lines of code
09:37:21 <Luke> this is probably wildly outside of the scope of this channel but, I'm trying to use the hackage pcap library to parse a pcap file and it's throwing an exception on read saying "unknown file format". The exception is a GHC.IO.Exception.UserError which I think means it's coming from the underlying libpcap?
09:38:14 <yitz> elliott: in fact, the implementation for showSDocOneLine is identical to showSDoc
09:38:27 <Saizan> Luke: it's coming from a call to error in the haskell code
09:38:30 <yitz> elliott: try reporting a bug and let's see what happens
09:38:57 <elliott> heh, you're right. ok, will report a bug once I pop my current work off the stack
09:38:57 <Luke> Saizan: its in a library that's not my code. is there a good way to figure out what's wrong?>
09:39:28 <Saizan> Luke: either the package documentation or its source
09:39:48 <Saizan> Luke: mailing the maintainer is an option too
09:39:55 <Luke> yeah it's bos' library I think
09:40:06 <Luke> bos_: you around? Have a pcap question
09:41:10 <yitz> Luke: bos_ is quite busy at facebook these days but he will respond if you follow the link to the bug tracker from hackage and report a bug
09:41:11 <Luke> Saizan: I suspect he's just throwing an exception when reading an error code from libpcap though
09:41:28 <Luke> i don't think it's a bug in his software
09:41:39 <yitz> Luke: first just check what the message says though: are you *sure* you are feeding it valid pcap?
09:41:59 <Luke> I posted what the message was above
09:42:05 <Luke> and yes it's a valid pcap
09:42:10 <Luke> wireshark can read it just fine
09:42:36 <Saizan> Luke: even if not a bug you want to understand under which conditions you get that error
09:42:44 <yitz> Luke: maybe an encoding issue? just throwing things out on the table.
09:43:27 <Luke> there are many different versions of pcap file format. I suspect my version of libpcap doesn't support it
09:43:47 <Luke> the pcap haskell library is likely dynamically linking to libpcap right?
09:44:36 <c_wraith> Luke: only way to know for sure is run ldd on a program that uses it
09:44:36 <yitz> Luke: no likely statically compiling it in
09:44:57 <Luke> hmm
09:45:14 <Luke> so even if I swap my system's version of libpcap it could be statically linked to a c library?
09:45:48 <yitz> Luke: though maybe you're right. bos_'s text-icu library dynamically links to icu.
09:45:48 <c_wraith> yes, though it's probably statically linked to the system lib..
09:45:55 <Luke> oh when I installed it. good call
09:47:45 <Luke> https://github.com/mcr/libpcap/blob/master/savefile.c#L301 here's the error i'm getting though I
09:47:52 <Luke> i'm not sure that' the correct occurance
09:48:00 <Luke> occurrence*
09:48:21 <Luke> well no that is it
09:48:25 <Luke> that's exactly it
09:48:28 <Luke> so it's definitely coming from C
09:51:46 <Luke> "Well, who knows what this mess is...." is the comment
09:51:49 <Luke> haha
09:56:37 * hackagebot smtLib 1.0.5 - A library for working with the SMTLIB format.  http://hackage.haskell.org/package/smtLib-1.0.5 (IavorDiatchki)
10:15:46 <fryguybob> ocharles: Yes
10:27:26 <merijn> elliott: Which type do you think will be lifted more frequently? "s -> a" of "s -> f a"?
10:28:02 * elliott would usually expect the mapping to be "id" :p
10:28:30 <merijn> elliott: You mean "SupplyT s m s"?
10:28:58 <merijn> I already have settled on the name "demand" for that, as that seems so fitting it pleases me :)
10:29:55 <elliott> right. so I don't know what is the more common case apart from that, because it seems like all common uses would be that.
10:31:26 <Rarrikins> Is there a standard function like f a b c xs ys = a (b (c xs) (c ys))?
10:31:49 <Rarrikins> Hmm, I guess f b c xs ys = b (c xs) (c ys)
10:32:03 <elliott> liftA2?
10:32:14 <elliott> > liftA2 f g h x y
10:32:15 <lambdabot>   Could not deduce (Debug.SimpleReflect.Expr.FromExpr b0)
10:32:15 <lambdabot>    arising from a u...
10:32:17 <elliott> > liftA2 f g h x y :: Expr
10:32:18 <lambdabot>   No instance for (Debug.SimpleReflect.Expr.FromExpr b0)
10:32:18 <lambdabot>    arising from a us...
10:32:20 <elliott> hmph.
10:32:23 <dmwit> no, it's on
10:32:25 <merijn> elliott: Then I will selfishly select whichever is most convenient for me :p
10:32:26 <dmwit> ?src on
10:32:26 <lambdabot> (*) `on` f = \x y -> f x * f y
10:32:29 <elliott> oh, right.
10:32:33 <quchen> elliott: That would not be (c xs) (c ys) but (c xs) (d xs)
10:32:55 <elliott> right.
10:33:03 <dmwit> (a . b) `on` c
10:33:08 <dmwit> err
10:33:21 <dmwit> a (on b c xs)
10:33:29 <quchen> on would also not work because the f are equal
10:33:39 <dmwit> eh?
10:33:40 <quchen> Oh wait, that's what he's asking, nevermind
10:33:48 <Rarrikins> Thanks :)
10:35:05 <S_J> > 7 + 87
10:35:06 <lambdabot>   94
10:35:15 <S_J> thank god for lamdabot!
10:36:13 <S_J> > give an example of a threaded application except for a GUI and a webserver..
10:36:13 <lambdabot>   <hint>:1:17: parse error on input `of'
10:36:33 <S_J> Also, can you run haskell on Android?
10:38:07 <augur> f (g x) (h y) looks an awful lot like a curried tupling of functions
10:38:32 <augur> which is just one of those arguments in favor of tuples and combinators, i guess
10:39:01 <banister_> augur: what is a combinator? just a function that modified another function?
10:39:29 <augur> yeah, combinators are essentially little gadgets for piecing things together without using lambdas
10:39:47 <augur> they can make presentations cleaner, but they can also mangle presentations as well
10:40:00 <augur> they must be used judiciously
10:40:04 <banister_> augur: can you give me an example of a very simple one
10:40:08 <banister_> just so i get the idea
10:40:12 <augur> sure, (.)!
10:40:20 <banister_> composition?
10:40:26 <augur> instead of writing \x -> f (g x)  you just write f . g
10:40:32 <Luke> if I want to force cabal to rebuild and reinstall from a clean install, do I have to do anything special to get it to clean first?
10:40:43 <augur> banister_: another common one is the curry combinator
10:40:48 <augur> curry f x y = f (x,y)
10:40:57 <banister_> cool
10:41:58 <augur> banister_: there's also the pair combinator, which i'll just write as (<*>): (f <*> g) (x,y) = (f x, g y)
10:42:38 <banister_> augur: isn't <*> the applicative functor function?
10:42:46 <augur> banister_: im abusing the symbol
10:42:49 <banister_> ah ok np
10:43:00 <elliott> aka (***) in haskell
10:43:04 <banister_> augur: starngely LYAH doesn't mention the word combinator once
10:43:06 <augur> f (g x) (h y) == uncur f . (g <*> h)
10:43:15 <banister_> augur: why is that do u think? are they an advanced topic or..?
10:43:17 <augur> elliott: oh is it (***)? i forget the standard stuff
10:43:26 <augur> banister_: LYAH is supposed to be for newbies
10:43:52 <arcatan> surely LYAH talks about the topic, they just don't call them combinators?
10:43:55 <arcatan> (i haven't read LYAH)
10:44:14 <augur> \x y -> f (g x) (h y) = cur (uncur f . (g *** h)) using standard haskell instead of my junk
10:44:14 <banister_> augur: tbh i dont really agree with that, LYAH goes into a lot more theoretical detail than real world haskell IMO, i found LYAH harder to understand, esp the chapters on applicative functors and monoids/monads etc
10:44:47 <augur> this is probably a case of abusing combinators
10:44:53 <augur> also
10:44:55 <banister_> augur: sorry i mean, it's clearly meant for noobies but (as a noob) i found it harder to understand than many other tutorials
10:44:59 <elliott> banister_: that's grounding you need, though
10:45:05 <augur> @pl \x y -> f (g x) (h y)
10:45:08 <lambdabot> flip ((.) . f . g) h
10:45:08 <lambdabot> optimization suspended, use @pl-resume to continue.
10:45:12 <augur> horrible
10:45:16 <augur> @pl-resume
10:45:22 <lambdabot> flip ((.) . f . g) h
10:45:22 <lambdabot> optimization suspended, use @pl-resume to continue.
10:45:54 <S_J> what do you actually win by using those combinators? it is more to write and not clear from the operator what it does, for example <*>.  I understand '.' though which is sueful.
10:45:56 <augur> i think the best examples of combinator non-abuse is when writing cute little interpreters and such
10:46:28 <augur> eval (f :$: x) env = eval f env (eval x env)
10:46:29 <merijn> banister_: I agree, but on the other hand I feel that the stuff LYAH covers is essential to understanding the later bits like transformers. RWH just kinda throws you into the deep when it comes to those
10:46:31 <augur> i'd much prefer
10:46:44 <augur> eval (f :$: x) = eval f `s` eval x
10:47:01 <augur> where s f x e = f e (x e)
10:47:08 <elliott> aka (<*>)
10:47:12 <elliott> full circle
10:47:28 <augur> yes, indeed, its <*> for this particular case :p
10:47:34 <augur> also, i much prefer
10:47:40 <int-e> @type ap const id
10:47:41 <lambdabot> a -> a
10:47:56 <augur> instead of this:   eval (var x) env = lookup x env   write   eval (var x) = lookup x
10:48:16 <banister_> merijn: another thing, i found its explanation of foldr extremely confusing as it said that foldr reads the list from the RIGHT, but then goes on to say it can be used for infinite lists...in fact i haven't found a satisfactory explanation of foldr at all, still kind of confused on it ;)
10:48:43 <augur> and instead of   eval (Lam b) env = \x -> eval b (x:env)   writing   eval (Lam b) = lam (eval b)
10:48:51 <augur> where lam = curry
10:48:56 <c_wraith> banister_: foldr definitely doesn't read the list from the right.  Any explanation that says that is very wrong and should be avoided
10:49:07 <augur> well, curry for lists
10:49:26 <augur> or if you're using real pairs then pairs
10:49:27 <augur> anyway
10:49:48 <augur> it makes the homomorphism look more like a homomorphism if you can basically write it.. as a homomorphism :)
10:49:58 <banister_> c_wraith: this is from LYAH, maybe i'm just misreading it? http://cl.ly/image/3z353A3s3v2b
10:49:59 <c_wraith> banister_: foldr actually is really subtle in a non-strict language, and tests your understanding of exactly how non-strict evaluation works
10:50:11 <augur> var ~> lookup, (:$:) ~> s, Lam ~> lam
10:50:32 <c_wraith> banister_: heh.  That's technically correct, but very misleading.  It says it *accumulates* to the right.
10:50:44 <startling> > foldr f a (repeat b)
10:50:45 <lambdabot>   f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (f b (...
10:50:48 <c_wraith> banister_: but that's a very subtle difference
10:50:49 <augur> thats judicious combinators
10:51:18 <startling> > foldr const a (repeat b)
10:51:19 <lambdabot>   b
10:51:38 * hackagebot oeis 0.3.4 - Interface to the Online Encyclopedia of Integer Sequences (OEIS)  http://hackage.haskell.org/package/oeis-0.3.4 (BrianLewis)
10:52:22 <c_wraith> banister_: the main thing is..  Your function f is passed two values. The first one is the head of the list.  The second one is the result of calling foldr on the rest of the list.  Whether foldr works on infinite lists depends on how much your function looks at its second argument.
10:52:36 <banister_> c_wraith: what about this: http://cl.ly/image/1g063B0K3J1L
10:52:41 <S_J> what do you actually win by using those combinators? it is more to write and not clear from the operator what it does, for example <*>.  I understand '.' though which is sueful.
10:52:47 <banister_> that's from LYAH too, it makes it seem that it really is reading it from right to left
10:52:50 <S_J> Also, can you run haskell on Android?
10:53:14 <c_wraith> banister_: yeah, that example is just wrong.
10:53:14 <startling> > foldr f a [b, c, d] -- banister
10:53:15 <lambdabot>   f b (f c (f d a))
10:53:57 <arcatan> > foldl f a [b, c, d]
10:53:58 <lambdabot>   f (f (f a b) c) d
10:54:34 <quchen> S_J: The Reader (i.e. "function") instance of Applicative is a little hard to use in the beginning (and arguably always hard to read). There are other scenarios in which Applicative style is very readable; parsers are a good example here.
10:54:50 <startling> > foldr (\x y -> if x == a then f x y else x) e (cycle [d, c, b, a])
10:54:51 <lambdabot>   d
10:55:42 <quchen> S_J: There are a lot of functions like (.) that somehow combine their arguments in a very specific manner. <*>, >>=, <$> etc. all glue something togehter. And for each gluing, there's probably the right operator in the libraries somewhere.
10:56:11 <startling> > ((,) <$> fmap fst ask <*> fmap snd ask) (4, 5)
10:56:11 <c_wraith> > let rtrim = foldr (\h t -> if isSpace h && null t then "" else h : t) "" in (rtrim "hello bob! ", rtrim $ cycle "one two three ")
10:56:12 <lambdabot>   can't find file: L.hs
10:56:12 <lambdabot>   (4,5)
10:56:20 <c_wraith> we race conditioned the poor bot
10:56:38 <banister_> c_wraith: so i shouldn't panic just yet if i dont grok foldr?
10:56:39 <c_wraith> nice timing, startling! :)
10:56:48 <c_wraith> banister_: no, it's really pretty subtle
10:56:49 <startling> :D
10:56:53 <c_wraith> > let rtrim = foldr (\h t -> if isSpace h && null t then "" else h : t) "" in (rtrim "hello bob! ", rtrim $ cycle "one two three ")
10:56:54 <lambdabot>   ("hello bob!","one two three one two three one two three one two three one ...
10:57:37 <c_wraith> banister_: that rtrim function there makes just about maximum use of foldr's subtlety.  Keep it around to look at, play with, and think about.
10:57:43 <startling> banister, take a look at "foldr f a [b, c, d] = f b (f c (f d a))"
10:57:55 <startling> banister, consider the case where f ignore its second argument
10:58:30 <S_J> quchen: maybe it is just me that find to many fo those '.', '>>=' being hard to remember.
10:58:33 <startling> then that whole "(f c (f d a))" gets ignored and, as a consequence, never gets evaluated
10:58:42 <S_J> :t cycle
10:58:43 <lambdabot> [a] -> [a]
10:58:59 <quchen> S_J: It's one of those things you get used to, and then it's pretty clear.
10:59:11 <startling> if instead we have an infinite sequence of function applications, it makes no difference; it still gets ignore and never evaluated
10:59:16 <S_J> > cycle 1 2 3 4
10:59:17 <lambdabot>   Couldn't match expected type `a1 -> a2 -> a3 -> t0'
10:59:17 <lambdabot>              with actua...
10:59:20 <S_J> :t cycle
10:59:21 <lambdabot> [a] -> [a]
10:59:26 <startling> S_J, forgot the []
10:59:28 <S_J> > cycle [1,2,3]
10:59:28 <lambdabot>   [1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,...
10:59:30 <banister_> startling: thx
11:00:03 <startling> banister, now note that f can optionally ignore its second argument depending on its first argument
11:02:15 <S_J> :t (=<<)
11:02:16 <lambdabot> Monad m => (a -> m b) -> m a -> m b
11:02:23 <S_J> :t (>>=)
11:02:24 <lambdabot> Monad m => m a -> (a -> m b) -> m b
11:02:31 <quchen> > let find p = foldr go Nothing where go x acc | p x = Just x | otherwise = acc in find even [1..]    -- This, for example ignores acc if "p x" is true.
11:02:32 <lambdabot>   Just 2
11:03:34 <startling> > let f n = if n > 3 then const 1 else id in foldr f 0 [1..]
11:03:35 <lambdabot>   1
11:03:42 <startling> er
11:03:54 <startling> > let f n = if n > 3 then id else const 1 in foldr f 0 [1..]
11:03:55 <lambdabot>   1
11:03:57 <startling> er
11:04:12 <startling> you get the idea?
11:05:03 <banister_> kinda, getting there, i'll just ponder it for a while thx :))
11:07:08 <S_J> Does processes use so much more memory or why isnt messaging between processes used more where people use threads?
11:07:32 <S_J> I assume however that deadlocks and livelocks can still be achieved with messaging?
11:08:08 <Addendum> Hey, ``ghc-pkg check'' recently started to give me this: ``WARNING: cache is out of date:/home/me/.ghc/x86_64-linux-7.6.3/package.conf.d/package.cache'' What could be the reason for this? I'm using the archhaskell repositories and have used cabal-install only inside a hsenv virtual environment.
11:08:14 <startling> S_J: yeah.
11:08:26 <startling> (to the latter)
11:10:06 <quchen> startling: Can STM deadlock somehow? I mean is there a pathological example?
11:10:11 <byorgey> Addendum: I am not sure what causes that.  But try doing  'ghc-pkg recache' and see if that fixes it.
11:10:31 <quchen> Like where one transaction does nothing but fiddle around in other transactions to make them rety and vice-versa
11:10:34 <byorgey> I realize that may not be a very satisfying answer.
11:10:53 <johnw> quchen: you could have a transaction that maps over an infinite list, for example
11:11:12 <johnw> quchen: that would make everyone block waiting on that transaction to finish
11:11:31 <johnw> but otherwise, it's very hard to create deadlocks with STM
11:11:41 <quchen> johnw: Wouldn't the longer taking transaction be retried once something else finishes first?
11:12:00 <johnw> quchen: actually, I think you might be right there
11:12:17 <johnw> The most asynchronous part of our server architecture uses STM, and I've never experienced a deadlock even once
11:12:47 <byorgey> you could have a transaction that just sits there writing to TVars and never finishing
11:12:54 <byorgey> so everything else would always retry?
11:13:17 <byorgey> fryguybob is the person you should ask =)
11:13:20 <johnw> The only bug I ever ran into, was that I had two threads, and one had dropped its reference to the TMVar (GC'd the value containing it), and so the other one raised an exception because it detected that the TMVar would never be written to
11:13:44 <quchen> byorgey: We're not sure. I think the case we're thinking about is "foldM (modifyTVar x) infiniteList", which makes everything retry that also accesses "x".
11:13:47 <johnw> that's in six months, one bug due to my error
11:13:55 <johnw> I'd say STM is pretty solid :)
11:13:56 <byorgey> quchen: right.
11:14:11 <johnw> and the exception told me exactly what the issue was!
11:14:29 <quchen> byorgey: But then I said "maybe the long-taking transaction is retried because it is never committed, as opposed to short other transactions that can finish early"
11:15:03 <byorgey> quchen: right, good question.  I don't know.
11:15:16 <johnw> today's challenge: create an STM deadlock scenario
11:15:27 <quchen> I'm not sure how exactly STM works, here's my mental model: run the STM thing until it's done; if something has changed when you're done, retry, otherwise commit
11:15:46 <johnw> quchen: there is some delaying smarts behind retry also
11:15:47 <fryguybob> quchen: There are a few more details :D
11:15:54 <elliott> STM's problem is more livelock, AIUI.
11:15:58 <quchen> If that's true, the "silly foldM" couldn't deadlock because it would a) never commit because it never terminates, or b) retry because something was modify.
11:16:03 <johnw> like, it will not rerun the transaction until it detects that something may have changed to warrant a retry
11:16:22 <quchen> fryguybob: Even more details? Man this is too complicated.
11:16:49 <luite> johnw: there must be more STM bugs since it took fryguybob only a day to find one when checking my GHCJS STM implementation (bug in GHC's STM) :p
11:16:57 <johnw> when I try to sell Haskell to my C++ friends, STM is one of my strongest examples
11:16:57 <fryguybob> It is helpful to separate the concept of a failed transaction from the  retry  primative.
11:17:19 <byorgey> luite: to be fair, that was a bug in a feature that no one uses, right? =)
11:17:20 <johnw> luite: well, if there are more bugs in my use of STM, I'm still waiting on the bug reports to come in :)
11:17:20 <quchen> elliott: Livelock in the sense that it can get unbearably slow when lots of transactions modify the same thing?
11:17:28 <fryguybob> luite: In GHC's defence it is in a feature that is never used :P
11:17:39 <quchen> elliott: I'm guessing that becomes an issue when your transactions become long and complex a lot
11:17:50 <S_J> When I try to sell C++ to my Haskell friends coolness is my strongest argument
11:17:55 <fryguybob> quchen: You can construct situations that *should* commit eventually, but do not.
11:17:58 <luite> byorgey: well, fryguybob certainly hopes so, because it's not supported in hardware ;)
11:18:04 <byorgey> hehe
11:18:12 <luite> i think he's been hiding all the uses from us
11:18:18 <johnw> fryguybob: I have noticed on Mac OS X that if an STM transaction sits idling for about 5 minutes, my process will segfault with a very strange error that appears to be coming from the STM internals; let me see if I can find you that error...
11:18:20 <quchen> fryguybob: "not" as in "never", or just very slowly?
11:18:26 * fryguybob deletes what he does not like from hackage.
11:18:42 <fryguybob> quchen: Never.
11:18:58 <quchen> fryguybob: Oh. Could you give me an example (idea)?
11:19:02 <luite> johnw: it was in the invariants, those are rather tricky
11:19:16 <monochrom> when using STM, I try very hard to not atomically (foldM (modifyTVar x) ys) anyway. it's a critical section. I don't like doing too many things in a critical section.
11:19:17 <johnw> luite: you mean that problem is fixed now?
11:19:34 <luite> johnw: dunno, maybe in GHC HEAD
11:19:42 <luite> fryguybob probably knows the ticket :)
11:19:47 <Addendum> byorgey: Didn't work unfortunately. I have now removed the /home/me/.ghc folder and reinstalled hsenv via cabal. Seems to work now.
11:19:54 <byorgey> Addendum: ok.
11:19:58 <johnw> monochrom: right, I try to "get in, get out", even if it means breaking it up into two atomically blocks if it makes sense to
11:20:20 <fryguybob> quchen: The simple example is some transaction that is very short that always succeeds and some transaction that does a lot of work, then reads the TVar from the short transaction.
11:20:48 <fryguybob> The long one will only commit when something strange happens with the schedular.
11:21:52 <quchen> fryguybob: Ah, right. For example if your program counted the number of successful STM transaction in a TVar.
11:22:05 <fryguybob> johnw: I'm not aware of the issue you are talking about.
11:22:07 <Luke> what's going on here?:    Couldn't match expected type `ByteString'  with actual type `bytestring-0.9.2.1:Data.ByteString.Internal.ByteString'
11:22:17 <Luke> shouldnt that be the same type?
11:22:25 <geekosaur> you have multiple versions of the bytestring package installed
11:22:34 <johnw> fryguybob: looking through my logs.  I record everything that ever occurs in my Terminal window to Git, so it's just a matter of finding it
11:22:37 <Luke> yeah I do
11:22:38 <elliott> incoming monochrom link :)
11:22:39 <Luke> i hid one though
11:22:52 <geekosaur> and it's trying to use the Bytestring from one with somethingt hat ewas compiled against theother
11:22:53 <quchen> elliott: The one on how to reinstall everything? :s
11:22:57 <monochrom> different versions imply different types. it is why one of them comes with package name and version
11:22:59 <byorgey> Luke: seeing package version numbers in your error messages is a Bad Sigh
11:23:06 <byorgey> *Sign, even
11:23:06 <Luke> i hid the bytestring-0.9.2.1 package
11:23:12 <byorgey> it also makes you Sigh
11:23:14 <geekosaur> hiding doesn't help if you still have exposed some library that was compiled against the hidden one
11:23:17 <elliott> byorgey: it usually causes a bad sigh, too
11:23:17 <Luke> haha
11:23:37 <fryguybob> quchen: Given  retry  you can write yourself a deadlock by just retrying when there is no hope of some other thread making a change to a relevent TVar.
11:23:42 <geekosaur> because it was compiled against that version and will not magically recompile itself against the one you want to use
11:23:42 <monochrom> you should disallow multiple versions. just disallow. just say no.
11:23:54 <Luke> i'm starting with a fresh cabal package env so I can just start again
11:24:35 <johnw> hmm.. since I don't remember what words the error message used, I can't find it
11:24:38 <fryguybob> quchen: And there is a narrow window for commits of two conflicting transactions to cause *both* to abort.  This could happen indefinately, but that is highly unlikely.
11:25:00 <fryguybob> johnw: :(
11:25:03 <joehillen> Luke: have you tried cabal-dev?
11:25:25 <quchen> fryguybob: And there goes my "STM is cool because no deadlocks by design" selling point.
11:25:26 <monochrom> cabal-dev would not have helped this one either
11:25:41 <S_J> :t readLine
11:25:41 <Luke> i don't bother with it
11:25:41 <lambdabot>     Not in scope: `readLine'
11:25:42 <lambdabot>     Perhaps you meant one of these:
11:25:42 <lambdabot>       `readFile' (imported from Prelude),
11:25:50 <quchen> :t readLn
11:25:51 <lambdabot> Read a => IO a
11:25:53 <S_J> how do i read input from commandline?
11:25:55 <Luke> i just blow things away and start over
11:26:11 <Luke> "Failed to load interface for `GHC.Paths'" what package do I need here?
11:26:20 <johnw> quchen: How about, "STM is cool because if you ever do create a deadlock, you deserved it."
11:26:25 <byorgey> quchen: it doesn't have deadlocks, only livelocks
11:26:29 <fryguybob> quchen: Well all but the last case I gave are pretty straight forward.
11:26:38 <joehillen> I assumed it would help prevent having with multiple versions
11:26:42 <quchen> S_J: Best practice is using `getLine` and using a parser. Read is smelly.
11:26:45 <geekosaur> I hope you did not literally blow *everything* away
11:27:12 <geekosaur> because that includes the ghc package and the base package, which come with the compiler and you can't replace or rebuild yourself
11:27:28 <fryguybob> byorgey: You could argue that  atomically retry  is a deadlock, but it is something silly that you wrote.
11:27:36 <byorgey> hehe, fair
11:28:16 <dropdrive> Is there a nice way to write, without do-syntax, x <- ...; ...; return x  -- i.e. do something with a result, do something else without a result, return the first result
11:28:21 <S_J> printer = print 5 >> printer // why cant that be IO Int?
11:28:31 <quchen> fryguybob: Well, that won't deadlock the program or anything useful at least.
11:28:38 <fryguybob> Your application may require more fairness then GHC's STM gives and I'm not sure what good options there are for addressing that.
11:28:39 <byorgey> S_J: it can.
11:28:53 <parcs> dropdrive: do_something <* do_something_else
11:29:05 <koala_man> neat
11:29:12 <quchen> forever . atomically $ modifyTVar (+1) x >> retry   -- That one looks lockier.
11:29:13 <byorgey> > @type let printer :: IO Int; printer = print 5 >> printer  in  printer
11:29:14 <lambdabot>   <hint>:1:1: parse error on input `@'
11:29:17 <dropdrive> parcs: Thanks.
11:29:18 <byorgey> @type let printer :: IO Int; printer = print 5 >> printer  in  printer
11:29:19 <lambdabot> IO Int
11:29:30 <quchen> Wait, you don't even need the `forever`.
11:30:46 <Luke> I started using flymake finally with haskell emacs and it's awesome
11:30:53 <Luke> any other absolute musts for emacs haskell?
11:31:20 * acube likes flycheck + hdevtools with emacs
11:31:38 <johnw> acube: yeah, that's a pretty amazing combination
11:31:39 * hackagebot smtLib 1.0.6 - A library for working with the SMTLIB format.  http://hackage.haskell.org/package/smtLib-1.0.6 (IavorDiatchki)
11:33:58 <johnw> how come Haskell Platform uses Cabal 1.16.0 instead of 1.16.0.3?  Hasn't the latter been out for a quite a while?  I thought there were some serious bugs in the former
11:34:17 <dcoutts> johnw: an unfortunate sequence of events
11:34:29 <dcoutts> ghc didn't pick it up when we were expecting
11:34:37 <johnw> ah, ok
11:35:08 <johnw> i'm trying monochrom's trick of "pinning" all the HP versions, which is working quite nicely, except that I noticed I've regressed down to 1.16.0
11:35:10 <elliott> everyone shoudl be on 1.17 anyway :)
11:35:15 <elliott> *should
11:35:27 <johnw> will there be a 2013.4 HP release to bump things like that?
11:35:48 <monochrom> Luke: GHC.Paths is from ghc-paths
11:36:24 <Luke> thanks
11:36:40 * hackagebot NetSNMP 0.3.0.6 - Bindings for net-snmp's C API for clients  http://hackage.haskell.org/package/NetSNMP-0.3.0.6 (PavloKerestey)
11:36:53 <monochrom> Haskell Platform does not muck with what comes with GHC. GHC 7.6.3 comes with Cabal 1.16.0
11:37:03 <johnw> ahh
11:37:06 <johnw> that makes sense
11:37:19 <S_J> is there single branch if? like if b then x.
11:37:25 <johnw> i guess I'll just stick with 1.16.0 then
11:37:36 <quchen> S_J: No. What happens if b is false?
11:37:56 <quchen> S_J: In a monadic context, there's `when` and `unless` though, which behave similar to what you're asking.
11:38:27 * monochrom suggests if b then x else undefined, to drive a point
11:38:41 <quchen> monochrom: :P
11:40:04 <monochrom> even in mainstream imperative language, the misleading shorthand "if b then do_this" harms reasoning about programs
11:40:05 <hpaste> elliott pasted “parametricity-based pattern matching!” at http://paste.tryhaskell.org/90659
11:40:09 <elliott> ^ silliness
11:41:06 <quchen> elliott: That's not legal, is it?
11:41:18 <monochrom> consider "x := 0; if b then x:=x+1". you run it, you observe that the final x is still 0. you infer that b must have been false. how do you infer it?
11:41:53 <elliott> quchen: no. but it could be.
11:41:59 <S_J> so does haskell have semaphores?
11:42:15 <elliott> quchen: I can translate all of those snippets into running code that obeys the equational laws given; I believe the translation could be mechanised
11:42:15 <quchen> S_J: Yes. They're called "Sem".
11:42:22 <monochrom> note that naively translating "if b then x:=x+1" to "b implies changing x" is insufficient. it emphatically does not say "what if b is false".
11:42:25 <elliott> except maybe coerce. that one is wacky.
11:42:29 <elliott> but sound.
11:42:43 <S_J> messagesging between threads? like block thread until it can receive froma  mailbox?
11:43:02 <quchen> S_J: Yes, MVars do that. They're the #1 tool for creating deadlocks.
11:43:21 <monochrom> you have to expand the shorthand, "if b then x:=x+1 else change_nothing". now you use the explicit change_nothing to infer that b was false.
11:43:26 <quchen> Or STM, which we discussed earlier. It's a very bad tool at creating deadlocks.
11:43:56 <monochrom> if you have to expand a shorthand for reasoning, it is a bad shorthand, it is not a true shorthand.
11:44:30 <S_J> so whats the weakness of STM?
11:44:38 <S_J> slow?
11:44:43 <Demos> IO is tricky
11:44:56 <quchen> S_J:  There's some overhead, yes, but not enough to make it "slow".
11:45:02 * elliott would say the separation of IO is a feature of STM, not a downside
11:45:12 <johnw> S_J: the biggest is that you can't do IO within an atomic block, which you can do with an MVar, say
11:45:17 <johnw> elliott++
11:45:22 <elliott> haskell has several properties that coincide to make STM an especially good fit. it is of course not a silver bullet.
11:45:24 <johnw> I *like* that I can't do IO in atomic blocks
11:45:37 <monochrom> "if b then x:=x+1 else change_nothing" is translated to "(b implies changing x) and (not b implies change_nothing)". the unsaid part "(not b implies change_nothing)" is the one you use to reason.
11:45:52 <johnw> you can always fake it in STM by using a flag to guard I/O regions
11:45:59 <quchen> johnw: Well, you kind of can do IO by forking off a dedicated IO worker thread. But that's a workaround.
11:46:01 <Demos> yes but sometimes you may want threaded IO, and you would just use testing to ensure no deadlocks. Sometimes you need to shoot the gun very close to the feet
11:46:22 <elliott> you can also use unsafeIOToSTM, not, that, um, I've ever done that or anything...
11:46:24 <startling> can't you just return IO actions from STM?
11:46:27 * elliott hides
11:46:30 <quchen> johnw: Often it's a very useful workaround that has benefits of its own though, such as not printing garbage when multiple IOs are issued
11:46:35 <elliott> (disclaimer: don't. I regretted it!)
11:46:40 <startling> (Maybe using an STMT thing?)
11:46:40 <fryguybob> startling: Yes
11:46:48 <johnw> atomically (working <- readTVar foo; check (not working); writeTVar working True); do I/O...; atomically (writeTVar working False)
11:46:48 <napping> or just implement the equivalent of lock and unlock with transactions
11:46:53 <startling> yeah. I don't see the problem.
11:46:55 <S_J> johnw: if you can do Io, how can it be atomic?
11:47:01 <quchen>  @remember  you can also use unsafeIOToSTM, not, that, um, I've ever done that or anything...
11:47:20 <quchen> elliott: The space is intentional. Let's see whether the HWN sees it the same way :>
11:47:29 <napping> S_J: the sequence with IO in the middle isn't atomic, but you can use STM to implement appropriate synchronization primitives
11:47:32 <elliott> quchen: I'm just glad you left my name off it!
11:47:33 <S_J> So testing for deadlocks with quickcheck, any code example of that?
11:47:37 <quchen> elliott: Arrr.
11:47:51 <startling> how could you test for a deadlock?
11:47:58 <startling> (timeouts I guess?)
11:48:00 <Demos> S_J I dont know, maybe look at Go's race detector?
11:48:08 <Demos> for ideas that is
11:48:23 <quchen> startling: Racing against threadDelay is one very basic way
11:49:07 <startling> yeah.
11:49:15 <elliott> hmm, what *is* the free theorem for (eq :: forall p. p A -> p B)?
11:49:19 <elliott> just f . eq = eq . f?
11:49:27 <quchen> startling: The only other thing I can come up with is pray that GHC detects it and throws
11:49:37 <startling> quchen, heh
11:49:47 <quchen> startling: compile with --faith
11:50:13 <napping> elliott: http://www-ps.iai.uni-bonn.de/cgi-bin/free-theorems-webui.cgi
11:50:26 <elliott> does that handle more than @free can?
11:50:29 <startling> +RTS --faith -RTS
11:50:43 <elliott> In the declaration of `f' at (1:1): A variable must not be applied to a type.
11:50:49 <S_J> is there a way to ahve a global variable in haskell? i assume not?
11:50:49 <elliott> well, looks like it can't handle leibniz equality at least
11:50:53 <elliott> neat-looking tool though
11:51:04 <napping> I guess it doesn't like higher-kinded variables?
11:51:05 <byorgey> napping: that can't handle quantification over type constructors
11:51:07 <startling> S_J: you can have lots of global variables in haskell! but you can't change them.
11:51:08 <quchen> startling: Isn't there this profiling flag that beeps every time there's a major garbage collection? This may sound silly, but in case of a big deadlock that might actually help
11:51:08 <byorgey> right.
11:51:22 <startling> quchen, no idea
11:51:31 <elliott> oh wait, f . eq = eq . f doesn't even type.
11:51:35 <monochrom> yes, there is
11:51:37 <elliott> so I don't know what it would be.
11:51:58 * monochrom is too lazy to read the GHC user's guide
11:52:44 <quchen> monochrom: http://www.haskell.org/ghc/docs/7.0.1/html/users_guide/runtime-control.html#rts-options-debugging
11:52:53 <Saizan> elliott: it does if you take f :: forall a b. P a -> P b
11:52:54 <quchen> "Oddly enough, people really do use this option!"
11:53:03 <Saizan> err
11:53:25 <Saizan> even with forall a b. P a -> Q b
11:53:49 <elliott> I'm confused
11:53:50 <byorgey> Saizan: that's not the same at all.
11:53:53 <Saizan> but what you want is forall a. P a -> P a
11:53:57 <elliott> huh?
11:54:00 <elliott> no, a and b are fixed
11:54:05 <elliott> I'm thinking Leibniz equality of a and b
11:54:14 <supki> @google toplevel mutable state
11:54:15 <lambdabot> http://www.haskell.org/haskellwiki/Top_level_mutable_state
11:54:15 <lambdabot> Title: Top level mutable state - HaskellWiki
11:54:19 <elliott> i.e. (forall p. p A -> p B) for some concrete A and B
11:54:21 <Saizan> sorry, i'm being a mess, but you want f to be a natural trasnformation there
11:54:21 <supki> S_J: ^
11:54:27 <monochrom> Saizan, elliott wants parametericity on the higher kinded p :: * -> *
11:54:33 <elliott> we don't know anything about p
11:54:47 <elliott> newtype Is a b = Is { subst :: forall p. p a -> p b }
11:54:51 <elliott> refl :: Is a a; refl = Is id
11:54:54 <elliott> is what I'm thinking about
11:55:01 <Saizan> monochrom: that's why the naturality condition is going to be about commuting eq with natural transformations
11:55:09 <Saizan> elliott: sure
11:55:51 <elliott> ok, maybe we're on the same page then :)
11:56:11 <johnw> dcoutts: can you think of a reason why passing -j to cabal would cause it to fail to resolve a dependency that it does just fine with no -j
11:56:22 <johnw> dcoutts: and further, when only one package is being built!
11:56:22 <Saizan> the theorem is going to be forall P, Q, (f :: Nat(P,Q)), f B . eq P = eq Q . f A
11:56:38 <dcoutts> johnw: no, that should make no difference to the dep resolution, just the plan execution.
11:56:41 <johnw> dcoutts: https://gist.github.com/5921673
11:56:53 <johnw> fpbuild is just our wrapper for deciding when cabal should actually be run
11:57:00 <Saizan> elliott: ^^^
11:57:12 <elliott> Saizan: ok, that does seem reasonable. I am wondering if you can use the free theorem to prove that all (eq :: forall p. p a -> p b) are actually (id :: forall p. p a -> p a)
11:57:22 <johnw> so, that Cabal-1.16.0 it's complaining about is in my user package database, but not in my hsenv environment's package database
11:57:27 <dcoutts> johnw: ah, so it's not a dep resolution error
11:57:29 <johnw> so I'm wondering what's "leaking" here
11:57:38 <elliott> hmm, I guess that's suspiciously close to a weirdo version of axiom K
11:57:51 <elliott> I am really just wondering if my "coerce" definition in http://paste.tryhaskell.org/90659 can be justified with similar principles as the rest.
11:58:13 <dcoutts> johnw: ok, the issue there is this...  when we do -j we always use the "external" setup method, ie we actually compile Setup.hs. That needs the Cabal lib. Without -j we sometimes can avoid compiling the Setup.hs
11:58:14 <monochrom> you have Cabal-1.16.0 in user? not just global?
11:58:26 <johnw> dcoutts: ahh
11:58:35 <johnw> monochrom: sorry, you're right, it's in the global package dataabse
11:58:49 <johnw> but globally I have GHC 7.6.3, while in this hsenv environment I have GHC 7.4.2
11:59:06 <johnw> so I'm just puzzled as to why it's touching my global environment at all
11:59:11 <byorgey> ahhhh, I think I have run into this before too.  Now I understand.
11:59:36 <johnw> monochrom: here's the output from ghc -v inside the hsenv environment: https://gist.github.com/5921707
11:59:46 <elliott> ...though maybe powerful enough parametricity axioms *do* imply axiom K???
11:59:47 <johnw> as you can see, no reference to the external database
12:00:14 <elliott> that would be interesting because it would mean there's a conflict between internalised parametricity and univalence.
12:02:05 <yesthisisuser> is it a type that is an instance of a typeclass or a type constructor?
12:02:36 <byorgey> yesthisisuser: a type.
12:02:44 <elliott> yesthisisuser: depends what you mean by type.
12:02:50 <elliott> most likely, it can be both.
12:03:07 <byorgey> what?
12:03:15 <yesthisisuser> i recall LYAH talking about type constructors being instances of typeclasses
12:03:21 <elliott> for instance, instances of Num are types of kind * (like Int or Double); instances of Functor are types of kind * -> * (like IO or [] or Maybe; type constructors)
12:03:35 <elliott> (one-argument type constructors, mind)
12:03:40 <byorgey> oh, I was thinking data constructor, sorry
12:03:47 <elliott> hehe
12:03:57 <byorgey> I really really hate the 'type constructor' terminology
12:04:05 <byorgey> it is such a useless distinction
12:04:15 <byorgey> and is inconsistent with 'data constructor'
12:04:17 <yesthisisuser> oh?
12:04:26 <Saizan> elliott: i don't think you get to prove Is a b is only inhabited by id, since A and B are fixed you could have a subst in there
12:04:44 <S_J> Control.Monad.when is handy!
12:05:33 <elliott> Saizan: right, I guess I'm not exactly sure what I'd need. I mean, coerce is basically using the J rule, I think, so I guess the question is whether you can justify the J rule for Leibniz equality "mechanically" from parametricity.
12:05:57 * byorgey makes a note to write a blog post about it
12:06:51 <johnw> dcoutts: ok, this isn't cabal
12:06:55 <S_J> how do I return an IO string?
12:06:57 <napping> which one is J
12:07:06 <S_J> i want to terminate my function
12:07:10 <napping> ah, http://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory/
12:07:11 <johnw> dcoutts: if I let fpbuild prep the package and then do "cabal install -j", same failure.  but if I cabal clean and then cabal install -j, it works just fine
12:07:18 <elliott> napping: the one that says you can do induction on (p : x = y) by considering the case where x is y and p is refl
12:07:26 <byorgey> S_J: you cannot terminate a function early in Haskell.
12:07:35 <Saizan> elliott: tbf you can implement coerce just by applying the function..
12:07:44 <johnw> byorgey: he could use ContT
12:07:51 <elliott> er, *y is x
12:08:05 <dcoutts> johnw: ok
12:08:29 <byorgey> johnw wins the award for most technically correct but completely useless advice of the day =)
12:08:40 <S_J> byorgey: but i can return something then it should go back to the calling function?
12:08:49 <elliott> Saizan: well, in Haskell you need a newtype wrapper around the value. the implementation strategy for these is obvious -- find everything referencing the type "a" in the environment, make a type parameterised on "a" where they're all arguments, make the function body take them all in, use the equality function on it and then pass everything from the environment in
12:09:12 <elliott> but I'm wondering if a more general "parametricity-based function pattern matching" approach can handle both the other examples and weirder stuff like "coerce" in a uniform way.
12:09:46 <byorgey> S_J: note, the 'return' function in Haskell has nothing to do with returning from functions. It is quite unlike the 'return' keyword in Java and C.
12:09:55 <monochrom> the day hasn't ended. you still don't know that johnw wins. who knows, perhaps I'll submit a better one in a moment
12:10:06 <monochrom> hell, I have just submitted one :)
12:10:18 <elliott> Saizan: I realise the question is pretty vague though :)
12:10:20 <S_J> how do I produce an IO String?
12:10:26 <byorgey> monochrom: you have a point =)
12:10:27 <S_J> byorgey: yes i know
12:10:48 <byorgey> S_J: if you have   x :: String, then   return x :: IO String
12:11:29 * johnw doesn't feel like a winner if byorgey uses the word "useless" in the same sentence as his name
12:11:40 <byorgey> heh
12:12:14 <byorgey> "johnw almost never says useless things"
12:12:25 <elliott> talk about damning with faint praise
12:12:33 * monochrom likes the same sentence having both his name and "useless", if it is "monochrom renders other people useless" :)
12:12:37 <elliott> man, johnw is great, he almost never kills my family.
12:12:38 <johnw> byorgey: haha
12:13:29 <S_J> http://paste.tryhaskell.org/90660 <- Func does not terminate. I keep being able to give input and it prints it...
12:14:13 <johnw> S_J: your second when in the second def of run needs to be an if
12:14:23 <djahandarie> koninkje_away, hmm, is there no way to do a lookup in bytestring-trie that just gives you the last node doven into when you shoot past the end of the tree?
12:14:26 <S_J> I see, it goes back and calls run False (Just tid) again
12:14:26 <johnw> run False $ if input == "q" then Nothing else Just tid
12:15:40 <S_J> weee!
12:17:12 <Saizan> elliott: dolio had some agda about deriving induction principles from parametricity for church encodings, i don't remember how far he got though
12:17:33 <elliott> yeah, I've seen that, it's cool
12:17:47 <elliott> it didn't look very "automatic" though
12:23:26 <dolio> elliott: You might be interested in a paper I was looking at the other day.
12:24:23 <dolio> http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.175.345
12:25:09 <elliott> dolio: looks interesting, thanks!
12:25:22 <dolio> I think he does GADTs and everything by the end.
12:26:26 <dolio> I'm not convinced it's a fruitful design for an actual language, though.
12:27:38 <dolio> It's interesting, though.
12:28:07 <elliott> well, using church/boehm-beararducci encoding for everything would be hideously inefficient, at the very least. but internalised parametricity + just using functions seems very elegant, at least.
12:28:15 <elliott> even if you need impredicativity to get it working nicely.
12:29:24 <elliott> I wonder if you get bisimulation-implies-equality with internalised parametricity and encoding codata like Wadler...
12:30:27 <dolio> Not sure.
12:32:01 <elliott> maybe you'd sort of have to, since otherwise the coinduction principle wouldn't work.
12:32:27 <elliott> uh, I wonder if that somehow lets you derive functional extensionality, then.
12:32:30 <dolio> What coinduction principle?
12:32:34 * elliott shouldn't speculate about things he knows next to nothing about.
12:32:56 <elliott> dolio: the one you'd hope to recover from an internalised parametricity axiom + an encoding of the codata
12:32:56 <danharaj> is ed_vardkk around just to ruin my tab completion? :3
12:33:07 <elliott> just like you can recover the induction principle for data.
12:33:23 <elliott> like uAgda does.
12:33:43 <gabriel__> @pl \as bs cs -> as ++ bs ++cs
12:33:46 <lambdabot> flip ((.) . (.) . (++)) (++)
12:33:46 <lambdabot> optimization suspended, use @pl-resume to continue.
12:34:21 <dolio> I'm kind of skeptical that you can get function extensionality.
12:34:32 <dolio> But I haven't thought about it much.
12:34:47 <gabriel__> @pl-resume
12:34:53 <lambdabot> flip ((.) . (.) . (++)) (++)
12:34:54 <lambdabot> optimization suspended, use @pl-resume to continue.
12:35:05 <elliott> yes, it seems sort of implausible. maybe you can get functional extensionality for any concrete domain type A, i.e. for (A -> ...)
12:35:10 <quchen> gabriel__: That won't get any prettier. Use the Lambda (or consider using `concat`).
12:35:14 <elliott> by encoding the function as codata using A's induction principle.
12:35:18 <gabriel__> :)
12:35:26 <gabriel__> thanks
12:35:29 <elliott> and then using the (presumed) ability to turn bisimulation into equality.
12:35:30 <elliott> or something.
12:35:55 <dolio> I'm a little skeptical that you could get a 'coinduction principle' for the same reason.
12:35:56 <quchen> gabriel__: As a rule of thumb, functions of more than one argument rarely yield nice poitfree versions. I have yet to see an example of a pretty 3-argument one.
12:36:24 <gabriel__> yeah, I was hoping for a pretty combinator
12:36:44 <quchen> > concat ["hell", "lo wo", "rld!"]
12:36:44 <lambdabot>   "helllo world!"
12:37:12 <danharaj> dolio: Was it you who wrote an article about dinaturality and parametricity for the comonad reader sometime last year?
12:37:15 <elliott> dolio: well, I'm just going off the intuition that it lets you prove that all elements of (forall A, A -> (A -> A) -> A) are equal to this-or-that, which is proving something about equalities of certain canonical forms of a type of codata (i.e. functions). but it's very vague, I know.
12:37:24 <elliott> it = internalised parametricity
12:37:24 <edwardk> he did
12:37:49 <danharaj> I was wondering if there ever was a follow-up since I've been doing stuff with ends and coends and wanted to know where the minefield is.
12:39:00 <dolio> elliott: Codata doesn't not have canonical forms, though.
12:39:26 <elliott> dolio: right.
12:39:50 <elliott> well, someone who isn't me should work out all the details and figure out what you need to get usable codata from encodings.
12:39:53 <dolio> It's like it has canonical responses to queries, or something.
12:40:04 <elliott> I assign shachaf.
12:40:06 <dolio> I don't know if you can work backwards from that.
12:40:57 <dolio> danharaj: I didn't have a followup planned.
12:41:01 <NemesisD> anyone have any suggestions for creating an Arbitrary instance for a Text newtype
12:41:38 <danharaj> dolio: but you left me with a cliff-hanger about whether or not removing the class constraint from the type was too restrictive or not :P
12:41:40 * hackagebot hatex-guide 1.0.1.3 - HaTeX User's Guide.  http://hackage.haskell.org/package/hatex-guide-1.0.1.3 (DanielDiaz)
12:41:47 <NemesisD> i figure i need it to generate a list of chars of random length and then pack it
12:41:49 <dolio> Except one where if you interpret quantifiers in a categorical way, then a lot of things we do in Haskell translate into category theory in general.
12:41:55 <dolio> But that's kind of the opposite message. :)
12:42:47 <dolio> I don't actually remember what you're talking about.
12:42:59 <S_J> Could not find module `System.Posix.Semaphore'
12:43:17 <S_J> not for windows?
12:43:35 <danharaj> dolio: fortunately I found a mirror of your article: http://comonad.newartisans.com/reader/2012/unnatural-transformations-and-quantifiers/index.html
12:45:40 <S_J> isnt it just cabal update?
12:45:49 <S_J> cabal: <socket: 348>: failed
12:45:58 <dolio> Oh.
12:48:09 <dolio> danharaj: Haven't thought about it since then. Sorry.
12:58:29 <danharaj> dolio: no worries. I'll just have to think for myself.
12:59:14 <dolio> danharaj: I haven't thought about it, but I think 'forall r m. (a -> m r) -> m r' isn't any different from 'forall r. (a -> r) -> r' which is isomorhic to a.
12:59:32 <dolio> Isomorphic.
13:00:34 <Bor0> @src (>>)
13:00:34 <lambdabot> m >> k      = m >>= \_ -> k
13:00:41 <Bor0> @src (>>=)
13:00:41 <lambdabot> Source not found. You type like i drive.
13:00:47 <Bor0> @src >>=
13:00:48 <lambdabot> Source not found. I am sorry.
13:00:51 <Eduard_Munteanu> Is there a tool that updates a .cabal file's dependencies section to whatever I have installed?
13:02:18 <nicoo> @ty (>>=)
13:02:19 <lambdabot> Monad m => m a -> (a -> m b) -> m b
13:03:11 <nicoo> Bor0: >>= is over a typeclass. lambdabot cannot find the source. (I dunno whether you can ask the source of a specific instance, though)
13:03:50 <dmwit> ?src [] >>=
13:03:50 <lambdabot> Source not found. My pet ferret can type better than you!
13:03:54 <dmwit> ?src >>= []
13:03:54 <lambdabot> Source not found.
13:03:57 <dmwit> hmph
13:04:24 <geekosaur> @src [] (>>=)
13:04:24 <lambdabot> xs >>= f     = concatMap f xs
13:04:25 <dmwit> ?src [] (>>=)
13:04:25 <lambdabot> xs >>= f     = concatMap f xs
13:04:35 <nicoo> \o/
13:04:37 <dmwit> hehe, a few seconds too slow =)
13:04:47 * nicoo hugs dmwit and geekosaur :3
13:05:48 <ethoma> Does anyone know a quick most significant bit / least significant bit function for Word64's?
13:06:25 <S_J> Can you Sleep in haskell? call Sleep on a thread+
13:06:34 <dmwit> S_J: threadDelay
13:06:45 <ethoma> I just need the position of the bit (i.e. f 1 = 0, f 8 = 3)
13:07:09 <dmwit> have you looked in http://graphics.stanford.edu/~seander/bithacks.html ?
13:07:16 <S_J> ethoma: mask with & 0x80000001 ?
13:07:38 <nicoo> S_J: I think you misunderstood the question
13:07:39 <inf-groupoid> ethoma: What should the function's output be if it is passed 0?
13:07:39 <S_J> wait sorryu
13:07:42 <S_J> yes sorry
13:07:53 <ethoma> It doesn't matter - I will catch -
13:07:55 <Bor0> where can I see how >>= is defined?
13:08:00 <ethoma> 0's before I try it
13:08:04 <startling> Bor0, it's in Control.Monad
13:08:12 <dmwit> ethoma: (Specifically the "log base 2 of an integer" section.)
13:08:14 <Bor0> @src Control.Monad.(>>=)
13:08:14 <lambdabot> Source not found. Wrong!  You cheating scum!
13:08:19 <byorgey> Bor0: >>= is defined differently for each instance of Monad.
13:08:23 <startling> er, wait, no, it's in Prelude?
13:08:28 <byorgey> it is a method of the Monad type class.
13:08:30 <Bor0> what does it do in general?
13:08:32 <S_J> but start with maskign with 0x80000000 then right shift it once until it is 1
13:08:49 <startling> :t (>>=) -- Bor0: this is what it does
13:08:50 <lambdabot> Monad m => m a -> (a -> m b) -> m b
13:09:04 <inf-groupoid> S_J: What if the function is passed 0?
13:09:12 <dmwit> Bor0: It's behavior is very different for each of the types it can take on.
13:09:12 <byorgey> Bor0: that is a difficult question to answer in a meaningful way.  I suggest studying how (>>=) is defined for lots of example Monad instances.
13:09:15 <ethoma> I had an implementation in assembly in my C code that was quick - but I don't know if using the ffi will slow it down a lot. Speed is important so I am willing to go compiler native code.
13:09:39 <S_J> is there some smart way of calculating the MSB from an Int?
13:09:51 <dmwit> S_J: See the link I sent ethoma.
13:09:55 <byorgey> Bor0: at the end you might get a general feel for what (>>=) does in general.  But if I tried to tell you right now it would not mean anything.
13:09:57 <ethoma> inf_groupoid: To me, it doesn't matter. I would think 0 or -1
13:10:01 <S_J> inf-groupoid: i guess youd mad shift 63 times
13:10:30 <napping> S_J: do you mean testing whether the MSB is set or not, or finding the highest set bit?
13:10:43 <inf-groupoid> The latter.
13:11:21 <nicoo> S_J: There are smarts ways to do so (and avoid branching). Mostly, it's clever use of De Bruijn sequences
13:11:21 <dmwit> Oh, neat, there's also http://www.haskell.org/ghc/docs/latest/html/libraries/integer-gmp-0.5.0.0/GHC-Integer-Logarithms.html
13:12:40 <nicoo> dmwit: Nice
13:13:21 <S_J> can you implement an eternal loop like so: forever = forever?
13:13:31 <ethoma> dmwit: Thanks for the link. I think I am looking for something faster though like a native function. I will be doing the LSB/MSB function several hundred million times a second.
13:13:36 <dmwit> (Found by googling for "haskell integer logarithm".)
13:14:01 <S_J> Main: <<loop>> // what does that mean? stack explode?
13:14:13 <dmwit> No, the stack didn't explode.
13:14:19 <dmwit> It means you defined some value in terms of itself.
13:14:33 <dmwit> ...in a non-productive way.
13:14:37 <inf-groupoid> Int<n>/Word<n> are the same ring (Z/Z(2^n)) with different canonical elements, right? (IOW, in other to distinguish them, I need their Ord instances.)
13:14:39 <nicoo> S_J: You sure can :)
13:14:48 <geekosaur> it means that while trying to evaluate something, it fell right back into it.
13:15:09 <geekosaur> which is pretty much exctly what `forever = forever` does
13:15:36 <ethoma> It seems like the only way to get assembly called is to write it inline in a C program and then call the C function. I write assembly there for now and come back to performance later.
13:15:44 <dmwit> > let productive = 1:productive; unproductive = unproductive ++ [1] in (take 5 productive, take 5 unproductive)
13:15:47 <lambdabot>   mueval-core: Time limit exceeded
13:16:04 <dmwit> > let productive = 1:productive in take 5 productive
13:16:05 <lambdabot>   [1,1,1,1,1]
13:16:13 <dmwit> > let unproductive = unproductive ++ [1] in take 5 unproductive
13:16:17 <lambdabot>   mueval-core: Time limit exceeded
13:16:22 <geekosaur> (note that there is already a somewhat more useful `forever` in Control.Monad)
13:17:06 <elliott>  @let unproductive = elliott
13:18:07 <dmwit> ethoma: If programmer speed is unimportant compared to program speed, you will probably want to implement one of the bit twiddling hacks on that page as a primop in GHC.
13:18:14 <dmwit> ...gone
13:20:08 <S_J> so threadDelay knows which thread it is in...?
13:20:43 <dmwit> Strange question.
13:20:45 <dmwit> Not really?
13:20:49 <dmwit> It just delays a while.
13:21:17 <geekosaur> in what sense? it delays the current thread, that doesn't mean it knows anything about the thread
13:21:30 <geekosaur> or even if there is a specific thread vs. unthraded
13:22:27 <S_J> well it doesnt delay my thread...
13:23:10 <S_J> http://paste.tryhaskell.org/90661
13:23:20 <S_J> makes no difference(seemingly if the delays are in there
13:24:21 <dmwit> S_J: How long do you think threadDelay 2000 delays?
13:24:25 <dmwit> (Hint: read the documentation.)
13:24:36 <byorgey> hehehe
13:24:44 <byorgey> man, that trips up everyone
13:24:54 <sm> yup
13:24:55 <dmwit> yup
13:25:42 <byorgey> http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Concurrent.html#v:threadDelay
13:26:12 <S_J> dmwit: i thought 2 seconds but i see it is microseconds not milliseconds
13:26:18 <Eduard_Munteanu> dmwit: very long seemingly, they actually capped it at Int size. :P
13:26:41 <c_wraith> on a 32-bit machine, the max threadDelay is around 34 minutes
13:26:46 <napping> is there an intermediate LLVM binding which hides the Builder stuff in a monad, but isn't quite as typed as "llvm"?
13:27:35 <byorgey> on a 64-bit machine, it is about 292 thousand years
13:27:57 <c_wraith> so..  you're saying 64-bit numbers are bigger than 32-bit numbers?
13:28:26 <Eduard_Munteanu> Just a few of them :P
13:28:34 <bigs> hehe
13:29:08 <S_J> http://paste.tryhaskell.org/90662 <- How can that ping twice in a row? i think it should make them both ping/pong every 4 seconds...
13:29:42 <c_wraith> Actually, last time I tried, on 64-bit GHC on OS X, the max threadDelay is "wait, why did the RTS just panic and die?"
13:30:16 <S_J> c_wraith: yes, 2 on a 64bit machine is bigger but for example 7,33 and 992 is smaller on 64bit. can you see why?
13:30:47 <Eduard_Munteanu> S_J: there are no guarantees it lasts just 2000000, and no guarantees the rest of the code is executed at about the same rate
13:31:31 <Eduard_Munteanu> S_J: the only guarantee is the delay lasts *at least* that long
13:32:25 <S_J> ok, but thwy should still say something every second time. not 2 times in a row, that should impossible...or not?
13:32:31 <dmwit> ?@ For 32-bit machines there is @hackage unbounded-delays.
13:32:32 <lambdabot>  For 32-bit machines there is http://hackage.haskell.org/package/unbounded-delays.
13:32:50 <dmwit> ?botsnack
13:32:50 <lambdabot> :)
13:33:07 <dmwit> elliott!!!
13:33:07 <Eduard_Munteanu> S_J: the 2 threads aren't in sync in any way
13:33:43 <byorgey> I am confused too.  Maybe I don't understand what the QSems are doing.
13:33:56 <Eduard_Munteanu> Oh!
13:34:15 <Eduard_Munteanu> Don't listen to me, I missed that completely. :/
13:36:01 <Eduard_Munteanu> S_J: mind your semaphores are both initialized to 1 when this starts
13:36:22 <Eduard_Munteanu> S_J: you probably want just one of them to be 1
13:37:13 <S_J> yes. weird thing is thats how i did on linux in C and it worked, i guess it was just lucky/unlucky that it did...
13:37:28 <elliott> dmwit: help, what did I do.
13:38:24 <S_J> Eduard_Munteanu: now it works ( with just 1 inited to 1)
13:40:01 * byorgey likes dmwit's usage of @@ for message generation
13:41:53 <elliott> byorgey: I realised you could use it for message addressing originally: @@ newbie: @where lyah
13:42:05 <elliott> it's pretty cute syntax
13:42:12 <byorgey> yeah, I like it
13:42:47 <byorgey> @@ elliot: good job, have a @quote
13:42:47 <lambdabot>  elliot: good job, have a CosmicRay says: <CosmicRay> Is there a way to, say, convert from a Word32 to a Word8 when I know the data in question will fit in a Word8? ; <drlion> CosmicRay: just open
13:42:47 <lambdabot> the file and Word will ask you to convert it
13:43:15 <elliott> byorgey: I'd rather have a t. :(
13:43:34 <byorgey> elliottt: sorry
13:44:52 <elliott> it's ok byorge. I forgive you.
13:46:34 <byorgey> lliott: thanks.
13:53:11 <dEPy> anyone knows a name for thing when your urls are instead od /task/1   like this  /task/1-some-task-name
13:53:35 <Jeanne-Kamikaze> what's the difference ?
13:53:36 <sm> readable urls ?
13:53:48 <dmwit> byorgey, georgey's twin brother
13:53:49 <sm> slugs ?
13:54:33 <dEPy> guess they're named "semantic urls"
13:58:34 <bor0> @src map
13:58:34 <lambdabot> map _ []     = []
13:58:34 <lambdabot> map f (x:xs) = f x : map f xs
14:00:43 <dmwit> I feel like 1-some-task-name is the worst of both worlds.
14:00:58 <dmwit> It's got that non-semantic "1" nonsense and it still isn't hackable to get to task 2.
14:01:23 <dmwit> Offering /task/id/1 and task/name/some-task-name as aliases seems much better to me.
14:02:20 <dmwit> Though I suppose then you have the question of which alias you choose every time you need to link to a task.
14:02:22 <mee> or, if name has to start with a character, you can just do both at /task/id
14:02:23 <dmwit> I dunno.
14:02:40 <byorgey> /task/name/id/1-some-lose-some
14:02:45 <dmwit> mee: That kind of arbitrary restriction seems stupid to me, too. =P
14:02:53 <dmwit> byorgey: hahaha
14:03:06 <mee> well, any way to make the two namespaces disjoint would work
14:03:14 <dmwit> sure
14:03:21 <dmwit> I'm not married to "id" and "name". =)
14:04:03 <mauke> /task/id/1/name/o-hai
14:04:21 <sm> also, simple consecutive integers could be insecure
14:04:36 * mauke uses consecutive reals
14:05:00 <c_wraith> that sounds hard.
14:05:15 <sm> trello uses /type-of-thing/long-hash-id/optional-readable-name
14:06:11 <S_J> Couldnt STM have grave problems if you do a lot of writes which means the reads are not(?) ok and the trasaction will be pulled back?
14:06:55 <dmwit> sm: Again, that seems like we've lost the point of having an easily-guessable ID. Why not just offer /type-of-thing/readable-unique instead?
14:06:56 <nullcone_> Is there a better way to write this mergesort? http://i.imgur.com/Ho3MUsJ.png
14:07:14 <c_wraith> S_J: you can end up with many more transactions retrying than committing, yes.
14:08:06 <c_wraith> S_J: But *some* transaction needs to commit to cause an automatic rollback + retry, which means some (maybe slow) progress will always be made
14:08:25 <dmwit> nullcone_: Does that even terminate?
14:08:34 <byorgey> nullcone_: instead of  left = ...  right = ...  you could say  (left,right) = splitAt half as
14:08:41 <S_J> Maybe im stupid but: http://en.wikipedia.org/wiki/Software_transactional_memory // under Composable actions, what can happen in the itnermediate state that is bad?
14:08:42 <roconnor> S_J: though one transaction may never make progress
14:08:46 <c_wraith> S_J: still, the current STM implementation performs best when you have many mutable cells and most transactions only touch a couple of them.
14:08:48 <byorgey> uh, right, it needs some base cases too
14:08:57 <sm> dmwit: because it's insecure ? just pointing out the tradeoff, I certainly prefer mnemonic urls when possible
14:09:08 <nullcone_> dmwit: No, I'm just writing out mergesort and trying to explain what I'm doing
14:09:37 <sm> I once made a wiki engine that accepted fuzzy urls and auto-corrected them, it was great
14:09:47 <dmwit> sm: Or, in the other direction, what's the point of /optional-readable-name if you've already got a hash in the URL?
14:10:04 <nullcone_> byorgey: I see
14:10:35 <dmwit> nullcone_: Also, optional trick that I like and some others don't: instead of "merge [] ys = ys; merge xs [] = xs" you could write "merge xs ys = xs ++ ys".
14:11:27 <byorgey> oh, nice!  I hadn't seen that trick =)
14:11:53 <elliott> that's tricksy
14:12:03 <sclv_> you can have an interleaved lazy split, right?
14:12:25 <sclv_> getting the length and cutting directly in half is sort of lame
14:12:25 <dmwit> sclv_: Yeah, I was debating whether to suggest that or not. =)
14:12:26 <joehillen> is github down for anyone else?
14:12:26 <tromp_> that's less efficient though?!
14:12:29 <dmwit> Alternately: get the length once and pass it down as you go.
14:12:38 <nullcone_> dmwit: Nice :) where did you learn about that trick?
14:12:54 <dmwit> I invented it. I make no claim to being the first to do so.
14:13:27 <byorgey> joehillen: downforeveryoneorjustme.com  says it's down
14:13:28 <sclv_> there's a very efficient if not awful pretty mergesort in the prelude
14:13:32 <byorgey> https://status.github.com/
14:13:59 <dmwit> tromp_: Which thing is less efficient?
14:14:05 <sclv_> or in data.list rather: http://www.haskell.org/ghc/docs/latest/html/libraries/base/src/Data-List.html#sort
14:14:13 <sm> dmwit: the optional readable part makes the link more meaningful out of context (eg in an email), also can be auto-completed in browser address bar
14:14:23 <sm> I guess
14:14:57 <tromp_> dmwit: merge xs ys = xs++ys is less efficient than merge xs [] == xs
14:15:08 <dmwit> I feel your email is probably going to give context.
14:15:11 <sclv_> the one from data.list is all fancylike, doing some special sort of run optimization
14:15:24 <sclv_> tromp_: with inlining i bet they're the same
14:15:49 <sclv_> but the commented out one from igloo is pretty natural
14:16:09 <S_J> anyone have some STM examples?
14:16:09 <nullcone_> tromp_: why is it less efficient?
14:16:46 <dmwit> You pay for having a thunk during the entire walk of xs.
14:17:07 <tromp_> xs++[] takes O(n) steps to normalize
14:17:23 <sclv_> S_J if you want to see some fancy STM you can just look at the source of the derived data structures, like stm channels
14:17:28 <S_J> could STM be implemented on bare metal?
14:17:35 <sclv_> don't know what that means!
14:17:59 <S_J> stupid, obv you need threads to have stm or there is no point
14:18:05 <S_J> nm
14:18:10 <sclv_> i would do it on silicon, not metal. and then it wouldn't be bare, but it would need to be etched and imbued with various metals to form circuits, etc.
14:18:18 <sclv_> :-P
14:18:46 <dmwit> There are efforts to make HTM work, if that's what you're asking.
14:18:57 <sclv_> haswell has htm builtin
14:19:23 <sclv_> fryguybob is looking at how leverage that to make ghc moar better iirc
14:19:29 <mantovani> can someone give me examples, whipaper, articles or something to teach do web crawlers using haskell ?
14:19:43 <dmwit> system "wget -R" -- ?
14:19:55 <dmwit> ;-)
14:20:04 <byorgey> tromp_: actually, GHC optimizes  xs ++ []
14:20:22 <nullcone_> dmwit: why do you like using  "merge xs ys = xs ++ ys". instead of "merge [] ys = ys; merge xs [] = xs"  btw?
14:20:41 <elliott> byorgey: but does it optimise xs ++ ys where ys must be [] but it isn't explicitly revealed?
14:20:45 <dmwit> byorgey: I believe GHC optimizes a literal "xs ++ []", but I have a hard time believing GHC optimizes "xs ++ ys" when "ys" happens to be "[]" at runtime.
14:20:57 <byorgey> oh. right =)
14:20:59 <dmwit> nullcone_: because it's pretty =)
14:21:09 <elliott> perhaps (bigger xs ys) would be better
14:21:10 <sclv_> dmwit: if it inlines (++) then shouldn't it work out?
14:21:12 <elliott> with the obvious definition of bigger
14:21:12 <alpounet> dmwit, but ++ has a clause for []
14:21:15 <tromp_> it could, but would require some extra GHC smarts
14:21:17 <elliott> alpounet: only on the left
14:21:22 <alpounet> oh right
14:21:31 <elliott> I mean, maybe if it inlines and merges the cases.
14:21:37 <elliott> I wouldn't rely on it.
14:21:59 <dmwit> sclv_, alpounet: Forcing ys in xs ++ ys before evaluating xs ++ ys is not a semantics-preserving change.
14:22:20 <elliott> aye, but if you already force ys with an earlier case...
14:22:26 <dmwit> And I don't know of any GHC optimizations that use unamb or anything like that. =P
14:22:50 <dmwit> Yes, Sufficiently Smart Compilers and all that. I'm not expert enough to say.
14:23:04 <dmwit> But I'd be very (pleasantly) surprised if you ended up paying nothing here.
14:23:22 <alpounet> well yeah most likely GHC doesn't perform that optimization
14:23:26 <elliott> well, you end up paying a little bit of clarity at the least, methinks :P
14:23:48 <Philippa_> dmwit: I can see tagging getting you the case/ctor version of "just use xs" for "xs ++ []" at runtime sometimes
14:23:51 <elliott> the solution is to get "bigger" into the stdlib and use that.
14:25:30 <sclv_> dmwit: good point. but i'm not sure if forcing ys makes that code "better" anyway?
14:26:18 <sclv_> oh i guess it does cost the thunk indirection
14:26:22 <sclv_> plus the traversal of xs
14:26:27 <sclv_> blah
14:26:47 <nullcone_> Is there a haskell beginners channel?
14:27:16 <kryft> nullcone_: I think this serves that function too :)
14:27:28 <dmj> there's a beginner's mailing list
14:27:29 <sclv_> yeah, this channel is very beginner-friendly
14:27:40 <elliott> well, sometimes we eat one.
14:27:50 <sclv_> if a conversation spills over way too much, there's #haskell-overflow iirc
14:27:53 <kryft> elliott: Yes, I didn't consider survivor bias
14:27:57 <sclv_> for ppl splitting off and doing a deep dive
14:28:09 <dmwit> Okay, I looked at the core for -O2.
14:28:13 <dmwit> It optimizes this in the way we all want.
14:28:14 <dmwit> amazing
14:28:25 <byorgey> =O
14:29:00 <alpounet> dmwit, hah, seen the same here, was doing it too
14:29:08 <dmwit> merge = \ds_dyn ds_dyo -> case ds_dyn of wild_X7 { [] -> ds_dyo; : xJ xK -> case ds_dyo of _ { [] -> wild_X7; : yL yM -> ... } }
14:29:16 <nullcone_> kryft: Oh okay... I thought maybe you guys get tired of helping nublets like me
14:29:20 <dmwit> after removing as much unimportant details as I could
14:29:28 <kryft> nullcone_: I'm a nublet too!
14:29:50 <Philippa_> nullcone_: eh, when one of us does we just let someone else do it. You noticed how many people are in here, right?
14:29:51 <elliott> dmwit: hmph. stupid GHC, being smarter than me.
14:29:51 <kryft> nullcone_: (One of those that wasn't eaten yet)
14:30:03 <elliott> nullcone_: that's when the eating happens. but don't worry, that's very unlikely to happen.
14:30:05 * dmwit sticks his tongue out at tromp_
14:30:36 <sclv_> nullcone_: you'll note that we took your question and started going all over with it
14:30:54 <sclv_> that's generally how it works -- you get your answer, then you get... stuff
14:30:56 <tromp_> happy to be proved wrong in this way:-)
14:31:03 <sclv_> dmwit: that's pretty awesome. you should post a note to -cafe!
14:31:22 <alpounet> ghc++
14:31:28 <sclv_> strictness analyzer ftw
14:31:40 <dmwit> yeah, this is a pretty amazing result
14:31:58 <dmwit> "Just write whatever the heck code you want and GHC will do Magic."
14:32:52 <Erreth> hey guys, got a quick question
14:33:08 <Erreth> I'm just starting to learn haskell, off the learn you a haskell site
14:33:37 <Erreth> learning all about list comprehensions and all that
14:33:38 <dmwit> I'm not really into -cafe, though.
14:33:38 <jonkri> anyone knows why haskell-src-exts can not be built on debian wheezy? i just get an ExitFailure 11 error
14:33:54 <Erreth> I'm getting an error on this comprehension: [a ++ b | a <- ['a'..'z'], b <- ['a'..'z']]
14:34:03 <Erreth> can someone tell me why? I don't understand the message
14:34:08 <dmwit> jonkri: Perhaps you are out of memory, or disk space, or permissions in the build directory are wonky, or permissions in the install directory are wonky, or...
14:34:11 <Erreth> something about types not being correct
14:34:15 <acowley> What type does a have?
14:34:22 <dmwit> jonkri: Maybe --verbose will tell you more details. =)
14:34:24 <Franciman> If I have a list of Maybes how can I let a fold stop when the current element is a Nothing?
14:34:34 <Franciman> *foldr
14:34:35 <Erreth> I'm trying to get all combinations of letters
14:34:45 <dmwit> Franciman: takeWhile isJust ?
14:34:54 <Erreth> the error is :Couldn't match expected type `[a0]' with actual type `Char'"
14:34:57 <acowley> Erreth: Right, but what type do a and b have?
14:34:59 <Philippa_> dmwit: I think spotting what's one of the most obvious pieces of induction going shouldn't be that amazing for a strictness analyser, but hey :p
14:35:01 <jonkri> thanks dmwit :)
14:35:05 <tromp_> Erreth: use [a,b], no a++b
14:35:11 <Franciman> dmwit oh thanks :D
14:35:11 <Erreth> those are just the variables, so they don't have types, right?
14:35:13 <carter> dcoutts : hey,  theres a number of things that may need to land in cabal soon for mac ghc usage to stay possible / sane I think, are you abreast of some of the issues?
14:35:20 <sclv_> jonkri: sounds like out of memory? possibly during linking?
14:35:22 <Erreth> those are the specific letters that are being iterated over in the list
14:35:30 <sclv_> ah i was beaten to it
14:35:38 <acowley> Erreth: Everything has a type!
14:35:42 <dmwit> Philippa_: Well, it threw the folks in this channel for a loop, and we're all pretty smart. =)
14:35:57 <Erreth> so [a,b] is how I would make those two letter combinations?
14:36:05 <monochrom> Erreth: variables have types. acowley is on the right track.
14:36:14 <Erreth> wow that did it perfectly
14:36:25 <Erreth> gotcha
14:36:31 <Franciman> dmwit, and what about having a list and willing to stop foldr when the accumulator becomes Nothing?
14:36:32 <acowley> Erreth: Can you decipher the error message you got now?
14:36:34 <Philippa_> dmwit: *nod*. It didn't occur to me to remember that there /is/ a strictness analyser, though :p
14:36:36 <tromp_> :t liftM2
14:36:37 <lambdabot> Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
14:36:46 <Erreth> I guess I was thinking a and b were lists of a single char, so I could use the ++
14:36:50 <tromp_> > liftM2 "abc" "123"
14:36:51 <lambdabot>   Couldn't match expected type `GHC.Types.Char -> a20 -> r0'
14:36:51 <lambdabot>              wit...
14:36:52 <Erreth> but they were just chars, right?
14:36:59 <Philippa_> I just realised afterwards why, given that we've got one, it's a fairly 'obvious' pattern
14:37:00 <S_J> did clojure ever hit it off?
14:37:08 <c_wraith> Well, the strictness analyzer is conservative, and misses a lot of cases.  It's easy to forget it's there.
14:37:08 <dmwit> Philippa_: right
14:37:22 <acowley> Erreth: Your use of ++ made the type checker think a and b must have types [a0], but the binding expressions (using the <-) forced them into being Chars.
14:37:33 <c_wraith> S_J: it's relatively successful, yes.  It's not languishing in obscurity
14:37:34 <Erreth> gotcha
14:37:41 <Erreth> that makes a lot more sense. Thanks acowley and all
14:37:46 <tromp_> :t sequence
14:37:46 <lambdabot> Monad m => [m a] -> m [a]
14:37:48 <dmwit> Franciman: I mean, the easiest thing is to use case analysis in the function you're folding.
14:38:00 <tromp_> > sequence ["abc", "123"]
14:38:01 <lambdabot>   ["a1","a2","a3","b1","b2","b3","c1","c2","c3"]
14:38:02 <Franciman> may you give me an example?
14:38:03 <dmwit> Franciman: But perhaps if you give a bit more of the big picture we can suggest an higher-level solution.
14:38:17 <Franciman> ok
14:38:33 <S_J> id rather have a very simple example of STM than a fancy one, anyone have anything to share?
14:39:20 <Franciman> dmwit, I want to rewrite the function using foldr
14:39:21 <Franciman> http://paste.tryhaskell.org/90663
14:39:22 <ciaranm> STM stands for too many things
14:39:26 <Franciman> ( or foldl )
14:39:32 <c_wraith> S_J: is the bank account example given everywhere insufficient?
14:39:40 <monochrom> what is "simple"? but I'd try: atomically (do { n <- readTVar v; writeTVar v (n-1) })
14:40:08 <monochrom> I guess that's a bank account example
14:40:34 <c_wraith> S_J: https://research.microsoft.com/pubs/74063/beautiful.pdf is a pretty core paper on the topic.
14:40:45 <c_wraith> and it starts with the bank account example
14:40:48 <monochrom> actually, make it a Federal Reserve example :)
14:40:53 <c_wraith> hah
14:41:29 <acowley> Federal Reserve doesn't need STM, they can make new resources.
14:41:53 <c_wraith> they still want an exact record of who owes them what
14:42:00 <jonkri> sclv, dmwit : i had 1.1gb disk space free, which apparantly was not enough :P
14:42:05 <Philippa_> acowley: I hear that makes them annoying relevant, yeah
14:42:29 <dmwit> Franciman: Looks like a foldM to me. One moment.
14:42:30 <Philippa_> *annoyingly
14:42:32 <dmwit> :t foldM
14:42:33 <lambdabot> Monad m => (a -> b -> m a) -> a -> [b] -> m a
14:43:06 <S_J> forkIO $ 25 `timesDo` (dispVar shared >> milliSleep 20) // where timesDo=replicateM, what does that do? creates a thread 25 times? or calls the function 25 times in one thread? must ba latter...?
14:44:24 <c_wraith> replicateM c = sequence . replicate c
14:44:32 <Franciman> dmwit ok thanks
14:44:37 <c_wraith> The name "sequence" is very evocative, there.
14:44:38 <Franciman> but how will it stop?
14:46:22 <monochrom> dmwit: because of the occurence of "length xs", this is unlikely to be easy as foldl, foldr, or foldM.
14:46:32 <hpaste> dmwit annotated “Foldr” with “Foldr (annotation)” at http://paste.tryhaskell.org/90663#a90664
14:46:48 <dmwit> monochrom: You may be right.
14:47:12 <dmwit> monochrom: I didn't test.
14:47:54 <dmwit> Franciman: It stops because (>>=) for Maybe stops.
14:48:01 <Franciman> Oh Great
14:48:04 <Franciman> thanks :)
14:48:06 <Franciman> a lot
14:48:22 <Franciman> monochrom what you mean?
14:48:28 <dmwit> Franciman: Also, you may like
14:48:30 <dmwit> :t genericLength
14:48:31 <lambdabot> Num i => [b] -> i
14:49:20 <Franciman> yes thanks
14:50:57 <startling> how do you use @check?
14:51:10 <dmwit> ?check \xs ys -> xs ++ ys == ys ++ xs
14:51:14 <lambdabot>   mueval-core: Time limit exceeded
14:51:20 <dmwit> ?check \xs ys -> xs ++ ys == ys ++ xs
14:51:21 <startling> that's what I was getting.
14:51:23 <lambdabot>   +++ OK, passed 100 tests.
14:51:24 <geekosaur> apparently not :p
14:52:01 <startling> dmwit, what's the difference?
14:52:11 <dmwit> Perhaps lambdabot has a too-low timeout, or perhaps mokus' changes don't incorporate whatever fix Cale did to old lambdabot.
14:52:19 <geekosaur> none, that was the bot timing out for unknown reasons
14:52:21 <startling> oh.
14:52:34 <geekosaur> (see threadDelay discussion earlier :)
14:52:38 <dmwit> startling: The RealWorld changed between one request and the other.
14:52:46 <startling> @check \a -> foldr (const (1 +)) 0 a == length a
14:52:49 <lambdabot>   +++ OK, passed 100 tests.
14:53:06 <startling> hrm
14:56:36 <elliott> dmwit: I tried to incorporate the mueval fix.
14:56:48 <elliott> dmwit: my solution is to rewrite the eval plugin to not spawn a new process for every request.
14:57:40 <dmwit> Does ?check go through the eval plugin?
15:03:32 <Rarrikins> Is there any evil way to convert if p then q else r to iif p q r?
15:04:01 <Hafydd> :t iif
15:04:02 <lambdabot> Not in scope: `iif'
15:04:13 <Rarrikins> iif being an arbitrary function
15:04:22 <Rarrikins> (or one I'll define)
15:04:46 <Hafydd> There's an extension that lets you overload the if then else syntax.
15:04:53 <ciaranm> @hoogle Bool -> a -> a -> a
15:04:53 <lambdabot> Data.Time.Calendar.MonthDay monthAndDayToDayOfYear :: Bool -> Int -> Int -> Int
15:04:53 <lambdabot> Graphics.Rendering.OpenGL.GL.Tensor Vertex3 :: a -> a -> a -> Vertex3 a
15:04:53 <lambdabot> Graphics.Rendering.OpenGL.GL.Tensor Vector3 :: a -> a -> a -> Vector3 a
15:05:37 <Hafydd> RebindableSyntax
15:06:01 <dmwit> Rarrikins: Are you asking whether it's possible to define a function that behaves like if/then/else or whether it's possible to change the behavior of the if/then/else syntax?
15:06:25 <Rarrikins> The latter.
15:06:37 <Demos> that extension probably just removes the if/than/else syntax then just defines a function to replace it
15:06:44 <Rarrikins> I want to be able to, for instance, take the symbolic GCD of an algebraic expression.
15:06:59 <dmwit> Okay, then listen to Hafydd.
15:07:23 <Rarrikins> Ahh, OK. Thanks for the name, Hafydd :)
15:07:26 <dmwit> Demos: No need to guess what the extension does; the GHC manual will tell you.
15:08:41 <Franciman> thanks alot again guys
15:08:42 <Franciman> bye
15:34:44 <S_J> i dont get the type: check :: Bool -> STM a // you pass a Bool and get an STM ?
15:36:30 <Botje_> an STM action that will yield a value of type a.
15:37:06 <acowley> When I look at the docs, check has type Bool -> STM ()
15:37:06 * glguy would have guessed a function with the name "check" and a type like that would have been: Bool -> STM ()
15:37:30 <Botje_> Bool -> STM () would make a ton more sense, yes
15:38:01 <alpounet> glguy, maybe for something like : check everyThingIsFine $ do …
15:38:10 <johnw> i don't think Bool -> STM a even has a real meaning, barring undefined and unsafeCoerce
15:38:15 <alpounet> err sorry, thought there was a STM parameter
15:38:26 <glguy> johnw: perhaps: const retry?
15:38:34 <johnw> :t retry
15:38:35 <lambdabot> Not in scope: `retry'
15:38:55 <glguy> retry :: STM a
15:39:01 <johnw> thanks
15:39:21 <johnw> ok, I guess that would work
15:41:40 <monochrom> @type putStrLn
15:41:41 <lambdabot> String -> IO ()
15:42:01 <monochrom> I pass a String and get an IO.
15:43:15 <elliott> monochrom: ah, you finally found out how to get the IO out of IO String.
15:43:30 <elliott> you take the String out and then pass it to putStrLn, giving you the IO!
15:43:32 <monochrom> I just learned from a beginner!
15:43:46 <acowley> We can basically shut down the #haskell tag on SO, now
15:47:02 <danharaj_> People still use SO?
15:47:09 <danharaj_> (this question has been closed for being off-topic)
15:47:12 <S_J> why does creating a (v <- STMTVar.newTVar 0) interfere with my C.forkIO (inc 5) where inc x = inc x ?
15:47:20 <monochrom> haha danharaj
15:47:44 <johnw> S_J: define interfere?
15:48:05 <monochrom> I don't understand the question. and not enough actual code.
15:48:38 <c_wraith> inc x = inc x looks a lot like an infinite loop
15:49:41 <elliott> SO is perfectly good at what it's good at.
15:49:50 <elliott> unfortunately people seem to refuse to be satisfied with that.
15:51:10 <sclv> there are some questions that get shut down out of stupidity
15:51:22 <e139> @run 0 :: Word8
15:51:23 <lambdabot>   0
15:51:27 <sclv> and others that get reopened for no good reason too :-)
15:51:43 <e139> @run shiftL 0x80 7
15:51:43 <lambdabot>   16384
15:51:48 <sclv> also been noticing more spam lately -- though it gets deleted effectively
15:51:57 <e139> @run shiftL 0x80 (-7)
15:51:57 <lambdabot>   1
15:52:05 <e139> @run shiftL 0x80 (-7) :: Word8
15:52:06 <lambdabot>   0
15:52:08 <e139> ?
15:52:27 <monochrom> it probably defaults to Integer if you don't specify a type
15:52:47 <elliott> sclv: yeah, I see quite a few hopeless questions get reopened and I'm like, omg what's with the voters! the whole world has gone downhill ever since I started paying attention!
15:52:48 <e139> Hmmm ... :-)
15:53:00 <sclv> and then i try to close them and am not allowed
15:53:03 <sclv> because i voted last time
15:53:05 <monochrom> @type shiftL
15:53:05 <lambdabot> Bits a => a -> Int -> a
15:53:19 <sclv> the worst is when legit type theory questions get closed because people are like "that's uh, math"
15:53:41 <e139> Well, I don't see why that should change the result
15:53:53 <acowley> I think SO is pretty great, actually
15:53:55 <e139> @run ( shiftL 0x80 (-7) ) :: Word8
15:53:55 <monochrom> right
15:53:55 <lambdabot>   0
15:54:08 <e139> @run ( shiftL 0x80 (-7) ) :: Int8
15:54:09 <lambdabot>   0
15:54:20 <elliott> sclv: yeah that does happen. questions that are a bit theory-ish can get some dumb comments from people who don't know anything about it too :p
15:54:29 <elliott> but I think the system works ok in the fairly narrow scope it has
15:54:47 <sclv> the new closure guidelines might help
15:54:54 <e139> @run ( shiftL 0x80 (-7) ) :: Int16
15:54:55 <lambdabot>   0
15:54:59 <e139> @run ( shiftL 0x80 (-7) ) :: Integer
15:54:59 <lambdabot>   1
15:55:03 <acowley> The hardest thing about the #haskell tag on SO when I checked in regularly was not getting scooped while writing an answer
15:55:03 <e139> @run ( shiftL 0x80 (-7) ) :: Int
15:55:04 <lambdabot>   0
15:55:31 <monochrom> e139: shiftL blah (negative number here) is meant to be unpredictable
15:56:06 <supki> > shiftL 0x80 (-1) :: Int16
15:56:07 <lambdabot>   0
15:56:07 <e139> monochrom: ahh, ok, so I'm going to avoid negative shifts
15:56:59 <e139> I expected that at least negative shifts on unsigned types would give the expected result
16:03:10 <acowley> Has anyone tried the FP Complete Center Haskell Web IDE Magic Thing yet?
16:03:46 <S_J> atomically $ readTVar x >>= writeTVar x . fn
16:03:51 <S_J> what is the prec3dence here?
16:04:33 <acowley> :i (>>=)
16:04:48 <monochrom> I think it's atomically $ (readTVar x >>= (writeTVar x . fn)). which means you don't need parentheses
16:04:50 <acowley> well, if we had a real GHCi here that would produce useful output
16:05:16 <c_wraith> $ has precedence 0
16:05:19 <acowley> ($) is 0, (>>=) is 1, (.) is 9
16:06:32 <dmwit> e139: Perhaps you want shift?
16:06:46 <dmwit> > shift 0x10 1 :: Word8
16:06:47 <lambdabot>   32
16:06:52 <dmwit> > shift 0x10 (-1) :: Word8
16:06:53 <lambdabot>   8
16:07:01 <alpounet> acowley, yeah
16:07:04 <Pip> Do I have to learn Java before Haskell?
16:07:07 <alpounet> (re. the IDE)
16:07:10 <dmwit> Pip: nope
16:07:11 <geekosaur> o.O
16:07:22 <tac> Pip: It's probably better if you never learn Java ever, actually :)
16:07:25 <c_wraith> geekosaur: knowledge is linear. :)
16:07:28 <acowley> alpounet: Any early impressions on how it works out for non-web programming?
16:07:33 <Pip> tac, Too bad, I know some Java
16:08:13 <dmwit> Neither of the following is true: you must know Java to learn Haskell; you must not know Java to learn Haskell.
16:08:52 <alpounet> acowley, i'm still not that comfortable with an IDE in the browser, just a few annoying details. also, I reported a bug about completion not working for locally (i.e in the same module) defined symbols
16:09:06 <alpounet> aside from that
16:09:32 <acowley> alpounet: I don't really understand how I could possibly use it. What do you do if you need some data files?
16:10:05 <acowley> alpounet: It looks really snazzy in the video, but I'm not sure if I'm supposed to be interested or if it's not aimed at me
16:10:28 <alpounet> go to definition, information (types + doc when available) and completion work well and do their jobs, it's nice to use
16:10:50 <alpounet> the UI is quite nice too, despite the fact that it is in a browser
16:10:59 <alpounet> acowley, you can upload files, they just get added to your project
16:11:39 <alpounet> (i accidentally opened a file dialog while in the IDE and found out about file upload because I was trying to figure out why that happened)
16:11:44 * hackagebot shelly 1.3.0.3 - shell-like (systems) programming in Haskell  http://hackage.haskell.org/package/shelly-1.3.0.3 (GregWeber)
16:13:44 <Pip> Is Haskell state of the art programming language ever built?
16:14:31 <josephle> "state of the art" is a vague qualifier
16:14:53 <dmwit> You can find a discussion of some of the tradeoffs involved in choosing Haskell in http://book.realworldhaskell.org/read/why-functional-programming-why-haskell.html
16:15:56 <dmwit> ...mostly pros. I don't know of a really good resource that discusses both pros and cons in an objective way.
16:16:31 <banister> dmwit: one thing i noticed is that haskell is ranked higher than both scala and clojure on 2013 tiobe
16:16:38 <Pip> How to make ghci colorful?
16:16:41 <banister> but is haskell actually used in industry to the same extent as those languages?
16:16:50 <danharaj> it is used.
16:17:07 <dmwit> Pip: Have you tried googling "ghci color"?
16:17:09 <josephle> just like every other programming language, Haskell gets more cons the more you program with it
16:17:09 <dmwit> If not, do.
16:17:17 <Pip> dmwit, not yet
16:18:00 <josephle> but such is the way of programmers, always demanding more out of their languages
16:27:23 <acowley> Why does idris depend on language-java?
16:27:52 <thoughtpolice> because it uses the pretty printer for the java backend, i presume
16:28:12 <acowley> Oh, I didn't know there was a Java backend!
16:29:33 <acowley> There's a Java flag, but it's not considered in build-depends
16:30:02 <thoughtpolice> acowley: i think it's used by Setup.hs
16:30:07 <thoughtpolice> because Idris has a weird build system and stuff
16:30:26 <thoughtpolice> (it compiles the RTS after building all the haskell object files)
16:33:10 <AlainODea> This is likely a silly question. Is it possible to Cross Compile an unregisterised GHC from x86-64 Linux (Ubuntu in my case) to x86-64 Solaris (SmartOS in my case)
16:40:52 <Cale> AlainODea: I suspect that it's possible, but quite likely to be a bit of an ordeal.
16:42:09 <AlainODea> Cale: I was afraid that might be the answer. I know Christian Maeder managed to get 7.0.3 working on i386, but I'm not sure I can follow that.
16:44:06 <Cale> If his binary will run, you could likely use it to build a newer GHC
16:45:06 <Cale> http://www.haskell.org/ghc/dist/7.0.3/maeder/ghc-7.0.3-i386-unknown-solaris2.tar.bz2
16:45:28 <AlainODea> Cale: I'll give that a try now. Thank you for your help :)
16:48:27 <AlainODea> I get this error when I ./configure "checking for path to top of build tree... ghc-pwd: mkTextEncoding: invalid argument (Invalid argument)".  Christian suggest altering C_INCLUDE_PATH, but I still get that error after applying his suggestion. What might cause this?
16:52:12 <Cale> What's LANG set to?
16:53:28 <AlainODea> en_CA.UTF-8
16:54:48 <Cale> hmm, well, the problem looks similar to this ticket
16:54:49 <Cale> http://hackage.haskell.org/trac/ghc/ticket/5190
16:55:45 <Cale> The iconv on my system is  iconv (Ubuntu EGLIBC 2.13-0ubuntu13.2) 2.13
16:56:14 <Pip> Where do you guys program in haskell on?
16:56:44 <Cale> Pip: The prepositions in that sentence are confusing.
16:56:44 <AlainODea> Cale: iconv (GNU libiconv 1.14) on my SmartOS host
16:57:02 <Pip> Cale, Which IDE or editor or ...
16:57:20 <Cale> Pip: I mostly use vim to edit text
16:57:46 <Cale> Pip: but anything which'll convert tabs to spaces and maybe does a little syntax highlighting will do, as far as I'm concerned
16:57:51 <Fuuzetsu> that question reminds me of http://www.youtube.com/watch?v=G7RgN9ijwE4 ;)
16:57:53 <Philippa_> jedit here, but really in a pinch anything that'll let you hand it regexen to do syntax highlighting suffices
16:58:00 <Cale> Lots of people also use emacs
16:58:01 <AlainODea> Pip: I program in Haskell in Sublime Text on Linux, but I'm a hobbyist at this point. Vim is pretty great for Haskell as well
16:58:06 <Philippa_> helps if you can customise indent levels and dedent automatically because layout, I guess
16:58:44 <Cale> Keep your editor window open alongside ghci, and type :r in ghci whenever you save your file
16:58:46 <Pip> Fuuzetsu, LOL
16:58:57 <achudnov> Pip: Emacs with haskell-mode and ghc-mod
17:00:09 <elliott> Philippa_: wow, I had no idea people actually used jedit.
17:01:09 <achudnov> Does anybody know how to specify which modules to load by default when I start a ghci session via cabal-dev? Note, it does have to work with cabal-dev. Putting an ':m + Module1 Module2" doesn't work for me :(
17:01:21 <Philippa_> elliott: if you do significant amounts of work on both windows and linux, it's got its uses
17:01:54 <adnap> Hey
17:02:09 <achudnov> Clarification: "Putting an ":m + Module1 Module2" in a .ghci file doesn't work for me"
17:02:09 <adnap> @type (`runState` 0) . traverse (\val -> do { counter<-get ; modify (+1) ; return (counter, val) })
17:02:10 <lambdabot> (Num s, Traversable t) => t t1 -> (t (s, t1), s)
17:02:12 <Cale> achudnov: make a .ghci in the project directory with some commands in it?
17:02:15 <Cale> oh
17:02:16 <Cale> hmm
17:02:18 <adnap> I need help understanding this
17:02:21 <Cale> I wonder why that wouldn't work
17:02:32 <adnap> :t traverse
17:02:45 <adnap> @type Data.Traversable.traverse
17:02:46 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
17:03:43 * tabemann forgets - how do you get GHC to dump Core when compiling something?
17:03:50 <Cale> -ddump-simpl
17:03:54 <tabemann> thanks
17:04:16 <Cale> > (`runState` 0) . traverse (\val -> do { counter<-get ; modify (+1) ; return (counter, val) }) $ "hello"
17:04:17 <lambdabot>   ([(0,'h'),(1,'e'),(2,'l'),(3,'l'),(4,'o')],5)
17:04:19 <achudnov> Cale: here's what ghci tells me when I try to load it via cabal-dev when I have a .ghci file with the above command. "<no location info>: Could not find module Module1. It's a member of a hidden package 'Package1'. Perhaps you need to add 'Package1' into your build depends".
17:04:49 <achudnov> Note, 'Package1' is the packages I'm running cabal-dev ghci on.
17:04:59 <Cale> hmm
17:05:14 <tabemann> okay, that answers what I'm looking for, but I want a different answer...
17:05:35 * tabemann was hoping GHC was optimize away a bunch of conversions between Int and Int# in his code...
17:06:07 <achudnov> Cale: as expected, if I follow ghci's "helpful" suggestion and add 'Package1' into build-depends of itself, cabal-dev righfully complains of a loop in the dependency graph.
17:06:49 <Cale> What if you :set -package Package1  at the top of your .ghci?
17:07:21 <adnap> Whoa
17:07:39 <adnap> It seems like the State persists through each call of the function (\val -> ...)
17:07:56 <Cale> adnap: Yes, you're just running a single State computation after all.
17:08:51 <Cale> In the type of traverse, f is being specialised to something like State Integer, and I picked t = []
17:08:57 <Cale> bbiab, dinner
17:09:01 <adnap> Cale: I don't quite understand though
17:09:17 <adnap> traverse takes (a -> f b) and calles this on every a in t a
17:09:21 <adnap> *calls
17:09:36 <adnap> But the State in the (a -> f b) seems to persist
17:09:44 <adnap> Because the counter keeps going up
17:09:52 <S_J> would stm be suited for embedded systems?
17:09:56 <achudnov> Cole: yes, that helps. Then I have another error. Attempting to use module 'Module3' (path) which is not loaded. Note I have Module3 in exposed modules in .cabal file as well in the ":m + " line in .ghci.
17:10:11 <achudnov> s/Cole/Cale
17:11:50 <tabemann> little question - if you have an expression of the form:
17:12:02 <tabemann> let (x, y) = (x', y') in foo x y
17:12:10 <tabemann> will GHC optimize away allocating the tuple?
17:12:31 <Eduard_Munteanu> tabemann: not necessarily
17:12:50 <c_wraith> check the core.
17:12:55 <achudnov> Cole: figured it out. I needed to issue a separate :load command for those modules as well. Silly ghci :(
17:13:01 <erisco> a bit perplexing... [[1,2], [6,3], [3,7,3]] -> [1,6,3,2,3,7,3]   some sort of 2D recursion is needed, it seems, if that makes sense
17:13:04 <achudnov> Cole: thanks
17:13:24 <achudnov> Cale++
17:13:25 <adnap> c_wraith: When I see your name, I always think of those things from LOTR
17:13:39 <adnap> Scary...
17:13:42 <c_wraith> those are ring wraiths.  I'm not that harmful.
17:13:45 <erisco> I can get the first element from each list, spit that out, then remove the first element and repeat
17:13:56 <erisco> but that is inefficient
17:13:56 <tabemann> I've got a version of the code right now that avoids doing that by basically calling a number of functions in sequence, which I've inlined most of away, but I should write a version that uses let (x, y) = if ... then ... else ... in foo xy etc. instead
17:14:03 <tabemann> and see what Core outputs
17:14:36 <erisco> especially since I have to keep reconstructing the outer list that way
17:14:58 <adnap> So, is get for State just a way to set the result of the State to the first state?
17:15:04 <tabemann> (the inlining results in two big functions in Core - one for the outer code and one for the inner loop that it can't inline away)
17:15:04 <Fuuzetsu> erisco: What is your function even supposed to do?
17:15:10 <adnap> I don't get why it's called "get"
17:15:51 <c_wraith> I think you're thinking of set
17:15:54 <c_wraith> :t get
17:15:55 <lambdabot> MonadState s m => m s
17:15:57 <c_wraith> :t set
17:15:57 <lambdabot> ASetter s t a b -> b -> s -> t
17:15:59 <erisco> Fuuzetsu, sorry maybe it wasn't clear. [[1,2], [3, 4], [5,6,7]] -> [1,3,5,2,4,6,7]
17:16:08 <c_wraith> heh.  conflicts!
17:16:31 <adnap> Er...
17:16:42 <c_wraith> erisco: concat . transpose   ?
17:16:43 <adnap> I forget because I use "do" with IO so much but...
17:16:52 <erisco> >:t concat. transpose
17:16:53 <adnap> Is "do" syntactic sugar for (>>)?
17:17:06 <geekosaur> > join . transpose $ [[1,2], [3, 4], [5,6,7]]
17:17:06 <erisco> lambdabot, where are you? :(
17:17:07 <lambdabot>   [1,3,5,2,4,6,7]
17:17:21 <Eduard_Munteanu> :q
17:17:23 <geekosaur> erisco: no preceding > on that
17:17:27 <Eduard_Munteanu> Argh.
17:17:45 <erisco> oh cool. so transpose rotates it like a matrix I presume
17:17:59 <Fuuzetsu> adnap: No. do is sugar for >>= AND >>
17:17:59 <geekosaur> yes
17:18:00 <c_wraith> adnap: do is syntactic sugar that can insert >> or >>=, depending on how you're using it
17:18:11 <erisco> or a rotate and flip.. whichever it is
17:18:16 <Rarrikins> Is there a way to turn on an extension in GHCi?
17:18:24 <c_wraith> transpose is actually a mirror across the diagonal, not a rotate
17:18:49 <tabemann> Rarrikins: {-# LANGUAGE ExtensionName #-} at the top of your source fine
17:18:52 <adnap> Also, "do" seems like it can carry along a value through multiple monadic expressions
17:18:52 <tabemann> oh GHCi
17:18:58 <erisco> yeah, a "flip" ... between rotating and flipping I think they are 8 unique possibilities IIRC
17:18:59 <tabemann> ghci -XExtensionName
17:19:06 <prophile> adnap: do { x } => x, do { a <- x; b } => x >>= (\a -> b); do { a; b } => a >> b
17:19:15 <geekosaur> > transpose [[1,2], [3, 4], [5,6,7]]
17:19:16 <lambdabot>   [[1,3,5],[2,4,6],[7]]
17:19:53 <geekosaur> (and join for lists is concat)
17:20:03 <erisco> transpose still seems nonintuitive
17:20:14 <adnap> > do { x <- return "hello"; return (); return (); putStrLn x }
17:20:15 <lambdabot>   <IO ()>
17:20:15 <Cale> erisco: a flip across the diagonal
17:20:16 <erisco> I mean, how you'd implement it
17:20:26 <geekosaur> @src transpose
17:20:26 <lambdabot> transpose []             = []
17:20:26 <lambdabot> transpose ([]   : xss)   = transpose xss
17:20:26 <lambdabot> transpose ((x:xs) : xss) = (x : [h | (h:t) <- xss]) : transpose (xs : [ t | (h:t) <- xss])
17:20:43 <adnap> So, the x gets carried along...
17:20:58 <prophile> adnap: yes
17:21:02 <adnap> How is that happening?
17:21:06 <Cale> adnap: Well, it's still in scope
17:21:13 <Cale> @undo do { x <- return "hello"; return (); return (); putStrLn x }
17:21:13 <lambdabot> return "hello" >>= \ x -> return () >> return () >> putStrLn x
17:21:16 <adnap> How could I translate that into something with (>>=)?
17:21:18 <Rarrikins> tabemann: Thanks :). I found out that that means you can do :set -cmdlinearg in combination with that from within a running GHCi.
17:21:20 <Cale> ^^
17:21:28 <adnap> Ha-ha
17:21:29 <adnap> undo...
17:21:33 <prophile> so do { x <- a; b } is more like a >>= (\x -> do {b})
17:21:39 <adnap> I didn't know...
17:21:43 <prophile> the entire rest of the do block (b) is now defined with x in scope
17:21:45 <dav> @t transpose
17:21:45 <lambdabot> Maybe you meant: tell thank you thanks thesaurus thx tic-tac-toe ticker time todo todo-add todo-delete type v @ ? .
17:21:45 <Cale> prophile: it's exactly like that
17:21:47 <adnap> That x is still in scope when you do
17:21:57 <adnap> \x -> return () >> ...
17:22:04 <Cale> do { v <- x; ... } = x >>= \v -> do { ... }
17:22:13 <dav> :t transpose
17:22:14 <Cale> do { x ; ... } = x >> do { ... }
17:22:14 <lambdabot> [[a]] -> [[a]]
17:22:18 <erisco> wow yeah, nonintuitive indeed
17:22:28 <Cale> do { let { ... } ; ... } = let { ... } in do { ... }
17:22:36 <Cale> do { x } = x
17:23:35 <c_wraith> erisco: well, you need to be really comfortable parsing haskell, but what's going on isn't actually very hard.
17:23:38 <achudnov> adnap: >> is itself a sugar over >>=
17:23:44 <Cale> do { pat <- x ; ... } = let { ok pat = do { ... }; ok _ = fail "error message" } in x >>= ok   -- when pat is a failable pattern
17:24:14 <Rarrikins> Why is Nat not kind *?
17:24:17 <adnap> Wha-...
17:24:18 <erisco> c_wraith, I suppose on second look it is doing what I thought of originally
17:24:20 <dav> erisco: actually it's quite intuitive..
17:24:27 <Cale> adnap: Feel free to ignore that last one
17:24:34 <erisco> c_wraith, which is grabbing the first element and then reconstructing the list
17:24:38 <c_wraith> yep
17:24:47 <Cale> adnap: It's just used when you match against some pattern like Just v on the left of <-
17:24:57 <erisco> it isn't the type of thing I was looking for but
17:24:57 <Cale> adnap: (a pattern which might fail to match)
17:25:22 <erisco> I guess this is where you just pray GHC can do something smart
17:25:33 <c_wraith> actually, it really can't do anything smart
17:25:39 <adnap> return "hello" >>= (\x -> return () >> return ())
17:25:51 <c_wraith> it's working with immutable singly-linked lists.  It really does need to reconstruct the whole thing
17:25:54 <erisco> then that seems kinda crappy... O(mn) memory
17:25:59 <adnap> So, every monad expression in (a -> m a) has a in scope
17:26:04 <adnap> Er
17:26:09 <adnap> (a -> m b)
17:26:13 <Cale> erisco: You can't really hope for it to be any less.
17:26:33 <c_wraith> erisco: Well, yes.  That's the size of the output.
17:26:44 <adnap> Hm...
17:26:48 <Cale> erisco: All the output lists in general will have no tail in common with any of the input lists.
17:26:49 <adnap> Is this true for function composition too?
17:26:57 <adnap> f . g . h
17:27:01 <Cale> erisco: and there are the same number of elements in the output as the input
17:27:05 <adnap> If h puts something in scop
17:27:10 <adnap> *scope
17:27:19 <adnap> Can g or f access it?
17:27:39 <c_wraith> adnap: no, functions can't *alter* a scope
17:27:50 <Cale> adnap: The scoping rules when you're using a monad are no different from the scoping rules in any other case.
17:27:50 <acowley> Only lambda and the module top-level can put things in scope.
17:27:57 <adnap> I just don't get it
17:28:12 <achudnov> adnap: did you mean, can f or g access h's parameter?
17:28:17 <adnap> return "hello" >>= \ x -> return () >> return () >> putStrLn x
17:28:18 <adnap> Here...
17:28:22 <adnap> putStrLn can access x
17:28:26 <tabemann> okay - my code that puts much of my code in one function that uses tuples is much shorter than my heavily inlined code that uses function-calling a lot, but no, the tuples are not optimized away at all - I'll have to remember this
17:28:29 <Cale> return "hello" >>= (\ x -> return () >> return () >> putStrLn x)
17:28:31 <achudnov> yes
17:28:32 <Cale> does that help?
17:28:36 <adnap> Yes
17:28:41 <adnap> That is what I was thinking
17:28:50 <Cale> Remember that lambdas will extend as far to the right as possible.
17:28:51 <adnap> Hm...
17:28:57 <Cale> (has nothing to do with monads)
17:29:02 <achudnov> but it's not function composition you are using
17:29:13 <erisco> ah, I suppose that's right. I was thinking of the copying of the rows, but that is still only done n times, so... just a coeff
17:29:21 <adnap> let f = \x g -> g x in f 2 (+2)
17:29:23 <achudnov> the whole 'return () >> return () >> putStrLn x' is in scope of '\x ->'
17:29:37 <adnap> Er....
17:29:57 <adnap> I guess there's no connection to function composition
17:30:01 <erisco> and you can't argue intuitiveness from a position of already knowing the answer ;)
17:30:02 <Cale> erisco: The elements of the lists themselves will be shared of course
17:30:04 * tabemann forgets - what is the name of that module for timing your functions with?
17:30:17 <c_wraith> tabemann: if you mean package, criterion
17:30:22 <tabemann> yeah
17:30:29 <achudnov> Adnap you can use '>=>' for doing something like function composition in monadic code
17:30:30 <dav> erisco: there's no copying, and the transpose will only be built on a needed basis..
17:30:30 <acowley> Isn't intuitive another way of saying that you already know the answer?
17:30:41 <Cale> acowley: It's a bit stronger than that...
17:30:44 <adnap> @type (>=>)
17:30:45 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
17:30:52 * tabemann is going to see whether his inlined, function-calling code or his non-inlined, tuple-making code is faster
17:30:53 <adnap> Hah
17:30:57 <erisco> Cale, dav, I mean the construction of the first level of the list. This is being redone each step. That is the "copying" I am referring to
17:31:46 * hackagebot haskades 0.2.0 - Utility to generate bindings for BlackBerry Cascades  http://hackage.haskell.org/package/haskades-0.2.0 (StephenWeber)
17:31:54 <achudnov> adnap: so if f :: (a -> m b) and g :: (b -> m c) you can write f >=> g to get a composition which is like an ordinary function composition
17:32:03 <adnap> > (\x -> (\y -> x) x) 2
17:32:04 <lambdabot>   2
17:32:35 <Cale> Or g <=< f which is even more like an ordinary function composition.
17:32:46 <dav> erisco: you mean the (h:t) <- xss is done twice?
17:32:49 <adnap> > (\x -> (\y -> 2 + x) 3) 2
17:32:50 <lambdabot>   4
17:32:51 <achudnov> um, yeah, Cale's right :()
17:32:58 <adnap> Oh, hey
17:32:58 <Cale> (and which works really nicely mixed with do-notation too :)
17:33:51 <adnap> (\x -> 2 + z) . (\z -> 3) $ 5
17:33:57 <adnap> > (\x -> 2 + z) . (\z -> 3) $ 5
17:33:57 <erisco> dav, no, I mean (xs : [ t | (h:t) <- xss]) is building a new list to recurse on
17:33:58 <lambdabot>   2 + z
17:35:00 <adnap> Okay
17:35:08 <adnap> So.. chaining monads is more like nesting functions
17:35:09 <adnap> not composing them
17:35:15 <Cale> You don't chain monads
17:35:18 <Cale> Monads aren't values
17:35:19 <adnap> (>>)
17:35:23 <Cale> They're type constructors :)
17:35:30 <adnap> monad *expressions*
17:35:36 <Cale> yeah, or actions
17:35:47 <achudnov> Monads are instances of typeclasses, no?
17:35:57 <achudnov> *very specific typeclasses*
17:35:59 <adnap> Monad is a typeclass
17:36:05 <S_J> :t (>=>)
17:36:05 <Cale> achudnov: They're instances of a specific typeclass
17:36:06 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
17:36:08 <adnap> and State is a monad
17:36:11 <S_J> :t (<=<)
17:36:12 <lambdabot> Monad m => (b -> m c) -> (a -> m b) -> a -> m c
17:36:18 <adnap> so, monads are instances of typeclass Monad
17:36:21 <Cale> Or State s is for any s, if you want to be really picky
17:36:22 <shachaf> Metafont is another example of a type constructor.
17:36:29 <Cale> lol
17:36:34 <adnap> Anyway
17:36:37 <adnap> I'm getting waay distracted
17:36:48 <adnap> I keep pushing more things on my brain stack
17:36:53 <adnap> lol
17:36:57 <S_J> can you give an example of jusage of (>=>)?
17:37:04 <adnap> I want to get back to lens at the bottom!
17:37:10 <erisco> oh shite... transpose isn't going to work well on an infinite list =\
17:37:19 <erisco> I had better rethink this
17:37:29 <roconnor> @src (<=<)
17:37:29 <lambdabot> Source not found. Whoa.
17:37:36 <roconnor> @src (>=>)
17:37:36 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
17:37:45 <S_J> > (>=>) (\x->Just (x+1)) (\x -> Right (x+1))
17:37:46 <lambdabot>   Couldn't match type `Data.Either.Either a0' with `Data.Maybe.Maybe'
17:37:46 <lambdabot>  Expect...
17:37:47 <achudnov> S_J: I'm writing code with >=> right now
17:37:59 <S_J> > (>=>) (\x->Just (x+1)) (\x -> Right (x+1)) 5
17:37:59 <lambdabot>   Couldn't match type `Data.Either.Either a0' with `Data.Maybe.Maybe'
17:38:00 <lambdabot>  Expect...
17:38:07 <S_J> > (>=>) (\x->Just (x+1)) (\x -> Just (x+1)) 5
17:38:08 <lambdabot>   Just 7
17:38:14 <Cale> S_J: putStrLn <=< readFile $ "filename"
17:38:21 <S_J> > (>=>) (\x->Just (x+1)) (\x -> Just (x-11)) 5
17:38:22 <lambdabot>   Just (-5)
17:38:56 <S_J> would STM be suited for embedded systems?
17:39:31 <erisco> well, actually, if it doesn't need to know all of row one in order to give me row 2, that isn't a concern
17:40:02 <erisco> but I'm not sure if lazy evaluation is going to grant that =\ the list comprehension is lazy yes?
17:40:06 <roconnor> @type \f g -> join . map g . f
17:40:06 <lambdabot> (a -> [a2]) -> (a2 -> [a1]) -> a -> [a1]
17:40:21 <roconnor> @type \f g -> join . mapM g . f
17:40:21 <lambdabot> (a -> [a2]) -> (a2 -> [a1]) -> a -> [a1]
17:40:24 <adnap> So, does "modify" from State throw away the result of the State?
17:40:28 <roconnor> @type \f g -> join . liftM g . f
17:40:29 <lambdabot> Monad m => (a -> m a2) -> (a2 -> m a1) -> a -> m a1
17:40:36 <adnap> I wrote
17:40:38 <adnap> > (a2 -> m a1) -> a -> m a1
17:40:40 <lambdabot>   <hint>:1:14: parse error on input `->'
17:40:41 <adnap> oops
17:40:45 <erisco> >take 10  [x | x <- [1..]]
17:40:50 <adnap> modify f = State $ \s -> ((), f s)
17:41:01 <erisco> > take 10  [x | x <- [1..]]
17:41:01 <lambdabot>   [1,2,3,4,5,6,7,8,9,10]
17:41:09 <erisco> guess it should be fine :)
17:41:21 <S_J> Could STM be implemented on top of any OS scheduler/threading system?
17:42:22 <adnap> @undo do { counter<-get ; modify (+1) ; return (counter, val) }
17:42:22 <lambdabot> get >>= \ counter -> modify (+ 1) >> return (counter, val)
17:43:12 <Rarrikins> S_J: Sure. If all else fails, you can just force everything to work sequentially with a custom scheduler that fakes multithreading.
17:45:02 <Cale> After all, concurrency is useful even without paralellism.
17:45:21 <Cale> parallelism*
17:45:49 <erisco> I find these terms to be quite arbitrary. How does one keep them straight?
17:46:01 <external-reality> erisco: lol
17:46:33 * erisco wasn't aware that he made a funny... be he'll take it.
17:46:43 <tac> erisco: The nice thing is everyone uses the terms slightly differently, so everyone has to explain what they mean before they use it.
17:46:50 <external-reality> erisco: That was a Through the Looking Glass style statement.
17:48:43 <Cale> erisco: Concurrency is about working on more than one task at once, so that long running tasks don't hold up a system. It's important in things like servers and GUIs, in order that systems remain responsive.
17:49:05 <Cale> erisco: Parallelism is about taking advantage of multiple processors in order to run faster
17:49:24 <Cale> A concurrent program needn't complete any more quickly than if it had done all its tasks in sequence.
17:49:43 <erisco> external-reality, I suppose I have never read it, but good to know :)
17:49:54 <Rarrikins> Are there any symbolic Word32 or similar types (with boolean algebra bits)?
17:50:10 <Jello_Raptor> point of note on the above, concurrency is very useful on even single core processors
17:50:14 <Cale> Yes
17:50:18 <Jello_Raptor> also, can haskell compile to ARM?
17:50:28 <Cale> Jello_Raptor: Yes.
17:50:40 <erisco> Cale, well, you say "work on more than one task at once", key phrase being "at once", and it seems to conflate with the idea of parallel, you see
17:50:43 <Cale> (GHC can)
17:50:54 <Cale> erisco: Well, you might switch between them
17:51:05 <external-reality> Cale: Actually concurrency is just an abstraction that allows one to model things as if they where happening asynchronously. Whether they are or not is of no consequence.
17:51:16 <Jello_Raptor> so is there any good model for embedded haskell (e.g. embedded haskell on microcontrollers, without linux)
17:52:02 <Jello_Raptor> external-reality: though usually it is expected that the tasks are interleaved, so that while atomically only one thing is happening at as time, when you zoom out it looks like multiples are happening at one.
17:52:04 <Cale> One analogy I've occasionally used is that of a fast-food restaurant. Concurrency is about having multiple queues, so that more than one customer's order can be processed at the same time. Parallelism is about having more than one worker behind the counter.
17:53:04 <erisco> How cute :D I'm sold
17:53:23 <mapreduce> fork-join is a rabble instead of a queue
17:54:40 <S_J> how does STM go with communication?
17:55:47 <tabemann> that was informative - apparently doing floor . sqrt . fromInteger is *significantly* faster than a heavily inlined, non-tuple-using pure integer sqrt base on newton's method - which in turn is far faster than such an integer sqrt but using tuples
17:56:16 <external-reality> Cale: I'm not sure that is very accurate. Concurrency is about having more than one worker!
17:56:30 * tabemann should use criterion more
17:56:37 <erisco> hm, I betcha sqrt is optimized down specially, or is outsourced to C
17:56:47 <tabemann> erisco: my thought too
17:56:59 <S_J> external-reality: concurrency is about the worker serving counter 1 then counter 2 then counter 3 then counter 1.
17:57:06 <tabemann> my integer sqrt is taken from Hacker's Delight - but in that book it's coded in C, not in Haskell
17:57:07 <Cale> external-reality: In my analogy, you'd have the option of having one worker serving multiple customers at once.
17:57:25 <erisco> first or second edition?
17:57:31 <tabemann> second edition
17:57:40 <erisco> what did they add?
17:58:04 <tabemann> I'd have to look up online (or dig in the book) to check just what parts they added to the book
17:58:15 <erisco> no big deal
17:58:20 <external-reality> Cale: The fact that multiple workers "appear" to be working independently is concurrency. Any actual parallel processing is parallelism.
17:58:21 <Cale> external-reality: (by switching between them)
17:58:40 <Cale> Perhaps the analogy can be confusing :P
17:58:47 <Cale> But it works!
17:58:52 * tabemann imagines that a lot of the stuff in that book isn't *that* useful when working in haskell just because the overhead of haskell will outweigh any gains from it
17:59:06 <Cale> The workers in my analogy are analogous to physical CPUs.
17:59:06 <external-reality> Cale: fair enough *sighb*
17:59:46 <Cale> and the customers are procedures or programs
18:00:50 <S_J> is STM fast? or is the answer, it depends as it often is?
18:01:34 * elliott thinks that was answered adequately when you asked six hours ago ;)
18:02:32 <Cale> S_J: It's usually fast enough.
18:02:52 <tabemann> the costs of STM are clearly outweighed by what you gain from it
18:02:57 <S_J> well, lets say for an embedded syste, hard real-time. to much overhead?
18:02:59 <Cale> S_J: There are also usually ways to avoid it in order to make programs faster, but those tend to be much harder to get right.
18:03:08 <elliott> well, Haskell doesn't really do hard real-time.
18:03:10 <tabemann> think what locking would do to that real-time system
18:03:13 <Cale> It's inappropriate for hard realtime.
18:03:20 <S_J> no but im talking STM in general
18:03:29 <tabemann> think what locking would do to that real-time system
18:03:33 <Cale> It's still inappropriate for hard real-time
18:03:36 <S_J> ok
18:03:41 <erisco> STM is what?
18:03:48 <tabemann> software transactional memory
18:03:49 <elliott> erisco: software transactional memory
18:03:49 <Cale> Software transactional memory
18:03:56 <erisco> sorry, what? :P
18:04:02 <erisco> one person at a time now
18:04:02 <external-reality> It's faster than HTM.
18:04:03 <tabemann> it's a way of being able to carry out transactions in software without relying on locking
18:04:06 <elliott> software transactional memory
18:04:13 <erisco> ah, okay, thanks.
18:04:17 <S_J> is there some apropriate alternative for hard realtime? i mean if you dont want those good old semaphores and mutexes
18:04:18 <Cale> http://research.microsoft.com/en-us/um/people/simonpj/papers/stm/stm.pdf
18:04:36 <tabemann> and it allows compositionality to one's code which mutexes and semaphore's don't allow
18:04:51 <Cale> erisco: It's a system for threads to communicate which in Haskell consists primarily of:
18:04:57 <Cale> :t atomically
18:04:58 <lambdabot> Not in scope: `atomically'
18:04:59 <erisco> must be an advanced topic for so many to pipe up so quickly
18:05:04 <Cale> :t Control.Concurrent.STM.atomically
18:05:05 <lambdabot> GHC.Conc.Sync.STM a -> IO a
18:05:10 <tabemann> in hard realtime I'd use semaphores and mutexes extremely sparingly myself
18:05:20 <Cale> a way to execute a transaction as-if atomically with respect to other transactions
18:06:03 <Demos> kinda like auto-locking
18:06:04 <Cale> and retry :: STM a  which gives up on a transaction and retries it at a later time (could retry immediately, but in practice, it only retries once one of the read variables has changed)
18:06:11 <elliott> erisco: it's pretty simple actually :)
18:06:12 <Cale> and TVars
18:06:28 <Cale> newTVar :: a -> STM (TVar a)
18:06:42 <Cale> readTVar :: TVar a -> STM a
18:06:52 <tabemann> :t Control.Concurrent.STM.orElse
18:06:52 <Cale> writeTVar :: TVar a -> a -> STM ()
18:06:53 <lambdabot> GHC.Conc.Sync.STM a -> GHC.Conc.Sync.STM a -> GHC.Conc.Sync.STM a
18:07:07 <Cale> right, and lastly, but importantly, there's orElse
18:07:15 <Cale> orElse :: STM a -> STM a -> STM a
18:07:24 <tabemann> orElse allows you to compose transactions, so that if one retries, the second will be tried instead of immediately retrying the first
18:07:36 <erisco> a bit confused on how this is different than locking
18:07:57 <singpolyma> If I `killThread` a thread blocked on an FFI call (such call marked as safe) does the `killThread` call itself block?
18:07:58 <tabemann> erisco: because there's no locking - if a variable is changed from under a transaction, it is just tried again
18:08:12 <tabemann> s/variable/TVar
18:08:28 <erisco> tabemann, ah what? that sounds bonkers
18:08:29 <Cale> erisco: If you have a program which needs to access multiple locked resources, you need a system to take locks in the right order and be careful to undo them in the reverse order
18:08:41 <tabemann> STM can't have deadlock, unlike locking - even though it can in theory have resource starvation
18:08:48 <Nisstyre-laptop> Is there a good HTTP library on Hackage that has Text responses?
18:08:57 <tabemann> erisco: the STM monad makes that quite simple, actually
18:09:08 <erisco> I just mean in concept
18:09:15 <tabemann> it remembers everything you've done within it, and can back up and try again when necessary
18:09:18 <Cale> erisco: There will tend to be some locking in the *implementation* of STM, when transactions complete and commit their logs.
18:09:46 <koninkje> djahandarie: I'm not sure entirely what you mean? Sounds like something that should be possible though
18:09:54 <tabemann> but STM abstracts that locking away, and in doing so prevents many of the failure modes one can have with normal locking
18:10:14 <erisco> the insanity of having transactions A, B, C, and watching them continually knock each other back to step one
18:10:29 <Cale> singpolyma: I doubt it.
18:10:36 <tabemann> erisco: usually you want your transactions to be short, so as to prevent that
18:10:49 <Nisstyre-laptop> erisco: do you find databases "bonkers" ?
18:11:09 <Nisstyre-laptop> because it's the same idea
18:11:17 <Cale> erisco: One will have to complete in order to step on the toes of the others.
18:11:52 <Cale> erisco: But you can have a system where there's one transaction which takes a long time and reads lots of stuff, and it constantly gets trampled by lots of short-running transactions which write.
18:11:59 <tabemann> but that failure mode is still not nearly as bad as deadlock, as eventually the transactions will succeed and break the cycle, whereas deadlock by definition cannot be broken
18:12:08 <erisco> Cale, why? they might be operating in parallel no? the transactions are not actually atomic if you aren't locking them ... or am I missing the idea?
18:12:27 <tabemann> they are atomic with regard to their side-effects on the outside world
18:12:34 <singpolyma> Cale: hmm... well, getting rid of the killThread call seems to have fixed my issue, anyway
18:13:12 <byorgey> erisco: the point is that in many systems with locking, *most* of the time there is no contention for the lock.  So you waste a lot of time taking and releasing locks when in fact nothing else tries to take the lock while you hold it anyway.
18:13:16 <tabemann> note that you do not do IO in the middle of a transaction - just accessing TVars and types derived from it, like TMVars and TChans
18:13:23 <Cale> erisco: Well, the implementation of transaction execution makes a log of the TVars read from (and the resulting values) as well as the TVars written to (and the values to store). This part happens concurrently.
18:13:53 <Cale> When the transaction completes, it takes a lock, and checks that all the TVars still have the values that it read
18:14:11 <Cale> and if they do, it writes all the new values of TVars to memory, and then releases the lock
18:14:24 <Cale> If not, it releases the lock and retries the transaction (immediately)
18:14:27 <byorgey> hmm, I guess that's not really the point, is it
18:14:27 <tabemann> but one lock controlled by STM is far better than many locks locked and unlocked arbitrarily
18:14:38 <byorgey> it's a small part of it
18:14:55 <Cale> These are just an implementation details though -- the important point is the semantics.
18:15:30 <Cale> The result of the program should be as if each transaction ran as if atomically with respect to all others.
18:15:41 <erisco> I get that idea, but it seems like you could construct transactions which "interleave" with each other, continually knocking each other out ... so you'd be relying on lucky runtime behaviour (and by "lucky" I don't mean unlikely)
18:15:47 <tabemann> and in Haskell the STM monad enforces that
18:15:57 <erisco> and to me that is rather hilarious
18:16:10 <erisco> a fascinating idea too
18:16:12 <Cale> erisco: Such a system will still make some measure of progress.
18:16:16 <tabemann> erisco: that is a potential failure case, but as I said, it isn't nearly as bad as deadlock
18:16:25 <Cale> In that transactions actually have to be completing in order to cause others to retry.
18:16:32 <tabemann> usually some thread will manage to succeed with its transaction, and thus break the cycle
18:16:50 <Cale> erisco: But you can still run into ill-behaved live-lock situations.
18:17:01 <tabemann> one may have degraded performance, but not complete failure generally
18:17:07 <erisco> Cale, are writes buffered until the end of the transaction? how are other transactions prevented from reading an invalid state when the buffer is flushed?
18:17:12 <byorgey> erisco: yes, of course you could construct transactions like that.  You can also construct threads using locking that are continually contending for the lock or even causing deadlock.  so?
18:17:27 <byorgey> erisco: but many (most?) real programs are not like that.
18:17:37 <tabemann> erisco: their buffering means that the other transactions still see the old values
18:17:40 <Cale> Yes, the other threads don't see changes until the transaction commits.
18:18:10 <Cale> (and the transaction log is carried out)
18:18:46 <Cale> At least, in the present implementation, that's what happens, and it's pretty reasonable.
18:18:58 <Cale> (but in any case, you'd have to make it look that way)
18:19:19 <erisco> ah, okay. so with buffering the writes you can at least guarantee that one transaction has finished any time another is reset
18:19:25 <Cale> yes
18:19:57 <Cale> and various systems could be devised to help out transactions which seem to be failing often
18:20:04 <erisco> I was imagining live writes, which I presume you could do as well, but might be less efficient and more dangerous :)
18:20:09 <Cale> without fundamentally ruining the system :)
18:20:36 <tabemann> the problem with live writes is that other threads may see inconsistent values
18:20:45 <Cale> You'd have to make sure to lock at the front and read everything then
18:21:03 <erisco> tabemann, yeah, but on write you also knock out other transactions which read
18:21:10 <Cale> (which might be tricky to implement because functions)
18:21:12 <tabemann> but with STM, the window in which things have to be locked is substantially compressed, as the actual computation occurs without locking
18:21:56 <erisco> well damn. has to be the coolest thing I'll hear all day
18:22:08 <Cale> Read the paper I linked, it's really good :)
18:22:12 <Cale> http://research.microsoft.com/en-us/um/people/simonpj/papers/stm/stm.pdf
18:22:17 <tabemann> erisco: I've heard of systems where there is a log of reads made too, and afterwards all the reads are checked to make sure they haven't changed, so as to allow live writing without locking
18:22:22 <erisco> reminds me of the 'unamb' operator
18:22:49 * tabemann doesn't know whether Haskell uses a read-logging or a locking system offhand
18:23:17 <Cale> (There are some small differences between the paper and what's in GHC -- atomic for some reason has been renamed atomically, and I believe the exception semantics might be slightly different.
18:23:18 <Cale> )
18:23:36 <Cale> tabemann: read-logging.
18:24:34 <Cale> But yeah, it's nice that there are multiple implementations of the semantics -- future runtime systems might be smarter, and improve the behaviour of existing programs.
18:24:46 <tabemann> the read-logging (with live-writing) system does kind of sound like a better idea to me anyways, as it doesn't rely on locks at all
18:25:01 <Cale> Well, there's one lock
18:25:09 <Cale> (to commit a transaction)
18:25:21 <Clint> did i dream something about hackage accepting things with UnknownLicense?
18:25:57 <fryguybob> For the current implementation details see: http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/STM
18:27:34 <e139> @type shift
18:27:34 <lambdabot> Bits a => a -> Int -> a
18:27:40 <Cale> Oh, right, there's also always now.
18:27:44 <Cale> Which is really cool :)
18:28:48 <e139> @run shift ( 0x80 :: Word8 ) ( -7 )
18:28:49 <lambdabot>   1
18:29:04 <Cale> always :: STM Bool -> STM ()  adds an invariant which must be True in order for a transaction to commit.
18:30:11 <Cale> More generally,  alwaysSucceeds :: STM a -> STM () does the same, but invariant failure is signalled by throwing an exception.
18:30:24 <e139> dmwit: belated thanks!
18:31:51 * hackagebot hOpenPGP 0.7 - native Haskell implementation of OpenPGP (RFC4880)  http://hackage.haskell.org/package/hOpenPGP-0.7 (ClintAdams)
18:32:33 <erisco> :t lift
18:32:34 <lambdabot> (Monad m, MonadTrans t) => m a -> t m a
18:34:26 <Cale> I'd also encourage people to look at the async library as a really cute example of an application of STM: http://hackage.haskell.org/packages/archive/async/2.0.1.4/doc/html/Control-Concurrent-Async.html
18:34:41 <Cale> There's a rather good recent-ish talk about async...
18:35:51 <Cale> http://skillsmatter.com/podcast/home/high-performance-concurrency -- This is it... I think :)
18:52:23 <monochrom> I like that talk too
18:57:13 <Gracenotes> how annoying, the way the video is embedded
18:57:21 <solrize_> http://www.haskell.org/pipermail/ghc-devs/2013-February/000414.html  is there more info about this, like a paper or anything?  tx
18:57:39 <hpc> Gracenotes: not as bad as vimeo
18:57:57 <hpc> vimeo doesn't work with noscript, even with everything disabled
18:58:14 <solrize_> http://hackage.haskell.org/trac/ghc/wiki/Status/May13 aha
18:58:17 <external-reality> Did something happen to *haskell-process-log* in the latest emacs-mode. Its not there anymore.
18:58:34 <external-reality> *?
18:59:03 <Gracenotes> hpc: vimeo is much preferably
18:59:06 <Gracenotes> preferable.
19:01:09 <monochrom> external-reality: I must be very young. I have used emacs haskell-mode for several years, and haven't even heard of haskell-process-log
19:03:43 <external-reality> monochrome: It a haskell emacs-mode thing. When you start a project a buffer is created named *haskell-process-log* it is useful for reading compilation errors and such much like the error window in modern IDEs.
19:04:07 <external-reality> monochrome: downloaded the a latest version and the buffer is no where to be found!
19:11:52 <byorgey> external-reality: ask hvr
19:12:16 <simon> I've got a silly problem: I've got a list of elements, and I'm transforming each element using a (state-)monadic action. I want each action to have the same initial state, but I don't want the actions to share each other's states. instead of "mapM action xs", should I "map (runState action) xs" or something similar?
19:12:48 <simon> I realize that I should probably consider using other monads than state.
19:13:18 <external-reality> byorgey: It is now turned off by default. I simply had to re-enable it. :-)
19:13:25 <byorgey> external-reality: ah =)
19:13:42 <solrize_> simon  that looks fine
19:14:24 <byorgey> simon: the state monad sounds perfectly reasonable for that.
19:14:51 <simon> byorgey, oh, ok. it's just that the compiler I'm writing an optimization has a bunch of other optimizations that uses stacks of writers and readers and whatnot. ;-)
19:17:42 <external-reality> So I saw a lady on the train today knitting some item of clothing (I could not make out what). I asked here a question that had been on my mind for some time: "Since the whole item is made from one long thread if I was to cut the thread in the middle of the finished item, how would you then repair it?" She replied, "I would make a knot." :-) Have a happy 4th everyone!
19:19:38 * tabemann figured out that his heavily-inlined newton's method integer sqrt is often about the same speed or a bit slower than the int->float->int sqrt, but other alternative integer sqrts are *much* slower
19:20:02 <tabemann> mind you this is in haskell - I might get different results if I were coding this in C, as the first sqrt uses division a lot
20:05:14 <adnap> Wow, there are so many people in here right now
20:05:48 <tac> haskell is the most popular of the unpopular languages
20:07:23 <joelteon> it's also the most unpopular of the popular languages
20:10:13 <edvardkk> well, it's at least very popular among those who use it
20:10:14 <Demos> haskell is the c++ of FP
20:10:24 <edvardkk> ;D
20:11:08 <adnap> ##c has 470 nicks
20:11:22 <imeredith> Demos: what is the c of fp? because a good number of people prefer c++ over c :P
20:11:39 <tac> Demos: it reallly is :P
20:11:40 <imeredith> err
20:11:41 <adnap> I want to talk to Peaker!
20:11:43 <imeredith> c over c++
20:11:49 <edvardkk> Demos: further, what is the haskell of FP? agda? :p
20:11:51 <Demos> maybe lisp...
20:11:51 <tac> imeredith: Scheme is the C of FP
20:11:56 <imeredith> ah
20:11:59 <joelteon> agda is the haskell of fp
20:12:00 <adnap> Is there anything I need to know about Data.Traversable besides traverse?
20:12:02 <imeredith> heh
20:12:04 <joelteon> I dunno what the agda of fp is
20:12:08 <adnap> I understand his example
20:12:09 <joelteon> probably lens
20:12:35 <kfish> i saw some announcement related to lisp on an fp list the other day, and my first thought was "wait, what does lisp have to do with fp?"
20:12:40 <adnap> I wanted to understand lens initially, and I was instructed about Traverable first
20:13:34 <adnap> So, maybe I'm ready now
20:13:41 <carter> is the libffi package actively maintained at all?
20:13:46 <carter> it works, per se
20:14:41 <adnap> Oh yeah! ion posted some examples yesterday
20:15:47 <carter> adnap my remark or lens?
20:16:24 <adnap> Crap
20:16:38 <adnap> I just overwrote my #haskell.log >_<
20:16:42 <adnap> carter: Huh?
20:16:45 <carter> nevermidn
20:16:52 <adnap> I lost ion's examples
20:17:40 <adnap> Will someone recommend some material to learn lens? Is the lecture the best thing?
20:18:24 <Clint> join #haskell-lens and stare at it for 48 hours
20:18:31 <adnap> Okay
20:18:49 <adnap> Does the bot in there understand lens?
20:19:18 <Demos> I mean lambdabot may well have lens
20:19:39 <adnap> Demos: It didn't work yesterday
20:19:59 <adnap> > ("hello","world")^._2
20:20:00 <lambdabot>   Not in scope: `_2'
20:20:01 <sclv> adnap: logs of the haskell irc channel are online
20:20:06 <sclv> you can see the url in the topic
20:20:59 <adnap> sclv: Thanks
20:21:19 <elliott> lambdabot will have lens in a day or two once i make the eval plugin not suck
20:21:53 * hackagebot yesod-comments 0.9.1 - A generic comments interface for a Yesod application  http://hackage.haskell.org/package/yesod-comments-0.9.1 (PatrickBrisbin)
20:23:00 <adnap> ion's examples have characters that Firefox doesn't render properly
20:23:12 <ion> adnap: A moment, i’ll explain again.
20:23:17 <adnap> e.g. "f aâ€ is a function"
20:23:34 <ion> adnap: (The problem is with the server with the log files claiming the incorrect character set, btw.)
20:23:34 <adnap> But it looks different in Firefox
20:23:40 <adnap> ion: Oh
20:24:00 <Demos> most browsers ignore the characterset though right
20:24:12 <Clint> only if you tell them to
20:24:31 <adnap> It needs <meta http-equiv="Content-Type" content="text; charset=utf-8" />
20:24:53 <Clint> or do it in the http header
20:25:14 <adnap> How do I do that?
20:25:33 <Clint> adnap: change the apache config
20:25:34 <ion> adnap: Let’s begin with the following four definitions. The first two should look familiar to you since you have implemented “traverse”. The latter two run traversal-like things exploiting the properties of Const and Identity.
20:25:50 <ion> @let _1 f (a,b) = flip (,) b <$> f a
20:25:52 <lambdabot>  Defined.
20:26:00 <ion> @let both f (a,b) = (,) <$> f a <*> f b
20:26:01 <lambdabot>  Defined.
20:26:14 <ion> @let view l x = getConst (l Const x); over l f x = runIdentity (l (Identity . f) x)
20:26:15 <lambdabot>  Defined.
20:26:22 <parcs_> @faq can haskell help heal my dislocated shoulder?
20:26:22 <lambdabot> The answer is: Yes! Haskell can do that.
20:26:31 <ion> Now, we can use _1, both (and traverse for that matter) as getters:
20:26:55 <parcs_> doubtful :P
20:26:58 <ion> > (view _1 ("foo", "bar baz"), view both ("foo", "bar baz"), view traverse (Just "foobar"))
20:26:59 <lambdabot>   Ambiguous occurrence `view'
20:26:59 <lambdabot>  It could refer to either `L.view', defined at ...
20:27:14 <ion> Err.
20:27:51 <adnap> This makes no sense: "@let view l x = getConst (l Const x); over l f x = runIdentity (l (Identity . f) x)"
20:28:00 <ion> @undefine
20:28:00 <lambdabot> Undefined.
20:28:12 <ion> @let my_1 f (a,b) = flip (,) b <$> f a; myboth f (a,b) = (,) <$> f a <*> f b; myview l x = getConst (l Const x); myover l f x = runIdentity (l (Identity . f) x)
20:28:13 <lambdabot>  Defined.
20:28:24 <ion> > (myview my_1 ("foo", "bar baz"), myview myboth ("foo", "bar baz"), myview traverse (Just "foobar"))
20:28:25 <lambdabot>   Not in scope: `traverse'
20:28:25 <lambdabot>  Perhaps you meant one of these:
20:28:25 <lambdabot>    `T.traverse' (...
20:28:33 <ion> sigh :-P
20:28:37 <ion> > (myview my_1 ("foo", "bar baz"), myview myboth ("foo", "bar baz"), myview T.traverse (Just "foobar"))
20:28:41 <lambdabot>   ("foo","foobar baz","foobar")
20:28:44 <adnap> @type both
20:28:45 <lambdabot> Not in scope: `both'
20:30:09 <ion> adnap: We’ll go to the explanation of view and over in a minute. A couple more examples first to motivate all of this. You just saw getters: _1 gets the first element out of a tuple, both gets both elements (and according to the behavior of the Const applicative, mappends them together), traverse gets the value out of a Just (or mempty in case of Nothing).
20:30:19 <ion> Then modifiers:
20:30:32 <adnap> I would like to see the types
20:30:51 <ion> > (myover my_1 length ("foo", "bar baz"), myover myboth ("foo", "bar baz"), myover T.traverse (Just "foobar"))
20:30:52 <lambdabot>   Couldn't match expected type `a10 -> b0'
20:30:53 <lambdabot>              with actual type `([G...
20:30:59 <ion> > (myover my_1 length ("foo", "bar baz"), myover myboth length ("foo", "bar baz"), myover T.traverse (Just "foobar"))
20:31:00 <lambdabot>   Couldn't match expected type `a10 -> b0'
20:31:00 <lambdabot>              with actual type `Dat...
20:31:12 <ion> Sigh. Sorry, i keep making stupid mistakes.
20:31:12 <adnap> What is the point of typing these things I don't understand?
20:31:51 <ion> To demonstrate the point of lens: using traversal-like things to get values out of data structures and modify them.
20:32:00 <adnap> Demonstrate to yourself?
20:32:05 <ion> > (myover my_1 length ("foo", "bar baz"), myover myboth length ("foo", "bar baz"), myover T.traverse length (Just "foobar"))
20:32:08 <lambdabot>   ((3,"bar baz"),(3,7),Just 6)
20:33:00 <ion> Ok, the types: _1 :: Functor f => (a -> f b) -> (a, c) -> f (b, c)
20:33:23 <ion> both :: Applicative f => (a -> f b) -> (a, a) -> f (b, b)
20:33:46 <ion> traverse :: (a -> f b) -> Maybe a -> f (Maybe b)
20:34:33 <ion> adnap: Now, try evaluating some of the examples i gave step by step manually. I suppose that should provide intuition into how this works.
20:35:01 <adnap> I understand _1 and both just fine
20:35:37 <ion> Yeah, but how the interaction with Const and Identity makes them behave as getters and modifiers.
20:36:02 <adnap> The third thing you defined, view, makes no sense
20:36:44 <elliott> (perhaps Const and its relevant instances have not been introduced?)
20:36:49 <adnap> Nope
20:37:03 <adnap> Or... correct
20:37:13 <ion> > getConst ((,) <$> Const "foo" <*> Const "bar baz"))
20:37:14 <lambdabot>   <hint>:1:51: parse error on input `)'
20:37:15 <ion> http://hackage.haskell.org/packages/archive/base/latest/doc/html/src/Control-Applicative.html#Const
20:37:19 <ion> > getConst ((,) <$> Const "foo" <*> Const "bar baz")
20:37:20 <lambdabot>   "foobar baz"
20:37:54 <DiegoNolan_> why is a Num not a Monoid by default?
20:38:02 <startling> DiegoNolan_: it's two monoids
20:38:06 <ion> According to the definitions, (,"bar") <$> Const "foo" = Const "foo"
20:38:09 <adnap> What happened to the tuple?
20:38:19 <ion> (,) <$> Const "foo" <*> Const "bar baz" = Const ("foo" <> "bar baz")
20:38:28 <startling> DiegoNolan_, (assuming you mean "why isn't Num a subclass of Monoid")
20:38:37 <DiegoNolan_> yes
20:38:44 <elliott> it's called Const because it ignores the value part.
20:38:50 <DiegoNolan_> whare are two Monoids it is?
20:39:14 <startling> DiegoNolan_, mappend = (*); mempty = 1; and mappend = (+); mempty = 0;
20:39:21 <DiegoNolan_> oh
20:39:28 <DiegoNolan_> yeah
20:39:30 <adnap> What is "<>"?
20:39:35 <ion> adnap: mappend
20:39:51 <ion> > ("foo" <> "bar baz", Sum 42 <> Sum 5)
20:39:51 <lambdabot>   ("foobar baz",Sum {getSum = 47})
20:39:57 <DiegoNolan_> makes sense
20:39:59 <startling> > Product 12 <> Product 3
20:40:00 <lambdabot>   Product {getProduct = 36}
20:40:14 <startling> > Sum 12 <> Sum 3
20:40:14 <lambdabot>   Sum {getSum = 15}
20:40:23 <startling> DiegoNolan_: you can do that, though ^
20:40:54 <DiegoNolan_> startling, declare the instances?
20:41:09 <DiegoNolan_> yeah i figured
20:41:15 <adnap> elliott: I don't understand, because getConst ((,) <$> Const "foo" <*> Const "bar baz") gives "foobar baz", so "foo" and "bar bz" weren't ignored
20:41:17 <startling> DiegoNolan, no, use the wrapper types Sum and Product
20:41:23 <adnap> *baz
20:41:34 <startling> :t Const "foo" -- adnap
20:41:35 <lambdabot> Const [Char] b
20:41:49 <tac> @kind Const
20:41:50 <lambdabot> * -> * -> *
20:41:50 <adnap> Oh
20:41:59 <DiegoNolan_> Sum and Product are typeclasses? defined where?  Or you mean sum and product?
20:42:43 <startling> DiegoNolan_, Sum and Product are types. when you wrap some Num with Sum, you get a type with a Monoid instance that adds the wrapped numbers
20:42:47 <startling> @where Sum
20:42:47 <lambdabot> I know nothing about sum.
20:42:54 <ion> adnap: Const carries a value with it that the Functor instance won’t touch at all. The Functor instance throw away the function parameter.
20:43:04 <startling> DiegoNolan_: they're from Data.Monoid iirc
20:43:16 <DiegoNolan_> k
20:43:43 <adnap> > fmap (+2) Const 2 "bla"
20:43:44 <lambdabot>   Couldn't match type `[GHC.Types.Char] -> t0'
20:43:44 <lambdabot>                with `Control.A...
20:43:48 <adnap> > fmap (+2) $ Const 2 "bla"
20:43:49 <lambdabot>   Couldn't match expected type `[GHC.Types.Char] -> f0 b0'
20:43:49 <lambdabot>              with ...
20:43:55 <adnap> > fmap (+2) $ Const 2 3
20:43:56 <lambdabot>   Couldn't match expected type `a1 -> f0 b0'
20:43:57 <lambdabot>              with actual type `C...
20:43:57 <startling> > getConst $ fmap (+ 1) (Const 12)
20:43:58 <lambdabot>   12
20:44:00 <ion> adnap: The second parameter to the Const type constructor doesn’t actually refer to anything wrapped by the data constructor.
20:44:10 <adnap> Oh
20:44:13 <adnap> But...
20:44:15 <startling> :t Const -- adnap
20:44:15 <lambdabot> a -> Const a b
20:44:16 <adnap> @kind Const
20:44:16 <lambdabot> * -> * -> *
20:44:21 <adnap> Oh, nevermind
20:44:25 <adnap> that refers to the type
20:44:31 <adnap> @type Const
20:44:32 <lambdabot> a -> Const a b
20:44:49 <ion> That is, there is no “b” inside a Const value.
20:44:54 <adnap> I see
20:44:56 <startling> Const is useful because you can derive "view" from lens with it
20:45:00 <adnap> It's a phantom type
20:45:37 <ion> @type fmap (length :: [Int] -> Int) (Const "hello")
20:45:38 <startling> > getConst $ _1 Const ('a', 'b')
20:45:40 <lambdabot> Const [Char] Int
20:45:41 <lambdabot>   Not in scope: `_1'
20:45:45 <startling> bah
20:45:49 <ion> startling: my_1
20:45:54 <startling> :t my_1
20:45:54 <lambdabot> Functor f => (t -> f a) -> (t, b) -> f (a, b)
20:45:56 <adnap> ((,) <$> Const "foo" <*> Const "bar baz")
20:46:05 <adnap> Somehow...
20:46:07 <startling> > getConst $ my_1 Const ('a', 'b')
20:46:09 <lambdabot>   'a'
20:46:22 <ion> adnap: Evaluate the expression by hand.
20:46:25 <adnap> the Applicative instance of Const causes the two strings to be concatenated
20:46:36 <ion> adnap: using the definitions from the Functor and Applicative instances for Const
20:46:42 <adnap> I don't know those
20:46:46 <ion> http://hackage.haskell.org/packages/archive/base/latest/doc/html/src/Control-Applicative.html#Const
20:46:55 <djahandarie> koninkje, I mean, say you have a trie [("foo", 1), ("foobar", 2), ("baz", 3)] and you lookup "foobarbaz", you would get 2 back, because it's essentially the longest prefix which matches.
20:47:14 <adnap> ion: Oh, I see
20:47:20 <adnap> Const values must be monoids
20:47:24 <startling> :t (pure :: b -> Const a b) 12
20:47:25 <lambdabot>     Could not deduce (Monoid a1) arising from a use of `pure'
20:47:25 <lambdabot>     from the context (Num b)
20:47:25 <lambdabot>       bound by the inferred type of it :: Num b => Const a b at Top level
20:47:28 <ion> adnap: For the Applicative instance, yes
20:47:36 <adnap> Okay
20:47:47 <adnap> I understand Const
20:47:57 <startling> :t (prue :: Monoid a => Const a b) 12
20:47:57 <lambdabot>     Not in scope: `prue'
20:47:57 <lambdabot>     Perhaps you meant `pure' (imported from Control.Applicative)
20:48:06 <startling> :t (pure :: Monoid a => Const a b) 12
20:48:06 <lambdabot>     Couldn't match expected type `a2 -> t0'
20:48:06 <lambdabot>                 with actual type `Const a1 b0'
20:48:06 <lambdabot>     The function `pure :: Monoid a => Const a b'
20:48:10 <djahandarie> koninkje, very useful for fast lookups on any hierarchical sort of string (in my case, domains (reversed)).
20:48:16 <startling> oh well
20:48:30 <adnap> ion: How do you decide what dummy thing to fmap over Const?
20:48:34 <adnap> It seems so silly
20:48:54 <startling> adnap, what do you mean?
20:48:56 <adnap> Why use Const at all instead of just Monoids for the values inside?
20:49:05 <adnap> Er...
20:49:08 <ion> adnap: Well, look at “over”, the function we used for modification.
20:49:12 <adnap> Why not just use the monoid operators on the values inside
20:49:16 <ion> > myover _1 length ("foo", "bar baz")
20:49:17 <lambdabot>   Not in scope: `_1'
20:49:18 <startling> adnap, because certain things can only be used with Applicatives etc
20:49:19 <ion> > myover my_1 length ("foo", "bar baz")
20:49:21 <adnap> ion: You're not explaning things well
20:49:22 <lambdabot>   (3,"bar baz")
20:49:47 <ion> adnap: We can use the same _1 as a getter (with Const) and a modifier (with Identity).
20:49:57 <adnap> Hold on...
20:50:00 <adnap> I don't know what Identity is
20:50:00 <startling> :t my_1
20:50:01 <lambdabot> Functor f => (t -> f a) -> (t, b) -> f (a, b)
20:50:06 * adnap scrolls up
20:50:21 <startling> adnap, data Indentity a = Identity a
20:50:22 <ion> adnap: You saw it yesterday. Under Identity, traverse is just isomorphic to fmap.
20:50:35 <adnap> Okay
20:50:37 <startling> > runIdentity $ return 12
20:50:40 <lambdabot>   12
20:50:55 <adnap> I am so lost
20:51:05 <adnap> What are you trying to explain to me?
20:51:07 <startling> adnap, Identity is the simplest Monad
20:51:27 <startling> adnap, what are you trying to find out? :)
20:51:29 <adnap> lens
20:51:39 <ion> adnap: Given an appropriate traversal to a data structure, we can use it as both a getter (using Const) and a setter (using Identity).
20:51:52 <adnap> ion: Okay, I don't understand that
20:51:59 <startling> :t my_1 -- take a look at this type
20:51:59 <lambdabot> Functor f => (t -> f a) -> (t, b) -> f (a, b)
20:52:06 <startling> do you see what it does?
20:52:30 * applicative is with adnap ... it takes getting used to
20:52:43 <adnap> Yes
20:52:53 <adnap> It applies the function to the first element of the tuple
20:52:59 <startling> and then what?
20:53:05 <adnap> Then fmaps the other element with the tuple constructor
20:53:11 <adnap> To make a tuple inside the functor
20:53:14 <startling> something like that, yeah
20:53:19 <startling> adnap, so take a look at
20:53:29 <startling> > my_1 Identity ('a', 'b')
20:53:32 <adnap> I told you already that I understand _1 and obth
20:53:32 <lambdabot>   Identity {runIdentity = ('a','b')}
20:53:42 <adnap> I don't understand view
20:53:47 <startling> adnap, we'll get there
20:53:49 <applicative> @type view
20:53:50 <lambdabot>     Not in scope: `view'
20:53:50 <lambdabot>     Perhaps you meant one of these:
20:53:50 <lambdabot>       `Seq.viewl' (imported from Data.Sequence),
20:53:53 <applicative> bah
20:53:59 <adnap> Okay, I get it
20:54:06 <startling> adnap, now take a look at
20:54:12 <adnap> With Identity, you can change one element of the tuple and make the Functor go away
20:54:13 <startling> > my_1 Const ('a', 'b')
20:54:14 <lambdabot>   No instance for (GHC.Show.Show
20:54:14 <lambdabot>                     (Control.Applicative.Con...
20:54:35 <startling> adnap, uh, "make the functor go away"?
20:54:41 <adnap> with getIdentity
20:54:45 <adnap> or runIdentity or whatever
20:54:57 <startling> oh, right.
20:55:05 <adnap> You can extract the mapped tuple out of the Identity Functor
20:55:11 <startling> > getConst $ my_1 Const ('a', 'b')
20:55:14 <lambdabot>   'a'
20:55:23 <adnap> Oh, that's cool
20:55:26 <startling> do you see how that works?
20:55:28 <shachaf> @let instance Show a => Show (Const a b) where showsPrec (Const x) = showString "Const " . showsPrec 11 x
20:55:28 <lambdabot>  .L.hs:121:20:
20:55:28 <lambdabot>      Couldn't match expected type `Int' with actual type `Cons...
20:55:31 <adnap> Yeah
20:55:50 <startling> adnap, you get Const 'a' and then fmap (, b) over it
20:55:56 <adnap> It's a funny way of accomplishing fst :P
20:55:59 <startling> but since fmapping over Const does nothing ...
20:56:10 <adnap> It does something
20:56:13 <shachaf> help
20:56:19 <adnap> It changes the type of Const, right?
20:56:28 <shachaf> :t \(Const x) -> showString "Const " . showsPrec 11 x
20:56:29 <lambdabot> Show a => Const a t -> String -> String
20:56:46 <startling> adnap, right, but it does nothing to the held value
20:56:50 <adnap> Yeah
20:56:51 <adnap> I get it
20:57:19 <startling> adnap, anyway, the cool big things about lenses are that you can view and set with the same type of thing, and that lenses are composable with (.)
20:57:20 <shachaf> Oh.
20:57:31 <ion> @let instance Show a => Show (Const a b) where showsPrec p (Const x) = showParen (p > 10) $ showString "Const " . showsPrec 11 x
20:57:32 <lambdabot>  Defined.
20:57:32 <shachaf> I forgot the n argument.
20:57:41 <shachaf> ion++ for remembering
20:57:56 <shachaf> @let deriving instance Show a => Show (Identity a)
20:57:56 <lambdabot>  Parse failed: StandaloneDeriving is not enabled
20:58:00 <startling> @let my_view l = getConst . l Const
20:58:00 <lambdabot>  Defined.
20:58:13 <ion> @type [myview, my_view]
20:58:14 <lambdabot> [((a1 -> Const a1 b1) -> t -> Const a b) -> t -> a]
20:58:35 <startling> > my_view (my_1 . my_1 . my_1) ((('a', 'b'), 'c'), 'd')
20:58:38 <lambdabot>   'a'
20:58:41 <startling> adnap: ^
20:58:45 <mapreduce> I have some code that processes lists of tuples as if they were ordered maps, and I'm doing [] x:xs style pattern matching over the lists..
20:58:46 <adnap> I don't even...
20:58:54 <adnap> What is this? I don't even...
20:58:56 <adnap> lol
20:59:02 <ion> adnap: First of all, fmap composes as follows:
20:59:06 <startling> :t my_1 . my_1 -- adnap
20:59:06 <ion> @type fmap length
20:59:07 <lambdabot> Functor f => (t -> f a) -> ((t, b1), b) -> f ((a, b1), b)
20:59:07 <lambdabot> Functor f => f [a] -> f Int
20:59:12 <ion> @type (fmap . fmap) length
20:59:12 <mapreduce> I'm looking to move from [(a,b)] to Data.Map.Map a b, but it doesn't seem to support pattern matching.
20:59:12 <lambdabot> (Functor f, Functor f1) => f (f1 [a]) -> f (f1 Int)
20:59:25 <ion> > (fmap . fmap) length [[1,2,3], [4,5,6,7]]
20:59:26 <lambdabot>   No instance for (GHC.Num.Num [a0]) arising from the literal `1'
20:59:26 <lambdabot>  Possible f...
20:59:26 <mapreduce> What's the 'safe' refactor path, try to convert the functions to foldl first?
20:59:34 <adnap> :(
21:00:00 <startling> adnap, do you see how my_1 . my_1 works
21:00:03 <startling> ?
21:00:05 <ion> > (fmap . fmap) length [[[1,2,3], [4,5,6,7]], [[7]]]
21:00:05 <lambdabot>   [[3,4],[1]]
21:00:11 <adnap> What is my_view?
21:00:17 <adnap> Should I ignore that?
21:00:21 <startling> my_view l = getConst . l Const
21:00:32 <adnap> I don't get it
21:00:33 <ion> traverse also composes in the same way.
21:00:36 <adnap> What is l Const doing?
21:00:39 <startling> adnap, that's just what we looked at before
21:00:51 <startling> adnap: getConst $ my_1 Const ('a', 'b')
21:00:53 <adnap> @type my_view
21:00:56 <lambdabot> ((a1 -> Const a1 b1) -> a -> Const c b) -> a -> c
21:01:21 <adnap> Ohhh
21:01:28 <startling> adnap, so now we have
21:01:35 <startling> > my_view my_1 ('a', 'b')
21:01:38 <lambdabot>   'a
21:01:41 <adnap> Yeah
21:02:01 <startling> we also can have
21:02:45 <startling> @let my_over l f = runIdentity . l (Identity . f)
21:02:46 <lambdabot>  Defined.
21:03:00 <startling> > my_over my_1 (+ 1) (0, 0)
21:03:01 <adnap> @type my_1
21:03:02 <lambdabot> Functor f => (t -> f a) -> (t, b) -> f (a, b)
21:03:03 <lambdabot>   (1,0)
21:03:37 <startling> adnap, make sense?
21:08:17 <startling> no?
21:08:24 <adnap> Still reading
21:08:39 <startling> k. let me know if you have a question.
21:15:40 <adnap> startling: Okay, makes sense
21:16:59 <adnap> @type my_over
21:19:34 <startling> adnap, okay, next!
21:19:37 <startling> :t my_1 . my_1
21:19:38 <lambdabot> Functor f => (t -> f a) -> ((t, b1), b) -> f ((a, b1), b)
21:19:42 <adnap> What the-
21:19:47 <adnap> :t my_over
21:20:06 <startling> :t my_over
21:20:10 <startling> o.o
21:20:18 <adnap> A moment ago it responded to @type
21:20:23 <startling> yeah. odd.
21:20:46 <adnap> :t my_1
21:20:46 <koninkje> djahandarie: so, when looking up "fooba" you'd get 1 because "foo" is the longest matching prefix?
21:20:48 <lambdabot> Functor f => (t -> f a) -> (t, b) -> f (a, b)
21:21:15 <koninkje> djahandarie: should be doable. I'd have to think about how to implement it; patches welcome, of course
21:21:27 <djahandarie> koninkje, yeah.
21:21:50 <djahandarie> I thought a little about it, it wasn't immediately obvious. I was mainly trying to wrap my head around the Trie representation in that time though.
21:22:36 <adnap> djahandarie:　こんばんは
21:22:47 <djahandarie> yo
21:23:21 <external-reality> can someone help me understand this line: A Getter s a is just any function (s -> a), which we've flipped into continuation passing style, (a -> r) -> s -> r and decorated with Accessor to obtain:
21:23:22 <koninkje> djahandarie: the big thing is just to keep track of the most-recent-match while doing the lookup. If the lookup fails, then return the most-recent-match
21:23:34 <djahandarie> koninkje, yeah.
21:24:00 <external-reality> how is '(a -> r) -> s -> r' a function in continuation passing style?
21:24:14 <adnap> startling: I'm not quite sure why my_1 . my_1 doesn't produce a functor value inside of a functor value
21:24:25 <adnap> startling: my_1 produces a functor, which is then passed into my_1 again
21:24:26 <koninkje> it's essentially the same as (s -> a)
21:24:31 <c_wraith> external-reality: specifically, it's the type (s -> a) in CPS
21:24:38 <startling> adnap, what happens if you fmap twice?
21:24:47 <adnap> startling: Oh, nevermind
21:24:49 <copumpkin> external-reality: try flipping its two arguments
21:24:52 <startling> adnap: yeah. :)
21:24:57 <adnap> startling: The my_1 takes two arguments
21:24:57 <copumpkin> `s -> (a -> r) -> r` is more conventional
21:25:08 <c_wraith> external-reality: instead of the function returning an a, it calls the function you've provided with the value of type a
21:25:12 <adnap> startling: so the my_1 is the (t -> f a) for the second my_1
21:25:27 <startling> yeah
21:25:38 <startling> well, the my_1 with some function applied
21:25:54 <adnap> startling: Yeaj
21:25:57 <startling> my_1 . my_1 = my_1 (my_1 f)
21:26:09 <external-reality> joy! I beginning to understand/recall
21:26:13 <startling> er, first half of that should be (my_1 . my_1) f
21:26:24 <startling> adnap: so do you see where 'f' gets applied?
21:27:14 <external-reality> c_wraith: what about the value of type `s`
21:27:34 <external-reality> c_wraith: nevermind
21:31:35 <adnap> startling: Yes. The second my_1 fmaps my_1 f over the first element of the tuple, which is a tuple, and my_1 f maps f over the first element of that tuple
21:31:54 <adnap> *.*
21:31:54 <ion> adnap: Some examples you might find useful: https://gist.github.com/ion1/5924946
21:32:09 <adnap> My brain...
21:32:40 <adnap> ion: Thanks
21:33:12 <adnap> But... does the real _1 only work on tuples?
21:33:27 <ion> adnap: example4{a,b,c,d} demonstrate how plain fmap and traverse composes, example4{f,g} take advantage of that with view/over.
21:33:38 <ion> adnap: Yes, _1 only works on tuples.
21:33:48 <tomboy64> how can i chain output and an if statement? Debug.Trace doesn't do it, neither does do putStrLn ... if...
21:33:50 <adnap> Why all this for manipulating tuples?
21:34:13 <ion> adnap: The file i linked contains other examples than just tuples.
21:35:00 <adnap> ion: You are an octopus
21:36:53 * ion notices there’s no example4e
21:38:16 <startling> adnap, you can use lenses on any product type
21:39:11 <ion> adnap: How map (map (map f)) [[[0,1],[2]],[[3,4],[5,6,7]]] works should give some intuition to how fmap composes and that extends to traversals as well.
21:41:50 <shachaf> ion: Did you figure out why Is/Refl is so great?
21:42:35 <ion> shachaf: Seeing your related lens change helped me understand it a bit better.
21:43:29 <shachaf> ion: You should look at the non-HEAD version of machines.
21:43:48 <shachaf> It uses it for various things.
21:43:57 <ion> Alright, will do. Why not HEAD?
21:44:10 <shachaf> Because HEAD does it in a simpler way. :-)
21:44:46 <shachaf> ion: Also you should figure out Leibniz equality -- i.e. newtype Is a b = Is { subst :: forall p. p a -> p b } -- which is almost, but not quite, the same thing.
21:46:47 <ion> huh
21:47:42 <shachaf> ion: In particular look at how you can convert back and forth between the two, and how you can write e.g. Is a b -> Is b c -> Is a c.
21:47:54 <shachaf> (Is is a category, predictably.)
21:48:37 <ion> “
21:48:40 <ion>     Given any x and y, x = y if, given any predicate P, P(x) if and only if P(y).”
21:48:52 <ion> So… subst :: forall p. (p a -> p b, p b -> p a)? :-P
21:50:36 <shachaf> In this law, the connective "if and only if" can be weakened to "if"; the modified law is equivalent to the original.
21:52:40 <ion> Hmm, i suppose it makes sense that if you can provide forall p. p a -> p b, you can also provide forall p. p b -> p a.
21:52:59 <elliott> you just need a clever choice of p
21:53:28 <elliott> (exercise: write symmetry :: Is a b -> Is b a)
21:54:10 <ion> I’ll get back to this when i’m over this cold.
21:54:41 <adnap> Are you talking about math with Haskell notation or something?
21:54:46 <adnap> o.o
21:55:24 <tac> adnap: Do you know about Curry-Howard?
21:55:54 <monochrom> it's likely haskell with math notation
21:56:02 <adnap> tac: Not really
21:56:14 * adnap Just skimmed the Wikipedia article
21:56:22 <tac> The Haskell type system is actually closely related to logic.
21:56:33 <tac> A fun tool to explore this idea is @djinn
21:56:45 <tac> @djinn a -> b -> (a, b)
21:56:45 <lambdabot> f a b = (a, b)
21:57:13 <zRecursive> :t (,))
21:57:14 <lambdabot> parse error on input `)'
21:57:18 <zRecursive> :t (,)
21:57:19 <lambdabot> a -> b -> (a, b)
21:57:20 <tac> a -> b -> (a, b) is read logically as "a implies b implies a and b"
21:57:21 <ion> adnap: You can write logic expressions as Haskell types and witnesses for them as Haskell values.
21:57:33 <adnap> wat
21:58:32 <augur> ion: yoneda.
21:58:45 <tac> @djinn Either a b -> Not (Not a, Not b)
21:58:45 <lambdabot> f a =
21:58:45 <lambdabot>     case a of
21:58:45 <lambdabot>     Left b -> \ (c, _) -> c b
21:58:45 <lambdabot>     Right d -> \ (_, e) -> e d
21:58:49 <tac> ^this is demorgan's law
21:59:09 <shachaf> It's mildly annoying that you can't have an existential type with a dictionary but no value.
21:59:12 <tac> a || b    implies   !(!a && !b)
21:59:13 <augur> adnap: i have a paper you can read on curry-howard
21:59:25 <adnap> augur: I'm trying to understand lens...
21:59:27 <shachaf> I.e. I have to store a Proxy for no reason.
21:59:56 <augur> adnap: HAH
22:00:06 <augur> then why are you listening to tac ramble on about curry howard? lol
22:00:15 <adnap> I am too curious
22:00:19 <adnap> I get distracted
22:00:22 <augur> adnap: well if you're curious about it, http://purelytheoretical.com/papers/ATCHC.pdf
22:00:23 <augur> :p
22:00:43 * adnap saves
22:01:01 <tac> augur: I will read it, and it will shut me up :P
22:01:20 <augur> that starts from pure proof theory and shows you how Curry-Howard isn't some magical "correspondence" but an on-the-nose identity.
22:01:20 <ion> adnap: Anything to ask about my paste so far?
22:01:25 <adnap> ion: Nope
22:04:53 <ion> In, say, _dogName f dog = (\n -> dog { dogName = n }) <$> f (dogName dog), it should make sense that Const (dogName dog) will only return the name in a wrapper because the definition of (<$>) for it throws away the function and leaves the carried value unchanged. It should also make sense that (Identity . sometFunction) (dogName dog) will modify the dog’s name, and fmap (\n -> dog { dogName = n }) will put
22:04:55 <ion> the rest of the original Dog back around it.
22:05:09 <ion> someFunction
22:13:33 <adnap> whoa
22:13:50 <adnap> > my_view Data.Traversable.traverse ["foo", "bar baz", "quux"]
22:13:51 <lambdabot>   Not in scope: `Data.Traversable.traverse'
22:14:41 <startling> :t traverse
22:14:42 <lambdabot>     Not in scope: `traverse'
22:14:42 <lambdabot>     Perhaps you meant one of these:
22:14:42 <lambdabot>       `T.traverse' (imported from Data.Traversable),
22:14:59 <startling> > my_view T.traverse ["foo", "bar", "quux"]
22:15:02 <lambdabot>   "foobarquux"
22:15:35 <startling> adnap, another fun thing you can do is
22:15:36 <augur> Philippa_: seriously tho, James Burke
22:15:45 <startling> > my_1 id (Just 12, 0)
22:15:48 <ion> traverse :: (Applicative f, Traversable t) => LensLike f (t a) (t b) a b
22:15:48 <lambdabot>   Just (12,0)
22:16:16 <adnap> Oh
22:16:20 <ion> > my_1 putStrLn (Just "hello", 42)
22:16:21 <lambdabot>   Couldn't match type `Data.Maybe.Maybe [GHC.Types.Char]'
22:16:21 <lambdabot>                with...
22:16:28 <adnap> 'Cause a function is a Functor
22:17:11 <ion> Ah, duh.
22:17:17 <ion> @type my_1 putStrLn ("hello", 42)
22:17:18 <lambdabot> Num b => IO ((), b)
22:17:41 <adnap> Okay, I don't fully get this
22:18:24 <ion> Remember how traverse is equivalent to mapM. traverse putStrLn ["foo", "bar"] works, so will _1 putStrLn ("hello", anything). Also:
22:18:26 <ion> @type mapM id
22:18:26 <lambdabot> Monad m => [m b] -> m [b]
22:18:32 <adnap> ion: Nope
22:18:40 <adnap> Don't think that was every explained
22:18:44 <adnap> *ever
22:19:20 <ion> Oh, ok. Well, traverse is a generalization of mapM.
22:19:28 <startling> adnap, traverse is mapM for anything, not just for lists
22:19:38 <adnap> Someone said traverse is a generalization of fmap
22:19:51 <augur> ion: i dont think this conversation is going to end well
22:19:57 <startling> adnap, that's a generalization in the other direction.
22:20:03 <augur> i think adnap is probably too newbie to grok this stuff.
22:20:07 <adnap> :(
22:20:33 <ion> augur: He has made great progress. Peaker assisted him yesterday and he implemented Traversable for a Tree.
22:20:34 <augur> adnap: its not a bad thing! I'm just saying i think the current route of learning for you is going to end in a ditch
22:20:39 <adnap> augur: I hate you
22:20:40 <startling> I think being exposed to it even if you don't understand it all yet will help.
22:21:14 <augur> adnap: i think you need to slow down and let stuff settle
22:21:22 <adnap> augur: Back off
22:21:39 <augur> suit yourself.
22:23:18 <Gracenotes> augur: don't make comments like that.
22:24:00 <startling> adnap, anyway, can you see how to implement fmap in terms of traverse?
22:24:47 <adnap> @type T.traverse
22:24:47 <lambdabot> (Applicative f, T.Traversable t) => (a -> f b) -> t a -> f (t b)
22:25:07 <adnap> @type fmap
22:25:07 <lambdabot> Functor f => (a -> b) -> f a -> f b
22:25:30 <startling> the type you want is T.traversable t => (a -> b) -> t a -> t b
22:26:18 <adnap> fmap f = traverse (id . f)
22:26:37 <startling> adnap, not quite
22:26:41 <ion> id . f = f
22:26:55 <adnap> fmap f = getIdentity . traverse (Identity . f)
22:27:08 <ion> Bingo
22:27:15 <startling> adnap, yep
22:27:34 <ion> See anything familiar? (Hint: over)
22:27:44 <adnap> Yes
22:28:11 <startling> :t my_over traverse
22:28:12 <lambdabot>     Not in scope: `traverse'
22:28:12 <lambdabot>     Perhaps you meant one of these:
22:28:12 <lambdabot>       `T.traverse' (imported from Data.Traversable),
22:28:13 <citizen93> I have a very nooby question, but I can't seem to find the answer quickly. I am debugging using the trace function, how can I temporary disable all its output?
22:28:20 <startling> :t my_over T.traverse
22:28:20 <lambdabot> T.Traversable t => (a1 -> b) -> t a1 -> t b
22:28:26 <adnap> So cool
22:28:47 <startling> adnap: it is pretty satisfying.
22:28:49 <ion> citizen93: You could comment out the import and write your own “trace” that does nothing.
22:29:01 <citizen93> No I mean setting in GHC some flag
22:29:08 <citizen93> that I can temporary enable it and disable it?
22:29:34 <citizen93> http://www.haskell.org/haskellwiki/Debugging, here they say "The advantage is that disabling and enabling the trace takes only one line comment."
22:29:49 <citizen93> and now I'm wondering which line comment... :(
22:29:51 <adnap> ion: What is your favorite animal?
22:30:05 <adnap> ion: (Besides humans)
22:30:05 <ion> adnap: Giraffe, i guess. But i like all of them. :-P
22:30:11 <startling> ion, what's your favorite kind of battery?
22:30:19 <ion> adnap: Humans certainly aren’t my favorite animal. ;-)
22:30:25 <adnap> Dang
22:30:40 <adnap> That's... humans are the best IMO :P
22:30:47 <ion> *Some* humans are great.
22:31:35 <startling> ion, what's your favorite kind of particle?
22:31:38 <ion> citizen93: If you use the style shown as the “common idiom” just commenting out the first line suffices.
22:31:47 <ion> startling: Any virtual one.
22:31:59 <startling> :(
22:32:34 <adnap> Are particles real?
22:32:53 <adnap> Maybe they're just a concept that represents something else
22:33:06 <citizen93> alright I will look, thanks ion!
22:33:23 <ion> Iso Haskell Philosophy
22:33:58 <citizen93> @ion, that was actually not what I was hoping for haha, but it seems there is not a trace function that has a flag to do that :)
22:33:58 <lambdabot> Unknown command, try @list
22:34:08 <citizen93> Thanks for explaining ion!
22:34:28 <ion> citizen93: You could also use CPP to switch between the real and a dummy implementation of trace using a compile-time flag.
22:35:17 <adnap> Do you get used to the s t a b type synonym eventually?
22:35:30 <adnap> It just seems to obfuscate things for me
22:35:30 <johnw> @forget kmc johnw: I'm rejoining this channel after months away just to tell you how incredibly wrong you are that monads are the "core concept" of Haskell
22:35:31 <lambdabot> Done.
22:35:45 <johnw> it's a bit wrong that that quote was @remembered, as that was not what I intended and now it's on Haskell News
22:35:57 <citizen93> what is CPP?
22:36:00 <ion> {-# LANGUAGE CPP #-}, …, #if TRACE, import …, #else, trace :: …, trace … = …, #endif, and compile with -DTRACE
22:36:05 <startling> citizen93: the C preprocessor
22:36:15 <Gracenotes> johnw: notify who remember'd it?
22:36:22 <johnw> I don't know who did
22:36:43 <roboguy_> the lens stuff you guys were just talking about is sort of making sense to me, but the type synonyms in the lens library kind of throw me off
22:36:50 <ion> chrisdone @remembered it.
22:36:59 <johnw> aha, ok
22:37:04 <johnw> who do you find that out?
22:37:08 <ion> adnap: I’m not too happy with s t a b, but you do get used to it.
22:37:09 <startling> roboguy_, you get used to it.
22:37:16 <ion> johnw: The IRC logs.
22:37:19 <johnw> then I know that chrisdone did it in jest
22:37:21 <johnw> oh yeah, duh
22:37:24 <citizen93> ah thanks ion, but I was hoping for that this could be possible without compiling, because I want to set the interpreter flags
22:37:38 <startling> there's a lot of hidden machinery going on in lens that you don't need to worry about to get a grasp on the library
22:37:42 <citizen93> (maybe I'm way too optimistic what is possible with Haskell :P)
22:38:12 <startling> citizen93, that's not really what trace is for, I think
22:38:26 <adnap> I think I will begin using lens instead of using record syntax
22:38:31 <citizen93> what I want is :r, then some command to set some flag and then run main
22:38:35 <NemesisD> is it possible to write a quickcheck test that rather than using some global Arbitrary instance, chooses random values within certain parameters?
22:38:40 <adnap> e.g f { g = 2 }
22:38:46 <citizen93> and depending on the command, showing the trace debugging lines
22:38:52 <startling> citizen93: if you were using a Writer(T), you could pretty easily shut it off (or just ignore the output)
22:39:05 <johnw> what is the opposite of "persistent"?  is it just "mutable"?
22:39:10 <startling> well, MonadWriter
22:39:12 <citizen93> XD that's too bad then, I'm not using a Writer(T)
22:39:13 <adnap> over _g (const 2) f
22:39:15 <startling> johnw: ephemeral?
22:39:20 <NemesisD> to test a function Foo -> Bar -> Baz, i want to generate Foos and Bars that share a similar pool of values
22:39:21 <citizen93> nor a MonadWriter
22:39:29 <ion> citizen93: If you are going to leave the trace calls to the code and add infrastructure for the user to control it, you almost certainly should use something other than trace.
22:40:09 <roboguy_> there isn't a ghci command to tell me what a type synonym is, is there?
22:40:09 <startling> > getConst $ tell "abc"
22:40:10 <lambdabot>   No instance for (Control.Monad.Writer.Class.MonadWriter
22:40:10 <lambdabot>                    ...
22:40:15 <startling> roboguy_, :info
22:40:31 <citizen93> ah icic, yes but the traces should be removed upon distribution. So I only wanted to use it so I can eliminate all the output
22:40:36 <roboguy_> startling: cool, thanks
22:40:37 <citizen93> so I can just see the result
22:41:00 <citizen93> now, it's like a flood of trace results that I sometimes want to enable and sometimes want to disable.
22:41:19 <startling> roboguy_: it'll tell you the definition of a type or class, where it was defined, and its instances
22:41:43 <roboguy_> startling: wow, that will come in handy
22:43:11 <adnap> startling: I keep imagining a Spalding basketball when I read your name
22:43:21 <startling> adnap, haha
22:43:28 <Gracenotes> hm. it's interesting how Haskell's concurrency models seem to be converging on Erlang's nowadays :p
22:43:33 <startling> most people thin it's "starling"
22:43:46 <startling> well, most people who misread it.
22:43:51 <Gracenotes> at least in some corners. but, Erlang's is pretty nice... nicer than MVars and forkIO.
22:44:00 <adnap> Oh man, I want to understand Haskell concurrency
22:44:16 <adnap> But I haven't even finished a program that I want to optimize yet
22:44:21 <Gracenotes> yeah, so like, basically, it's purity and stuff. yeah.
22:44:49 <Gracenotes> and laziness. but laziness, like, completely is all about purity, but also about being lazy. totally.
22:44:53 <ion> gracenotes: “Cloud Haskell” even attempts to copy most of Erlang/OTP’s goodness verbatim.
22:47:39 <Gracenotes> I'm not sure if Cloud Haskell will necessarily reach the same hyper-performance-oriented bottlenecks of e.g. some of the C-MPI-based code out there, but... it's also Haskell.
22:47:50 <Gracenotes> I am watching some talks to learn more about it.
22:47:55 <zRecursive> Haskell is used to study forever, Erlang is now used to make money :)
22:48:58 <startling> @faq can haskell make money?
22:48:58 <lambdabot> The answer is: Yes! Haskell can do that.
22:49:07 <startling> @faq can haskell be used to study forever?
22:49:08 <lambdabot> The answer is: Yes! Haskell can do that.
22:49:31 <adnap> @faq what is haskell?
22:49:31 <lambdabot> The answer is: Yes! Haskell can do that.
22:49:35 <mm_freak_> > (3, 5) & _1 %&!~ sin
22:49:38 <lambdabot>   Stabbed by s t a b for (Control.Lens.%&!~)
22:49:38 <lambdabot>  Possible fix: use a simple lens
22:49:49 <startling> haha what
22:49:50 <adnap> Gross
22:49:56 <adnap> Is that lens syntax?
22:50:02 <adnap> It looks terrible
22:50:22 * ksf wonders why there's no integrated logging/exception framework. errors and errors and error providers and extensible exceptions line up perfectly.
22:50:53 <mapreduce> It means, take a tuple of 3 and 5, then with the first element %&!~ing apply sin to it.
22:51:17 <shachaf> No, it's not lens syntax. It's people making fun of lens.
22:51:33 <mapreduce> What's lambdabot's error message about?
22:51:44 <shachaf> It's not an error message.
22:52:02 <startling> :t (%&!)
22:52:02 <lambdabot> Not in scope: `%&!'
22:52:26 <mm_freak_> @let data XXX = XXX
22:52:27 <lambdabot>  Defined.
22:52:32 <mapreduce> Ok, what does Stabbed by s t a b for (Control.Lens.%&!~) mean?
22:52:36 <mm_freak_> @let instance Show XXX where show = const "blah"
22:52:37 <lambdabot>  Defined.
22:52:38 <startling> did someone special-case that in lambdabot?
22:52:39 <mm_freak_> > XXX
22:52:42 <lambdabot>   blah
22:52:46 <mm_freak_> @undefine
22:52:46 <lambdabot> Undefined.
22:52:51 <startling> :t my_1
22:52:52 <lambdabot> Not in scope: `my_1'
22:52:53 <startling> :(
22:52:59 <roboguy_> :t (%%!~)
22:53:00 <lambdabot> Not in scope: `%%!~'
22:53:19 <ksf> I'd like a mix of monad-abort-fd and hslogger
22:53:20 <mm_freak_> it's no longer there…  i used the above technique
22:54:56 <adnap> mm_freak_: How do you type ...?
22:55:01 <adnap> …
22:55:04 <adnap> Nevermind
22:55:09 <adnap> I can do it with Japanese input
22:55:15 <ion> compose . .
22:55:21 <mm_freak_> adnap: xmodmap
22:55:28 <adnap> !xmodmap
22:55:59 <Gracenotes> I have seen some interesting concurrency things based on Datalog
22:56:27 <Gracenotes> Which are even purer than many Haskell concurrency things, which often give you IO.
22:56:52 <Gracenotes> of course, you can always fit Datalog into a Monad, but I'm not sure if anyone's done that in Haskell for concurrency purposes
22:56:55 <adnap> @type traverse
22:56:56 <lambdabot>     Not in scope: `traverse'
22:56:56 <lambdabot>     Perhaps you meant one of these:
22:56:56 <lambdabot>       `T.traverse' (imported from Data.Traversable),
22:57:02 <adnap> @type T.traverse
22:57:03 <lambdabot> (Applicative f, T.Traversable t) => (a -> f b) -> t a -> f (t b)
22:57:19 <adnap> @type T.traverse . T.traverse
22:57:19 <lambdabot> (Applicative f, T.Traversable t, T.Traversable t1) => (a -> f b) -> t (t1 a) -> f (t (t1 b))
22:58:40 <startling> > (T.traverse . T.traverse) (+ 2) [[1, 2, 3]]
22:58:41 <lambdabot>   No instance for (Control.Applicative.Applicative f0)
22:58:41 <lambdabot>    arising from a use ...
22:59:05 <startling>  > (T.traverse . T.traverse) (Just . (+ 2)) [[1, 2, 3]]
22:59:19 <startling> > (T.traverse . T.traverse) (Just . (+ 2)) [[1, 2, 3]]
22:59:20 <lambdabot>   Just [[3,4,5]]
22:59:23 <startling> there we go.
23:00:16 <adnap> > (fmap . fmap) (Just . (+ 2)) [[1, 2, 3]]
23:00:17 <lambdabot>   [[Just 3,Just 4,Just 5]]
23:01:08 <adnap> > (T.traverse . fmap) (Just . (+ 2)) [[1, 2, 3]]
23:01:11 <lambdabot>   [[Just 3],[Just 4],[Just 5]]
23:09:09 <adnap> This is giving me trouble:
23:09:12 <adnap> example4f = view (_1 . traverse . _dogName)
23:09:13 <adnap> (Just (Dog "D-G" "Steve" 0.5), Nothing)
23:09:46 <adnap> -- "D-G"
23:10:27 <ion> _1 goes into the first element of the outer (,), the traverse goes into the Maybe and finally _dogName goes into the Dog field.
23:10:31 <adnap> > T.traverse (Just . (+1)) (2, 3)
23:10:34 <lambdabot>   No instance for (Data.Traversable.Traversable ((,) t0))
23:10:35 <lambdabot>    arising from a u...
23:11:08 <startling> I don't know why there isn't a traversable instance for tuples
23:11:12 <startling> there's a Functor one
23:11:18 <startling> > fmap (+ 1) ('a', 0)
23:11:19 <lambdabot>   ('a',1)
23:11:27 <ion> instance Traversable ((,) b)   -- Defined in `Control.Lens.Internal.Instances'
23:11:29 <ion> ;-)
23:12:13 <adnap> ion: You seemingly listed the actions in reverse
23:12:46 <ion> adnap: Analogy: in map (map (map f)), the innermost “map” works on the innermost nested list.
23:12:57 <adnap> Yeah
23:30:13 <ksf> the main problem I have with
23:30:37 <ksf> irc is that I start to type stuff then don't send it and after hours accidentally hit enter.
23:52:50 <shachaf> Hmm, is there a function with a type like Data a => DataType -> Proxy a? To get the Data dictionary from a DataType?
23:53:14 <shachaf> I suppose that wouldn't really work.
23:55:02 <shachaf> Er, that type was just backwards.
23:55:13 <shachaf> What I want is DataType -> Data a *> Proxy a
23:55:30 <shachaf> I.e. data Foo a = forall a. Data a => a; foo :: DataType -> Foo
23:56:46 <external-reality> When something that is clearly a set of things get modeled as a list of things a unicorn kills himself.
23:57:39 <external-reality> ...by swallowing his tongue.
